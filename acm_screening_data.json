{
  "ft_included": [
    {
      "openalex_id": "https://openalex.org/W4395464415",
      "doi": "10.1145/3660631",
      "title": "Leveraging Simulation Data to Understand Bias in Predictive Models of Infectious Disease Spread",
      "abstract": "The spread of infectious diseases is a highly complex spatiotemporal process, difficult to understand, predict, and effectively respond to. Machine learning and artificial intelligence (AI) have achieved impressive results in other learning and prediction tasks; however, while many AI solutions are developed for disease prediction, only a few of them are adopted by decision-makers to support policy interventions. Among several issues preventing their uptake, AI methods are known to amplify the bias in the data they are trained on. This is especially problematic for infectious disease models that typically leverage large, open, and inherently biased spatiotemporal data. These biases may propagate through the modeling pipeline to decision-making, resulting in inequitable policy interventions. Therefore, there is a need to gain an understanding of how the AI disease modeling pipeline can mitigate biased input data, in-processing models, and biased outputs. Specifically, our vision is to develop a large-scale micro-simulation of individuals from which human mobility, population, and disease ground-truth data can be obtained. From this complete dataset\u2014which may not reflect the real world\u2014we can sample and inject different types of bias. By using the sampled data in which bias is known (as it is given as the simulation parameter), we can explore how existing solutions for fairness in AI can mitigate and correct these biases and investigate novel AI fairness solutions. Achieving this vision would result in improved trust in such models for informing fair and equitable policy interventions.",
      "year": "2024",
      "journal": "ACM Transactions on Spatial Algorithms and Systems",
      "authors": "Andreas Z\u00fcfle et al.",
      "keywords": "Computer science; Infectious disease (medical specialty); Disease; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3660631",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Guideline/Policy",
      "ai_ml_method": "Clinical Prediction Model",
      "health_domain": "ICU/Critical Care; Infectious Disease",
      "bias_axes": "Age",
      "lifecycle_stage": "Model Development/Training",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "ICU; Public Health/Population",
      "key_findings": "By using the sampled data in which bias is known (as it is given as the simulation parameter), we can explore how existing solutions for fairness in AI can mitigate and correct these biases and investigate novel AI fairness solutions. Achieving this vision would result in improved trust in such models for informing fair and equitable policy interventions."
    },
    {
      "openalex_id": "https://openalex.org/W4390824398",
      "doi": "10.1145/3631455",
      "title": "Bias Mitigation in Federated Learning for Edge Computing",
      "abstract": "Federated learning (FL) is a distributed machine learning paradigm that enables data owners to collaborate on training models while preserving data privacy. As FL effectively leverages decentralized and sensitive data sources, it is increasingly used in ubiquitous computing including remote healthcare, activity recognition, and mobile applications. However, FL raises ethical and social concerns as it may introduce bias with regard to sensitive attributes such as race, gender, and location. Mitigating FL bias is thus a major research challenge. In this paper, we propose Astral, a novel bias mitigation system for FL. Astral provides a novel model aggregation approach to select the most effective aggregation weights to combine FL clients' models. It guarantees a predefined fairness objective by constraining bias below a given threshold while keeping model accuracy as high as possible. Astral handles the bias of single and multiple sensitive attributes and supports all bias metrics. Our comprehensive evaluation on seven real-world datasets with three popular bias metrics shows that Astral outperforms state-of-the-art FL bias mitigation techniques in terms of bias mitigation and model accuracy. Moreover, we show that Astral is robust against data heterogeneity and scalable in terms of data size and number of FL clients. Astral's code base is publicly available.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Yasmine Djebrouni et al.",
      "keywords": "Computer science; Scalability; Enhanced Data Rates for GSM Evolution; Data science; Gender bias; Data mining; Artificial intelligence; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3631455",
      "cited_by_count": 15,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Methodology",
      "ai_ml_method": "Federated Learning",
      "health_domain": "General Healthcare",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age; Intersectional",
      "lifecycle_stage": "Data Collection; Model Evaluation; Deployment",
      "assessment_or_mitigation": "Both",
      "approach_method": "Threshold Adjustment; Federated Learning",
      "clinical_setting": "Telehealth/Remote",
      "key_findings": "Moreover, we show that Astral is robust against data heterogeneity and scalable in terms of data size and number of FL clients. Astral's code base is publicly available."
    },
    {
      "openalex_id": "https://openalex.org/W3092541244",
      "doi": "10.1145/3616865",
      "title": "Fairness in Machine Learning: A Survey",
      "abstract": "When Machine Learning technologies are used in contexts that affect citizens, companies as well as researchers need to be confident that there will not be any unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote fairness, yet the area is complex and hard to penetrate for newcomers to the domain. This article seeks to provide an overview of the different schools of thought and approaches that aim to increase the fairness of Machine Learning. It organizes approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, and unsupervised learning is also provided along with a selection of currently available open source libraries. The article concludes by summarizing open challenges articulated as five dilemmas for fairness research.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Simon Caton et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3616865",
      "cited_by_count": 392,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "Generative AI; Clustering",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Gender/Sex",
      "lifecycle_stage": "Data Preprocessing; Model Development/Training; Model Evaluation",
      "assessment_or_mitigation": "Mitigation",
      "approach_method": "Post-hoc Correction",
      "clinical_setting": "ICU",
      "key_findings": "Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, and unsupervised learning is also provided along with a selection of currently available open source libraries. The article concludes by summarizing open challenges articulated as five dilemmas for fairness research."
    },
    {
      "openalex_id": "https://openalex.org/W4388229648",
      "doi": "10.1145/3631326",
      "title": "Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey",
      "abstract": "This article provides a comprehensive survey of bias mitigation methods for achieving fairness in Machine Learning (ML) models. We collect a total of 341 publications concerning bias mitigation for ML classifiers. These methods can be distinguished based on their intervention procedure (i.e., pre-processing, in-processing, post-processing) and the technique they apply. We investigate how existing bias mitigation methods are evaluated in the literature. In particular, we consider datasets, metrics, and benchmarking. Based on the gathered insights (e.g., What is the most popular fairness metric? How many datasets are used for evaluating bias mitigation methods?), we hope to support practitioners in making informed choices when developing and evaluating new bias mitigation methods.",
      "year": "2023",
      "journal": "ACM Journal on Responsible Computing",
      "authors": "Max Hort et al.",
      "keywords": "Machine learning; Artificial intelligence; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3631326",
      "cited_by_count": 165,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Not specified",
      "lifecycle_stage": "Data Preprocessing; Model Development/Training; Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Fairness Metrics Evaluation; Post-hoc Correction",
      "clinical_setting": "ICU",
      "key_findings": "Based on the gathered insights (e.g., What is the most popular fairness metric? How many datasets are used for evaluating bias mitigation methods?), we hope to support practitioners in making informed choices when developing and evaluating new bias mitigation methods."
    },
    {
      "openalex_id": "https://openalex.org/W4390002645",
      "doi": "10.1145/3637549",
      "title": "Fairness in Deep Learning: A Survey on Vision and Language Research",
      "abstract": "Despite being responsible for state-of-the-art results in several computer vision and natural language processing tasks, neural networks have faced harsh criticism due to some of their current shortcomings. One of them is that neural networks are correlation machines prone to model biases within the data instead of focusing on actual useful causal relationships. This problem is particularly serious in application domains affected by aspects such as race, gender, and age. To prevent models from incurring unfair decision-making, the AI community has concentrated efforts on correcting algorithmic biases, giving rise to the research area now widely known as fairness in AI . In this survey paper, we provide an in-depth overview of the main debiasing methods for fairness-aware neural networks in the context of vision and language research. We propose a novel taxonomy that builds upon previous proposals but is tailored for deep learning research to better organize the literature on debiasing methods for fairness. We review all important neural-based methods and evaluation metrics while discussing the current challenges, trends, and important future work directions for the interested researcher and practitioner.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Ot\u00e1vio Parraga et al.",
      "keywords": "Debiasing; Computer science; Artificial intelligence; Artificial neural network; Taxonomy (biology); Deep learning; Machine learning; Deep neural networks; Data science; Context (archaeology); Cognitive science; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3637549",
      "cited_by_count": 35,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "Deep Learning; NLP/LLM; Neural Network; Computer Vision/Imaging AI; Generative AI",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age; Language",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "ICU; Public Health/Population",
      "key_findings": "We propose a novel taxonomy that builds upon previous proposals but is tailored for deep learning research to better organize the literature on debiasing methods for fairness. We review all important neural-based methods and evaluation metrics while discussing the current challenges, trends, and important future work directions for the interested researcher and practitioner."
    },
    {
      "openalex_id": "https://openalex.org/W4224281327",
      "doi": "10.1145/3524887",
      "title": "Interpretable Bias Mitigation for Textual Data: Reducing Genderization in Patient Notes While Maintaining Classification Performance",
      "abstract": "Medical systems in general, and patient treatment decisions and outcomes in particular, can be affected by bias based on gender and other demographic elements. As language models are increasingly applied to medicine, there is a growing interest in building algorithmic fairness into processes impacting patient care. Much of the work addressing this question has focused on biases encoded in language models\u2014statistical estimates of the relationships between concepts derived from distant reading of corpora. Building on this work, we investigate how differences in gender-specific word frequency distributions and language models interact with regards to bias. We identify and remove gendered language from two clinical-note datasets and describe a new debiasing procedure using BERT-based gender classifiers. We show minimal degradation in health condition classification tasks for low- to medium-levels of dataset bias removal via data augmentation. Finally, we compare the bias semantically encoded in the language models with the bias empirically observed in health records. This work outlines an interpretable approach for using data augmentation to identify and reduce biases in natural language processing pipelines.",
      "year": "2022",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Joshua R. Minot et al.",
      "keywords": "Debiasing; Computer science; Language model; Artificial intelligence; Reading (process); Gender bias; Natural language processing; Work (physics); Machine learning; Health care; Data science; Psychology; Linguistics; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3524887",
      "cited_by_count": 24,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias central + approach content",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "NLP/LLM",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age; Language",
      "lifecycle_stage": "Data Preprocessing",
      "assessment_or_mitigation": "Both",
      "approach_method": "Data Augmentation; Explainability/Interpretability",
      "clinical_setting": "ICU",
      "key_findings": "Finally, we compare the bias semantically encoded in the language models with the bias empirically observed in health records. This work outlines an interpretable approach for using data augmentation to identify and reduce biases in natural language processing pipelines."
    },
    {
      "openalex_id": "https://openalex.org/W4311212906",
      "doi": "10.1145/3527152",
      "title": "Mitigating Bias in Algorithmic Systems\u2014A Fish-eye View",
      "abstract": "Mitigating bias in algorithmic systems is a critical issue drawing attention across communities within the information and computer sciences. Given the complexity of the problem and the involvement of multiple stakeholders\u2014including developers, end users, and third-parties\u2014there is a need to understand the landscape of the sources of bias, and the solutions being proposed to address them, from a broad, cross-domain perspective. This survey provides a \u201cfish-eye view,\u201d examining approaches across four areas of research. The literature describes three steps toward a comprehensive treatment\u2014bias detection, fairness management, and explainability management\u2014and underscores the need to work from within the system as well as from the perspective of stakeholders in the broader context.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Kalia Orphanou et al.",
      "keywords": "Computer science; Perspective (graphical); Context (archaeology); Domain (mathematical analysis); Data science; Fish <Actinopterygii>; Work (physics); Human\u2013computer interaction; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3527152",
      "cited_by_count": 40,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "Not specified",
      "health_domain": "General Healthcare",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Explainability/Interpretability",
      "clinical_setting": "Not specified",
      "key_findings": "This survey provides a \u201cfish-eye view,\u201d examining approaches across four areas of research. The literature describes three steps toward a comprehensive treatment\u2014bias detection, fairness management, and explainability management\u2014and underscores the need to work from within the system as well as from the perspective of stakeholders in the broader context."
    },
    {
      "openalex_id": "https://openalex.org/W3162710786",
      "doi": "10.1145/3468507.3468518",
      "title": "An Empirical Comparison of Bias Reduction Methods on Real-World Problems in High-Stakes Policy Settings",
      "abstract": "Applications of machine learning (ML) to high-stakes policy settings - such as education, criminal justice, healthcare, and social service delivery - have grown rapidly in recent years, sparking important conversations about how to ensure fair outcomes from these systems. The machine learning research community has responded to this challenge with a wide array of proposed fairness-enhancing strategies for ML models, but despite the large number of methods that have been developed, little empirical work exists evaluating these methods in real-world settings. Here, we seek to fill this research gap by investigating the performance of several methods that operate at different points in the ML pipeline across four real-world public policy and social good problems. Across these problems, we find a wide degree of variability and inconsistency in the ability of many of these methods to improve model fairness, but postprocessing by choosing group-specific score thresholds consistently removes disparities, with important implications for both the ML research community and practitioners deploying machine learning to inform consequential policy decisions.",
      "year": "2021",
      "journal": "ACM SIGKDD Explorations Newsletter",
      "authors": "Hemank Lamba et al.",
      "keywords": "Pipeline (software); Empirical research; Computer science; Machine learning; Social work; Work (physics); Artificial intelligence; Economics; Engineering; Economic growth",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3468507.3468518",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_include": true,
      "ft_reason": "Included: bias is central topic (abstract only)",
      "study_type": "Guideline/Policy",
      "ai_ml_method": "Not specified",
      "health_domain": "General Healthcare",
      "bias_axes": "Not specified",
      "lifecycle_stage": "Deployment",
      "assessment_or_mitigation": "Both",
      "approach_method": "Threshold Adjustment",
      "clinical_setting": "Public Health/Population",
      "key_findings": "Here, we seek to fill this research gap by investigating the performance of several methods that operate at different points in the ML pipeline across four real-world public policy and social good problems. Across these problems, we find a wide degree of variability and inconsistency in the ability of many of these methods to improve model fairness, but postprocessing by choosing group-specific score thresholds consistently removes disparities, with important implications for both the ML researc..."
    }
  ],
  "ft_excluded": [
    {
      "openalex_id": "https://openalex.org/W4384696745",
      "doi": "10.1145/3609502",
      "title": "Bias in Reinforcement Learning: A Review in Healthcare Applications",
      "abstract": "Reinforcement learning (RL) can assist in medical decision making using patient data collected in electronic health record (EHR) systems. RL, a type of machine learning, can use these data to develop treatment policies. However, RL models are typically trained using imperfect retrospective EHR data. Therefore, if care is not taken in training, RL policies can propagate existing bias in healthcare. Literature that considers and addresses the issues of bias and fairness in sequential decision making are reviewed. The major themes to mitigate bias that emerge relate to (1) data management; (2) algorithmic design; and (3) clinical understanding of the resulting policies.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Benjamin Smith et al.",
      "keywords": "Reinforcement learning; Computer science; Health care; Imperfect; Artificial intelligence; Health records; Machine learning; Perfect information",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3609502",
      "cited_by_count": 18,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W3021559413",
      "doi": "10.1145/3386295",
      "title": "An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification",
      "abstract": "Precise and efficient automated identification of gastrointestinal (GI) tract diseases can help doctors treat more patients and improve the rate of disease detection and identification. Currently, automatic analysis of diseases in the GI tract is a hot topic in both computer science and medical-related journals. Nevertheless, the evaluation of such an automatic analysis is often incomplete or simply wrong. Algorithms are often only tested on small and biased datasets, and cross-dataset evaluations are rarely performed. A clear understanding of evaluation metrics and machine learning models with cross datasets is crucial to bring research in the field to a new quality level. Toward this goal, we present comprehensive evaluations of five distinct machine learning models using global features and deep neural networks that can classify 16 different key types of GI tract conditions, including pathological findings, anatomical landmarks, polyp removal conditions, and normal findings from images captured by common GI tract examination instruments. In our evaluation, we introduce performance hexagons using six performance metrics, such as recall, precision, specificity, accuracy, F1-score, and the Matthews correlation coefficient to demonstrate how to determine the real capabilities of models rather than evaluating them shallowly. Furthermore, we perform cross-dataset evaluations using different datasets for training and testing. With these cross-dataset evaluations, we demonstrate the challenge of actually building a generalizable model that could be used across different hospitals. Our experiments clearly show that more sophisticated performance metrics and evaluation methods need to be applied to get reliable models rather than depending on evaluations of the splits of the same dataset\u2014that is, the performance metrics should always be interpreted together rather than relying on a single metric.",
      "year": "2020",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Vajira Thambawita et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Identification (biology); Precision and recall; Abnormality; Field (mathematics); F1 score; Deep learning; Data mining; Cross-validation; Pattern recognition (psychology); Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3386295",
      "cited_by_count": 66,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4385322130",
      "doi": "10.1145/3610914",
      "title": "Uncovering Bias in Personal Informatics",
      "abstract": "Personal informatics (PI) systems, powered by smartphones and wearables, enable people to lead healthier lifestyles by providing meaningful and actionable insights that break down barriers between users and their health information. Today, such systems are used by billions of users for monitoring not only physical activity and sleep but also vital signs and women's and heart health, among others. Despite their widespread usage, the processing of sensitive PI data may suffer from biases, which may entail practical and ethical implications. In this work, we present the first comprehensive empirical and analytical study of bias in PI systems, including biases in raw data and in the entire machine learning life cycle. We use the most detailed framework to date for exploring the different sources of bias and find that biases exist both in the data generation and the model learning and implementation streams. According to our results, the most affected minority groups are users with health issues, such as diabetes, joint issues, and hypertension, and female users, whose data biases are propagated or even amplified by learning models, while intersectional biases can also be observed.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Sofia Yfantidou et al.",
      "keywords": "Informatics; Wearable computer; Computer science; Health informatics; Wearable technology; Internet privacy; Data science; Raw data; Human\u2013computer interaction; Applied psychology; Psychology; Health care; Engineering; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610914",
      "cited_by_count": 8,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4387344911",
      "doi": "10.1145/3610213",
      "title": "The Potential of Diverse Youth as Stakeholders in Identifying and Mitigating Algorithmic Bias for a Future of Fairer AI",
      "abstract": "Youth regularly use technology driven by artificial intelligence (AI). However, it is increasingly well-known that AI can cause harm on small and large scales, especially for those underrepresented in tech fields. Recently, users have played active roles in surfacing and mitigating harm from algorithmic bias. Despite being frequent users of AI, youth have been under-explored as potential contributors and stakeholders to the future of AI. We consider three notions that may be at the root of youth facing barriers to playing an active role in responsible AI, which are youth (1) cannot understand the technical aspects of AI, (2) cannot understand the ethical issues around AI, and (3) need protection from serious topics related to bias and injustice. In this study, we worked with youth (N = 30) in first through twelfth grade and parents (N = 6) to explore how youth can be part of identifying algorithmic bias and designing future systems to address problematic technology behavior. We found that youth are capable of identifying and articulating algorithmic bias, often in great detail. Participants suggested different ways users could give feedback for AI that reflects their values of diversity and inclusion. Youth who may have less experience with computing or exposure to societal structures can be supported by peers or adults with more of this knowledge, leading to critical conversations about fairer AI. This work illustrates youths' insights, suggesting that they should be integrated in building a future of responsible AI.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Jaemarie Solyst et al.",
      "keywords": "Harm; Diversity (politics); Injustice; Inclusion (mineral); Psychology; Political science; Computer science; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610213",
      "cited_by_count": 51,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W4386193772",
      "doi": "10.1145/3616380",
      "title": "Analysis of Performance Improvements and Bias Associated with the Use of Human Mobility Data in COVID-19 Case Prediction Models",
      "abstract": "The COVID-19 pandemic has mainstreamed human mobility data into the public domain, with research focused on understanding the impact of mobility reduction policies as well as on regional COVID-19 case prediction models. Nevertheless, current research on COVID-19 case prediction tends to focus on performance improvements, masking relevant insights about when mobility data does not help, and more importantly, why, so that it can adequately inform local decision making. In this article, we carry out a systematic analysis to reveal the conditions under which human mobility data provides (or not) an enhancement over individual regional COVID-19 case prediction models that do not use mobility as a source of information. Our analysis\u2014focused on U.S. county-based COVID-19 case prediction models\u2014shows that (1) at most, 60% of counties improve their performance after adding mobility data; (2) the performance improvements are modest, with median correlation improvements of approximately 0.13; (3) improvements were lower for counties with higher Black, Hispanic, and other non-White populations as well as low-income and rural populations, pointing to potential bias in the mobility data negatively impacting predictive performance; and (4) different mobility datasets, predictive models, and training approaches bring about diverse performance improvements.",
      "year": "2023",
      "journal": "ACM Journal on Computing and Sustainable Societies",
      "authors": "Saad Mohammad Abrar et al.",
      "keywords": "Coronavirus disease 2019 (COVID-19); Masking (illustration); Computer science; Predictive modelling; Econometrics; Data science; Machine learning; Mathematics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3616380",
      "cited_by_count": 8,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2971288133",
      "doi": "10.1145/3386296.3386300",
      "title": "Artificial intelligence fairness in the context of accessibility research on intelligent systems for people who are deaf or hard of hearing",
      "abstract": "We discuss issues of Artificial Intelligence (AI) fairness for people with disabilities, with examples drawn from our research on HCI for AI-based systems for people who are Deaf or Hard of Hearing (DHH). In particular, we discuss the need for inclusion of data from people with disabilities in training sets, the lack of interpretability of AI systems, ethical responsibilities of access technology researchers and companies, the need for appropriate evaluation metrics for AI-based access technologies (to determine if they are ready to be deployed and if they can be trusted by users), and the ways in which AI systems influence human behavior and influence the set of abilities needed by users to successfully interact with computing systems.",
      "year": "2020",
      "journal": "ACM SIGACCESS Accessibility and Computing",
      "authors": "Sushant Kafle et al.",
      "keywords": "Interpretability; Computer science; Set (abstract data type); Inclusion (mineral); Context (archaeology); Human\u2013computer interaction; Universal design; Knowledge management; Artificial intelligence; World Wide Web; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3386296.3386300",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W3201690998",
      "doi": "10.1145/3639368",
      "title": "Fairness-Driven Private Collaborative Machine Learning",
      "abstract": "The performance of machine learning algorithms can be considerably improved when trained over larger datasets. In many domains, such as medicine and finance, larger datasets can be obtained if several parties, each having access to limited amounts of data, collaborate and share their data. However, such data sharing introduces significant privacy challenges. While multiple recent studies have investigated methods for private collaborative machine learning, the fairness of such collaborative algorithms has been overlooked. In this work, we suggest a feasible privacy-preserving pre-process mechanism for enhancing fairness of collaborative machine learning algorithms. An extensive evaluation of the proposed method shows that it is able to enhance fairness considerably with only a minor compromise in accuracy.",
      "year": "2024",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Dana Pessach et al.",
      "keywords": "Computer science; Compromise; Machine learning; Artificial intelligence; Process (computing); Data sharing; Collaborative learning; Knowledge management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3639368",
      "cited_by_count": 7,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "Excluded: insufficient approach content (0 indicators)"
    },
    {
      "openalex_id": "https://openalex.org/W3181952565",
      "doi": "10.1145/3473673",
      "title": "How Could Equality and Data Protection Law Shape AI Fairness for People with Disabilities?",
      "abstract": "This article examines the concept of \u2018AI fairness\u2019 for people with disabilities from the perspective of data protection and equality law. This examination demonstrates that there is a need for a distinctive approach to AI fairness that is fundamentally different to that used for other protected characteristics, due to the different ways in which discrimination and data protection law applies in respect of Disability. We articulate this new agenda for AI fairness for people with disabilities, explaining how combining data protection and equality law creates new opportunities for disabled people's organisations and assistive technology researchers alike to shape the use of AI, as well as to challenge potential harmful uses.",
      "year": "2021",
      "journal": "ACM Transactions on Accessible Computing",
      "authors": "Reuben Binns et al.",
      "keywords": "Perspective (graphical); Data Protection Act 1998; Law and economics; Political science; Sociology; Psychology; Law; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3473673",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_include": false,
      "ft_reason": "No AI/ML component"
    }
  ],
  "ta_excluded": [
    {
      "openalex_id": "https://openalex.org/W2970837303",
      "doi": "10.1145/3359206",
      "title": "\"Hello AI\": Uncovering the Onboarding Needs of Medical Practitioners for Human-AI Collaborative Decision-Making",
      "abstract": "Although rapid advances in machine learning have made it increasingly applicable to expert decision-making, the delivery of accurate algorithmic predictions alone is insufficient for effective human-AI collaboration. In this work, we investigate the key types of information medical experts desire when they are first introduced to a diagnostic AI assistant. In a qualitative lab study, we interviewed 21 pathologists before, during, and after being presented deep neural network (DNN) predictions for prostate cancer diagnosis, to learn the types of information that they desired about the AI assistant. Our findings reveal that, far beyond understanding the local, case-specific reasoning behind any model decision, clinicians desired upfront information about basic, global properties of the model, such as its known strengths and limitations, its subjective point-of-view, and its overall design objective--what it's designed to be optimized for. Participants compared these information needs to the collaborative mental models they develop of their medical colleagues when seeking a second opinion: the medical perspectives and standards that those colleagues embody, and the compatibility of those perspectives with their own diagnostic patterns. These findings broaden and enrich discussions surrounding AI transparency for collaborative decision-making, providing a richer understanding of what experts find important in their introduction to AI assistants before integrating them into routine practice.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Carrie J. Cai et al.",
      "keywords": "Onboarding; Computer science; Applications of artificial intelligence; Transparency (behavior); Clinical decision making; Data science; Artificial intelligence; Knowledge management; Management science; Psychology; Medicine; Engineering; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359206",
      "cited_by_count": 523,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3104128335",
      "doi": "10.1145/3533378",
      "title": "Challenges in Deploying Machine Learning: A Survey of Case Studies",
      "abstract": "In recent years, machine learning has transitioned from a field of academic research interest to a field capable of solving real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries, and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. By mapping found challenges to the steps of the machine learning deployment workflow, we show that practitioners face issues at each stage of the deployment process. The goal of this article is to lay out a research agenda to explore approaches addressing these challenges.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Andrei Paleyes et al.",
      "keywords": "Software deployment; Workflow; Computer science; Artificial intelligence; Machine learning; Field (mathematics); Variety (cybernetics); Data science; Software engineering; Knowledge management; Process management; Database",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3533378",
      "cited_by_count": 495,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2439568532",
      "doi": "10.1145/3233231",
      "title": "The Mythos of Model Interpretability",
      "abstract": "In machine learning, the concept of interpretability is both important and slippery.",
      "year": "2018",
      "journal": "Communications of the ACM",
      "authors": "Zachary C. Lipton",
      "keywords": "Interpretability; Ambiguity; Computer science; Artificial intelligence; Interpretation (philosophy); Transparency (behavior); Machine learning; Cognitive science; Psychology; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3233231",
      "cited_by_count": 456,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3169231731",
      "doi": "10.1145/3412357",
      "title": "Federated Learning in a Medical Context: A Systematic Literature Review",
      "abstract": "Data privacy is a very important issue. Especially in fields like medicine, it is paramount to abide by the existing privacy regulations to preserve patients\u2019 anonymity. However, data is required for research and training machine learning models that could help gain insight into complex correlations or personalised treatments that may otherwise stay undiscovered. Those models generally scale with the amount of data available, but the current situation often prohibits building large databases across sites. So it would be beneficial to be able to combine similar or related data from different sites all over the world while still preserving data privacy. Federated learning has been proposed as a solution for this, because it relies on the sharing of machine learning models, instead of the raw data itself. That means private data never leaves the site or device it was collected on. Federated learning is an emerging research area, and many domains have been identified for the application of those methods. This systematic literature review provides an extensive look at the concept of and research into federated learning and its applicability for confidential healthcare datasets.",
      "year": "2021",
      "journal": "ACM Transactions on Internet Technology",
      "authors": "Bjarne Pfitzner et al.",
      "keywords": "Computer science; Confidentiality; Federated learning; Context (archaeology); Data science; Raw data; Anonymity; Data sharing; Big data; Information privacy; Artificial intelligence; Machine learning; Internet privacy; Data mining; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3412357",
      "cited_by_count": 243,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4280617223",
      "doi": "10.1145/3533708",
      "title": "Federated Learning for Healthcare Domain - Pipeline, Applications and Challenges",
      "abstract": "Federated learning is the process of developing machine learning models over datasets distributed across data centers such as hospitals, clinical research labs, and mobile devices while preventing data leakage. This survey examines previous research and studies on federated learning in the healthcare sector across a range of use cases and applications. Our survey shows what challenges, methods, and applications a practitioner should be aware of in the topic of federated learning. This paper aims to lay out existing research and list the possibilities of federated learning for healthcare industries.",
      "year": "2022",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Madhura Joshi et al.",
      "keywords": "Pipeline (software); Health care; Computer science; Data science; Domain (mathematical analysis); Process (computing); Federated learning; Knowledge management; Artificial intelligence; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3533708",
      "cited_by_count": 154,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2988595016",
      "doi": "10.1145/3359249",
      "title": "Who is the \"Human\" in Human-Centered Machine Learning",
      "abstract": "\"Human-centered machine learning\" (HCML) combines human insights and domain expertise with data-driven predictions to answer societal questions. This area's inherent interdisciplinarity causes tensions in the obligations researchers have to the humans whose data they use. This paper studies how scientific papers represent human research subjects in HCML. Using mental health status prediction on social media as a case study, we conduct thematic discourse analysis on 55 papers to examine these representations. We identify five discourses that weave a complex narrative of who the human subject is in this research: Disorder/Patient, Social Media, Scientific, Data/Machine Learning, and Person. We show how these five discourses create paradoxical subject and object representations of the human, which may inadvertently risk dehumanization. We also discuss the tensions and impacts of interdisciplinary research; the risks of this work to scientific rigor, online communities, and mental health; and guidelines for stronger HCML research in this nascent area.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Stevie Chancellor et al.",
      "keywords": "Dehumanization; Subject (documents); Thematic analysis; Object (grammar); Rigour; Social media; Narrative; Mental health; Psychology; Domain (mathematical analysis); Data science; Sociology; Epistemology; Computer science; Artificial intelligence; Social science; Qualitative research; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359249",
      "cited_by_count": 163,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2992923261",
      "doi": "10.1145/3387166",
      "title": "A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems",
      "abstract": "The need for interpretable and accountable intelligent systems grows along with the prevalence of artificial intelligence ( AI ) applications used in everyday life. Explainable AI ( XAI ) systems are intended to self-explain the reasoning behind system decisions and predictions. Researchers from different disciplines work together to define, design, and evaluate explainable systems. However, scholars from different disciplines focus on different objectives and fairly independent topics of XAI research, which poses challenges for identifying appropriate design and evaluation methodology and consolidating knowledge across efforts. To this end, this article presents a survey and framework intended to share knowledge and experiences of XAI design and evaluation methods across multiple disciplines. Aiming to support diverse design goals and evaluation methods in XAI research, after a thorough review of XAI related papers in the fields of machine learning, visualization, and human-computer interaction, we present a categorization of XAI design goals and evaluation methods. Our categorization presents the mapping between design goals for different XAI user groups and their evaluation methods. From our findings, we develop a framework with step-by-step design guidelines paired with evaluation methods to close the iterative design and evaluation cycles in multidisciplinary XAI teams. Further, we provide summarized ready-to-use tables of evaluation methods and recommendations for different goals in XAI research.",
      "year": "2021",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "Sina Mohseni et al.",
      "keywords": "Multidisciplinary approach; Computer science; Categorization; Management science; Artificial intelligence; Knowledge management; Data science; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3387166",
      "cited_by_count": 172,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4206629261",
      "doi": "10.1145/3490234",
      "title": "The Secondary Use of Electronic Health Records for Data Mining: Data Characteristics and Challenges",
      "abstract": "The primary objective of implementing Electronic Health Records (EHRs) is to improve the management of patients\u2019 health-related information. However, these records have also been extensively used for the secondary purpose of clinical research and to improve healthcare practice. EHRs provide a rich set of information that includes demographics, medical history, medications, laboratory test results, and diagnosis. Data mining and analytics techniques have extensively exploited EHR information to study patient cohorts for various clinical and research applications, such as phenotype extraction, precision medicine, intervention evaluation, disease prediction, detection, and progression. But the presence of diverse data types and associated characteristics poses many challenges to the use of EHR data. In this article, we provide an overview of information found in EHR systems and their characteristics that could be utilized for secondary applications. We first discuss the different types of data stored in EHRs, followed by the data transformations necessary for data analysis and mining. Later, we discuss the data quality issues and characteristics of the EHRs along with the relevant methods used to address them. Moreover, this survey also highlights the usage of various data types for different applications. Hence, this article can serve as a primer for researchers to understand the use of EHRs for data mining and analytics purposes.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Tabinda Sarwar et al.",
      "keywords": "Computer science; Data science; Health records; Analytics; Clinical decision support system; Data extraction; Medical record; Data quality; Data mining; Health care; Medicine; MEDLINE; Decision support system",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3490234",
      "cited_by_count": 114,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3197040406",
      "doi": "10.1145/3531326",
      "title": "Time Series Prediction Using Deep Learning Methods in Healthcare",
      "abstract": "Traditional machine learning methods face unique challenges when applied to healthcare predictive analytics. The high-dimensional nature of healthcare data necessitates labor-intensive and time-consuming processes when selecting an appropriate set of features for each new task. Furthermore, machine learning methods depend heavily on feature engineering to capture the sequential nature of patient data, oftentimes failing to adequately leverage the temporal patterns of medical events and their dependencies. In contrast, recent deep learning (DL) methods have shown promising performance for various healthcare prediction tasks by specifically addressing the high-dimensional and temporal challenges of medical data. DL techniques excel at learning useful representations of medical concepts and patient clinical data as well as their nonlinear interactions from high-dimensional raw or minimally processed healthcare data. In this article, we systematically reviewed research works that focused on advancing deep neural networks to leverage patient structured time series data for healthcare prediction tasks. To identify relevant studies, we searched MEDLINE, IEEE, Scopus, and ACM Digital Library for relevant publications through November 4, 2021. Overall, we found that researchers have contributed to deep time series prediction literature in 10 identifiable research streams: DL models, missing value handling, addressing temporal irregularity, patient representation, static data inclusion, attention mechanisms, interpretation, incorporation of medical ontologies, learning strategies, and scalability. This study summarizes research insights from these literature streams, identifies several critical research gaps, and suggests future research opportunities for DL applications using patient time series data.",
      "year": "2022",
      "journal": "ACM Transactions on Management Information Systems",
      "authors": "Mohammad Amin Morid et al.",
      "keywords": "Computer science; Artificial intelligence; Leverage (statistics); Deep learning; Machine learning; Feature engineering; Health care; Scalability; Data science; Big data; Data stream mining; Feature learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3531326",
      "cited_by_count": 161,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4303427132",
      "doi": "10.1145/3564752",
      "title": "Designing Human-centered AI for Mental Health: Developing Clinically Relevant Applications for Online CBT Treatment",
      "abstract": "Recent advances in AI and machine learning (ML) promise significant transformations in the future delivery of healthcare. Despite a surge in research and development, few works have moved beyond demonstrations of technical feasibility and algorithmic performance. However, to realize many of the ambitious visions for how AI can contribute to clinical impact requires the closer design and study of AI tools or interventions within specific health and care contexts. This article outlines our collaborative, human-centered approach to developing an AI application that predicts treatment outcomes for patients who are receiving human-supported, internet-delivered Cognitive Behavioral Therapy (iCBT) for symptoms of depression and anxiety. Intersecting the fields of HCI, AI, and healthcare, we describe how we addressed the specific challenges of (1) identifying clinically relevant AI applications ; and (2) designing AI applications for sensitive use contexts like mental health. Aiming to better assist the work practices of iCBT supporters, we share how learnings from an interview study with 15 iCBT supporters surfaced their practices and information needs and revealed new opportunities for the use of AI. Combined with insights from the clinical literature and technical feasibility constraints, this led to the development of two clinical outcome prediction models. To clarify their potential utility for use in practice, we conducted 13 design sessions with iCBT supporters that utilized interface mock-ups to concretize the AI output and derive additional design requirements. Our findings demonstrate how design choices can impact interpretations of the AI predictions as well as supporter motivation and sense of agency. We detail how this analysis and the design principles derived from it enabled the integration of the prediction models into a production interface. Reporting on identified risks of over-reliance on AI outputs and needs for balanced information assessment and preservation of a focus on individualized care, we discuss and reflect on what constitutes a responsible, human-centered approach to AI design in this healthcare context.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Anja Thieme et al.",
      "keywords": "Psychological intervention; Vision; Health care; Mental health; Computer science; Psychology; Agency (philosophy); Psychotherapist; Political science; Psychiatry; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3564752",
      "cited_by_count": 132,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4324155120",
      "doi": "10.1145/3587271",
      "title": "Co-design of Human-centered, Explainable AI for Clinical Decision Support",
      "abstract": "eXplainable AI (XAI) involves two intertwined but separate challenges: the development of techniques to extract explanations from black-box AI models and the way such explanations are presented to users, i.e., the explanation user interface. Despite its importance, the second aspect has received limited attention so far in the literature. Effective AI explanation interfaces are fundamental for allowing human decision-makers to take advantage and oversee high-risk AI systems effectively. Following an iterative design approach, we present the first cycle of prototyping-testing-redesigning of an explainable AI technique and its explanation user interface for clinical Decision Support Systems (DSS). We first present an XAI technique that meets the technical requirements of the healthcare domain: sequential, ontology-linked patient data, and multi-label classification tasks. We demonstrate its applicability to explain a clinical DSS, and we design a first prototype of an explanation user interface. Next, we test such a prototype with healthcare providers and collect their feedback with a two-fold outcome: First, we obtain evidence that explanations increase users\u2019 trust in the XAI system, and second, we obtain useful insights on the perceived deficiencies of their interaction with the system, so we can re-design a better, more human-centered explanation interface.",
      "year": "2023",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "Cecilia Panigutti et al.",
      "keywords": "Computer science; Interface (matter); Ontology; Domain (mathematical analysis); Human\u2013computer interaction; User interface; Decision support system; Clinical decision support system; Health care; Outcome (game theory); Test (biology); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3587271",
      "cited_by_count": 74,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387344906",
      "doi": "10.1145/3610219",
      "title": "Understanding the Role of Human Intuition on Reliance in Human-AI Decision-Making with Explanations",
      "abstract": "AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition---beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments---with the information provided by the AI system to determine when to override AI predictions. We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI. Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the task outcome, features, and AI limitations. Building on these, we summarize three observed pathways for decision-makers to apply their own intuition and override AI predictions. We use these pathways to explain why (1) the feature-based explanations we used did not improve participants' decision outcomes and increased their overreliance on AI, and (2) the example-based explanations we used improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance. Overall, our work identifies directions for further development of AI decision-support systems and explanation methods that help decision-makers effectively apply their intuition to achieve appropriate reliance on AI.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Valerie Chen et al.",
      "keywords": "Intuition; Heuristics; Artificial intelligence; Computer science; Empirical evidence; Psychology; Cognitive science; Epistemology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610219",
      "cited_by_count": 95,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2786715987",
      "doi": "10.1145/3236009",
      "title": "A Survey of Methods for Explaining Black Box Models",
      "abstract": "In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.",
      "year": "2018",
      "journal": "ACM Computing Surveys",
      "authors": "Riccardo Guidotti et al.",
      "keywords": "Interpretability; Black box; Perspective (graphical); Computer science; Data science; Management science; Artificial intelligence; Machine learning; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3236009",
      "cited_by_count": 205,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3207701354",
      "doi": "10.1145/3479609",
      "title": "A Human-Centered Systematic Literature Review of the Computational Approaches for Online Sexual Risk Detection",
      "abstract": "In the era of big data and artificial intelligence, online risk detection has become a popular research topic. From detecting online harassment to the sexual predation of youth, the state-of-the-art in computational risk detection has the potential to protect particularly vulnerable populations from online victimization. Yet, this is a high-risk, high-reward endeavor that requires a systematic and human-centered approach to synthesize disparate bodies of research across different application domains, so that we can identify best practices, potential gaps, and set a strategic research agenda for leveraging these approaches in a way that betters society. Therefore, we conducted a comprehensive literature review to analyze 73 peer-reviewed articles on computational approaches utilizing text or meta-data/multimedia for online sexual risk detection. We identified sexual grooming (75%), sex trafficking (12%), and sexual harassment and/or abuse (12%) as the three types of sexual risk detection present in the extant literature. Furthermore, we found that the majority (93%) of this work has focused on identifying sexual predators after-the-fact, rather than taking more nuanced approaches to identify potential victims and problematic patterns that could be used to prevent victimization before it occurs. Many studies rely on public datasets (82%) and third-party annotators (33%) to establish ground truth and train their algorithms. Finally, the majority of this work (78%) mostly focused on algorithmic performance evaluation of their model and rarely (4%) evaluate these systems with real users. Thus, we urge computational risk detection researchers to integrate more human-centered approaches to both developing and evaluating sexual risk detection algorithms to ensure the broader societal impacts of this important work.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Afsaneh Razi et al.",
      "keywords": "Harassment; Computer science; Extant taxon; Data science; Set (abstract data type); Systematic review; Big data; Psychology; Artificial intelligence; Social psychology; Political science; Data mining; MEDLINE",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3479609",
      "cited_by_count": 82,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4308764909",
      "doi": "10.1145/3555634",
      "title": "Towards Transparency in Dermatology Image Datasets with Skin Tone Annotations by Experts, Crowds, and an Algorithm",
      "abstract": "While artificial intelligence (AI) holds promise for supporting healthcare providers and improving the accuracy of medical diagnoses, a lack of transparency in the composition of datasets exposes AI models to the possibility of unintentional and avoidable mistakes. In particular, public and private image datasets of dermatological conditions rarely include information on skin color. As a start towards increasing transparency, AI researchers have appropriated the use of the Fitzpatrick skin type (FST) from a measure of patient photosensitivity to a measure for estimating skin tone in algorithmic audits of computer vision applications including facial recognition and dermatology diagnosis. In order to understand the variability of estimated FST annotations on images, we compare several FST annotation methods on a diverse set of 460 images of skin conditions from both textbooks and online dermatology atlases. These methods include expert annotation by board-certified dermatologists, algorithmic annotation via the Individual Typology Angle algorithm, which is then converted to estimated FST (ITA-FST), and two crowd-sourced, dynamic consensus protocols for annotating estimated FSTs. We find the inter-rater reliability between three board-certified dermatologists is comparable to the inter-rater reliability between the board-certified dermatologists and either of the crowdsourcing methods. In contrast, we find that the ITA-FST method produces annotations that are significantly less correlated with the experts' annotations than the experts' annotations are correlated with each other. These results demonstrate that algorithms based on ITA-FST are not reliable for annotating large-scale image datasets, but human-centered, crowd-based protocols can reliably add skin type transparency to dermatology datasets. Furthermore, we introduce the concept of dynamic consensus protocols with tunable parameters including expert review that increase the visibility of crowdwork and provide guidance for future crowdsourced annotations of large image datasets.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Matthew Groh et al.",
      "keywords": "Transparency (behavior); Computer science; Crowdsourcing; Annotation; Audit; Reliability (semiconductor); Certification; Medical diagnosis; Artificial intelligence; Medicine; World Wide Web; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555634",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394606408",
      "doi": "10.1145/3656580",
      "title": "Foundations &amp; Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions",
      "abstract": "Multimodal machine learning is a vibrant multi-disciplinary research field that aims to design computer agents with intelligent capabilities such as understanding, reasoning, and learning through integrating multiple communicative modalities, including linguistic, acoustic, visual, tactile, and physiological messages. With the recent interest in video understanding, embodied autonomous agents, text-to-image generation, and multisensor fusion in application domains such as healthcare and robotics, multimodal machine learning has brought unique computational and theoretical challenges to the machine learning community given the heterogeneity of data sources and the interconnections often found between modalities. However, the breadth of progress in multimodal research has made it difficult to identify the common themes and open questions in the field. By synthesizing a broad range of application domains and theoretical frameworks from both historical and recent perspectives, this article is designed to provide an overview of the computational and theoretical foundations of multimodal machine learning. We start by defining three key principles of modality heterogeneity , connections , and interactions that have driven subsequent innovations, and propose a taxonomy of six core technical challenges: representation , alignment , reasoning , generation , transference , and quantification covering historical and recent trends. Recent technical achievements will be presented through the lens of this taxonomy, allowing researchers to understand the similarities and differences across new approaches. We end by motivating several open problems for future research as identified by our taxonomy.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Paul Pu Liang et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Data science; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3656580",
      "cited_by_count": 120,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387377782",
      "doi": "10.1145/3626234",
      "title": "Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering",
      "abstract": "Responsible Artificial Intelligence (RAI) is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of Artificial Intelligence (AI). Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. In addition, significant efforts have been placed at algorithm level rather than system level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize RAI from a system perspective, in this article, we present an RAI Pattern Catalogue based on the results of a multivocal literature review. Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The RAI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and RAI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement RAI.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Qinghua Lu et al.",
      "keywords": "Computer science; Corporate governance; Best practice; Software engineering; Data science; Artificial intelligence; Engineering management; Management",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3626234",
      "cited_by_count": 72,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3128510346",
      "doi": "10.1145/3439720",
      "title": "A Taxonomy of Social Errors in Human-Robot Interaction",
      "abstract": "Robotic applications have entered various aspects of our lives, such as health care and educational services. In such Human-robot Interaction (HRI), trust and mutual adaption are established and maintained through a positive social relationship between a user and a robot. This social relationship relies on the perceived competence of a robot on the social-emotional dimension. However, because of technical limitations and user heterogeneity, current HRI is far from error-free, especially when a system leaves controlled lab environments and is applied to in-the-wild conditions. Errors in HRI may either degrade a user\u2019s perception of a robot\u2019s capability in achieving a task (defined as performance errors in this work) or degrade a user\u2019s perception of a robot\u2019s socio-affective competence (defined as social errors in this work). The impact of these errors and effective strategies to handle such an impact remains an open question. We focus on social errors in HRI in this work. In particular, we identify the major attributes of perceived socio-affective competence by reviewing human social interaction studies and HRI error studies. This motivates us to propose a taxonomy of social errors in HRI. We then discuss the impact of social errors situated in three representative HRI scenarios. This article provides foundations for a systematic analysis of the social-emotional dimension of HRI. The proposed taxonomy of social errors encourages the development of user-centered HRI systems, designed to offer positive and adaptive interaction experiences and improved interaction outcomes.",
      "year": "2021",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Leimin Tian et al.",
      "keywords": "Social competence; Competence (human resources); Human\u2013computer interaction; Perception; Robot; Human\u2013robot interaction; Computer science; Social relation; Psychology; Situated; Social robot; Cognitive psychology; Artificial intelligence; Social psychology; Mobile robot; Social change; Robot control",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3439720",
      "cited_by_count": 108,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387055640",
      "doi": "10.1145/3625287",
      "title": "Explainable Deep Learning Methods in Medical Image Classification: A Survey",
      "abstract": "The remarkable success of deep learning has prompted interest in its application to medical imaging diagnosis. Even though state-of-the-art deep learning models have achieved human-level accuracy on the classification of different types of medical data, these models are hardly adopted in clinical workflows, mainly due to their lack of interpretability. The black-box nature of deep learning models has raised the need for devising strategies to explain the decision process of these models, leading to the creation of the topic of eXplainable Artificial Intelligence (XAI). In this context, we provide a thorough survey of XAI applied to medical imaging diagnosis, including visual, textual, example-based and concept-based explanation methods. Moreover, this work reviews the existing medical imaging datasets and the existing metrics for evaluating the quality of the explanations. In addition, we include a performance comparison among a set of report generation\u2013based methods. Finally, the major challenges in applying XAI to medical imaging and the future research directions on the topic are discussed.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Cristiano Patr\u00edcio et al.",
      "keywords": "Interpretability; Computer science; Deep learning; Artificial intelligence; Context (archaeology); Medical imaging; Workflow; Machine learning; Process (computing); Data science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3625287",
      "cited_by_count": 99,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389674995",
      "doi": "10.1145/3637487",
      "title": "Explainable AI for Medical Data: Current Methods, Limitations, and Future Directions",
      "abstract": "With the power of parallel processing, large datasets, and fast computational resources, deep neural networks (DNNs) have outperformed highly trained and experienced human experts in medical applications. However, the large global community of healthcare professionals, many of whom routinely face potentially life-or-death outcomes with complex medicolegal consequences, have yet to embrace this powerful technology. The major problem is that most current AI solutions function as a metaphorical black-box positioned between input data and output decisions without a rigorous explanation for their internal processes. With the goal of enhancing trust and improving acceptance of artificial intelligence\u2013 (AI) based technology in clinical medicine, there is a large and growing effort to address this challenge using eXplainable AI (XAI), a set of techniques, strategies, and algorithms with an explicit focus on explaining the \u201chows and whys\u201d of DNNs. Here, we provide a comprehensive review of the state-of-the-art XAI techniques concerning healthcare applications and discuss current challenges and future directions. We emphasize the strengths and limitations of each category, including image, tabular, and textual explanations, and explore a range of evaluation metrics for assessing the effectiveness of XAI solutions. Finally, we highlight promising opportunities for XAI research to enhance the acceptance of DNNs by the healthcare community.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Md. Imran Hossain et al.",
      "keywords": "Computer science; Data science; Function (biology); Set (abstract data type); Face (sociological concept); Health care; Deep neural networks; Artificial intelligence; Variety (cybernetics); Range (aeronautics); Deep learning",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3637487",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389676498",
      "doi": "10.1145/3636509",
      "title": "Against Predictive Optimization: On the Legitimacy of Decision-making Algorithms That Optimize Predictive Accuracy",
      "abstract": "We formalize predictive optimization, a category of decision-making algorithms that use machine learning (ML) to predict future outcomes of interest about individuals . For example, pre-trial risk prediction algorithms such as COMPAS use ML to predict whether an individual will re-offend in the future. Our thesis is that predictive optimization raises a distinctive and serious set of normative concerns that cause it to fail on its own terms. To test this, we review 387 reports, articles, and web pages from academia, industry, non-profits, governments, and data science contests, and we find many real-world examples of predictive optimization. We select eight particularly consequential examples as case studies. Simultaneously, we develop a set of normative and technical critiques that challenge the claims made by the developers of these applications\u2014in particular, claims of increased accuracy, efficiency, and fairness. Our key finding is that these critiques apply to each of the applications, are not easily evaded by redesigning the systems, and thus challenge whether these applications should be deployed. We argue that the burden of evidence for justifying why the deployment of predictive optimization is not harmful should rest with the developers of the tools. Based on our analysis, we provide a rubric of critical questions that can be used to deliberate or contest specific predictive optimization applications. 1",
      "year": "2023",
      "journal": "ACM Journal on Responsible Computing",
      "authors": "Angelina Wang et al.",
      "keywords": "Computer science; Machine learning; Predictive analytics; Artificial intelligence; Rubric; Set (abstract data type); Normative; Key (lock); Risk analysis (engineering); Psychology; Law; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3636509",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4318616691",
      "doi": "10.1145/3582430",
      "title": "Clinician-Facing AI in the Wild: Taking Stock of the Sociotechnical Challenges and Opportunities for HCI",
      "abstract": "Artificial Intelligence (AI) in medical applications holds great promise. However, the use of Machine Learning-based (ML) systems in clinical practice is still minimal. It is uniquely difficult to introduce clinician-facing ML-based systems in practice, which has been recognised in HCI and related fields. Recent publications have begun to address the sociotechnical challenges of designing, developing, and successfully deploying clinician-facing ML-based systems. We conducted a qualitative systematic review and provided answers to the question: \u201cHow can HCI researchers and practitioners contribute to the successful realisation of ML in medical practice?\u201d We reviewed 25 eligible papers that investigated the real-world clinical implications of concrete clinician-facing ML-based systems. The main contributions of this systematic review are: (1) an overview of the technical aspects of ML innovation and their consequences for HCI researchers and practitioners; (2) a description of the different roles that ML-based systems can take in clinical settings; (3) a conceptualisation of the main activities of medical ML innovation processes; (4) identification of five sociotechnical interdependencies that emerge from medical ML innovation; and (5) implications for HCI researchers and practitioners on how to mitigate the sociotechnical challenges of medical ML innovation.",
      "year": "2023",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Hubert Dariusz Zaj\u0105c et al.",
      "keywords": "Sociotechnical system; Stock (firearms); Computer science; Engineering; Engineering management; Sociology; Knowledge management; Geography; Archaeology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3582430",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4321853859",
      "doi": "10.1145/3579601",
      "title": "Deliberating with AI: Improving Decision-Making for the Future through Participatory AI Design and Stakeholder Deliberation",
      "abstract": "Research exploring how to support decision-making has often used machine learning to automate or assist human decisions. We take an alternative approach for improving decision-making, using machine learning to help stakeholders surface ways to improve and make fairer decision-making processes. We created \"Deliberating with AI\", a web tool that enables people to create and evaluate ML models in order to examine strengths and shortcomings of past decision-making and deliberate on how to improve future decisions. We apply this tool to a context of people selection, having stakeholders---decision makers (faculty) and decision subjects (students)---use the tool to improve graduate school admission decisions. Through our case study, we demonstrate how the stakeholders used the web tool to create ML models that they used as boundary objects to deliberate over organization decision-making practices. We share insights from our study to inform future research on stakeholder-centered participatory AI design and technology for organizational decision-making.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Angie Zhang et al.",
      "keywords": "Deliberation; Stakeholder; Knowledge management; Computer science; Context (archaeology); Decision engineering; Business decision mapping; Citizen journalism; Stakeholder engagement; Management science; R-CAST; Decision support system; Artificial intelligence; Engineering; Political science; Public relations; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579601",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4319165740",
      "doi": "10.1145/3579467",
      "title": "Charting the Sociotechnical Gap in Explainable AI: A Framework to Address the Gap in XAI",
      "abstract": "Explainable AI (XAI) systems are sociotechnical in nature; thus, they are subject to the sociotechnical gap-divide between the technical affordances and the social needs. However, charting this gap is challenging. In the context of XAI, we argue that charting the gap improves our problem understanding, which can reflexively provide actionable insights to improve explainability. Utilizing two case studies in distinct domains, we empirically derive a framework that facilitates systematic charting of the sociotechnical gap by connecting AI guidelines in the context of XAI and elucidating how to use them to address the gap. We apply the framework to a third case in a new domain, showcasing its affordances. Finally, we discuss conceptual implications of the framework, share practical considerations in its operationalization, and offer guidance on transferring it to new contexts. By making conceptual and practical contributions to understanding the sociotechnical gap in XAI, the framework expands the XAI design space.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Upol Ehsan et al.",
      "keywords": "Sociotechnical system; Operationalization; Affordance; Context (archaeology); Computer science; Knowledge management; Domain (mathematical analysis); Conceptual framework; Management science; Data science; Sociology; Epistemology; Engineering; Social science; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579467",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389386858",
      "doi": "10.1145/3636424",
      "title": "A Survey of Generative Adversarial Networks for Synthesizing Structured Electronic Health Records",
      "abstract": "Electronic Health Records (EHRs) are a valuable asset to facilitate clinical research and point of care applications; however, many challenges such as data privacy concerns impede its optimal utilization. Deep generative models, particularly Generative Adversarial Networks (GANs), show great promise in generating synthetic EHR data by learning underlying data distributions while achieving excellent performance and addressing these challenges. This work aims to survey the major developments in various applications of GANs for EHRs and provides an overview of the proposed methodologies. For this purpose, we combine perspectives from healthcare applications and machine learning techniques in terms of source datasets and the fidelity and privacy evaluation of the generated synthetic datasets. We also compile a list of the metrics and datasets used by the reviewed works, which can be utilized as benchmarks for future research in the field. We conclude by discussing challenges in GANs for EHRs development and proposing recommended practices. We hope that this work motivates novel research development directions in the intersection of healthcare and machine learning.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Ghadeer O. Ghosheh et al.",
      "keywords": "Computer science; Generative grammar; Adversarial system; Data science; Intersection (aeronautics); Field (mathematics); Health records; Health care; Artificial intelligence; Fidelity; Compiler; Asset (computer security); Point (geometry); Deep learning; Machine learning; Computer security",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3636424",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2988242552",
      "doi": "10.1145/3359298",
      "title": "Rural HCI Research",
      "abstract": "HCI researchers are increasingly conducting research in rural communities. This paper interrogates how rurality has been treated in previous HCI research conducted in developed and high-income countries. We draw from research outside of HCI to suggest how we can effectively engage with rurality in research. We present results of a scoping review of HCI literature that asks: 1) How do HCI researchers define rurality?; 2) How do the unique characteristics of rural communities enter into study findings?; 3) What methods are used in rural research?; and 4) Where has rural research been conducted? More than twice as many rural HCI articles have been conducted in low-income and/or developing countries than in high-income and/or developed countries. HCI researchers rarely define rurality, and when they do, they primarily define it using descriptive rather than sociocultural or symbolic definitions. Rural research findings have primarily addressed infrastructure and distance/geographic isolation as unique rural characteristics, while qualitative, observational, and cross-sectional methods dominate this research. There are further opportunities for HCI research to more productively advance understanding of what rurality is, and how it matters for sociotechnical systems.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Jean Hard\u00ff et al.",
      "keywords": "Rurality; Qualitative research; Sociotechnical system; Sociology; Rural area; Geography; Social science; Political science; Knowledge management; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359298",
      "cited_by_count": 81,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4313476346",
      "doi": "10.1145/3577011",
      "title": "Improving Workflow Integration with xPath: Design and Evaluation of a Human-AI Diagnosis System in Pathology",
      "abstract": "Recent developments in AI have provided assisting tools to support pathologists\u2019 diagnoses. However, it remains challenging to incorporate such tools into pathologists\u2019 practice; one main concern is AI\u2019s insufficient workflow integration with medical decisions. We observed pathologists\u2019 examination and discovered that the main hindering factor to integrate AI is its incompatibility with pathologists\u2019 workflow. To bridge the gap between pathologists and AI, we developed a human-AI collaborative diagnosis tool\u2014 xPath \u2014that shares a similar examination process to that of pathologists, which can improve AI\u2019s integration into their routine examination. The viability of xPath is confirmed by a technical evaluation and work sessions with 12 medical professionals in pathology. This work identifies and addresses the challenge of incorporating AI models into pathology, which can offer first-hand knowledge about how HCI researchers can work with medical professionals side-by-side to bring technological advances to medical tasks towards practical applications.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Hongyan Gu et al.",
      "keywords": "Workflow; XPath; Computer science; Medical diagnosis; Bridge (graph theory); Process (computing); Medical laboratory; Data science; Medicine; Pathology; World Wide Web; XML; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3577011",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2278655912",
      "doi": "10.1145/2871196",
      "title": "The Ethics of Computing",
      "abstract": "Computing technologies and artifacts are increasingly integrated into most aspects of our professional, social, and private lives. One consequence of this growing ubiquity of computing is that it can have significant ethical implications that computing professionals need to be aware of. The relationship between ethics and computing has long been discussed. However, this is the first comprehensive survey of the mainstream academic literature of the topic. Based on a detailed qualitative analysis of the literature, the article discusses ethical issues, technologies that they are related to, and ethical theories, as well as the methodologies that the literature employs, its academic contribution, and resulting recommendations. The article discusses general trends and argues that the time has come for a transition to responsible research and innovation to ensure that ethical reflection of computing has practical and manifest consequences.",
      "year": "2016",
      "journal": "ACM Computing Surveys",
      "authors": "Bernd Carsten Stahl et al.",
      "keywords": "Mainstream; Computer science; Engineering ethics; Reflection (computer programming); Ethical issues; Data science; Management science; Political science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/2871196",
      "cited_by_count": 115,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4366407820",
      "doi": "10.1145/3592616",
      "title": "A Survey of Data Quality Requirements That Matter in ML Development Pipelines",
      "abstract": "The fitness of the systems in which Machine Learning (ML) is used depends greatly on good-quality data. Specifications on what makes a good-quality dataset have traditionally been defined by the needs of the data users\u2014typically analysts and engineers. Our article critically examines the extent to which established data quality frameworks are applicable to contemporary use cases in ML. Using a review of recent literature at the intersection of ML, data management, and human-computer interaction, we find that the classical \u201cfitness-for-use\u201d view of data quality can benefit from a more stage-specific approach that is sensitive to where in the ML lifecycle the data are encountered. This helps practitioners to plan their data quality tasks in a manner that meets the needs of the stakeholders who will encounter the dataset, whether it be data subjects, software developers or organisations. We therefore propose a new treatment of traditional data quality criteria by structuring them according to two dimensions: (1) the stage of the ML lifecycle where the use case occurs vs. (2) the main categories of data quality that can be pursued (intrinsic, contextual, representational and accessibility). To illustrate how this works in practice, we contribute a temporal mapping of the various data quality requirements that are important at different stages of the ML data pipeline. We also share some implications for data practitioners and organisations that wish to enhance their data management routines in preparation for ML.",
      "year": "2023",
      "journal": "Journal of Data and Information Quality",
      "authors": "Maria Priestley et al.",
      "keywords": "Computer science; Data quality; Quality (philosophy); Pipeline (software); Data science; Data governance; Intersection (aeronautics); Structuring; Data management; Risk analysis (engineering); Data mining; Engineering; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3592616",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319837253",
      "doi": "10.1145/3569485",
      "title": "GLOBEM",
      "abstract": "There is a growing body of research revealing that longitudinal passive sensing data from smartphones and wearable devices can capture daily behavior signals for human behavior modeling, such as depression detection. Most prior studies build and evaluate machine learning models using data collected from a single population. However, to ensure that a behavior model can work for a larger group of users, its generalizability needs to be verified on multiple datasets from different populations. We present the first work evaluating cross-dataset generalizability of longitudinal behavior models, using depression detection as an application. We collect multiple longitudinal passive mobile sensing datasets with over 500 users from two institutes over a two-year span, leading to four institute-year datasets. Using the datasets, we closely re-implement and evaluated nine prior depression detection algorithms. Our experiment reveals the lack of model generalizability of these methods. We also implement eight recently popular domain generalization algorithms from the machine learning community. Our results indicate that these methods also do not generalize well on our datasets, with barely any advantage over the naive baseline of guessing the majority. We then present two new algorithms with better generalizability. Our new algorithm, Reorder, significantly and consistently outperforms existing methods on most cross-dataset generalization setups. However, the overall advantage is incremental and still has great room for improvement. Our analysis reveals that the individual differences (both within and between populations) may play the most important role in the cross-dataset generalization challenge. Finally, we provide an open-source benchmark platform GLOBEM- short for Generalization of Longitudinal BEhavior Modeling - to consolidate all 19 algorithms. GLOBEM can support researchers in using, developing, and evaluating different longitudinal behavior modeling methods. We call for researchers' attention to model generalizability evaluation for future longitudinal human behavior modeling studies.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Xuhai Xu et al.",
      "keywords": "Generalizability theory; Computer science; Benchmark (surveying); Generalization; Machine learning; Artificial intelligence; Baseline (sea); Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3569485",
      "cited_by_count": 75,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385895991",
      "doi": "10.1145/3610218",
      "title": "Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making",
      "abstract": "Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when 'right' AI outputs are presented. While both therapists and laypersons over-relied on 'wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on 'wrong' AI outputs by 21% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on 'wrong' AI outputs and implications for improving human-AI collaborative decision-making.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Min Hun Lee et al.",
      "keywords": "Counterfactual thinking; Salient; Task (project management); Quality (philosophy); Psychology; Feature (linguistics); Cognitive psychology; Artificial intelligence; Computer science; Social psychology; Epistemology; Management; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610218",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365999090",
      "doi": "10.1145/3579528",
      "title": "Automated Emotion Recognition in the Workplace: How Proposed Technologies Reveal Potential Futures of Work",
      "abstract": "Emotion recognition technologies, while critiqued for bias, validity, and privacy invasion, continue to be developed and applied in a range of domains including in high-stakes settings like the workplace. We set out to examine emotion recognition technologies proposed for use in the workplace, describing the input data and training, outputs, and actions that these systems take or prompt. We use these design features to reflect on these technologies' implications using the ethical speculation lens. We analyzed patent applications that developed emotion recognition technologies to be used in the workplace (N=86). We found that these technologies scope data collection broadly; claim to reveal not only targets' emotional expressions, but also their internal states; and take or prompt a wide range of actions, many of which impact workers' employment and livelihoods. Technologies described in patent applications frequently violated existing guidelines for ethical automated emotion recognition technology. We demonstrate the utility of using patent applications for ethical speculation. In doing so, we suggest that 1) increasing the visibility of claimed emotional states has the potential to create additional emotional labor for workers (a burden that is disproportionately distributed to low-power and marginalized workers) and contribute to a larger pattern of blurring boundaries between expectations of the workplace and a worker's autonomy, and more broadly to the data colonialism regime; 2) Emotion recognition technology's failures can be invisible, may inappropriately influence high-stakes workplace decisions and can exacerbate inequity. We discuss the implications of making emotions and emotional data visible in the workplace and submit for consideration implications for designers of emotion recognition, employers who use them, and policymakers.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Karen Boyd et al.",
      "keywords": "Speculation; Futures contract; Autonomy; Emerging technologies; Emotional labor; Scope (computer science); Set (abstract data type); Psychology; Social psychology; Computer science; Business; Political science; Artificial intelligence; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579528",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4378981991",
      "doi": "10.1145/3599974",
      "title": "The Role of Explainable AI in the Research Field of AI Ethics",
      "abstract": "Ethics of Artificial Intelligence (AI) is a growing research field that has emerged in response to the challenges related to AI. Transparency poses a key challenge for implementing AI ethics in practice. One solution to transparency issues is AI systems that can explain their decisions. Explainable AI (XAI) refers to AI systems that are interpretable or understandable to humans. The research fields of AI ethics and XAI lack a common framework and conceptualization. There is no clarity of the field\u2019s depth and versatility. A systematic approach to understanding the corpus is needed. A systematic review offers an opportunity to detect research gaps and focus points. This article presents the results of a systematic mapping study (SMS) of the research field of the Ethics of AI. The focus is on understanding the role of XAI and how the topic has been studied empirically. An SMS is a tool for performing a repeatable and continuable literature search. This article contributes to the research field with a Systematic Map that visualizes what, how, when, and why XAI has been studied empirically in the field of AI ethics. The mapping reveals research gaps in the area. Empirical contributions are drawn from the analysis. The contributions are reflected on in regards to theoretical and practical implications. As the scope of the SMS is a broader research area of AI ethics, the collected dataset opens possibilities to continue the mapping process in other directions.",
      "year": "2023",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "Heidi Vainio-Pekka et al.",
      "keywords": "Transparency (behavior); Conceptualization; CLARITY; Field (mathematics); Scope (computer science); Engineering ethics; Systematic review; Empirical research; Data science; Computer science; Focus (optics); Sociology; Management science; Knowledge management; Epistemology; Artificial intelligence; Political science; Law; Engineering; Philosophy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3599974",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392163191",
      "doi": "10.1145/3649468",
      "title": "Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web?",
      "abstract": "We observe a recent trend toward applying large language models (LLMs) in search and positioning them as effective information access systems. While the interfaces may look appealing and the apparent breadth of applicability is exciting, we are concerned that the field is rushing ahead with a technology without sufficient study of the uses it is meant to serve, how it would be used, and what its use would mean. We argue that it is important to reassert the central research focus of the field of information retrieval, because information access is not merely an application to be solved by the so-called \u2018AI\u2019 techniques du jour. Rather, it is a key human activity, with impacts on both individuals and society. As information scientists, we should be asking what do people and society want and need from information access systems and how do we design and build systems to meet those needs? With that goal, in this conceptual article we investigate fundamental questions concerning information access from user and societal viewpoints. We revisit foundational work related to information behavior, information seeking, information retrieval, information filtering, and information access to resurface what we know about these fundamental questions and what may be missing. We then provide our conceptual framing about how we could fill this gap, focusing on methods as well as experimental and evaluation frameworks. We consider the Web as an information ecosystem and explore the ways in which synthetic media, produced by LLMs and otherwise, endangers that ecosystem. The primary goal of this conceptual article is to shed light on what we still do not know about the potential impacts of LLM-based information access systems, how to advance our understanding of user behaviors, and where the next generations of students, scholars, and developers could fruitfully invest their energies.",
      "year": "2024",
      "journal": "ACM Transactions on the Web",
      "authors": "Chirag Shah et al.",
      "keywords": "Computer science; World Wide Web; Data science; Database; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3649468",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3205314427",
      "doi": "10.1145/3476049",
      "title": "Data Subjects' Conceptualizations of and Attitudes Toward Automatic Emotion Recognition-Enabled Wellbeing Interventions on Social Media",
      "abstract": "Automatic emotion recognition (ER)-enabled wellbeing interventions use ER algorithms to infer the emotions of a data subject (i.e., a person about whom data is collected or processed to enable ER) based on data generated from their online interactions, such as social media activity, and intervene accordingly. The potential commercial applications of this technology are widely acknowledged, particularly in the context of social media. Yet, little is known about data subjects' conceptualizations of and attitudes toward automatic ER-enabled wellbeing interventions. To address this gap, we interviewed 13 US adult social media data subjects regarding social media-based automatic ER-enabled wellbeing interventions. We found that participants' attitudes toward automatic ER-enabled wellbeing interventions were predominantly negative. Negative attitudes were largely shaped by how participants compared their conceptualizations of Artificial Intelligence (AI) to the humans that traditionally deliver wellbeing support. Comparisons between AI and human wellbeing interventions were based upon human attributes participants doubted AI could hold: 1) helpfulness and authentic care; 2) personal and professional expertise; 3) morality; and 4) benevolence through shared humanity. In some cases, participants' attitudes toward automatic ER-enabled wellbeing interventions shifted when participants conceptualized automatic ER-enabled wellbeing interventions' impact on others, rather than themselves. Though with reluctance, a minority of participants held more positive attitudes toward their conceptualizations of automatic ER-enabled wellbeing interventions, citing their potential to benefit others: 1) by supporting academic research; 2) by increasing access to wellbeing support; and 3) through egregious harm prevention. However, most participants anticipated harms associated with their conceptualizations of automatic ER-enabled wellbeing interventions for others, such as re-traumatization, the spread of inaccurate health information, inappropriate surveillance, and interventions informed by inaccurate predictions. Lastly, while participants had qualms about automatic ER-enabled wellbeing interventions, we identified three development and delivery qualities of automatic ER-enabled wellbeing interventions upon which their attitudes toward them depended: 1) accuracy; 2) contextual sensitivity; and 3) positive outcome. Our study is not motivated to make normative statements about whether or how automatic ER-enabled wellbeing interventions should exist, but to center voices of the data subjects affected by this technology. We argue for the inclusion of data subjects in the development of requirements for ethical and trustworthy ER applications. To that end, we discuss ethical, social, and policy implications of our findings, suggesting that automatic ER-enabled wellbeing interventions imagined by participants are incompatible with aims to promote trustworthy, socially aware, and responsible AI technologies in the current practical and regulatory landscape in the US.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Kat Roemmich et al.",
      "keywords": "Psychological intervention; Social media; Psychology; Harm; Helpfulness; Context (archaeology); Social psychology; Computer science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3476049",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309617398",
      "doi": "10.1145/3555531",
      "title": "Burnout and the Quantified Workplace: Tensions around Personal Sensing Interventions for Stress in Resident Physicians",
      "abstract": "Recent research has explored computational tools to manage workplace stress via personal sensing, a measurement paradigm in which behavioral data streams are collected from technologies including smartphones, wearables, and personal computers. As these tools develop, they invite inquiry into how they can be appropriately implemented towards improving workers' well-being. In this study, we explored this proposition through formative interviews followed by a design provocation centered around measuring burnout in a U.S. resident physician program. Residents and their supervising attending physicians were presented with medium-fidelity mockups of a dashboard providing behavioral data on residents' sleep, activity and time working; self-reported data on residents' levels of burnout; and a free text box where residents could further contextualize their well-being. Our findings uncover tensions around how best to measure workplace well-being, who within a workplace is accountable for worker stress, and how the introduction of such tools remakes the boundaries of appropriate information flows between worker and workplace. We conclude by charting future work confronting these tensions, to ensure personal sensing is leveraged to truly improve worker well-being.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Daniel A. Adler et al.",
      "keywords": "Burnout; Applied psychology; Dashboard; Fidelity; Psychological intervention; Psychology; Formative assessment; Wearable computer; Occupational stress; Work (physics); Medical education; Computer science; Medicine; Social psychology; Data science; Clinical psychology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555531",
      "cited_by_count": 55,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4394809297",
      "doi": "10.1145/3659099",
      "title": "Blockchained Federated Learning for Internet of Things: A Comprehensive Survey",
      "abstract": "The demand for intelligent industries and smart services based on big data is rising rapidly with the increasing digitization and intelligence of the modern world. This survey comprehensively reviews Blockchained Federated Learning (BlockFL) that joins the benefits of both Blockchain and Federated Learning to provide a secure and efficient solution for the demand. We compare the existing BlockFL models in four Internet-of-Things (IoT) application scenarios: Personal IoT (PIoT), Industrial IoT (IIoT), Internet of Vehicles (IoV), and Internet of Health Things (IoHT), with a focus on security and privacy, trust and reliability, efficiency, and data diversity. Our analysis shows that the features of decentralization and transparency make BlockFL a secure and effective solution for distributed model training, while the overhead and compatibility still need further study. It also reveals the unique challenges of each domain presents unique challenges, e.g., the requirement of accommodating dynamic environments in IoV and the high demands of identity and permission management in IoHT, in addition to some common challenges identified, such as privacy, resource constraints, and data heterogeneity. Furthermore, we examine the existing technologies that can benefit BlockFL, thereby helping researchers and practitioners to make informed decisions about the selection and development of BlockFL for various IoT application scenarios.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Yanna Jiang et al.",
      "keywords": "Computer science; Identity management; The Internet; Computer security; Transparency (behavior); World Wide Web; Authentication (law)",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3659099",
      "cited_by_count": 44,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387328585",
      "doi": "10.1145/3610107",
      "title": "AI Consent Futures: A Case Study on Voice Data Collection with Clinicians",
      "abstract": "As new forms of data capture emerge to power new AI applications, questions abound about the ethical implications of these data collection practices. In this paper, we present clinicians' perspectives on the prospective benefits and harms of voice data collection during health consultations. Such data collection is being proposed as a means to power models to assist clinicians with medical data entry, administrative tasks, and consultation analysis. Yet, clinicians' attitudes and concerns are largely absent from the AI narratives surrounding these use cases, and the academic literature investigating them. Our qualitative interview study used the concept of an informed consent process as a type of design fiction, to support elicitation of clinicians' perspectives on voice data collection and use associated with a fictional, near-term AI assistant. Through reflexive thematic analysis of in-depth sessions with physicians, we distilled eight classes of potential risks that clinicians are concerned about, including workflow disruptions, self-censorship, and errors that could impact patient eligibility for services. We conclude with an in-depth discussion of these prospective risks, reflect on the use of the speculative processes that illuminated them, and reconsider evaluation criteria for AI-assisted clinical documentation technologies in light of our findings.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Lauren Wilcox et al.",
      "keywords": "Data collection; Documentation; Thematic analysis; Reflexivity; Workflow; Psychology; Medical education; Informed consent; Qualitative research; Medicine; Applied psychology; Computer science; Alternative medicine; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610107",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4309618418",
      "doi": "10.1145/3555146",
      "title": "\"For an App Supposed to Make Its Users Feel Better, It Sure is a Joke\" - An Analysis of User Reviews of Mobile Mental Health Applications",
      "abstract": "Mobile mental health applications are seen as a promising way to fulfill the growing need for mental health care. Although there are more than ten thousand mental health apps available on app marketplaces, such as Google Play and Apple App Store, many of them are not evidence-based, or have been minimally evaluated or regulated. The real-life experience and concerns of the app users are largely unknown. To address this knowledge gap, we analyzed 2159 user reviews from 117 Android apps and 2764 user reviews from 76 iOS apps. Our findings include the critiques around inconsistent moderation standards and lack of transparency. App-embedded social features and chatbots were criticized for providing little support during crises. We provide research and design implications for future mental health app developers, discuss the necessity of developing a comprehensive and centralized app development guideline, and the opportunities of incorporating existing AI technology in mental health chatbots.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Md Romael Haque et al.",
      "keywords": "Mental health; Mobile apps; App store; Internet privacy; Android (operating system); Moderation; Transparency (behavior); World Wide Web; Joke; Android app; Mobile device; Smartphone application; Computer science; Social media; Psychology; Multimedia; Computer security; Psychiatry; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555146",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4317464833",
      "doi": "10.1145/3579612",
      "title": "Improving Human-AI Collaboration With Descriptions of AI Behavior",
      "abstract": "People work with AI systems to improve their decision making, but often under- or over-rely on AI predictions and perform worse than they would have unassisted. To help people appropriately rely on AI aids, we propose showing them behavior descriptions, details of how AI systems perform on subgroups of instances. We tested the efficacy of behavior descriptions through user studies with 225 participants in three distinct domains: fake review detection, satellite image classification, and bird classification. We found that behavior descriptions can increase human-AI accuracy through two mechanisms: helping people identify AI failures and increasing people's reliance on the AI when it is more accurate. These findings highlight the importance of people's mental models in human-AI collaboration and show that informing people of high-level AI behaviors can significantly improve AI-assisted decision making.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "\u00c1ngel Alexander Cabrera et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579612",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388534126",
      "doi": "10.1145/3632120",
      "title": "Which Skin Tone Measures Are the Most Inclusive? An Investigation of Skin Tone Measures for Artificial Intelligence",
      "abstract": "Skin tone plays a critical role in artificial intelligence (AI). However, many algorithms have exhibited unfair bias against people with darker skin tones. One reason this occurs is a poor understanding of how well the scales we use to measure and account for skin tone in AI actually represent the variation of skin tones in people affected by these systems. To address this, we conducted a survey with 2,214 people in the United States to compare three skin tone scales: The Fitzpatrick 6-point scale, Rihanna's Fenty Beauty 40-point skin tone palette, and a newly developed Monk 10-point scale from the social sciences. We find that the Fitzpatrick scale is perceived to be less inclusive than the Fenty and Monk skin tone scales, and this was especially true for people from historically marginalized communities (i.e., people with darker skin tones, BIPOCs, and women). We also find no statistically meaningful differences in perceived representation across the Monk skin tone scale and the Fenty Beauty palette. We discuss the ways in which our findings can advance the understanding of skin tone in both the social science and machine learning communities.",
      "year": "2023",
      "journal": "ACM Journal on Responsible Computing",
      "authors": "Courtney Heldreth et al.",
      "keywords": "Tone (literature); Beauty; Palette (painting); Scale (ratio); Psychology; Point (geometry); Computer science; Aesthetics; Art; Mathematics; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3632120",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4205860831",
      "doi": "10.1145/3506734",
      "title": "Constraint Enforcement on Decision Trees: A Survey",
      "abstract": "Decision trees have the particularity of being machine learning models that are visually easy to interpret and understand. Therefore, they are primarily suited for sensitive domains like medical diagnosis, where decisions need to be explainable. However, if used on complex problems, then decision trees can become large, making them hard to grasp. In addition to this aspect, when learning decision trees, it may be necessary to consider a broader class of constraints, such as the fact that two variables should not be used in a single branch of the tree. This motivates the need to enforce constraints in learning algorithms of decision trees. We propose a survey of works that attempted to solve the problem of learning decision trees under constraints. Our contributions are fourfold. First, to the best of our knowledge, this is the first survey that deals with constraints on decision trees. Second, we define a flexible taxonomy of constraints applied to decision trees and methods for their treatment in the literature. Third, we benchmark state-of-the art depth-constrained decision tree learners with respect to predictive accuracy and computational time. Fourth, we discuss potential future research directions that would be of interest for researchers who wish to conduct research in this field.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "G\u00e9raldin Nanfack et al.",
      "keywords": "Computer science; Decision tree; Decision tree learning; Machine learning; GRASP; Artificial intelligence; Incremental decision tree; Benchmark (surveying); Decision engineering; Taxonomy (biology); Alternating decision tree; Field (mathematics); Business decision mapping; Decision support system; Mathematics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3506734",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3206502478",
      "doi": "10.1145/3479596",
      "title": "Data Work in Education: Enacting and Negotiating Care and Control in Teachers' Use of Data-Driven Classroom Surveillance Technology",
      "abstract": "Today, teachers have been increasingly relying on data-driven technologies to track and monitor student behavior data for classroom management. Drawing insights from interviews with 20 K--8 teachers, in this paper we unpack how teachers enacted both care and control through their data work in collecting, interpreting, and using student behavior data. In this process, teachers found themselves subject to surveilling gazes from parents, school administrators, and students. As a result, teachers had to manipulate the student behavior data to navigate the balance between presenting a professional image to surveillants and enacting care/control that they deemed appropriate. In this paper we locate two nuanced forms of teachers' data work that have been under-studied in CSCW: (1) data work as recontextualizing meanings and (2) data work as resisting surveillance. We discuss teachers' struggle over (in)visibility and their negotiation of autonomy and subjectivity in these two forms of data work. We highlight the importance of foregrounding and making space for informal data workers' (in our case, teachers') resistance and negotiation of autonomy in light of datafication.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Alex Jiahong Lu et al.",
      "keywords": "Foregrounding; Negotiation; Autonomy; Subjectivity; Work (physics); Pedagogy; Control (management); Visibility; Sociology; Psychology; Computer science; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3479596",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387344795",
      "doi": "10.1145/3610206",
      "title": "Selective Explanations: Leveraging Human Input to Align Explainable AI",
      "abstract": "While a vast collection of explainable AI (XAI) algorithms has been developed in recent years, they have been criticized for significant gaps with how humans produce and consume explanations. As a result, current XAI techniques are often found to be hard to use and lack effectiveness. In this work, we attempt to close these gaps by making AI explanations selective ---a fundamental property of human explanations---by selectively presenting a subset of model reasoning based on what aligns with the recipient's preferences. We propose a general framework for generating selective explanations by leveraging human input on a small dataset. This framework opens up a rich design space that accounts for different selectivity goals, types of input, and more. As a showcase, we use a decision-support task to explore selective explanations based on what the decision-maker would consider relevant to the decision task. We conducted two experimental studies to examine three paradigms based on our proposed framework: in Study 1, we ask the participants to provide critique-based or open-ended input to generate selective explanations (self-input). In Study 2, we show the participants selective explanations based on input from a panel of similar users (annotator input). Our experiments demonstrate the promise of selective explanations in reducing over-reliance on AI and improving collaborative decision making and subjective perceptions of the AI system, but also paint a nuanced picture that attributes some of these positive effects to the opportunity to provide one's own input to augment AI explanations. Overall, our work proposes a novel XAI framework inspired by human communication behaviors and demonstrates its potential to encourage future work to make AI explanations more human-compatible.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Vivian Lai et al.",
      "keywords": "Task (project management); Computer science; Space (punctuation); Perception; Artificial intelligence; Property (philosophy); Ask price; Machine learning; Data science; Psychology; Epistemology; Management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610206",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386001503",
      "doi": "10.1145/3614425",
      "title": "Non-imaging Medical Data Synthesis for Trustworthy AI: A Comprehensive Survey",
      "abstract": "Data quality is a key factor in the development of trustworthy AI in healthcare. A large volume of curated datasets with controlled confounding factors can improve the accuracy, robustness, and privacy of downstream AI algorithms. However, access to high-quality datasets is limited by the technical difficulties of data acquisition, and large-scale sharing of healthcare data is hindered by strict ethical restrictions. Data synthesis algorithms, which generate data with distributions similar to real clinical data, can serve as a potential solution to address the scarcity of good quality data during the development of trustworthy AI. However, state-of-the-art data synthesis algorithms, especially deep learning algorithms, focus more on imaging data while neglecting the synthesis of non-imaging healthcare data, including clinical measurements, medical signals and waveforms, and electronic healthcare records (EHRs). Therefore, in this article, we will review synthesis algorithms, particularly for non-imaging medical data, with the aim of providing trustworthy AI in this domain. This tutorial-style review article will provide comprehensive descriptions of non-imaging medical data synthesis, covering aspects such as algorithms, evaluations, limitations, and future research directions.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Xiaodan Xing et al.",
      "keywords": "Computer science; Trustworthiness; Data science; Artificial intelligence; Information retrieval; Computer security",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3614425",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386370663",
      "doi": "10.1145/3616473",
      "title": "Algorithmic Harms in Child Welfare: Uncertainties in Practice, Organization, and Street-level Decision-making",
      "abstract": "Algorithms in public services such as child welfare, criminal justice, and education are increasingly being used to make high-stakes decisions about human lives. Drawing upon findings from a two-year ethnography conducted at a child welfare agency, we highlight how algorithmic systems are embedded within a complex decision-making ecosystem at critical points of the child welfare process. Caseworkers interact with algorithms in their daily lives where they must collect information about families and feed it to algorithms to make critical decisions. We show how the interplay between systemic mechanics and algorithmic decision-making can adversely impact the fairness of the decision-making process itself. We show how functionality issues in algorithmic systems can lead to process-oriented harms where they adversely affect the nature of professional practice, and administration at the agency, and lead to inconsistent and unreliable decisions at the street level. In addition, caseworkers are compelled to undertake additional labor in the form of repair work to restore disrupted administrative processes and decision-making, all while facing organizational pressures and time and resource constraints. Finally, we share the case study of a simple algorithmic tool that centers caseworkers\u2019 decision-making within a trauma-informed framework and leads to better outcomes, however, required a significant amount of investments on the agency\u2019s part in creating the ecosystem for its proper use.",
      "year": "2023",
      "journal": "ACM Journal on Responsible Computing",
      "authors": "Devansh Saxena et al.",
      "keywords": "Agency (philosophy); Welfare; Process (computing); Economic Justice; Computer science; Resource (disambiguation); Public relations; Business; Economics; Knowledge management; Sociology; Political science; Microeconomics; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3616473",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387344747",
      "doi": "10.1145/3610203",
      "title": "Public Health Calls for/with AI: An Ethnographic Perspective",
      "abstract": "Artificial Intelligence (AI) based technologies are increasingly being integrated into public sector programs to help with decision-support and effective distribution of constrained resources. The field of Computer Supported Cooperative Work (CSCW) has begun to examine how the resultant sociotechnical systems may be designed appropriately when targeting underserved populations. We present an ethnographic study of a large-scale real-world integration of an AI system for resource allocation in a call-based maternal and child health program in India. Our findings uncover complexities around determining who benefits from the intervention, how the human-AI collaboration is managed, when intervention must take place in alignment with various priorities, and why the AI is sought, for what purpose. Our paper offers takeaways for human-centered AI integration in public health, drawing attention to the work done by the AI as actor, the work of configuring the human-AI partnership with multiple diverse stakeholders, and the work of aligning program goals for design and implementation through continual dialogue across stakeholders.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Azra Ismail et al.",
      "keywords": "Sociotechnical system; General partnership; Knowledge management; Computer-supported cooperative work; Intervention (counseling); Work (physics); Collective intelligence; Public health; Public relations; Computer science; Sociology; Business; Political science; Engineering; Medicine; Nursing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610203",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3205149574",
      "doi": "10.1145/3479561",
      "title": "Effective Strategies for Crowd-Powered Cognitive Reappraisal Systems: A Field Deployment of the Flip*Doubt Web Application for Mental Health",
      "abstract": "Online technologies offer great promise to expand models of delivery for therapeutic interventions to help users cope with increasingly common mental illnesses like anxiety and depression. For example, \"cognitive reappraisal\" is a skill that involves changing one's perspective on negative thoughts in order to improve one's emotional state. In this work, we present Flip*Doubt, a novel crowd-powered web application that provides users with cognitive reappraisals (\"reframes\") of negative thoughts. A one-month field deployment of Flip*Doubt with 13 graduate students yielded a data set of negative thoughts paired with positive reframes, as well as rich interview data about how participants interacted with the system. Through this deployment, our work contributes: (1) an in-depth qualitative understanding of how participants used a crowd-powered cognitive reappraisal system in the wild; and (2) detailed codebooks that capture informative context about negative input thoughts and reframes. Our results surface data-derived hypotheses that may help to explain what types of reframes are helpful for users, while also providing guidance to future researchers and developers interested in building collaborative systems for mental health. In our discussion, we outline implications for systems research to leverage peer training and support, as well as opportunities to integrate AI/ML-based algorithms to support the cognitive reappraisal task. (Note: This paper includes potentially triggering mentions of mental health issues and suicide.)",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "C. Estelle Smith et al.",
      "keywords": "Software deployment; Mental health; Psychology; Psychological intervention; Cognition; Applied psychology; Context (archaeology); Leverage (statistics); Cognitive psychology; Computer science; Psychotherapist; Artificial intelligence; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3479561",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309287926",
      "doi": "10.1145/3571810",
      "title": "Achieving Digital Wellbeing Through Digital Self-control Tools: A Systematic Review and Meta-analysis",
      "abstract": "Public media and researchers in different areas have recently focused on perhaps unexpected problems that derive from an excessive and frequent use of technology, giving rise to a new kind of psychological \u201cdigital\u201d wellbeing. Such a novel and pressing topic has fostered, both in the academia and in the industry, the emergence of a variety of digital self-control tools allowing users to self-regulate their technology use through interventions like timers and lock-out mechanisms. While these emerging technologies for behavior change hold great promise to support people\u2019s digital wellbeing, we still have a limited understanding of their real effectiveness, as well as of how to best design and evaluate them. Aiming to guide future research in this important domain, this article presents a systematic review and a meta-analysis of current work on tools for digital self-control. We surface motivations, strategies, design choices, and challenges that characterize the design, development, and evaluation of digital self-control tools. Furthermore, we estimate their overall effect size on reducing (unwanted) technology use through a meta-analysis. By discussing our findings, we provide insights on how to (i) overcome a limited perspective that exclusively focuses on technology overuse and self-monitoring tools, (ii) evaluate digital self-control tools through long-term studies and standardized measures, and (iii) bring ethics in the digital wellbeing discourse and deal with the business model of contemporary tech companies.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Alberto Monge Roffarello et al.",
      "keywords": "Control (management); Computer science; Psychological intervention; Perspective (graphical); Systematic review; Variety (cybernetics); Knowledge management; Data science; Risk analysis (engineering); Psychology; Business; Political science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3571810",
      "cited_by_count": 79,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385979136",
      "doi": "10.1145/3604570",
      "title": "The End of the Policy Analyst? Testing the Capability of Artificial Intelligence to Generate Plausible, Persuasive, and Useful Policy Analysis",
      "abstract": "Policy advising in government centers on the analysis of public problems and the developing of recommendations for dealing with them. In carrying out this work, policy analysts consult a variety of sources and work to synthesize that body of evidence into useful decision support documents commonly called briefing notes. Advances in natural language processing (NLP) have led to the continuing development of tools that can undertake a similar task. Given a brief prompt, a large language model (LLM) can synthesize information in content databases. This article documents the findings from an experiment that tested whether contemporary NLP technology is capable of producing public policy relevant briefing notes that expert evaluators judge to be useful. The research involved two stages. First, briefing notes were created using three models: NLP generated; human generated; and NLP generated/human edited. Next, two panels of retired senior public servants (with only one panel informed of the use of NLP in the experiment) were asked to judge the briefing notes using a heuristic evaluation rubric. The findings indicate that contemporary NLP tools were not able to, on their own, generate useful policy briefings. However, the feedback from the expert evaluators indicates that automatically generated briefing notes might serve as a useful supplement to the work of human policy analysts. And the speed with which the capabilities of NLP tools are developing, supplemented with access to a larger corpus of previously prepared policy briefings and other policy-relevant material, suggests that the quality of automatically generated briefings may improve significantly in the coming years. The article concludes with reflections on what such improvements might mean for the future practice of policy analysis.",
      "year": "2023",
      "journal": "Digital Government Research and Practice",
      "authors": "Mehrdad Safaei et al.",
      "keywords": "Rubric; Computer science; Government (linguistics); Artificial intelligence; Task (project management); Heuristic; Public policy; Quality (philosophy); Political science; Psychology; Engineering; Mathematics education; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3604570",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4308789076",
      "doi": "10.1145/3555623",
      "title": "Documenting Data Production Processes",
      "abstract": "The opacity of machine learning data is a significant threat to ethical data work and intelligible systems. Previous research has addressed this issue by proposing standardized checklists to document datasets. This paper expands that field of inquiry by proposing a shift of perspective: from documenting datasets towards documenting data production. We draw on participatory design and collaborate with data workers at two companies located in Bulgaria and Argentina, where the collection and annotation of data for machine learning are outsourced. Our investigation comprises 2.5 years of research, including 33 semi-structured interviews, five co-design workshops, the development of prototypes, and several feedback instances with participants. We identify key challenges and requirements related to the integration of documentation practices in real-world data production scenarios. Our findings comprise important design considerations and highlight the value of designing data documentation based on the needs of data workers. We argue that a view of documentation as a boundary object, i.e., an object that can be used differently across organizations and teams but holds enough immutable content to maintain integrity, can be useful when designing documentation to retrieve heterogeneous, often distributed, contexts of data production.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Milagros Miceli et al.",
      "keywords": "Documentation; Computer science; Boundary object; Data science; Production (economics); Knowledge management; Object (grammar); Citizen journalism; Data curation; Data collection; Field (mathematics); Process management; World Wide Web; Artificial intelligence; Engineering; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555623",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4402100280",
      "doi": "10.1145/3689037",
      "title": "Physics-Informed Computer Vision: A Review and Perspectives",
      "abstract": "The incorporation of physical information in machine learning frameworks is opening and transforming many application domains. Here the learning process is augmented through the induction of fundamental knowledge and governing physical laws. In this work, we explore their utility for computer vision tasks in interpreting and understanding visual data. We present a systematic literature review of more than 250 papers on formulation and approaches to computer vision tasks guided by physical laws. We begin by decomposing the popular computer vision pipeline into a taxonomy of stages and investigate approaches to incorporate governing physical equations in each stage. Existing approaches are analyzed in terms of modeling and formulation of governing physical processes, including modifying input data (observation bias), network architectures (inductive bias), and training losses (learning bias). The taxonomy offers a unified view of the application of the physics-informed capability, highlighting where physics-informed learning has been conducted and where the gaps and opportunities are. Finally, we highlight open problems and challenges to inform future research. While still in its early days, the study of physics-informed computer vision has the promise to develop better computer vision models that can improve physical plausibility, accuracy, data efficiency, and generalization in increasingly realistic applications.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Chayan Banerjee et al.",
      "keywords": "Computer science; Artificial intelligence; Process (computing); Physical law; Human\u2013computer interaction; Physical system; Pipeline (software); Taxonomy (biology); Generalization; Data science; Machine learning",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3689037",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4360851815",
      "doi": "10.1145/3588594",
      "title": "How Do Users Experience Traceability of AI Systems? Examining Subjective Information Processing Awareness in Automated Insulin Delivery (AID) Systems",
      "abstract": "When interacting with artificial intelligence (AI) in the medical domain, users frequently face automated information processing, which can remain opaque to them. For example, users with diabetes may interact daily with automated insulin delivery (AID). However, effective AID therapy requires traceability of automated decisions for diverse users. Grounded in research on human-automation interaction, we study Subjective Information Processing Awareness (SIPA) as a key construct to research users\u2019 experience of explainable AI. The objective of the present research was to examine how users experience differing levels of traceability of an AI algorithm. We developed a basic AID simulation to create realistic scenarios for an experiment with N = 80, where we examined the effect of three levels of information disclosure on SIPA and performance. Attributes serving as the basis for insulin needs calculation were shown to users, who predicted the AID system\u2019s calculation after over 60 observations. Results showed a difference in SIPA after repeated observations, associated with a general decline of SIPA ratings over time. Supporting scale validity, SIPA was strongly correlated with trust and satisfaction with explanations. The present research indicates that the effect of different levels of information disclosure may need several repetitions before it manifests. Additionally, high levels of information disclosure may lead to a miscalibration between SIPA and performance in predicting the system\u2019s results. The results indicate that for a responsible design of XAI, system designers could utilize prediction tasks in order to calibrate experienced traceability.",
      "year": "2023",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "Tim Schrills et al.",
      "keywords": "Traceability; Computer science; Automation; Construct (python library); Human\u2013computer interaction; Engineering; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3588594",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2980092400",
      "doi": "10.1145/3358175",
      "title": "An Ultra-Low Energy Human Activity Recognition Accelerator for Wearable Health Applications",
      "abstract": "Human activity recognition (HAR) has recently received significant attention due to its wide range of applications in health and activity monitoring. The nature of these applications requires mobile or wearable devices with limited battery capacity. User surveys show that charging requirement is one of the leading reasons for abandoning these devices. Hence, practical solutions must offer ultra-low power capabilities that enable operation on harvested energy. To address this need, we present the first fully integrated custom hardware accelerator (HAR engine) that consumes 22.4 \u03bcJ per operation using a commercial 65 nm technology. We present a complete solution that integrates all steps of HAR , i.e., reading the raw sensor data, generating features, and activity classification using a deep neural network (DNN). It achieves 95% accuracy in recognizing 8 common human activities while providing three orders of magnitude higher energy efficiency compared to existing solutions.",
      "year": "2019",
      "journal": "ACM Transactions on Embedded Computing Systems",
      "authors": "Ganapati Bhat et al.",
      "keywords": "Computer science; Wearable computer; Activity recognition; Wearable technology; Embedded system; Mobile device; Battery (electricity); Energy (signal processing); Deep learning; Smartwatch; Efficient energy use; Ultra low power; Range (aeronautics); Human health; Power (physics); Artificial intelligence; Computer hardware; Electrical engineering; Power consumption; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3358175",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388499385",
      "doi": "10.1145/3631614",
      "title": "Meaningful Explanation Effect on User\u2019s Trust in an AI Medical System: Designing Explanations for Non-Expert Users",
      "abstract": "Whereas most research in AI system explanation for healthcare applications looks at developing algorithmic explanations targeted at AI experts or medical professionals, the question we raise is: How do we build meaningful explanations for laypeople? And how does a meaningful explanation affect user\u2019s trust perceptions? Our research investigates how the key factors affecting human-AI trust change in the light of human expertise, and how to design explanations specifically targeted at non-experts. By means of a stage-based design method, we map the ways laypeople understand AI explanations in a User Explanation Model. We also map both medical professionals and AI experts\u2019 practice in an Expert Explanation Model. A Target Explanation Model is then proposed, which represents how experts\u2019 practice and layperson\u2019s understanding can be combined to design meaningful explanations. Design guidelines for meaningful AI explanations are proposed, and a prototype of AI system explanation for non-expert users in a breast cancer scenario is presented and assessed on how it affect users\u2019 trust perceptions.",
      "year": "2023",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "Retno Larasati et al.",
      "keywords": "Layperson; Affect (linguistics); Perception; Computer science; Knowledge management; Data science; Human\u2013computer interaction; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3631614",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309617546",
      "doi": "10.1145/3555650",
      "title": "Risk, Resilience and Reward: Impacts of Shifting to Digital Sex Work",
      "abstract": "Workers from a variety of industries rapidly shifted to remote work at the onset of the COVID-19 pandemic. While existing work has examined the impact of this shift on office workers, little work has examined how shifting from in-person to online work affected workers in the informal labor sector. We examine the impact of shifting from in-person to online-only work on a particularly marginalized group of workers: sex workers. Through 34 qualitative interviews with sex workers from seven countries in the Global North, we examine how a shift to online-only sex work impacted: (1) working conditions, (2) risks and protective behaviors, and (3) labor rewards. We find that online work offers benefits to sex workers' financial and physical well-being. However, online-only work introduces new and greater digital and mental health risks as a result of the need to be publicly visible on more platforms and to share more explicit content. From our findings we propose design and platform governance suggestions for digital sex workers and for informal workers more broadly, particularly those who create and sell digital content.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Vaughn Hamilton et al.",
      "keywords": "Sex work; Work (physics); Psychological resilience; Digital media; Sex workers; Business; Psychology; Variety (cybernetics); Public relations; Social psychology; Political science; Engineering; Environmental health; Medicine; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555650",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4224289290",
      "doi": "10.1145/3524885",
      "title": "Semi-Synchronous Federated Learning for Energy-Efficient Training and Accelerated Convergence in Cross-Silo Settings",
      "abstract": "There are situations where data relevant to machine learning problems are distributed across multiple locations that cannot share the data due to regulatory, competitiveness, or privacy reasons. Machine learning approaches that require data to be copied to a single location are hampered by the challenges of data sharing. Federated Learning (FL) is a promising approach to learn a joint model over all the available data across silos. In many cases, the sites participating in a federation have different data distributions and computational capabilities. In these heterogeneous environments existing approaches exhibit poor performance: synchronous FL protocols are communication efficient, but have slow learning convergence and high energy cost; conversely, asynchronous FL protocols have faster convergence with lower energy cost, but higher communication. In this work, we introduce a novel energy-efficient Semi-Synchronous Federated Learning protocol that mixes local models periodically with minimal idle time and fast convergence. We show through extensive experiments over established benchmark datasets in the computer-vision domain as well as in real-world biomedical settings that our approach significantly outperforms previous work in data and computationally heterogeneous environments .",
      "year": "2022",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Dimitris Stripelis et al.",
      "keywords": "Computer science; Asynchronous communication; Convergence (economics); Benchmark (surveying); Federated learning; Distributed computing; Efficient energy use; Machine learning; Protocol (science); Artificial intelligence; Computer network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3524885",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3145190647",
      "doi": "10.1145/3448106",
      "title": "The Design and Evaluation of a Mobile System for Rapid Diagnostic Test Interpretation",
      "abstract": "Rapid diagnostic tests (RDTs) provide point-of-care medical screening without the need for expensive laboratory equipment. RDTs are theoretically straightforward to use, yet their analog colorimetric output leaves room for diagnostic uncertainty and error. Furthermore, RDT results within a community are kept isolated unless they are aggregated by healthcare workers, limiting the potential that RDTs can have in supporting public health efforts. In light of these issues, we present a system called RDTScan for detecting and interpreting lateral flow RDTs with a smartphone. RDTScan provides real-time guidance for clear RDT image capture and automatic interpretation for accurate diagnostic decisions. RDTScan is structured to be quickly configurable to new RDT designs by requiring only a template image and some metadata about how the RDT is supposed to be read, making it easier to extend than a data-driven approach. Through a controlled lab study, we demonstrate that RDTScan's limit-of-detection can match, and even exceed, the performance of expert readers who are interpreting the physical RDTs themselves. We then present two field evaluations of smartphone apps built on the RDTScan system: (1) at-home influenza testing in Australia and (2) malaria testing by community healthcare workers in Kenya. RDTScan achieved 97.5% and 96.3% accuracy compared to RDT interpretation by experts in the Australia Flu Study and the Kenya Malaria Study, respectively.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Chunjong Park et al.",
      "keywords": "Computer science; Metadata; Point-of-care testing; Diagnostic test; Malaria; Interpretation (philosophy); Rapid diagnostic test; Test (biology); Health care; Healthcare system; Limiting; Risk analysis (engineering); Medicine; Engineering; Pathology; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3448106",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390811623",
      "doi": "10.1145/3631452",
      "title": "Investigating Generalizability of Speech-based Suicidal Ideation Detection Using Mobile Phones",
      "abstract": "Speech-based diaries from mobile phones can capture paralinguistic patterns that help detect mental illness symptoms such as suicidal ideation. However, previous studies have primarily evaluated machine learning models on a single dataset, making their performance unknown under distribution shifts. In this paper, we investigate the generalizability of speech-based suicidal ideation detection using mobile phones through cross-dataset experiments using four datasets with N=786 individuals experiencing major depressive disorder, auditory verbal hallucinations, persecutory thoughts, and students with suicidal thoughts. Our results show that machine and deep learning methods generalize poorly in many cases. Thus, we evaluate unsupervised domain adaptation (UDA) and semi-supervised domain adaptation (SSDA) to mitigate performance decreases owing to distribution shifts. While SSDA approaches showed superior performance, they are often ineffective, requiring large target datasets with limited labels for adversarial and contrastive training. Therefore, we propose sinusoidal similarity sub-sampling (S3), a method that selects optimal source subsets for the target domain by computing pair-wise scores using sinusoids. Compared to prior approaches, S3 does not use labeled target data or transform features. Fine-tuning using S3 improves the cross-dataset performance of deep models across the datasets, thus having implications in ubiquitous technology, mental health, and machine learning.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Arvind Pillai et al.",
      "keywords": "Generalizability theory; Computer science; Suicidal ideation; Paralanguage; Artificial intelligence; Deep learning; Machine learning; Experience sampling method; Similarity (geometry); Speech recognition; Psychology; Poison control; Suicide prevention; Communication",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3631452",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391453317",
      "doi": "10.1145/3645091",
      "title": "Wearable Activity Trackers: A Survey on Utility, Privacy, and Security",
      "abstract": "Over the past decade, wearable activity trackers (WATs) have become increasingly popular. However, despite many research studies in different fields (e.g. psychology, health, and design), few have sought to jointly examine the critical aspects of utility (i.e., benefits brought by these devices), privacy, and security (i.e., risks and vulnerabilities associated with them). To fill this gap, we reviewed 236 studies that researched the benefits of using WATs, the implications for the privacy of users of WATs, and the security vulnerabilities of these devices. Our survey revealed that these devices expose users to several threats. For example, WAT data can be mined to infer private information, such as the personality traits of the user. Whereas many works propose empirical findings about users\u2019 privacy perceptions and their behaviors in relation to privacy, we found relatively few studies researching technologies to better protect users\u2019 privacy with these devices. This survey contributes to systematizing knowledge on the utility, privacy, and security of WATs, shedding light on the state-of-the-art approaches with these devices, and discussing open research opportunities.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Kavous Salehzadeh Niksirat et al.",
      "keywords": "Internet privacy; Computer science; Computer security; Information privacy; Wearable computer; Relation (database); Empirical research; Wearable technology; Privacy by Design",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3645091",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391840620",
      "doi": "10.1145/3643457",
      "title": "Robots as Mental Well-being Coaches: Design and Ethical Recommendations",
      "abstract": "The last decade has shown a growing interest in robots as well-being coaches. However, insightful guidelines for the design of robots as coaches to promote mental well-being have not yet been proposed. This article details design and ethical recommendations based on a qualitative analysis drawing on a grounded theory approach, which was conducted with a three-step iterative design process which included user-centered design studies involving robotic well-being coaches, namely: (1) a user-centred design study conducted with 11 participants consisting of both prospective users who had participated in a Brief Solution-Focused Practice study with a human coach, as well as coaches of different disciplines, (2) semi-structured individual interview data gathered from 20 participants attending a Positive Psychology intervention study with the robotic well-being coach Pepper, and (3) a user-centred design study conducted with 3 participants of the Positive Psychology study as well as 2 relevant well-being coaches. After conducting a thematic analysis and a qualitative analysis, we collated the data gathered into convergent and divergent themes, and we distilled from those results a set of design guidelines and ethical considerations. Our findings can inform researchers and roboticists on the key aspects to take into account when designing robotic mental well-being coaches.",
      "year": "2024",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Minja Axelsson et al.",
      "keywords": "Thematic analysis; Applied psychology; Grounded theory; Psychology; Qualitative research; Set (abstract data type); User-centered design; Robot; Intervention (counseling); Computer science; Human\u2013computer interaction; Artificial intelligence; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643457",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3198841974",
      "doi": "10.1145/3563041",
      "title": "Multitask Balanced and Recalibrated Network for Medical Code Prediction",
      "abstract": "Human coders assign standardized medical codes to clinical documents generated during patients\u2019 hospitalization, which is error prone and labor intensive. Automated medical coding approaches have been developed using machine learning methods, such as deep neural networks. Nevertheless, automated medical coding is still challenging because of complex code association, noise in lengthy documents, and the imbalanced class problem. We propose a novel neural network, called the Multitask Balanced and Recalibrated Neural Network, to solve these issues. Significantly, the multitask learning scheme shares the relationship knowledge between different coding branches to capture code association. A recalibrated aggregation module is developed by cascading convolutional blocks to extract high-level semantic features that mitigate the impact of noise in documents. Also, the cascaded structure of the recalibrated module can benefit learning from lengthy notes. To solve the imbalanced class problem, we deploy focal loss to redistribute the attention on low- and high-frequency medical codes. Experimental results show that our proposed model outperforms competitive baselines on a real-world clinical dataset called the Medical Information Mart for Intensive Care (MIMIC-III).",
      "year": "2022",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Wei Sun et al.",
      "keywords": "Computer science; Deep learning; Convolutional neural network; Coding (social sciences); Artificial intelligence; Machine learning; Code (set theory); Artificial neural network; Medical classification",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3563041",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4307411695",
      "doi": "10.1145/3555102",
      "title": "The Distressing Ads That Persist: Uncovering The Harms of Targeted Weight-Loss Ads Among Users with Histories of Disordered Eating",
      "abstract": "Targeted advertising can harm vulnerable groups when it targets individuals' personal and psychological vulnerabilities. We focus on how targeted weight-loss advertisements harm people with histories of disordered eating. We identify three features of targeted advertising that cause harm: the persistence of personal data that can expose vulnerabilities, over-simplifying algorithmic relevancy models, and design patterns encouraging engagement that can facilitate unhealthy behavior. Through a series of semi-structured interviews with individuals with histories of unhealthy body stigma, dieting, and disordered eating, we found that targeted weight-loss ads reinforced low self-esteem and deepened pre-existing anxieties around food and exercise. At the same time, we observed that targeted individuals demonstrated agency and resistance against distressing ads. Drawing on scholarship in postcolonial environmental studies, we use the concept of slow violence to articulate how online targeted advertising inflicts harms that may not be immediately identifiable. CAUTION: This paper includes media that could be triggering, particularly to people with an eating disorder. Please use caution when reading, printing, or disseminating this paper.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Liza Gak et al.",
      "keywords": "Dieting; Distressing; Disordered eating; Harm; Psychology; Stigma (botany); Shame; Eating disorders; Weight loss; Social psychology; Medicine; Clinical psychology; Psychiatry; Obesity",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555102",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4413941679",
      "doi": "10.1145/3764579",
      "title": "Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey",
      "abstract": "Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). Domain specification techniques are key to making large language models disruptive in many applications. Specifically, to solve these hurdles, there has been a notable increase in research and practices conducted in recent years on the domain specialization of LLMs. This emerging field of study, with its substantial potential for impact, necessitates a comprehensive and systematic review to summarize better and guide ongoing work in this area. In this article, we present a comprehensive survey on domain specification techniques for large language models, an emerging direction critical for large language model applications. First, we propose a systematic taxonomy that categorizes the LLM domain-specialization techniques based on the accessibility to LLMs and summarizes the framework for all the subcategories as well as their relations and differences to each other. Second, we present an extensive taxonomy of critical application domains that can benefit dramatically from specialized LLMs, discussing their practical significance and open challenges. Last, we offer our insights into the current research status and future trends in this area.",
      "year": "2025",
      "journal": "ACM Computing Surveys",
      "authors": "Chen Ling et al.",
      "keywords": "Computer science; Key (lock); Domain (mathematical analysis); Data science; Domain-specific language; Software engineering; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3764579",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391897126",
      "doi": "10.1145/3648472",
      "title": "Redefining Counterfactual Explanations for Reinforcement Learning: Overview, Challenges and Opportunities",
      "abstract": "While AI algorithms have shown remarkable success in various fields, their lack of transparency hinders their application to real-life tasks. Although explanations targeted at non-experts are necessary for user trust and human-AI collaboration, the majority of explanation methods for AI are focused on developers and expert users. Counterfactual explanations are local explanations that offer users advice on what can be changed in the input for the output of the black-box model to change. Counterfactuals are user-friendly and provide actionable advice for achieving the desired output from the AI system. While extensively researched in supervised learning, there are few methods applying them to reinforcement learning (RL). In this work, we explore the reasons for the underrepresentation of a powerful explanation method in RL. We start by reviewing the current work in counterfactual explanations in supervised learning. Additionally, we explore the differences between counterfactual explanations in supervised learning and RL and identify the main challenges that prevent the adoption of methods from supervised in reinforcement learning. Finally, we redefine counterfactuals for RL and propose research directions for implementing counterfactuals in RL.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Jasmina Gajcin et al.",
      "keywords": "Counterfactual thinking; Counterfactual conditional; Computer science; Reinforcement learning; Artificial intelligence; Transparency (behavior); Supervised learning; Machine learning; Data science; Psychology; Social psychology; Artificial neural network; Computer security",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3648472",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4284879859",
      "doi": "10.1145/3534580",
      "title": "Template Matching Based Early Exit CNN for Energy-efficient Myocardial Infarction Detection on Low-power Wearable Devices",
      "abstract": "Myocardial Infarction (MI), also known as heart attack, is a life-threatening form of heart disease that is a leading cause of death worldwide. Its recurrent and silent nature emphasizes the need for continuous monitoring through wearable devices. The wearable device solutions should provide adequate performance while being resource-constrained in terms of power and memory. This paper proposes an MI detection methodology using a Convolutional Neural Network (CNN) that outperforms the state-of-the-art works on wearable devices for two datasets - PTB and PTB-XL, while being energy and memory-efficient. Moreover, we also propose a novel Template Matching based Early Exit (TMEX) CNN architecture that further increases the energy efficiency compared to baseline architecture while maintaining similar performance. Our baseline and TMEX architecture achieve 99.33% and 99.24% accuracy on PTB dataset, whereas on PTB-XL dataset they achieve 84.36% and 84.24% accuracy, respectively. Both architectures are suitable for wearable devices requiring only 20 KB of RAM. Evaluation of real hardware shows that our baseline architecture is 0.6x to 53x more energy-efficient than the state-of-the-art works on wearable devices. Moreover, our TMEX architecture further improves the energy efficiency by 8.12% (PTB) and 6.36% (PTB-XL) while maintaining similar performance as the baseline architecture.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Nafiul Rashid et al.",
      "keywords": "Wearable computer; Computer science; Baseline (sea); Wearable technology; Architecture; Efficient energy use; Energy (signal processing); Power (physics); Convolutional neural network; Matching (statistics); Artificial intelligence; Real-time computing; Embedded system; Medicine; Engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3534580",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3148976461",
      "doi": "10.1145/3448096",
      "title": "11 Years with Wearables",
      "abstract": "The role of wearable technology in our daily lives is rapidly growing and many users are cumulatively becoming dependent on it. To provide insight into the future of wearable technologies and various community attitudes towards them, we implemented an in-depth quantitative investigation of opinions from academic texts (DBLP and PubMed), social media (Twitter), news media (Google News and Bing News), and entrepreneurship communities (Kickstarter and Indiegogo) over a 10-year period. Our results indicate that unlike academia, the news media, entrepreneurship communities, and social media all hold overall positive attitudes towards wearable technologies. Secondly, there are diverse perspectives towards various wearable products across different platforms. Specifically, \"XR\" technologies received the most attention, while \"Exoskeleton\" ignited the most heated debates. Thirdly, we discovered that the lifetime of a hyped wearable technology lasts approximately three years. Furthermore, the news media and entrepreneurship community's attitudes towards wearable technologies did not have a strong impact on public opinion. Finally, among all types of wearable technologies, \"fashion design\" and \"healthcare\" products were the most enlightening for the market.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Yanglei Gan et al.",
      "keywords": "Wearable computer; Social media; Wearable technology; Entrepreneurship; Internet privacy; Emerging technologies; Computer science; World Wide Web; Political science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3448096",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309618075",
      "doi": "10.1145/3555155",
      "title": "\"Money Doesn't Buy You Happiness\": Negative Consequences of Using the Freemium Model for Mental Health Apps",
      "abstract": "As global rates of anxiety and depression increase, we observe millions of downloads of mobile apps addressing mental health that adopt 'freemium' charging models offering complex combinations of free and paid features. We explore potentially negative outcomes of deploying such freemium designs to vulnerable MH populations. We assess outcomes for 41 frequently downloaded mental health apps, by combining thematic analysis of 41K user reviews with audits to validate app descriptions and reviews. We propose a new analytic framework identifying three types of negative outcomes for freemium deployments: first vulnerable users currently experiencing crises may feel pressure to download unhelpful or costly apps. Second unintuitive descriptions of complex apps can lead to inappropriate treatments and expensive subscriptions. Third, limited duration offers may result in incomplete treatments or unexpected charges. We discuss ethical considerations and broader HCI consequences. We describe implications for mental health app design, including the need for greater transparency around free versus paid features, and propose new approaches to provide vulnerable users with validated information about these commonly downloaded apps.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Tessa Eagle et al.",
      "keywords": "Download; Mental health; App store; Internet privacy; Mobile apps; Happiness; Anxiety; Transparency (behavior); Audit; Thematic analysis; Computer science; Psychology; Business; World Wide Web; Computer security; Qualitative research; Social psychology; Psychiatry; Accounting; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555155",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4379521748",
      "doi": "10.1145/3603495",
      "title": "Sensor-Based Locomotion Data Mining for Supporting the Diagnosis of Neurodegenerative Disorders: A Survey",
      "abstract": "Locomotion characteristics and movement patterns are reliable indicators of neurodegenerative diseases (NDDs). This survey provides a systematic literature review of locomotion data mining systems for supporting NDD diagnosis. We discuss techniques for discovering low-level locomotion indicators, sensor data acquisition and processing methods, and NDD detection algorithms. The survey presents a comprehensive discussion on the main challenges for this active area, including the addressed diseases, locomotion data types, duration of monitoring, employed algorithms, and experimental validation strategies. We also identify prominent open challenges and research directions regarding ethics and privacy issues, technological and usability aspects, and availability of public benchmarks.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Samaneh Zolfaghari et al.",
      "keywords": "Computer science; Usability; Data science; Open research; Data mining; Human\u2013computer interaction; Machine learning; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3603495",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226363257",
      "doi": "10.1145/3512958",
      "title": "Practicing Moderation: Community Moderation as Reflective Practice",
      "abstract": "Many types of online communities rely on volunteer moderators to manage the community and maintain behavioral standards. While prior work has shown that community moderators often develop a deep understanding of the goals of their moderation context and sophisticated processes for managing disruptions,less is known about the processes through which moderators develop this knowledge. In this paper, we leverage Donald Sch\u00f6n's concept of reflective practice as a lens for exploring how community moderators develop the 'knowledge-in-action' that they use to perform their work. Drawing on interviews with 18 Twitch moderators, we conceptualize moderators as reflective practitioners, iteratively encountering novel situations and adjusting their practices and mental models. Our findings provide detailed insight into how community moderators reflect-in-action, re-evaluating in real-time their mental models of viewer intent and community goals, and reflect-on-action, conducting post hoc assessments of individual incidents and long-term changes to adjust their practice over time. Moderators working in teams reveal specific aspects of reflection facilitated by cooperative discussion, which we call 'groupwise reflective practice'. By identifying community moderation as a form of reflective practice, we can leverage insights gained from studying practitioners in other fields,providing theoretical and practical implications for the study and support of community moderation.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Amanda L. L. Cullen et al.",
      "keywords": "Moderation; Leverage (statistics); Action (physics); Psychology; Context (archaeology); Reflective practice; Social psychology; Applied psychology; Knowledge management; Computer science; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3512958",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387329168",
      "doi": "10.1145/3610031",
      "title": "Technology-Mediated Strategies for Coping with Mental Health Challenges: Insights from People with Bipolar Disorder",
      "abstract": "Technology plays an increasingly pivotal role in mediating mental health support in people's everyday lives. However, it is not clear how that mediation is occurring, to what end, and what technologies are implicated. In this study, we examine these questions with a mixed-methods analysis of conversations among participants in several Bipolar Disorder (BD) communities on Reddit. Analyzing posts produced over four years, we identify a wide variety of technologies that people employ to manage their mental conditions, such as communication technologies, online communities and tracking tools. Using this taxonomy of technologies as a framework, we then summarize three technology-mediated management strategies that these technologies enable, including serving as community, episode, and information mediators. We argue that with a comprehensive and nuanced understanding of people's in situ technology use, we can identify research and design opportunities for designing human-centered technologies to help people manage mental health challenges more effectively.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Tian Xu et al.",
      "keywords": "Mental health; Variety (cybernetics); Bipolar disorder; Psychology; Mediation; Information and Communications Technology; Knowledge management; Sociology; Computer science; Psychotherapist; World Wide Web; Psychiatry; Cognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610031",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387344842",
      "doi": "10.1145/3610210",
      "title": "Speculating with Care: Worker-centered Perspectives on Scale in a Chat-based Health Information Service",
      "abstract": "Seeking to address barriers to in-person care, governments and non-governmental organizations (NGOs) globally have been pushing for scaling chat- or phone-based information services that rely on care workers to engage with users. Despite theoretical tensions between care and scale and the essential role of care workers, workers' perspective on scale and its impact on care provision is rarely centered early on in decisions to scale. In this paper, we examine care and scale from the perspective of medical support executives (MSEs) who support a chat-based health information service for maternal and child health deployed across multiple states in India. We draw on observations of MSEs' work, interviews with MSEs, NGO staff who implement the service, and families who use the service, and speculative design sessions conducted with MSEs. We find that by centering MSEs' perspectives, we can differentiate between growth of the relationships and heterogeneity that enable social impact, versus scale-thinking that promotes the decontextualization of care. We leverage our findings to discuss implications for scale and automation in chat-based health information services, including the importance of human connection, place, and support for care workers.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Naveena Karusala et al.",
      "keywords": "Leverage (statistics); Phone; Scale (ratio); Public relations; Service (business); Perspective (graphical); Business; Health care; Service delivery framework; Human services; Social work; Psychology; Nursing; Marketing; Medicine; Political science; Economic growth; Computer science; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610210",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391653597",
      "doi": "10.1145/3645090",
      "title": "Who\u2019s in Charge Here? A Survey on Trustworthy AI in Variable Autonomy Robotic Systems",
      "abstract": "This article surveys the Variable Autonomy (VA) robotics literature that considers two contributory elements to Trustworthy AI: transparency and explainability. These elements should play a crucial role when designing and adopting robotic systems, especially in VA where poor or untimely adjustments of the system\u2019s level of autonomy can lead to errors, control conflicts, user frustration, and ultimate disuse of the system. Despite this need, transparency and explainability is, to the best of our knowledge, mostly overlooked in VA robotics literature or is not considered explicitly. In this article, we aim to present and examine the most recent contributions to the VA literature concerning transparency and explainability. In addition, we propose a way of thinking about VA by breaking these two concepts down based on: the mission of the human-robot team; who the stakeholder is; what needs to be made transparent or explained; why they need it; and how it can be achieved. Last, we provide insights and propose ways to move VA research forward. Our goal with this article is to raise awareness and inter-community discussions among the Trustworthy AI and the VA robotics communities.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Leila Methnani et al.",
      "keywords": "Transparency (behavior); Autonomy; Robotics; Computer science; Trustworthiness; Artificial intelligence; Robot; Stakeholder; Human\u2013computer interaction; Knowledge management; Computer security; Public relations; Political science; Law",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3645090",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390815865",
      "doi": "10.1145/3631430",
      "title": "A User-Centered Framework to Empower People with Parkinson's Disease",
      "abstract": "We present a user-centric validation of a teleneurology platform, assessing its effectiveness in conveying screening information, facilitating user queries, and offering resources to enhance user empowerment. This validation process is implemented in the setting of Parkinson's disease (PD), in collaboration with a neurology department of a major medical center in the USA. Our intention is that with this platform, anyone globally with a webcam and microphone-equipped computer can carry out a series of speech, motor, and facial mimicry tasks. Our validation method demonstrates to users a mock PD risk assessment and provides access to relevant resources, including a chatbot driven by GPT, locations of local neurologists, and actionable and scientifically-backed PD prevention and management recommendations. We share findings from 91 participants (48 with PD, 43 without) aimed at evaluating the user experience and collecting feedback. Our framework was rated positively by 80.85% (standard deviation \u00b1 8.92%) of the participants, and it achieved an above-average 70.42 (standard deviation \u00b1 13.85) System-Usability-Scale (SUS) score. We also conducted a thematic analysis of open-ended feedback to further inform our future work. When given the option to ask any questions to the chatbot, participants typically asked for information about neurologists, screening results, and the community support group. We also provide a roadmap of how the knowledge generated in this paper can be generalized to screening frameworks for other diseases through designing appropriate recording environments, appropriate tasks, and tailored user-interfaces.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Wasifur Rahman et al.",
      "keywords": "Usability; Computer science; Chatbot; Notice; Thematic analysis; Medicine; Human\u2013computer interaction; World Wide Web; Qualitative research",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3631430",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4396695484",
      "doi": "10.1145/3660634",
      "title": "Data management for continuous learning in EHR systems",
      "abstract": "To gain a comprehensive understanding of a patient\u2019s health, advanced analytics must be applied to the data collected by electronic health record (EHR) systems. However, managing and curating this data requires carefully designed workflows. While digitalization and standardization enable continuous health monitoring, missing data values and technical issues can compromise the consistency and timeliness of the data. In this paper, we propose a workflow for developing prognostic models that leverages the SMART BEAR infrastructure and the capabilities of the Big Data Analytics (BDA) engine to homogenize and harmonize data points. Our workflow improves the quality of the data by evaluating different imputation algorithms and selecting one that maintains the distribution and correlation of features similar to the raw data. We applied this workflow to a subset of the data stored in the SMART BEAR repository and examined its impact on the prediction of emerging health states such as cardiovascular disease and mild depression. We also discussed the possibility of model validation by clinicians in the SMART BEAR project, the transmission of subsequent actions in the decision support system, and the estimation of the required number of data points.",
      "year": "2024",
      "journal": "ACM Transactions on Internet Technology",
      "authors": "Valerio Bellandi et al.",
      "keywords": "Computer science; Workflow; Data science; Standardization; Raw data; Big data; Analytics; Data quality; Workflow management system; Missing data; Consistency (knowledge bases); Data mining; Data warehouse; Database; Machine learning; Artificial intelligence; Service (business)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3660634",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391221822",
      "doi": "10.1145/3643034",
      "title": "Voxel-Wise Medical Image Generalization for Eliminating Distribution Shift",
      "abstract": "Currently, the medical field is witnessing an increase in the use of machine learning techniques. Supervised learning methods adopted in classification, prediction, and segmentation tasks for medical images always experience decreased performance when the training and testing datasets do not follow the independent and identically distributed assumption. These distribution shift situations seriously influence machine learning applications\u2019 robustness, fairness, and trustworthiness in the medical domain. Hence, in this article, we adopt the CycleGAN (generative adversarial network) method to cycle train the computed tomography data from different scanners/manufacturers. It aims to eliminate the distribution shift from diverse data terminals based on our previous work [ 14 ]. However, due to the model collapse problem and generative mechanisms of the GAN-based model, the images we generated contained serious artifacts. To remove the boundary marks and artifacts, we adopt score-based diffusion generative models to refine the images voxel-wisely. This innovative combination of two generative models enhances the quality of data providers while maintaining significant features. Meanwhile, we use five paired patients\u2019 medical images to deal with the evaluation experiments with structural similarity index measure metrics and the segmentation model\u2019s performance comparison. We conclude that CycleGAN can be utilized as an efficient data augmentation technique rather than a distribution-shift-eliminating method. In contrast, the denoising diffusion the denoising diffusion model is more suitable for dealing with the distribution shift problem aroused by the different terminal modules. The limitation of generative methods applied in medical images is the difficulty in obtaining large and diverse datasets that accurately capture the complexity of biological structure and variability. In our following research, we plan to assess the initial and generated datasets to explore more possibilities to overcome the above limitation. We will also incorporate the generative methods into the federated learning architecture, which can maintain their advantages and resolve the distribution shift issue on a larger scale.",
      "year": "2024",
      "journal": "ACM Transactions on Knowledge Discovery from Data",
      "authors": "Feifei Li et al.",
      "keywords": "Computer science; Artificial intelligence; Robustness (evolution); Voxel; Generative grammar; Segmentation; Generative model; Pattern recognition (psychology); Generalization; Machine learning; Field (mathematics); Pooling; Data mining; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643034",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3141735920",
      "doi": "10.1145/3448095",
      "title": "Outliers in Smartphone Sensor Data Reveal Outliers in Daily Happiness",
      "abstract": "Enabling smartphones to understand our emotional well-being provides the potential to create personalised applications and highly responsive interfaces. However, this is by no means a trivial task - subjectivity in reporting emotions impacts the reliability of ground-truth information whereas smartphones, unlike specialised wearables, have limited sensing capabilities. In this paper, we propose a new approach that advances emotional state prediction by extracting outlier-based features and by mitigating the subjectivity in capturing ground-truth information. We utilised this approach in a distinctive and challenging use case - happiness detection - and we demonstrated prediction performance improvements of up to 13% in AUC and 27% in F-score compared to the traditional modelling approaches. The results indicate that extreme values (i.e. outliers) of sensor readings mirror extreme values in the reported happiness levels. Furthermore, we showed that this approach is more robust in replicating the prediction model in completely new experimental settings.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Teodora Sandra Buda et al.",
      "keywords": "Happiness; Outlier; Computer science; Wearable computer; Reliability (semiconductor); Task (project management); Ground truth; Artificial intelligence; Anomaly detection; Subjectivity; Data mining; Machine learning; Psychology; Social psychology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3448095",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3011506732",
      "doi": "10.1145/3372045",
      "title": "Sub-Population Specific Models of Couples\u2019 Conflict",
      "abstract": "Interpersonal conflict between couples is a significant source of stress with long-lasting effects on partners\u2019 physical and psychological health. Motivated by findings in psychological science, we study how couples with distinct relationship functioning characteristics experience conflict in real life. We propose sub-population specific machine learning models using hierarchical and adaptive learning frameworks to automatically detect interpersonal conflict through the ambulatory monitoring of couples\u2019 physiological signals, audio samples, and linguistic indices. Results indicate that the proposed models outperform a general model learned for the entire population and separate models independently trained on each sub-population, providing a foundation toward personalized health applications.",
      "year": "2020",
      "journal": "ACM Transactions on Internet Technology",
      "authors": "Krit Gupta et al.",
      "keywords": "Interpersonal communication; Population; Computer science; Foundation (evidence); Interpersonal relationship; Artificial intelligence; Cognitive psychology; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3372045",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366456029",
      "doi": "10.1145/3592621",
      "title": "14 Years of Self-Tracking Technology for mHealth\u2014Literature Review: Lessons Learned and the PAST SELF Framework",
      "abstract": "In today\u2019s connected society, many people rely on mHealth and self-tracking (ST) technology to help them adopt healthier habits with a focus on breaking their sedentary lifestyle and staying fit. However, there is scarce evidence of such technological interventions\u2019 effectiveness, and there are no standardized methods to evaluate their impact on people\u2019s physical activity and health. This work aims to help ST practitioners and researchers by empowering them with systematic guidelines and a framework for designing and evaluating technological interventions to facilitate health behavior change and user engagement, focusing on increasing physical activity and decreasing sedentariness. To this end, we conduct a literature review of 129 papers between 2008 and 2022, which identifies the core ST design principles and their efficacy, as well as the most comprehensive list to date of user engagement evaluation metrics for ST. Based on the review\u2019s findings, we propose PAST SELF, a framework to guide the design and evaluation of ST technology that has potential applications in industrial and scientific settings. Finally, to facilitate researchers and practitioners, we complement this article with an open corpus and an online, adaptive exploration tool for the PAST SELF data.",
      "year": "2023",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Sofia Yfantidou et al.",
      "keywords": "mHealth; Psychological intervention; Tracking (education); Sedentary behavior; Work (physics); Computer science; Psychology; Knowledge management; Physical activity; Applied psychology; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3592621",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391169641",
      "doi": "10.1145/3635148",
      "title": "Adult Autism Research Priorities and Conceptualization in Computing Research: Invitation to Co-lead with Autistic Adults",
      "abstract": "Autism research is primarily targeted toward children and at normalizing autistic traits. We conducted a literature review of computing research on adult autism, focusing on identifying research priorities set by autistic adults and their allies, determining participation levels, identifying how autism is conceptualized, and the types of technologies designed and their purposes. We found: (1) that computing research in adult autism is neither representative of older and non-binary adults nor of autistic adults living outside the USA and Europe; (2) a lack of technologies geared towards the priorities set by autistic adults and their allies; and (3) that computing research primarily views adult autism as a medical deficit and builds design solutions and technologies that follow this marginalizing narrative. We discuss the status quo and provide recommendations for computing researchers to encourage research built on user needs and that is respectful of autistic adults.",
      "year": "2024",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Dafne Zuleima Morgado Ram\u00edrez et al.",
      "keywords": "Conceptualization; Autism; Lead (geology); Psychology; Autistic spectrum disorder; Developmental psychology; Data science; Computer science; Cognitive psychology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3635148",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393992298",
      "doi": "10.1145/3653982",
      "title": "HydraGAN: A Cooperative Agent Model for Multi-Objective Data Generation",
      "abstract": "Generative adversarial networks have become a de facto approach to generate synthetic data points that resemble their real counterparts. We tackle the situation where the realism of individual samples is not the sole criterion for synthetic data generation. Additional constraints such as privacy preservation, distribution realism, and diversity promotion may also be essential to optimize. To address this challenge, we introduce HydraGAN , a multi-agent network that performs multi-objective synthetic data generation. We theoretically verify that training the HydraGAN system, containing a single generator and an arbitrary number of discriminators, leads to a Nash equilibrium. Experimental results for six datasets indicate that HydraGAN consistently outperforms prior methods in maximizing the Area under the Radar Chart, balancing a combination of cooperative or competitive data generation goals.",
      "year": "2024",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Chance DeSmet et al.",
      "keywords": "Computer science; Generator (circuit theory); Synthetic data; De facto; Generative grammar; Artificial intelligence; Machine learning; Mathematical optimization; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3653982",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392471831",
      "doi": "10.1145/3650206",
      "title": "Am I Hurt?: Evaluating Psychological Pain Detection in Hindi Text Using Transformer-based Models",
      "abstract": "The automated evaluation of pain is critical for developing effective pain management approaches that seek to alleviate pain while preserving patients\u2019 functioning. Transformer-based models can aid in detecting pain from Hindi text data gathered from social media by leveraging their ability to capture complex language patterns and contextual information. By understanding the nuances and context of Hindi text, transformer models can effectively identify linguistic cues and sentiments and expressions associated with pain, enabling the detection and analysis of pain-related content present in social media posts. The purpose of this research is to analyze the feasibility of utilizing NLP techniques to automatically identify pain within Hindi textual data, providing a valuable tool for pain assessment in Hindi-speaking populations. The research showcases the HindiPainNet model, a deep neural network that employs the IndicBERT model, classifying the dataset into two class labels {pain, no_pain} for detecting pain in Hindi textual data. The model is trained and tested using a novel dataset, \u0926\u0930\u094d\u0926-\u090f-\u0936\u093e\u092f\u0930\u0940 (pronounced as Dard-e-Shayari ), curated using posts from social media platforms. The results demonstrate the model's effectiveness, achieving an accuracy of 70.5%. This pioneer research highlights the potential of utilizing textual data from diverse sources to identify and understand pain experiences based on psychosocial factors. This research could pave the path for the development of automated pain assessment tools that help medical professionals comprehend and treat pain in Hindi-speaking populations. Additionally, it opens avenues to conduct further NLP-based multilingual pain detection research, addressing the needs of diverse language communities.",
      "year": "2024",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Ravleen Kaur et al.",
      "keywords": "Hindi; Computer science; Social media; Natural language processing; Artificial intelligence; Psychosocial; Transformer; Psychology; Machine learning; World Wide Web; Engineering; Psychotherapist",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3650206",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387087186",
      "doi": "10.1145/3610924",
      "title": "Contact Tracing for Healthcare Workers in an Intensive Care Unit",
      "abstract": "Contact tracing is a powerful tool for mitigating the spread of COVID-19 during the pandemic. Front-line healthcare workers are particularly at high risk of infection in hospital units. This paper presents ContAct TraCing for Hospitals (CATCH), an automated contact tracing system designed specifically for healthcare workers in hospital environments. CATCH employs distributed embedded devices placed throughout a hospital unit to detect close contacts among healthcare workers wearing Bluetooth Low Energy (BLE) beacons. We first identify a set of distinct contact tracing scenarios based on the diverse environmental characteristics of a real-world intensive care unit (ICU) and the different working patterns of healthcare workers in different spaces within the unit. We then develop a suite of novel contact tracing methods tailored for each scenario. CATCH has been deployed and evaluated in the ICU of a major medical center, demonstrating superior accuracy in contact tracing over existing approaches through a wide range of experiments. Furthermore, the real-world case study highlights the effectiveness and efficiency of CATCH compared to standard contact tracing practices.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Jingwen Zhang et al.",
      "keywords": "Contact tracing; Beacon; Tracing; Health care; Bluetooth; Suite; Intensive care unit; Computer science; Medical emergency; Medicine; Coronavirus disease 2019 (COVID-19); Real-time computing; Geography; Telecommunications; Infectious disease (medical specialty); Intensive care medicine; Disease; Wireless; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610924",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3184815793",
      "doi": "10.1145/3453166",
      "title": "Triage of 2D Mammographic Images Using Multi-view Multi-task Convolutional Neural Networks",
      "abstract": "With an aging and growing population, the number of women receiving mammograms is increasing. However, existing techniques for autonomous diagnosis do not surpass a well-trained radiologist. Therefore, to reduce the number of mammograms that require examination by a radiologist, subject to preserving the diagnostic accuracy observed in current clinical practice, we develop Man and Machine Mammography Oracle (MAMMO)\u2014a clinical decision support system capable of determining whether its predicted diagnoses require further radiologist examination. We first introduce a novel multi-view convolutional neural network (CNN) trained using multi-task learning (MTL) to diagnose mammograms and predict the radiological assessments known to be associated with cancer. MTL improves diagnostic performance and triage efficiency while providing an additional layer of model interpretability. Furthermore, we introduce a novel triage network that takes as input the radiological assessment and diagnostic predictions of the multi-view CNN and determines whether the radiologist or CNN will most likely provide the correct diagnosis. Results obtained on a dataset of over 7,000 patients show that MAMMO reduced the number of diagnostic mammograms requiring radiologist reading by 42.8% while improving the overall diagnostic accuracy in comparison to readings done by radiologists alone.",
      "year": "2021",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Trent Kyono et al.",
      "keywords": "Interpretability; Triage; Convolutional neural network; Medical diagnosis; Computer science; Oracle; Artificial intelligence; Mammography; Scintimammography; Machine learning; Task (project management); Radiology; Medical physics; Medicine; Breast cancer; Cancer; Medical emergency",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3453166",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377824818",
      "doi": "10.1145/3598301",
      "title": "Data-driven Energy-efficient Adaptive Sampling Using Deep Reinforcement Learning",
      "abstract": "This article presents a resource-efficient adaptive sampling methodology for classifying electrocardiogram (ECG) signals into different heart rhythms. We present our methodology in two folds: ( i ) the design of a novel real-time adaptive neural network architecture capable of classifying ECG signals with different sampling rates and ( ii ) a runtime implementation of sampling rate control using deep reinforcement learning (DRL). By using essential morphological details contained in the heartbeat waveform, the DRL agent can control the sampling rate and effectively reduce energy consumption at runtime. To evaluate our adaptive classifier, we use the MIT-BIH database and the recommendation of the AAMI to train the classifiers. The classifier is designed to recognize three major types of arrhythmias, which are supraventricular ectopic beats (SVEB), ventricular ectopic beats (VEB), and normal beats (N). The performance of the arrhythmia classification reaches an accuracy of 97.2% for SVEB and 97.6% for VEB beats. Moreover, the designed system is 7.3\u00d7 more energy-efficient compared to the baseline architecture, where the adaptive sampling rate is not utilized. The proposed methodology can provide reliable and accurate real-time ECG signal analysis with performances comparable to state-of-the-art methods. Given its time-efficient, low-complexity, and low-memory-usage characteristics, the proposed methodology is also suitable for practical ECG applications, in our case for arrhythmia classification, using resource-constrained devices, especially wearable healthcare devices and implanted medical devices.",
      "year": "2023",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Berken Utku Demirel et al.",
      "keywords": "Computer science; Artificial intelligence; Reinforcement learning; Heartbeat; Adaptive sampling; Classifier (UML); Wearable computer; Pattern recognition (psychology); Sampling (signal processing); Machine learning; Computer vision; Embedded system; Filter (signal processing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3598301",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387329104",
      "doi": "10.1145/3610192",
      "title": "Inform, Explain, or Control: Techniques to Adjust End-User Performance Expectations for a Conversational Agent Facilitating Group Chat Discussions",
      "abstract": "A conversational agent (CA) effectively facilitates online group discussions at scale. However, users may have expectations about how well the CA would perform that do not match with the actual performance, compromising technology acceptance. We built a facilitator CA that detects a member who has low contribution during a synchronous group chat discussion and asks the person to participate more. We designed three techniques to set end-user expectations about how accurately the CA identifies an under-contributing member: 1)information: explicitly communicating the accuracy of the detection algorithm, 2)explanation: providing an overview of the algorithm and the data used for the detection, and 3)adjustment: enabling users to gain a feeling of control over the algorithm. We conducted an online experiment with 163 crowdworkers in which each group completed a collaborative decision-making task and experienced one of the techniques. Through surveys and interviews, we found that the explanation technique was the most effective strategy overall as it reduced user embarrassment, increased the perceived intelligence of the CA, and helped users better understand the detection algorithm. In contrast, the information technique reduced members' contributions and the adjustment technique led to a more negative perceived discussion experience. We also discovered that the interactions with other team members diluted the effects of the techniques on users' performance expectations and acceptance of the CA. We discuss implications for better designing expectation-setting techniques for AI-team collaboration such as ways to improve collaborative decision outcomes and quality of contributions.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Hyo Jin et al.",
      "keywords": "Facilitator; Task (project management); Set (abstract data type); Computer science; Feeling; Control (management); Embarrassment; Quality (philosophy); Group decision-making; Contrast (vision); Knowledge management; Psychology; Human\u2013computer interaction; Social psychology; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610192",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4309618997",
      "doi": "10.1145/3555605",
      "title": "Uncovering Adverse Childhood Experiences (ACEs) from Clinical Narratives within the Electronic Health Record",
      "abstract": "Adverse Childhood Events (ACEs) are potentially traumatic events that occur in childhood (e.g., sexual abuse and maternal violence). Clinical research highlights the significant impact ACEs have on youth's mental health similar to other youth-related issues like traditional bullying and cyberbullying. However, research focused on the intersection of these two are limited. We report the results from a qualitative study that used electronic health record (EHR) data and clinical narratives from Parkview Behavioral Health hospital (n=719) to better understand the presentation of ACEs in patients who indicated cyber/bullying contributed to their inpatient hospital admission. Our deductive thematic analyses on the clinical narratives/notes and diagnoses highlight the connection of ACEs with cyber/bullying and other clinical diagnoses like depression, anxiety, PTSD, and ADD/ADHD. Additionally, our results point to potential impacts of the gender spectrum and other non-ACE indicators like adoption and the need for Department of Child Services (DCS). The outcome of this study provides distinct computational and clinical design guidelines for better collaborative decision making in healthcare, including the need for ACEs screening as standard-of-care within acute mental health settings. CAUTION: This paper includes graphic contents about adverse childhood traumas and events.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Fayika Farhat Nova et al.",
      "keywords": "Mental health; Adverse Childhood Experiences; Psychiatry; Anxiety; Thematic analysis; Sexual abuse; Narrative; Medicine; Health care; Psychology; Clinical psychology; Poison control; Qualitative research; Suicide prevention; Medical emergency",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555605",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4384697538",
      "doi": "10.1145/3609483",
      "title": "Few-shot Named Entity Recognition: Definition, Taxonomy and Research Directions",
      "abstract": "Recent years have seen an exponential growth (+98% in 2022 w.r.t. the previous year) of the number of research articles in the few-shot learning field, which aims at training machine learning models with extremely limited available data. The research interest toward few-shot learning systems for Named Entity Recognition (NER) is thus at the same time increasing. NER consists in identifying mentions of pre-defined entities from unstructured text, and serves as a fundamental step in many downstream tasks, such as the construction of Knowledge Graphs, or Question Answering. The need for a NER system able to be trained with few-annotated examples comes in all its urgency in domains where the annotation process requires time, knowledge and expertise (e.g., healthcare, finance, legal), and in low-resource languages. In this survey, starting from a clear definition and description of the few-shot NER (FS-NER) problem, we take stock of the current state-of-the-art and propose a taxonomy which divides algorithms in two macro-categories according to the underlying mechanisms: model-centric and data-centric. For each category, we line-up works as a story to show how the field is moving toward new research directions. Eventually, techniques, limitations, and key aspects are deeply analyzed to facilitate future studies.",
      "year": "2023",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Vincenzo Moscato et al.",
      "keywords": "Computer science; Named-entity recognition; Annotation; Taxonomy (biology); Artificial intelligence; Natural language processing; Field (mathematics); Data science; Information retrieval; Task (project management)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3609483",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390575528",
      "doi": "10.1145/3639047",
      "title": "Survey on Recommender Systems for Biomedical Items in Life and Health Sciences",
      "abstract": "The generation of biomedical data is of such magnitude that its retrieval and analysis have posed several challenges. A survey of recommender system (RS) approaches in biomedical fields is provided in this analysis, along with a discussion of existing challenges related to large-scale biomedical information retrieval systems. We collect original studies, identify entities and models, and discuss how knowledge graphs (KGs) can improve results. As a result, most of the papers used model-based collaborative filtering algorithms, most of the available datasets did not follow the standard format &lt; user, item, rating &gt;, and regarding qualitative evaluations of RSs use mainly classification metrics. Finally, we have assembled and coded a unique dataset of 60 papers \u2014 Sur-RS4BioT, available for download at DOI:10.34740/kaggle/ds/2346894",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Matilde Pato et al.",
      "keywords": "Computer science; Recommender system; Data science; Information retrieval; Biomedical sciences; World Wide Web; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3639047",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4413973419",
      "doi": "10.1145/3749494",
      "title": "Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications across Lab and Field Settings",
      "abstract": "Photoplethysmography (PPG)-based foundation models are gaining traction due to the widespread use of PPG in biosignal monitoring and their potential to track diverse health indicators. In this paper, we introduce Pulse-PPG, an open-source PPG foundation model trained exclusively on raw PPG data collected over a 100-day field study with 120 participants. Existing open-source PPG foundation models are trained on clinical data, and those trained on field data are closed source, limiting their applicability in real-world settings. Extensive evaluations demonstrate that Pulse-PPG, trained on uncurated field data, exhibits superior generalization and performance across clinical and mobile health applications in both lab and field settings, when compared with state-of-the-art PPG foundation models trained on clinical data. Exposure to real-world variability in field-collected PPG data enables Pulse-PPG to learn more robust representations. Furthermore, pre-training Pulse-PPG on field data outperforms its own pre-training on clinical data in many tasks, reinforcing the importance of training on real-world datasets. To encourage further advancements in robust PPG modeling, we have open-sourced*our Pulse-PPG model, providing researchers with a valuable resource for developing the next generation of task-specific PPG-based models.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Mithun Saha et al.",
      "keywords": "Wearable computer; Field (mathematics); Pulse (music); Open source; Foundation (evidence); Computer science; Acoustics; Engineering; Physics; Telecommunications; Embedded system; Geography; Mathematics; Software",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749494",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387344934",
      "doi": "10.1145/3610037",
      "title": "Building Causal Agency in Autistic Students through Iterative Reflection in Collaborative Transition Planning",
      "abstract": "Transition planning is a collaborative process to promote agency in students with disabilities by encouraging them to participate in setting their own goals with team members and learn ways to assess their progress towards the goals. For autistic young adults who experience a lower employment rate, less stability in employment, and lower community connections than those with other disabilities, successful transition planning is an important opportunity to develop agency towards preparing and attaining success in employment and other areas meaningful to them. However, a failure of consistent information sharing among team members and opportunities for agency in students has prevented successful transition planning for autistic students. Therefore, this work brings causal agency theory and the collaborative reflection framework together to uncover ways transition teams can develop students' agency by collaboratively reflecting on students' inputs related to transition goals and progress. By interviewing autistic students, parents of autistic students, and professionals who were involved in transition planning, we uncovered that teams can better support student agency by accommodating their needs and encouraging their input in annual meetings, building relationships through transparent and frequent communication about day-to-day activities, centering goals on student's interests, and supporting student's skill-building in areas related to their transition goals. However, we found that many teams were not enacting these practices, leading to frustration and negative outcomes for young adults. Based on our findings, we propose a role for autistic students in the collaborative reflection framework that encouraged participation and builds causal agency. We also make design recommendations to encourage autistic students' participation in collaborative reflection around long-term and short-term needs in ways that promote their causal agency.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Rachel Lowy et al.",
      "keywords": "Agency (philosophy); Psychology; Transition (genetics); Public relations; Pedagogy; Political science; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610037",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393716831",
      "doi": "10.1145/3654660",
      "title": "Computational Politeness in Natural Language Processing: A Survey",
      "abstract": "Computational approach to politeness is the task of automatically predicting and/or generating politeness in text. This is a pivotal task for conversational analysis, given the ubiquity and challenges of politeness in interactions. The computational approach to politeness has witnessed great interest from the conversational analysis community. This article is a compilation of past works in computational politeness in natural language processing. We view four milestones in the research so far, viz. supervised and weakly supervised feature extraction to identify and induce politeness in a given text, incorporation of context beyond the target text, study of politeness across different social factors, and study the relationship between politeness and various socio-linguistic cues. In this article, we describe the datasets, approaches, trends, and issues in computational politeness research. We also discuss representative performance values and provide pointers to future works, as given in the prior works. In terms of resources to understand the state of the art, this survey presents several valuable illustrations\u2014most prominently, a table summarizing the past papers along different dimensions, such as the types of features, annotation techniques, and datasets used.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Priyanshu Priya et al.",
      "keywords": "Computer science; Politeness; Natural language processing; Natural language; Natural (archaeology); Artificial intelligence; Linguistics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3654660",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386001609",
      "doi": "10.1145/3617127",
      "title": "Recruitment Promotion via Twitter: A Network-centric Approach of Analyzing Community Engagement Using Social Identity",
      "abstract": "With the proliferation of online technologies, social media recruitment has become an essential part of any company\u2019s outreach campaign. A social media platform can provide marketing posts with access to a large pool of candidates and at a low cost. It also provides the opportunity to quickly customize and refine messages in response to the reception. With online marketing, the key question is: which communities are attracted by recruitment tweets on social media? In this work, we profile the Twitter accounts that interact with a set of recruitment tweets by the U.S. Army\u2019s Recruitment Command through a network-centric perspective. By harnessing how users signal their affiliations through user information, we extract and analyze communities of social identities. From Social Identity Theory, these social identities can be critical drivers of behavior, like the decision to enlist in the military. With this framework, we evaluate the effectiveness of the U.S. Army\u2019s recruitment campaign on Twitter, observing that these campaigns typically attract communities with military exposure like veterans or those that identify with professional careers and fitness (e.g., student, professionals, athletes). The campaign also attracts, but at a much lower level, interaction from those in the digital industries\u2014data scientists, cybersecurity professionals, and so forth. When analyzing the accounts in terms of their degree of automation, we find a set of intent-unknown bot accounts interacting with the tweets, and that many of the recruitment accounts are perceived as automated accounts. These observations can aid in campaign refinement: targeting the digital community and getting a broader reach for online recruitment publicity campaigns.",
      "year": "2023",
      "journal": "Digital Government Research and Practice",
      "authors": "Lynnette Hui Xian Ng et al.",
      "keywords": "Social media; Public relations; Outreach; Promotion (chess); Set (abstract data type); Identity (music); Social network (sociolinguistics); Online community; Internet privacy; Sociology; Computer science; World Wide Web; Political science; Politics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3617127",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3128935193",
      "doi": "10.1145/3447954",
      "title": "Why Real Citizens Would Turn to Artificial Leaders",
      "abstract": "Governments are increasingly using artificial intelligence to improve workflows and services. Applications range from predicting climate change, crime, and earthquakes to flu outbreaks, low air quality, and tax fraud. Artificial agents are already having an impact on eldercare, education, and open government, enabling users to complete procedures through a conversational interface. Whether replacing humans or assisting them, they are the technological fix of our times. In two experiments and a follow-up study, we investigate factors that influence the acceptance of artificial agents in positions of power, using attachment theory and disappointment theory as explanatory models. We found that when the state of the world provokes anxiety, citizens perceive artificial agents as a reliable proxy to replace human leaders. Moreover, people accept artificial agents as decision-makers in politics and security more willingly when they deem their leaders or government to be untrustworthy, disappointing, or immoral. Finally, we discuss these results with respect to theories of technology acceptance and the delegation of duties and prerogatives.",
      "year": "2021",
      "journal": "Digital Government Research and Practice",
      "authors": "Nicolas Spatola et al.",
      "keywords": "Disappointment; Government (linguistics); Delegation; Business; Public relations; Political science; Social psychology; Psychology; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3447954",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386928368",
      "doi": "10.1145/3625238",
      "title": "Exploring Structure Incentive Domain Adversarial Learning for Generalizable Sleep Stage Classification",
      "abstract": "Sleep stage classification is crucial for sleep state monitoring and health interventions. In accordance with the standards prescribed by the American Academy of Sleep Medicine, a sleep episode follows a specific structure comprising five distinctive sleep stages that collectively form a sleep cycle. Typically, this cycle repeats about five times, providing an insightful portrayal of the subject\u2019s physiological attributes. The progress of deep learning and advanced domain generalization methods allows automatic and even adaptive sleep stage classification. However, applying models trained with visible subject data to invisible subject data remains challenging due to significant individual differences among subjects. Motivated by the periodic category-complete structure of sleep stage classification, we propose a Structure Incentive Domain Adversarial learning (SIDA) method that combines the sleep stage classification method with domain generalization to enable cross-subject sleep stage classification. SIDA includes individual domain discriminators for each sleep stage category to decouple subject dependence differences among different categories and fine-grained learning of domain-invariant features. Furthermore, SIDA directly connects the label classifier and domain discriminators to promote the training process. Experiments on three benchmark sleep stage classification datasets demonstrate that the proposed SIDA method outperforms other state-of-the-art sleep stage classification and domain generalization methods and achieves the best cross-subject sleep stage classification results.",
      "year": "2023",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Shuo Ma et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Classifier (UML); Sleep (system call); Sleep Stages; Domain (mathematical analysis); Adversarial system; Benchmark (surveying); Psychology; Polysomnography; Mathematics; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3625238",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387329244",
      "doi": "10.1145/3610086",
      "title": "Similar Others, Social Comparison, and Social Support in Online Support Groups",
      "abstract": "Social comparison and social support have implications for individuals' wellbeing, offline and on social media. Perceptions of similarity underlie both social comparison and social support processes, though how comparison and support function in tandem in online spaces, and which aspects of identity and experiential similarity are salient to which comparison and support outcomes, merits investigation. Through interviews with people who have joined or considered joining social media-based support groups following pregnancy loss (N=18), we provide an intracommunity view into social comparison within online support groups. We identify a set of identity and experience attributes that inform perceptions of similarity and difference in these support spaces. We characterize tensions arising from these attributes and propose the preliminary Social Comparison and Social Support in Online Support Groups model to describe interactions between social support and comparison processes within online support groups. We further discuss findings' implications for design, including via introducing the tolerance principle of online health support groups. CAUTION: This paper includes quotes about pregnancy loss.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Kristen Barta et al.",
      "keywords": "Social support; Similarity (geometry); Social identity theory; Psychology; Set (abstract data type); Social psychology; Social identity approach; Social media; Social group; Perception; Computer science; World Wide Web; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610086",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394979938",
      "doi": "10.1145/3658666",
      "title": "Qualitative Approaches to Voice UX",
      "abstract": "Voice is a natural mode of expression offered by modern computer-based systems. Qualitative perspectives on voice-based user experiences (voice UX) offer rich descriptions of complex interactions that numbers alone cannot fully represent. We conducted a systematic review of the literature on qualitative approaches to voice UX, capturing the nature of this body of work in a systematic map and offering a qualitative synthesis of findings. We highlight the benefits of qualitative methods for voice UX research, identify opportunities for increasing rigour in methods and outcomes, and distill patterns of experience across a diversity of devices and modes of qualitative praxis.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Katie Seaborn et al.",
      "keywords": "Computer science; Rigour; Qualitative research; Human\u2013computer interaction; Praxis; Diversity (politics); Natural (archaeology); User experience design; Multimedia; Data science; Sociology; Epistemology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3658666",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391761597",
      "doi": "10.1145/3643643",
      "title": "Do We Really Need Imputation in AutoML Predictive Modeling?",
      "abstract": "Numerous real-world data contain missing values, while in contrast, most Machine Learning (ML) algorithms assume complete datasets. For this reason, several imputation algorithms have been proposed to predict and fill in the missing values. Given the advances in predictive modeling algorithms tuned in an Automated Machine Learning context (AutoML) setting, a question that naturally arises is to what extent sophisticated imputation algorithms (e.g., Neural Network based) are really needed, or we can obtain a descent performance using simple methods like Mean/Mode (MM). In this article, we experimentally compare six state-of-the-art representatives of different imputation algorithmic families from an AutoML predictive modeling perspective, including a feature selection step and combined algorithm and hyper-parameter selection. We used a commercial AutoML tool for our experiments, in which we included the selected imputation methods. Experiments ran on 25 binary classification real-world incomplete datasets with missing values and 10 binary classification complete datasets in which synthetic missing values are introduced according to different missingness mechanisms, at varying missing frequencies. The main conclusion drawn from our experiments is that the best method on average is the Denoise AutoEncoder on real-world datasets and the MissForest in simulated datasets, followed closely by MM. In addition, binary indicator variables encoding missingness patterns actually improve predictive performance, on average. Last, although there are cases where Neural-Network-based imputation significantly improves predictive performance, this comes at a great computational cost and requires measuring all feature values to impute new samples.",
      "year": "2024",
      "journal": "ACM Transactions on Knowledge Discovery from Data",
      "authors": "George Paterakis et al.",
      "keywords": "Imputation (statistics); Missing data; Computer science; Artificial intelligence; Artificial neural network; Feature selection; Machine learning; Binary classification; Data mining; Autoencoder; Binary number; Pattern recognition (psychology); Support vector machine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643643",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387331310",
      "doi": "10.1145/3610075",
      "title": "Knowing Unknown Teammates: Exploring Anonymity and Explanations in a Teammate Information-Sharing Recommender System",
      "abstract": "A growing organizational trend is to utilize ad-hoc team formation which allows for teams to intentionally form based on the member skills required to accomplish a specific task. Due to the unfamiliar nature of these teams, teammates are often limited by their understanding of one another (e.g., teammate preferences, tendencies, attitudes) which limits the team's functioning and efficiency. This study conceptualizes and investigates the use of a teammate information-sharing recommender system which selectively shares interpersonal recommendations between unfamiliar teammates (e.g., \"Your voice may be overshadowed by this teammate when making decisions...\") to promote teammate understanding. Through a mixed-methods approach involving 105 participants working on actual unfamiliar teams, this study explores how presentation elements such as anonymity and explanations influence system perceptions and how anonymity influences team outcomes. Results indicate that anonymizing recommendations was associated with worse team measures, particularly team satisfaction and team cohesion. Qualitative results shed light on why team members perceived privacy concerns and team benefits associated with using the system. We contribute to CSCW through a better understanding of how to support unfamiliar teams, the conceptualization and empirical investigation of a novel teammate information-sharing recommender system, and foundational design recommendations associated with such a system.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Geoff Musick et al.",
      "keywords": "Anonymity; Conceptualization; Computer science; Recommender system; Empirical research; Task (project management); Cohesion (chemistry); Perception; Interpersonal communication; Information sharing; Knowledge management; Psychology; Social psychology; World Wide Web; Artificial intelligence; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610075",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4413751343",
      "doi": "10.1145/3760549",
      "title": "Moving from Fairness to Justice: Intentional Algorithmic Solutions Through an Intersectional Lens",
      "abstract": "In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors",
      "year": "2025",
      "journal": "interactions",
      "authors": "Kenya S. Andrews",
      "keywords": "Economic Justice; Through-the-lens metering; Lens (geology); Sociology; Social justice; Criminology; Computer science; Law and economics; Political science; Law; Optics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3760549",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414128177",
      "doi": "10.1145/3767326",
      "title": "Explainable Surgical Procedures Recommender System Leveraging Large Language Models",
      "abstract": "Significant advancements have recently been made in the fields of recommender systems and natural language processing, particularly with large language models (LLMs). In most cases, recommender systems have been used to suggest items and enhance personalization for users, while LLMs have been applied to textual tasks such as text completion, translation, and summarization. In this study, we demonstrate that integrating recommender system models with recent LLMs can effectively suggest appropriate surgical procedures for patients. We employ several LLMs to process clinical text in a morphologically rich language, serving three crucial roles: information representation, information enrichment, and explaining the surgical procedure suggestions made by the recommender system. Our method was evaluated using real-world clinical data, considering patients\u2019 demographic attributes and health conditions. To assess the explainability of our method, we conducted an extensive experiment involving several clinicians. The results achieved by our method indicate that using recommender systems and LLMs can lead to high performance and improved explanations. Our study has the potential to enhance the personalization of healthcare and could be adopted by health services to assist healthcare professionals in recommending appropriate surgical procedures.",
      "year": "2025",
      "journal": "ACM Transactions on Recommender Systems",
      "authors": "Adir Solomon et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3767326",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4413308157",
      "doi": "10.1145/3762180",
      "title": "Metaverse Platforms for Immersive Healthcare: A Survey on Telemedicine Solutions",
      "abstract": "Health disorders are characterized by physical health and mental health, which are pretty standard among the majority of the population. Telemedicine solutions to address such issues are experienced only by a significant portion of health professionals and the diseased. Lack of awareness and hindrance to modern technology are identified as an impact on the usage of telemedicine solutions, and there is growing evidence that a significant number of members utilize these platforms. However, despite this growing trend, the physical presence of health professionals in face-to-face discussions seems challenging. The emergence of Metaverse has turned out to be a possible solution to facilitate immersive experiences for patients and healthcare professionals. In this pap er, we survey the utilization of the Metaverse platforms to facilitate current medical diagnosis and treatment procedures through remote and immersive means. To provide secure means of healthcare solutions, we summarize the privacy and security concerns prevalent in Metaverse platforms and the potential solutions for addressing them. Finally, we summarize the future research trends by addressing six challenges of incorporating telemedicine communication in the Metaverse.",
      "year": "2025",
      "journal": "ACM Computing Surveys",
      "authors": "Senthil Kumar Jagatheesaperumal et al.",
      "keywords": "Computer science; Telemedicine; Metaverse; Health care; Human\u2013computer interaction; Multimedia; World Wide Web; Virtual reality",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3762180",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386928909",
      "doi": "10.1145/3616862",
      "title": "On the Frontline During the COVID-19 Pandemic: Gender Inequality and Experiences of Healthcare Workers in Pakistan",
      "abstract": "This mixed methods study investigates the experiences of healthcare workers (HCWs) along gender lines during the COVID-19 pandemic in Lahore, the second most populous city in Pakistan. In-person semi-structured interviews ( n = 62) and researcher-administered surveys ( n = 631) were conducted with doctors and nurses in five private and public hospitals. The findings reveal that male and female HCWs shared experiences related to increased working hours, psychological burdens, and adverse financial impacts. However, female HCWs struggled more than male HCWs, as their responsibilities at home and in the workplace increased. Additionally, more female HCWs than their male peers reported experiencing occupational stress due to transportation issues, working during pregnancy, and discriminatory attitudes of the patients toward them. Building on the results from our study, we propose several technological and policy initiatives that can be adopted by governments and organizations, especially in countries like Pakistan, where women account for most of the healthcare workforce but continue to bear a heavier burden when balancing work and family.",
      "year": "2023",
      "journal": "ACM Journal on Computing and Sustainable Societies",
      "authors": "Rukhshan Haroon et al.",
      "keywords": "Pandemic; Coronavirus disease 2019 (COVID-19); Inequality; Health care; 2019-20 coronavirus outbreak; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); Health equity; Healthcare worker; Sociology; Political science; Medicine; Economic growth; Virology; Economics; Outbreak; Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3616862",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413968401",
      "doi": "10.1145/3749503",
      "title": "Engagements with Generative AI and Personal Health Informatics: Opportunities for Planning, Tracking, Reflecting, and Acting around Personal Health Data",
      "abstract": "Personal informatics processes require navigating distinct challenges across stages of tracking, but the range of data, goals, expertise, and context that individuals bring to self-tracking often presents barriers that undermine those processes. We investigate the potential of Generative AI (GAI) to support people across stages of pursuing self-tracking for health. We conducted interview and observation sessions with 19 participants from the United States who self-track for health, examining how they interact with GAI around their personal health data. Participants formulated and refined queries, reflected on recommendations, and abandoned queries that did not meet their needs and health goals. They further identified opportunities for GAI support across stages of self-tracking, including in deciding what data to track and how, in defining and modifying tracking plans, and in interpreting data-driven insights. We discuss GAI opportunities in accounting for a range of health goals, in providing support for self-tracking processes across planning, reflection, and action, and in consideration of limitations of embedding GAI in health self-tracking tools.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Shaan Chopra et al.",
      "keywords": "Tracking (education); Health informatics; Informatics; Generative grammar; Public health informatics; Computer science; Data science; Psychology; Medicine; Artificial intelligence; Public health; Health promotion; Political science; Nursing; HRHIS; Pedagogy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749503",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390860179",
      "doi": "10.1145/3639452",
      "title": "Resolving the Human-subjects Status of Machine Learning's Crowdworkers",
      "abstract": "In recent years, machine learning (ML) has relied heavily on crowdworkers both for building datasets and for addressing research questions requiring human interaction or judgment. The diversity of both the tasks performed and the uses of the resulting data render it difficult to determine when crowdworkers are best thought of as workers versus human subjects. These difficulties are compounded by conflicting policies, with some institutions and researchers regarding all ML crowdworkers as human subjects and others holding that they rarely constitute human subjects. Notably few ML papers involving crowdwork mention IRB oversight, raising the prospect of non-compliance with ethical and regulatory requirements. We investigate the appropriate designation of ML crowdsourcing studies, focusing our inquiry on natural language processing to expose unique challenges for research oversight. Crucially, under the U.S. Common Rule, these judgments hinge on determinations of aboutness , concerning both whom (or what) the collected data is about and whom (or what) the analysis is about. We highlight two challenges posed by ML: the same set of workers can serve multiple roles and provide many sorts of information; and ML research tends to embrace a dynamic workflow, where research questions are seldom stated ex ante and data sharing opens the door for future studies to aim questions at different targets. Our analysis exposes a potential loophole in the Common Rule, where researchers can elude research ethics oversight by splitting data collection and analysis into distinct studies. Finally, we offer several policy recommendations to address these concerns.",
      "year": "2023",
      "journal": "Queue",
      "authors": "Divyansh Kaushik et al.",
      "keywords": "Crowdsourcing; Set (abstract data type); Workflow; Computer science; Data science; Diversity (politics); Common Rule; Knowledge management; World Wide Web; Political science; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3639452",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414241766",
      "doi": "10.1145/3767735",
      "title": "\u201cA 6 or a 9?\u201d: Ensemble Learning through the Multiplicity of Performant Models and Explanations",
      "abstract": "Creating models from past observations and ensuring their effectiveness on new data is the essence of machine learning. However, selecting models that generalize well remains a challenging task. Related to this topic, the Rashomon Effect refers to cases where multiple models perform similarly well for a given learning problem. This often occurs in real-world scenarios, like the manufacturing process or medical diagnosis, where diverse patterns in data lead to multiple high-performing solutions. We propose the Rashomon Ensemble, a method that strategically selects models from these diverse high-performing solutions to improve generalization. By grouping models based on both their performance and explanations, we construct ensembles that maximize diversity while maintaining predictive accuracy. This selection ensures that each model covers a distinct region of the solution space, making the ensemble more robust to distribution shifts and variations in unseen data. We validate our approach on both open and proprietary collaborative real-world datasets, demonstrating up to 0.20+ AUROC improvements in scenarios where the Rashomon ratio is large. Additionally, we demonstrate tangible benefits for businesses in various real-world applications, highlighting the robustness, practicality, and effectiveness of our approach.",
      "year": "2025",
      "journal": "ACM Transactions on Knowledge Discovery from Data",
      "authors": "Gianlucca Zuin et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3767735",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4413968568",
      "doi": "10.1145/3749465",
      "title": "Human Heterogeneity Invariant Stress Sensing",
      "abstract": "Stress affects physical and mental health, and wearable devices have been widely used to detect daily stress through physiological signals. However, these signals vary due to factors such as individual differences and health conditions, making generalizing machine learning models difficult. To address these challenges, we present Human Heterogeneity Invariant Stress Sensing (HHISS), a domain generalization approach designed to find consistent patterns in stress signals by removing person-specific differences. This helps the model perform more accurately across new people, environments, and stress types not seen during training. Its novelty lies in proposing a novel technique called person-wise sub-network pruning intersection to focus on shared features across individuals, alongside preventing overfitting by leveraging continuous labels while training. The present study focuses on people with opioid use disorder (OUD)---a group where stress responses can change dramatically depending on the presents of opioids in their system, including daily timed medication for OUD (MOUD). Since stress often triggers cravings, a model that can adapt well to these changes could support better OUD rehabilitation and recovery. We tested HHISS on seven different stress datasets---four which we collected ourselves and three public datasets. Four are from lab setups, one from a controlled real-world driving setting, and two are from real-world in-the-wild field datasets with no constraints. The present study is the first known to evaluate how well a stress detection model works across such a wide range of data. Results show HHISS consistently outperformed state-of-the-art baseline methods, proving both effective and practical for real-world use. Ablation studies, empirical justifications, and runtime evaluations confirm HHISS's feasibility and scalability for mobile stress sensing in sensitive real-world applications.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Yi Xiao et al.",
      "keywords": "Invariant (physics); Computer science; Geography; Mathematics; Mathematical physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749465",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3160537436",
      "doi": "10.1145/3444944",
      "title": "A Survey on Causal Inference",
      "abstract": "Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy, and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well-known causal inference frameworks. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent machine learning enhanced methods are discussed and compared. The plausible applications of these methods are also presented, including the applications in advertising, recommendation, medicine, and so on. Moreover, the commonly used benchmark datasets as well as the open-source codes are also summarized, which facilitate researchers and practitioners to explore, evaluate and apply the causal inference methods.",
      "year": "2021",
      "journal": "ACM Transactions on Knowledge Discovery from Data",
      "authors": "Liuyi Yao et al.",
      "keywords": "Causal inference; Randomized experiment; Observational study; Inference; Computer science; Data science; Outcome (game theory); Machine learning; Statistical inference; Benchmark (surveying); Artificial intelligence; Causal model; Data mining; Econometrics; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3444944",
      "cited_by_count": 410,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2969896603",
      "doi": "10.1145/3457607",
      "title": "A Survey on Bias and Fairness in Machine Learning",
      "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",
      "year": "2021",
      "journal": "ACM Computing Surveys",
      "authors": "Ninareh Mehrabi et al.",
      "keywords": "Computer science; Artificial intelligence; Commercialization; Data science; Taxonomy (biology); Work (physics); Order (exchange); Machine learning; Risk analysis (engineering); Business; Engineering; Marketing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3457607",
      "cited_by_count": 316,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4288083705",
      "doi": "10.1145/3274405",
      "title": "Trust in Data Science",
      "abstract": "The trustworthiness of data science systems in applied and real-world settings emerges from the resolution of specific tensions through situated, pragmatic, and ongoing forms of work. Drawing on research in CSCW, critical data studies, and history and sociology of science, and six months of immersive ethnographic fieldwork with a corporate data science team, we describe four common tensions in applied data science work: (un)equivocal numbers, (counter)intuitive knowledge, (in)credible data, and (in)scrutable models. We show how organizational actors establish and re-negotiate trust under messy and uncertain analytic conditions through practices of skepticism, assessment, and credibility. Highlighting the collaborative and heterogeneous nature of real-world data science, we show how the management of trust in applied corporate data science settings depends not only on pre-processing and quantification, but also on negotiation and translation. We conclude by discussing the implications of our findings for data science research and practice, both within and beyond CSCW.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Samir Passi et al.",
      "keywords": "Negotiation; Credibility; Skepticism; Computer-supported cooperative work; Data science; Knowledge management; Computer science; Sociology; Trustworthiness; Science communication; Work (physics); Epistemology; Engineering ethics; Science education; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274405",
      "cited_by_count": 176,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3043638540",
      "doi": "10.1145/3624010",
      "title": "A Survey of Privacy Attacks in Machine Learning",
      "abstract": "As machine learning becomes more widely used, the need to study its implications in security and privacy becomes more urgent. Although the body of work in privacy has been steadily growing over the past few years, research on the privacy aspects of machine learning has received less focus than the security aspects. Our contribution in this research is an analysis of more than 45 papers related to privacy attacks against machine learning that have been published during the past seven years. We propose an attack taxonomy, together with a threat model that allows the categorization of different attacks based on the adversarial knowledge, and the assets under attack. An initial exploration of the causes of privacy leaks is presented, as well as a detailed analysis of the different attacks. Finally, we present an overview of the most commonly proposed defenses and a discussion of the open problems and future directions identified during our analysis.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Mar\u00eda Rigaki et al.",
      "keywords": "Computer science; Adversarial machine learning; Adversarial system; Categorization; Computer security; Focus (optics); Open research; Internet privacy; Taxonomy (biology); Data science; Artificial intelligence; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3624010",
      "cited_by_count": 171,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3128981305",
      "doi": "10.1145/3448112",
      "title": "SelfHAR",
      "abstract": "Machine learning and deep learning have shown great promise in mobile sensing applications, including Human Activity Recognition. However, the performance of such models in real-world settings largely depends on the availability of large datasets that captures diverse behaviors. Recently, studies in computer vision and natural language processing have shown that leveraging massive amounts of unlabeled data enables performance on par with state-of-the-art supervised models. In this work, we present SelfHAR, a semi-supervised model that effectively learns to leverage unlabeled mobile sensing datasets to complement small labeled datasets. Our approach combines teacher-student self-training, which distills the knowledge of unlabeled and labeled datasets while allowing for data augmentation, and multi-task self-supervision, which learns robust signal-level representations by predicting distorted versions of the input. We evaluated SelfHAR on various HAR datasets and showed state-of-the-art performance over supervised and previous semi-supervised approaches, with up to 12% increase in F1 score using the same number of model parameters at inference. Furthermore, SelfHAR is data-efficient, reaching similar performance using up to 10 times less labeled data compared to supervised approaches. Our work not only achieves state-of-the-art performance in a diverse set of HAR datasets, but also sheds light on how pre-training tasks may affect downstream performance.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Chi Ian Tang et al.",
      "keywords": "Computer science; Leverage (statistics); Artificial intelligence; Labeled data; Machine learning; Inference; Complement (music); Task (project management); Semi-supervised learning; Set (abstract data type); Training set; Supervised learning; Pattern recognition (psychology); Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3448112",
      "cited_by_count": 119,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4224105048",
      "doi": "10.1145/3529225",
      "title": "The Placebo Effect of Artificial Intelligence in Human\u2013Computer Interaction",
      "abstract": "In medicine, patients can obtain real benefits from a sham treatment. These benefits are known as the placebo effect. We report two experiments (Experiment I: N = 369; Experiment II: N = 100) demonstrating a placebo effect in adaptive interfaces. Participants were asked to solve word puzzles while being supported by no system or an adaptive AI interface. All participants experienced the same word puzzle difficulty and had no support from an AI throughout the experiments. Our results showed that the belief of receiving adaptive AI support increases expectations regarding the participant\u2019s own task performance, sustained after interaction. These expectations were positively correlated to performance, as indicated by the number of solved word puzzles. We integrate our findings into technological acceptance theories and discuss implications for the future assessment of AI-based user interfaces and novel technologies. We argue that system descriptions can elicit placebo effects through user expectations biasing the results of user-centered studies.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Thomas Kosch et al.",
      "keywords": "Placebo; Task (project management); Computer science; Word (group theory); Artificial intelligence; Human\u2013computer interaction; Interface (matter); Psychology; Cognitive psychology; Machine learning; Medicine; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3529225",
      "cited_by_count": 103,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3161311103",
      "doi": "10.1145/3466132.3466134",
      "title": "Biases in AI Systems",
      "abstract": "This article provides an organization of various kinds of biases that can occur in the AI pipeline starting from dataset creation and problem formulation to data analysis and evaluation. It highlights the challenges associated with the design of bias-mitigation strategies, and it outlines some best practices suggested by researchers. Finally, a set of guidelines is presented that could aid ML developers in identifying potential sources of bias, as well as avoiding the introduction of unwanted biases. The work is meant to serve as an educational resource for ML developers in handling and addressing issues related to bias in AI systems.",
      "year": "2021",
      "journal": "Queue",
      "authors": "Ramya Srinivasan et al.",
      "keywords": "Computer science; Pipeline (software); Set (abstract data type); Resource (disambiguation); Data science; Work (physics); Risk analysis (engineering); Engineering; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3466132.3466134",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3207635698",
      "doi": "10.1145/3476059",
      "title": "Contestability For Content Moderation",
      "abstract": "Content moderation systems for social media have had numerous issues of bias, in terms of race, gender, and ability among many others. One proposal for addressing such issues in automated decision making is by designing for contestability, whereby users can shape and influence how decisions are made. In this study, we conduct a series of participatory design workshops with participants from communities that have experienced problems with social media content moderation in the past. Together with participants, we explore the idea of designing for contestability in content moderation and find that users' designs suggest three fruitful, practical avenues: adding representation, improving communication, and designing with compassion. We conclude with design recommendations drawn from participants' proposals, and reflect on the challenges that remain.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Kristen Vaccaro et al.",
      "keywords": "Moderation; Compassion; Citizen journalism; Psychology; Social media; Social psychology; Content (measure theory); Computer science; World Wide Web; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3476059",
      "cited_by_count": 64,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4313429401",
      "doi": "10.1145/3542921",
      "title": "What Did My AI Learn? How Data Scientists Make Sense of Model Behavior",
      "abstract": "Data scientists require rich mental models of how AI systems behave to effectively train, debug, and work with them. Despite the prevalence of AI analysis tools, there is no general theory describing how people make sense of what their models have learned. We frame this process as a form of sensemaking and derive a framework describing how data scientists develop mental models of AI behavior. To evaluate the framework, we show how existing AI analysis tools fit into this sensemaking process and use it to design AIFinnity , a system for analyzing image-and-text models. Lastly, we explored how data scientists use a tool developed with the framework through a think-aloud study with 10 data scientists tasked with using AIFinnity to pick an image captioning model. We found that AIFinnity \u2019s sensemaking workflow reflected participants\u2019 mental processes and enabled them to discover and validate diverse AI behaviors.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "\u00c1ngel Alexander Cabrera et al.",
      "keywords": "Sensemaking; Workflow; Closed captioning; Computer science; Debugging; Mental model; Process (computing); Data science; Think aloud protocol; Frame (networking); Human\u2013computer interaction; Artificial intelligence; Image (mathematics); Cognitive science; Psychology; Usability; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3542921",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2898701693",
      "doi": "10.1145/3274324",
      "title": "To Label or Not to Label",
      "abstract": "Social media sites use different labels to help users find and select news feeds. For example, Blue Feed, Red Feed, a news feed created by the Wall Street Journal, use stance labels to separate news articles with opposing political ideologies to help people explore diverse opinions. To combat the spread of fake news, Facebook has experimented with putting credibility labels on news articles to help readers decide whether the content is trustworthy. To systematically understand the effects of stance and credibility labels on online news selection and consumption, we conducted a controlled experiment to study how these labels influence the selection, perceived extremeness, and level of agreement of news articles. Results show that stance labels may intensify selective exposure - a tendency for people to look for agreeable opinions -- and make people more vulnerable to polarized opinions and fake news. We found, however, that the effect of credibility labels on reducing selective exposure and recognizing fake news is limited. Although originally designed to encourage exposure to opposite viewpoints, stance labels can make fake news articles look more trustworthy, and they may lower people's perception of the extremeness of fake news articles. Our results have important implications on the subtle effects of stance and credibility labels on online news consumption.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Mingkun Gao et al.",
      "keywords": "Credibility; Viewpoints; Trustworthiness; Fake news; Selection (genetic algorithm); Advertising; Source credibility; Internet privacy; Social media; Perception; Consumption (sociology); Psychology; News media; Political science; Computer science; Sociology; Business; World Wide Web; Art; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274324",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4288890098",
      "doi": "10.1145/3453538",
      "title": "Computing competencies for undergraduate data science curricula",
      "abstract": "In 2009, Turing award winner Jim Gray spoke of data science as a fourth paradigm of science (empirical, theoretical, computational and data-driven) arising from and capitalizing on the huge amount of data that is now available for investigation.The confluence of the availability of data and increasing sophisticated tools, processes, and algorithms for analysing and drawing knowledge and insight from data has impacted every area of scientific engagement.It has also opened up exciting new opportunities for interdisciplinary work across the many fields including (but certainly not limited to) computer science, mathematics, statistics, and information science from which it draws foundational knowledge.For computer science, the emergence of data science offers both tremendous opportunity and something of a conundrum, as once again the emergence of a new and closely related computing practice or field raises inevitable questions about whether and how it fits into current postsecondary computer science curricula.This document represents an effort by the ACM Education Board through the work of the Data Science Task Force to answer this question.It is an effort to put our own data science house in order.This document is not, however, an effort to claim ownership or even primacy in data science.To do so would be to negate the powerful interdisciplinarity that data science makes possible.It is our hope that this document will represent a productive step in a conversation that engages all relevant fields and disciplines.Toward this end, the ACM Education Board wishes to express our willingness and excitement about participating in future, more expansive and inclusive conversations regarding the promise and practice of data science.",
      "year": "2021",
      "journal": "ACM eBooks",
      "authors": "ACM Data Science Task Force",
      "keywords": "Curriculum; Mathematics education; Computer science; Engineering ethics; Data science; Psychology; Engineering; Pedagogy",
      "mesh_terms": "",
      "pub_types": "book",
      "url": "https://doi.org/10.1145/3453538",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386390750",
      "doi": "10.1145/3618105",
      "title": "A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation, and Research Challenges",
      "abstract": "Graph Neural Networks (GNNs) perform well in community detection and molecule classification. Counterfactual Explanations (CE) provide counter-examples to overcome the transparency limitations of black-box models. Due to the growing attention in graph learning, we focus on the concepts of CE for GNNs. We analysed the SoA to provide a taxonomy, a uniform notation, and the benchmarking datasets and evaluation metrics. We discuss fourteen methods, their evaluation protocols, twenty-two datasets, and nineteen metrics. We integrated the majority of methods into the GRETEL library to conduct an empirical evaluation to understand their strengths and pitfalls. We highlight open challenges and future work.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Mario Alfonso Prado-Romero et al.",
      "keywords": "Computer science; Benchmarking; Counterfactual thinking; Data science; Graph; Taxonomy (biology); Transparency (behavior); Notation; Machine learning; Artificial intelligence; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3618105",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4308101891",
      "doi": "10.1145/3563659",
      "title": "The Handbook on Socially Interactive Agents",
      "abstract": "International audience",
      "year": "2022",
      "journal": "ACM eBooks",
      "authors": "Birgit Lugrin et al.",
      "keywords": "Embodied cognition; Multimodality; Embodied agent; Bridging (networking); Human\u2013computer interaction; Space (punctuation); Cognitive science; Computer science; Psychology; Artificial intelligence; World Wide Web",
      "mesh_terms": "",
      "pub_types": "book",
      "url": "https://doi.org/10.1145/3563659",
      "cited_by_count": 51,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W1957379630",
      "doi": "10.1145/2746410",
      "title": "From Observational Studies to Causal Rule Mining",
      "abstract": "Randomised controlled trials (RCTs) are the most effective approach to causal discovery, but in many circumstances it is impossible to conduct RCTs. Therefore, observational studies based on passively observed data are widely accepted as an alternative to RCTs. However, in observational studies, prior knowledge is required to generate the hypotheses about the cause-effect relationships to be tested, and hence they can only be applied to problems with available domain knowledge and a handful of variables. In practice, many datasets are of high dimensionality, which leaves observational studies out of the opportunities for causal discovery from such a wealth of data sources. In another direction, many efficient data mining methods have been developed to identify associations among variables in large datasets. The problem is that causal relationships imply associations, but the reverse is not always true. However, we can see the synergy between the two paradigms here. Specifically, association rule mining can be used to deal with the high-dimensionality problem, whereas observational studies can be utilised to eliminate noncausal associations. In this article, we propose the concept of causal rules (CRs) and develop an algorithm for mining CRs in large datasets. We use the idea of retrospective cohort studies to detect CRs based on the results of association rule mining. Experiments with both synthetic and real-world datasets have demonstrated the effectiveness and efficiency of CR mining. In comparison with the commonly used causal discovery methods, the proposed approach generally is faster and has better or competitive performance in finding correct or sensible causes. It is also capable of finding a cause consisting of multiple variables\u2014a feature that other causal discovery methods do not possess.",
      "year": "2015",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Jiuyong Li et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/2746410",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387933547",
      "doi": "10.1145/3630107",
      "title": "Data Refusal from Below: A Framework for Understanding, Evaluating, and Envisioning Refusal as Design",
      "abstract": "Amidst calls for public accountability over large data-driven systems, feminist and indigenous scholars have developed refusal as a practice that challenges the authority of data collectors. However, because data affect so many aspects of daily life, it can be hard to see seemingly different refusal strategies as part of the same repertoire. Furthermore, conversations about refusal often happen from the standpoint of designers and policymakers rather than the people and communities most affected by data collection. In this article, we introduce a framework for data refusal from below \u2014writing from the standpoint of people who refuse, rather than the institutions that seek their compliance. Because refusers work to reshape socio-technical systems, we argue that refusal is an act of design and that design-based frameworks and methods can contribute to refusal. We characterize refusal strategies across four constituent facets common to all refusal, whatever strategies are used: autonomy , or how refusal accounts for individual and collective interests; time , or whether refusal reacts to past harm or proactively prevents future harm; power , or the extent to which refusal makes change possible; and cost , or whether or not refusal can reduce or redistribute penalties experienced by refusers. We illustrate each facet by drawing on cases of people and collectives that have refused data systems. Together, the four facets of our framework are designed to help scholars and activists describe, evaluate, and imagine new forms of refusal.",
      "year": "2023",
      "journal": "ACM Journal on Responsible Computing",
      "authors": "Jonathan Zong et al.",
      "keywords": "Harm; Autonomy; Repertoire; Accountability; Public relations; Indigenous; Power (physics); Sociology; Political science; Psychology; Social psychology; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3630107",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388827078",
      "doi": "10.1145/3632753",
      "title": "The Right to Transparency in Public Governance: Freedom of Information and the Use of Artificial Intelligence by Public Agencies",
      "abstract": "What information should and can be transparent for artificial intelligence (AI) algorithms? This article examines the socio-technical and legal perspectives of transparency in relation to algorithmic decision-making in public administration. We show how transparency in AI can be understood in light of the various technologies and the challenges one may encounter. Despite some first steps in that direction, there exists so far no mature standard for documenting AI models. From a legal perspective, this article examined the applicable freedom of information (FOI) regimes across different jurisdictions, with a particular focus on Denmark and other Scandinavian countries. Despite notable differences, our findings show that the FOI regimes generally only grant access to existing documents, and that access can be denied on the basis of the wide proprietary interests and internal documents exemptions. This is why we ultimately conclude that the European data-protection framework and the proposed EU AI Act \u2014 with their far-reaching duties to document the functioning of AI systems \u2014 provide promising new avenues for research and insights into transparency in AI.",
      "year": "2023",
      "journal": "Digital Government Research and Practice",
      "authors": "Henrik Palmer Olsen et al.",
      "keywords": "Transparency (behavior); Freedom of information; Corporate governance; Public information; Business; Political science; Public relations; Computer science; Computer security; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3632753",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365998993",
      "doi": "10.1145/3579481",
      "title": "Evaluating the Impact of Human Explanation Strategies on Human-AI Visual Decision-Making",
      "abstract": "Artificial intelligence (AI) is increasingly being deployed in high-stakes domains, such as disaster relief and radiology, to aid practitioners during the decision-making process. Explainable AI techniques have been developed and deployed to provide users insights into why the AI made certain predictions. However, recent research suggests that these techniques may confuse or mislead users. We conducted a series of two studies to uncover strategies that humans use to explain decisions and then understand how those explanation strategies impact visual decision-making. In our first study, we elicit explanations from humans when assessing and localizing damaged buildings after natural disasters from satellite imagery and identify four core explanation strategies that humans employed. We then follow up by studying the impact of these explanation strategies by framing the explanations from Study 1 as if they were generated by AI and showing them to a different set of decision-makers performing the same task. We provide initial insights on how causal explanation strategies improve humans' accuracy and calibrate humans' reliance on AI when the AI is incorrect. However, we also find that causal explanation strategies may lead to incorrect rationalizations when AI presents a correct assessment with incorrect localization. We explore the implications of our findings for the design of human-centered explainable AI and address directions for future work.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Katelyn Morrison et al.",
      "keywords": "Framing (construction); Computer science; Set (abstract data type); Artificial intelligence; Process (computing); Data science; Psychology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579481",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4308791796",
      "doi": "10.1145/3555101",
      "title": "Heterogeneity in Algorithm-Assisted Decision-Making: A Case Study in Child Abuse Hotline Screening",
      "abstract": "Algorithmic risk assessment tools are now commonplace in public sector domains such as criminal justice and human services. These tools are intended to aid decision makers in systematically using rich and complex data captured in administrative systems. In this study we investigate sources of heterogeneity in the alignment between worker decisions and algorithmic risk scores in the context of a real world child abuse hotline screening use case. Specifically, we focus on heterogeneity related to worker experience. We find that senior workers are far more likely to screen in referrals for investigation, even after we control for the observed algorithmic risk score and other case characteristics. We also observe that the decisions of less-experienced workers are more closely aligned with algorithmic risk scores than those of senior workers who had decision-making experience prior to the tool being introduced. While screening decisions vary across child race, we do not find evidence of racial differences in the relationship between worker experience and screening decisions. Our findings indicate that it is important for agencies and system designers to consider ways of preserving institutional knowledge when introducing algorithms into high employee turnover settings such as child welfare call screening.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Lingwei Cheng et al.",
      "keywords": "Hotline; Context (archaeology); Welfare; Criminal justice; Computer science; Psychology; Criminology; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555101",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4220892194",
      "doi": "10.1145/3494519",
      "title": "Industry\u2013Academia Research Collaboration and Knowledge Co-creation: Patterns and Anti-patterns",
      "abstract": "Increasing the impact of software engineering research in the software industry and the society at large has long been a concern of high priority for the software engineering community. The problem of two cultures, research conducted in a vacuum (disconnected from the real world), or misaligned time horizons are just some of the many complex challenges standing in the way of successful industry\u2013academia collaborations. This article reports on the experience of research collaboration and knowledge co-creation between industry and academia in software engineering as a way to bridge the research\u2013practice collaboration gap. Our experience spans 14 years of collaboration between researchers in software engineering and the European and Norwegian software and IT industry. Using the participant observation and interview methods, we have collected and afterwards analyzed an extensive record of qualitative data. Drawing upon the findings made and the experience gained, we provide a set of 14 patterns and 14 anti-patterns for industry\u2013academia collaborations, aimed to support other researchers and practitioners in establishing and running research collaboration projects in software engineering.",
      "year": "2022",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Dusica Marijan et al.",
      "keywords": "Software; Software Engineering Process Group; Social software engineering; Engineering management; Software development; Computer science; Bridge (graph theory); Knowledge management; Personal software process; Software engineering; Engineering; Software construction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3494519",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4365999202",
      "doi": "10.1145/3579520",
      "title": "Reviewing Interventions to Address Misinformation: The Need to Expand Our Vision Beyond an Individualistic Focus",
      "abstract": "Prior work has identified a variety of factors that drive the way people identify and respond to misinformation. Such factors include confirmation bias, perceived credibility of the information source, individual media literacy, social norms, and others. This paper reviews the interventions designed to address misinformation and examines how various underlying mechanisms of response to misinformation are operationalized and implemented in the reviewed interventions. Key findings show that most prior work to address misinformation heavily focuses on individual pieces of misinformation and the actions individuals take in response to those individual pieces. These individualistic approaches, we argue, overlook the other drivers of responses to misinformation, such as individuals' prior beliefs and the social contexts in which misinformation is encountered. Additionally, the analysis shows that an individualistic focus on misinformation draws attention away from the systemic nature and consequences of misinformation. This paper argues that to overcome the limitation of individualistic approaches to addressing misinformation, future interventions need to expand their scope beyond individualistic approaches. As one way to do so, it discusses leveraging the impacts of community factors that impact the spread and impacts of misinformation. The paper concludes by using social norms as an example to illustrate how a focus on community factors might work in practice.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Zhila Aghajari et al.",
      "keywords": "Misinformation; Psychological intervention; Credibility; Operationalization; Individualism; Psychology; Social psychology; Social media; Perception; Public relations; Internet privacy; Political science; Computer science; Epistemology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579520",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3182589790",
      "doi": "10.1145/3463929",
      "title": "Adapting Ethical Sensitivity as a Construct to Study Technology Design Teams",
      "abstract": "The design of new technologies is a cooperative task (between designers on teams, and between designers and users) with ethical import. Studying technology development teams' engagement with the ethical aspects of their work is important, but engagement with ethical issues is an unobservable construct without agreement on what observable factors comprise it. Ethical sensitivity (ES), a construct studied in medicine, accounting, and other professions, offers a framework of observable factors by operationalizing ethical engagement in workplaces into component parts. However, ES has primarily been studied as a property of individuals rather than groups and in professions outside of computing. This paper uses a corpus of 108 ES studies from 1985-2020 to adapt the framework for studies of technology design teams. From the ES corpus, we build an umbrella framework that conceptualizes ES as comprising the moment of noticing an ethical problem (recognition), the process of building understanding of the situation (particularization), and the decision about what to do (judgment). This framework makes theoretical and methodological contributions to the study of how ethics are operationalized on design teams. We find that ethical sensitivity provides useful language for studies of collaboration and communication around ethics; suggests opportunities for, and evaluations of, ethical interventions for design workplaces; and connects team members' backgrounds, educational experiences, work practices, and organizational factors to design decisions. Simultaneously, existing research in HCI and CSCW addresses the limited range of research methods currently employed in the ES literature, adding rich, contextualized data about situated and embodied ethical practice to the theory.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Karen Boyd et al.",
      "keywords": "Operationalization; Construct (python library); Engineering ethics; Knowledge management; Situated; Psychology; Management science; Sociology; Computer science; Engineering; Epistemology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3463929",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387735167",
      "doi": "10.1145/3628602",
      "title": "Measuring and Mitigating Gender Bias in Legal Contextualized Language Models",
      "abstract": "Transformer-based contextualized language models constitute the state-of-the-art in several natural language processing (NLP) tasks and applications. Despite their utility, contextualized models can contain human-like social biases, as their training corpora generally consist of human-generated text. Evaluating and removing social biases in NLP models has been a major research endeavor. In parallel, NLP approaches in the legal domain, namely, legal NLP or computational law, have also been increasing. Eliminating unwanted bias in legal NLP is crucial, since the law has the utmost importance and effect on people. In this work, we focus on the gender bias encoded in BERT-based models. We propose a new template-based bias measurement method with a new bias evaluation corpus using crime words from the FBI database. This method quantifies the gender bias present in BERT-based models for legal applications. Furthermore, we propose a new fine-tuning-based debiasing method using the European Court of Human Rights (ECtHR) corpus to debias legal pre-trained models. We test the debiased models\u2019 language understanding performance on the LexGLUE benchmark to confirm that the underlying semantic vector space is not perturbed during the debiasing process. Finally, we propose a bias penalty for the performance scores to emphasize the effect of gender bias on model performance.",
      "year": "2023",
      "journal": "ACM Transactions on Knowledge Discovery from Data",
      "authors": "Mustafa Bozdag et al.",
      "keywords": "Debiasing; Computer science; Artificial intelligence; Natural language processing; Machine learning; Gender bias; Language model; Psychology; Cognitive science; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3628602",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3203862194",
      "doi": "10.1145/3492858",
      "title": "Explanation Strategies as an Empirical-Analytical Lens for Socio-Technical Contextualization of Machine Learning Interpretability",
      "abstract": "During a research project in which we developed a machine learning (ML) driven visualization system for non-ML experts, we reflected on interpretability research in ML, computer-supported collaborative work and human-computer interaction. We found that while there are manifold technical approaches, these often focus on ML experts and are evaluated in decontextualized empirical studies. We hypothesized that participatory design research may support the understanding of stakeholders' situated sense-making in our project, yet, found guidance regarding ML interpretability inexhaustive. Building on philosophy of technology, we formulated explanation strategies as an empirical-analytical lens explicating how technical explanations mediate the contextual preferences concerning people's interpretations. In this paper, we contribute a report of our proof-of-concept use of explanation strategies to analyze a co-design workshop with non-ML experts, methodological implications for participatory design research, design implications for explanations for non-ML experts and suggest further investigation of technological mediation theories in the ML interpretability space.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Jesse Josua Benjamin et al.",
      "keywords": "Interpretability; Contextualization; Through-the-lens metering; Mediation; Computer science; Empirical research; Knowledge management; Citizen journalism; Situated; Management science; Visualization; Artificial intelligence; Data science; Sociology; Epistemology; Lens (geology); Engineering; Interpretation (philosophy); Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3492858",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4404399830",
      "doi": "10.1145/3662731",
      "title": "AI Must Be Anti-Ableist and Accessible",
      "abstract": "Seeking to improve AI accessibility by changing how AI-based systems are built.",
      "year": "2024",
      "journal": "Communications of the ACM",
      "authors": "Jennifer Mankoff et al.",
      "keywords": "Computer science; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3662731",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3180717668",
      "doi": "10.1145/3476089",
      "title": "A Framework of High-Stakes Algorithmic Decision-Making for the Public Sector Developed through a Case Study of Child-Welfare",
      "abstract": "Algorithms have permeated throughout civil government and society, where they are being used to make high-stakes decisions about human lives. In this paper, we first develop a cohesive framework of algorithmic decision-making adapted for the public sector (ADMAPS) that reflects the complex socio-technical interactions between human discretion, bureaucratic processes, and algorithmic decision-making by synthesizing disparate bodies of work in the fields of Human-Computer Interaction (HCI), Science and Technology Studies (STS), and Public Administration (PA). We then applied the ADMAPS framework to conduct a qualitative analysis of an in-depth, eight-month ethnographic case study of algorithms in daily use within a child-welfare agency that serves approximately 900 families and 1300 children in the mid-western United States. Overall, we found that there is a need to focus on strength-based algorithmic outcomes centered in social ecological frameworks. In addition, algorithmic systems need to support existing bureaucratic processes and augment human discretion, rather than replace it. Finally, collective buy-in in algorithmic systems requires trust in the target outcomes at both the practitioner and bureaucratic levels. As a result of our study, we propose guidelines for the design of high-stakes algorithmic decision-making tools in the child-welfare system, and more generally, in the public sector. We empirically validate the theoretically derived ADMAPS framework to demonstrate how it can be useful for systematically making pragmatic decisions about the design of algorithms for the public sector.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Devansh Saxena et al.",
      "keywords": "Bureaucracy; Discretion; Agency (philosophy); Government (linguistics); Public sector; Welfare; Human welfare; Preference; Computer science; Work (physics); Ethnography; Management science; Political science; Public relations; Sociology; Public administration; Economics; Engineering; Law; Social science; Microeconomics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3476089",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393213377",
      "doi": "10.1145/3637366",
      "title": "Linguistically Differentiating Acts and Recalls of Racial Microaggressions on Social Media",
      "abstract": "In this work, we examine the linguistic signature of online racial microaggressions (acts) and how it differs from that of personal narratives recalling experiences of such aggressions (recalls) by Black social media users. We manually curate and annotate a corpus of acts and recalls fromin-the-wild social media discussions, and verify labels with Black workshop participants. We leverage Natural Language Processing (NLP) and qualitative analysis on this data to classify (RQ1), interpret (RQ2), and characterize (RQ3) the language underlying acts and recalls of racial microaggressions in the context of racism in the U.S. Our findings show that neural language models (LMs) can classify acts and recalls with high accuracy (RQ1) with contextual words revealing themes that associate Blacks with objects that reify negative stereotypes (RQ2). Furthermore, overlapping linguistic signatures between acts and recalls serve functionally different purposes (RQ3), providing broader implications to the current challenges in content moderation systems on social media.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Uma Sushmitha Gunturi et al.",
      "keywords": "Social media; Narrative; Psychology; Racism; Moderation; Social psychology; Linguistics; Sociology; Computer science; Gender studies; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3637366",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3134199894",
      "doi": "10.1145/3448117",
      "title": "Person-Centered Predictions of Psychological Constructs with Social Media Contextualized by Multimodal Sensing",
      "abstract": "Personalized predictions have shown promises in various disciplines but they are fundamentally constrained in their ability to generalize across individuals. These models are often trained on limited datasets which do not represent the fluidity of human functioning. In contrast, generalized models capture normative behaviors between individuals but lack precision in predicting individual outcomes. This paper aims to balance the tradeoff between one-for-each and one-for-all models by clustering individuals on mutable behaviors and conducting cluster-specific predictions of psychological constructs in a multimodal sensing dataset of 754 individuals. Specifically, we situate our modeling on social media that has exhibited capability in inferring psychosocial attributes. We hypothesize that complementing social media data with offline sensor data can help to personalize and improve predictions. We cluster individuals on physical behaviors captured via Bluetooth, wearables, and smartphone sensors. We build contextualized models predicting psychological constructs trained on each cluster's social media data and compare their performance against generalized models trained on all individuals' data. The comparison reveals no difference in predicting affect and a decline in predicting cognitive ability, but an improvement in predicting personality, anxiety, and sleep quality. We construe that our approach improves predicting psychological constructs sharing theoretical associations with physical behavior. We also find how social media language associates with offline behavioral contextualization. Our work bears implications in understanding the nuanced strengths and weaknesses of personalized predictions, and how the effectiveness may vary by multiple factors. This work reveals the importance of taking a critical stance on evaluating the effectiveness before investing efforts in personalization.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Koustuv Saha et al.",
      "keywords": "Social media; Psychology; Cognitive psychology; Cluster analysis; Computer science; Normative; Psychosocial; Big Five personality traits; Personality; Data science; Artificial intelligence; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3448117",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2807850020",
      "doi": "10.1145/3158226",
      "title": "Evaluation and Refinement of Clustered Search Results with the Crowd",
      "abstract": "When searching on the web or in an app, results are often returned as lists of hundreds to thousands of items, making it difficult for users to understand or navigate the space of results. Research has demonstrated that using clustering to partition search results into coherent, topical clusters can aid in both exploration and discovery. Yet clusters generated by an algorithm for this purpose are often of poor quality and do not satisfy users. To achieve acceptable clustered search results, experts must manually evaluate and refine the clustered results for each search query, a process that does not scale to large numbers of search queries. In this article, we investigate using crowd-based human evaluation to inspect, evaluate, and improve clusters to create high-quality clustered search results at scale. We introduce a workflow that begins by using a collection of well-known clustering algorithms to produce a set of clustered search results for a given query. Then, we use crowd workers to holistically assess the quality of each clustered search result to find the best one. Finally, the workflow has the crowd spot and fix problems in the best result to produce a final output. We evaluate this workflow on 120 top search queries from the Google Play Store, some of whom have clustered search results as a result of evaluations and refinements by experts. Our evaluations demonstrate that the workflow is effective at reproducing the evaluation of expert judges and also improves clusters in a way that agrees with experts and crowds alike.",
      "year": "2018",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "Amy X. Zhang et al.",
      "keywords": "Computer science; Workflow; Cluster analysis; Information retrieval; Set (abstract data type); Data mining; Web search query; Quality (philosophy); Process (computing); Partition (number theory); Search engine; Machine learning; Database; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3158226",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4308791600",
      "doi": "10.1145/3555185",
      "title": "Do as I say, not as I do: Therapist Evaluation of a Practice and Supervision Aid",
      "abstract": "Interactive software offers the potential to improve the quality of mental health care by promoting skill development, clinical insight, and shared reflection among mental health professionals. However, research on therapists' usage of interactive software has been primarily based in training and mock-clinical settings. In this paper, we present a qualitative study of clinicians' experience using CORE-MI, a collaborative recording and annotation software, in a real-world university counseling center. We describe how and why therapists, both trainees and licensed staff, used CORE-MI to support their practice and improve their skills. We also consider how usage varied with therapists' developmental level and how the software impacted relationships between supervisors and supervisees. Finally, we offer recommendations for future research and design of interactive systems in mental health settings.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Patty Kuo et al.",
      "keywords": "Mental health; Medical education; Psychology; Quality (philosophy); Reflection (computer programming); Qualitative research; Clinical supervision; Medicine; Computer science; Psychotherapist",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555185",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387087040",
      "doi": "10.1145/3610915",
      "title": "Society's Attitudes Towards Human Augmentation and Performance Enhancement Technologies (SHAPE) Scale",
      "abstract": "Human augmentation technologies (ATs) are a subset of ubiquitous on-body devices designed to improve cognitive, sensory, and motor capacities. Although there is a large corpus of knowledge concerning ATs, less is known about societal attitudes towards them and how they shift over time. To that end, we developed The Society's Attitudes Towards Human Augmentation and Performance Enhancement Technologies (SHAPE) Scale, which measures how users of ATs are perceived. To develop the scale, we first created a list of possible scale items based on past work on how people respond to new technologies. The items were then reviewed by experts. Next, we performed exploratory factor analysis to reduce the scale to its final length of thirteen items. Subsequently, we confirmed test-retest validity of our instrument, as well as its construct validity. The SHAPE scale enables researchers and practitioners to understand elements contributing to attitudes toward augmentation technology users. The SHAPE scale assists designers of ATs in designing artifacts that will be more universally accepted.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Steeven Villa et al.",
      "keywords": "Scale (ratio); Construct (python library); Exploratory factor analysis; Cognition; Psychology; Construct validity; Computer science; Data science; Applied psychology; Psychometrics; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610915",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392519673",
      "doi": "10.1145/3643516",
      "title": "IOTeeth",
      "abstract": "While occlusal diseases - the main cause of tooth loss -- significantly impact patients' teeth and well-being, they are the most underdiagnosed dental diseases nowadays. Experiencing occlusal diseases could result in difficulties in eating, speaking, and chronicle headaches, ultimately impacting patients' quality of life. Although attempts have been made to develop sensing systems for teeth activity monitoring, solutions that support sufficient sensing resolution for occlusal monitoring are missing. To fill that gap, this paper presents IOTeeth, a cost-effective and automated intra-oral sensing system for continuous and fine-grained monitoring of occlusal diseases. The IOTeeth system includes an intra-oral piezoelectric-based sensing array integrated into a dental retainer platform to support reliable occlusal disease recognition. IOTeeth focuses on biting and grinding activities from the canines and front teeth, which contain essential information of occlusion. IOTeeth's intra-oral wearable collects signals from the sensors and fetches them into a lightweight and robust deep learning model called Physioaware Attention Network (PAN Net) for occlusal disease recognition. We evaluate IOTeeth with 12 articulator teeth models from dental clinic patients. Evaluation results show an F1 score of 0.97 for activity recognition with leave-one-out validation and an average F1 score of 0.92 for dental disease recognition for different activities with leave-one-out validation.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Zhizhang Hu et al.",
      "keywords": "Articulator; Occlusion; Computer science; Orthodontics; Medicine; Dentistry; Wearable computer; Dental occlusion",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643516",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366003111",
      "doi": "10.1145/3579540",
      "title": "Understanding Postpartum Parents' Experiences via Two Digital Platforms",
      "abstract": "Digital platforms, including online forums and helplines, have emerged as avenues of support for caregivers suffering from postpartum mental health distress. Understanding support seekers' experiences as shared on these platforms could provide crucial insight into caregivers' needs during this vulnerable time. In the current work, we provide a descriptive analysis of the concerns, psychological states, and motivations shared by healthy and distressed postpartum support seekers on two digital platforms, a one-on-one digital helpline and a publicly available online forum. Using a combination of human annotations, dictionary models and unsupervised techniques, we find stark differences between the experiences of distressed and healthy mothers. Distressed mothers described interpersonal problems and a lack of support, with 8.60% - 14.56% reporting severe symptoms including suicidal ideation. In contrast, the majority of healthy mothers described childcare issues, such as questions about breastfeeding or sleeping, and reported no severe mental health concerns. Across the two digital platforms, we found that distressed mothers shared similar content. However, the patterns of speech and affect shared by distressed mothers differed between the helpline vs. the online forum, suggesting the design of these platforms may shape meaningful measures of their support-seeking experiences. Our results provide new insight into the experiences of caregivers suffering from postpartum mental health distress. We conclude by discussing methodological considerations for understanding content shared by support seekers and design considerations for the next generation of support tools for postpartum parents.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Xuewen Yao et al.",
      "keywords": "Mental health; Helpline; Psychology; Distress; Breastfeeding; Interpersonal communication; Clinical psychology; Medicine; Social psychology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579540",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391879340",
      "doi": "10.1145/3648614",
      "title": "Mitigating Epistemic Injustice: The Online Construction of a Bisexual Culture",
      "abstract": "People participating in online groups often co-construct knowledge of what they believe and, sometimes, co-construct their understanding of who they are . Through participant observation and semi-structured interviews with 13 members of the online forum r/bisexual on Reddit, we found participants collaboratively constructing an understanding of bisexuality. We found that this knowledge-building fills an epistemic gap resulting from bisexuality often being poorly understood. When individuals do not possess knowledge key to understanding their own lives, this can be seen as hermeneutical injustice \u2014a type of epistemic injustice. We use the lens of hermeneutical injustice to shed light on participants\u2019 experiences on r/bisexual. Our work contributes to recent research on epistemic injustice in HCI by looking at how members of r/bisexual mitigate epistemic injustice by reclaiming residuality\u2014the space outside the gay-straight binary. We also discuss considerations for hermeneutical injustice to inform the design of online communities and HCI research practice.",
      "year": "2024",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Jordan Taylor et al.",
      "keywords": "Injustice; Construct (python library); Epistemology; Sociology; Space (punctuation); Psychology; Social psychology; Philosophy; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3648614",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393157942",
      "doi": "10.1145/3641858",
      "title": "Resolving the Human-Subjects Status of ML's Crowdworkers",
      "abstract": "What ethical framework should govern the interaction of ML researchers and crowdworkers?",
      "year": "2024",
      "journal": "Communications of the ACM",
      "authors": "Divyansh Kaushik et al.",
      "keywords": "Computer science; Human\u2013computer interaction; World Wide Web; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3641858",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389196097",
      "doi": "10.1145/3635033",
      "title": "Bridging Performance of X (formerly known as Twitter) Users: A Predictor of Subjective Well-Being During the Pandemic",
      "abstract": "The outbreak of the COVID-19 pandemic triggered the perils of misinformation over social media. By amplifying the spreading speed and popularity of trustworthy information, influential social media users have been helping overcome the negative impacts of such flooding misinformation. In this article, we use the COVID-19 pandemic as a representative global health crisisand examine the impact of the COVID-19 pandemic on these influential users\u2019 subjective well-being (SWB), one of the most important indicators of mental health. We leverage X (formerly known as Twitter) as a representative social media platform and conduct the analysis with our collection of 37,281,824 tweets spanning almost two years. To identify influential X users, we propose a new measurement called user bridging performance (UBM) to evaluate the speed and wideness gain of information transmission due to their sharing. With our tweet collection, we manage to reveal the more significant mental sufferings of influential users during the COVID-19 pandemic. According to this observation, through comprehensive hierarchical multiple regression analysis , we are the first to discover the strong relationship between individual social users\u2019 subjective well-being and their bridging performance. We proceed to extend bridging performance from individuals to user subgroups. The new measurement allows us to conduct a subgroup analysis according to users\u2019 multilingualism and confirm the bridging role of multilingual users in the COVID-19 information propagation. We also find that multilingual users not only suffer from a much lower SWB in the pandemic, but also experienced a more significant SWB drop.",
      "year": "2023",
      "journal": "ACM Transactions on the Web",
      "authors": "Ninghan Chen et al.",
      "keywords": "Bridging (networking); Pandemic; Computer science; Coronavirus disease 2019 (COVID-19); World Wide Web; Computer security; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3635033",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3164551806",
      "doi": "10.1145/3462221",
      "title": "On sharing knowledge and fostering \"open science\"",
      "abstract": "The crucial importance of science and technology and its accurate peer reviewed dissemination, has once again been demonstrated during the current pandemic. Thus the COVID-19 pandemic together with the inevitable energy transition required by climate change, lead us to consider the issue of scientific and technical communication, both for the written papers and proceedings that have largely moved online (but not always in open access), and the various types of seminars, workshops, and symposia that frequently involve air travel with substantial CO2 impact. Online meetings that have become recently very popular, as well as online repositories for publications, themselves have a significant CO2---as well as environmental---impact, due to the massive use of electricity by information and communication technologies (ICT) and of the environmentally unfriendly manufacturing processes and decommissioning of ICT equipment. Presented is a broad overview of these aspects, and some recommendations regarding the future organization of scientific and technical communication, including: (1) peer-reviewed journals and proceedings with online open access; (2) the importance of face to face seminars and symposia, together with online meetings, to maintain the serendipity and importance of direct human contact while reducing the need for air travel; (3) the peer evaluation of research and of academic and research staff and its dependence on publications and their qualitative---rather than excessively quantitative---evaluation, where the concept of impact should include the usefulness of research to education, industry and society; (4) and the crucial role of ICT in all these aspects and the questions raised by the sustainability of ICT itself.",
      "year": "2021",
      "journal": "Ubiquity",
      "authors": "Erol Gelenbe et al.",
      "keywords": "Information and Communications Technology; Sustainability; Open science; Nuclear decommissioning; Sociotechnical system; Knowledge management; Computer science; Public relations; Business; Engineering ethics; Political science; Engineering; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3462221",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413968508",
      "doi": "10.1145/3749474",
      "title": "GLOSS: Group of LLMs for Open-ended Sensemaking of Passive Sensing Data for Health and Wellbeing",
      "abstract": "The ubiquitous presence of smartphones and wearables has enabled researchers to build prediction and detection models for various health and behavior outcomes using passive sensing data from these devices. Achieving a high-level, holistic understanding of an individual's behavior and context, however, remains a significant challenge. Due to the nature of the passive sensing data, sensemaking --- the process of interpreting and extracting insights - requires both domain knowledge and technical expertise, creating barriers for different stakeholders. Existing systems designed to support sensemaking are not open-ended or cannot perform complex data triangulation. In this paper, we present a novel sensemaking system, Group of LLMs for Open-ended Sensemaking (GLOSS), for open-ended sensemaking capable of performing complex multimodal triangulation to derive insights. We demonstrate that GLOSS significantly outperforms commonly used Retrieval-Augmented Generation (RAG) technique, achieving 87.93% accuracy and 66.19% consistency compared to RAG's 29.31% accuracy and 52.85% consistency. Furthermore, we showcase the promise of GLOSS using four use cases inspired by prior and ongoing work in UbiComp and HCI communities. Finally, we discuss the potential of GLOSS, the broader implications, and the limitations of our work.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Akshat Choube et al.",
      "keywords": "Gloss (optics); Sensemaking; Psychology; Group (periodic table); Computer science; Knowledge management; Materials science; Nanotechnology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749474",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4321786089",
      "doi": "10.1145/3583558",
      "title": "From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI",
      "abstract": "The rising popularity of explainable artificial intelligence (XAI) to understand high-performing black boxes raised the question of how to evaluate explanations of machine learning (ML) models. While interpretability and explainability are often presented as a subjectively validated binary property, we consider it a multi-faceted concept. We identify 12 conceptual properties, such as Compactness and Correctness, that should be evaluated for comprehensively assessing the quality of an explanation. Our so-called Co-12 properties serve as categorization scheme for systematically reviewing the evaluation practices of more than 300 papers published in the past 7 years at major AI and ML conferences that introduce an XAI method. We find that one in three papers evaluate exclusively with anecdotal evidence, and one in five papers evaluate with users. This survey also contributes to the call for objective, quantifiable evaluation methods by presenting an extensive overview of quantitative XAI evaluation methods. Our systematic collection of evaluation methods provides researchers and practitioners with concrete tools to thoroughly validate, benchmark, and compare new and existing XAI methods. The Co-12 categorization scheme and our identified evaluation methods open up opportunities to include quantitative metrics as optimization criteria during model training to optimize for accuracy and interpretability simultaneously.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Meike Nauta et al.",
      "keywords": "Computer science; Interpretability; Popularity; Categorization; Benchmark (surveying); Correctness; Artificial intelligence; Systematic review; Quality (philosophy); Scheme (mathematics); Machine learning; Data science; Information retrieval",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3583558",
      "cited_by_count": 401,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2794079986",
      "doi": "10.1145/3185517",
      "title": "A Review of User Interface Design for Interactive Machine Learning",
      "abstract": "Interactive Machine Learning (IML) seeks to complement human perception and intelligence by tightly integrating these strengths with the computational power and speed of computers. The interactive process is designed to involve input from the user but does not require the background knowledge or experience that might be necessary to work with more traditional machine learning techniques. Under the IML process, non-experts can apply their domain knowledge and insight over otherwise unwieldy datasets to find patterns of interest or develop complex data-driven applications. This process is co-adaptive in nature and relies on careful management of the interaction between human and machine. User interface design is fundamental to the success of this approach, yet there is a lack of consolidated principles on how such an interface should be implemented. This article presents a detailed review and characterisation of Interactive Machine Learning from an interactive systems perspective. We propose and describe a structural and behavioural model of a generalised IML system and identify solution principles for building effective interfaces for IML. Where possible, these emergent solution principles are contextualised by reference to the broader human-computer interaction literature. Finally, we identify strands of user interface research key to unlocking more efficient and productive non-expert interactive machine learning applications.",
      "year": "2018",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "John J. Dudley et al.",
      "keywords": "Computer science; Human\u2013computer interaction; Process (computing); Interface (matter); Complement (music); User interface; Domain (mathematical analysis); Artificial intelligence; Machine learning; Perspective (graphical); Interactive Learning; Multimedia",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3185517",
      "cited_by_count": 316,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4292092796",
      "doi": "10.1145/3556536",
      "title": "Evaluating Recommender Systems: Survey and Framework",
      "abstract": "The comprehensive evaluation of the performance of a recommender system is a complex endeavor: many facets need to be considered in configuring an adequate and effective evaluation setting. Such facets include, for instance, defining the specific goals of the evaluation, choosing an evaluation method, underlying data, and suitable evaluation metrics. In this article, we consolidate and systematically organize this dispersed knowledge on recommender systems evaluation. We introduce the Framework for Evaluating Recommender systems (FEVR), which we derive from the discourse on recommender systems evaluation. In FEVR, we categorize the evaluation space of recommender systems evaluation. We postulate that the comprehensive evaluation of a recommender system frequently requires considering multiple facets and perspectives in the evaluation. The FEVR framework provides a structured foundation to adopt adequate evaluation configurations that encompass this required multi-facetedness and provides the basis to advance in the field. We outline and discuss the challenges of a comprehensive evaluation of recommender systems and provide an outlook on what we need to embrace and do to move forward as a research community.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Eva Zangerle et al.",
      "keywords": "Recommender system; Computer science; Categorization; Field (mathematics); Foundation (evidence); Space (punctuation); Data science; Information retrieval; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3556536",
      "cited_by_count": 219,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3165722314",
      "doi": "10.1145/3453444",
      "title": "Assuring the Machine Learning Lifecycle",
      "abstract": "Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic, and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence, and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our article provides a comprehensive survey of the state of the art in the assurance of ML , i.e., in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle , i.e., of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The article begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.",
      "year": "2021",
      "journal": "ACM Computing Surveys",
      "authors": "Rob Ashmore et al.",
      "keywords": "Computer science; Software deployment; Process (computing); System lifecycle; Component (thermodynamics); Risk analysis (engineering); Process management; Presentation (obstetrics); Systems engineering; Engineering management; Artificial intelligence; Software engineering; Application lifecycle management; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3453444",
      "cited_by_count": 195,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2982915530",
      "doi": "10.1145/3359283",
      "title": "WeBuildAI",
      "abstract": "Algorithms increasingly govern societal functions, impacting multiple stakeholders and social groups. How can we design these algorithms to balance varying interests in a moral, legitimate way? As one answer to this question, we present WeBuildAI, a collective participatory framework that enables people to build algorithmic policy for their communities. The key idea of the framework is to enable stakeholders to construct a computational model that represents their views and to have those models vote on their behalf to create algorithmic policy. As a case study, we applied this framework to a matching algorithm that operates an on-demand food donation transportation service in order to adjudicate equity and efficiency trade-offs. The service's stakeholders--donors, volunteers, recipient organizations, and nonprofit employees--used the framework to design the algorithm through a series of studies in which we researched their experiences. Our findings suggest that the framework successfully enabled participants to build models that they felt confident represented their own beliefs. Participatory algorithm design also improved both procedural fairness and the distributive outcomes of the algorithm, raised participants' algorithmic awareness, and helped identify inconsistencies in human decision-making in the governing organization. Our work demonstrates the feasibility, potential and challenges of community involvement in algorithm design.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Min Kyung Lee et al.",
      "keywords": "Computer science; Equity (law); Construct (python library); Participatory design; Citizen journalism; Knowledge management; Matching (statistics); Key (lock); Political science; Economics; World Wide Web; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359283",
      "cited_by_count": 175,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226290207",
      "doi": "10.1145/3527848",
      "title": "A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations",
      "abstract": "Machine learning is increasingly used to inform decision making in sensitive situations where decisions have consequential effects on individuals\u2019 lives. In these settings, in addition to requiring models to be accurate and robust, socially relevant values such as fairness, privacy, accountability, and explainability play an important role in the adoption and impact of said technologies. In this work, we focus on algorithmic recourse , which is concerned with providing explanations and recommendations to individuals who are unfavorably treated by automated decision-making systems. We first perform an extensive literature review, and align the efforts of many authors by presenting unified definitions, formulations, and solutions to recourse. Then, we provide an overview of the prospective research directions toward which the community may engage, challenging existing assumptions and making explicit connections to other ethical challenges such as security, privacy, and fairness.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Amir-Hossein Karimi et al.",
      "keywords": "Computer science; Accountability; Focus (optics); Work (physics); Management science; Data science; Risk analysis (engineering); Political science; Law",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3527848",
      "cited_by_count": 120,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2983996708",
      "doi": "10.1145/3359284",
      "title": "Procedural Justice in Algorithmic Fairness",
      "abstract": "As algorithms increasingly take managerial and governance roles, it is ever more important to build them to be perceived as fair and adopted by people. With this goal, we propose a procedural justice framework in algorithmic decision-making drawing from procedural justice theory, which lays out elements that promote a sense of fairness among users. As a case study, we built an interface that leveraged two key elements of the framework---transparency and outcome control---and evaluated it in the context of goods division. Our interface explained the algorithm's allocative fairness properties (standards clarity) and outcomes through an input-output matrix (outcome explanation), then allowed people to interactively adjust the algorithmic allocations as a group (outcome control). The findings from our within-subjects laboratory study suggest that standards clarity alone did not increase perceived fairness; outcome explanation had mixed effects, increasing or decreasing perceived fairness and reducing algorithmic accountability; and outcome control universally improved perceived fairness by allowing people to realize the inherent limitations of decisions and redistribute the goods to better fit their contexts, and by bringing human elements into final decision-making.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Min Kyung Lee et al.",
      "keywords": "CLARITY; Outcome (game theory); Allocative efficiency; Accountability; Transparency (behavior); Procedural justice; Context (archaeology); Economic Justice; Control (management); Computer science; Fairness measure; Corporate governance; Social psychology; Psychology; Microeconomics; Economics; Political science; Artificial intelligence; Computer security; Management; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359284",
      "cited_by_count": 198,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388631551",
      "doi": "10.1145/3632297",
      "title": "Building Human Values into Recommender Systems: An Interdisciplinary Synthesis",
      "abstract": "Recommender systems are the algorithms which select, filter, and personalize content across many of the world's largest platforms and apps. As such, their positive and negative effects on individuals and on societies have been extensively theorized and studied. Our overarching question is how to ensure that recommender systems enact the values of the individuals and societies that they serve. Addressing this question in a principled fashion requires technical knowledge of recommender design and operation, and also critically depends on insights from diverse fields including social science, ethics, economics, psychology, policy, and law. This article is a multidisciplinary effort to synthesize theory and practice from different perspectives, with the goal of providing a shared language, articulating current design approaches, and identifying open problems. We collect a set of values that seem most relevant to recommender systems operating across different domains, and then examine them from the perspectives of current industry practice, measurement, product design, and policy approaches. Important open problems include multi-stakeholder processes for defining values and resolving trade-offs, better values-driven measurements, recommender controls that people use, non-behavioral algorithmic feedback, optimization for long-term outcomes, causal inference of recommender effects, academic-industry research collaborations, and interdisciplinary policy-making.",
      "year": "2023",
      "journal": "ACM Transactions on Recommender Systems",
      "authors": "Jonathan Stray et al.",
      "keywords": "Recommender system; Computer science; Data science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3632297",
      "cited_by_count": 70,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309619003",
      "doi": "10.1145/3555561",
      "title": "The Data-Production Dispositif",
      "abstract": "Machine learning (ML) depends on data to train and verify models. Very often, organizations outsource processes related to data work (i.e., generating and annotating data and evaluating outputs) through business process outsourcing (BPO) companies and crowdsourcing platforms. This paper investigates outsourced ML data work in Latin America by studying three platforms in Venezuela and a BPO in Argentina. We lean on the Foucauldian notion of dispositif to define the data-production dispositif as an ensemble of discourses, actions, and objects strategically disposed to (re)produce power/knowledge relations in data and labor. Our dispositif analysis comprises the examination of 210 data work instruction documents, 55 interviews with data workers, managers, and requesters, and participant observation. Our findings show that discourses encoded in instructions reproduce and normalize the worldviews of requesters. Precarious working conditions and economic dependency alienate workers, making them obedient to instructions. Furthermore, discourses and social contexts materialize in artifacts, such as interfaces and performance metrics, limiting workers' agency and normalizing specific ways of interpreting data. We conclude by stressing the importance of counteracting the data-production dispositif by fighting alienation and precarization, and empowering data workers to become assets in the quest for high-quality data.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Milagros Miceli et al.",
      "keywords": "Outsourcing; Crowdsourcing; Agency (philosophy); Production (economics); Work (physics); Alienation; Power (physics); Raw data; Quality (philosophy); Data quality; Computer science; Knowledge management; Business; Data science; Sociology; World Wide Web; Marketing; Political science; Engineering; Economics; Service (business); Social science; Microeconomics; Epistemology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555561",
      "cited_by_count": 84,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4366003746",
      "doi": "10.1145/3579600",
      "title": "Data Subjects' Perspectives on Emotion Artificial Intelligence Use in the Workplace: A Relational Ethics Lens",
      "abstract": "The workplace has experienced extensive digital transformation, in part due to artificial intelligence's commercial availability. Though still an emerging technology, emotional artificial intelligence (EAI) is increasingly incorporated into enterprise systems to augment and automate organizational decisions and to monitor and manage workers. EAI use is often celebrated for its potential to improve workers' wellbeing and performance as well as address organizational problems such as bias and safety. Workers subject to EAI in the workplace are data subjects whose data make EAI possible and who are most impacted by it. However, we lack empirical knowledge about data subjects' perspectives on EAI, including in the workplace. To this end, using a relational ethics lens, we qualitatively analyzed 395 U.S. adults' open-ended survey (partly representative) responses regarding the perceived benefits and risks they associate with being subjected to EAI in the workplace. While participants acknowledged potential benefits of being subject to EAI (e.g., employers using EAI to aid their wellbeing, enhance their work environment, reduce bias), a myriad of potential risks overshadowed perceptions of potential benefits. Participants expressed concerns regarding the potential for EAI use to harm their wellbeing, work environment and employment status, and create and amplify bias and stigma against them, especially the most marginalized (e.g., along dimensions of race, gender, mental health status, disability). Distrustful of EAI and its potential risks, participants anticipated conforming to (e.g., partaking in emotional labor) or refusing (e.g., quitting a job) EAI implementation in practice. We argue that EAI may magnify, rather than alleviate, existing challenges data subjects face in the workplace and suggest that some EAI-inflicted harms would persist even if concerns of EAI's accuracy and bias are addressed.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Shanley Corvite et al.",
      "keywords": "Harm; Psychology; Emotional intelligence; Applied psychology; Social psychology; Knowledge management; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579600",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366003037",
      "doi": "10.1145/3579543",
      "title": "Values in Emotion Artificial Intelligence Hiring Services: Technosolutions to Organizational Problems",
      "abstract": "Despite debates about emotion artificial intelligence's (EAI) validity, legality, and social consequences, EAI is increasingly present in the high stakes context of hiring, with potential to shape the future of work and the workforce. The values laden in technology play a significant role in its societal impact.We conducted qualitative content analysis on the public-facing websites (N=229) of EAI hiring services. We identify the organizational problems that EAI hiring services claim to solve and reveal the values emerging in desired EAI uses as promoted by EAI hiring services to solve organizational problems. Our findings show that EAI hiring services market their technologies as technosolutions to three purported organizational hiring problems: 1) hiring (in)accuracy, 2) hiring (mis)fit, and 3) hiring (in)authenticity. We unpack these problems to expose how these desired uses of EAI are legitimized by the corporate ideals of data-driven decision making, continuous improvement, precision, loyalty, and stability. We identify the unfair and deceptive mechanisms by which EAI hiring services claim to solve the purported organizational hiring problems, suggesting that they unfairly exclude and exploit job candidates through EAI's creation, extraction, and affective commodification of a candidate's affective value through pseudoscientific approaches. Lastly, we interrogate EAI hiring service claims to reveal the core values that underpin their stated desired use: techno-omnipresence, techno-omnipotence, and techno-omniscience. We show how EAI hiring services position desired use of their technology as a moral imperative for hiring organizations with supreme capabilities to solve organizational hiring problems, then discuss implications for fairness, ethics, and policy in EAI-enabled hiring within the US policy landscape.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Kat Roemmich et al.",
      "keywords": "Context (archaeology); Knowledge management; Business; Marketing; Public relations; Computer science; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579543",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387344871",
      "doi": "10.1145/3610207",
      "title": "Sensing Wellbeing in the Workplace, Why and For Whom? Envisioning Impacts with Organizational Stakeholders",
      "abstract": "With the heightened digitization of the workplace, alongside the rise of remote and hybrid work prompted by the pandemic, there is growing corporate interest in using passive sensing technologies for workplace wellbeing. Existing research on these technologies often focus on understanding or improving interactions between an individual user and the technology. Workplace settings can, however, introduce a range of complexities that challenge the potential impact and in-practice desirability of wellbeing sensing technologies. Today, there is an inadequate empirical understanding of how everyday workers---including those who are impacted by, and impact the deployment of workplace technologies--envision its broader socio-ecological impacts. In this study, we conduct storyboard-driven interviews with 33 participants across three stakeholder groups: organizational governors, AI builders, and worker data subjects. Overall, our findings surface how workers envisioned wellbeing sensing technologies may lead to cascading impacts on their broader organizational culture, interpersonal relationships with colleagues, and individual day-to-day lives. Participants anticipated harms arising from ambiguity and misalignment around scaled notions of \"worker wellbeing,'' underlying technical limitations to workplace-situated sensing, and assumptions regarding how social structures and relationships may shape the impacts and use of these technologies. Based on our findings, we discuss implications for designing worker-centered data-driven wellbeing technologies.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Anna Kawakami et al.",
      "keywords": "Software deployment; Stakeholder; Emerging technologies; Digitization; Ambiguity; Knowledge management; Public relations; Situated; Sociotechnical system; Sociology; Computer science; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610207",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4210481853",
      "doi": "10.1145/3502288",
      "title": "Understanding Online Privacy\u2014A Systematic Review of Privacy Visualizations and Privacy by Design Guidelines",
      "abstract": "Privacy visualizations help users understand the privacy implications of using an online service. Privacy by Design guidelines provide generally accepted privacy standards for developers of online services. To obtain a comprehensive understanding of online privacy, we review established approaches, distill a unified list of 15 privacy attributes and rank them based on perceived importance by users and privacy experts. We then discuss similarities, explain notable differences, and examine trends in terms of the attributes covered. Finally, we show how our results provide a foundation for user-centric privacy visualizations, inspire best practices for developers, and give structure to privacy policies.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Susanne Barth et al.",
      "keywords": "Computer science; Internet privacy; Privacy software; Privacy by Design; Information privacy; Privacy policy; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3502288",
      "cited_by_count": 61,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4309617476",
      "doi": "10.1145/3555186",
      "title": "Ethical Tensions in Applications of AI for Addressing Human Trafficking: A Human Rights Perspective",
      "abstract": "In the last two decades, human trafficking (where individuals are forcibly exploited for the profits of another) has seen increased attention from the artificial intelligence (AI) community. Clear focus on the ethical risks of this research is critical given that those risks are disproportionately born by already vulnerable populations. To understand and subsequently address these risks, we conducted a systematic literature review of computing research leveraging AI to combat human trafficking and apply a framework using principles from international human rights law to categorize ethical risks. This paper uncovers a number of ethical tensions including bias endemic in datasets, privacy risks stemming from data collection and reporting, and issues concerning potential misuse. We conclude by highlighting four suggestions for future research: broader use of participatory design; engaging with other forms of trafficking; developing best practices for harm prevention; and including transparent ethics disclosures in research. We find that there are significant gaps in what aspects of human trafficking researchers have focused on. Most research to date focuses on aiding criminal investigations in cases of sex trafficking, but more work is needed to support other anti-trafficking activities like supporting survivors, adequately address labor trafficking, and support more diverse survivor populations including transgender and nonbinary individuals.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Julia Deeb-Swihart et al.",
      "keywords": "Harm; Human trafficking; Human rights; Transgender; Political science; Perspective (graphical); Engineering ethics; Criminology; Public relations; Sociology; Law; Computer science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555186",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W173339872",
      "doi": "10.1145/2629559",
      "title": "Human-agent collectives",
      "abstract": "HACs offer a new science for exploring the computational and human aspects of society.",
      "year": "2014",
      "journal": "Communications of the ACM",
      "authors": "Nicholas R. Jennings et al.",
      "keywords": "Computer science; Multi-agent system; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/2629559",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394686888",
      "doi": "10.1145/3657294",
      "title": "GANs in the Panorama of Synthetic Data Generation Methods",
      "abstract": "This article focuses on the creation and evaluation of synthetic data to address the challenges of imbalanced datasets in machine learning (ML) applications, using fake news detection as a case study. We conducted a thorough literature review on generative adversarial networks (GANs) for tabular data, synthetic data generation methods, and synthetic data quality assessment. By augmenting a public news dataset with synthetic data generated by different GAN architectures, we demonstrate the potential of synthetic data to improve ML models\u2019 performance in fake news detection. Our results show a significant improvement in classification performance, especially in the underrepresented class. We also modify and extend a data usage approach to evaluate the quality of synthetic data and investigate the relationship between synthetic data quality and data augmentation performance in classification tasks. We found a positive correlation between synthetic data quality and performance in the underrepresented class, highlighting the importance of high-quality synthetic data for effective data augmentation.",
      "year": "2024",
      "journal": "ACM Transactions on Multimedia Computing Communications and Applications",
      "authors": "Bruno Vaz et al.",
      "keywords": "Panorama; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3657294",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396695389",
      "doi": "10.1145/3652158",
      "title": "Mobility Data Science: Perspectives and Challenges",
      "abstract": "Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of Global Positioning System (GPS)\u2013equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated a significant impact in various domains, including traffic management, urban planning, and health sciences. In this article, we present the domain of mobility data science. Towards a unified approach to mobility data science, we present a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state-of-the-art, and describe open challenges for the research community in the coming years.",
      "year": "2024",
      "journal": "ACM Transactions on Spatial Algorithms and Systems",
      "authors": "Mohamed F. Mokbel et al.",
      "keywords": "Data science; Pipeline (software); Computer science; Global Positioning System; Data management; Mobility management; Domain (mathematical analysis); Mobility model; Mobile device; Data collection; Telecommunications; Database; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3652158",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4396230898",
      "doi": "10.1145/3637342",
      "title": "\"I'm Constantly in This Dilemma\": How Migrant Technology Professionals Perceive Social Media Recommendation Algorithms",
      "abstract": "Migrants experience unique needs and use social media, in part, to address them. While prior work has primarily focused on migrant populations who are vulnerable socio-economically and legally, less is known about how highly educated migrant populations use social media. Additionally, a growing body of work focuses on algorithmic perceptions and resistance, primarily from laypersons' perspectives rather than people with high degrees of algorithmic literacy. To address these gaps, we draw from interviews with 20 Chinese-born migrant technology professionals. We found that social media played an integral role in helping participants meet their unique needs but that participants perceived social media algorithms to negatively shape the content they consumed, which ultimately influenced their mobility-related aspirations and goals. We discuss how findings challenge the promise of algorithmic literacy and contribute to a human-centered conceptualization of algorithmic mobility as socially and algorithmically produced motion that concerns the movement of physical bodies and interactions as well as associated digital movement. Specifically, we introduce a fourth dimension of algorithmic mobility: algorithmically curated content on social media and elsewhere based on facets of users' identities directly influences users' mobility-related aspirations and goals, such as how, when, and where they go. Finally, we call for transnational policy interventions related to algorithms and highlight design considerations around content moderation, algorithmic user-control, and contestability.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Cassidy Pyle et al.",
      "keywords": "Social media; Conceptualization; Moderation; Dilemma; Literacy; Computer science; Perception; Internet privacy; Public relations; Sociology; Social psychology; Psychology; World Wide Web; Political science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3637342",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4280553643",
      "doi": "10.1145/3529166",
      "title": "From Centuries to Hours: The Journey of Research into Practice",
      "abstract": "COVID-19 has made the research-policy nexus visible as never before. Public health officials, doctors and scientists are standing alongside political and other leaders all around the world to promote research-informed health behaviors to \u2018flatten the curve\u2019 of this global pandemic. Proper hand hygiene, physical distancing and use of masks are now either recommended or mandated everyday public health behaviors across the world. Obviously, application of research to public problem solving is not new. However, the pace of the journey from research to policy and practice has shortened at a similar exponential rate as the spread of the virus. This paper provides a historical overview of research-informed policy and practice. In doing so, it aims to build an understanding of how research is able to address COVID-related policy questions in almost real-time; how the demand-side consequences of this global pandemic have advanced research-informed policy and practice; and how policymakers can harness research to solve public policy problems in the future.",
      "year": "2022",
      "journal": "Digital Government Research and Practice",
      "authors": "Peter Bragge",
      "keywords": "Pace; Distancing; Pandemic; Public relations; Political science; Public policy; Public health; Nexus (standard); Politics; Research policy; Health policy; Coronavirus disease 2019 (COVID-19); Public administration; Medicine; Law; Nursing; Geography; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3529166",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4365999229",
      "doi": "10.1145/3579617",
      "title": "\"Oh yes! over-preparing for meetings is my jam :)\": The Gendered Experiences of System Administrators",
      "abstract": "In the system and network administration domain, gender diversity remains a distant target. The experiences and perspectives of sysadmins who belong to marginalized genders (non cis-men) are not well understood beyond the fact that sysadmin work environments are generally not equitable. We address this knowledge gap in our study by focusing on the ways in which sysadmins from marginalized genders manage their work in men-dominated sysadmin work spaces and by understanding what an inclusive workplace would look like. Using a feminist research approach, we engaged with a group of 16 sysadmins who are not cis-men via six online focus groups. We found that managing the impact of gender identity in the sysadmin workplace means demonstrating excellence and going above and beyond in system administration tasks, and also requires performing additional care work not expected from cis men. Furthermore, our participants handle additional layers of work due to gender considerations and to actively find community in the workplace. We found that sysadmins manage by going above and beyond in their tasks, performing care work and doing extra layers of work because of gender considerations, and finding community in the workplace. To mitigate this additional workload, we recommend more care for care work. For future research, we recommend the use of feminist lenses when studying sysadmin work in order to provide more equitable solutions that ultimately contribute to improving system security by fostering a just workplace.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Mannat Kaur et al.",
      "keywords": "Excellence; Work (physics); Workload; Public relations; Identity (music); Care work; Diversity (politics); Sociology; Psychology; Political science; Management; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579617",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2923299197",
      "doi": "10.1145/3427787",
      "title": "Review of Human Decision-making during Computer Security Incident Analysis",
      "abstract": "We review practical advice on decision-making during computer security incident response. Scope includes standards from the IETF, ISO, FIRST, and the US intelligence community. To focus on human decision-making, the scope is the evidence collection, analysis, and reporting phases of response, which includes human decision-making within and connecting these phases. The results indicate both strengths and gaps. A strength is available advice on how to accomplish many specific tasks. However, there is little guidance on how to prioritize tasks in limited time or how to interpret, generalize, and convincingly report results. Future work should focus on these gaps in explication and specification of decision-making during incident analysis.",
      "year": "2021",
      "journal": "Digital Threats Research and Practice",
      "authors": "Jonathan Spring et al.",
      "keywords": "Scope (computer science); Explication; Computer science; Focus (optics); Advice (programming); Work (physics); Decision analysis; Incident response; Intelligence analysis; Risk analysis (engineering); Knowledge management; Management science; Data science; Computer security; Engineering; Business",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3427787",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413681943",
      "doi": "10.1145/3763243",
      "title": "Accessible Web Design for Older Adults: Challenges and Solutions",
      "abstract": "The growing number of older adults online has spurred interest in improving web accessibility for this demographic. To evaluate the current state of this field, we conducted a systematic review of studies published between 2014 and 2023. Our research aimed to identify the challenges older adults face online and effective solutions for accessible web design. From 4,052 articles, we identified 25 types of accessibility issues, 104 improvements to enhance website accessibility, 24 technological resources to design these accessibility enhancements, and 20 evaluation methods. Despite notable progress enhancing web accessibility for older people, our findings underscore the need for ongoing improvements for a truly inclusive web, considering the differences within this heterogeneous group and understanding old age not as a problem but as an opportunity.",
      "year": "2025",
      "journal": "ACM Transactions on Accessible Computing",
      "authors": "Washington Chiriboga-Casanova et al.",
      "keywords": "Computer science; World Wide Web; Web application; Psychology; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3763243",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2594685110",
      "doi": "10.1145/3127881",
      "title": "Mining Electronic Health Records (EHRs)",
      "abstract": "The continuously increasing cost of the US healthcare system has received significant attention. Central to the ideas aimed at curbing this trend is the use of technology in the form of the mandate to implement electronic health records (EHRs). EHRs consist of patient information such as demographics, medications, laboratory test results, diagnosis codes, and procedures. Mining EHRs could lead to improvement in patient health management as EHRs contain detailed information related to disease prognosis for large patient populations. In this article, we provide a structured and comprehensive overview of data mining techniques for modeling EHRs. We first provide a detailed understanding of the major application areas to which EHR mining has been applied and then discuss the nature of EHR data and its accompanying challenges. Next, we describe major approaches used for EHR mining, the metrics associated with EHRs, and the various study designs. With this foundation, we then provide a systematic and methodological organization of existing data mining techniques used to model EHRs and discuss ideas for future research.",
      "year": "2018",
      "journal": "ACM Computing Surveys",
      "authors": "Pranjul Yadav et al.",
      "keywords": "Health records; Computer science; Data science; Mandate; Health information technology; Data mining; Electronic health record; Health care",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3127881",
      "cited_by_count": 299,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3173515334",
      "doi": "10.1145/3510579",
      "title": "A Survey of Privacy Vulnerabilities of Mobile Device Sensors",
      "abstract": "The number of mobile devices, such as smartphones and smartwatches, is relentlessly increasing, to almost 6.8 billion by 2022, and along with it, the amount of personal and sensitive data captured by them. This survey overviews the state of the art of what personal and sensitive user attributes can be extracted from mobile device sensors, emphasizing critical aspects such as demographics, health and body features, activity and behavior recognition, and so forth. In addition, we review popular metrics in the literature to quantify the degree of privacy and discuss powerful privacy methods to protect the sensitive data while preserving data utility for analysis. Finally, open research questions are presented for further advancements in the field.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Paula Delgado-Santos et al.",
      "keywords": "Computer science; Mobile device; Smartwatch; Demographics; Field (mathematics); Internet privacy; Personally identifiable information; Computer security; Information privacy; Human\u2013computer interaction; Data science; World Wide Web; Wearable computer; Embedded system",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3510579",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4281400173",
      "doi": "10.1145/3488717",
      "title": "Responsible data management",
      "abstract": "Perspectives on the role and responsibility of the data-management research community in designing, developing, using, and overseeing automated decision systems.",
      "year": "2022",
      "journal": "Communications of the ACM",
      "authors": "Julia Stoyanovich et al.",
      "keywords": "Data management; Computer science; Knowledge management; Process management; Data science; Business; Engineering management; Data mining; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3488717",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3028938806",
      "doi": "10.1145/3392828",
      "title": "\"They Just Don't Get It\": Towards Social Technologies for Coping with Interpersonal Racism",
      "abstract": "Over 35% of Americans belong to racial minority groups. Racism targeting these individuals results in a range of harmful physical, psychological, and practical consequences. The present work aims to shed light on the current sense-making and support-seeking practices exhibited by targets of racism, as well as to identify the core needs and barriers that future socio-technical interventions could potentially address. The long-term goal of this work is to understand how CSCW researchers and designers could best support members of marginalized groups to make sense of and to seek support for experiences with racism. Narrative episode interviews with targets of racism revealed a number of key entry points for intervention. For example, participants' personal stories confirmed that uncertainty, both about the nature and consequences of the experience of racism, is a key motivator for support-seeking. In addition, despite the need for support, participants largely do not trust public forms of social media for support-seeking. We discuss how participants' accounts of the complex labor involved in determining who \"gets it\" in identifying potential supporters, and in navigating the complexities of trust and agency in sharing their experiences, present clear implications for the design of new socio-technical platforms for members of racial minority groups.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Alexandra To et al.",
      "keywords": "Racism; Agency (philosophy); Social psychology; Psychological intervention; Interpersonal communication; Narrative; Sense of agency; Social support; Psychology; Coping (psychology); Psychometrics of racism; Public relations; Sociology; Political science; Gender studies; Psychotherapist",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3392828",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393224518",
      "doi": "10.1145/3653711",
      "title": "FairSNA: Algorithmic Fairness in Social Network Analysis",
      "abstract": "In recent years, designing fairness-aware methods has received much attention in various domains, including machine learning, natural language processing, and information retrieval. However, in social network analysis (SNA), designing fairness-aware methods for various research problems by considering structural bias and inequalities of large-scale social networks has not received much attention. In this work, we highlight how the structural bias of social networks impacts the fairness of different SNA methods. We further discuss fairness aspects that should be considered while proposing network structure-based solutions for different SNA problems, such as link prediction, influence maximization, centrality ranking, and community detection. This survey-cum-vision clearly highlights that very few works have considered fairness and bias while proposing solutions; even these works are mainly focused on some research topics, such as link prediction, influence maximization, and PageRank. However, fairness has not yet been addressed for other research topics, such as influence blocking and community detection. We review the state of the art for different research topics in SNA, including the considered fairness constraints, their limitations, and our vision. This survey also covers evaluation metrics, available datasets and synthetic network generating models used in such studies. Finally, we highlight various open research directions that require researchers\u2019 attention to bridge the gap between fairness and SNA.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Akrati Saxena et al.",
      "keywords": "Computer science; Social network analysis; World Wide Web; Social media",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3653711",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3202632262",
      "doi": "10.1145/3474665",
      "title": "The Effects of a Self-Similar Avatar Voice in Educational Games",
      "abstract": "Avatar identification is one of the most promising research areas in games user research. Greater identification with one's avatar has been associated with improved outcomes in the domains of health, entertainment, and education. However, existing studies have focused almost exclusively on the visual appearance of avatars. Yet audio is known to influence immersion/presence, performance, and physiological responses. We perform one of the first studies to date on avatar self-similar audio. We conducted a 2 x 3 (similar/dissimilar x modulation upwards/downwards/none) study in a Java programming game. We find that voice similarity leads to a significant increase in performance, time spent, similarity identification, competence, relatedness, and immersion. Similarity identification acts as a significant mediator variable between voice similarity and all measured outcomes. Our study demonstrates the importance of avatar audio and has implications for avatar design more generally across digital applications.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Dominic Kao et al.",
      "keywords": "Avatar; Entertainment; Competence (human resources); Multimedia; Similarity (geometry); Identification (biology); Psychology; Computer science; Human\u2013computer interaction; Social psychology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3474665",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4364381409",
      "doi": "10.1145/3591867",
      "title": "Tiny, Always-on, and Fragile: Bias Propagation through Design Choices in On-device Machine Learning Workflows",
      "abstract": "Billions of distributed, heterogeneous, and resource constrained IoT devices deploy on-device machine learning (ML) for private, fast, and offline inference on personal data. On-device ML is highly context dependent and sensitive to user, usage, hardware, and environment attributes. This sensitivity and the propensity toward bias in ML makes it important to study bias in on-device settings. Our study is one of the first investigations of bias in this emerging domain and lays important foundations for building fairer on-device ML. We apply a software engineering lens, investigating the propagation of bias through design choices in on-device ML workflows. We first identify reliability bias as a source of unfairness and propose a measure to quantify it. We then conduct empirical experiments for a keyword spotting task to show how complex and interacting technical design choices amplify and propagate reliability bias . Our results validate that design choices made during model training, like the sample rate and input feature type, and choices made to optimize models, like light-weight architectures, the pruning learning rate, and pruning sparsity, can result in disparate predictive performance across male and female groups. Based on our findings, we suggest low effort strategies for engineers to mitigate bias in on-device ML.",
      "year": "2023",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Wiebke Hutiri et al.",
      "keywords": "Computer science; Workflow; Machine learning; Artificial intelligence; Inference; Context (archaeology); Software; Pruning; Human\u2013computer interaction; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3591867",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3197886899",
      "doi": "10.1145/3479572",
      "title": "The Impact of Algorithmic Risk Assessments on Human Predictions and its Analysis via Crowdsourcing Studies",
      "abstract": "As algorithmic risk assessment instruments (RAIs) are increasingly adopted to assist decision makers, their predictive performance and potential to promote inequity have come under scrutiny. However, while most studies examine these tools in isolation, researchers have come to recognize that assessing their impact requires understanding the behavior of their human interactants. In this paper, building off of several recent crowdsourcing works focused on criminal justice, we conduct a vignette study in which laypersons are tasked with predicting future re-arrests. Our key findings are as follows: (1) Participants often predict that an offender will be rearrested even when they deem the likelihood of re-arrest to be well below 50%; (2) Participants do not anchor on the RAI's predictions; (3) The time spent on the survey varies widely across participants and most cases are assessed in less than 10 seconds; (4) Judicial decisions, unlike participants' predictions, depend in part on factors that are orthogonal to the likelihood of re-arrest. These results highlight the influence of several crucial but often overlooked design decisions and concerns around generalizability when constructing crowdsourcing studies to analyze the impacts of RAI",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Riccardo Fogliato et al.",
      "keywords": "Crowdsourcing; Generalizability theory; Vignette; Scrutiny; Psychology; Criminal justice; Applied psychology; Data science; Computer science; Social psychology; Political science; Criminology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3479572",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389386412",
      "doi": "10.1145/3635712",
      "title": "Using Voice and Biofeedback to Predict User Engagement during Product Feedback Interviews",
      "abstract": "Capturing users\u2019 engagement is crucial for gathering feedback about the features of a software product. In a market-driven context, current approaches to collecting and analyzing users\u2019 feedback are based on techniques leveraging information extracted from product reviews and social media. These approaches are hardly applicable in contexts where online feedback is limited, as for the majority of apps, and software in general. In such cases, companies need to resort to face-to-face interviews to get feedback on their products. In this article, we propose to utilize biometric data, in terms of physiological and voice features, to complement product feedback interviews with information about the engagement of the user on product-relevant topics. We evaluate our approach by interviewing users while gathering their physiological data (i.e., biofeedback ) using an Empatica E4 wristband, and capturing their voice through the default audio-recorder of a common laptop. Our results show that we can predict users\u2019 engagement by training supervised machine learning algorithms on biofeedback and voice data, and that voice features alone can be sufficiently effective. The best configurations evaluated achieve an average F1 \u223c 70% in terms of classification performance, and use voice features only. This work is one of the first studies in requirements engineering in which biometrics are used to identify emotions. Furthermore, this is one of the first studies in software engineering that considers voice analysis. The usage of voice features can be particularly helpful for emotion-aware feedback collection in remote communication, either performed by human analysts or voice-based chatbots, and can also be exploited to support the analysis of meetings in software engineering research.",
      "year": "2023",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Alessio Ferrari et al.",
      "keywords": "Computer science; Software; Laptop; Human\u2013computer interaction; Biometrics; Context (archaeology); Product (mathematics); Multimedia; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3635712",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388499444",
      "doi": "10.1145/3632122",
      "title": "Measuring and Mitigating Group Inequalities In Resource Allocation",
      "abstract": "Resource allocation, an integral part of socio-economic governance, profoundly influences individual prosperity and has the potential to mitigate or exacerbate socioeconomic disparities. This paper addresses the challenge of equitably allocating finite resources among individuals by answering two fundamental questions: (1) how to accurately measure and test group disparities and (2) how to optimally distribute resources while ensuring group fairness. We propose the Group Beneficiary Disparity (GBD) metric \u2013 an evaluation tool engineered to systematically gauge inequalities in a binary beneficiary/non-beneficiary context. The GBD provides decision-makers and planners with a powerful tool to audit social programs and optimize policies from a lens of group equality. We argue that utilitarian decision-makers cannot fully eliminate group disparities even when operating under social welfare constraints. To address this issue, we propose a new resource allocation optimization model, called A-FARM (Asymptotically Fair Allocation of Resources Model), with asymptotic group fairness guarantees. A-FARM partitions individuals into distinct, non-overlapping units and distributes resources among these units based on a utility-based allocation mechanism. Finally, we evaluate the performance of our proposed algorithm using both simulated and real-world data. Our results demonstrate that, A-FARM enables decision-makers to (1) achieve maximum efficiency under group fairness constraints and (2) perform a fairness-efficiency trade-off.",
      "year": "2023",
      "journal": "ACM Journal on Responsible Computing",
      "authors": "Arya Farahi et al.",
      "keywords": "Resource allocation; Beneficiary; Environmental economics; Computer science; Context (archaeology); Economics; Inequality; Tariff; Microeconomics; Mathematics; Finance; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3632122",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2917286209",
      "doi": "10.1145/3241036",
      "title": "The seven tools of causal inference, with reflections on machine learning",
      "abstract": "The kind of causal inference seen in natural human thought can be \"algorithmitized\" to help produce human-level machine intelligence.",
      "year": "2019",
      "journal": "Communications of the ACM",
      "authors": "Judea Pearl",
      "keywords": "Causal inference; Computer science; Inference; Artificial intelligence; Machine learning; Econometrics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3241036",
      "cited_by_count": 607,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2989168403",
      "doi": "10.1145/3359246",
      "title": "How Computers See Gender",
      "abstract": "Investigations of facial analysis (FA) technologies-such as facial detection and facial recognition-have been central to discussions about Artificial Intelligence's (AI) impact on human beings. Research on automatic gender recognition, the classification of gender by FA technologies, has raised potential concerns around issues of racial and gender bias. In this study, we augment past work with empirical data by conducting a systematic analysis of how gender classification and gender labeling in computer vision services operate when faced with gender diversity. We sought to understand how gender is concretely conceptualized and encoded into commercial facial analysis and image labeling technologies available today. We then conducted a two-phase study: (1) a system analysis of ten commercial FA and image labeling services and (2) an evaluation of five services using a custom dataset of diverse genders using self-labeled Instagram images. Our analysis highlights how gender is codified into both classifiers and data standards. We found that FA services performed consistently worse on transgender individuals and were universally unable to classify non-binary genders. In contrast, image labeling often presented multiple gendered concepts. We also found that user perceptions about gender performance and identity contradict the way gender performance is encoded into the computer vision infrastructure. We discuss our findings from three perspectives of gender identity (self-identity, gender performativity, and demographic identity) and how these perspectives interact across three layers: the classification infrastructure, the third-party applications that make use of that infrastructure, and the individuals who interact with that software. We employ Bowker and Star's concepts of \"torque\" and \"residuality\" to further discuss the social implications of gender classification. We conclude by outlining opportunities for creating more inclusive classification infrastructures and datasets, as well as with implications for policy.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Morgan Klaus Scheuerman et al.",
      "keywords": "Transgender; Gender identity; Identity (music); Gender diversity; Performativity; Psychology; Gender bias; Gender analysis; Artificial intelligence; Computer science; Social psychology; Political science; Sociology; Gender studies; Management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359246",
      "cited_by_count": 222,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2911424601",
      "doi": "10.1145/3274658",
      "title": "A Perspective Analysis of Handwritten Signature Technology",
      "abstract": "Handwritten signatures are biometric traits at the center of debate in the scientific community. Over the last 40 years, the interest in signature studies has grown steadily, having as its main reference the application of automatic signature verification, as previously published reviews in 1989, 2000, and 2008 bear witness. Ever since, and over the last 10 years, the application of handwritten signature technology has strongly evolved and much research has focused on the possibility of applying systems based on handwritten signature analysis and processing to a multitude of new fields. After several years of haphazard growth of this research area, it is time to assess its current developments for their applicability in order to draw a structured way forward. This perspective reports a systematic review of the last 10 years of the literature on handwritten signatures with respect to the new scenario, focusing on the most promising domains of research and trying to elicit possible future research directions in this subject.",
      "year": "2019",
      "journal": "ACM Computing Surveys",
      "authors": "Moises D\u00edaz et al.",
      "keywords": "Computer science; Perspective (graphical); Signature (topology); Artificial intelligence; Natural language processing",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3274658",
      "cited_by_count": 239,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3189849087",
      "doi": "10.1145/3476058",
      "title": "Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development",
      "abstract": "Data is a crucial component of machine learning. The field is reliant on data to train, validate, and test models. With increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. Computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. Given computer vision's propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation - how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. To conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. Through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. We discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. Many of the silenced values we identify sit in opposition with social computing practices. We conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Morgan Klaus Scheuerman et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3476058",
      "cited_by_count": 153,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2881747041",
      "doi": "10.1145/3317287.3328534",
      "title": "Troubling Trends in Machine Learning Scholarship",
      "abstract": "Flawed scholarship threatens to mislead the public and stymie future research by compromising ML\u2019s intellectual foundations. Indeed, many of these problems have recurred cyclically throughout the history of AI and, more broadly, in scientific research. In 1976, Drew McDermott chastised the AI community for abandoning self-discipline, warning prophetically that \"if we can\u2019t criticize ourselves, someone else will save us the trouble.\" The current strength of machine learning owes to a large body of rigorous research to date, both theoretical and empirical. By promoting clear scientific thinking and communication, our community can sustain the trust and investment it currently enjoys.",
      "year": "2019",
      "journal": "Queue",
      "authors": "Zachary C. Lipton et al.",
      "keywords": "Scholarship; Speculation; Incentive; Service (business); Computer science; Artificial intelligence; Focus (optics); Bibliometrics; Data science; Political science; Marketing; Economics; Business; World Wide Web; Law; Finance",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3317287.3328534",
      "cited_by_count": 95,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3170155921",
      "doi": "10.1145/3453175",
      "title": "Can Chatbots Help Support a Person\u2019s Mental Health? Perceptions and Views from Mental Healthcare Professionals and Experts",
      "abstract": "The objective of this study was to understand the attitudes of professionals who work in mental health regarding the use of conversational user interfaces, or chatbots, to support people\u2019s mental health and wellbeing. This study involves an online survey to measure the awareness and attitudes of mental healthcare professionals and experts. The findings from this survey show that more than half of the participants in the survey agreed that there are benefits associated with mental healthcare chatbots (65%, p &lt; 0.01). The perceived importance of chatbots was also relatively high (74%, p &lt; 0.01), with more than three-quarters (79%, p &lt; 0.01) of respondents agreeing that mental healthcare chatbots could help their clients better manage their own health, yet chatbots are overwhelmingly perceived as not adequately understanding or displaying human emotion (86%, p &lt; 0.01). Even though the level of personal experience with chatbots among professionals and experts in mental health has been quite low, this study shows that where they have been used, the experience has been mostly satisfactory. This study has found that as years of experience increased, there was a corresponding increase in the belief that healthcare chatbots could help clients better manage their own mental health.",
      "year": "2021",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Colm Sweeney et al.",
      "keywords": "Mental health; Perception; Mental healthcare; Psychology; Health professionals; Health care; Computer-assisted web interviewing; Nursing; Applied psychology; Medical education; Medicine; Psychiatry; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3453175",
      "cited_by_count": 166,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393002303",
      "doi": "10.1145/3653070",
      "title": "On the Opportunities and Challenges of Foundation Models for GeoAI (Vision Paper)",
      "abstract": "Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have not yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial domains, including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality, such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, the task-agnostic large learning models (LLMs) can outperform task-specific fully supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image\u2013based urban noise intensity classification, and remote sensing image scene classification), existing FMs still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing an FM for GeoAI is to address the multimodal nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal FM that can reason over various types of geospatial data through geospatial alignments. We conclude this article by discussing the unique risks and challenges to developing such a model for GeoAI.",
      "year": "2024",
      "journal": "ACM Transactions on Spatial Algorithms and Systems",
      "authors": "Gengchen Mai et al.",
      "keywords": "Foundation (evidence); Computer science; Data science; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3653070",
      "cited_by_count": 74,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3163680969",
      "doi": "10.1145/3479594",
      "title": "Image Cropping on Twitter: Fairness Metrics, their Limitations, and the Importance of Representation, Design, and Agency",
      "abstract": "Twitter uses machine learning to crop images, where crops are centered around the part predicted to be the most salient. In fall 2020, Twitter users raised concerns that the automated image cropping system on Twitter favored light-skinned over dark-skinned individuals, as well as concerns that the system favored cropping woman's bodies instead of their heads. In order to address these concerns, we conduct an extensive analysis using formalized group fairness metrics. We find systematic disparities in cropping and identify contributing factors, including the fact that the cropping based on the single most salient point can amplify the disparities because of an effect we term argmax bias. However, we demonstrate that formalized fairness metrics and quantitative analysis on their own are insufficient for capturing the risk of representational harm in automatic cropping. We suggest the removal of saliency-based cropping in favor of a solution that better preserves user agency. For developing a new solution that sufficiently address concerns related to representational harm, our critique motivates a combination of quantitative and qualitative methods that include human-centered design.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Kyra Yee et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3479594",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3112374793",
      "doi": "10.1145/3479562",
      "title": "Algorithmic Risk Assessments Can Alter Human Decision-Making Processes in High-Stakes Government Contexts",
      "abstract": "Governments are increasingly turning to algorithmic risk assessments when making important decisions, such as whether to release criminal defendants before trial. Policymakers assert that providing public servants with algorithmic advice will improve human risk predictions and thereby lead to better (e.g., fairer) decisions. Yet because many policy decisions require balancing risk-reduction with competing goals, improving the accuracy of predictions may not necessarily improve the quality of decisions. If risk assessments make people more attentive to reducing risk at the expense of other values, these algorithms would diminish the implementation of public policy even as they lead to more accurate predictions. Through an experiment with 2,140 lay participants simulating two high-stakes government contexts, we provide the first direct evidence that risk assessments can systematically alter how people factor risk into their decisions. These shifts counteracted the potential benefits of improved prediction accuracy. In the pretrial setting of our experiment, the risk assessment made participants more sensitive to increases in perceived risk; this shift increased the racial disparity in pretrial detention by 1.9%. In the government loans setting of our experiment, the risk assessment made participants more risk-averse; this shift reduced government aid by 8.3%. These results demonstrate the potential limits and harms of attempts to improve public policy by incorporating predictive algorithms into multifaceted policy decisions. If these observed behaviors occur in practice, presenting risk assessments to public servants would generate unexpected and unjust shifts in public policy without being subject to democratic deliberation or oversight.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Ben Green et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3479562",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392645489",
      "doi": "10.1145/3652155",
      "title": "Fairness Testing: A Comprehensive Survey and Analysis of Trends",
      "abstract": "Unfair behaviors of Machine Learning (ML) software have garnered increasing attention and concern among software engineers. To tackle this issue, extensive research has been dedicated to conducting fairness testing of ML software, and this article offers a comprehensive survey of existing studies in this field. We collect 100 papers and organize them based on the testing workflow (i.e., how to test) and testing components (i.e., what to test). Furthermore, we analyze the research focus, trends, and promising directions in the realm of fairness testing. We also identify widely adopted datasets and open-source tools for fairness testing.",
      "year": "2024",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Zhenpeng Chen et al.",
      "keywords": "Computer science; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3652155",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4289328212",
      "doi": "10.1145/3274342",
      "title": "Debiasing Desire",
      "abstract": "Designing technical systems to be resistant to bias and discrimination represents vital new terrain for researchers, policymakers, and the anti-discrimination project more broadly. We consider bias and discrimination in the context of popular online dating and hookup platforms in the United States, which we call intimate platforms. Drawing on work in social-justice-oriented and Queer HCI, we review design features of popular intimate platforms and their potential role in exacerbating or mitigating interpersonal bias. We argue that focusing on platform design can reveal opportunities to reshape troubling patterns of intimate contact without overriding users' decisional autonomy. We identify and address the difficult ethical questions that nevertheless come along with such intervention, while urging the social computing community to engage more deeply with issues of bias, discrimination, and exclusion in the study and design of intimate platforms.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Jevan Hutson et al.",
      "keywords": "Debiasing; Autonomy; Context (archaeology); Queer; Internet privacy; Intervention (counseling); Psychology; Social psychology; Political science; Sociology; Computer science; Law; Gender studies",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274342",
      "cited_by_count": 70,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3134200403",
      "doi": "10.1145/3452118",
      "title": "Citizen Participation and Machine Learning for a Better Democracy",
      "abstract": "The development of democratic systems is a crucial task as confirmed by its selection as one of the Millennium Sustainable Development Goals by the United Nations. In this article, we report on the progress of a project that aims to address barriers, one of which is information overload, to achieving effective direct citizen participation in democratic decision-making processes. The main objectives are to explore if the application of Natural Language Processing ( NLP ) and machine learning can improve citizens\u2019 experience of digital citizen participation platforms. Taking as a case study the \u201cDecide Madrid\u201d Consul platform, which enables citizens to post proposals for policies they would like to see adopted by the city council, we used NLP and machine learning to provide new ways to (a) suggest to citizens proposals they might wish to support; (b) group citizens by interests so that they can more easily interact with each other; (c) summarise comments posted in response to proposals; and (d) assist citizens in aggregating and developing proposals. Evaluation of the results confirms that NLP and machine learning have a role to play in addressing some of the barriers users of platforms such as Consul currently experience. CCS concepts: \u2022 Human-centred computing\u2192Collaborative and social computing \u2022 Computing methodologies\u2192Artificial intelligence\u2192Natural language processing",
      "year": "2021",
      "journal": "Digital Government Research and Practice",
      "authors": "Miguel Arana-Catania et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3452118",
      "cited_by_count": 69,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2984641700",
      "doi": "10.1145/3359320",
      "title": "Additional Labors of the Entrepreneurial Self",
      "abstract": "Workers are increasingly expected to take on the responsibility and effort of preparing for employment in the new economy, where digital technologies play a central role in bridging access to resources, connections, and opportunity. Drawing from multi-year studies of entrepreneurs in Accra and Detroit, two cities that continue to experience high rates of inequality and persistently low incomes for the majority of their residents, this article highlights three key challenges to self-entrepreneurialization in the digital age: self-upgrading, maintaining technology, and overcoming exclusion. Locating these challenges at the intersection of (1) two powerful global discourses of entrepreneurialism and technology upgrade and (2) class frictions and racial dynamics, this paper uncovers ways in which CSCW might support entrepreneurialism in the new economy, particularly given that it is becoming a de facto space of work and mode of living.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Seyram Avle et al.",
      "keywords": "Bridging (networking); De facto; Entrepreneurship; Work (physics); Sharing economy; Inequality; Business; Economic growth; Sociology; Political science; Economics; Engineering; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359320",
      "cited_by_count": 75,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391614477",
      "doi": "10.1145/3645102",
      "title": "Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance",
      "abstract": "Emerging Distributed AI systems are revolutionizing big data computing and data processing capabilities with growing economic and societal impact. However, recent studies have identified new attack surfaces and risks caused by security, privacy, and fairness issues in AI systems. In this article, we review representative techniques, algorithms, and theoretical foundations for trustworthy distributed AI through robustness guarantee, privacy protection, and fairness awareness in distributed learning. We first provide a brief overview of alternative architectures for distributed learning, discuss inherent vulnerabilities for security, privacy, and fairness of AI algorithms in distributed learning, and analyze why these problems are present in distributed learning regardless of specific architectures. Then, we provide a unique taxonomy of countermeasures for trustworthy distributed AI, covering (1) robustness to evasion attacks and irregular queries at inference, and robustness to poisoning attacks, Byzantine attacks, and irregular data distribution during training; (2) privacy protection during distributed learning and model inference at deployment; and (3) AI fairness and governance with respect to both data and models. We conclude with a discussion on open challenges and future research directions toward trustworthy distributed AI, such as the need for trustworthy AI policy guidelines, the AI responsibility-utility co-design, and incentives and compliance.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Wenqi Wei et al.",
      "keywords": "Computer science; Robustness (evolution); Trustworthiness; Computer security; Distributed learning; Information privacy; Software deployment; Inference; Corporate governance; Incentive; Artificial intelligence; Software engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3645102",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3086302916",
      "doi": "10.1145/3409289",
      "title": "Proactively Identifying Emerging Hacker Threats from the Dark Web",
      "abstract": "Cybersecurity experts have appraised the total global cost of malicious hacking activities to be $450 billion annually. Cyber Threat Intelligence (CTI) has emerged as a viable approach to combat this societal issue. However, existing processes are criticized as inherently reactive to known threats. To combat these concerns, CTI experts have suggested proactively examining emerging threats in the vast, international online hacker community. In this study, we aim to develop proactive CTI capabilities by exploring online hacker forums to identify emerging threats in terms of popularity and tool functionality. To achieve these goals, we create a novel Diachronic Graph Embedding Framework (D-GEF). D-GEF operates on a Graph-of-Words (GoW) representation of hacker forum text to generate word embeddings in an unsupervised manner. Semantic displacement measures adopted from diachronic linguistics literature identify how terminology evolves. A series of benchmark experiments illustrate D-GEF's ability to generate higher quality than state-of-the-art word embedding models (e.g., word2vec) in tasks pertaining to semantic analogy, clustering, and threat classification. D-GEF's practical utility is illustrated with in-depth case studies on web application and denial of service threats targeting PHP and Windows technologies, respectively. We also discuss the implications of the proposed framework for strategic, operational, and tactical CTI scenarios. All datasets and code are publicly released to facilitate scientific reproducibility and extensions of this work.",
      "year": "2020",
      "journal": "ACM Transactions on Privacy and Security",
      "authors": "Sagar Samtani et al.",
      "keywords": "Hacker; Computer science; Popularity; Word2vec; Data science; Word embedding; Terminology; Computer security; World Wide Web; Artificial intelligence; Embedding",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3409289",
      "cited_by_count": 65,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3108851260",
      "doi": "10.1145/3428253",
      "title": "Perfectly parallel fairness certification of neural networks",
      "abstract": "Recently, there is growing concern that machine-learned software, which currently assists or even automates decision making, reproduces, and in the worst case reinforces, bias present in the training data. The development of tools and techniques for certifying fairness of this software or describing its biases is, therefore, critical. In this paper, we propose a perfectly parallel static analysis for certifying fairness of feed-forward neural networks used for classification of tabular data. When certification succeeds, our approach provides definite guarantees, otherwise, it describes and quantifies the biased input space regions. We design the analysis to be sound, in practice also exact, and configurable in terms of scalability and precision, thereby enabling pay-as-you-go certification. We implement our approach in an open-source tool called Libra and demonstrate its effectiveness on neural networks trained on popular datasets.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Programming Languages",
      "authors": "Caterina Urban et al.",
      "keywords": "Certification; Computer science; Scalability; Artificial neural network; Software; Machine learning; Artificial intelligence; Software engineering; Data mining; Computer engineering; Data science; Programming language; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3428253",
      "cited_by_count": 61,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4319837288",
      "doi": "10.1145/3569501",
      "title": "Privacy-Enhancing Technology and Everyday Augmented Reality",
      "abstract": "Fundamental to Augmented Reality (AR) headsets is their capacity to visually and aurally sense the world around them, necessary to drive the positional tracking that makes rendering 3D spatial content possible. This requisite sensing also opens the door for more advanced AR-driven activities, such as augmented perception, volumetric capture and biometric identification - activities with the potential to expose bystanders to significant privacy risks. Existing Privacy-Enhancing Technologies (PETs) often safeguard against these risks at a low level e.g., instituting camera access controls. However, we argue that such PETs are incompatible with the need for always-on sensing given AR headsets' intended everyday use. Through an online survey (N=102), we examine bystanders' awareness of, and concerns regarding, potentially privacy infringing AR activities; the extent to which bystanders' consent should be sought; and the level of granularity of information necessary to provide awareness of AR activities to bystanders. Our findings suggest that PETs should take into account the AR activity type, and relationship to bystanders, selectively facilitating awareness and consent. In this way, we can ensure bystanders feel their privacy is respected by everyday AR headsets, and avoid unnecessary rejection of these powerful devices by society.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Joseph O\u2019Hagan et al.",
      "keywords": "Internet privacy; Augmented reality; Perception; Rendering (computer graphics); Everyday life; Computer science; Human\u2013computer interaction; Computer security; Psychology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3569501",
      "cited_by_count": 82,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4396919238",
      "doi": "10.1145/3659625",
      "title": "Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults",
      "abstract": "Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Ziqi Yang et al.",
      "keywords": "Health care; Nursing; Psychology; Internet privacy; Medicine; Computer science; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3659625",
      "cited_by_count": 70,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309617715",
      "doi": "10.1145/3555149",
      "title": "\"Give Everybody [..] a Little Bit More Equity\": Content Creator Perspectives and Responses to the Algorithmic Demonetization of Content Associated with Disadvantaged Groups",
      "abstract": "Algorithmic systems help manage the governance of digital platforms featuring user-generated content, including how money is distributed to creators from the profits a platform earns from advertising on this content. However, creators producing content about disadvantaged populations have reported that these kinds of systems are biased, having associated their content with prohibited or unsafe content, leading to what creators believed were error-prone decisions to demonetize their videos. Motivated by these reports, we present the results of 20 interviews with YouTube creators and a content analysis of videos, tweets, and news about demonetization cases to understand YouTubers' perceptions of demonetization affecting videos featuring disadvantaged or vulnerable populations, as well as creator responses to demonetization, and what kinds of tools and infrastructure support they desired. We found creators had concerns about YouTube's algorithmic system stereotyping content featuring vulnerable demographics in harmful ways, for example by labeling it \"unsafe'' for children or families -- creators believed these demonetization errors led to a range of economic, social, and personal harms. To provide more context to these findings, we analyzed and report on the technique a few creators used to audit YouTube's algorithms to learn what could cause the demonetization of videos featuring LGBTQ people, culture and/or social issues. In response to the varying beliefs about the causes and harms of demonetization errors, we found our interviewees wanted more reliable information and statistics about demonetization cases and errors, more control over their content and advertising, and better economic security.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Sara Kingsley et al.",
      "keywords": "Disadvantaged; Digital content; Content analysis; Context (archaeology); Equity (law); Advertising; Content (measure theory); Internet privacy; Public relations; Business; Computer science; Sociology; Multimedia; Political science; Law; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555149",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385806860",
      "doi": "10.1145/3616088",
      "title": "Understanding the Contribution of Recommendation Algorithms on Misinformation Recommendation and Misinformation Dissemination on Social Networks",
      "abstract": "Social networks are a platform for individuals and organizations to connect with each other and inform, advertise, spread ideas, and ultimately influence opinions. These platforms have been known to propel misinformation. We argue that this could be compounded by the recommender algorithms that these platforms use to suggest items potentially of interest to their users, given the known biases and filter bubbles issues affecting recommender systems. While much has been studied about misinformation on social networks, the potential exacerbation that could result from recommender algorithms in this environment is in its infancy. In this manuscript, we present the result of an in-depth analysis conducted on two datasets ( Politifact FakeNewsNet dataset and HealthStory FakeHealth dataset ) in order to deepen our understanding of the interconnection between recommender algorithms and misinformation spread on Twitter. In particular, we explore the degree to which well-known recommendation algorithms are prone to be impacted by misinformation. Via simulation, we also study misinformation diffusion on social networks, as triggered by suggestions produced by these recommendation algorithms. Outcomes from this work evidence that misinformation does not equally affect all recommendation algorithms. Popularity-based and network-based recommender algorithms contribute the most to misinformation diffusion. Users who are known to be superspreaders are known to directly impact algorithmic performance and misinformation spread in specific scenarios. Findings emerging from our exploration result in a number of implications for researchers and practitioners to consider when designing and deploying recommender algorithms in social networks.",
      "year": "2023",
      "journal": "ACM Transactions on the Web",
      "authors": "R. S. Pathak et al.",
      "keywords": "Misinformation; Recommender system; Computer science; Popularity; Collaborative filtering; Social network (sociolinguistics); Social media; Data science; Algorithm; Internet privacy; Information retrieval; World Wide Web; Computer security; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3616088",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295678468",
      "doi": "10.1145/3507695",
      "title": "A Method to the Madness: Applying an Intersectional Analysis of Structural Oppression and Power in HCI and Design",
      "abstract": "With increased focus on historically excluded populations, there have been recent calls for HCI research methods to more adequately acknowledge and address the historical context of racism, sexism, gendered racism, epistemic violence, classism, and so on. In this article, we utilize Black feminist epistemologies to serve as critical frameworks for understanding the historical context that reveals the interconnected systems of power that mutually influence one another to create unequal outcomes or social inequalities for different populations. Leveraging Black feminist thought (BFT) and intersectionality as critical social theories of design praxis, we introduce intersectional analysis of power\u2014a method that enables HCI researchers, designers, and practitioners to identify and situate saturated sites of violence in a historical context and to transform the ways in which they engage with populations that have been historically oppressed. Engaging in self-reflection as researchers, we apply an intersectional analysis of power to co-design technologies with community street outreach workers who address violence in their predominantly Black communities. We: (1) identify the saturated site of violence; (2) identify the intersecting systems of power and who holds power (past and present); (3) describe the \u201cconceptual glue\u201d that binds these intersecting systems together and the assumption(s) that those who hold power are employing to guide their interactions; (4) examine the ways in which Black people are subjugated, surveilled, and/or expected to assimilate to \u201cnormative\u201d ways of being and behaving; and (5) identify acts of resistance. This article contributes an alternative to traditional HCI and design methods that falsely perpetuate a lens of neutrality and colorblindness that centers on whiteness, innovation, and capitalism and ignores the history of State-sanctioned violence and structural oppression.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Sheena Erete et al.",
      "keywords": "Intersectionality; Oppression; Racism; Sociology; Praxis; Context (archaeology); Power (physics); Gender studies; Epistemology; Politics; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3507695",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4396920249",
      "doi": "10.1145/3659604",
      "title": "From Classification to Clinical Insights",
      "abstract": "Passively collected behavioral health data from ubiquitous sensors could provide mental health professionals valuable insights into patient's daily lives, but such efforts are impeded by disparate metrics, lack of interoperability, and unclear correlations between the measured signals and an individual's mental health. To address these challenges, we pioneer the exploration of large language models (LLMs) to synthesize clinically relevant insights from multi-sensor data. We develop chain-of-thought prompting methods to generate LLM reasoning on how data pertaining to activity, sleep and social interaction relate to conditions such as depression and anxiety. We then prompt the LLM to perform binary classification, achieving accuracies of 61.1%, exceeding the state of the art. We find models like GPT-4 correctly reference numerical data 75% of the time. While we began our investigation by developing methods to use LLMs to output binary classifications for conditions like depression, we find instead that their greatest potential value to clinicians lies not in diagnostic classification, but rather in rigorous analysis of diverse self-tracking data to generate natural language summaries that synthesize multiple data streams and identify potential concerns. Clinicians envisioned using these insights in a variety of ways, principally for fostering collaborative investigation with patients to strengthen the therapeutic alliance and guide treatment. We describe this collaborative engagement, additional envisioned uses, and associated concerns that must be addressed before adoption in real-world contexts.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Zachary Englhardt et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3659604",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226026693",
      "doi": "10.1145/3512901",
      "title": "Conversations About Crime: Re-Enforcing and Fighting Against Platformed Racism on Reddit",
      "abstract": "With the emergence of Information and Communication Technologies (ICTs), people are being exposed to an increased volume of crime-related information, which induces fear. While the fear of crime has been explored around people's experiences with crime, little is known about how people frame their conversations about crime online. In this study, we explore how citizens talk about crime on Reddit. By collecting crime conversations from the subreddit r/baltimore, we find that, on the surface, redditors discuss topics such as comparing crime rates in Baltimore with other cities in an effort to destigmatize the depictions of Baltimore as a city rife with crime. On a deeper level, we find that through their conversations about crime, redditors are engaging in discourse frames that both re-enforce and fight against platformed racism. On the one hand, some redditors perpetuate racially coded language that is rife with anti-Black stereotypes, framing their conversations using old and new racism to cover their racism and discrimination against Black people. On the other hand, others push back against platformed racism by drawing attention to individual racism and systemic racism, and situating crime in root, societal causes. We then discuss how platformed racism operates in online conversations, and develop the concepts of weaponized identity and digital gentrification, which we argue are ways in which people, through their engagements in digital platforms, continue to perpetuate white hegemonic power structures in society. Finally, we discuss implications for how to design to support the fight against platformed racism in sociotechnical systems like Reddit. As a content note and warning, this paper discusses racist content which may be upsetting or harmful to some readers.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Qunfang Wu et al.",
      "keywords": "Racism; Sociology; Framing (construction); Criminology; Gender studies; Media studies; History",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3512901",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3023222649",
      "doi": "10.1145/3380971",
      "title": "TDEFSI",
      "abstract": "Influenza-like illness (ILI) places a heavy social and economic burden on our society. Traditionally, ILI surveillance data are updated weekly and provided at a spatially coarse resolution. Producing timely and reliable high-resolution spatiotemporal forecasts for ILI is crucial for local preparedness and optimal interventions. We present T heory-guided D eep Learning-based E pidemic F orecasting with S ynthetic I nformation (TDEFSI), 1 an epidemic forecasting framework that integrates the strengths of deep neural networks and high-resolution simulations of epidemic processes over networks. TDEFSI yields accurate high-resolution spatiotemporal forecasts using low-resolution time-series data. During the training phase, TDEFSI uses high-resolution simulations of epidemics that explicitly model spatial and social heterogeneity inherent in urban regions as one component of training data. We train a two-branch recurrent neural network model to take both within-season and between-season low-resolution observations as features and output high-resolution detailed forecasts. The resulting forecasts are not just driven by observed data but also capture the intricate social, demographic, and geographic attributes of specific urban regions and mathematical theories of disease propagation over networks. We focus on forecasting the incidence of ILI and evaluate TDEFSI\u2019s performance using synthetic and real-world testing datasets at the state and county levels in the USA. The results show that, at the state level, our method achieves comparable/better performance than several state-of-the-art methods. At the county level, TDEFSI outperforms the other methods. The proposed method can be applied to other infectious diseases as well.",
      "year": "2020",
      "journal": "ACM Transactions on Spatial Algorithms and Systems",
      "authors": "Lijing Wang et al.",
      "keywords": "Computer science; Preparedness; Deep learning; Artificial intelligence; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3380971",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387329047",
      "doi": "10.1145/3610072",
      "title": "Investigating AI Teammate Communication Strategies and Their Impact in Human-AI Teams for Effective Teamwork",
      "abstract": "Recently, AI is integrating into teams to collaborate with humans as a teammate with the goal of achieving unprecedented team outcomes. Much of the coordination between humans and AI teammates relies on human-AI communication, which is challenging due to AI's limitations on natural language communication. Thus, it is essential to identify and develop effective communication strategies for AI teammates in human-AI teams to facilitate the coordination process. Through interviews with 60 participants who collaborated with an AI teammate in a multiplayer online game, in this paper, we explore communication strategies that humans expect AI teammates to apply to support human-AI coordination and collaboration in dyadic teaming environments, and how the AI teammate's communication can impact teaming processes. Our findings highlight four communication strategies AI teammates should apply to support their coordination with humans in dyadic teaming environments. We also find that AI teammates' proactive communication with humans could facilitate the development of human trust and situation awareness, whereas AI lacking such proactive communication is often not perceived as a teammate. Our study extends the current CSCW/HCI research on human-AI communication in teaming environments by shedding light on how communication should be structured in dyadic human-AI teams for effective and smooth collaboration.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Rui Zhang et al.",
      "keywords": "Teamwork; Computer science; Process (computing); Human communication; Knowledge management; Human\u2013computer interaction; Artificial intelligence; Psychology; Communication",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610072",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4376616686",
      "doi": "10.1145/3597199",
      "title": "What-is and How-to for Fairness in Machine Learning: A Survey, Reflection, and Perspective",
      "abstract": "We review and reflect on fairness notions proposed in machine learning literature and make an attempt to draw connections to arguments in moral and political philosophy, especially theories of justice. We survey dynamic fairness inquiries and further consider the long-term impact induced by current prediction and decision. We present a flowchart that encompasses implicit assumptions and expected outcomes of different fairness inquiries on the data-generating process, the predicted outcome, and the induced impact, respectively. We demonstrate the importance of matching the mission (what kind of fairness to enforce) and the means (which appropriate fairness spectrum to analyze) to fulfill the intended purpose.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Zeyu Tang et al.",
      "keywords": "Computer science; Perspective (graphical); Reflection (computer programming); Artificial intelligence; Machine learning; Data science; Programming language",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3597199",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3201365832",
      "doi": "10.1145/3477007",
      "title": "SNR: <u>S</u> queezing <u>N</u> umerical <u>R</u> ange Defuses Bit Error Vulnerability Surface in Deep Neural Networks",
      "abstract": "As deep learning algorithms are widely adopted, an increasing number of them are positioned in embedded application domains with strict reliability constraints. The expenditure of significant resources to satisfy performance requirements in deep neural network accelerators has thinned out the margins for delivering safety in embedded deep learning applications, thus precluding the adoption of conventional fault tolerance methods. The potential of exploiting the inherent resilience characteristics of deep neural networks remains though unexplored, offering a promising low-cost path towards safety in embedded deep learning applications. This work demonstrates the possibility of such exploitation by juxtaposing the reduction of the vulnerability surface through the proper design of the quantization schemes with shaping the parameter distributions at each layer through the guidance offered by appropriate training methods, thus delivering deep neural networks of high resilience merely through algorithmic modifications. Unequaled error resilience characteristics can be thus injected into safety-critical deep learning applications to tolerate bit error rates of up to at absolutely zero hardware, energy, and performance costs while improving the error-free model accuracy even further.",
      "year": "2021",
      "journal": "ACM Transactions on Embedded Computing Systems",
      "authors": "Elbruz Ozen et al.",
      "keywords": "Deep learning; Computer science; Artificial neural network; Resilience (materials science); Vulnerability (computing); Artificial intelligence; Deep neural networks; Computer engineering; Reliability engineering; Reduction (mathematics); Reliability (semiconductor); Machine learning; Real-time computing; Computer security; Power (physics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3477007",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3039518923",
      "doi": "10.1145/3406772",
      "title": "Retention in Computer Science Undergraduate Programs in the U.S.",
      "abstract": "",
      "year": "2018",
      "journal": "ACM eBooks",
      "authors": "Chris Stephenson et al.",
      "keywords": "Computer science; Mathematics education; Psychology",
      "mesh_terms": "",
      "pub_types": "book",
      "url": "https://doi.org/10.1145/3406772",
      "cited_by_count": 51,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386348070",
      "doi": "10.1145/3610209",
      "title": "Sociotechnical Audits: Broadening the Algorithm Auditing Lens to Investigate Targeted Advertising",
      "abstract": "Algorithm audits are powerful tools for studying black-box systems without direct knowledge of their inner workings. While very effective in examining technical components, the method stops short of a sociotechnical frame, which would also consider users themselves as an integral and dynamic part of the system. Addressing this limitation, we propose the concept of sociotechnical auditing: auditing methods that evaluate algorithmic systems at the sociotechnical level, focusing on the interplay between algorithms and users as each impacts the other. Just as algorithm audits probe an algorithm with varied inputs and observe outputs, a sociotechnical audit (STA) additionally probes users, exposing them to different algorithmic behavior and measuring their resulting attitudes and behaviors. As an example of this method, we develop Intervenr, a platform for conducting browser-based, longitudinal sociotechnical audits with consenting, compensated participants. Intervenr investigates the algorithmic content users encounter online, and also coordinates systematic client-side interventions to understand how users change in response. As a case study, we deploy Intervenr in a two-week sociotechnical audit of online advertising (N = 244) to investigate the central premise that personalized ad targeting is more effective on users. In the first week, we observe and collect all browser ads delivered to users, and in the second, we deploy an ablation-style intervention that disrupts normal targeting by randomly pairing participants and swapping all their ads. We collect user-oriented metrics (self-reported ad interest and feeling of representation) and advertiser-oriented metrics (ad views, clicks, and recognition) throughout, along with a total of over 500,000 ads. Our STA finds that targeted ads indeed perform better with users, but also that users begin to acclimate to different ads in only a week, casting doubt on the primacy of personalized ad targeting given the impact of repeated exposure. In comparison with other evaluation methods that only study technical components, or only experiment on users, sociotechnical audits evaluate sociotechnical systems through the interplay of their technical and human components.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Michelle S. Lam et al.",
      "keywords": "Sociotechnical system; Audit; Computer science; Algorithm; Knowledge management; Accounting; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610209",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3158801326",
      "doi": "10.1145/3428157",
      "title": "A Perfect Storm",
      "abstract": "In an age where news information is created by millions and consumed by billions over social media ( SM ) every day, issues of information biases, fake news, and echo-chambers have dominated the corridors of technology firms, news corporations, policy makers, and society. While multiple disciplines have tried to tackle the issue using their disciplinary lenses, there has, hitherto, been no integrative model that surface the intricate, albeit \u201cdark\u201d explainable AI confluence of both technology and psychology. Investigating information bias anchoring as the overarching phenomenon, this research proposes a theoretical framework that brings together traditionally fragmented domains of AI technology, and human psychology. The proposed Information Bias Anchoring Model reveals how SM news information creates an information deluge leading to uncertainty, and how technological rationality and individual biases intersect to mitigate the uncertainty, often leading to news information biases. The research ends with a discussion of contributions and offering to reduce information bias anchoring.",
      "year": "2021",
      "journal": "Digital Threats Research and Practice",
      "authors": "Pratim Datta et al.",
      "keywords": "Anchoring; Rationality; Phenomenon; Data science; Discipline; Social media; Psychology; Sociology; Public relations; Epistemology; Positive economics; Computer science; Political science; Social psychology; Economics; Social science; World Wide Web; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3428157",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4323651873",
      "doi": "10.1145/3579610",
      "title": "Having your Privacy Cake and Eating it Too: Platform-supported Auditing of Social Media Algorithms for Public Interest",
      "abstract": "Social media platforms curate access to information and opportunities, and so play a critical role in shaping public discourse today. The opaque nature of the algorithms these platforms use to curate content raises societal questions. Prior studies have used black-box methods led by experts or collaborative audits driven by everyday users to show that these algorithms can lead to biased or discriminatory outcomes. However, existing auditing methods face fundamental limitations because they function independent of the platforms. Concerns of potential harmful outcomes have prompted proposal of legislation in both the U.S. and the E.U. to mandate a new form of auditing where vetted external researchers get privileged access to social media platforms. Unfortunately, to date there have been no concrete technical proposals to provide such auditing, because auditing at scale risks disclosure of users' private data and platforms' proprietary algorithms. We propose a new method for platform-supported auditing that can meet the goals of the proposed legislation. The first contribution of our work is to enumerate the challenges and the limitations of existing auditing methods to implement these policies at scale. Second, we suggest that limited, privileged access to relevance estimators is the key to enabling generalizable platform-supported auditing of social media platforms by external researchers. Third, we show platform-supported auditing need not risk user privacy nor disclosure of platforms' business interests by proposing an auditing framework that protects against these risks. For a particular fairness metric, we show that ensuring privacy imposes only a small constant factor increase (6.34x as an upper bound, and 4\u00d7 for typical parameters) in the number of samples required for accurate auditing. Our technical contributions, combined with ongoing legal and policy efforts, can enable public oversight into how social media platforms affect individuals and society by moving past the privacy-vs-transparency hurdle.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Basileal Imana et al.",
      "keywords": "Audit; Social media; Computer science; Internet privacy; Mandate; Computer security; Business; World Wide Web; Accounting; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579610",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2986671035",
      "doi": "10.1145/3359216",
      "title": "Passively-sensed Behavioral Correlates of Discrimination Events in College Students",
      "abstract": "A deep understanding of how discrimination impacts psychological health and well-being of students could allow us to better protect individuals at risk and support those who encounter discrimination. While the link between discrimination and diminished psychological and physical well-being is well established, existing research largely focuses on chronic discrimination and long-term outcomes. A better understanding of the short-term behavioral correlates of discrimination events could help us to concretely quantify such experiences, which in turn could support policy and intervention design. In this paper we specifically examine, for the first time, what behaviors change and in what ways in relation to discrimination. We use actively-reported and passively-measured markers of health and well-being in a sample of 209 first-year college students over the course of two academic quarters. We examine changes in indicators of psychological state in relation to reports of unfair treatment in terms of five categories of behaviors: physical activity, phone usage, social interaction, mobility, and sleep. We find that students who encounter unfair treatment become more physically active, interact more with their phone in the morning, make more calls in the evening, and spend more time in bed on the day of the event. Some of these patterns continue the next day. Our results further our understanding of the impact of discrimination and can inform intervention work.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Yasaman S. Sefidgar et al.",
      "keywords": "Psychology; Intervention (counseling); Phone; Sample (material); Evening; Applied psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359216",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4397022293",
      "doi": "10.1145/3664615",
      "title": "A Unified Review of Deep Learning for Automated Medical Coding",
      "abstract": "Automated medical coding, an essential task for healthcare operation and delivery, makes unstructured data manageable by predicting medical codes from clinical documents. Recent advances in deep learning and natural language processing have been widely applied to this task. However, deep learning\u2013based medical coding lacks a unified view of the design of neural network architectures. This review proposes a unified framework to provide a general understanding of the building blocks of medical coding models and summarizes recent advanced models under the proposed framework. Our unified framework decomposes medical coding into four main components, i.e., encoder modules for text feature extraction, mechanisms for building deep encoder architectures, decoder modules for transforming hidden representations into medical codes, and the usage of auxiliary information. Finally, we introduce the benchmarks and real-world usage and discuss key research challenges and future directions.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Shaoxiong Ji et al.",
      "keywords": "Computer science; Coding (social sciences); Deep learning; Encoder; Artificial intelligence; Task (project management); Machine learning; Systems engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3664615",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4361271596",
      "doi": "10.1145/3589784",
      "title": "Detecting Mental Distresses Using Social Behavior Analysis in the Context of COVID-19: A Survey",
      "abstract": "Online social media provides a channel for monitoring people\u2019s social behaviors from which to infer and detect their mental distresses. During the COVID-19 pandemic, online social networks were increasingly used to express opinions, views, and moods due to the restrictions on physical activities and in-person meetings, leading to a significant amount of diverse user-generated social media content. This offers a unique opportunity to examine how COVID-19 changed global behaviors regarding its ramifications on mental well-being. In this article, we surveyed the literature on social media analysis for the detection of mental distress, with a special emphasis on the studies published since the COVID-19 outbreak. We analyze relevant research and its characteristics and propose new approaches to organizing the large amount of studies arising from this emerging research area, thus drawing new views, insights, and knowledge for interested communities. Specifically, we first classify the studies in terms of feature extraction types, language usage patterns, aesthetic preferences, and online behaviors. We then explored various methods (including machine learning and deep learning techniques) for detecting mental health problems. Building upon the in-depth review, we present our findings and discuss future research directions and niche areas in detecting mental health problems using social media data. We also elaborate on the challenges of this fast-growing research area, such as technical issues in deploying such systems at scale as well as privacy and ethical concerns.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Sahraoui Dhelim et al.",
      "keywords": "Social media; Computer science; Mental health; Context (archaeology); Data science; Internet privacy; Coronavirus disease 2019 (COVID-19); World Wide Web; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3589784",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387331356",
      "doi": "10.1145/3610169",
      "title": "\"Honestly, I Think TikTok has a Vendetta Against Black Creators\": Understanding Black Content Creator Experiences on TikTok",
      "abstract": "As video-sharing social-media platforms have increased in popularity, a 'creator economy' has emerged in which platform users make online content to share with wide audiences, often for profit. As the creator economy has risen in popularity, so have concerns of racism and discrimination on social media. Black content creators across multiple platforms have identified challenges with racism and discrimination, perpetuated by platform users, companies that collaborate with creators for sponsored content, and the algorithms governing these platforms. In this work, we provide a qualitative study of the experiences of Black content creators on one video-sharing platform, TikTok. We conduct 12 semi-structured interviews with Black TikTok content creators to understand their experiences, identify the challenges they face, and understand their perceptions of the platform. We find that some common challenges include: content moderation, monetization, harassment and bullying from viewers, lack of transparency of recommendation and filtering algorithms, and the perception that content from Black creators is treated unfairly by those algorithms. We then suggest design interventions to mitigate the challenges, bolster positive aspects, and overall cultivate an inclusive algorithmic experience for Black creators on TikTok",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Camille Harris et al.",
      "keywords": "Monetization; Social media; Popularity; Internet privacy; Boycott; Content analysis; Transparency (behavior); Public relations; Sociology; World Wide Web; Advertising; Computer science; Politics; Political science; Business; Law; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610169",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3093664790",
      "doi": "10.1145/3415172",
      "title": "Informational Friction as a Lens for Studying Algorithmic Aspects of Privacy",
      "abstract": "This paper addresses challenges in conceptualizing privacy posed by algorithmic systems that can infer sensitive information from seemingly innocuous data. This type of privacy is of imminent concern due to the rapid adoption of machine learning and artificial intelligence systems in virtually every industry. In this paper, we suggest informational friction, a concept from Floridi's ethics of information, as a valuable conceptual lens for studying algorithmic aspects of privacy. Informational friction describes the amount of work required for one agent to access or alter the information of another. By focusing on amount of work, rather than the type of information or manner in which it is collected, informational friction can help to explain why automated analyses should raise privacy concerns independently of, and in addition to, those associated with data collection. As a demonstration, this paper analyze law enforcement use of facial recognition, andFacebook's targeted advertising model using informational friction and demonstrate risks inherent to these systems which are not completely identified in another popular framework, Nissenbaum's Contextual Integrity.The paper concludes with a discussion of broader implications, both for privacy research and for privacy regulation.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Patrick Skeba et al.",
      "keywords": "Through-the-lens metering; Computer science; Law enforcement; Privacy by Design; Information privacy; Work (physics); Internet privacy; Enforcement; Lens (geology); Computer security; Data science; Engineering; Political science; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3415172",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2904160032",
      "doi": "10.1145/3241044",
      "title": "Responding to Sensitive Disclosures on Social Media",
      "abstract": "When people disclose information on social media that is sensitive or potentially stigmatized (e.g., mental illness, pregnancy loss), how do others decide to respond? We use interviews and vignettes to provide a response decision-making framework (RDM) that explains factors informing whether and how individuals respond to sensitive disclosures from their social media connections. The RDM framework includes factors related to the self, poster, and disclosure context (i.e., relational, temporal, social). Our findings include how people's decisions are complicated by balancing their own needs (e.g., privacy, wellbeing) as well as the posters\u2019 (e.g., support) when seeing what they consider sensitive posts on social media. We identify empirically grounded insights and information that social media designs could surface to support both potential disclosers and responders. We argue that social media sites should provide privacy controls for both disclosers and responders, and facilitate the visibility of network-level support.",
      "year": "2018",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Nazanin Andalibi et al.",
      "keywords": "RDM; Social media; Psychology; Context (archaeology); Visibility; Self-disclosure; Internet privacy; Social psychology; Computer science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3241044",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391540800",
      "doi": "10.1145/3643859",
      "title": "Boosting Healthiness Exposure in Category-Constrained Meal Recommendation Using Nutritional Standards",
      "abstract": "Food computing, a newly emerging topic, is closely linked to human life through computational methodologies. Meal recommendation, a food-related study about human health, aims to provide users a meal with courses constrained from specific categories (e.g., appetizers, main dishes) that can be enjoyed as a service. Historical interaction data, important user information, is often used by existing models to learn user preferences. However, if a user\u2019s preferences favor less healthy meals, the model will follow that preference and make similar recommendations, potentially negatively impacting the user\u2019s long-term health. This emphasizes the necessity for health-oriented and responsible meal recommendation systems. In this article, we propose a healthiness-aware and category-wise meal recommendation model called CateRec, which boosts healthiness exposure by using nutritional standards as knowledge to guide the model training. Two fundamental questions are raised and answered: (1) How can the healthiness of meals be evaluated? Two well-known nutritional standards from the World Health Organization and the United Kingdom Food Standards Agency are used to calculate the healthiness score of the meal. (2) How can the model training be guided in a health-oriented manner? We construct category-wise personalization partial rankings and category-wise healthiness partial rankings, and theoretically analyze that they meet the necessary properties and assumptions required to be trained by the maximum posterior estimator under Bayesian probability. The data analysis confirms the existence of user preferences leaning towards less healthy meals in two public datasets. A comprehensive experiment demonstrates that our CateRec effectively boosts healthiness exposure in terms of mean healthiness score and ranking exposure while being comparable to the state-of-the-art model in terms of recommendation accuracy.",
      "year": "2024",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Ming Li et al.",
      "keywords": "Computer science; Boosting (machine learning); Artificial intelligence; Meal; Machine learning; Food science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643859",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4363677096",
      "doi": "10.1145/3591869",
      "title": "<scp>TestSGD</scp> : Interpretable Testing of Neural Networks against Subtle Group Discrimination",
      "abstract": "Discrimination has been shown in many machine learning applications, which calls for sufficient fairness testing before their deployment in ethic-relevant domains. One widely concerning type of discrimination, testing against group discrimination, mostly hidden , is much less studied, compared with identifying individual discrimination . In this work, we propose TestSGD , an interpretable testing approach that systematically identifies and measures hidden (which we call \u201csubtle\u201d) group discrimination of a neural network characterized by conditions over combinations of the sensitive attributes . Specifically, given a neural network, TestSGD first automatically generates an interpretable rule set that categorizes the input space into two groups. Alongside, TestSGD also provides an estimated group discrimination score based on sampling the input space to measure the degree of the identified subtle group discrimination, which is guaranteed to be accurate up to an error bound. We evaluate TestSGD on multiple neural network models trained on popular datasets including both structured data and text data. The experiment results show that TestSGD is effective and efficient in identifying and measuring such subtle group discrimination that has never been revealed before. Furthermore, we show that the testing results of TestSGD can be used to mitigate such discrimination through retraining with negligible accuracy drop.",
      "year": "2023",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Mengdi Zhang et al.",
      "keywords": "Retraining; Computer science; Artificial neural network; Artificial intelligence; Machine learning; Set (abstract data type); Space (punctuation); Deep neural networks; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3591869",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4289255339",
      "doi": "10.1145/3274414",
      "title": "Socio-spatial Self-organizing Maps",
      "abstract": "Social media offers a unique window into attitudes like racism and homophobia, exposure to which are important, hard to measure and understudied social determinants of health. However, individual geo-located observations from social media are noisy and geographically inconsistent. Existing areas by which exposures are measured, like Zip codes, average over irrelevant administratively-defined boundaries. Hence, in order to enable studies of online social environmental measures like attitudes on social media and their possible relationship to health outcomes, first there is a need for a method to define the collective, underlying degree of social media attitudes by region. To address this, we create the Socio-spatial-Self organizing map, \"SS-SOM\" pipeline to best identify regions by their latent social attitude from Twitter posts. SS-SOMs use neural embedding for text-classification, and augment traditional SOMs to generate a controlled number of non-overlapping, topologically-constrained and topically-similar clusters. We find that not only are SS-SOMs robust to missing data, the exposure of a cohort of men who are susceptible to multiple racism and homophobia-linked health outcomes, changes by up to 42% using SS-SOM measures as compared to using Zip code-based measures.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Kunal Relia et al.",
      "keywords": "Social media; Pipeline (software); Code (set theory); Computer science; Racism; Psychology; Artificial intelligence; Sociology; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274414",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225919440",
      "doi": "10.1145/3512980",
      "title": "Veteran Critical Theory as a Lens to Understand Veterans' Needs and Support on Social Media",
      "abstract": "Veterans are a unique marginalized group facing multiple vulnerabilities. Current assessments of veteran needs and support largely come from first-person accounts guided by researchers' prompts. Social media platforms not only enable veterans to connect with each other, but also to self-disclose experiences and seek support. This paper addresses the gap in our understanding of veteran needs and their own support dynamics by examining self-initiated and ecologically-valid self-expressions. In particular, we adopt the Veteran Critical Theory (VCT) to conduct a computational study on the Reddit community of veterans. Using topic modeling, we find veteran-friendly gestures with good intentions might not be appreciated in the subreddit. By employing transfer learning methodologies, we find this community has more informational and emotional support behaviors than general online communities and a higher prevalence of informational support than emotional support. Lastly, an examination of support dynamics reveals some contrasts to previous scholarship in military culture and social media. We discover that positive language and author platform tenure have negative relations with posts receiving replies and replies getting votes, and that replies reflecting personal disclosures tend to get more votes. Through the lens of VCT, we discuss how online communities can help uncover veterans' needs and provide more effective social support.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Jiawei Zhou et al.",
      "keywords": "Scholarship; Social media; Through-the-lens metering; Psychology; Social support; Public relations; Social psychology; Lens (geology); Computer science; Political science; World Wide Web; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3512980",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387329158",
      "doi": "10.1145/3610195",
      "title": "Marginalization and the Construction of Mental Illness Narratives Online: Foregrounding Institutions in Technology-Mediated Care",
      "abstract": "People experiencing mental illness are often forced into a system in which their chances of finding relief are largely determined by institutions that evaluate whether their distress deserves treatment. These governing institutions can be offline, such as the American healthcare system, and can also be online, such as online social platforms. As work in Human-Computer Interaction (HCI) and Computer Supported Cooperative Work (CSCW) frames technology-mediated support as one method to fill structural gaps in care, in this study, we ask the question: how do online and offline institutions influence how people in resource-scarce areas understand and express their distress online? We situate our work in U.S. Mental Health Professional Shortage Areas (MHPSAs), or areas in which there are too few mental health professionals to meet expected needs. We use an analysis of illness narratives to answer this question, conducting a large scale linguistic analysis of social media posts to understand broader trends in expressions of distress online. We then build on these analyses via in-depth interviews with 18 participants with lived experience of mental illness, analyzing the role of online and offline institutions in how participants express distress online. Through our findings, we argue that a consideration of institutions is crucial in designing effective technology-mediated support, and discuss the implications of considering institutions in mental health support for platform designers.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Sachin R. Pendse et al.",
      "keywords": "Foregrounding; Mental health; Computer-supported cooperative work; Mental distress; Mental illness; Narrative; Online and offline; Distress; Psychology; Work (physics); Online participation; Public relations; Sociology; The Internet; Political science; Computer science; Psychiatry; Psychotherapist; Engineering; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610195",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2882995261",
      "doi": "10.1145/3185516",
      "title": "An Active Sleep Monitoring Framework Using Wearables",
      "abstract": "Sleep is the most important aspect of healthy and active living. The right amount of sleep at the right time helps an individual to protect his or her physical, mental, and cognitive health and maintain his or her quality of life. The most durative of the Activities of Daily Living (ADL), sleep has a major synergic influence on a person\u2019s fuctional, behavioral, and cognitive health. A deep understanding of sleep behavior and its relationship with its physiological signals, and contexts (such as eye or body movements), is necessary to design and develop a robust intelligent sleep monitoring system. In this article, we propose an intelligent algorithm to detect the microscopic states of sleep that fundamentally constitute the components of good and bad sleeping behaviors and thus help shape the formative assessment of sleep quality. Our initial analysis includes the investigation of several classification techniques to identify and correlate the relationship of microscopic sleep states with overall sleep behavior. Subsequently, we also propose an online algorithm based on change point detection to process and classify the microscopic sleep states. We also develop a lightweight version of the proposed algorithm for real-time sleep monitoring, recognition, and assessment at scale. For a larger deployment of our proposed model across a community of individuals, we propose an active-learning-based methodology to reduce the effort of ground-truth data collection and labeling. Finally, we evaluate the performance of our proposed algorithms on real data traces and demonstrate the efficacy of our models for detecting and assessing the fine-grained sleep states beyond an individual.",
      "year": "2018",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "H M Sajjad Hossain et al.",
      "keywords": "Sleep (system call); Wearable computer; Software deployment; Computer science; Formative assessment; Cognition; Process (computing); Machine learning; Artificial intelligence; Ground truth; Sleep quality; Scale (ratio); Human\u2013computer interaction; Psychology; Psychiatry; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3185516",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4324088968",
      "doi": "10.1145/3582927",
      "title": "The Many Faces of Monetisation: Understanding the Diversity and Extremity of Player Spending in Mobile Games via Massive-scale Transactional Analysis",
      "abstract": "With the rise of microtransactions, particularly in the mobile games industry, there has been ongoing concern that games reliant on these obtain substantial revenue from a small proportion of heavily involved individuals, to an extent that may be financially burdensome to these individuals. Yet despite substantive grey literature and speculation on this topic, there is little robust data available. We explore the revenue distribution in microtransaction-based mobile games using a transactional dataset of $4.7B in in-game spending drawn from 69,144,363 players of 2,873 mobile games over the course of 624 days. We find diverse revenue distributions in mobile games, ranging from a \u201cuniform\u201d cluster, in which all spenders invest approximately similar amounts, to \u201chyper-Pareto\u201d games, in which a large proportion of revenue (approximately 38%) stems from 1% of spenders alone. Specific kinds of games are typified by higher spending: The more a game relies on its top 1% for revenue generation, the more these individuals tend to spend, with simulated gambling products (\u201csocial casinos\u201d) at the top. We find a small subset of games across all genres, clusters, and age ratings in which the top 1% of gamers are highly financially involved\u2014spending an average of $66,285 each in the 624 days under evaluation in the most extreme case. We discuss implications for future studies on links between gaming and wellbeing.",
      "year": "2023",
      "journal": "Games Research and Practice",
      "authors": "David Zendle et al.",
      "keywords": "Revenue; Transactional leadership; Diversity (politics); Scale (ratio); Pareto principle; Advertising; Business; Economics; Marketing; Microeconomics; Finance; Sociology; Geography; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3582927",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4365999247",
      "doi": "10.1145/3579488",
      "title": "From Human to Data to Dataset: Mapping the Traceability of Human Subjects in Computer Vision Datasets",
      "abstract": "Computer vision is a \"data hungry\" field. Researchers and practitioners who work on human-centric computer vision, like facial recognition, emphasize the necessity of vast amounts of data for more robust and accurate models. Humans are seen as a data resource which can be converted into datasets. The necessity of data has led to a proliferation of gathering data from easily available sources, including \"public\" data from the web. Yet the use of public data has significant ethical implications for the human subjects in datasets. We bridge academic conversations on the ethics of using publicly obtained data with concerns about privacy and agency associated with computer vision applications. Specifically, we examine how practices of dataset construction from public data-not only from websites, but also from public settings and public records-make it extremely difficult for human subjects to trace their images as they are collected, converted into datasets, distributed for use, and, in some cases, retracted. We discuss two interconnected barriers current data practices present to providing an ethics of traceability for human subjects: awareness and control. We conclude with key intervention points for enabling traceability for data subjects. We also offer suggestions for an improved ethics of traceability to enable both awareness and control for individual subjects in dataset curation practices.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Morgan Klaus Scheuerman et al.",
      "keywords": "Traceability; Computer science; Data science; Agency (philosophy); Field (mathematics); Data collection",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579488",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387999295",
      "doi": "10.1145/3629170",
      "title": "Exploring the Landscape of Recommender Systems Evaluation: Practices and Perspectives",
      "abstract": "Recommender systems research and practice are fast-developing topics with growing adoption in a wide variety of information access scenarios. In this article, we present an overview of research specifically focused on the evaluation of recommender systems. We perform a systematic literature review, in which we analyze 57 papers spanning six years (2017\u20132022). Focusing on the processes surrounding evaluation, we dial in on the methods applied, the datasets utilized, and the metrics used. Our study shows that the predominant experiment type in research on the evaluation of recommender systems is offline experimentation and that online evaluations are primarily used in combination with other experimentation methods, e.g., an offline experiment. Furthermore, we find that only a few datasets (MovieLens, Amazon review dataset) are widely used, while many datasets are used in only a few papers each. We observe a similar scenario when analyzing the employed performance metrics\u2014a few metrics are widely used (precision, normalized Discounted Cumulative Gain, and Recall), while many others are used in only a few papers. Overall, our review indicates that beyond-accuracy qualities are rarely assessed. Our analysis shows that the research community working on evaluation has focused on the development of evaluation in a rather narrow scope, with the majority of experiments focusing on a few metrics, datasets, and methods.",
      "year": "2023",
      "journal": "ACM Transactions on Recommender Systems",
      "authors": "Christine Bauer et al.",
      "keywords": "MovieLens; Computer science; Recommender system; Variety (cybernetics); Data science; Scope (computer science); Precision and recall; Collaborative filtering; Information retrieval; Machine learning; Data mining; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3629170",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387344951",
      "doi": "10.1145/3610183",
      "title": "Crowdsourcing Subjective Annotations Using Pairwise Comparisons Reduces Bias and Error Compared to the Majority-vote Method",
      "abstract": "How to better reduce measurement variability and bias introduced by subjectivity in crowdsourced labelling remains an open question. We introduce a theoretical framework for understanding how random error and measurement bias enter into crowdsourced annotations of subjective constructs. We then propose a pipeline that combines pairwise comparison labelling with Elo scoring, and demonstrate that it outperforms the ubiquitous majority-voting method in reducing both types of measurement error. To assess the performance of the labelling approaches, we constructed an agent-based model of crowdsourced labelling that lets us introduce different types of subjectivity into the tasks. We find that under most conditions with task subjectivity, the comparison approach produced higher f1 scores. Further, the comparison approach is less susceptible to inflating bias, which majority voting tends to do. To facilitate applications, we show with simulated and real-world data that the number of required random comparisons for the same classification accuracy scales log-linearly O(N log N) with the number of labelled items. We also implemented the Elo system as an open-source Python package.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Hasti Narimanzadeh et al.",
      "keywords": "Crowdsourcing; Pairwise comparison; Computer science; Majority rule; Python (programming language); Voting; Subjectivity; Pipeline (software); Artificial intelligence; Machine learning; Data mining; Natural language processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610183",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391103901",
      "doi": "10.1145/3641552",
      "title": "Co-ML: Collaborative Machine Learning Model Building for Developing Dataset Design Practices",
      "abstract": "Machine learning (ML) models are fundamentally shaped by data, and building inclusive ML systems requires significant considerations around how to design representative datasets. Yet, few novice-oriented ML modeling tools are designed to foster hands-on learning of dataset design practices, including how to design for data diversity and inspect for data quality. To this end, we outline a set of four data design practices (DDPs) for designing inclusive ML models and share how we designed a tablet-based application called Co-ML to foster learning of DDPs through a collaborative ML model building experience. With Co-ML, beginners can build image classifiers through a distributed experience where data is synchronized across multiple devices, enabling multiple users to iteratively refine ML datasets in discussion and coordination with their peers. We deployed Co-ML in a 2-week-long educational AIML Summer Camp, where youth ages 13\u201318 worked in groups to build custom ML-powered mobile applications. Our analysis reveals how multi-user model building with Co-ML, in the context of student-driven projects created during the summer camp, supported development of DDPs including incorporating data diversity, evaluating model performance, and inspecting for data quality. Additionally, we found that students\u2019 attempts to improve model performance often prioritized learnability over class balance. Through this work, we highlight how the combination of collaboration, model testing interfaces, and student-driven projects can empower learners to actively engage in exploring the role of data in ML systems.",
      "year": "2024",
      "journal": "ACM Transactions on Computing Education",
      "authors": "Tiffany Tseng et al.",
      "keywords": "Computer science; Context (archaeology); Learnability; Machine learning; Collaborative learning; Artificial intelligence; Human\u2013computer interaction; Knowledge management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3641552",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4395033024",
      "doi": "10.1145/3660645",
      "title": "\u201cShow Them the Playbook That These Companies Are Using\u201d: Youth Voices about Why Computer Science Education Must Center Discussions of Power, Ethics, and Culturally Responsive Computing",
      "abstract": "Culturally responsive computing (CRC), that centers sociopolitical issues and transformational uses of technology, has been described as valuable for increasing engagement with computing, especially for historically underrepresented minoritized students. But what do high school students think? Through a sociocultural lens prioritizing student voices recorded in 56 interviews over a period of 2 years (1\u20133 years after students\u2019 first experience with computer science (CS) education through Exploring Computer Science or Advanced Placement CS Principles in high school), this study centers the perspectives of 39 primarily low-income, Latine and Black youth from urban California and rural Mississippi public schools to understand what they perceive as the role of technology in our world and what they subsequently desire of their computing education. While none have studied CRC before, the majority responded with CRC ideas about the kind of pedagogy they believe would make for a more meaningful computing learning experience: They see computing as a form of power that impacts both good and bad in the world and want computing educators to prepare them to take on these issues of equity, ethics, social responsibility, and underrepresentation in the field. The students\u2019 perspectives offer important pedagogical insight into how to support deeper engagement with computing in current CS for All initiatives, while also preparing youth for the rapidly evolving and increasingly complex computing landscape that impacts all of our lives.",
      "year": "2024",
      "journal": "ACM Transactions on Computing Education",
      "authors": "Jean J. Ryoo et al.",
      "keywords": "Center (category theory); Power (physics); Computer science; Mathematics education; Power structure; Pedagogy; Sociology; Knowledge management; Engineering ethics; Psychology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3660645",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390817987",
      "doi": "10.1145/3633808",
      "title": "PASTEL",
      "abstract": "Federated Learning (FL) aims to improve machine learning privacy by allowing several data owners in edge and ubiquitous computing systems to collaboratively train a model, while preserving their local training data private, and sharing only model training parameters. However, FL systems remain vulnerable to privacy attacks, and in particular, to membership inference attacks that allow adversaries to determine whether a given data sample belongs to participants' training data, thus, raising a significant threat in sensitive ubiquitous computing systems. Indeed, membership inference attacks are based on a binary classifier that is able to differentiate between member data samples used to train a model and non-member data samples not used for training. In this context, several defense mechanisms, including differential privacy, have been proposed to counter such privacy attacks. However, the main drawback of these methods is that they may reduce model accuracy while incurring non-negligible computational costs. In this paper, we precisely address this problem with PASTEL, a FL privacy-preserving mechanism that is based on a novel multi-objective learning function. On the one hand, PASTEL decreases the generalization gap to reduce the difference between member data and non-member data, and on the other hand, PASTEL reduces model loss and leverages adaptive gradient descent optimization for preserving high model accuracy. Our experimental evaluations conducted on eight widely used datasets and five model architectures show that PASTEL significantly reduces membership inference attack success rates by up to -28%, reaching optimal privacy protection in most cases, with low to no perceptible impact on model accuracy.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Fatima Elhattab et al.",
      "keywords": "Computer science; Differential privacy; Inference; Artificial intelligence; Machine learning; Classifier (UML); Sample (material); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3633808",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386928422",
      "doi": "10.1145/3623401",
      "title": "Enabling Graph Neural Networks for Semi-Supervised Risk Prediction in Online Credit Loan Services",
      "abstract": "Graph neural networks (GNNs) are playing exciting roles in the application scenarios where features are hidden in information associations. Fraud prediction of online credit loan services (OCLSs) is such a typical scenario. But it has another rather critical challenge, i.e., the scarcity of data labels. Fortunately, GNNs can also cope with this problem due to their good ability of semi-supervised learning by mining structure and feature information within graphs. Nevertheless, the gain of internal information is often too limited to help GNNs handle the extreme deficiency of labels with high performance beyond the basic requirement of fraud prediction in OCLSs. Therefore, adding labels from the experts, such as manually adding labels through rules, has become a logical practice. However, the existing rule engines for OCLSs have the confliction problem among continuously accumulated rules. To address this issue, we propose a Snorkel-based Semi-Supervised GNN (S3GNN). Under S3GNN, we specially design an upgraded version of the rule engines, called Graph-Oriented Snorkel (GOS), a graph-specific extension of Snorkel, a widely used weakly supervised learning framework, to design rules by subject matter experts (SMEs) and resolve confliction. In particular, in the graph of an anti-fraud scenario, each node pair may have multiple different types of edges, so we propose the Multiple Edge-Types Based Attention mechanism. In general, for the heterogeneous information and multiple relations in the graph, we first obtain the embedding of applicant nodes by aggregating the representation of attribute nodes, and then use the attention mechanism to aggregate neighbor nodes on multiple meta-paths to get ultimate applicant node embedding. We conduct experiments over the real-life data of a large financial platform. The results demonstrate that S3GNN can outperform the state-of-the-art methods, including the method of pilot platform.",
      "year": "2023",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Hao Tang et al.",
      "keywords": "Computer science; Loan; Artificial neural network; Graph; Artificial intelligence; Machine learning; Credit risk; Finance; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3623401",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385959933",
      "doi": "10.1145/3610887",
      "title": "Privacy against Real-Time Speech Emotion Detection via Acoustic Adversarial Evasion of Machine Learning",
      "abstract": "Smart speaker voice assistants (VAs) such as Amazon Echo and Google Home have been widely adopted due to their seamless integration with smart home devices and the Internet of Things (IoT) technologies. These VA services raise privacy concerns, especially due to their access to our speech. This work considers one such use case: the unaccountable and unauthorized surveillance of a user's emotion via speech emotion recognition (SER). This paper presents DARE-GP, a solution that creates additive noise to mask users' emotional information while preserving the transcription-relevant portions of their speech. DARE-GP does this by using a constrained genetic programming approach to learn the spectral frequency traits that depict target users' emotional content, and then generating a universal adversarial audio perturbation that provides this privacy protection. Unlike existing works, DARE-GP provides: a) real-time protection of previously unheard utterances, b) against previously unseen black-box SER classifiers, c) while protecting speech transcription, and d) does so in a realistic, acoustic environment. Further, this evasion is robust against defenses employed by a knowledgeable adversary. The evaluations in this work culminate with acoustic evaluations against two off-the-shelf commercial smart speakers using a small-form-factor (raspberry pi) integrated with a wake-word system to evaluate the efficacy of its real-world, real-time deployment.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Brian Testa et al.",
      "keywords": "Computer science; Adversarial system; Voice activity detection; Adversary; Speech recognition; Computer security; Software deployment; Evasion (ethics); Internet privacy; Machine learning; Human\u2013computer interaction; Artificial intelligence; Speech processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610887",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4309617707",
      "doi": "10.1145/3555176",
      "title": "Community-in-the-loop: Creating Artificial Process Intelligence for Co-production of City Service",
      "abstract": "Communities have first-hand knowledge about community issues. This study aims to improve the efficiency of social-technical problem-solving by proposing the concept of \"artificial process intelligence,\" based on the theories of socio-technical decision-making. The technical challenges addressed were channeling the communication between the internal-facing and external-facing 311 categorizations. Accordingly, deep learning models were trained on data from Kansas City's 311 system: (1) Bidirectional Encoder Representations from Transformers (BERT) based classification models that can predict the internal-facing 311 service categories and the city departments that handle the issue; (2) the Balanced Latent Dirichlet Allocation (LDA) and BERT clustering (BLBC) model that inductively summarizes residents' complaints and maps the main themes to the internal-facing 311 service categories; (3) a regression time series model that can predict response and completion time. Our case study demonstrated that these models could provide the information needed for reciprocal communication, city service planning, and community envisioning. Future studies should explore interface design like a chatbot and conduct more research on the acceptance and diffusion of AI-assisted 311 systems.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Ye Wang et al.",
      "keywords": "Computer science; Latent Dirichlet allocation; Chatbot; Artificial intelligence; Service (business); Cluster analysis; Process (computing); Knowledge management; Operations research; Data science; Topic model; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555176",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2909755349",
      "doi": "10.1145/3283070",
      "title": "Identifying Pathways to Computer Science",
      "abstract": "Short-term outreach interventions are conducted to raise young students\u2019 awareness of the computer science (CS) field. Typically, these interventions are targeted at K\u201312 students, attempting to encourage them to study CS in higher education. This study is based on a series of extra-curricular outreach events that introduced students to the discipline of computing, nurturing creative computational thinking through problem solving and game programming. To assess the long-term impact of this campaign, the participants were contacted and interviewed two to five years after they had attended an outreach event. We studied how participating in the outreach program affected the students\u2019 perceptions of CS as a field and, more importantly, how it affected their educational choices. We found that the outreach program generally had a positive effect on the students\u2019 educational choices. The most prominent finding was that students who already possessed a \u201cmaintained situational interest\u201d in CS found that the event strengthened their confidence in studying CS. However, many students were not affected by attending the program, but their perceptions of CS did change. Our results emphasize the need to provide continuing possibilities for interested students to experiment with computing-related activities and hence maintain their emerging individual interests.",
      "year": "2019",
      "journal": "ACM Transactions on Computing Education",
      "authors": "Antti-Jussi Lakanen et al.",
      "keywords": "Outreach; Psychological intervention; Situational ethics; Perception; Psychology; Medical education; Event (particle physics); Field (mathematics); Mathematics education; Social psychology; Medicine; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3283070",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391448911",
      "doi": "10.1145/3643857",
      "title": "Overcoming Diverse Undesired Effects in Recommender Systems: A Deontological Approach",
      "abstract": "In today\u2019s digital landscape, recommender systems have gained ubiquity as a means of directing users toward personalized products, services, and content. However, despite their widespread adoption and a long track of research, these systems are not immune to shortcomings. A significant challenge faced by recommender systems is the presence of biases, which produces various undesirable effects, prominently the popularity bias. This bias hampers the diversity of recommended items, thus restricting users\u2019 exposure to less popular or niche content. Furthermore, this issue is compounded when multiple stakeholders are considered, requiring the balance of multiple, potentially conflicting objectives. In this article, we present a new approach to address a wide range of undesired consequences in recommender systems that involve various stakeholders. Instead of adopting a consequentialist perspective that aims to mitigate the repercussions of a recommendation policy, we propose a deontological approach centered around a minimal set of ethical principles. More precisely, we introduce two distinct principles aimed at avoiding overconfidence in predictions and accurately modeling the genuine interests of users. The proposed approach circumvents the need for defining a multi-objective system, which has been identified as one of the main limitations when developing complex recommenders. Through extensive experimentation, we show the efficacy of our approach in mitigating the adverse impact of the recommender from both user and item perspectives, ultimately enhancing various beyond accuracy metrics. This study underscores the significance of responsible and equitable recommendations and proposes a strategy that can be easily deployed in real-world scenarios.",
      "year": "2024",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Paula G\u00f3mez Duran et al.",
      "keywords": "Recommender system; Computer science; Popularity; Perspective (graphical); Set (abstract data type); Overconfidence effect; Diversity (politics); Data science; Risk analysis (engineering); Artificial intelligence; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643857",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391388021",
      "doi": "10.1145/3643035",
      "title": "Domain Generalization in Time Series Forecasting",
      "abstract": "Domain generalization aims to design models that can effectively generalize to unseen target domains by learning from observed source domains. Domain generalization poses a significant challenge for time series data, due to varying data distributions and temporal dependencies. Existing approaches to domain generalization are not designed for time series data, which often results in suboptimal or unstable performance when confronted with diverse temporal patterns and complex data characteristics. We propose a novel approach to tackle the problem of domain generalization in time series forecasting. We focus on a scenario where time series domains share certain common attributes and exhibit no abrupt distribution shifts. Our method revolves around the incorporation of a key regularization term into an existing time series forecasting model: domain discrepancy regularization . In this way, we aim to enforce consistent performance across different domains that exhibit distinct patterns. We calibrate the regularization term by investigating the performance within individual domains and propose the domain discrepancy regularization with domain difficulty awareness . We demonstrate the effectiveness of our method on multiple datasets, including synthetic and real-world time series datasets from diverse domains such as retail, transportation, and finance. Our method is compared against traditional methods, deep learning models, and domain generalization approaches to provide comprehensive insights into its performance. In these experiments, our method showcases superior performance, surpassing both the base model and competing domain generalization models across all datasets. Furthermore, our method is highly general and can be applied to various time series models.",
      "year": "2024",
      "journal": "ACM Transactions on Knowledge Discovery from Data",
      "authors": "Songgaojun Deng et al.",
      "keywords": "Generalization; Regularization (linguistics); Computer science; Time series; Artificial intelligence; Domain (mathematical analysis); Machine learning; Series (stratigraphy); Data mining; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643035",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385402337",
      "doi": "10.1145/3608112",
      "title": "Pixel Perfect: Using Vision Transformers to Improve Road Quality Predictions from Medium Resolution and Heterogeneous Satellite Imagery",
      "abstract": "Critical infrastructure, such as roads and electricity, are core systems that enable economic development. However, these crucial systems are frequently under-monitored in developing regions, resulting in lost opportunities for growth. Recent advances in remote sensing and machine learning have enabled monitoring and measurement of infrastructure faster and more frequently than traditional methods. However, ground data are often unavailable, resulting in a disconnect between labels and remotely sensed data. Furthermore, data from industrialized regions can only sometimes be transferred to regions with sparse data due to differences in the concept of quality between regions. Additionally, inconsistency in data and the complexity of ML models can introduce bias due to learned characteristics across diverse regions, leading to inaccurate predictions and recommendations for action. In this study, we train and compare traditional neural networks and vision transformers to predict road quality from medium-resolution satellite imagery and apply them to realistic data conditions: heterogeneous temporal-spatial resolutions. The best models (vision transformers) achieve AUROC scores of 0.934 and 0.685 for binary and five-class classification tasks, respectively, exhibiting results appealing for inference in otherwise unmeasured areas. Furthermore, these experiments and results showed that proper training techniques could produce accurate models from limited, heterogeneous, and low-resolution data.",
      "year": "2023",
      "journal": "ACM Journal on Computing and Sustainable Societies",
      "authors": "Aggrey Muhebwa et al.",
      "keywords": "Computer science; Inference; Satellite imagery; Transformer; Artificial intelligence; Data quality; Pixel; Data mining; Machine learning; Remote sensing; Voltage; Engineering; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3608112",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3014429356",
      "doi": "10.1145/3359134",
      "title": "\"This Place Does What It Was Built For\"",
      "abstract": "Whether we recognize it or not, the Internet is rife with exciting and original institutional forms that are transforming social organization on and offline. Governing these Internet platforms and other digital institutions has posed a challenge for engineers and managers, many of whom have little exposure to the relevant history or theory of institutional design. The dominant guiding practices for the design of digital institutions to date in human-computer interaction, computer-supported cooperative work, and the tech industry at large have been an incentive-focused behavioral engineering paradigm encompassing atheoretical approaches such as emulation, A/B-testing, engagement maximization, and piecemeal issue-driven engineering. One institutional analysis framework that has been useful in the study of traditional institutions comes from scholars of natural resource management, particularly that community of economists, anthropologists, and environmental and political scientists focused around the work of Elinor Ostrom, known collectively as the \"Ostrom Workshop.\" A key finding from this community that has yet to be broadly incorporated into the design of many digital institutions is the importance of including participatory change mechanisms in what is called a \"constitutional layer\" of institutional design. The institutional rules that compose a constitutional layer facilitate stakeholder participation in the ongoing process of institutional design change. We explore to what extent consideration of constitutional layers is met or could be better met in three varied cases of digital institutions: cryptocurrencies, cannabis informatics, and amateur Minecraft server governance. Examining such highly varied cases allows us to demonstrate the broad relevance of constitutional layers in many different types of digital institutions.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Seth Frey et al.",
      "keywords": "Corporate governance; Institutional analysis; Public relations; Political science; Knowledge management; Computer science; Sociology; Social science; Management; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359134",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4320560404",
      "doi": "10.1145/3579461",
      "title": "Beyond the Boolean: How Programmers Ask About, Use, and Discuss Gender",
      "abstract": "Categorization via gender is omnipresent throughout society, and thus also computing; gender identity is often requested of users before they use software or web services. Despite this fact, no research has explored how software developers approach requesting gender disclosure from users. To understand how developers think about gender in software, we present an interview study with 15 software developers recruited from the freelancing platform Upwork as well as Twitter. We also collected and categorized 917 threads that contained keywords relevant to gender from programming-related sub-forums on the social media service Reddit. 16 posts that discussed approaches to gender disclosure were further analyzed. We found that while some developers have an understanding of inclusive gender options, programmers rarely consider when gender data is necessary or the way in which they request gender disclosure from users. Our findings have implications for programmers, software engineering educators, and the broader community concerned with inclusivity.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Elijah Bouma-Sims et al.",
      "keywords": "Computer science; Ask price; Categorization; Gender identity; Software; World Wide Web; Social media; Identity (music); Software development; Data science; Psychology; Social psychology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579461",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389793939",
      "doi": "10.1145/3637438",
      "title": "Preserving the Fairness Guarantees of Classifiers in Changing Environments: A Survey",
      "abstract": "The impact of automated decision-making systems on human lives is growing, emphasizing the need for these systems to be not only accurate but also fair. The field of algorithmic fairness has expanded significantly in the past decade, with most approaches assuming that training and testing data are drawn independently and identically from the same distribution. However, in practice, differences between the training and deployment environments exist, compromising both the performance and fairness of the decision-making algorithms in real-world scenarios. A new area of research has emerged to address how to maintain fairness guarantees in classification tasks when the data generation processes differ between the source (training) and target (testing) domains. The objective of this survey is to offer a comprehensive examination of fair classification under distribution shift by presenting a taxonomy of current approaches. The latter is formulated based on the available information from the target domain, distinguishing between adaptive methods, which adapt to the target environment based on available information, and robust methods, which make minimal assumptions about the target environment. Additionally, this study emphasizes alternative benchmarking methods, investigates the interconnection with related research fields, and identifies potential avenues for future research.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Ainhize Barrainkua et al.",
      "keywords": "Computer science; Benchmarking; Software deployment; Machine learning; Field (mathematics); Domain (mathematical analysis); Profiling (computer programming); Artificial intelligence; Data science; Software engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3637438",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392110476",
      "doi": "10.1145/3649312",
      "title": "The Challenge of Data Analytics with Climate-neutral Urban Mobility (Vision Paper)",
      "abstract": "Urban mobility is a major contributor to human-induced climate change, a challenge that urban and transport planning and spatial computing academic communities have been actively addressing. In this article we argue, however, that the common data analytics research into incremental efficiency improvements of originally non-sustainable urban mobility systems will never be able to help reach climate neutrality \u2014the goal we must achieve by 2050 as per the Paris Agreement. This imperative is exacerbated by the observation that improvements, by data analytics, in one segment of urban mobility typically have unintended and often adverse consequences in other segments. In this vision paper we argue for a data analytics agenda to advance climate action at the core of urban mobility research. This agenda must disrupt the way we think and operate, as much as it is disrupting the accessibility issues of society in cities.",
      "year": "2024",
      "journal": "ACM Transactions on Spatial Algorithms and Systems",
      "authors": "Stephan Winter et al.",
      "keywords": "Analytics; Visual analytics; Unintended consequences; Data science; Climate change; Computer science; Action (physics); Political science; Visualization; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3649312",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391402420",
      "doi": "10.1145/3643673",
      "title": "An Empirical Analysis of Issue Templates Usage in Large-Scale Projects on GitHub",
      "abstract": "GitHub Issues is a widely used issue tracking tool in open-source software projects. Originally designed with broad flexibility, its lack of standardization led to incomplete issue reports, impeding software development and maintenance efficiency. To counteract this, GitHub introduced issue templates in 2016, which rapidly became popular. Our study assesses the current use and evolution of these templates in large-scale open-source projects and their impact on issue tracking metrics, including resolution time, number of reopens, and number of issue comments. Employing a comprehensive analysis of 350 templates from 100 projects, we also evaluated over 1.9 million issues for template conformity and impact. Additionally, we solicited insights from open-source software maintainers through a survey. Our findings highlight issue templates\u2019 extensive usage in 99 of the 100 surveyed projects, with a growing preference for YAML-based templates, a more structured template variant. Projects with a template exhibited markedly reduced resolution time (381.02 days to 103.18 days) and reduced issue comment count (4.95 to 4.32) compared to those without. The use of YAML-based templates further significantly decreased resolution time, the number of reopenings, and the discussion extent. Thus, our research underscores issue templates\u2019 positive impact on large-scale open-source projects, offering recommendations for improved effectiveness.",
      "year": "2024",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Emre S\u00fcl\u00fcn et al.",
      "keywords": "Computer science; Scale (ratio); Data science; Template; Software engineering; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643673",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4313331832",
      "doi": "10.1145/3567567",
      "title": "The Stoop",
      "abstract": "Inspired by previous research examining the challenges and benefits of Black Twitter (a community gathered on a platform used by Black people but not created by or for them), this design fiction presents a fictional study of a successful yet speculative social media platform named The Stoop. We envision this digital space as one that a Black woman created and a predominantly Black team designed and developed. Imagining what future online communities of marginalized people could be based on current struggles and shortcomings provides the inspiration for this design fiction. Proactively addressing content moderation, harassment, content controls, and the need for reducing appropriation while centering on the lived experiences and preferences of Black people allows this design fiction to joyfully speculate on what it can look like to get it right as a way of thinking through best practices for current technology design.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Shamika Klassen et al.",
      "keywords": "Appropriation; Harassment; Moderation; Social media; Space (punctuation); Sociology; Black box; Internet privacy; Media studies; Public relations; Computer science; Political science; World Wide Web; Psychology; Social psychology; Epistemology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3567567",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4396919945",
      "doi": "10.1145/3659621",
      "title": "ShuffleFL: Addressing Heterogeneity in Multi-Device Federated Learning",
      "abstract": "Federated Learning (FL) has emerged as a privacy-preserving paradigm for collaborative deep learning model training across distributed data silos. Despite its importance, FL faces challenges such as high latency and less effective global models. In this paper, we propose ShuffleFL, an innovative framework stemming from the hierarchical FL, which introduces a user layer between the FL devices and the FL server. ShuffleFL naturally groups devices based on their affiliations, e.g., belonging to the same user, to ease the strict privacy restriction-\"data at the FL devices cannot be shared with others\", thereby enabling the exchange of local samples among them. The user layer assumes a multi-faceted role, not just aggregating local updates but also coordinating data shuffling within affiliated devices. We formulate this data shuffling as an optimization problem, detailing our objectives to align local data closely with device computing capabilities and to ensure a more balanced data distribution at the intra-user devices. Through extensive experiments using realistic device profiles and five non-IID datasets, we demonstrate that ShuffleFL can improve inference accuracy by 2.81% to 7.85% and speed up the convergence by 4.11x to 36.56x when reaching the target accuracy.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Ran Zhu et al.",
      "keywords": "Federated learning; Computer science; Data science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3659621",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3094511312",
      "doi": "10.1145/3415225",
      "title": "Toward Interactively Balancing the Screen Time of Actors Based on Observable Phenotypic Traits in Live Telecast",
      "abstract": "Several prominent studies have shown that the imbalanced on-screen exposure of observable phenotypic traits like gender and skin-tone in movies, TV shows, live telecasts, and other visual media can reinforce gender and racial stereotypes in society. Researchers and human rights organizations alike have long been calling to make media producers more aware of such stereotypes. While awareness among media producers is growing, balancing the presence of different phenotypes in a video requires substantial manual effort and can typically only be done in the post-production phase. The task becomes even more challenging in the case of a live telecast where video producers must make instantaneous decisions with no post-production phase to refine or revert a decision. In this paper, we propose Screen-Balancer, an interactive tool that assists media producers in balancing the presence of different phenotypes in a live telecast. The design of Screen-Balancer is informed by a field study conducted in a professional live studio. Screen-Balancer analyzes the facial features of the actors to determine phenotypic traits using facial detection packages; it then facilitates real-time visual feedback for interactive moderation of gender and skin-tone distributions. To demonstrate the effectiveness of our approach, we conducted a user study with 20 participants and asked them to compose live telecasts from a set of video streams simulating different camera angles, and featuring several male and female actors with different skin-tones. The study revealed that the participants were able to reduce the difference of screen times of male and female actors by 43%, and that of light-skinned and dark-skinned actors by 44%, thus showing the promise and potential of using such a tool in commercial production systems.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Md Naimul Hoque et al.",
      "keywords": "Studio; Moderation; Computer science; Screen time; Set (abstract data type); Psychology; Multimedia; Social psychology; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3415225",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413446160",
      "doi": "10.1145/3762179",
      "title": "Deep Causal Learning: Representation, Discovery and Inference",
      "abstract": "Causal learning has garnered significant attention in recent years because it reveals the essential relationships that underpin phenomena and delineates the mechanisms by which the world evolves. Nevertheless, traditional causal learning methods face numerous challenges and limitations, including high-dimensional, unstructured variables, combinatorial optimization problems, unobserved confounders, selection biases, and estimation inaccuracies. Deep causal learning, which leverages deep neural networks, offers innovative insights and solutions for addressing these challenges. Although numerous deep learning-based methods for causal discovery and inference have been proposed, there remains a dearth of reviews examining the underlying mechanisms by which deep learning can enhance causal learning. In this article, we comprehensively review how deep learning can contribute to causal learning by tackling traditional challenges across three key dimensions: representation, discovery, and inference. We emphasize that deep causal learning is pivotal for advancing the theoretical frontiers and broadening the practical applications of causal science. We conclude by summarizing open issues and outlining potential directions for future research.",
      "year": "2025",
      "journal": "ACM Computing Surveys",
      "authors": "Zizhen Deng et al.",
      "keywords": "Computer science; Artificial intelligence; Inference; Causal inference; Representation (politics); Natural language processing; Deep learning; Data science; Machine learning; Econometrics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3762179",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387377522",
      "doi": "10.1145/3626324",
      "title": "Unbiased Identification of Broadly Appealing Content Using a Pure Exploration Infinitely Armed Bandit Strategy",
      "abstract": "Podcasting is an increasingly popular medium for entertainment and discourse around the world, with tens of thousands of new podcasts released on a monthly basis. We consider the problem of identifying from these newly released podcasts those with the largest potential audiences so they can be considered for personalized recommendation to users. We first study and then discard a supervised approach due to the inadequacy of either content or consumption features for this task and instead propose a novel non-contextual bandit algorithm in the fixed-budget infinitely armed pure-exploration setting. We demonstrate that our algorithm is well suited to the best-arm identification task for a broad class of arm reservoir distributions, out-competing a large number of state-of-the-art algorithms. We then apply the algorithm to identifying podcasts with broad appeal in a simulated study and show that it efficiently sorts podcasts into groups by increasing appeal while avoiding the popularity bias inherent in supervised approaches. Finally, we study a setting in which users are more likely to stream more-streamed podcasts independent of their general appeal and find that our proposed algorithm is robust to this type of popularity bias. 1",
      "year": "2023",
      "journal": "ACM Transactions on Recommender Systems",
      "authors": "Maryam Aziz et al.",
      "keywords": "Appeal; Computer science; Popularity; Identification (biology); Task (project management); Class (philosophy); Machine learning; Entertainment; Data science; Artificial intelligence; Information retrieval; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3626324",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387344866",
      "doi": "10.1145/3610050",
      "title": "Competing Imaginaries and Partisan Divides in the Data Rhetoric of Advocacy Organizations",
      "abstract": "Data are wielded to shape public opinion, particularly in electoral contexts where the role and veracity of information is questioned. This post-truth era is characterized by world events in which facts too often are obfuscated and evidential standards are abandoned. To study how data are used to influence pressing and divisive contemporary issues, this paper explores the rhetorical work that quantitative data are doing through the blogging practices of advocacy organizations during the highly-polarized month preceding the 2016 United States elections. We present results of a qualitative content analysis of the quantitative data used in 337 blog posts published by five pairs of conservative and liberal advocacy organizations over the course of the month leading up to the 2016 US elections. We identify key data rhetoric practices along partisan lines and contribute an analytic framework-evaluating ethos, pathos, and logos- that can be used to analyze the rhetorical use of data in other contexts. We then characterize two different imaginaries that come into conflict in this research: 1) the political imaginaries being promoted through organizational blogging and 2) the sociotechnical imaginary of the data economy, foregrounding differences in the epistemic value of data in each. We conclude by outlining research challenges and trajectories for future research within each of the two imaginaries of data.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Shiva Darian et al.",
      "keywords": "Rhetoric; Rhetorical question; Pathos; Ethos; Foregrounding; Sociology; Political science; Politics; Logos Bible Software; Public relations; Sustenance; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610050",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388638405",
      "doi": "10.1145/3632531",
      "title": "Investigating Participation Mechanisms in EU Code Week",
      "abstract": "Digital competence (DC) is a broad set of skills, attitudes, and knowledge for confident, critical, and responsible use of digital technologies in every aspect of life. DC proves essential in the contemporary digital landscape, yet its diffusion is hindered by biases, misunderstandings, and limited awareness. Teaching Informatics in the educational curriculum is increasingly supported by the institutions but faces serious challenges, such as teacher upskilling and support. In response, grassroots movements promoting computing literacy in an informal setting have grown, including EU Code Week, whose vision is to develop computing skills while promoting diversity and raising awareness of the importance of digital skills. This study extensively analyses EU Code Week editions spanning 2014 to 2021 across European Union member states, pursuing three primary objectives: firstly, to evaluate teacher engagement in the campaign in terms of penetration, retention, and spatial distribution; secondly, to characterise the multifaceted audience and themes embraced by these initiatives; and, lastly, to investigate the influence of socio-economic factors on engagement. The investigation uncovers the underlying mechanisms fostering Code Week\u2019s engagement, providing insights to campaign organisers for strategic planning and resource allocation in future editions. Moreover, the analysis reveals that the most engaged areas are characterised by lower income as well as lower digital literacy, restricted access to technology, and a less established computer education, suggesting that Code Week thrives precisely where its impact is most needed.",
      "year": "2023",
      "journal": "ACM Transactions on Computing Education",
      "authors": "Christel Sirocchi et al.",
      "keywords": "Computer science; Code (set theory); Mathematics education; Psychology; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3632531",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3046337576",
      "doi": "10.1145/3434184",
      "title": "Patterns of Patient and Caregiver Mutual Support Connections in an Online Health Community",
      "abstract": "Online health communities offer the promise of support benefits to users, in particular because these communities enable users to find peers with similar experiences. Building mutually supportive connections between peers is a key motivation for using online health communities. However, a user's role in a community may influence the formation of peer connections. In this work, we study patterns of peer connections between two structural health roles: patient and non-professional caregiver. We examine user behavior in an online health community---CaringBridge.org---where finding peers is not explicitly supported. This context lets us use social network analysis methods to explore the growth of such connections in the wild and identify users' peer communication preferences. We investigated how connections between peers were initiated, finding that initiations are more likely between two authors who have the same role and who are close within the broader communication network. Relationships---patterns of repeated interactions---are also more likely to form and be more interactive when authors have the same role. Our results have implications for the design of systems supporting peer communication, e.g. peer-to-peer recommendation systems.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Zachary Levonian et al.",
      "keywords": "Context (archaeology); Online community; Peer-to-peer; Psychology; Peer support; Social network (sociolinguistics); Social network analysis; Internet privacy; Computer science; World Wide Web; Social media",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3434184",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388178453",
      "doi": "10.1145/3630743",
      "title": "Shadow Program Committee: Designing for Diversity and Equity within Academic Communities",
      "abstract": "The development of early career researchers (ECRs) and their induction into academia has traditionally been a process that is at best obscure, and at worst, cronyism laden. Arguably this is especially true for cross-disciplinary fields like HCI, where relatively fragmented specialisms co-exist. With COVID-19 and its negative impacts on ECRs as the backdrop, we explored the design of a 5-month virtual training program for ECRs worldwide (with particular emphasis on the Global South). Through an action research approach, the program was executed in collaboration with the organizers of a cross-disciplinary conference. Eighty-one participants from 26 countries took part. The program created a collaborative learning experience for attendees and provided opportunities for networking and learning the nuances of the peer-review process. This article details our experiences and provides reflections on design opportunities to (1) develop professional development spaces for underserved researchers, and (2) leverage ECRs\u2019 unique capacity for contributing to inclusive conference spaces.",
      "year": "2023",
      "journal": "ACM Journal on Computing and Sustainable Societies",
      "authors": "Delvin Varghese et al.",
      "keywords": "Equity (law); Leverage (statistics); Public relations; Discipline; Political science; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3630743",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413744122",
      "doi": "10.1145/3762199",
      "title": "What is New, and What is Old, in Fairness and Machine Learning",
      "abstract": "This article explores the issue of normative distinctiveness in machine learning decision systems alongside Solon Barocas, Moritz Hardt, and Arvind Narayanan's landmark book Fairness and Machine Learning . What, if anything, is different this time, with the rise of machine learning-based aids to bureaucratic decision-making? I show how a focus on normative distinctiveness can obscure from view a much more significant upshot of machine learning: that the mere existence of feasible alternatives presses new justificatory demands not just on the design of new technical systems but on the prevailing human-centered decision regime. I argue that depoliticizing conventional bureaucratic structures of decision-making leads to a missed opportunity for a broader normative reevaluation of what we owe to each other in a world of expanded practical possibility.",
      "year": "2025",
      "journal": "ACM Journal on Responsible Computing",
      "authors": "Lily Hu",
      "keywords": "Psychology; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3762199",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4413968530",
      "doi": "10.1145/3749509",
      "title": "One Model to Fit Them All: Universal IMU-based Human Activity Recognition with LLM-assisted Cross-dataset Representation",
      "abstract": "Human Activity Recognition (HAR) is essential for pervasive computing and intelligent interaction, with broad applications across various fields. However, there is still no one model capable of fitting various HAR datasets, severely limiting its applicability in practical scenarios. To address this, we propose oneHAR, an LLM-assisted universal IMU-based HAR system designed to achieve \"one model to fit them all\" --- just one model that can adapt to diverse HAR datasets without any dataset-specific operation. In particular, we propose Cross-Dataset neural network (CDNet) for the \"one model,\" which models both the temporal context and spatial relationships of IMU data to capture cross-dataset representations, encompassing differences in device, participant, data collection position, and environment, etc. Additionally, we introduce LLM-driven data synthesis, which enhances the training process by generating virtual IMU data through three carefully designed strategies. Furthermore, LLM-assisted adaptive position processing optimizes the inference process by flexibly handling a variable combination of positional inputs. Our model demonstrates strong generalization across five public IMU-based HAR datasets, outperforming the best baselines by up to 46.9% in the unseen-dataset scenario, and 6.5% in the cross-dataset scenario.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Qingxin Wei et al.",
      "keywords": "Inertial measurement unit; Representation (politics); Activity recognition; Artificial intelligence; Computer science; Pattern recognition (psychology); Computer vision; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749509",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4230946804",
      "doi": "10.1145/3236465",
      "title": "",
      "abstract": "This article reports on the development of capabilities for (on-screen) virtual agents and robots to support isolated older adults in their homes. A real-time architecture was developed to use a virtual agent or a robot interchangeably to interact via ...",
      "year": "2018",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "H Sajjad Hossain et al.",
      "keywords": "Robot; Human\u2013computer interaction; Architecture; Computer science; Artificial intelligence; Visual arts; Art",
      "mesh_terms": "",
      "pub_types": "paratext",
      "url": "https://doi.org/10.1145/3236465",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4413506798",
      "doi": "10.1145/3762808",
      "title": "Meena Needs a Computer Now: Co-design Solutions to Barriers using Fictional Inquiry for Women in Computing",
      "abstract": "Gender disparity in computing is a well-explored concern. To complement existing research, we use a non-intrusive exploration method of Fictional Inquiry. Followed by co-design workshop to explore solution approaches to increase women\u2019s participation in computing. The study involved n=48 women in computing (WiC) students in computing from 4 universities across Bangladesh. Participants shared their challenges and desired solutions which we analyzed using qualitative methods along with Natural Language Processing based tools to illustrate the problems from various perspectives while minimizing potential biases. The research team reflects on methodological decisions, policy implications, and the need for culturally and contextually appropriate tools and datasets to better support WiC research in resource-limited settings.",
      "year": "2025",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Nova Ahmed et al.",
      "keywords": "Computer science; Sociology; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3762808",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4413968205",
      "doi": "10.1145/3749978",
      "title": "Semi-supervised Contrastive Learning for Reliable Sleep Staging with Small Labeled Photoplethysmography Data",
      "abstract": "Sleep monitoring is essential for assessing the quality of the body's rest. In medicine, it involves collecting polysomnography (PSG) data in hospitals, along with expert annotations. For convenient sleep monitoring, some studies on wearable devices train models using labeled photoplethysmography (PPG) data to classify multiple sleep stages. However, the difficulty of collecting labeled PPG data limits the application of these studies. To address the impaired model performance caused by the limited labeled PPG data, we develop a sleep staging model that simultaneously inputs sleep-related features and raw data to leverage their advantages in high task correlation and rich information. Furthermore, we design a semi-supervised contrastive learning method, FASL, which adjusts the loss function based on a soft label confidence coefficient to utilize the majority of unlabeled data and enhance the model's generalization ability. Finally, we apply semi-supervised contrastive learning to the features before the Sequence Encoder to mitigate the impact of individual variations. Compared to the best semi-supervised baseline, our approach demonstrates apparent performance improvements on two publicly available datasets and one self-collected dataset. To our knowledge, this work is the first to investigate a semi-supervised sleep monitoring method using PPG data, providing guidance on how to leverage unlabeled PPG data for sleep staging. The code and self-collected dataset used in this study are publicly available at https://github.com/QiWangXPY/FASL.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Qi Wang et al.",
      "keywords": "Photoplethysmogram; Computer science; Artificial intelligence; Sleep (system call); Psychology; Natural language processing; Medicine; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749978",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319736227",
      "doi": "10.1145/3583561",
      "title": "A Comprehensive Empirical Study of Bias Mitigation Methods for Machine Learning Classifiers",
      "abstract": "Software bias is an increasingly important operational concern for software engineers. We present a large-scale, comprehensive empirical study of 17 representative bias mitigation methods for Machine Learning (ML) classifiers, evaluated with 11 ML performance metrics (e.g., accuracy), 4 fairness metrics, and 20 types of fairness-performance tradeoff assessment, applied to 8 widely-adopted software decision tasks. The empirical coverage is much more comprehensive, covering the largest numbers of bias mitigation methods, evaluation metrics, and fairness-performance tradeoff measures compared to previous work on this important software property. We find that (1) the bias mitigation methods significantly decrease ML performance in 53% of the studied scenarios (ranging between 42%\u223c66% according to different ML performance metrics); (2) the bias mitigation methods significantly improve fairness measured by the 4 used metrics in 46% of all the scenarios (ranging between 24%\u223c59% according to different fairness metrics); (3) the bias mitigation methods even lead to decrease in both fairness and ML performance in 25% of the scenarios; (4) the effectiveness of the bias mitigation methods depends on tasks, models, the choice of protected attributes, and the set of metrics used to assess fairness and ML performance; (5) there is no bias mitigation method that can achieve the best tradeoff in all the scenarios. The best method that we find outperforms other methods in 30% of the scenarios. Researchers and practitioners need to choose the bias mitigation method best suited to their intended application scenario(s).",
      "year": "2023",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Zhenpeng Chen et al.",
      "keywords": "Computer science; Software; Machine learning; Empirical research; Fairness measure; Artificial intelligence; Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3583561",
      "cited_by_count": 81,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4308792237",
      "doi": "10.1145/3555100",
      "title": "Revisiting Group Fairness Metrics: The Effect of Networks",
      "abstract": "An increasing amount of work studies fairness in socio-technical settings from a computational perspective. This work has introduced a variety of metrics to measure fairness in different settings. Most of these metrics, however, do not account for the interactions between individuals or evaluate any underlying network's effect on the outcomes measured. While a wide body of work studies the organization of individuals into a network structure and how individuals access resources in networks, the impact of network structure on fairness has been largely unexplored. We introduce templates for group fairness metrics that account for network structure. More specifically, we present two types of group fairness metrics that measure distinct yet complementary forms of bias in networks. The first type of metric evaluates how access to others in the network is distributed across groups. The second type of metric evaluates how groups distribute their interactions across other groups, and hence captures inter-group biases. We find that ignoring the network can lead to spurious fairness evaluations by either not capturing imbalances in influence and reach illuminated by the first type of metric, or by overlooking interaction biases as evaluated by the second type of metric. Our empirical study illustrates these pronounced differences between network and non-network evaluations of fairness.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Anay Mehrotra et al.",
      "keywords": "Metric (unit); Spurious relationship; Computer science; Perspective (graphical); Variety (cybernetics); Fairness measure; Group (periodic table); Empirical research; Machine learning; Mathematics; Artificial intelligence; Statistics; Throughput; Engineering; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555100",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4293762926",
      "doi": "10.1145/3559540",
      "title": "Generative Adversarial Networks in Time Series: A Systematic Literature Review",
      "abstract": "Generative adversarial network (GAN) studies have grown exponentially in the past few years. Their impact has been seen mainly in the computer vision field with realistic image and video manipulation, especially generation, making significant advancements. Although these computer vision advances have garnered much attention, GAN applications have diversified across disciplines such as time series and sequence generation. As a relatively new niche for GANs, fieldwork is ongoing to develop high-quality, diverse, and private time series data. In this article, we review GAN variants designed for time series related applications. We propose a classification of discrete-variant GANs and continuous-variant GANs, in which GANs deal with discrete time series and continuous time series data. Here we showcase the latest and most popular literature in this field\u2014their architectures, results, and applications. We also provide a list of the most popular evaluation metrics and their suitability across applications. Also presented is a discussion of privacy measures for these GANs and further protections and directions for dealing with sensitive data. We aim to frame clearly and concisely the latest and state-of-the-art research in this area and their applications to real-world technologies.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Eoin Brophy et al.",
      "keywords": "Computer science; Adversarial system; Field (mathematics); Generative grammar; Data science; Series (stratigraphy); Generative adversarial network; Time series; Artificial intelligence; Machine learning; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3559540",
      "cited_by_count": 269,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W1986841213",
      "doi": "10.1145/2659796",
      "title": "Supporting Novice to Expert Transitions in User Interfaces",
      "abstract": "Interface design guidelines encourage designers to provide high-performance mechanisms for expert users. However, research shows that many expert interface components are seldom used and that there is a tendency for users to persistently fail to adopt faster methods for completing their work. This article summarizes and organizes research relevant to supporting users in making successful transitions to expert levels of performance. First, we provide a brief introduction to the underlying human factors of skill acquisition relevant to interaction with computer systems. We then present our focus, which is a review of the state of the art in user interfaces that promote expertise development. The review of interface research is based around four domains of performance improvement: intramodal improvement that occurs as a factor of repetition and practice with a single method of interaction; intermodal improvement that occurs when users switch from one method to another that has a higher performance ceiling; vocabulary extension , in which the user broadens his or her knowledge of the range of functions available; and task mapping , which examines the ways in which users perform their tasks. The review emphasizes the relationship between interface techniques and the human factors that explain their relative success.",
      "year": "2014",
      "journal": "ACM Computing Surveys",
      "authors": "Andy Cockburn et al.",
      "keywords": "Computer science; Human\u2013computer interaction; Focus (optics); User interface; Interface (matter); Task (project management); Vocabulary; Factor (programming language); User interface design; Multimedia; User experience design",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/2659796",
      "cited_by_count": 171,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4318618520",
      "doi": "10.1145/3582272",
      "title": "A Survey on Measuring Cognitive Workload in Human-Computer Interaction",
      "abstract": "The ever-increasing number of computing devices around us results in more and more systems competing for our attention, making cognitive workload a crucial factor for the user experience of human-computer interfaces. Research in Human-Computer Interaction (HCI) has used various metrics to determine users\u2019 mental demands. However, there needs to be a systematic way to choose an appropriate and effective measure for cognitive workload in experimental setups, posing a challenge to their reproducibility. We present a literature survey of past and current metrics for cognitive workload used throughout HCI literature to address this challenge. By initially exploring what cognitive workload resembles in the HCI context, we derive a categorization supporting researchers and practitioners in selecting cognitive workload metrics for system design and evaluation. We conclude with three following research gaps: (1) defining and interpreting cognitive workload in HCI, (2) the hidden cost of the NASA-TLX, and (3) HCI research as a catalyst for workload-aware systems, highlighting that HCI research has to deepen and conceptualize the understanding of cognitive workload in the context of interactive computing systems.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Thomas Kosch et al.",
      "keywords": "Workload; Computer science; Context (archaeology); Human\u2013computer interaction; Cognition; Categorization; Data science; Artificial intelligence; Psychology; Operating system",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3582272",
      "cited_by_count": 193,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2916700883",
      "doi": "10.1145/3230632",
      "title": "A Survey on Brain Biometrics",
      "abstract": "Brainwaves, which reflect brain electrical activity and have been studied for a long time in the domain of cognitive neuroscience, have recently been proposed as a promising biometric approach due to their unique advantages of confidentiality, resistance to spoofing/circumvention, sensitivity to emotional and mental state, continuous nature, and cancelability. Recent research efforts have explored many possible ways of using brain biometrics and demonstrated that they are a promising candidate for more robust and secure personal identification and authentication. Although existing research on brain biometrics has obtained some intriguing insights, much work is still necessary to achieve a reliable ready-to-deploy brain biometric system. This article aims to provide a detailed survey of the current literature and outline the scientific work conducted on brain biometric systems. It provides an up-to-date review of state-of-the-art acquisition, collection, processing, and analysis of brainwave signals, publicly available databases, feature extraction and selection, and classifiers. Furthermore, it highlights some of the emerging open research problems for brain biometrics, including multimodality, security, permanence, and stability.",
      "year": "2019",
      "journal": "ACM Computing Surveys",
      "authors": "Qiong Gui et al.",
      "keywords": "Biometrics; Computer science; Spoofing attack; Identification (biology); Authentication (law); Confidentiality; Human\u2013computer interaction; Data science; Computer security",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3230632",
      "cited_by_count": 134,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392199044",
      "doi": "10.1145/3649448",
      "title": "Deep Learning for Time Series Classification and Extrinsic Regression: A Current Survey",
      "abstract": "Time Series Classification and Extrinsic Regression are important and challenging machine learning tasks. Deep learning has revolutionized natural language processing and computer vision and holds great promise in other fields such as time series analysis where the relevant features must often be abstracted from the raw data but are not known a priori. This article surveys the current state of the art in the fast-moving field of deep learning for time series classification and extrinsic regression. We review different network architectures and training methods used for these tasks and discuss the challenges and opportunities when applying deep learning to time series data. We also summarize two critical applications of time series classification and extrinsic regression, human activity recognition and satellite earth observation.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Navid Mohammadi Foumani et al.",
      "keywords": "Computer science; Current (fluid); Series (stratigraphy); Artificial intelligence; Regression; Time series; Machine learning; Deep learning; Data science; Statistics; Geology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3649448",
      "cited_by_count": 165,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4308605894",
      "doi": "10.1145/3570954",
      "title": "AI-Based Intrusion Detection Systems for In-Vehicle Networks: A Survey",
      "abstract": "The Controller Area Network (CAN) is the most widely used in-vehicle communication protocol, which still lacks the implementation of suitable security mechanisms such as message authentication and encryption. This makes the CAN bus vulnerable to numerous cyber attacks. Various Intrusion Detection Systems (IDSs) have been developed to detect these attacks. However, the high generalization capabilities of Artificial Intelligence (AI) make AI-based IDS an excellent countermeasure against automotive cyber attacks. This article surveys AI-based in-vehicle IDS from 2016 to 2022 (August) with a novel taxonomy. It reviews the detection techniques, attack types, features, and benchmark datasets. Furthermore, the article discusses the security of AI models, necessary steps to develop AI-based IDSs in the CAN bus, identifies the limitations of existing proposals, and gives recommendations for future research directions.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Sampath Rajapaksha et al.",
      "keywords": "Computer science; Intrusion detection system; Computer security; CAN bus; Encryption; Benchmark (surveying); Authentication (law); Artificial intelligence; Computer network",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3570954",
      "cited_by_count": 178,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3199015608",
      "doi": "10.1145/3543848",
      "title": "Multimodal Classification: Current Landscape, Taxonomy and Future Directions",
      "abstract": "Multimodal classification research has been gaining popularity with new datasets in domains such as satellite imagery, biometrics, and medicine. Prior research has shown the benefits of combining data from multiple sources compared to traditional unimodal data that has led to the development of many novel multimodal architectures. However, the lack of consistent terminologies and architectural descriptions makes it difficult to compare different solutions. We address these challenges by proposing a new taxonomy for describing multimodal classification models based on trends found in recent publications. Examples of how this taxonomy could be applied to existing models are presented as well as a checklist to aid in the clear and complete presentation of future models. Many of the most difficult aspects of unimodal classification have not yet been fully addressed for multimodal datasets, including big data, class imbalance, and instance-level difficulty. We also provide a discussion of these challenges and future directions of research.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "William C. Sleeman et al.",
      "keywords": "Computer science; Taxonomy (biology); Data science; Popularity; Artificial intelligence; Biometrics; Presentation (obstetrics); Information retrieval",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3543848",
      "cited_by_count": 108,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2023666594",
      "doi": "10.1145/2597892",
      "title": "#swineflu",
      "abstract": "The need to improve population monitoring and enhance surveillance of infectious diseases has never been more pressing. Factors such as air travel act as a catalyst in the spread of new and existing viruses. The unprecedented user-generated activity on social networks over the last few years has created real-time streams of personal data that provide an invaluable tool for monitoring and sampling large populations. Epidemic intelligence relies on constant monitoring of online media sources for early warning, detection, and rapid response; however, the real-time information available in social networks provides a new paradigm for the early warning function. The communication of risk in any public health emergency is a complex task for governments and healthcare agencies. This task is made more challenging in the current situation when the public has access to a wide range of online resources, ranging from traditional news channels to information posted on blogs and social networks. Twitter\u2019s strength is its two-way communication nature --- both as an information source but also as a central hub for publishing, disseminating and discovering online media. This study addresses these two challenges by investigating the role of Twitter during the 2009 swine flu pandemic by analysing data collected from the SN, and by Twitter using the opposite way for dissemination information through the network. First, we demonstrate the role of the social network for early warning by detecting an upcoming spike in an epidemic before the official surveillance systems by up to two weeks in the U.K. and up to two to three weeks in the U.S. Second, we illustrate how online resources are propagated through Twitter at the time of the WHO\u2019s declaration of the swine flu \u201cpandemic\u201d. Our findings indicate that Twitter does favour reputable t bogus information can still leak into the network.",
      "year": "2014",
      "journal": "ACM Transactions on Management Information Systems",
      "authors": "Patty Kostkova et al.",
      "keywords": "Dissemination; Social media; Warning system; Internet privacy; Computer science; Information Dissemination; Social network (sociolinguistics); Function (biology); Population; Download; World Wide Web; Task (project management); Data science; Telecommunications; Engineering; Medicine; Environmental health",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/2597892",
      "cited_by_count": 88,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3027515711",
      "doi": "10.1145/3400030",
      "title": "Biometric Systems Utilising Health Data from Wearable Devices",
      "abstract": "Health data are being increasingly sensed from the health-based wearable Internet of Things (IoT) devices, providing much-needed fitness and health tracking. However, data generated also present opportunities within computer security, specifically with biometric systems used for identification and authentication purposes. This article performs a systematic review of health-based IoT data collected from wearable IoT technology. This involved performing research in the underlying data sources, what they are collected for in terms of their health monitoring, and the underlying data characteristics. Furthermore, it explores existing work in computer security using these data sources, identifying key themes of work, key limitations, and challenges. Finally, key opportunities are provided as summaries to the potential of health-based IoT data, highlighting challenges that are yet to be addressed, which motivate areas of future work.",
      "year": "2020",
      "journal": "ACM Computing Surveys",
      "authors": "Saad Khan et al.",
      "keywords": "Computer science; Wearable computer; Biometrics; Key (lock); Identification (biology); Data science; Internet of Things; Computer security; Wearable technology; Health data; Authentication (law); Work (physics); Human\u2013computer interaction; Health care; Embedded system",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3400030",
      "cited_by_count": 74,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3003600674",
      "doi": "10.1145/3369835",
      "title": "Breeze",
      "abstract": "Slow-paced biofeedback-guided breathing training has been shown to improve cardiac functioning and psychological well-being. Current training options, however, attract only a fraction of individuals and are limited in their scalability as they require dedicated biofeedback hardware. In this work, we present Breeze, a mobile application that uses a smartphone's microphone to continuously detect breathing phases, which then trigger a gamified biofeedback-guided breathing training. Circa 2.76 million breathing sounds from 43 subjects and control sounds were collected and labeled to train and test our breathing detection algorithm. We model breathing as inhalation-pause-exhalation-pause sequences and implement a phase-detection system with an attention-based LSTM model in conjunction with a CNN-based breath extraction module. A biofeedback-guided breathing training with Breeze takes place in real-time and achieves 75.5% accuracy in breathing phases detection. Breeze was also evaluated in a pilot study with 16 new subjects, which demonstrated that the majority of subjects prefer Breeze over a validated active control condition in its usefulness, enjoyment, control, and usage intentions. Breeze is also effective for strengthening users' cardiac functioning by increasing high-frequency heart rate variability. The results of our study suggest that Breeze could potentially be utilized in clinical and self-care activities.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Chen-Hsuan Iris Shih et al.",
      "keywords": "Biofeedback; Breathing; Exhalation; Computer science; Medicine; Simulation; Physical medicine and rehabilitation; Anesthesia",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3369835",
      "cited_by_count": 87,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2890025384",
      "doi": "10.1145/3195833",
      "title": "Triclustering Algorithms for Three-Dimensional Data Analysis",
      "abstract": "Three-dimensional data are increasingly prevalent across biomedical and social domains. Notable examples are gene-sample-time, individual-feature-time, or node-node-time data, generally referred to as observation-attribute-context data. The unsupervised analysis of three-dimensional data can be pursued to discover putative biological modules, disease progression profiles, and communities of individuals with coherent behavior, among other patterns of interest. It is thus key to enhance the understanding of complex biological, individual, and societal systems. In this context, although clustering can be applied to group observations, its relevance is limited since observations in three-dimensional data domains are typically only meaningfully correlated on subspaces of the overall space. Biclustering tackles this challenge but disregards the third dimension. In this scenario, triclustering\u2014the discovery of coherent subspaces within three-dimensional data\u2014has been largely researched to tackle these problems. Despite the diversity of contributions in this field, there still lacks a structured view on the major requirements of triclustering, desirable forms of homogeneity (including coherency, structure, quality, locality, and orthonormality criteria), and algorithmic approaches. This work formalizes the triclustering task and its scope, introduces a taxonomy to categorize the contributions in the field, provides a comprehensive comparison of state-of-the-art triclustering algorithms according to their behavior and output, and lists relevant real-world applications. Finally, it highlights challenges and opportunities to advance the field of triclustering and its applicability to complex three-dimensional data analysis.",
      "year": "2018",
      "journal": "ACM Computing Surveys",
      "authors": "Rui Henriques et al.",
      "keywords": "Computer science; Cluster analysis; Linear subspace; Field (mathematics); Context (archaeology); Data science; Data mining; Biclustering; Artificial intelligence; Theoretical computer science; Machine learning; Fuzzy clustering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3195833",
      "cited_by_count": 76,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2985601033",
      "doi": "10.1145/3359323",
      "title": "Coordinating Clinical Teams",
      "abstract": "Patient safety errors account for over 400,000 preventable deaths annually in US in hospitals alone, 70% of which are caused by team communication breakdowns, stemming from hierarchical structures and asymmetrical power dynamics between physicians, nurses, patients, and others. Nurses are uniquely positioned to identify and prevent these errors, but they are often penalized for speaking up, particularly when physicians are responsible. Nevertheless, empowering nurses and building strong interdisciplinary teams can lead to improved patient safety and outcomes. Thus, our group has been developing a series of intelligent systems that support teaming in safety critical settings, Robot-Centric Team Support System (RoboTSS), and recently developed a group detection and tracking system for collaborative robots. In this paper, we explore how RoboTSS can be used to empower nurses in interprofessional team settings, through a three month long, collaborative design process with nurses across five US-based hospitals. The main findings and contributions of this paper are as follows. First, we found that participants envisioned using a robotic crash cart to guide resuscitation procedures to improve efficiency and reduce errors. Second, nurses discussed how RoboTSS can generate choreography for efficient spatial reconfigurations in co-located clinical teams, which is particularly important in time-sensitive situations such as resuscitation. Third, we found that nurses want to use RoboTSS to \"stop the line,\" and disrupt power dynamics by policing unsafe physician behavior, such as avoiding safety protocols using a robotic crash cart. Fourth, nurses envisioned using our system to support real-time error identification, such as breaking the sterile field, and then communicating those errors to physicians, to relieve them of responsibility. Finally, based on our findings, we propose robot design implications that capture how nurses envision utilizing RoboTSS. We hope this work promotes further exploration in how to design technology to challenge authority in asymmetrical power relationships, particularly in healthcare, as strong teams save lives.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Angelique Taylor et al.",
      "keywords": "Crash; Patient safety; Process (computing); Identification (biology); Nursing; Medical emergency; Computer science; Medicine; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359323",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2898858289",
      "doi": "10.1145/3274288",
      "title": "Testing Waters, Sending Clues",
      "abstract": "Indirect disclosure strategies include hinting about an experience or a facet of one's identity or relaying information explicitly but through another person. These strategies lend themselves to sharing stigmatized or sensitive experiences such as a pregnancy loss, mental illness, or abuse. Drawing on interviews with women in the U.S. who use social media and experienced pregnancy loss, we investigated factors guiding indirect disclosure decisions on social media. Our findings include 1) a typology of indirect disclosure strategies based on content explicitness, original content creator, and content sharer, and 2) an examination of indirect disclosure decision factors related to the self, audience, platform affordances, and temporality. We identify how people intentionally adapt social media and indirect disclosures to meet psychological (e.g., keeping a personal record) and social (e.g., feeling out the audience) needs associated with loss. We discuss implications for design and research, including features that support disclosures through proxy, and relevance for algorithmic detection and intervention. CAUTION: This paper includes quotes about pregnancy loss.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Nazanin Andalibi et al.",
      "keywords": "Psychology; Social media; Social psychology; Feeling; Shame; Affordance; Relevance (law); Anonymity; Typology; Internet privacy; Computer science; Sociology; Computer security; Cognitive psychology; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274288",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4220822781",
      "doi": "10.1145/3527170",
      "title": "MHDeep: Mental Health Disorder Detection System Based on Wearable Sensors and Artificial Neural Networks",
      "abstract": "Mental health problems impact the quality of life of millions of people around the world. However, diagnosis of mental health disorders is a challenging problem that often relies on self-reporting by patients about their behavioral patterns and social interactions. Therefore, there is a need for new strategies for diagnosis and daily monitoring of mental health conditions. The recent introduction of body-area networks consisting of a plethora of accurate sensors embedded in smartwatches and smartphones and edge-compatible deep neural networks (DNNs) points toward a possible solution. Such wearable medical sensors (WMSs) enable continuous monitoring of physiological signals in a passive and non-invasive manner. However, disease diagnosis based on WMSs and DNNs, and their deployment on edge devices, such as smartphones, remains a challenging problem. These challenges stem from the difficulty of feature engineering and knowledge distillation from the raw sensor data, as well as the computational and memory constraints of battery-operated edge devices. To this end, we propose a framework called MHDeep that utilizes commercially available WMSs and efficient DNN models to diagnose three important mental health disorders: schizoaffective, major depressive, and bipolar. MHDeep uses eight different categories of data obtained from sensors integrated in a smartwatch and smartphone. These categories include various physiological signals and additional information on motion patterns and environmental variables related to the wearer. MHDeep eliminates the need for manual feature engineering by directly operating on the data streams obtained from participants. Because the amount of data is limited, MHDeep uses a synthetic data generation module to augment real data with synthetic data drawn from the same probability distribution. We use the synthetic dataset to pre-train the weights of the DNN models, thus imposing a prior on the weights. We use a grow-and-prune DNN synthesis approach to learn both architecture and weights during the training process. We use three different data partitions to evaluate the MHDeep models trained with data collected from 74 individuals. We conduct two types of evaluations: at the data instance level and at the patient level. MHDeep achieves an average test accuracy, across the three data partitions, of 90.4%, 87.3%, and 82.4%, respectively, for classifications between healthy and schizoaffective disorder instances, healthy and major depressive disorder instances, and healthy and bipolar disorder instances. At the patient level, MHDeep DNN models achieve an accuracy of 100%, 100%, and 90.0% for the three mental health disorders, respectively, based on inference that uses 40, 16, and 22 minutes of sensor data collection from each patient.",
      "year": "2022",
      "journal": "ACM Transactions on Embedded Computing Systems",
      "authors": "Shayan Hassantabar et al.",
      "keywords": "Computer science; Wearable computer; Smartwatch; Artificial intelligence; Feature engineering; Feature (linguistics); Machine learning; Artificial neural network; Activity recognition; Edge device; Software deployment; Wearable technology; Enhanced Data Rates for GSM Evolution; Deep learning; Human\u2013computer interaction; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3527170",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3196160080",
      "doi": "10.1145/3479499",
      "title": "Tactics of Soft Resistance in User Experience Professionals' Values Work",
      "abstract": "User experience (UX) professionals' attempts to address social values as a part of their work practice can overlap with tactics to contest, resist, or change the companies they work for. This paper studies tactics that take place in this overlap, where UX professionals try to re-shape the values embodied and promoted by their companies, in addition to the values embodied and promoted in the technical systems and products that their companies produce. Through interviews with UX professionals working at large U.S.-based technology companies and observations at UX meetup events, this paper identifies tactics used towards three goals: (1) creating space for UX expertise to address values; (2) making values visible and relevant to other organizational stakeholders; and (3) changing organizational processes and orientations towards values. This paper analyzes these as tactics of resistance: UX professionals seek to subvert or change existing practices and organizational structures towards more values-conscious ends. Yet, these tactics of resistance often rely on the dominant discourses and logics of the technology industry. The paper characterizes these as partial or \"soft\" tactics, but also argues that they nevertheless hold possibilities for enacting values-oriented changes.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Richmond Y. Wong",
      "keywords": "CONTEST; Resistance (ecology); Embodied cognition; Work (physics); Space (punctuation); Knowledge management; Business; Public relations; Sociology; Computer science; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3479499",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3112789885",
      "doi": "10.1145/3410158",
      "title": "A Survey on Heart Biometrics",
      "abstract": "In recent years, biometrics (e.g., fingerprint or face recognition) has replaced traditional passwords and PINs as a widely used method for user authentication, particularly in personal or mobile devices. Differing from state-of-the-art biometrics, heart biometrics offer the advantages of liveness detection, which provides strong tolerance to spoofing attacks. To date, several authentication methods primarily focusing on electrocardiogram (ECG) have demonstrated remarkable success; however, the degree of exploration with other cardiac signals is still limited. To this end, we discuss the challenges in various cardiac domains and propose future prospectives for developing effective heart biometrics systems in real-world applications.",
      "year": "2020",
      "journal": "ACM Computing Surveys",
      "authors": "Aditya Singh Rathore et al.",
      "keywords": "Liveness; Biometrics; Spoofing attack; Computer science; Password; Fingerprint (computing); Authentication (law); Computer security; Face (sociological concept); Mobile device; Artificial intelligence; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3410158",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2920553042",
      "doi": "10.1145/3309550",
      "title": "A Survey on Modality Characteristics, Performance Evaluation Metrics, and Security for Traditional and Wearable Biometric Systems",
      "abstract": "Biometric research is directed increasingly toward Wearable Biometric Systems (WBS) for user authentication and identification. However, prior to engaging in WBS research, how their operational dynamics and design considerations differ from those of Traditional Biometric Systems (TBS) must be understood. While the current literature is cognizant of those differences, there is no effective work that summarizes the factors where TBS and WBS differ, namely, their modality characteristics, performance, security, and privacy. To bridge the gap, this article accordingly reviews and compares the key characteristics of modalities, contrasts the metrics used to evaluate system performance, and highlights the divergence in critical vulnerabilities, attacks, and defenses for TBS and WBS. It further discusses how these factors affect the design considerations for WBS, the open challenges, and future directions of research in these areas. In doing so, the article provides a big-picture overview of the important avenues of challenges and potential solutions that researchers entering the field should be aware of. Hence, this survey aims to be a starting point for researchers in comprehending the fundamental differences between TBS and WBS before understanding the core challenges associated with WBS and its design.",
      "year": "2019",
      "journal": "ACM Computing Surveys",
      "authors": "Aditya Sundararajan et al.",
      "keywords": "Biometrics; Computer science; Modality (human\u2013computer interaction); Modalities; Open research; Identification (biology); Wearable computer; Bridge (graph theory); Computer security; Human\u2013computer interaction; Data science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3309550",
      "cited_by_count": 73,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3033180295",
      "doi": "10.1145/3386600",
      "title": "Disclosure, Privacy, and Stigma on Social Media",
      "abstract": "Disclosures of distress and stigma on identified social media can be beneficial. Yet, many who may benefit from such disclosures do not engage in them. I examine factors that inform decisions to not disclose stigmatized experiences on identified social media. I conducted in-depth interviews with women in the US who used social media, had experienced pregnancy loss, and had not disclosed about their loss on identified social media. I detail six types of factors related to the self, audience, network, society, platform, and temporality that contribute to non-disclosure decisions. I show that the Disclosure Decision-Making (DDM) framework introduced in prior work explaining disclosures when they do occur, also explains non-disclosure decisions on social media. I show how DDM builds from and bridges prior privacy theories, namely, Communication Privacy Management and Contextual Integrity. I discuss design implications around removing barriers to disclosure to facilitate beneficial disclosures and reduce stigma.",
      "year": "2020",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Nazanin Andalibi",
      "keywords": "Social media; Stigma (botany); Psychology; Internet privacy; Distress; Temporality; Self-disclosure; Social psychology; Public relations; Computer science; Political science; Clinical psychology; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3386600",
      "cited_by_count": 70,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4362472235",
      "doi": "10.1145/3589959",
      "title": "Beyond Self-diagnosis: How a Chatbot-based Symptom Checker Should Respond",
      "abstract": "Chatbot-based symptom checker (CSC) apps have become increasingly popular in healthcare. These apps engage users in human-like conversations and offer possible medical diagnoses. The conversational design of these apps can significantly impact user perceptions and experiences, and may influence medical decisions users make and the medical care they receive. However, the effects of the conversational design of CSCs remain understudied, and there is a need to investigate and enhance users\u2019 interactions with CSCs. In this article, we conducted a two-stage exploratory study using a human-centered design methodology. We first conducted a qualitative interview study to identify key user needs in engaging with CSCs. We then performed an experimental study to investigate potential CSC conversational design solutions based on the results from the interview study. We identified that emotional support, explanations of medical information, and efficiency were important factors for users in their interactions with CSCs. We also demonstrated that emotional support and explanations could affect user perceptions and experiences, and they are context-dependent. Based on these findings, we offer design implications for CSC conversations to improve the user experience and health-related decision-making.",
      "year": "2023",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Yue You et al.",
      "keywords": "Chatbot; Context (archaeology); Exploratory research; Perception; Computer science; Affect (linguistics); Medical diagnosis; Psychology; Health care; Human\u2013computer interaction; Applied psychology; Internet privacy; World Wide Web; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3589959",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2988826827",
      "doi": "10.1145/3359250",
      "title": "Joining Together Online",
      "abstract": "The field of Computer Supported Cooperative Work (CSCW) has an enduring interest in studying and designing technologies that bring people together in partnerships, teams, crowds, communities, and other collectives. As the technologies enabling group formation have evolved, so too have the guiding questions pursued by CSCW scholars. This review outlines the trajectory of scholarship on group formation with an eye towards the most pressing future questions in this area. To understand how CSCW researchers have studied technology-enabled group formation, we systematically review articles published at CSCW from 1992 to 2018. Exploring more than 2,000 potentially relevant works, we identified 35 focused on technologies and group formation. Content coding and thematic analysis revealed four periods and six themes in the study of online group formation. These themes include: group composition, self-presentation, assembly mechanisms, recruitment, organizing structures, and group culture. Quo vadis? Based on our review, we offer recommendations for the next generation of CSCW scholarship seeking to understand and enable collectives joining together online.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Alexa M. Harris et al.",
      "keywords": "Computer-supported cooperative work; Scholarship; Affordance; Sociology; Knowledge management; Computer science; Work (physics); Engineering; Political science; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359250",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4288050564",
      "doi": "10.1145/3551890",
      "title": "Explainable Deep Attention Active Learning for Sentimental Analytics of Mental Disorder",
      "abstract": "With the increasing use of online mediums, Internet-delivered psychological treatments (IDPs) are becoming an essential tool for improving mental disorders. Online-based health therapies can help a large segment of the population with little resource investment. The task is greatly complicated by the overlapping emotions for specific mental health. Early adoption of a deep learning system presented severe difficulties, including ethical and legal considerations that contributed to a lack of trust. Modern models required highly interpretable, intuitive explanations that humans could understand. To achieve this, we present a deep attention model based on fuzzy classification that uses the linguistic features of patient texts to build emotional lexicons. In medical applications, a diversified dataset generates work. Active learning techniques are used to extend fuzzy rules and the learned dataset gradually. From this, the model can gain a reduction in labeling efforts in mental health applications. In this way, difficulties such as the amount of vocabulary per class, method of generation, the source of data, and the baseline for human performance level can be solved. Moreover, this work illustrates fuzzy explainability by using weighted terms. The proposed method incorporates a subset of unstructured data into the set for training and uses a similarity-based approach. The approach then updates the model training using the new training points in the subsequent cycle of the active learning mechanism. The cycle is repeated until the optimal solution is found. At this point, all unlabeled text is converted into the set for training. The experimental results show that the emotion-based enhancement improves test accuracy and helps develop quality criteria. In the blind test, the bidirectional LSTM architecture with an attention mechanism and fuzzy classification achieved an F1 score of 0.89.",
      "year": "2022",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Usman Ahmed et al.",
      "keywords": "Artificial intelligence; Computer science; Machine learning; Set (abstract data type); Mental health; Task (project management); Vocabulary; Deep learning; Class (philosophy); Fuzzy logic; Psychology; Psychiatry; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3551890",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3011886608",
      "doi": "10.1145/3380994",
      "title": "How Does Fitbit Measure Brainwaves",
      "abstract": "Consumer sleep-tracking devices provide an unobtrusive and affordable way to learn about personal sleep habits. Recent research focused primarily on the information provided by such devices, i.e., whether the information is accurate and meaningful to people. However, little is known about how people judge the credibility of such information, and how the functionality and the design may influence such judgements. Hence, the aim of this research was to examine how consumers assess the credibility of sleep-tracking devices. We conducted a qualitative study with 22 participants who tracked their sleep for 3 nights with three different devices: Fitbit Charge 2, Neuroon EEG, and SleepScope, a medical sleep monitor. Based on semi-structured interviews, we found that people assess the credibility of sleep-tracking devices based not only on the credibility of sleep data per se, but also on device functionality, interface design and physical appearance. People found it difficult to judge credibility, because of the complexities of sleep stages and micro-arousals (sleep fallacy) and the black boxed nature of devices (black box fallacy), and also because of the misalignment between objective sleep measures and subjective sleep quality. We discuss the significance of design and functionality on the credibility of personal health technologies and highlight design challenges and opportunities to enhance their credibility.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Zilu Liang et al.",
      "keywords": "Credibility; Sleep (system call); Fallacy; Applied psychology; Psychology; Tracking (education); Internet privacy; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3380994",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4220847066",
      "doi": "10.1145/3502740",
      "title": "A Study on Blockchain Architecture Design Decisions and Their Security Attacks and Threats",
      "abstract": "Blockchain is a disruptive technology intended to implement secure decentralised distributed systems, in which transactional data can be shared, stored, and verified by participants of the system without needing a central authentication/verification authority. Blockchain-based systems have several architectural components and variants, which architects can leverage to build secure software systems. However, there is a lack of studies to assist architects in making architecture design and configuration decisions for blockchain-based systems. This knowledge gap may increase the chance of making unsuitable design decisions and producing configurations prone to potential security risks. To address this limitation, we report our comprehensive systematic literature review to derive a taxonomy of commonly used architecture design decisions in blockchain-based systems. We map each of these decisions to potential security attacks and their posed threats. MITRE\u2019s attack tactic categories and Microsoft STRIDE threat modeling are used to systematically classify threats and their associated attacks to identify potential attacks and threats in blockchain-based systems. Our mapping approach aims to guide architects to make justifiable design decisions that will result in more secure implementations.",
      "year": "2022",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Sabreen Ahmadjee et al.",
      "keywords": "Computer science; Blockchain; Computer security; Threat model; Architecture; Leverage (statistics); Implementation; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3502740",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2774000474",
      "doi": "10.1145/3134689",
      "title": "High-resolution Temporal Representations of Alcohol and Tobacco Behaviors from Social Media Data",
      "abstract": "Understanding tobacco- and alcohol-related behavioral patterns is critical for uncovering risk factors and potentially designing targeted social computing intervention systems. Given that we make choices multiple times per day, hourly and daily patterns are critical for better understanding behaviors. Here, we combine natural language processing, machine learning and time series analyses to assess Twitter activity specifically related to alcohol and tobacco consumption and their sub-daily, daily and weekly cycles. Twitter self-reports of alcohol and tobacco use are compared to other data streams available at similar temporal resolution. We assess if discussion of drinking by inferred underage versus legal age people or discussion of use of different types of tobacco products can be differentiated using these temporal patterns. We find that time and frequency domain representations of behaviors on social media can provide meaningful and unique insights, and we discuss the types of behaviors for which the approach may be most useful.",
      "year": "2017",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Tom Huang et al.",
      "keywords": "Tobacco use; Social media; Computer science; Intervention (counseling); Psychology; Behavioral pattern; Alcohol consumption; Domain (mathematical analysis); Cognitive psychology; Data science; Alcohol; Environmental health; World Wide Web; Medicine; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3134689",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2984985665",
      "doi": "10.1145/3359175",
      "title": "'Routine Infrastructuring' as 'Building Everyday Resilience with Technology'",
      "abstract": "Getting a divorce. Being diagnosed with a disease. Going through a relationship breakup. Living through a natural disaster. All of these events are often life disrupting and debilitating. While some disruptive events are short-lived, some can be a routine part of everyday life. This leads to the question of how people who experience prolonged disruption in their lives build resilience---that is, how do they manage and overcome such events? To explore this question, this paper utilizes a case study approach to explore the use, creation, and re-appropriation of technology across three prolonged disruptions-the Second Gulf War in Iraq, veteran transitions, and the coming out experiences of LGBTQ-identifying people. Using a conceptual frame that brings together routine dynamics and infrastructuring, we find that engaging in routine infrastructuring practices generated resilience in people's daily lives---a phenomenon we dub 'routine infrastructuring' as 'building everyday resilience with technology.' We then theorize properties of infrastructure and infrastructuring practice that enable resiliency, and conclude with how infrastructuring is a form of care work that is oriented towards individuals, communities, and society.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Bryan Semaan",
      "keywords": "Appropriation; Everyday life; Psychological resilience; Resilience (materials science); Phenomenon; Sociology; Public relations; Political science; Social psychology; Psychology; Epistemology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359175",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3094443176",
      "doi": "10.1145/3415252",
      "title": "A Taxonomy of Team-Assembly Systems",
      "abstract": "The emergence of team-assembly technologies has brought with it new challenges in designing and implementing socio-technical systems. Our understanding of how systems shape the team-assembly processes is still limited. How do systems enable users to find teammates? How do users make decisions when using these systems? And what factors explain the characteristics of the teams assembled? Building on existing literature from CSCW, computer science, and management science, we propose a taxonomy to characterize how systems influence team assembly. This taxonomy argues that two dimensions determine how systems shape team assembly: (i) users? agency, to what extent the system enables its users to exercise their agency, and (ii) users? participation, how many users the system allows to participate in the team-formation process. The intersection of these two dimensions manifest four types of teams enabled by systems: self-assembled teams, staffed teams, optimized teams, and augmented teams. We characterize each one of these types of teams, considering their qualities, advantages, and challenges. To contextualize these types of teams, we map the current literature of team-assembly systems using a scoping literature review. Lastly, we discuss ways through which these two dimensions alter users' behavior, team diversity, and team composition. This paper provides theoretical implications and research questions for future systems that reconfigure the organization of people into teams.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Diego G\u00f3mez-Zar\u00e1 et al.",
      "keywords": "Team composition; Knowledge management; Taxonomy (biology); Computer-supported cooperative work; Process (computing); Computer science; Agency (philosophy); Intersection (aeronautics); Process management; Team effectiveness; Human\u2013computer interaction; Engineering; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3415252",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2986412349",
      "doi": "10.1145/3359239",
      "title": "LibRA",
      "abstract": "Job roles serve as a boundary between an employee and an organization, and are often considered building blocks in understanding the behavior and functioning of organizational systems. However, a lack of clarity about one's role, that is, one's work responsibilities and degree of authority, can lead to absenteeism, turnover, dissatisfaction, stress, and lower workplace performance. This paper proposes a methodology to quantitatively estimate role ambiguity via unobtrusively gathered data from LinkedIn, shared voluntarily by a cohort of information workers spanning multiple organizations. After successfully validating this LinkedIn based measure of Role Ambiguity, or LibRA against a state-of-the-art gold standard, drawing upon theories in organizational psychology, we examine the efficacy and convergent validity of LibRA in explaining established relationships of role ambiguity with wellbeing and performance measures of individuals. We find that greater LibRA is associated with depleted wellbeing, such as increased heart rate, increased arousal, decreased sleep, and higher stress. In addition, greater LibRA is associated with lower job performance such as decreased organizational citizenship behavior and decreased individual task performance. We discuss how LibRA can help fill gaps in state-of-the-art assessments of role ambiguity, and the potential of this measure in building novel technology-mediated strategies to combat role ambiguity in organizations.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Koustuv Saha et al.",
      "keywords": "Ambiguity; CLARITY; Psychology; Organizational citizenship behavior; Social psychology; Job performance; Task (project management); Absenteeism; Role conflict; Applied psychology; Job satisfaction; Computer science; Organizational commitment; Management; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359239",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390781042",
      "doi": "10.1145/3639466",
      "title": "Federated Learning-based Information Leakage Risk Detection for Secure Medical Internet of Things",
      "abstract": "The Medical Internet of Things (MIoT) requires extreme information and communication security, particularly for remote consultation systems. MIoT\u2019s integration of physical and computational components creates a seamless network of medical devices providing high-quality care via continuous monitoring and treatment. However, traditional security methods such as cryptography cannot prevent privacy compromise and information leakage caused by security breaches. To solve this issue, this paper proposes a novel Federated Learning Intrusion Detection System (FLIDS). FLIDS combines Generative Adversarial Network (GAN) and Federated Learning (FL) to detect cyber attacks like Denial of Service (DoS), data modification, and data injection using machine learning. FLIDS shows exceptional performance with over 99% detection accuracy and 1% False Positive Rate (FPR). It saves bandwidth by transmitting 3.8 times fewer bytes compared to central data collection. These results prove FLIDS\u2019 effectiveness in detecting and mitigating security threats in Medical Cyber-Physical Systems (MCPS). The paper recommends scaling up FLIDS to use computing resources from multiple mobile devices for better intrusion detection accuracy and efficiency while reducing the burden on individual devices in MIoT.",
      "year": "2024",
      "journal": "ACM Transactions on Internet Technology",
      "authors": "Tingting Wang et al.",
      "keywords": "Computer science; Computer security; Intrusion detection system; Denial-of-service attack; Information sensitivity; Information leakage; Byte; The Internet; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3639466",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4294533799",
      "doi": "10.1145/3555610",
      "title": "Using HCI in Cross-Disciplinary Teams: A Case Study of Academic Collaboration in HCI-Health Teams in the US Using a Team Science Perspective",
      "abstract": "Human-centered computing research has been increasingly applied to address important challenges in the health domain. Conducting research in cross-disciplinary teams can come with a lot of challenges in integrating knowledge across fields. Yet, we do not know what challenges HCI researchers encounter in building collaborations with health researchers, and how these researchers negotiate challenges while balancing their professional goals. We interviewed 17 early- and mid-career HCI faculty working in the United States who conducted research in collaboration with health researchers. Drawing from a Team Science framework, we share participants' lived experiences and identify major challenges that HCI researchers encounter when finding, collaborating with, and negotiating with health collaborators when building technologies. We propose ways to better support research collaboration aimed at designing technologies using human-centered computing approaches. This includes strategies to support HCI researchers at individual, institutional, research community, and funding agencies levels through tools to translate disciplinary approaches. We suggest institutional policies to support HCI researchers through training, networking, and promotion.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Elena Agapie et al.",
      "keywords": "Negotiation; Discipline; Perspective (graphical); Knowledge management; Engineering ethics; Cross disciplinary; Promotion (chess); Domain (mathematical analysis); Public relations; Sociology; Computer science; Political science; Data science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555610",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2768844221",
      "doi": "10.1145/3009973",
      "title": "Adaptive Contextualization Methods for Combating Selection Bias during High-Dimensional Visualization",
      "abstract": "Large and high-dimensional real-world datasets are being gathered across a wide range of application disciplines to enable data-driven decision making. Interactive data visualization can play a critical role in allowing domain experts to select and analyze data from these large collections. However, there is a critical mismatch between the very large number of dimensions in complex real-world datasets and the much smaller number of dimensions that can be concurrently visualized using modern techniques. This gap in dimensionality can result in high levels of selection bias that go unnoticed by users. The bias can in turn threaten the very validity of any subsequent insights. This article describes Adaptive Contextualization (AC), a novel approach to interactive visual data selection that is specifically designed to combat the invisible introduction of selection bias. The AC approach (1) monitors and models a user\u2019s visual data selection activity, (2) computes metrics over that model to quantify the amount of selection bias after each step, (3) visualizes the metric results, and (4) provides interactive tools that help users assess and avoid bias-related problems. This article expands on an earlier article presented at ACM IUI 2016 [16] by providing a more detailed review of the AC methodology and additional evaluation results.",
      "year": "2017",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "David Gotz et al.",
      "keywords": "Computer science; Selection (genetic algorithm); Contextualization; Visualization; Metric (unit); Domain (mathematical analysis); Selection bias; Curse of dimensionality; Range (aeronautics); Data science; Data mining; Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3009973",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3199451910",
      "doi": "10.1145/3478129",
      "title": "FaceSense",
      "abstract": "Face touch is an unconscious human habit. Frequent touching of sensitive/mucosal facial zones (eyes, nose, and mouth) increases health risks by passing pathogens into the body and spreading diseases. Furthermore, accurate monitoring of face touch is critical for behavioral intervention. Existing monitoring systems only capture objects approaching the face, rather than detecting actual touches. As such, these systems are prone to false positives upon hand or object movement in proximity to one's face (e.g., picking up a phone). We present FaceSense, an ear-worn system capable of identifying actual touches and differentiating them between sensitive/mucosal areas from other facial areas. Following a multimodal approach, FaceSense integrates low-resolution thermal images and physiological signals. Thermal sensors sense the thermal infrared signal emitted by an approaching hand, while physiological sensors monitor impedance changes caused by skin deformation during a touch. Processed thermal and physiological signals are fed into a deep learning model (TouchNet) to detect touches and identify the facial zone of the touch. We fabricated prototypes using off-the-shelf hardware and conducted experiments with 14 participants while they perform various daily activities (e.g., drinking, talking). Results show a macro-F1-score of 83.4% for touch detection with leave-one-user-out cross-validation and a macro-F1-score of 90.1% for touch zone identification with a personalized model.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Vimal Kakaraparthi et al.",
      "keywords": "Computer science; Artificial intelligence; Computer vision; Face detection; Identification (biology); Face (sociological concept); SIGNAL (programming language); Human\u2013computer interaction; Facial recognition system; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3478129",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4318908907",
      "doi": "10.1145/3582491",
      "title": "Data Science---A Systematic Treatment",
      "abstract": "While the success of early data-science applications is evident, the full impact of data science has yet to be realized.",
      "year": "2023",
      "journal": "Communications of the ACM",
      "authors": "M. TAMER \u00d6ZSU",
      "keywords": "Computer science; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3582491",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392377684",
      "doi": "10.1145/3650116",
      "title": "SoK: Analyzing Privacy and Security of Healthcare Data from the User Perspective",
      "abstract": "Interactions in healthcare, by necessity, involve sharing sensitive information to achieve high-quality patient outcomes. Therefore, sensitive data must be carefully protected. This article explores existing privacy and security research conducted in the context of healthcare organizations. We conducted a systematic literature review of N =1,553 articles that examine the security and privacy of healthcare data and focus on 80 articles addressing human factors. Key findings show that much of the healthcare security and privacy research is focused on technology (44.11%, 712 articles), with a lack of emphasis on the human element (4.96%, 80 articles). In the subset of user studies, we find that patients and the general public express concerns about privacy and security with technologies like electronic health records (EHRs). Furthermore, our analysis shows that healthcare professionals often have low awareness of risks related to data security. Additionally, our analysis revealed that most research focuses narrowly on large hospitals, neglecting private practices and the unique challenges they face. We conclude by identifying research gaps and providing potential solutions to enable robust data security for sensitive patient data.",
      "year": "2024",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Faiza Tazi et al.",
      "keywords": "Perspective (graphical); Internet privacy; Health care; Computer science; Computer security; Information privacy; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3650116",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4309618910",
      "doi": "10.1145/3555202",
      "title": "Matching for Peer Support: Exploring Algorithmic Matching for Online Mental Health Communities",
      "abstract": "Online mental health communities (OMHCs) have emerged in recent years as an effective and accessible way to obtain peer support, filling crucial gaps of traditional mental health resources. However, the mechanisms for users to find relationships that fulfill their needs and capabilities in these communities are highly underdeveloped. Using a mixed-methods approach of user interviews and behavioral log analysis on 7Cups.com, we explore central challenges in finding adequate peer relationships in online support platforms and how algorithmic matching can alleviate many of these issues. We measure the impact of using qualities like gender and age in purposeful matching to improve member experiences, with especially salient results for users belonging to vulnerable populations. Lastly, we note key considerations for designing matching systems in the online mental health context, such as the necessity for better moderation to avoid potential harassment behaviors exacerbated by algorithmic matching. Our findings yield key insights into current user experiences in OMHCs as well as design implications for building matching systems in the future for OMHCs.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Anna Fang et al.",
      "keywords": "Matching (statistics); Mental health; Context (archaeology); Salient; Computer science; Key (lock); Moderation; Data science; Internet privacy; Psychology; Computer security; Medicine; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555202",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313272959",
      "doi": "10.1145/3567556",
      "title": "Duty to Respond",
      "abstract": "Social service providers play a vital role in the developmental outcomes of underprivileged youth as they transition into adulthood. Educators, mental health professionals, juvenile justice officers, and child welfare caseworkers often have first-hand knowledge of the trials uniquely faced by these vulnerable youth and are charged with mitigating harmful risks, such as mental health challenges, child abuse, drug use, and sex trafficking. Yet, less is known about whether or how social service providers assess and mitigate the online risk experiences of youth under their care. Therefore, as part of the National Science Foundation (NSF) I-Corps program, we conducted interviews with 37 social service providers (SSPs) who work with underprivileged youth to determine what (if any) online risks are most concerning to them given their role in youth protection, how they assess or become aware of these online risk experiences, and whether they see value in the possibility of using artificial intelligence (AI) as a potential solution for online risk detection. Overall, online sexual risks (e.g., sexual grooming and abuse) and cyberbullying were the most salient concern across all social service domains, especially when these experiences crossed the boundary between the digital and the physical worlds. Yet, SSPs had to rely heavily on youth self-reports to know whether and when online risks occurred, which required building a trusting relationship with youth; otherwise, SSPs became aware only after a formal investigation had been launched. Therefore, most SSPs found value in the potential for using AI as an early detection system and to monitor youth, but they were concerned that such a solution would not be feasible due to a lack of resources to adequately respond to online incidences, access to the necessary digital trace data (e.g., social media), context, and concerns about violating the trust relationships they built with youth. Thus, such automated risk detection systems should be designed and deployed with caution, as their implementation could cause youth to mistrust adults, thereby limiting the receipt of necessary guidance and support. We add to the bodies of research on adolescent online safety and the benefits and challenges of leveraging algorithmic systems in the public sector.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Xavier Caddle et al.",
      "keywords": "Service provider; Mental health; Psychology; Economic Justice; Value (mathematics); Sexual abuse; Service (business); Public relations; Medicine; Poison control; Suicide prevention; Political science; Psychiatry; Business; Medical emergency",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3567556",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297220992",
      "doi": "10.1145/3564275",
      "title": "<i>MediCoSpace</i> : Visual Decision-Support for Doctor-Patient Consultations using Medical Concept Spaces from EHRs",
      "abstract": "Healthcare systems are under pressure from an aging population, rising costs, and increasingly complex conditions and treatments. Although data are determined to play a bigger role in how doctors diagnose and prescribe treatments, they struggle due to a lack of time and an abundance of structured and unstructured information. To address this challenge, we introduce MediCoSpace , a visual decision-support tool for more efficient doctor-patient consultations. The tool links patient reports to past and present diagnoses, diseases, drugs, and treatments, both for the current patient and other patients in comparable situations. MediCoSpace uses textual medical data, deep-learning supported text analysis and concept spaces to facilitate a visual discovery process. The tool is evaluated by five medical doctors. The results show that MediCoSpace facilitates a promising, yet complex way to discover unlikely relations and thus suggests a path toward the development of interactive visual tools to provide physicians with more holistic diagnoses and personalized, dynamic treatments for patients.",
      "year": "2022",
      "journal": "ACM Transactions on Management Information Systems",
      "authors": "Sanne van der Linden et al.",
      "keywords": "Medical diagnosis; Process (computing); Decision support system; Psychology; Computer science; Data science; Medicine; Artificial intelligence; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3564275",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365447235",
      "doi": "10.1145/3592597",
      "title": "A Survey of Threats to Research Literature-dependent Medical AI Solutions",
      "abstract": "Medical Artificial Intelligence (MedAI) harnesses the power of medical research through AI algorithms and vast data to address healthcare challenges. The security, integrity, and credibility of MedAI tools are paramount, because human lives are at stake. Predatory research, in a culture of \u201cpublish or perish,\u201d is exploiting the \u201cpay for publish\u201d model to infiltrate he research literature repositories. Although, it is challenging to measure the actual predatory research induced data pollution and patient harm, our work shows that the breached integrity of MedAI inputs is a serious threat to trust the MedAI output. We review a wide range of research literature discussing the threats of data pollution in the research literature, feasible attacks impacting MedAI solutions, research literature-based tools, and influence on healthcare. Our contribution lies in presenting a comprehensive literature review, addressing the gap of predatory research vulnerabilities affecting MedAI solutions, and helping to develop robust MedAI solutions in the future.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Shalini Saini et al.",
      "keywords": "Computer science; Credibility; Publication; Harm; Data science; Computer security; Medical research; Health care; Internet privacy; Medicine; Political science; Law",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3592597",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386191714",
      "doi": "10.1145/3617361",
      "title": "Patient Acceptance of Self-Monitoring on a Smartwatch in a Routine Digital Therapy: A Mixed-Methods Study",
      "abstract": "Self-monitoring of mood and lifestyle habits is the cornerstone of many therapies, but it is still hindered by persistent issues including inaccurate records, gaps in the monitoring, patient burden, and perceived stigma. Smartwatches have the potential to deliver enhanced self-reports, but their acceptance in clinical mental health settings is unexplored and rendered difficult by a complex theoretical landscape and need for a longitudinal perspective. We present the Mood Monitor smartwatch application for mood and lifestyle habits self-monitoring. We investigated patient acceptance of the app within a routine 8-week digital therapy. We recruited 35 patients of the UK\u2019s National Health Service and evaluated their acceptance through three online questionnaires and a post-study interview. We assessed the clinical feasibility of the Mood Monitor by comparing clinical, usage, and acceptance metrics obtained from the 35 patients with a smartwatch with those from an additional 34 patients without a smartwatch (digital treatment as usual). Findings showed that the smartwatch app was highly accepted by patients, revealed which factors facilitated and impeded this acceptance, and supported clinical feasibility. We provide guidelines for the design of self-monitoring on a smartwatch and reflect on the conduct of human-computer interaction research evaluating user acceptance of mental health technologies.",
      "year": "2023",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Camille Nadal et al.",
      "keywords": "Smartwatch; Mood; Mental health; Wearable computer; Digital health; Medicine; Applied psychology; Self-monitoring; Psychology; Internet privacy; Clinical psychology; Health care; Computer science; Psychiatry; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3617361",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4214849789",
      "doi": "10.1145/3494580",
      "title": "A Survey on Healthy Food Decision Influences Through Technological Innovations",
      "abstract": "It is well known that unhealthy food consumption plays a significant role in dietary and lifestyle-related diseases. Therefore, it is important for researchers to examine methods that may encourage the consumer to consider healthier dietary and lifestyle habits as diseases such as obesity, heart disease, and high blood pressure remain a worldwide issue. One promising approach to influencing healthy dietary and lifestyle habits is food recommendation models that recommend food to users based on various factors such as health effects, nutrition, preferences, and daily habits. Unfortunately, much of this work has focused on individual factors such as taste preferences and often neglects to understand other factors that influence our choices. Additionally, the evaluation of technological approaches often lacks user studies in the context of intended use. In this systematic review of food choice technology, we focus on the factors that may influence food choices and how technology can play a role in supporting those choices. We also describe existing work, approaches, trends, and issues in current food choice technology and give advice for future work areas in this space.",
      "year": "2022",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Jermaine Marshall et al.",
      "keywords": "Food choice; Context (archaeology); Work (physics); Consumption (sociology); Obesity; Marketing; Healthy food; Medicine; Psychology; Business; Engineering; Food science; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3494580",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388977699",
      "doi": "10.1145/3633785",
      "title": "Application of Smart Insoles for Recognition of Activities of Daily Living: A Systematic Review",
      "abstract": "Recent years have witnessed the increasing literature on using smart insoles in health and well-being, and yet, their capability of daily living activity recognition has not been reviewed. This paper addressed this need and provided a systematic review of smart insole-based systems in the recognition of Activities of Daily Living (ADLs). The review followed the PRISMA guidelines, assessing the sensing elements used, the participants involved, the activities recognised, and the algorithms employed. The findings demonstrate the feasibility of using smart insoles for recognising ADLs, showing their high performance in recognising ambulation and physical activities involving the lower body, ranging from 70% to 99.8% of Accuracy, with 13 studies over 95%. The preferred solutions have been those including machine learning. A lack of existing publicly available datasets has been identified, and the majority of the studies were conducted in controlled environments. Furthermore, no studies assessed the impact of different sampling frequencies during data collection, and a trade-off between comfort and performance has been identified between the solutions. In conclusion, real-life applications were investigated showing the benefits of smart insoles over other solutions and placing more emphasis on the capabilities of smart insoles.",
      "year": "2023",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Luigi D\u2019Arco et al.",
      "keywords": "Activities of daily living; Activity recognition; Computer science; Home automation; Independent living; Assisted living; Physical medicine and rehabilitation; Machine learning; Medicine; Physical therapy; Gerontology; Telecommunications",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3633785",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3093956631",
      "doi": "10.1145/3415239",
      "title": "Good for the Many or Best for the Few?",
      "abstract": "Applications in a range of domains, including route planning and well-being, offer advice based on the social information available in prior users' aggregated activity. When designing these applications, is it better to offer: a) advice that if strictly adhered to is more likely to result in an individual successfully achieving their goal, even if fewer users will choose to adopt it? or b) advice that is likely to be adopted by a larger number of users, but which is sub-optimal with regard to any particular individual achieving their goal? We identify this dilemma, characterized as Goal-Directed vs. Adoption-Directed advice, and investigate the design questions it raises through an online experiment undertaken in four advice domains (financial investment, making healthier lifestyle choices, route planning, training for a 5k run), with three user types, and across two levels of uncertainty. We report findings that suggest a preference for advice favoring individual goal attainment over higher user adoption rates, albeit with significant variation across advice domains; and discuss their design implications.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Graham Dove et al.",
      "keywords": "Advice (programming); Preference; Dilemma; Computer science; Social dilemma; Investment (military); Psychology; Knowledge management; Social psychology; Economics; Microeconomics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3415239",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386326584",
      "doi": "10.1145/3617896",
      "title": "Bolstering the Persistence of Black Students in Undergraduate Computer Science Programs: A Systematic Mapping Study",
      "abstract": "Background: People who are racialized, gendered, or otherwise minoritized are underrepresented in computing professions in North America. This is reflected in undergraduate computer science (CS) programs, in which students from marginalized backgrounds continue to experience inequities that do not typically affect White cis-men. This is especially true for Black students in general, and Black women in particular, whose experience of systemic, anti-Black racism compromises their ability to persist and thrive in CS education contexts. Objectives: This systematic mapping study endeavours to (1) determine the quantity of existing non-deficit-based studies concerned with the persistence of Black students in undergraduate CS; (2) summarize the findings and recommendations in those studies; and (3) identify areas in which additional studies may be required. We aim to accomplish these objectives by way of two research questions: (RQ1) What factors are associated with Black students\u2019 persistence in undergraduate CS programs?; and (RQ2) What recommendations have been made to further bolster Black students\u2019 persistence in undergraduate CS education programs? Methods: This systematic mapping study was conducted in accordance with PRISMA 2020 and SEGRESS guidelines. Studies were identified by conducting keyword searches in seven databases. Inclusion and exclusion criteria were designed to capture studies illuminating persistence factors for Black students in undergraduate CS programs. To ensure the completeness of our search results, we engaged in snowballing and an expert-based search to identify additional studies of interest. Finally, data were collected from each study to address the research questions outlined above. Results: Using the methods outlined above, we identified 16 empirical studies, including qualitative, quantitative, and mixed-methods studies informed by a range of theoretical frameworks. Based on data collected from the primary studies in our sample, we identified 13 persistence factors across four categories: (I) social capital, networking, &amp; support; (II) career &amp; professional development; (III) pedagogical &amp; programmatic interventions; and (IV) exposure &amp; access. This data-collection process also yielded 26 recommendations across six stakeholder groups: (i) researchers; (ii) colleges and universities; (iii) the computing industry; (iv) K-12 systems and schools; (v) governments; and (vi) parents. Conclusion: This systematic mapping study resulted in the identification of numerous persistence factors for Black students in CS. Crucially, however, these persistence factors allow Black students to persist, but not thrive, in CS. Accordingly, we contend that more needs to be done to address the systemic inequities faced by Black people in general, and Black women in particular, in computing programs and professions. As evidenced by the relatively small number of primary studies captured by this systematic mapping study, there exists an urgent need for additional, asset-based empirical studies involving Black students in CS. In addition to foregrounding the intersectional experiences of Black women in CS, future studies should attend to the currently understudied experiences of Black men.",
      "year": "2023",
      "journal": "ACM Transactions on Computing Education",
      "authors": "Alvine Boaye Belle et al.",
      "keywords": "Inclusion (mineral); Persistence (discontinuity); Psychology; Higher education; Undergraduate research; Mathematics education; Medical education; Pedagogy; Social psychology; Political science; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3617896",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4307412319",
      "doi": "10.1145/3569489",
      "title": "SleepMore",
      "abstract": "The availability of commercial wearable trackers equipped with features to monitor sleep duration and quality has enabled more useful sleep health monitoring applications and analyses. However, much research has reported the challenge of long-term user retention in sleep monitoring through these modalities. Since modern Internet users own multiple mobile devices, our work explores the possibility of employing ubiquitous mobile devices and passive WiFi sensing techniques to predict sleep duration as the fundamental measure for complementing long-term sleep monitoring initiatives. In this paper, we propose SleepMore, an accurate and easy-to-deploy sleep-tracking approach based on machine learning over the user's WiFi network activity. It first employs a semi-personalized random forest model with an infinitesimal jackknife variance estimation method to classify a user's network activity behavior into sleep and awake states per minute granularity. Through a moving average technique, the system uses these state sequences to estimate the user's nocturnal sleep period and its uncertainty rate. Uncertainty quantification enables SleepMore to overcome the impact of noisy WiFi data that can yield large prediction errors. We validate SleepMore using data from a month-long user study involving 46 college students and draw comparisons with the Oura Ring wearable. Beyond the college campus, we evaluate SleepMore on non-student users of different housing profiles. Our results demonstrate that SleepMore produces statistically indistinguishable sleep statistics from the Oura ring baseline for predictions made within a 5% uncertainty rate. These errors range between 15-28 minutes for determining sleep time and 7-29 minutes for determining wake time, proving statistically significant improvements over prior work. Our in-depth analysis explains the sources of errors.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Camellia Zakaria et al.",
      "keywords": "Computer science; Wearable computer; Sleep (system call); Real-time computing; Duration (music); Mobile device; Machine learning; Artificial intelligence; Embedded system; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3569489",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393378029",
      "doi": "10.1145/3654664",
      "title": "Domain Adaptation and Generalization of Functional Medical Data: A Systematic Survey of Brain Data",
      "abstract": "Despite the excellent capabilities of machine learning algorithms, their performance deteriorates when the distribution of test data differs from the distribution of training data. In medical data research, this problem is exacerbated by its connection to human health, expensive equipment, and meticulous setups. Consequently, achieving domain generalizations and domain adaptations under distribution shifts is an essential step in the analysis of medical data. As the first systematic review of domain generalization and domain adaptation on functional brain signals, the article discusses and categorizes various methods, tasks, and datasets in this field. Moreover, it discusses relevant directions for future research.",
      "year": "2024",
      "journal": "ACM Computing Surveys",
      "authors": "Gita Sarafraz et al.",
      "keywords": "Computer science; Adaptation (eye); Generalization; Domain adaptation; Domain (mathematical analysis); Artificial intelligence; Data science; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3654664",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4402500624",
      "doi": "10.1145/3686972",
      "title": "Extended Reality Trans Technologies: Bridging Digital and Physical Worlds to Support Transgender People",
      "abstract": "Extended reality (XR) technologies are becoming increasingly pervasive, and may have capacity to help marginalized groups such as transgender people. Drawing from interviews with n = 18 creators of trans technology, we examined how XR technologies do and can support trans people. We uncovered a number of creative ways that XR technologies support trans experiences. Trans technology creators are designing augmented reality (AR) and virtual reality (VR) systems that help people explore trans identity, experience new types of bodies, educate about and display trans stories and curated trans content, manipulate the physical world, and innovate gender-affirming surgical techniques. Additionally, we show how considering XR as an analogy for trans identity helps us to think about the fluidity and fluctuation inherent in trans identity in new ways, which in turn enables envisioning technologies that can better support complex and changing identities. Despite XR's potential for supporting trans people, current AR and VR systems face limitations that restrict their large-scale use, but as access to XR systems increase, so will their capacity to improve trans lives.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Oliver L. Haimson et al.",
      "keywords": "Bridging (networking); Transgender; Transgender people; Psychology; Sociology; Internet privacy; Human\u2013computer interaction; Computer science; Gender studies; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3686972",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4296783789",
      "doi": "10.1145/3563042",
      "title": "Prediction Method of Government Economic Situation based on Big Data Analysis",
      "abstract": "In order to improve the forecasting accuracy of economic situation, a government economic situation forecasting method based on big data analysis is proposed. According to the hardware structure of the system, STC12C5608AD is used as the data acquisition terminal chip to simplify the circuit. The proposed forecasting method can give real-time early warning to the government's economic situation. The software part screens the influencing factors of government economic development, constructs a government economic development index system, collects government economic index data, cleans, clusters, classifies, and standardizes the government economic index data, and extracts the preprocessed government economic index data from the preprocessed government economic index data through data mining. The economic development features are extracted and then input into the neural network. After training and learning, the predicted value of the economic situation is output, and the economic situation level is classified. The experimental results show that the proposed method reduces the error rate of economic situation forecast, shortens the forecast time, improves the forecast accuracy and efficiency, with the peak error ratio not exceeding 15%.",
      "year": "2022",
      "journal": "Digital Government Research and Practice",
      "authors": "Yisheng Liu et al.",
      "keywords": "Index (typography); Government (linguistics); Computer science; Economic statistics; Big data; Artificial neural network; Economic forecasting; Economic indicator; Economic data; Order (exchange); Econometrics; Data mining; Artificial intelligence; Economics; Finance; Macroeconomics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3563042",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385986381",
      "doi": "10.1145/3616021",
      "title": "Clinical Phenotyping with an Outcomes-driven Mixture of Experts for Patient Matching and Risk Estimation",
      "abstract": "Observational medical data present unique opportunities for analysis of medical outcomes and treatment decision making. However, because these datasets do not contain the strict pairing of randomized control trials, matching techniques are to draw comparisons among patients. A key limitation to such techniques is verification that the variables used to model treatment decision making are also relevant in identifying the risk of major adverse events. This article explores a deep mixture of experts approach to jointly learn how to match patients and model the risk of major adverse events in patients. Although trained with information regarding treatment and outcomes, after training, the proposed model is decomposable into a network that clusters patients into phenotypes from information available before treatment. This model is validated on a dataset of patients with acute myocardial infarction complicated by cardiogenic shock. The mixture of experts approach can predict the outcome of mortality with an area under the receiver operating characteristic curve of 0.85 \u00b1 0.01 while jointly discovering five potential phenotypes of interest. The technique and interpretation allow for identifying clinically relevant phenotypes that may be used both for outcomes modeling as well as potentially evaluating individualized treatment effects.",
      "year": "2023",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Nathan C. Hurley et al.",
      "keywords": "Observational study; Matching (statistics); Computer science; Randomized controlled trial; Outcome (game theory); Receiver operating characteristic; Machine learning; Artificial intelligence; Intensive care medicine; Medicine; Data mining; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3616021",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226053008",
      "doi": "10.1145/3512912",
      "title": "Surfacing Equity Issues in Large Computing Courses with Peer-Ranked, Demographically-Labeled Student Feedback",
      "abstract": "As computing courses become larger, students of minoritized groups continue to disproportionately face challenges that hinder their academic and professional success (e.g. implicit bias, microaggressions, lack of resources, assumptions of preparatory privilege). This can impact career aspirations and sense of belonging in computing communities. Instructors have the power to make immediate changes to support more equitable learning, but they are often unaware of students' challenges. To help both instructors and students understand the inequities in their classes, we developed StudentAmp, an interactive system that uses student feedback and self-reported demographic information (e.g. gender, ethnicity, disability, educational background) to show challenges and how they affect students differently. To help instructors make sense of feedback, StudentAmp ranks challenges by student-perceived disruptiveness. We conducted formative evaluations with five large college computing courses (150 - 750 students) being taught remotely during the COVID-19 pandemic. We found that students shared challenges beyond the scope of the course, perceived sharing information about who they were as useful but potentially dangerous, and that teaching teams were able to use this information to consider the positionality of students sharing challenges. Our findings relate to a central design tension of supporting equity by sharing contextualized information about students while also ensuring their privacy and well-being.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Benjamin Xie et al.",
      "keywords": "Equity (law); Formative assessment; Privilege (computing); Psychology; Ethnic group; Medical education; Mathematics education; Computer science; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3512912",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4247716657",
      "doi": "10.1145/1400181",
      "title": "",
      "abstract": "This book is the only source that provides comprehensive, current, and correct information on problem solving using modern heuristics.It covers classic methods of optimization, including dynamic programming, the simplex method, and gradient techniques, as well as recent innovations such as simulated annealing, tabu search, and evolutionary computation.This second edition contains two new chapters, one on co evolutionary systems and one on multicriterial decision-making.Also some new puzzles are added and various subchapters are revised.",
      "year": "2008",
      "journal": "Communications of the ACM",
      "authors": "Zbigniew Michalewicz et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "paratext",
      "url": "https://doi.org/10.1145/1400181",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4377012943",
      "doi": "10.1145/3591130",
      "title": "Exploring the Effects of Scanpath Feature Engineering for Supervised Image Classification Models",
      "abstract": "Image classification models are becoming a popular method of analysis for scanpath classification. To implement these models, gaze data must first be reconfigured into a 2D image. However, this step gets relatively little attention in the literature as focus is mostly placed on model configuration. As standard model architectures have become more accessible to the wider eye-tracking community, we highlight the importance of carefully choosing feature representations within scanpath images as they may heavily affect classification accuracy. To illustrate this point, we create thirteen sets of scanpath designs incorporating different eye-tracking feature representations from data recorded during a task-based viewing experiment. We evaluate each scanpath design by passing the sets of images through a standard pre-trained deep learning model as well as a SVM image classifier. Results from our primary experiment show an average accuracy improvement of 25 percentage points between the best-performing set and one baseline set.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Sean Anthony Byrne et al.",
      "keywords": "Artificial intelligence; Computer science; Classifier (UML); Support vector machine; Pattern recognition (psychology); Eye tracking; Contextual image classification; Gaze; Feature (linguistics); Feature extraction; Machine learning; Set (abstract data type); Feature engineering; Image (mathematics); Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3591130",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297320250",
      "doi": "10.1145/3564274",
      "title": "Examining Disease Multimorbidity in U.S. Hospital Visits Before and During COVID-19 Pandemic: A Graph Analytics Approach",
      "abstract": "Enduring effects of the COVID-19 pandemic on healthcare systems can be preempted by identifying patterns in diseases recorded in hospital visits over time. Disease multimorbidity or simultaneous occurrence of multiple diseases is a growing global public health challenge as populations age and long-term conditions become more prevalent. We propose a graph analytics framework for analyzing disease multimorbidity in hospital visits. Within the framework, we propose a graph model to explain multimorbidity as a function of prevalence, category, and chronic nature of the underlying disease. We apply our model to examine and compare multimorbidity patterns in public hospitals in Arizona, U.S., during five six-month time periods before and during the pandemic. We observe that while multimorbidity increased by 34.26% and 41.04% during peak pandemic for mental disorders and respiratory disorders respectively, the gradients for endocrine diseases and circulatory disorders were not significant. Multimorbidity for acute conditions is observed to be decreasing during the pandemic while multimorbidity for chronic conditions remains unchanged. Our graph analytics framework provides guidelines for empirical analysis of disease multimorbidity using electronic health records. The patterns identified using our proposed graph model informs future research and healthcare policy makers for pre-emptive decision making.",
      "year": "2022",
      "journal": "ACM Transactions on Management Information Systems",
      "authors": "Karthik Srinivasan et al.",
      "keywords": "Multimorbidity; Pandemic; Analytics; Disease; Coronavirus disease 2019 (COVID-19); Public health; Medicine; Health care; Graph; Data science; Computer science; Infectious disease (medical specialty); Nursing; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3564274",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4200219457",
      "doi": "10.1145/3483411",
      "title": "Computer-Assisted Cohort Identification in Practice",
      "abstract": "The standard approach to expert-in-the-loop machine learning is active learning, where, repeatedly, an expert is asked to annotate one or more records and the machine finds a classifier that respects all annotations made until that point. We propose an alternative approach, IQRef , in which the expert iteratively designs a classifier and the machine helps him or her to determine how well it is performing and, importantly, when to stop, by reporting statistics on a fixed, hold-out sample of annotated records. We justify our approach based on prior work giving a theoretical model of how to re-use hold-out data. We compare the two approaches in the context of identifying a cohort of EHRs and examine their strengths and weaknesses through a case study arising from an optometric research problem. We conclude that both approaches are complementary, and we recommend that they both be employed in conjunction to address the problem of cohort identification in health research.",
      "year": "2021",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Besat Kassaie et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Classifier (UML); Strengths and weaknesses; Cohort; Identification (biology); Data mining; Statistics; Psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3483411",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385696377",
      "doi": "10.1145/3614427",
      "title": "Low Resource Language Analysis Using Deep Learning Algorithm for Gender Classification",
      "abstract": "Voice signals are the essential input source for applications based on human and computer interaction technology. Gender identification through voice signals is one of the most challenging tasks. For voice signal based analysis, deep learning algorithms provide an alternative to traditional and conventional algorithms for classification. To identify the gender through voice signals of female, male and \u2018first-time\u2019 transgender, the deep learning algorithm is used to improve the robustness of the identification model with the Mel Frequency Cepstrum Coefficients (MFCC) as a feature of the voice signals. This article presents the identification accuracy of gender with the help of recorded live voice signals. The voice samples of the third gender are recorded in the Hindi language. These Hindi language voice samples of transgender are very low resources and are unavailable at any recognized sources. The simulation results do not depend on the duration of the signals and are text independent. The recurrent neural network \u2013 Bidirectional Long Short-term Memory (RNN \u2013 BiLSTM) algorithm has been simulated on the recorded voice signals. The simulation outcome is compared with the earlier reported results in the literature. The gender-wise average accuracy of the proposed model is achieved as 91.44%, 94.94%, and 96.11% for males, females, and transgender, respectively, using voice signals. The identification accuracy of transgender is high in comparison to other genders. On the other hand, the average accuracy of the proposed model is obtained as 94.16%.",
      "year": "2023",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Abhishek Singhal et al.",
      "keywords": "Computer science; Mel-frequency cepstrum; Speech recognition; Artificial intelligence; Robustness (evolution); Cepstrum; Transgender; Feature (linguistics); Hindi; Identification (biology); Deep learning; Support vector machine; Pattern recognition (psychology); Feature extraction; Machine learning; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3614427",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4256660407",
      "doi": "10.1145/134374.1096744",
      "title": "Selected IR-Related Dissertation Abstracts",
      "abstract": "article Free Access Share on Selected IR-Related Dissertation Abstracts Editor: Susanne M. Humphrey View Profile Authors Info & Claims ACM SIGIR ForumVolume 26Issue 1Spring 1992 pp 22\u201347https://doi.org/10.1145/134374.1096744Online:01 February 1992Publication History 0citation98DownloadsMetricsTotal Citations0Total Downloads98Last 12 Months1Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
      "year": "1992",
      "journal": "ACM SIGIR Forum",
      "authors": "Susanne M. Humphrey",
      "keywords": "Computer science; Citation; World Wide Web; Information retrieval; Library science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/134374.1096744",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413949187",
      "doi": "10.1145/3749482",
      "title": "The Cognitive Strategies Behind Multimodal Health Sensemaking: A Menstrual Health Tracking Case Study",
      "abstract": "The proliferation of commodity devices for gathering health data has led to multimodal health trackers that provide increasingly holistic views of people's well-being. As these trackers become more complex, it becomes harder for users to interpret how different signals interrelate in order to derive actionable insights and make informed health decisions. Addressing this challenge first requires understanding the cognitive and behavioral processes through which users interpret and make sense of multimodal data. In this paper, we use menstrual health tracking as a case study for investigating how individuals interpret multimodal health data. We conducted a 100-day longitudinal study with 20 participants who used a variety of health trackers to monitor signals relevant to menstrual health (e.g., hormones, sleep, mood). Through surveys and interviews, we identified that participants aligned their health goals with each device's perceived scope and approached multimodal data with hypotheses that involved pairs of signals. Our findings shed light on how a person's confidence in the sensemaking processes shapes their engagement with multimodality, leading to design recommendations that scaffold trust between users and their devices while encouraging exploration and staying true to users' evolving health goals.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Georgianna Lin et al.",
      "keywords": "Sensemaking; Tracking (education); Psychology; Cognition; Medicine; Computer science; Knowledge management; Psychiatry; Pedagogy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749482",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413968349",
      "doi": "10.1145/3749489",
      "title": "SpiroSense: Transforming Smartphones into Pulmonary Metrics Monitors with Ultrasonic Technology",
      "abstract": "Chronic respiratory conditions such as Chronic Obstructive Pulmonary Disease (COPD) and asthma often progress insidiously, making early detection vital for effective intervention. Current gold-standard Pulmonary Function Testing (PFT) methods, such as spirometry, evaluate lung function by measuring airflow rates to detect potential obstructions. But, their cost, often several hundred dollars or more, limits their accessibility for regular at-home monitoring. In this paper, we present SpiroSense, a novel system that transforms a smartphone into a portable, low-cost, and accurate PFT device for everyday use by integrating a custom 3D-printed attachment costing just a dozen dollars. However, a critical limitation arises from the smartphone's inherent audio sampling rate (typically 48kHz), which constrains the airflow resolution to 11.9L/s when using conventional cross-correlation-based time delay estimation. This coarse resolution is insufficient to capture key pulmonary metrics, such as a Peak Expiratory Flow (PEF) of 10 L/s, with high fidelity. To address this, we propose SonicFlow, which establishes a foundational airflow rate sensing model based on ultrasonic phase features and improves the airflow rate resolution to 0.148L/s. Furthermore, airflow-induced high-frequency harmonic noise within the 3D-printed model, combined with ambient environmental noise, further complicates accurate sensing. To mitigate this, we introduce NoiseClear, an end-to-end ultrasonic signal enhancement model designed to effectively suppress noise while preserving critical airflow velocity information. We prototype SpiroSense and evaluate its performance on a cohort of 59 participants, including 29 healthy individuals and 30 patients. Experimental results show that SpiroSense achieves average estimation error of 6.44% for Forced Vital Capacity (FVC), 7.42% for Forced Expiratory Volume in one second (FEV1), and 3.01% for the FEV1/FVC ratio.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Long Fan et al.",
      "keywords": "Ultrasonic sensor; Computer science; Environmental science; Acoustics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749489",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413968224",
      "doi": "10.1145/3749480",
      "title": "Computing with Smart Rings: A Systematic Literature Review",
      "abstract": "A smart ring is a wearable electronic device in the form of a ring that incorporates diverse sensors and computing technologies to perform a variety of functions. Designed for use with fingers, smart rings are capable of sensing more subtle and abundant hand movements, thus making them a good platform for interaction. Meanwhile, fingers are abundant with blood vessels and nerve endings and accustomed to wearing rings, providing an ideal site for continuous health monitoring through smart rings, which combine comfort with the ability to capture vital biometric data, making them suitable for all-day wear. We collected in total of 206 smart ring-related publications and conducted a systematic literature review. We provide a taxonomy regarding the sensing and feedback modalities, applications, and phenomena. We review and categorize these literatures into four main areas: (1) interaction - input, (2) interaction - output, (3) passive sensing - in body feature, (4) passive sensing - out body activity. This comprehensive review highlights the current advancements within the field of smart ring and identifies potential areas for future research.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Z. S. Wang et al.",
      "keywords": "Computer science; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749480",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4366004108",
      "doi": "10.1145/3579628",
      "title": "Toward Supporting Perceptual Complementarity in Human-AI Collaboration via Reflection on Unobservables",
      "abstract": "In many real world contexts, successful human-AI collaboration requires humans to productively integrate complementary sources of information into AI-informed decisions. However, in practice human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves. There are few available guidelines regarding how to effectively communicate aboutunobservables: features that may influence the outcome, but which are unavailable to the model. In this work, we conducted an online experiment to understand whether and how explicitly communicating potentially relevant unobservables influences how people integrate model outputs and unobservables when making predictions. Our findings indicate that presenting prompts about unobservables can change how humans integrate model outputs and unobservables, but do not necessarily lead to improved performance. Furthermore, the impacts of these prompts can vary depending on decision-makers' prior domain expertise. We conclude by discussing implications for future research and design of AI-based decision support tools.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Kenneth Holstein et al.",
      "keywords": "Complementarity (molecular biology); Perception; Computer science; Relation (database); Data science; Knowledge management; Psychology; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579628",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3206387060",
      "doi": "10.1145/3505245",
      "title": "Deep Transfer Learning &amp; Beyond: Transformer Language Models in Information Systems Research",
      "abstract": "AI is widely thought to be poised to transform business, yet current perceptions of the scope of this transformation may be myopic. Recent progress in natural language processing involving transformer language models (TLMs) offers a potential avenue for AI-driven business and societal transformation that is beyond the scope of what most currently foresee. We review this recent progress as well as recent literature utilizing text mining in top IS journals to develop an outline for how future IS research can benefit from these new techniques. Our review of existing IS literature reveals that suboptimal text mining techniques are prevalent and that the more advanced TLMs could be applied to enhance and increase IS research involving text data, and to enable new IS research topics, thus creating more value for the research community. This is possible because these techniques make it easier to develop very powerful custom systems and their performance is superior to existing methods for a wide range of tasks and applications. Further, multilingual language models make possible higher quality text analytics for research in multiple languages. We also identify new avenues for IS research, like language user interfaces, that may offer even greater potential for future IS research.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "Ross Gruetzemacher et al.",
      "keywords": "Computer science; Scope (computer science); Data science; Transformer; Artificial intelligence; Programming language",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3505245",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2985204356",
      "doi": "10.1145/3359190",
      "title": "Narrative Paths and Negotiation of Power in Birth Stories",
      "abstract": "Birth stories have become increasingly common on the internet, but they have received little attention as a computational dataset. These unsolicited, publicly posted stories provide rich descriptions of decisions, emotions, and relationships during a common but sometimes traumatic medical experience. These personal details can be illuminating for medical practitioners, and due to their shared structures, birth stories are also an ideal testing ground for narrative analysis techniques. We present an analysis of 2,847 birth stories from an online forum and demonstrate the utility of these stories for computational work. We discover clear sentiment, topic and persona-based patterns that both model the expected narrative event sequences of birth stories and highlight diverging pathways and exceptions to narrative norms. The authors' motivation to publicly post these personal stories can be a way to regain power after a surveilled and disempowering experience, and we explore power relationships between the personas in the stories, showing that these dynamics can vary with the type of birth (e.g., medicated vs unmedicated). Finally, birth stories exist in a space that is both public and deeply personal. This liminality poses a challenge for analysis and presentation, and we discuss tradeoffs and ethical practices for this collection. WARNING: This paper includes detailed narratives of pregnancy and birth.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Maria Antoniak et al.",
      "keywords": "Narrative; Persona; Liminality; Negotiation; Power (physics); Narrative inquiry; Storytelling; Presentation (obstetrics); Narrative structure; Psychology; Social psychology; Sociology; Computer science; Aesthetics; Medicine; Literature; Art; Social science; Obstetrics; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359190",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4362454930",
      "doi": "10.1145/3589955",
      "title": "<scp>Paper Plain</scp> : Making Medical Research Papers Approachable to Healthcare Consumers with Natural Language Processing",
      "abstract": "When seeking information not covered in patient-friendly documents, healthcare consumers may turn to the research literature. Reading medical papers, however, can be a challenging experience. To improve access to medical papers, we explore four features enabled by natural language processing: definitions of unfamiliar terms, in-situ plain language section summaries, a collection of key questions that guides readers to answering passages, and plain language summaries of those passages. We embody these features into a prototype system, Paper Plain . We evaluate Paper Plain , finding that participants who used the prototype system had an easier time reading research papers without a loss in paper comprehension compared to those who used a typical PDF reader. Altogether, the study results suggest that guiding readers to relevant passages and providing plain language summaries alongside the original paper content can make reading medical papers easier and give readers more confidence to approach these papers.",
      "year": "2023",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Tal August et al.",
      "keywords": "Plain language; Reading (process); Plain English; Comprehension; Computer science; Key (lock); Plain text; Reading comprehension; Natural (archaeology); World Wide Web; Question answering; Natural language processing; Linguistics; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3589955",
      "cited_by_count": 44,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2892246074",
      "doi": "10.1145/3264937",
      "title": "Using Autoencoders to Automatically Extract Mobility Features for Predicting Depressive States",
      "abstract": "Recent studies have shown the potential of exploiting GPS data for passively inferring people's mental health conditions. However, feature extraction for characterizing human mobility remains a heuristic process that relies on the domain knowledge of the condition under consideration. Moreover, we do not have guarantees that these \"hand-crafted\" metrics are able to effectively capture mobility behavior of users. Indeed, informative emerging patterns in the data might not be characterized by them. This is also a complex and often time-consuming task, since it usually consists of a lengthy trial-and-error process. In this paper, we investigate the potential of using autoencoders for automatically extracting features from the raw input data. Through a series of experiments we show the effectiveness of autoencoder-based features for predicting depressive states of individuals compared to \"hand-crafted\" ones. Our results show that automatically extracted features lead to an improvement of the performance of the prediction models, while, at the same time, reducing the complexity of the feature design task. Moreover, through an extensive experimental performance analysis, we demonstrate the optimal configuration of the key parameters at the basis of the proposed approach.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Abhinav Mehrotra et al.",
      "keywords": "Autoencoder; Computer science; Heuristic; Artificial intelligence; Process (computing); Task (project management); Machine learning; Feature (linguistics); Feature extraction; Domain (mathematical analysis); Basis (linear algebra); Raw data; Pattern recognition (psychology); Data mining; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3264937",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387344366",
      "doi": "10.1145/3626319",
      "title": "Efficient Low-Resource Medical Information Processing Based on Semantic Analysis and Granular Computing",
      "abstract": "The rise of the digital economy and e-commerce has fostered a movement towards efficient low-resource medical information processing, a trend that holds great importance in the healthcare sector. Diabetes, being a widespread chronic condition, has witnessed the introduction of glucometers, which offer patients a convenient method of monitoring their blood sugar levels. However, it is worth noting that a considerable proportion of online comments may be subject to emotional bias or contain inaccurate information. Furthermore, the performance of glucometers can be influenced by several attributes, including price, accuracy and portability, thereby potentially complicating the decision-making process for consumers. Semantic analysis can be employed to acquire valuable information, aiding consumers in reasonably choosing the suitable glucometer. This paper utilizes the benefits of granular computing, an emerging computing paradigm, to effectively handle incomplete and uncertain medical information. It employs generalized fuzzy sets, rough sets and three-way decisions (TWD) techniques to boost the accuracy and reliability of medical information fusion. Subsequently, the MABAC (Multi-Attribute Border Approximation Area Comparison) method is utilized to evaluate the reviews of every glucometer, calculate their aggregated scores, and rank and compare them. Ultimately, in light of consumers\u2019 needs and trade-offs, the glucometer with the highest score can be selected. The proposed approach comprehensively considers the weight and priority of multiple attributes, reduces information overload and mitigates selection difficulties, thereby enhancing the accuracy and reliability of low-resource medical information processing.",
      "year": "2023",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Yu-Ting Cheng et al.",
      "keywords": "Computer science; Reliability (semiconductor); Process (computing); Resource (disambiguation); Risk analysis (engineering); Granular computing; Information processing; Software portability; Data science; Data mining; Rough set; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3626319",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4378837867",
      "doi": "10.1145/3600230",
      "title": "Methodical Systematic Review of Abstractive Summarization and Natural Language Processing Models for Biomedical Health Informatics: Approaches, Metrics and Challenges",
      "abstract": "Text summarization tasks are primarily very useful for decision support systems and provide a source for useful data for training of bots as they can reduce and retain the useful information from the large corpus. This review article is for studying the literature that already exists in context of abstractive summarization and application of NLP language models in biomedical and associated healthcare applications. In past decade with trends like bigdata, IOT, enormous amount of data is getting processed in all structured, unstructured and semi structured formats. This review provides a comprehensive literature survey in research trends for abstractive summarization, foundations of machine translation and evolution of language models. This review identifies the potential of language model to provide a possible methodology for improving the performance and accuracy of various tasks in summarization. Deep neural network-based language models have now been the widely accepted state of art for various abstractive summarization and there exists an enormous scope to improvise and tune the language models for domain specific use case. This study shows current systems lack in faithfulness to original content and control of degree of hallucination. This review also details on the evaluation criteria and need for automated metrics and attempts to provide guideline for evaluation for abstractive summarization for health informatics.",
      "year": "2023",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Praveen Kumar Katwe et al.",
      "keywords": "Automatic summarization; Computer science; Natural language processing; Artificial intelligence; Context (archaeology); Data science; Machine translation; Scope (computer science); Health informatics; Domain (mathematical analysis); Information retrieval; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3600230",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4308391738",
      "doi": "10.1145/3523282",
      "title": "Study on Machine Translation Teaching Model Based on Translation Parallel Corpus and Exploitation for Multimedia Asian Information Processing",
      "abstract": "Text in one language can be mechanically translated into another language using machine translation (MT). It is possible to anticipate a sequence of words, generally modeling full sentences using machine translation in a single integrated model. Human language's flexibility makes automatic translation an artificial intelligence (AI) challenge of the highest order. A single model rather than a pipeline of fine-tuned models is now the best way to attain state-of-the-art outcomes in machine translation. For example, words having numerous meanings, phrases that use more than one grammatical structure, and other grammar issues make it difficult for a machine to translate; however, many misinterpretations translate to be a breeze. A teacher's job is to assist pupils in overcoming the emotional and cognitive obstacles that stand in the way of developing effective problem-solving abilities. Students will benefit from developing problem-solving abilities since they will apply what they have learned to new circumstances. MT-AI, machine translation technology, and products have been employed in a wide range of applications, including business travel, tourism, and cross-lingual information retrieval. Text translation and phonetic translation are two types of translations that focus on the content of the source language. It is possible to create self-learning systems by injecting machine learning techniques into existing software and then observing the results of such injection. Computer software can translate a massive volume of text in a short period. It takes longer for a human translator to perform the same work as a computer program. The simulation investigation is developed based on correctness and effectiveness, demonstrating the proposed framework's reliability of 95.1%.",
      "year": "2022",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Yan Gong",
      "keywords": "Machine translation; Computer science; Artificial intelligence; Natural language processing; Rule-based machine translation; Machine translation software usability; Example-based machine translation; Computer-assisted translation; Pipeline (software); Flexibility (engineering); Transfer-based machine translation; Focus (optics); Grammar; Synchronous context-free grammar; Translation (biology); Linguistics; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3523282",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386162676",
      "doi": "10.1145/3617180",
      "title": "SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for Actionable Healthcare",
      "abstract": "The synthetic control method has pioneered a class of powerful data-driven techniques to estimate the counterfactual reality of a unit from donor units. At its core, the technique involves a linear model fitted on the pre-intervention period that combines donor outcomes to yield the counterfactual. However, linearly combining spatial information at each time instance using time-agnostic weights fails to capture important inter-unit and intra-unit temporal contexts and complex nonlinear dynamics of real data. We instead propose an approach to use local spatiotemporal information before the onset of the intervention as a promising way to estimate the counterfactual sequence. To this end, we suggest a Transformer model that leverages particular positional embeddings, a modified decoder attention mask, and a novel pre-training task to perform spatiotemporal sequence-to-sequence modeling. Our experiments on synthetic data demonstrate the efficacy of our method in the typical small donor pool setting and its robustness against noise. We also generate actionable healthcare insights at the population and patient levels by simulating a state-wide public health policy to evaluate its effectiveness, an in silico trial for asthma medications to support randomized controlled trials, and a medical intervention for patients with Friedreich\u2019s ataxia to improve clinical decision making and promote personalized therapy (code is available at https://github.com/JHA-Lab/scout ).",
      "year": "2023",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Bhishma Dedhia et al.",
      "keywords": "Counterfactual thinking; Computer science; Robustness (evolution); Synthetic data; Health care; Machine learning; Transformer; Artificial intelligence; Data mining; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3617180",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W1976978876",
      "doi": "10.1145/2701583.2701592",
      "title": "Report on the SIGIR 2014 Workshop on Medical Information Retrieval (MedIR)",
      "abstract": "The workshop on Medical Information Retrieval took place at SIGIR 2014 in Gold Coast, Australia on July 11. The workshop included eight oral presentations of referred papers and an invited keynote presentation. This allowed time for lively discussions among the participants. These showed the significant interest in the medical information retrieval domain and the many research challenges arising in this space which need to be addressed to give added value to the wide variety of users that can profit from medical information search, such as patients, general health professionals and specialist groups such as radiologists who mainly search for images and image related information.",
      "year": "2014",
      "journal": "ACM SIGIR Forum",
      "authors": "Lorraine Goeuriot et al.",
      "keywords": "Computer science; Presentation (obstetrics); Information retrieval; Variety (cybernetics); World Wide Web; Space (punctuation); Library science; Medicine; Radiology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/2701583.2701592",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4304693602",
      "doi": "10.1145/3564610",
      "title": "Security and Usability of a Personalized User Authentication Paradigm: Insights from a Longitudinal Study with Three Healthcare Organizations",
      "abstract": "This article proposes a user-adaptable and personalized authentication paradigm for healthcare organizations, which anticipates to seamlessly reflect patients\u2019 episodic and autobiographical memories to graphical and textual passwords aiming to improve the security strength of user-selected passwords and provide a positive user experience. We report on a longitudinal study that spanned over 3 years in which three public European healthcare organizations participated to design and evaluate the aforementioned paradigm. Three studies were conducted ( n = 169) with different stakeholders: (1) a verification study aiming to identify existing authentication practices of the three healthcare organizations with diverse stakeholders ( n = 9), (2) a patient-centric feasibility study during which users interacted with the proposed authentication system ( n = 68), and (3) a human guessing attack study focusing on vulnerabilities among people sharing common experiences within location-aware images used for graphical passwords ( n = 92). Results revealed that the suggested paradigm scored high with regard to users\u2019 likeability, perceived security, usability, and trust, but more importantly it assists the creation of more secure passwords. On the downside, the suggested paradigm introduces password guessing vulnerabilities by individuals sharing common experiences with the end users. Findings are expected to scaffold the design of more patient-centric knowledge-based authentication mechanisms within today's dynamic computation realms.",
      "year": "2022",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Argyris Constantinides et al.",
      "keywords": "Usability; Password; Computer science; Authentication (law); Health care; User-centered design; Internet privacy; World Wide Web; Computer security; Knowledge management; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3564610",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4410579485",
      "doi": "10.1145/3733702",
      "title": "Generative AI at the Edge: Challenges and Opportunities",
      "abstract": "Generative AI at the edge is the next phase in AI's deployment: from centralized supercomputers to ubiquitous assistants and creators operating alongside humans. The challenges are significant but so are the opportunities for personalization, privacy, and innovation. By tackling the technical hurdles and establishing new frameworks (conceptual and infrastructural), we can ensure this transition is successful and beneficial.",
      "year": "2025",
      "journal": "Queue",
      "authors": "Vijay Janapa Reddi",
      "keywords": "Generative grammar; Enhanced Data Rates for GSM Evolution; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3733702",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4414128359",
      "doi": "10.1145/3764113",
      "title": "Unique Security and Privacy Threats of Large Language Models: A Comprehensive Survey",
      "abstract": "With the rapid development of artificial intelligence, large language models (LLMs) have made remarkable advancements in natural language processing. These models are trained on vast datasets to exhibit powerful language understanding and generation capabilities across various applications, including chatbots and agents. However, LLMs have revealed a variety of privacy and security issues throughout their life cycle, drawing significant academic and industrial attention. Moreover, the risks faced by LLMs differ significantly from those encountered by traditional language models. Given that current surveys lack a clear taxonomy of unique threat models across diverse scenarios, we emphasize the unique privacy and security threats associated with four specific scenarios: pre-training, fine-tuning, deployment, and LLM-based agents. Addressing the characteristics of each risk, this survey outlines and analyzes potential countermeasures. Research on attack and defense situations can offer feasible research directions, enabling more areas to benefit from LLMs.",
      "year": "2025",
      "journal": "ACM Computing Surveys",
      "authors": "Shang Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3764113",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393183699",
      "doi": "10.1145/3639317",
      "title": "RITA: Group Attention is All You Need for Timeseries Analytics",
      "abstract": "Timeseries analytics is important in many real-world applications. Recently, the Transformer model, popular in natural language processing, has been leveraged to learn high quality feature embeddings from timeseries: embeddings are key to the performance of various timeseries analytics tasks such as similarity-based timeseries queries within vector databases. However, quadratic time and space complexities limit Transformers' scalability, especially for long timeseries. To address these issues, we develop a timeseries analytics tool, RITA, which uses a novel attention mechanism, named group attention, to address this scalability issue. Group attention dynamically clusters the objects based on their similarity into a small number of groups and approximately computes the attention at the coarse group granularity. It thus significantly reduces the time and space complexity, yet provides a theoretical guarantee on the quality of the computed attention. The dynamic scheduler of RITA continuously adapts the number of groups and the batch size in the training process, ensuring group attention always uses the fewest groups needed to meet the approximation quality requirement. Extensive experiments on various timeseries datasets and analytics tasks demonstrate that RITA outperforms the state-of-the-art in accuracy and is significantly faster --- with speedups of up to 63X.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Management of Data",
      "authors": "Jiaming Calvin Liang et al.",
      "keywords": "Analytics; Group (periodic table); Computer science; Data science; Chemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3639317",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4306790013",
      "doi": "10.1145/3568164",
      "title": "Automatically Temporal Labeled Data Generation Using Positional Lexicon Expansion for Focus Time Estimation of News Articles",
      "abstract": "Many facts change over time, which is a fundamental aspect of our physical environment. In the case of pandemic articles, the user is not interested in the creation date of the document but in the facts and the cause of the last pandemic. Fake news can be better combated by having a document with a temporal focus. Currently, neither the sequence of events nor the temporal focus is considered when obtaining news documents. Despite the limited number of temporal aspects in the available datasets, it is difficult to test and evaluate the temporal conclusions of the model. The goal of this work is to develop a temporal focus news article retrieval model based on co-training to advance research in semi-supervised learning. A mapping of the dataset is performed using (1) the evolving focus time of news articles and (2) the semi-supervised method based on coincidence contexts for learning low-dimensional continuous vectors for learning neural contrast embedding models generating focus time-based query in sequential news articles to facilitate temporal understanding by learning low-dimensional continuous vectors. A diverse dataset of news articles is used to evaluate the effectiveness of the proposed method. With semi-supervised learning and lexicon expansion, the result of the developed model can achieve 89%. The method performed better than previous baselines and traditional machine learning models with improvements of 12.65% and 4.7%, respectively.",
      "year": "2022",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Usman Ahmed et al.",
      "keywords": "Lexicon; Focus (optics); Computer science; Estimation; Natural language processing; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3568164",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210635544",
      "doi": "10.1145/3490503",
      "title": "A Twitter Framework to assess the Effectiveness of Indian Government Campaign",
      "abstract": "Many government and private agencies introduce social, governmental, educational, commercial and public-health based campaigns to refine various sections of the society. Traditionally, citizen feedback and on-field surveys are performed to assess the effectiveness of such campaigns. However, there is limited availability of the social media tools that assess the impact of different government campaigns automatically. In this research work, a framework has been proposed which uses the social media data i.e. Twitter data pertaining to an Indian Cleanliness Campaign Swachh Bharat Abhiyan (SBA) to perform the effectiveness assessment. This research work has been performed in two parts. First, Twitter data has been processed to predict the perceptions of citizens using Word Embeddings -based Tweet Pooling and Subjectivity score -based Sentiment Analysis and second, the performance of the cities has been predicted using the demographic features based predictor models. The experimentation shows a 0.77 correlation between the proposed framework and the government surveys while predicting the citizens\u2019 perspectives and 80(+/-15)% accuracy while predicting the performance of cities using Random Forest Regression. Furthermore, the cities have been clustered using Twitter and the demographic data to find out the interesting patterns and behaviors. This research work provides better insights to the potential of social media data in the interventional studies of the developing countries such as India.",
      "year": "2022",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Aarzoo Dhiman et al.",
      "keywords": "Social media; Government (linguistics); Pooling; Field (mathematics); Data science; Work (physics); Public relations; Newspaper; Political science; Computer science; Business; Engineering; Advertising; Artificial intelligence; World Wide Web; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3490503",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392750126",
      "doi": "10.1145/3652603",
      "title": "\u201cI Really Need Your Help with This Work...\u201d: A System for Navigating the Tricky Terrain of Managing Up by Leveraging One\u2019s Motivation to Get Things Done",
      "abstract": "When people need help from their supervisors or peers, they often have to manage up to get things done. However, unlike managing subordinates (managing down), managing people of equal or higher status (managing up) are not obligated to help. These requests often involve collaborative tasks between requesters and performers. Through interviews, we found that these collaborative tasks require coordination work that is not materialized in existing management tools. We also found that requesters are willing to take on this coordination work to see their requests fulfilled. To address this issue, we propose a system called TaskLight , which allows requesters to handle coordination work themselves. For example, requesters can collect useful context and information for their performers. We conducted two deployment studies and found that TaskLight leads to better outcomes because requesters are able to assist performers more effectively. Our findings demonstrate a new way to reduce the social burdens of managing up and improve collaboration.",
      "year": "2024",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Soya Park et al.",
      "keywords": "Computer science; Work (physics); Software deployment; Context (archaeology); Knowledge management; Internet privacy; Human\u2013computer interaction; World Wide Web; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3652603",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4414080965",
      "doi": "10.1145/3747346",
      "title": "A Multivocal Review of MLOps Practices, Challenges and Open Issues",
      "abstract": "MLOps has emerged as a key solution to address many socio-technical challenges of bringing ML models to production, such as integrating ML models with non-ML software, continuous monitoring, maintenance, and retraining of deployed models. Despite the utility of MLOps, an integrated body of knowledge regarding MLOps remains elusive because of its extensive scope due to the diversity of ML productionalization challenges it addresses. Whilst the existing literature reviews provide valuable snapshots of specific practices, tools, and research prototypes related to MLOps at various times, they focus on particular facets of MLOps, thus fail to offer a comprehensive and invariant framework that can weave these perspectives into a unified understanding of MLOps. This article presents a Multivocal Literature Review that systematically analyzes a corpus of 150 peer-reviewed and 48 grey literature to synthesize a unified conceptualization of MLOps and develop a snapshot of its best practices, adoption challenges, and solutions.",
      "year": "2025",
      "journal": "ACM Computing Surveys",
      "authors": "Beyza Eken et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3747346",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393002646",
      "doi": "10.1145/3652610",
      "title": "Empowering Predictive Modeling by GAN-based Causal Information Learning",
      "abstract": "Generally speaking, we can easily specify many causal relationships in the prediction tasks of ubiquitous computing, such as human activity prediction, mobility prediction, and health prediction. However, most of the existing methods in these fields failed to take advantage of this prior causal knowledge. They typically make predictions only based on correlations in the data, which hinders the prediction performance in real-world scenarios, because a distribution shift between training data and testing data generally exists. To fill in this gap, we proposed a Generative Adversarial Network (GAN)-based Causal Information Learning prediction framework, which can effectively leverage causal information to improve the prediction performance of existing ubiquitous computing deep learning models. Specifically, faced with a unique challenge that the treatment variable, referring to the intervention that influences the target in a causal relationship, is generally continuous in ubiquitous computing, the framework employs a representation learning approach with a GAN-based deep learning model. By projecting all variables except the treatment into a latent space, it effectively minimizes confounding bias and leverages the learned latent representation for accurate predictions. In this way, it deals with the continuous treatment challenge, and in the meantime, it can be easily integrated with existing deep learning models to lift their prediction performance in practical scenarios with causal information. Extensive experiments on two large-scale real-world datasets demonstrate its superior performance over multiple state-of-the-art baselines. We also propose an analytical framework together with extensive experiments to empirically show that our framework achieves better performance gain under two conditions: when the distribution differences between the training data and the testing data are more significant and when the treatment effects are larger. Overall, this work suggests that learning causal information is a promising way to improve the prediction performance of ubiquitous computing tasks. We open both our dataset and code 1 and call for more research attention in this area.",
      "year": "2024",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Jinwei Zeng et al.",
      "keywords": "Computer science; Machine learning; Leverage (statistics); Artificial intelligence; Lift (data mining); Feature learning; Latent variable; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3652610",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2984485371",
      "doi": "10.1145/3359237",
      "title": "Self-declared Throwaway Accounts on Reddit",
      "abstract": "Parents can be subjected to scrutiny and judgment for their parenting choices. Much of this scrutiny is experienced online, especially around stigmatized topics such as divorce, custody, postpartum depression, and miscarriage. Prior theory suggests that parents might be able to access greater support online when anonymous, but other evidence suggests that anonymity may increase bad behavior. Drawing from ten years of Reddit parenting boards, we show that parents are more likely to discuss potentially stigmatizing topics using anonymous (\"throwaway\") accounts. We find that, on average, throwaway comments are more likely to receive a response, receive more responses that are longer, and receive responses that have higher karma scores than topically similar comments posted by non-throwaway accounts. We argue that self-identified throwaway accounts provide a crucial environment for supporting parents with stigmatizing experiences. They also provide a shared platform signal (the throwaway account) which enables other Reddit users to access shared experiences and support. We propose that a hybrid combination of identified and anonymous platforms could provide more supportive online experiences for parents and other users.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Tawfiq Ammari et al.",
      "keywords": "Scrutiny; Anonymity; Psychology; Social psychology; Internet privacy; Computer science; Computer security; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359237",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4294891660",
      "doi": "10.1145/3550299",
      "title": "Assessing the State of Self-Supervised Human Activity Recognition Using Wearables",
      "abstract": "The emergence of self-supervised learning in the field of wearables-based human activity recognition (HAR) has opened up opportunities to tackle the most pressing challenges in the field, namely to exploit unlabeled data to derive reliable recognition systems for scenarios where only small amounts of labeled training samples can be collected. As such, self-supervision, i.e., the paradigm of 'pretrain-then-finetune' has the potential to become a strong alternative to the predominant end-to-end training approaches, let alone hand-crafted features for the classic activity recognition chain. Recently a number of contributions have been made that introduced self-supervised learning into the field of HAR, including, Multi-task self-supervision, Masked Reconstruction, CPC, and SimCLR, to name but a few. With the initial success of these methods, the time has come for a systematic inventory and analysis of the potential self-supervised learning has for the field. This paper provides exactly that. We assess the progress of self-supervised HAR research by introducing a framework that performs a multi-faceted exploration of model performance. We organize the framework into three dimensions, each containing three constituent criteria, such that each dimension captures specific aspects of performance, including the robustness to differing source and target conditions, the influence of dataset characteristics, and the feature space characteristics. We utilize this framework to assess seven state-of-the-art self-supervised methods for HAR, leading to the formulation of insights into the properties of these techniques and to establish their value towards learning representations for diverse scenarios.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Harish Haresamudram et al.",
      "keywords": "Computer science; Exploit; Wearable computer; Robustness (evolution); Artificial intelligence; Field (mathematics); Machine learning; Activity recognition; Supervised learning; Task (project management); Labeled data; Data science; Mathematics; Artificial neural network; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3550299",
      "cited_by_count": 89,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2925512010",
      "doi": "10.1145/3314394",
      "title": "Identifying and Planning for Individualized Change",
      "abstract": "Identifying and planning strategies that support a healthy lifestyle or manage a chronic disease often require patient-provider collaboration. For example, people with healthy eating goals often share everyday food, exercise, or sleep data with health coaches or nutritionists to find opportunities for change, and patients with irritable bowel syndrome (IBS) often gather food and symptom data as part of working with providers to diagnose and manage symptoms. However, a lack of effective support often prevents health experts from reviewing large amounts of data in time-constrained visits, prevents focusing on individual goals, and prevents generating correct, individualized, and actionable recommendations. To examine how to design photo-based diaries to help people and health experts exchange knowledge and focus on collaboration goals when reviewing the data together, we designed and developed Foodprint, a photo-based food diary. Foodprint includes three components: (1) A mobile app supporting lightweight data collection, (2) a web app with photo-based visualization and quantitative visualizations supporting collaborative reflection, and (3) a pre-visit note communicating an individual's expectations and questions to experts. We deployed Foodprint in two studies: (1) with 17 people with healthy eating goals and 7 health experts, and (2) with 16 IBS patients and 8 health experts. Building upon the lens of boundary negotiating artifacts and findings from two field studies, our research contributes design principles to (1) prepare individuals to collect data relevant to their health goals and for collaboration, (2) help health experts focus on an individual's eating context, experiences, and goals in collaborative review, and (3) support individuals and experts to develop individualized, actionable plans and strategies.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Chia-Fang Chung et al.",
      "keywords": "Context (archaeology); Focus group; Psychology; Data collection; Negotiation; Medicine; Knowledge management; Applied psychology; Medical education; Computer science; Business; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3314394",
      "cited_by_count": 91,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3035860379",
      "doi": "10.1145/3385009",
      "title": "Towards Effective Interface Designs for Collaborative HRI in Manufacturing",
      "abstract": "We present a comprehensive framework and test methodology for the evaluation of human-machine interfaces (HMI) and human-robot interactions (HRI) in collaborative manufacturing applications. An overview of the challenges that face current- and next-generation collaborative robot systems is presented, specifically focused on the interactions between man and machine, and a series of objectively quantitative and subjectively qualitative metrics are given to guide the development and assessment of interfaces and interactions. A generalized set of guidelines for the design of HMI is also proposed to address these challenges and thereby enable effective and intuitive diagnostics and error corrections when process failures occur. These guidelines are aimed at aiding researchers in developing effective interface and interaction technologies, maximizing operator situation awareness in human-robot collaborative manufacturing teams, promoting effective process and system diagnostics reporting, and enabling faster responses to equipment or application errors.",
      "year": "2020",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Jeremy A. Marvel et al.",
      "keywords": "Computer science; Interface (matter); Process (computing); Human\u2013computer interaction; Set (abstract data type); Human\u2013robot interaction; Robot; Systems engineering; Process management; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3385009",
      "cited_by_count": 108,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3093827093",
      "doi": "10.1145/3415247",
      "title": "Robots in Groups and Teams",
      "abstract": "Autonomous robots are increasingly placed in contexts that require them to interact with groups of people rather than just a single individual. Interactions with groups of people introduce nuanced challenges for robots, since robots? actions influence both individual group members and complex group dynamics. We review the unique roles robots can play in groups, finding that small changes in their nonverbal behavior and personality impacts group behavior and, by extension, influences ongoing interpersonal interactions.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Sarah Sebo et al.",
      "keywords": "Robot; Interpersonal communication; Group behavior; Group (periodic table); Personality; Nonverbal communication; Psychology; Interpersonal relationship; Human\u2013computer interaction; Extension (predicate logic); Computer science; Social psychology; Artificial intelligence; Cognitive psychology; Communication",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3415247",
      "cited_by_count": 121,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2985186227",
      "doi": "10.1145/3359304",
      "title": "\"Is my phone hacked?\" Analyzing Clinical Computer Security Interventions with Survivors of Intimate Partner Violence",
      "abstract": "Intimate partner abusers use technology to track, monitor, harass, and otherwise harm their victims, and prior work reports that victims have few resources for obtaining help with such attacks. This paper presents a qualitative analysis of data from a field study of an approach to helping survivors of intimate partner violence (IPV) with technology abuse. In this approach, called clinical computer security, a trained technologist performs a face-to-face consultation with an IPV survivor to help them understand and navigate technology issues. Findings from consultations with 31 survivors, as well as IPV professionals working on their behalf, uncovered a range of digital security and privacy vulnerabilities exacerbated by the nuanced social context of such abuse. In this paper we explore survivor experiences with, and reactions to, the consultations, discussing (1) the ways in which survivors present their tech concerns, (2) the cooperative work required to guide survivors towards understanding probable causes of tech insecurity, (3) survivors' reactions to the consultations, particularly when security vulnerabilities or spyware are discovered, and (4) the role we play as consultants and interventionists in the complex socio-technical systems involved in mitigating IPV. We conclude by discussing some of the broad ethical and sustainability challenges raised by our work, and provide design opportunities for tech platforms to better support survivors of IPV.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Diana Freed et al.",
      "keywords": "Domestic violence; Context (archaeology); Harm; Internet privacy; Psychological intervention; Phone; Psychology; Computer security; Public relations; Poison control; Suicide prevention; Medicine; Medical emergency; Social psychology; Computer science; Psychiatry; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359304",
      "cited_by_count": 76,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3087527158",
      "doi": "10.1145/3406091",
      "title": "Introduction to the Special Issue on HCI and the Body",
      "abstract": "introduction Free Access Share on Introduction to the Special Issue on HCI and the Body: Reimagining Women's Health Authors: Teresa Almeida IT University of Copenhagen, Denmark IT University of Copenhagen, DenmarkView Profile , Madeline Balaam KTH Royal Institute of Technology, Stockholm, Sweden KTH Royal Institute of Technology, Stockholm, SwedenView Profile , Shaowen Bardzell Indiana University, Bloomington Indiana University, BloomingtonView Profile , Lone Koefoed Hansen Aarhus University, Denmark Aarhus University, DenmarkView Profile Authors Info & Claims ACM Transactions on Computer-Human InteractionVolume 27Issue 4August 2020 Article No.: 20pp 1\u201332https://doi.org/10.1145/3406091Published:26 August 2020Publication History 11citation1,324DownloadsMetricsTotal Citations11Total Downloads1,324Last 12 Months546Last 6 weeks51 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
      "year": "2020",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Teresa Almeida et al.",
      "keywords": "Citation; Library science; Engineering; Media studies; Sociology; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3406091",
      "cited_by_count": 44,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4311808540",
      "doi": "10.1145/3570169",
      "title": "Nonverbal Cues in Human\u2013Robot Interaction: A Communication Studies Perspective",
      "abstract": "Communication between people is characterized by a broad range of nonverbal cues. Transferring these cues into the design of robots and other artificial agents that interact with people may foster more natural, inviting, and accessible experiences. In this article, we offer a series of definitive nonverbal codes for human\u2013robot interaction (HRI) that address the five human sensory systems (visual, auditory, haptic, olfactory, and gustatory) drawn from the field of communication studies. We discuss how these codes can be translated into design patterns for HRI using a curated sample of the communication studies and HRI literatures. As nonverbal codes are an essential mode in human communication, we argue that integrating robotic nonverbal codes in HRI will afford robots a feeling of \u201caliveness\u201d or \u201csocial agency\u201d that would otherwise be missing. We end with suggestions for research directions to stimulate work on nonverbal communication within the field of HRI and improve communication between people and robots.",
      "year": "2022",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Jacqueline Urakami et al.",
      "keywords": "Nonverbal communication; Robot; Human\u2013robot interaction; Perspective (graphical); Communication; Gesture; Psychology; Human\u2013computer interaction; Computer science; Feeling; Cognitive psychology; Artificial intelligence; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3570169",
      "cited_by_count": 79,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3083982195",
      "doi": "10.1145/3415202",
      "title": "Quantifying the Causal Effects of Conversational Tendencies",
      "abstract": "Understanding what leads to effective conversations can aid the design of better computer-mediated communication platforms. In particular, prior observational work has sought to identify behaviors of individuals that correlate to their conversational efficiency. However, translating such correlations to causal interpretations is a necessary step in using them in a prescriptive fashion to guide better designs and policies. In this work, we formally describe the problem of drawing causal links between conversational behaviors and outcomes. We focus on the task of determining a particular type of policy for a text-based crisis counseling platform: how best to allocate counselors based on their behavioral tendencies exhibited in their past conversations. We apply arguments derived from causal inference to underline key challenges that arise in conversational settings where randomized trials are hard to implement. Finally, we show how to circumvent these inference challenges in our particular domain, and illustrate the potential benefits of an allocation policy informed by the resulting prescriptive information.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Justine Zhang et al.",
      "keywords": "Causal inference; Inference; Task (project management); Computer science; Observational study; Key (lock); Causal model; Focus (optics); Randomized experiment; Cognitive psychology; Psychology; Data science; Artificial intelligence; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3415202",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2898785285",
      "doi": "10.1145/3274425",
      "title": "Participatory Design of Technologies to Support Recovery from Substance Use Disorders",
      "abstract": "Substance use disorders, such as alcoholism and drug addiction, are a widespread and hazardous public health issue. Technology designed for the needs and values of people in recovery may be able to supplement traditional treatment options, enhance long-term abstinence maintenance, and create new opportunities for social support. We conducted a series of participatory design workshops with women in recovery from substance use disorders to identify design opportunities for supportive technologies that align with the specific values, practices and traditions of the recovery community. Through a data-driven inductive qualitative analysis, we identify five major themes that may be addressed with technology: 1) supporting twelve-step traditions and practices, 2) management of restlessness and moments of crisis, 3) agency and control over privacy and personal safety, 4) tracking progress and maintaining motivation, and 5) constructing a new normal. We connect these themes to specific implications for design.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Zachary Schmitt et al.",
      "keywords": "Substance use; Agency (philosophy); Addiction; Abstinence; Participatory design; Citizen journalism; Psychology; Public relations; Medicine; Psychiatry; Engineering; Sociology; Political science; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274425",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3036069040",
      "doi": "10.1145/3380783",
      "title": "Robot Errors in Proximate HRI",
      "abstract": "Advancements within human\u2013robot interaction generate increasing opportunities for proximate, goal-directed joint action (GDJA). However, robot errors are common and researchers must determine how to mitigate them. In this article, we examine how expectations for robot functionality affect people\u2019s perceptions of robot reliability and trust for a robot that makes errors. Here 35 participants ( n = 35) performed a collaborative banner-hanging task with an autonomous mobile manipulator (Toyota HSR). Each participant received either a low- or high-functionality framing for the robot. We then measured how participants perceived the robot\u2019s reliability and trust prior to, during, and after interaction. Functionality framing changed how robot errors affected participant experiences of robot behavior. People with low expectations experienced positive changes in reliability and trust after interacting with the robot, while those with high expectations experienced a negative change in reliability and no change in trust. The low-expectation group also showed greater trust recovery following the robot\u2019s first error compared to the high group. Our findings inform human\u2013robot teaming through: (1) identifying robot presentation factors that can be employed to facilitate trust calibration and (2) establishing the effects of framing, functionality, and the interactions between them to improve dynamic models of human\u2013robot teaming.",
      "year": "2020",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Auriel Washburn et al.",
      "keywords": "Robot; Framing (construction); Computer science; Human\u2013computer interaction; Behavior-based robotics; Human\u2013robot interaction; Perception; Mobile robot; Reliability (semiconductor); Artificial intelligence; Psychology; Applied psychology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3380783",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385877222",
      "doi": "10.1145/3615862",
      "title": "A Systematic Collection of Medical Image Datasets for Deep Learning",
      "abstract": "The astounding success made by artificial intelligence in healthcare and other fields proves that it can achieve human-like performance. However, success always comes with challenges. Deep learning algorithms are data dependent and require large datasets for training. Many junior researchers face a lack of data for a variety of reasons. Medical image acquisition, annotation, and analysis are costly, and their usage is constrained by ethical restrictions. They also require several other resources, such as professional equipment and expertise. That makes it difficult for novice and non-medical researchers to have access to medical data. Thus, as comprehensively as possible, this article provides a collection of medical image datasets with their associated challenges for deep learning research. We have collected the information of approximately 300 datasets and challenges mainly reported between 2007 and 2020 and categorized them into four categories: head and neck, chest and abdomen, pathology and blood, and others. The purpose of our work is to provide a list, as up-to-date and complete as possible, that can be used as a reference to easily find the datasets for medical image analysis and the information related to these datasets.",
      "year": "2023",
      "journal": "ACM Computing Surveys",
      "authors": "Johann Li et al.",
      "keywords": "Computer science; Variety (cybernetics); Deep learning; Data science; Artificial intelligence; Annotation; Face (sociological concept); Machine learning",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3615862",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3173464203",
      "doi": "10.1145/3463528",
      "title": "Identifying Mobile Sensing Indicators of Stress-Resilience",
      "abstract": "Resident physicians (residents) experiencing prolonged workplace stress are at risk of developing mental health symptoms. Creating novel, unobtrusive measures of resilience would provide an accessible approach to evaluate symptom susceptibility without the perceived stigma of formal mental health assessments. In this work, we created a system to find indicators of resilience using passive wearable sensors and smartphone-delivered ecological momentary assessment (EMA). This system identified indicators of resilience during a medical internship, the high stress first-year of a residency program. We then created density estimation approaches to predict these indicators before mental health changes occurred, and validated whether the predicted indicators were also associated with resilience. Our system identified resilience indicators associated with physical activity (step count), sleeping behavior, reduced heart rate, increased mood, and reduced mood variability. Density estimation models were able to replicate a subset of the associations between sleeping behavior, heart rate, and resilience. To the best of our knowledge, this work provides the first methodology to identify and predict indicators of resilience using passive sensing and EMA. Researchers studying resident mental health can apply this approach to design resilience-building interventions and prevent mental health symptom development.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Daniel A. Adler et al.",
      "keywords": "Mental health; Mood; Psychological intervention; Resilience (materials science); Psychological resilience; Psychology; Health indicator; Applied psychology; Wearable computer; Medicine; Computer science; Clinical psychology; Psychiatry; Public health; Social psychology; Nursing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3463528",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4309617712",
      "doi": "10.1145/3555143",
      "title": "Human and Technological Infrastructures of Fact-checking",
      "abstract": "Increasing demands for fact-checking have led to a growing interest in developing systems and tools to automate the fact-checking process. However, such systems are limited in practice because their system design often does not take into account how fact-checking is done in the real world and ignores the insights and needs of various stakeholder groups core to the fact-checking process. This paper unpacks the fact-checking process by revealing the infrastructures---both human and technological---that support and shape fact-checking work. We interviewed 26 participants belonging to 16 fact-checking teams and organizations with representation from 4 continents. Through these interviews, we describe the human infrastructure of fact-checking by identifying and presenting, in-depth, the roles of six primary stakeholder groups, 1) Editors, 2) External fact-checkers, 3) In-house fact-checkers, 4) Investigators and researchers, 5) Social media managers, and 6) Advocators. Our findings highlight that the fact-checking process is a collaborative effort among various stakeholder groups and associated technological and informational infrastructures. By rendering visibility to the infrastructures, we reveal how fact-checking has evolved to include both short-term claims centric and long-term advocacy centric fact-checking. Our work also identifies key social and technical needs and challenges faced by each stakeholder group. Based on our findings, we suggest that improving the quality of fact-checking requires systematic changes in the civic, informational, and technological contexts.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Prerna Juneja et al.",
      "keywords": "Stakeholder; Computer science; Process (computing); Model checking; Quality (philosophy); Rendering (computer graphics); Process management; Data science; Knowledge management; Business; Public relations; Political science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555143",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3012323441",
      "doi": "10.1145/3365665",
      "title": "The Unexpected Downside of Paying or Sending Messages to People to Make Them Walk",
      "abstract": "People do not exercise as much and as regularly as they should. To support users in adopting healthy exercise routines, app designers integrate persuasive techniques in their apps. In this study, we focus on two of these techniques, i.e., offering tangible rewards and sending motivational messages to users. Past research has demonstrated the effects of these techniques in nudging recipients to increase their physical activity levels. However, the effect of these interventions on the intrinsic motivation of the participants has not yet been studied. We conducted a 10-month study involving 208 participants; this research consisted of a 3-month baseline (pre-phase), a 4-month experiment and a 3-month follow-up (post-phase). The participants were randomly assigned to one of the following three interventions: either they receive money ((i.) through a fixed incentive or (ii.) a lottery), or (iii.) informative messages. Their daily goal was to walk 10K steps. Through their smart phones, we recorded how many steps they walked every day. These interventions had no effect on the main outcome variable (i.e., the number of steps). However, the manipulations produced a detrimental effect on the intrinsic motivation of the participants, measured through a standardized questionnaire. This negative effect extended into the follow-up period. Our study reveals that tangible rewards and motivational messages decrease the intrinsic motivation of the participants, hence their connected physical activity. In our findings, we highlight the importance of intrinsic motivation in setting up healthy exercise routines that will be carried on autonomously by the participants after the period of the intervention. Finally, we present implications for the design of persuasive apps.",
      "year": "2020",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Mauro Cherubini et al.",
      "keywords": "Psychological intervention; Psychology; Intrinsic motivation; Lottery; Incentive; Physical activity; Applied psychology; Social psychology; Physical therapy; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3365665",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2994761079",
      "doi": "10.1145/3368554",
      "title": "Results of Field Trials with a Mobile Service Robot for Older Adults in 16 Private Households",
      "abstract": "In this article, we present results obtained from field trials with the Hobbit robotic platform, an assistive, social service robot aiming at enabling prolonged independent living of older adults in their own homes. Our main contribution lies within the detailed results on perceived safety, usability, and acceptance from field trials with autonomous robots in real homes of older users. In these field trials, we studied how 16 older adults (75 plus) lived with autonomously interacting service robots over multiple weeks. Robots have been employed for periods of months previously in home environments for older people, and some have been tested with manipulation abilities, but this is the first time a study has tested a robot in private homes that provided the combination of manipulation abilities, autonomous navigation, and non-scheduled interaction for an extended period of time. This article aims to explore how older adults interact with such a robot in their private homes. Our results show that all users interacted with Hobbit daily, rated most functions as well working, and reported that they believe that Hobbit will be part of future elderly care. We show that Hobbit\u2019s adaptive behavior approach towards the user increasingly eased the interaction between the users and the robot. Our trials reveal the necessity to move into actual users\u2019 homes, as only there, we encounter real-world challenges and demonstrate issues such as misinterpretation of actions during non-scripted human-robot interaction.",
      "year": "2019",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Markus Bajones et al.",
      "keywords": "Usability; Robot; Service (business); Field (mathematics); Applied psychology; Human\u2013computer interaction; Psychology; Independent living; Computer science; Gerontology; Internet privacy; Artificial intelligence; Medicine; Business; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3368554",
      "cited_by_count": 73,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3180786255",
      "doi": "10.1145/3451882",
      "title": "Robot-Delivered Cognitive Stimulation Games for Older Adults",
      "abstract": "Cognitive stimulation games delivered on robots may be able to improve cognitive functioning and delay decline in older adults. However, little is known about older adults\u2019 in-depth opinions of robot-delivered games, as current research primarily focuses on technical development and one-off use. This article explores the usability, acceptability, and perceptions of community-dwelling older adults towards cognitive games delivered on a robot that incorporated movable interactive blocks. Semi-structured interviews were conducted with participants at the end of a 12-week cognitive stimulation games intervention delivered entirely on robots. Participants were 10 older adults purposively sampled from two retirement villages. A framework analysis approach was used to code data to predefined themes related to technology acceptance (perceived benefits, satisfaction, and preference), and usability (effectiveness, efficiency, and satisfaction). Results indicated that cognitive games delivered on a robot may be a valuable addition to existing cognitive stimulation activities. The robot was considered easy to use and useful in improving cognitive functioning. Future developments should incorporate interactive gaming tools, the use of social anthropomorphic robots, contrasting colour schemes to accommodate macular degeneration, and cultural-specific imagery and language. This will help cater to the preferences and age-related health needs of older adults, to ultimately enhance usability and acceptability.",
      "year": "2021",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Norina Gasteiger et al.",
      "keywords": "Usability; Cognition; Psychology; Applied psychology; Robot; Cognitive decline; Perception; Preference; Cognitive skill; Intervention (counseling); Cognitive psychology; Human\u2013computer interaction; Computer science; Medicine; Dementia; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3451882",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2090463552",
      "doi": "10.1145/1017583.1017597",
      "title": "A DSS for diagnosis and therapy",
      "abstract": "This paper reviews an approach to the design and construction of a decision support system intended to function as a consultant on the question of diagnosis and therapy selection. It describes the system in terms of the nature of the decision problem involved, discusses factors which make the problem difficult and considers the design goals that have led to the construction of a system with several novel capabilities. Many of those capabilities result from representing domain-specific knowledge in the system in terms of numerous judgmental decision rules, and we examine a number of such rules. Examples of the system in operation are given to illustrate many of these issues, and performance is compared with previous approaches to automated medical decision making. Finally, we consider the domain independence and generality of the methodology and consider the potential impact the system may have as a tool for decision support.",
      "year": "1977",
      "journal": "ACM SIGMIS Database the DATABASE for Advances in Information Systems",
      "authors": "Randall Davis",
      "keywords": "Generality; Decision support system; Computer science; Domain (mathematical analysis); Function (biology); Selection (genetic algorithm); Independence (probability theory); Risk analysis (engineering); Decision system; Management science; Artificial intelligence; Operations research; Engineering; Psychology; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/1017583.1017597",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3202122852",
      "doi": "10.1145/3474675",
      "title": "How Avatar Customization Affects Fear in a Game-based Digital Exposure Task for Social Anxiety",
      "abstract": "The treatment of social anxiety through digital exposure therapy is challenging due to the cognitive properties of social anxiety-individuals need to be fully engaged in the task and feel themselves represented in the social situation; however, avatar customization has been shown to increase both engagement and social presence. In this paper, we harness techniques used in commercial games, and investigate how customizing self-representation in a novel digital exposure task for social anxiety influences the experience of social threat. In an online experiment with 200 participants, participants either customized their avatar or were assigned a predefined avatar. Participants then controlled the avatar through a virtual shop, where they had to solve a math problem, while a simulated audience within the virtual world observed them and negatively judged their performance. Our findings show that we can stimulate the fear of evaluation by others in our task, that fear is driven primarily by trait social anxiety, and that this relationship is strengthened for people higher in trait social anxiety. We provide new insights into the effects of customization in a novel therapeutic context, and embed the discussion of avatar customization into related work in social anxiety and human-computer interaction. ?",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Martin Dechant et al.",
      "keywords": "Avatar; Social anxiety; Personalization; Psychology; Anxiety; Context (archaeology); Task (project management); Applied psychology; Social psychology; Cognitive psychology; Computer science; Human\u2013computer interaction; Engineering; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3474675",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2987347991",
      "doi": "10.1145/3359271",
      "title": "LEAP",
      "abstract": "Despite a crucial role in providing public health services, Community Health Workers (CHWs) remain disadvantaged in receiving effective skill-building opportunities. Due to the lack of health experts and appropriate infrastructure, it becomes challenging to provide training on a regular basis. Our aim is to investigate opportunities for designing technology-supported collaborative learning to compensate for the limited availability of instructors. We designed a mobile learning-based peer-led educational intervention, and conducted an eight week long between-group study with 120 CHWs across four districts of Delhi, India. We found that CHWs were able to participate and use the system on their own leading to significant knowledge gains and increased desire to learn. With little guidance, CHWs exhibited benefits of collaborative learning in terms of positive interdependence on each other and use of interpersonal skills. The informal peer learning environment encouraged CHWs to have discourses on deeper societal aspects e.g. their role in society.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Deepika Yadav et al.",
      "keywords": "Disadvantaged; Intervention (counseling); Psychology; Medical education; Collaborative learning; Nursing; Pedagogy; Medicine; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359271",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3120244041",
      "doi": "10.1145/3434167",
      "title": "Online Community-based Design of Free and Open Source Software for Transgender Voice Training",
      "abstract": "This paper describes Project Spectra, a collective of open source developers that aims to build free and open source voice training technology for transgender people. We demonstrate how a design prioritizing the agency of trans users was made possible through sustained community collaboration. Using an autoethnographic approach, we discuss our community-based design process, which was documented with memos, online meetings and text conversations, sketches, and other data sources. We illustrate how we articulated our values as a group: deciding our programming framework (including a Statement of Principles), elaborating our \"Experience Goals\" (the feelings we wanted our design to elicit), and determining the features we wanted to implement in our app. We conclude with a reflection on the benefits and challenges of conducting community-based design research through an open-source organizational model.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Alex A. Ahmed et al.",
      "keywords": "Transgender; Agency (philosophy); Computer science; Process (computing); Online community; Feeling; Reflection (computer programming); Statement (logic); Open source; Training (meteorology); Software; World Wide Web; Psychology; Sociology; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3434167",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391473821",
      "doi": "10.1145/3643803",
      "title": "Interaction-Shaping Robotics: Robots That Influence Interactions between Other Agents",
      "abstract": "Work in Human\u2013Robot Interaction (HRI) has investigated interactions between one human and one robot as well as human\u2013robot group interactions. Yet the field lacks a clear definition and understanding of the influence a robot can exert on interactions between other group members (e.g., human-to-human). In this article, we define Interaction-Shaping Robotics (ISR), a subfield of HRI that investigates robots that influence the behaviors and attitudes exchanged between two (or more) other agents. We highlight key factors of interaction-shaping robots that include the role of the robot, the robot-shaping outcome, the form of robot influence, the type of robot communication, and the timeline of the robot\u2019s influence. We also describe three distinct structures of human\u2013robot groups to highlight the potential of ISR in different group compositions and discuss targets for a robot\u2019s interaction-shaping behavior. Finally, we propose areas of opportunity and challenges for future research in ISR.",
      "year": "2024",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Sarah Gillet et al.",
      "keywords": "Robotics; Artificial intelligence; Robot; Human\u2013computer interaction; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643803",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4366003228",
      "doi": "10.1145/3579545",
      "title": "\"We are half-doctors\": Family Caregivers as Boundary Actors in Chronic Disease Management",
      "abstract": "Computer-Supported Cooperative Work (CSCW) and Human--Computer Interaction (HCI) research is increasingly investigating the roles of caregivers as ancillary stakeholders in patient-centered care. Our research extends this body of work to identify caregivers as key decision-makers and boundary actors in mobilizing and managing care. We draw on qualitative data collected via 20 semi-structured interviews to examine caregiving responsibilities in physical and remote care interactions within households in urban India. Our findings demonstrate the crucial intermediating roles family caregivers take on while situated along the boundaries separating healthcare professionals, patients and other household members, and online/offline communities. We propose design recommendations for supporting caregivers in intermediating patient-centered care, such as through training content and expert feedback mechanisms for remote care, collaborative tracking mechanisms integrating patient- and caregiver-generated health data, and caregiving-centered online health communities. We conclude by arguing for recognizing caregivers as critical stakeholders in patient-centered care who might constitute technologically assisted pathways to care.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Karthik Bhat et al.",
      "keywords": "Situated; Computer-supported cooperative work; Health care; Work (physics); Family caregivers; Qualitative research; Nursing; Psychology; Tracking (education); Knowledge management; Medicine; Sociology; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579545",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387328660",
      "doi": "10.1145/3610170",
      "title": "\"I don't know how to help with that\" - Learning from Limitations of Modern Conversational Agent Systems in Caregiving Networks",
      "abstract": "While commercial conversational agents (CA) (i.e. Google assistant, Siri, Alexa) are widely used, these systems have limitations in error-handling, flexibility, personalization and overall dialogue management that are amplified in care coordination settings. In this paper, we synthesize and articulate these limitations through quantitative and qualitative analysis of 56 older adults interacting with a commercial CA deployed in their home for a 10 week period. We look at the CA as a compensatory technology in an older adult's care network. We argue that the CA limitations are rooted in the rigid cue-and-response style of task-oriented interactions common in CAs. We then propose a redesign for CA conversation flow to favor flexibility and personalization that is nonetheless viable within the limitations of current AI and machine learning technologies. We explore design tradeoffs to better support the usability needs of older adults compared to current design optimizations driven by efficiency and privacy goals.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Tamara Zubatiy et al.",
      "keywords": "Flexibility (engineering); Personalization; Conversation; Usability; Computer science; Human\u2013computer interaction; Dialog system; Task (project management); Knowledge management; Internet privacy; World Wide Web; Psychology; Communication; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610170",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313436069",
      "doi": "10.1145/3577008",
      "title": "Me, My Health, and My Watch: How Children with ADHD Understand Smartwatch Health Data",
      "abstract": "Children with ADHD can experience a wide variety of challenges related to self-regulation, which can lead to poor educational, health, and wellness outcomes. Technological interventions, such as mobile and wearable health systems, can support data collection and reflection about health status. However, little is known about how ADHD children interpret such data. We conducted a deployment study with 10 children, aged 10 to 15, for six weeks, during which they used a smartwatch in their homes. Results from observations and interviews during this study indicate that children with ADHD can interpret their own health data, particularly at the moment. However, as ADHD children develop more autonomy, smartwatch systems may require alternatives for data reflection that are interpretable and actionable for them. This work contributes to the scholarly discourse around health data visualization, particularly in considering implications for the design of health technologies for children with ADHD.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Elizabeth Ankrah et al.",
      "keywords": "Smartwatch; Wearable computer; Variety (cybernetics); Software deployment; Psychological intervention; Autonomy; Psychology; Applied psychology; Data science; Developmental psychology; Computer science; Psychiatry; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3577008",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3005339103",
      "doi": "10.1145/3340960",
      "title": "Interactive Clustering",
      "abstract": "In this survey, 105 papers related to interactive clustering were reviewed according to seven perspectives: (1) on what level is the interaction happening, (2) which interactive operations are involved, (3) how user feedback is incorporated, (4) how interactive clustering is evaluated, (5) which data and (6) which clustering methods have been used, and (7) what outlined challenges there are. This article serves as a comprehensive overview of the field and outlines the state of the art within the area as well as identifies challenges and future research needs.",
      "year": "2020",
      "journal": "ACM Computing Surveys",
      "authors": "Juhee Bae et al.",
      "keywords": "Computer science; Cluster analysis; Field (mathematics); Human\u2013computer interaction; Data science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3340960",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3206153526",
      "doi": "10.1145/3481585",
      "title": "A Cloud-based Robot System for Long-term Interaction: Principles, Implementation, Lessons Learned",
      "abstract": "Making the transition to long-term interaction with social-robot systems has been identified as one of the main challenges in human-robot interaction. This article identifies four design principles to address this challenge and applies them in a real-world implementation: cloud-based robot control, a modular design, one common knowledge base for all applications, and hybrid artificial intelligence for decision making and reasoning. The control architecture for this robot includes a common Knowledge-base (ontologies), Data-base, \u201cHybrid Artificial Brain\u201d (dialogue manager, action selection and explainable AI), Activities Centre (Timeline, Quiz, Break and Sort, Memory, Tip of the Day, \\( \\ldots \\) ), Embodied Conversational Agent (ECA, i.e., robot and avatar), and Dashboards (for authoring and monitoring the interaction). Further, the ECA is integrated with an expandable set of (mobile) health applications. The resulting system is a Personal Assistant for a healthy Lifestyle (PAL), which supports diabetic children with self-management and educates them on health-related issues (48 children, aged 6\u201314, recruited via hospitals in the Netherlands and in Italy). It is capable of autonomous interaction \u201cin the wild\u201d for prolonged periods of time without the need for a \u201cWizard-of-Oz\u201d (up until 6 months online). PAL is an exemplary system that provides personalised, stable and diverse, long-term human-robot interaction.",
      "year": "2021",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Frank Kaptein et al.",
      "keywords": "Computer science; Human\u2013computer interaction; Robot; Modular design; Timeline; Knowledge base; Cloud computing; Human\u2013robot interaction; Dialog system; Social robot; Artificial intelligence; Dialog box; Robot control; World Wide Web; Mobile robot",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3481585",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3035887284",
      "doi": "10.1145/3389210",
      "title": "Embodiment, Presence, and Their Intersections",
      "abstract": "Subjective experience of human control over remote, artificial, or virtual limbs has traditionally been investigated from two separate angles: presence research originates from teleoperation, aiming to capture to what extent the user feels like actually being in the remote or virtual environment. Embodiment captures to what extent a virtual or artificial limb is perceived as one\u2019s own limb. Unfortunately, the two research fields have not interacted much. This survey intends to provide a coherent overview of the literature at the intersection of these two fields to further that interaction. Two rounds of systematic research in topic-related data bases resulted in 414 related articles, 14 of which satisfy the deliberately strict inclusion criteria: 2 theoretical frameworks that highlighted intersections and 12 experimental studies that evaluated subjective measures for both concepts. Considering the surrounding literature as well, theoretical and experimental potential of embodiment and presence are discussed and suggestions to apply them in teleoperation research are derived. While increased publication activity is observed between 2016 and 2018, potentially caused by affordable virtual reality technologies, various open questions remain. To tackle them, human-in-the-loop experiments and three guiding principles for teleoperation system design (mechanical fidelity, spatial bodily awareness, and self-identification) are suggested.",
      "year": "2020",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Nicolas Nostadt et al.",
      "keywords": "Teleoperation; Human\u2013computer interaction; Fidelity; Virtual reality; Computer science; Identification (biology); Intersection (aeronautics); Haptic technology; Telerobotics; Control (management); Simulation; Artificial intelligence; Robot; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3389210",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3158729208",
      "doi": "10.1145/3449153",
      "title": "Anyone else have this experience",
      "abstract": "Self-tracking technologies, ranging from digital thermometers to wearable fitness trackers, allow users to use personal data accumulated from their everyday activities. But, to use these data, people have to make sense of how these numbers and figures are relevant to their lives in some way in order to make decisions and gain new insight. This process is impacted by people's emotional reactions to their data. While seeking support from others can be an effective strategy for overcoming these emotional challenges, self-trackers face unique barriers in sharing their personal data. Our study investigates 1) how users seek out support online for emotional barriers elicited by their self-tracking data and 2) what self-described impact this sharing has on their self-tracking practices. To investigate these topics, we analyzed discussions in two online communities on Reddit.com centered around infertility and trying to conceive that consistently describe self-tracking experiences. We found that community members described three distinct driving emotional tensions with their self-tracking data. In seeking community input, users were focused on support for understanding and acting upon their feelings and emotions. Even when data was uncertain, frustrating, or viewed as inaccurate, comparing and learning with others benefited users through feelings of connection, control, and humor this collective sense-making provided. Additionally, we found that users taking breaks from self-tracking in whole or part appeared to support their emotional well-being and long-term motivation to track. Based on these findings, we conclude that self-tracking data has social and emotional value beyond perceived accuracy and individual treatment goals.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Megan Knittel et al.",
      "keywords": "Feeling; Psychology; BitTorrent tracker; Tracking (education); Activity tracker; Social psychology; Emotional well-being; Wearable computer; Everyday life; Self; Internet privacy; Applied psychology; Computer science; Eye tracking; Developmental psychology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3449153",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387324560",
      "doi": "10.1145/3610059",
      "title": "Digital Legacy: A Systematic Literature Review",
      "abstract": "To more effectively support the dying and bereaved in end-of-life contexts, over the past two decades HCI and social computing scholars have sought to understand digital legacy. In this paper, we argue that it is time to take stock of digital legacy scholarship, examining what we know, what gaps remain, and what areas are imperative for future work. Through a Grounded Theory Literature Review, we identify four foci in digital legacy research to date: how identity is navigated in the passing of digital legacy, how digital legacies are engaged with, how digital legacies are put to rest, and how technology interfaces with offline legacy technologies. Based on our analysis, we present a model depicting how digital legacy research examines a lifecycle of data as it is passed down. This model identifies that digital legacy data moves through three stages: encoding, accessing, and dispossessing. The model illustrates gaps in current research and charts possible inflection points for future social computing research. Specifically, we highlight the importance of multi-user and multi-generational networks of people in end-of-life scenarios. Additionally, the model exhibits emerging theoretical findings and major concepts in the nascent field of digital legacy research.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Dylan Thomas Doyle et al.",
      "keywords": "Legacy system; Data science; Computer science; Scholarship; Grounded theory; Field (mathematics); Identity (music); World Wide Web; Sociology; Qualitative research; Political science; Social science; Software; Aesthetics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610059",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4205919053",
      "doi": "10.1145/3492826",
      "title": "Cultivating the Community",
      "abstract": "A growing body of HCI research has sought to understand how online networks are utilized in the adoption and maintenance of disordered activities and behaviors associated with mental illness, including eating habits. However, individual-level influences over discrete online eating disorder (ED) communities are not yet well understood. This study reports results from a comprehensive network and content analysis (combining computational topic modeling and qualitative thematic analysis) of over 32,000 public tweets collected using popular ED-related hashtags during May 2020. Our findings indicate that this ED network in Twitter consists of multiple smaller ED communities where a majority of the nodes are exposed to unhealthy ED contents through retweeting certain influential central nodes. The emergence of novel linguistic indicators and trends (e.g., \"#meanspo\") also demonstrates the evolving nature of the ED network. This paper contextualizes ED influence in online communities through node-level participation and engagement, as well as relates emerging ED contents with established online behaviors, such as self-harassment.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Fayika Farhat Nova et al.",
      "keywords": "Thematic analysis; Harassment; Social media; Psychology; Internet privacy; Data science; Computer science; Applied psychology; Social psychology; World Wide Web; Sociology; Qualitative research; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3492826",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3004250597",
      "doi": "10.1145/3539737",
      "title": "You, Me, and IoT: How Internet-connected Consumer Devices Affect Interpersonal Relationships",
      "abstract": "Internet-connected consumer devices have rapidly increased in popularity; however, relatively little is known about how these technologies are affecting interpersonal relationships in multi-occupant households. In this study, we conduct 13 semi-structured interviews and survey 508 individuals from a variety of backgrounds to discover and categorize how consumer IoT devices are affecting interpersonal relationships in the United States. We highlight several themes, providing exploratory data about the pervasiveness of interpersonal costs and benefits of consumer IoT devices. These results inform follow-up studies and design priorities for future IoT technologies to amplify positive and reduce negative interpersonal effects.",
      "year": "2022",
      "journal": "ACM Transactions on Internet of Things",
      "authors": "Noah Apthorpe et al.",
      "keywords": "Popularity; Interpersonal communication; Affect (linguistics); Categorization; Variety (cybernetics); Internet privacy; The Internet; Interpersonal relationship; Internet of Things; Psychology; Business; Social psychology; Computer science; World Wide Web; Communication",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3539737",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4317209693",
      "doi": "10.1145/3579356",
      "title": "Performance and Usability Evaluation of Brainwave Authentication Techniques with Consumer Devices",
      "abstract": "Brainwaves have demonstrated to be unique enough across individuals to be useful as biometrics. They also provide promising advantages over traditional means of authentication, such as resistance to external observability, revocability, and intrinsic liveness detection. However, most of the research so far has been conducted with expensive, bulky, medical-grade helmets, which offer limited applicability for everyday usage. With the aim to bring brainwave authentication and its benefits closer to real world deployment, we investigate brain biometrics with consumer devices. We conduct a comprehensive measurement experiment and user study that compare five authentication tasks on a user sample up to 10 times larger than those from previous studies, introducing three novel techniques based on cognitive semantic processing. Furthermore, we apply our analysis on high-quality open brainwave data obtained with a medical-grade headset, to assess the differences. We investigate both the performance, security, and usability of the different options and use this evidence to elicit design and research recommendations. Our results show that it is possible to achieve Equal Error Rates as low as 7.2% (a reduction between 68\u201372% with respect to existing approaches) based on brain responses to images with current inexpensive technology. We show that the common practice of testing authentication systems only with known attacker data is unrealistic and may lead to overly optimistic evaluations. With regard to adoption, users call for simpler devices, faster authentication, and better privacy.",
      "year": "2023",
      "journal": "ACM Transactions on Privacy and Security",
      "authors": "Patricia Arias-Cabarcos et al.",
      "keywords": "Usability; Biometrics; Computer science; Authentication (law); Headset; Computer security; Liveness; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3579356",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392356983",
      "doi": "10.1145/3650040",
      "title": "FedCMD: A Federated Cross-modal Knowledge Distillation for Drivers\u2019 Emotion Recognition",
      "abstract": "Emotion recognition has attracted a lot of interest in recent years in various application areas such as healthcare and autonomous driving. Existing approaches to emotion recognition are based on visual, speech, or psychophysiological signals. However, recent studies are looking at multimodal techniques that combine different modalities for emotion recognition. In this work, we address the problem of recognizing the user\u2019s emotion as a driver from unlabeled videos using multimodal techniques. We propose a collaborative training method based on cross-modal distillation, i.e., \u201cFedCMD\u201d (Federated Cross-Modal Distillation). Federated Learning (FL) is an emerging collaborative decentralized learning technique that allows each participant to train their model locally to build a better generalized global model without sharing their data. The main advantage of FL is that only local data is used for training, thus maintaining privacy and providing a secure and efficient emotion recognition system. The local model in FL is trained for each vehicle device with unlabeled video data by using sensor data as a proxy. Specifically, for each local model, we show how driver emotional annotations can be transferred from the sensor domain to the visual domain by using cross-modal distillation. The key idea is based on the observation that a driver\u2019s emotional state indicated by a sensor correlates with facial expressions shown in videos. The proposed \u201cFedCMD\u201d approach is tested on the multimodal dataset \u201cBioVid Emo DB\u201d and achieves state-of-the-art performance. Experimental results show that our approach is robust to non-identically distributed data, achieving 96.67% and 90.83% accuracy in classifying five different emotions with IID (independently and identically distributed) and non-IID data, respectively. Moreover, our model is much more robust to overfitting, resulting in better generalization than the other existing methods.",
      "year": "2024",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Saira Bano et al.",
      "keywords": "Computer science; Modal; Distillation; Emotion recognition; Artificial intelligence; Machine learning; Human\u2013computer interaction; Speech recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3650040",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3033821783",
      "doi": "10.1145/3379179",
      "title": "Challenges in Designing a Fully Autonomous Socially Assistive Robot for People with Parkinson\u2019s Disease",
      "abstract": "Assistive robots are becoming an increasingly important application platform for research in robotics, AI, and HRI, as there is a pressing need to develop systems that support the elderly and people with disabilities, with a clear path to market. Yet, what remains unclear is whether current autonomous systems are already up to the task or whether additional HRI work is needed to make these systems acceptable and useful. In this article, we report our efforts of developing and evaluating an architecture for a fully autonomous robot designed to assist older adults with Parkinson\u2019s disease (PD) in sorting their medications. The main goal for the robot is to aid users in a manner that maintains the autonomy of the user by providing cognitive and social support with varying levels of assistance. We first evaluated the robot with subjects drawn from a pool of university students, which is common practice in experimental work in psychology and HRI. As the results were very positive, we followed up with an evaluation using people with Parkinson\u2019s disease, who surprisingly had mostly negative outcomes. We thus report our analysis of the differences in the evaluations and discuss the challenges for HRI posed by the sources of the negative evaluations: (1) designing a robot to adapt to the many routines the participants use at home, (2) unique needs of participants with PD not present in student participants, and (3) the role of familiar technologies in designing and evaluating a new technology. While it is unlikely, given the current state of technology, that fully autonomous assistive robots for older adults will be available in the near term, we believe that our work exposes a critical need in HRI to involve the target population as early as possible in the design process.",
      "year": "2020",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Jason R. Wilson et al.",
      "keywords": "Autonomy; Robot; Psychology; Human\u2013computer interaction; Robotics; Social robot; Work (physics); Applied psychology; Computer science; Artificial intelligence; Knowledge management; Engineering; Mobile robot; Robot control",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3379179",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309619856",
      "doi": "10.1145/3555200",
      "title": "Learning to Become a Volunteer Counselor: Lessons from a Peer-to-Peer Mental Health Community",
      "abstract": "Online peer-to-peer therapy sessions can be effective in improving people's mental well-being. However, online volunteer counselors may lack the expertise and necessary training to provide high-quality sessions, and these low-quality sessions may negatively impact volunteers' motivations as well as clients' well-being. This paper uses interviews with 20 senior online volunteer counselors to examine how they addressed challenges and acquired skills when volunteering in a large, mental-health support community - 7Cups.com. Although volunteers in this community received some training based on principles of active listening and motivational interviewing, results indicate that the training was insufficient and that volunteer counselors had to independently develop strategies to deal with specific challenges that they encountered in their volunteer work. Their strategies, however, might deviate from standard practice since they generally lacked systematic feedback from mentors or clients and, instead, relied on their personal experiences. Additionally, volunteer counselors reported having difficulty maintaining their professional boundaries with the clients. Even though training and support resources were available, they were underutilized. The results of this study have uncovered new design spaces for HCI practitioners and researchers, including social computing and artificial intelligence approaches that may provide better support to volunteer counselors in online mental health communities.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Zheng Yao et al.",
      "keywords": "Mental health; Psychology; Medical education; Volunteer; Applied psychology; Interview; Peer support; Active listening; Quality (philosophy); Medicine; Psychotherapist; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555200",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387344808",
      "doi": "10.1145/3610060",
      "title": "Evaluating Similarity Variables for Peer Matching in Digital Health Storytelling",
      "abstract": "Peer matching can enhance the impact of social health technologies. By matching similar peers, online health communities can optimally facilitate social modeling that supports positive health attitudes and moods. However, little work has examined how to operationalize similarities in digital health tools, thus limiting our ability to perform optimal peer matching. To address this gap, we conducted a factorial experiment to examine how three categories of similarity variables (i.e., Demographic, Ability, Experiential) can be used to perform peer matching that supports the social modeling of physical activity. We focus this study on physical activity because it is a health behavior that reduces the risk of chronic diseases. We also prioritized this study for single-caregiver mothers who often face substantial barriers to being active because of immense employment and household responsibilities, especially Black single-caregiver mothers. We recruited 309 single-caregiver mothers (49% Black, 51% white), then we asked them to listen to peer audio storytelling about family physical activity. We randomly matched/mismatched the storyteller's profile using the three categories of similarity variables. Our analyses demonstrated that matching by Demographic variables led to a significantly higher Physical Activity Intention. Furthermore, our subgroup analyses indicated that Black single-caregiver mothers experienced a significant and immediate effect of peer matching in Physical Activity Intention, Self-efficacy, and mood. In contrast, white single-caregiver mothers did not report any significant immediate effect. Collectively, our data suggest that peer matching in health storytelling is potentially beneficial for racially minoritized groups; and that having diverse representations in health technology is required for promoting health equity.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Herman Saksono et al.",
      "keywords": "Matching (statistics); Psychology; Mood; Operationalization; Similarity (geometry); Social psychology; Developmental psychology; Computer science; Medicine; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610060",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2972927194",
      "doi": "10.1145/3351262",
      "title": "Recruit Until It Fails",
      "abstract": "Distinguishing identities is useful for several applications such as automated grocery or personalized recommendations. Unfortunately, several recent proposals for identification systems are evaluated using poor recruitment practices. We discovered that 23 out of 30 surveyed systems used datasets with 20 participants or less. Those studies achieved an average classification accuracy of 93%. We show that the classifier performance is misleading when the participant count is small. This is because the finite precision of measurements creates upper limits on the number of users that can be distinguished. To demonstrate why classifier performance is misleading, we used publicly available datasets. The data was collected from human subjects. We created five systems with at least 20 participants each. In three cases we achieved accuracies greater than 90% by merely applying readily available machine learning software packages, often with default parameters. For datasets where we had sufficient participants, we evaluated how the performance degrades as the number of participants increases. One of the systems built suffered a drop in accuracy that was over 35% as the participant count increased from 20 to 250. We argue that data from small participant count datasets do not adequately explore variations. Systems trained on such limited data are likely to incorrectly identify users when the user base increases beyond what was tested. We conclude by explaining generalizable reasons for this issue and provide insights on how to conduct more robust system analysis and design.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Shridatt Sugrim et al.",
      "keywords": "Computer science; Classifier (UML); Machine learning; Software; Artificial intelligence; Identification (biology); Data mining; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3351262",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2899071040",
      "doi": "10.1145/3274316",
      "title": "Shifting Expectations",
      "abstract": "As digital fabrication technology has become mainstream, the increased demand for 3D printed objects has created a new market for professional outsourcing. Given that most of this work does not require advanced training, and is an appropriate entry-level manufacturing job, there is an exciting opportunity to employ youth already skilled in \"making\" and interested in technology to do this work as an after-school job. The combination of this new technology and workforce calls for new workflows that streamline client-driven digital manufacturing. However, the limitations of current digital fabrication technology and youth schedules require that this work be spread between multiple shifts, necessitating employees to coordinate and handoff their work. We investigated the collaborative practices between youth employees while working on client jobs in a 3D print shop during one year of field work. In this paper, we describe instances where youth employees successfully, and unsuccessfully, handed off work between shifts and identify techniques utilized by youth to support successful handoffs, including: counting physical artifacts, using asynchronous chat programs, and documenting work. We then discuss the impact of the print shop manager's presence, physical characteristics of 3D prints, and youth perspectives of work on the selection of and effectiveness of these techniques. Finally, we offer lessons learned from successful handoffs in the print shop and recommendations for supporting youth in collaborative work environments.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "William Easley et al.",
      "keywords": "Outsourcing; Work (physics); Workflow; Mainstream; Workforce; Computer science; Multimedia; Business; Engineering; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274316",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4309618088",
      "doi": "10.1145/3555145",
      "title": "\"Do You Ladies Relate?\": Experiences of Gender Diverse People in Online Eating Disorder Communities",
      "abstract": "The study of eating disorders online has a long tradition within CSCW and HCI scholarship. Research within this body of work highlights the types of content people with eating disorders post as well as the ways in which individuals use online spaces for acceptance, connection, and support. However, despite nearly a decade of research, online eating disorder scholarship in CSCW and HCI rarely accounts for the ways gender shapes online engagement. In this paper, we present empirical results from interviews with 14 trans people with eating disorders. Our findings illustrate how working with gender as an analytic lens allowed us to produce new knowledge about the embodiment of participation in online eating disorder spaces. We show how trans people with eating disorders use online eating disorder content to inform and set goals for their bodies and how, as gender minorities within online eating disorder spaces, trans people occupy marginal positions that make them more susceptible to harms, such as threats to eating disorder validity and gender authenticity. In our discussion, we consider life transitions in the context of gender and eating disorders and address how online eating disorder spaces operate as social transition machinery. We also call attention to the labor associated with online participation as a gender minority within online eating disorder spaces, outlining several design recommendations for supporting the ways trans people with eating disorders use online spaces. CONTENT WARNING: This paper is about the online experiences of trans people with eating disorders. We discuss eating disorders, related content (e.g., thinspiration) and practices (e.g., binge eating, restriction), and gender dysphoria. Please read with caution.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Jessica L. Feuston et al.",
      "keywords": "Eating disorders; Psychology; Context (archaeology); Scholarship; Online community; Inclusion (mineral); Social psychology; Clinical psychology; World Wide Web; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555145",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226250863",
      "doi": "10.1145/3512952",
      "title": "Opening the Gate to Urban Repair: A Tool for Citizen-Led Design",
      "abstract": "City planning in the United States suffers from opaque and unresponsive processes---egalitarian in name but in reality controlled and mediated by city officials and powerful interests, not residents. We explore methods for placing city planning directly in the hands of the people. For inspiration, we look to the democratization of knowledge production through citizen science, and examine how this trend can be paralleled in urban design. To that end, we give ordinary people pattern-based planning tools to help them redesign (and repair) urban areas. We describe a prototype for such a tool that leverages classic patterns to enable city planning by residents, and show through a series of Mechanical Turk experiments that this prototype allows ordinary people to create designs and communicate their intentions without design training or expert intervention.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Sarah Cooney et al.",
      "keywords": "Intervention (counseling); Urban planning; Democratization; Public relations; Computer science; Architectural engineering; Engineering; Political science; Psychology; Civil engineering; Democracy; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3512952",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3030294612",
      "doi": "10.1145/3374137",
      "title": "Thinking Unveiled",
      "abstract": "Very few studies have explored linkages between physiological, such as electroencephalograph (EEG), and behavioral patterns, such as wrist movements. These linkages provide us a unique mechanism to predict one set of patterns from other related patterns. Unlike conventional biometrics, EEG biometrics are hard to spoof using standard presentation attack methods, given the intrinsic liveness resulting from the bounded randomness of EEG signals specific to an individual. In this article, we propose a novel attack on the EEG-based authentication systems by investigating and leveraging the strong correlation between hand movements and brain signals captured through the motion sensors on a smartwatch and the wearable EEG headset, respectively. Based on this technique, we can successfully estimate the user\u2019s EEG signals from the stolen hand movement data while the user was typing on the keyboard. Our attack results on the EEG biometric authentication system show an increase in the mean equal error rates of the classifiers by between 180% and 360% based on a dataset of 59 users. In summary, our pilot study calls for a rethinking of EEG-based authentication mechanisms from the perspective of unique vulnerabilities, particularly for multimodal biometric systems involving a variety of wearable or mobile devices.",
      "year": "2020",
      "journal": "Digital Threats Research and Practice",
      "authors": "Diksha Shukla et al.",
      "keywords": "Biometrics; Computer science; Headset; Electroencephalography; Smartwatch; Wearable computer; Artificial intelligence; Authentication (law); Human\u2013computer interaction; Pattern recognition (psychology); Speech recognition; Computer security; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3374137",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392503805",
      "doi": "10.1145/3643507",
      "title": "Investigating Technology Adoption Soon After Sustaining a Spinal Cord Injury",
      "abstract": "A spinal cord injury (SCI) typically results in a sudden change to an individual's motor function. People's adoption of technology soon after a severe SCI is crucial, since they must relearn most technology interactions to adjust to their new physical abilities and regain independence. This study examines how individuals adopt technologies soon after sustaining a severe SCI. By qualitatively analyzing the perspectives of ten rehabilitation clinicians, three individuals who recently sustained an SCI, and two of those participants' family members, we surfaced a spectrum of individuals' motivations to adopt technology post-injury and highlight the challenges they face to adopt technology. Our findings highlight the need to incorporate the holistic experience---including technology literacy, perception of support, and acceptance of the \"new-normal\"---in technology design for individuals who have a sudden change to motor functions. Our findings show that technology adoption is a critical component for the overall adjustment of post-SCI life. Finally, we use the extended version of the Technology Acceptance Model (TAM) to make recommendations for more inclusive assistive design.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Tamanna Motahar et al.",
      "keywords": "Spinal cord injury; Spinal cord; Business; Medicine; Computer science; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643507",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387328615",
      "doi": "10.1145/3610175",
      "title": "Beyond the Session: Centering Teleoperators in Socially Assistive Robot-Child Interactions Reveals the Bigger Picture",
      "abstract": "Socially assistive robots play an effective role in children's therapy and education. Robots engage children and provide interaction that is free of the potential judgment of human peers and adults. Research in socially assistive robots for children generally focuses on therapeutic and educational outcomes for those children, informed by a vision of autonomous robots. This perspective ignores therapists and educators, who operate these robots in practice. Through nine interviews with individuals who have used robots to deliver socially assistive services to neurodivergent children, we (1) define a dual-cycle model of therapy that helps capture the domain expert view of therapy, (2) identify six core themes of teleoperator needs and patterns across these themes, (3) provide high-level guidelines and detailed recommendations for designing teleoperated socially assistive robot systems, and (4) outline a vision of robot-assisted therapy informed by these guidelines and recommendations that centers teleoperators of socially assistive robots in practice.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Saad Elbeleidy et al.",
      "keywords": "Robot; Perspective (graphical); Psychology; Human\u2013computer interaction; Session (web analytics); Teleoperation; Human\u2013robot interaction; Computer science; Applied psychology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610175",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3036982890",
      "doi": "10.1145/3469888",
      "title": "Psychometrics in Behavioral Software Engineering: A Methodological Introduction with Guidelines",
      "abstract": "A meaningful and deep understanding of the human aspects of software engineering (SE) requires psychological constructs to be considered. Psychology theory can facilitate the systematic and sound development as well as the adoption of instruments (e.g., psychological tests, questionnaires) to assess these constructs. In particular, to ensure high quality, the psychometric properties of instruments need evaluation. In this article, we provide an introduction to psychometric theory for the evaluation of measurement instruments for SE researchers. We present guidelines that enable using existing instruments and developing new ones adequately. We conducted a comprehensive review of the psychology literature framed by the Standards for Educational and Psychological Testing. We detail activities used when operationalizing new psychological constructs, such as item pooling, item review, pilot testing, item analysis, factor analysis, statistical property of items, reliability, validity, and fairness in testing and test bias. We provide an openly available example of a psychometric evaluation based on our guideline. We hope to encourage a culture change in SE research towards the adoption of established methods from psychology. To improve the quality of behavioral research in SE, studies focusing on introducing, validating, and then using psychometric instruments need to be more common.",
      "year": "2021",
      "journal": "ACM Transactions on Software Engineering and Methodology",
      "authors": "Daniel Graziotin et al.",
      "keywords": "Operationalization; Applied psychology; Psychometrics; Reliability (semiconductor); Psychology; Quality (philosophy); Rasch model; Item response theory; Pooling; Psychological testing; Computer science; Data science; Management science; Clinical psychology; Artificial intelligence; Engineering; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3469888",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3204606269",
      "doi": "10.1145/3473343",
      "title": "How Do Home Computer Users Browse the Web?",
      "abstract": "With the ubiquity of web tracking, information on how people navigate the internet is abundantly collected yet, due to its proprietary nature, rarely distributed. As a result, our understanding of user browsing primarily derives from small-scale studies conducted more than a decade ago. To provide an broader updated perspective, we analyze data from 257 participants who consented to have their home computer and browsing behavior monitored through the Security Behavior Observatory. Compared to previous work, we find a substantial increase in tabbed browsing and demonstrate the need to include tab information for accurate web measurements. Our results confirm that user browsing is highly centralized, with 50% of internet use spent on 1% of visited websites. However, we also find that users spend a disproportionate amount of time on low-visited websites, areas with a greater likelihood of containing risky content. We then identify the primary gateways to these sites and discuss implications for future research.",
      "year": "2021",
      "journal": "ACM Transactions on the Web",
      "authors": "Kyle Crichton et al.",
      "keywords": "The Internet; World Wide Web; Computer science; Web navigation; Web browser; Perspective (graphical); Internet privacy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3473343",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386864637",
      "doi": "10.1145/3617364",
      "title": "Blueprints: Systematizing Behavior Change Designs\u2014The Case of Social Comparison Theory",
      "abstract": "To improve people\u2019s lives, human-computer interaction researchers are increasingly designing technological solutions based on behavior change theory, such as social comparison theory (SCT). However, how researchers operationalize such a theory as a design remains largely unclear. One way to clarify this methodological step is to clearly state which functional elements of a design are aimed at operationalizing a specific behavior change theory construct to evaluate if such aims were successful. In this article, we investigate how the operationalization of functional elements of theories and designs can be more easily conveyed. First, we present a scoping review of the literature to determine the state of operationalizations of SCT as behavior change designs. Second, we introduce a new tool to facilitate the operationalization process. We term the tool blueprints . A blueprint explicates essential functional elements of a behavior change theory by describing it in relation to necessary and sufficient building blocks incorporated in a design. We describe the process of developing a blueprint for SCT. Last, we illustrate how the blueprint can be used during the design refinement and reflection process.",
      "year": "2023",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Roelof A. J. de Vries et al.",
      "keywords": "Operationalization; Blueprint; Construct (python library); Process (computing); Computer science; Development theory; Management science; Process management; Epistemology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3617364",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388282047",
      "doi": "10.1145/3631618",
      "title": "Combining Deep Learning with Signal-image Encoding for Multi-Modal Mental Wellbeing Classification",
      "abstract": "The quantification of emotional states is an important step to understanding wellbeing. Time series data from multiple modalities such as physiological and motion sensor data have proven to be integral for measuring and quantifying emotions. Monitoring emotional trajectories over long periods of time inherits some critical limitations in relation to the size of the training data. This shortcoming may hinder the development of reliable and accurate machine learning models. To address this problem, this article proposes a framework to tackle the limitation in performing emotional state recognition: (1) encoding time series data into coloured images; (2) leveraging pre-trained object recognition models to apply a Transfer Learning (TL) approach using the images from step 1; (3) utilising a 1D Convolutional Neural Network (CNN) to perform emotion classification from physiological data; (4) concatenating the pre-trained TL model with the 1D CNN. We demonstrate that model performance when inferring real-world wellbeing rated on a 5-point Likert scale can be enhanced using our framework, resulting in up to 98.5% accuracy, outperforming a conventional CNN by 4.5%. Subject-independent models using the same approach resulted in an average of 72.3% accuracy (SD 0.038). The proposed methodology helps improve performance and overcome problems with small training datasets.",
      "year": "2023",
      "journal": "ACM Transactions on Computing for Healthcare",
      "authors": "Kieran Woodward et al.",
      "keywords": "Modal; Encoding (memory); Computer science; Artificial intelligence; SIGNAL (programming language); Pattern recognition (psychology); Image (mathematics); Deep learning; Psychology; Speech recognition; Chemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3631618",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392519684",
      "doi": "10.1145/3643538",
      "title": "Planning the Future in a Longer Perspective",
      "abstract": "A long-term perspective toward the future enables a more comprehensive approach to decision-making, considering a variety of potential scenarios. The forecasting of mental health was anticipated to promote proactive planning, however, it faces challenges such as a short forecasting period and a lack of intuitive understanding of the relationship between actions and the forecast. This study presents a novel mental health indicator that incorporates a long-term perspective by considering past actions. A four-week experiment was conducted with 105 participants to evaluate the effects of a one-week forecast. Qualitative analysis reveals the effects of the one-week forecast on behavioral planning, emotional states, and reasons for disregarding the forecasts. Findings indicate that conventional mood indicators prompt participants to prioritize pre-existing schedules and perceive the forecast as infeasible, whereas the proposed indicator enhances the ability to plan work schedules in advance. Our results offer valuable insights into the presentation of forecasts for effectively managing mental health, considering the time constraints of everyday life.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Naoki Tateyama et al.",
      "keywords": "Perspective (graphical); Mood; Variety (cybernetics); Plan (archaeology); Mental health; Presentation (obstetrics); Psychology; Computer science; Applied psychology; Management science; Risk analysis (engineering); Operations research; Process management; Social psychology; Business; Artificial intelligence; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3643538",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297184016",
      "doi": "10.1145/3564276",
      "title": "A Human-in-the-Loop Segmented Mixed-Effects Modeling Method for Analyzing Wearables Data",
      "abstract": "Wearables are an important source of big data, as they provide real-time high-resolution data logs of health indicators of individuals. Higher-order associations between pairs of variables is common in wearables data. Representing higher-order association curves as piecewise linear segments in a regression model makes them more interpretable. However, existing methods for identifying the change points for segmented modeling either overfit or have low external validity for wearables data containing repeated measures. Therefore, we propose a human-in-the-loop method for segmented modeling of higher-order pairwise associations between variables in wearables data. Our method uses the smooth function estimated by a generalized additive mixed model to allow the analyst to annotate change point estimates for a segmented mixed-effects model, and thereafter employs Brent's constrained optimization procedure to fine-tune the manually provided estimates. We validate our method using three real-world wearables datasets. Our method not only outperforms state-of-the-art modeling methods in terms of prediction performance but also provides more interpretable results. Our study contributes to health data science in terms of developing a new method for interpretable modeling of wearables data. Our analysis uncovers interesting insights on higher-order associations for health researchers.",
      "year": "2022",
      "journal": "ACM Transactions on Management Information Systems",
      "authors": "Karthik Srinivasan et al.",
      "keywords": "Overfitting; Wearable computer; Computer science; Data mining; Piecewise; Pairwise comparison; Wearable technology; Machine learning; Artificial intelligence; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3564276",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309619000",
      "doi": "10.1145/3555771",
      "title": "Warm Solutions: Centering Nurse Contributions in Medical Making",
      "abstract": "Making medical devices in healthcare settings engages practitioners in organizational innovation. Nurses improvise physical workarounds at the bedside in response to patient needs. Yet nurse-led problem-solving is rarely centralized in an emerging innovation ecosystem through medical making. We interviewed medical makers in six healthcare makerspaces to understand factors for nurse inclusion in the medical making ecosystem. Findings from 16 multi-stakeholder interviews with 6 facilitators and 10 nurses in the USA, reveal insights into nurse-led problem-solving with and without the use of physical prototyping (making) in formal innovation spaces with maker technologies. We report how a nurse's capacity for making is practice-driven to address in-patient discomfort, repair their own practice, and update standardized workflows. Most nurses iterate on low-tech solutions facing barriers to formal collaboration when they attempt to scale up. Their technical capabilities extend from innovation-centered resources (e.g., lab spaces, technologies), often with complete reliance on facilitators who have limited authority in the medical system. We contribute to themes around practice-based innovation, participation in technology design, and articulation work for collaborative innovation. From nurse makers' experiences, we discuss how nurse participation can be supported in healthcare technology design.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "U. K. Lakshmi et al.",
      "keywords": "Workaround; Workflow; Health care; Stakeholder; Nursing; Work (physics); Health technology; Knowledge management; Business; Psychology; Public relations; Medicine; Computer science; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3555771",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4213445565",
      "doi": "10.1145/3504004",
      "title": "Uncovering Personal Histories: A Technology-Mediated Approach to Eliciting Reflection on Identity Transitions",
      "abstract": "When studying identity transitions, interview participants can find it difficult to reflect on their transitions and recall specific details related to past experiences. We present a new approach to enable participant reflection on past identity transitions, and a means to fill in blanks by eliciting data that may not otherwise come up: showing participants sentiment visualizations of their social media data. After detailing our methods of constructing sentiment visualizations, we discuss our experiences using them in a study on gender transition. For most participants, the visualizations elicited substantial reflection, and enabled recalling forgotten data and new interpretations of transition experiences. We guide researchers on how to use this method when studying other identity transitions; this may be especially powerful for marginalized people who undergo substantial identity changes. This article proposes a way to uncover participants\u2019 personal histories, which can help HCI researchers to better understand and support marginalized people\u2019s experiences.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Oliver L. Haimson et al.",
      "keywords": "Identity (music); Transition (genetics); Reflection (computer programming); Recall; Psychology; Social psychology; Internet privacy; Cognitive psychology; Computer science; Aesthetics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3504004",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3173310622",
      "doi": "10.1145/3463500",
      "title": "LumNet",
      "abstract": "High-quality lighting positively influences visual performance in humans. The experienced visual performance can be measured using desktop luminance and hence several lighting control systems have been developed for its quantification. However, the measurement devices that are used to monitor the desktop luminance in existing lighting control systems are obtrusive to the users. As an alternative, ceiling-based luminance projection sensors are being used recently as these are unobtrusive and can capture the direct task area of a user. The positioning of these devices on the ceiling requires to estimate the desktop luminance in the user's vertical visual field, solely using ceiling-based measurements, to better predict the experienced visual performance of the user. For this purpose, we present LUMNET, an approach for estimating desktop luminance with deep models through utilizing supervised and self-supervised learning. Our model learns visual representations from ceiling-based images, which are collected in indoor spaces within the physical vicinity of the user to predict average desktop luminance as experienced in a real-life setting. We also propose a self-supervised contrastive method for pre-training LUMNET with unlabeled data and we demonstrate that the learned features are transferable onto a small labeled dataset which minimizes the requirement of costly data annotations. Likewise, we perform experiments on domain-specific datasets and show that our approach significantly improves over the baseline results from prior methods in estimating luminance, particularly in the low-data regime. LUMNET is an important step towards learning-based technique for luminance estimation and can be used for adaptive lighting control directly on-device thanks to its minimal computational footprint with an added benefit of preserving user's privacy.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Prince U.C. Songwa et al.",
      "keywords": "Luminance; Computer science; Ceiling (cloud); Artificial intelligence; Computer vision; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3463500",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4401175792",
      "doi": "10.1145/3685235.3685238",
      "title": "Too Small to Succeed: Small Samples and the p-Value Problem",
      "abstract": "Determining an appropriate sample size is a critical planning decision in quantitative empirical research. In recent years, there has been a growing concern that researchers have excessively focused on statistical significance in large sample studies to the detriment of effect sizes. This research focuses on a related concern at the other end of the spectrum. We argue that a combination of bias in significant estimates obtained from small samples (compared to their population values) and an editorial preference for the publication of significant results compound to produce marked bias in published small sample studies. We then present a simulation study covering a variety of statistical techniques commonly used to examine structural equation models with latent variables. Our results support our contention that significant results obtained from small samples are likely biased and should be considered with skepticism. We also argue for the need to provide a priori power analyses to understand the behavior of parameter estimates under the small sample conditions we examine.",
      "year": "2024",
      "journal": "ACM SIGMIS Database the DATABASE for Advances in Information Systems",
      "authors": "Miguel I. Aguirre\u2010Urreta et al.",
      "keywords": "Sample size determination; Econometrics; Statistics; Sample (material); Statistical power; Skepticism; A priori and a posteriori; Preference; Population; Psychology; Variety (cybernetics); Mathematics; Sociology; Demography; Physics; Epistemology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3685235.3685238",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4396230911",
      "doi": "10.1145/3637317",
      "title": "Data Work Between the Local and the Global: An Ethnography of a Healthcare Business Intelligence Unit",
      "abstract": "This paper describes work practices at a public, non-profit healthcare business intelligence unit involved in creating BI reports and sharing these with healthcare management and professionals. Based on ethnographic fieldwork, we detail the various work tasks and processes involved in building data products that are applicable across various wards and healthcare professions, and, at the same time, intelligible and relevant for specific users: a challenge we frame as working with the tension between making the local and the global relevant to each other. We identified four ways in which this tension unfolds in the business intelligence unit's data work: consolidating standards, creating order out of chaos, engaging with healthcare professionals, and negotiating data and conflicts. We provide three contributions: we show how data work can unfold in close collaboration between professional data workers and domain experts; we nuance the existing research on data work by focusing on a less researched group of data workers; and we add to the few detailed ethnographies of business intelligence units.",
      "year": "2024",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Asbj\u00f8rn Malte Pedersen et al.",
      "keywords": "Health care; Negotiation; Work (physics); Ethnography; Knowledge management; Business intelligence; Public relations; Unit (ring theory); Sociology; Computer science; Data science; Psychology; Engineering; Political science; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3637317",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4293084021",
      "doi": "10.1145/3543514",
      "title": "Affective Robots Need Therapy",
      "abstract": "Emotion researchers have begun to converge on the theory that emotions are psychologically and socially constructed. A common assumption in affective robotics is that emotions are categorical brain-body states that can be confidently modeled. But if emotions are constructed, then they are interpretive, ambiguous, and specific to an individual\u2019s unique experience. Constructivist views of emotion pose several challenges to affective robotics: first, it calls into question the validity of attempting to obtain objective measures of emotion through rating scales or biometrics. Second, ambiguous subjective data poses a challenge to computational systems that need structured and definite data to operate. How can a constructivist view of emotion be rectified with these challenges? In this article, we look to psychotherapy for ontological, epistemic, and methodological guidance. These fields (1) already understand emotions to be intrinsically embodied, relative, and metaphorical and (2) have built up substantial knowledge informed by everyday practice. It is our hope that by using interpretive methods inspired by therapeutic approaches, HRI researchers will be able to focus on the practicalities of designing effective embodied emotional interactions.",
      "year": "2022",
      "journal": "ACM Transactions on Human-Robot Interaction",
      "authors": "Paul Bucci et al.",
      "keywords": "Embodied cognition; Psychology; Focus (optics); Categorical variable; Robotics; Cognitive psychology; Artificial intelligence; Cognitive science; Robot; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3543514",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392131596",
      "doi": "10.1145/3648621",
      "title": "Health Data Visualization Literacy Skills of Young Adults with Down Syndrome and the Barriers to Inference-making",
      "abstract": "As health management becomes more intertwined with data, an individual\u2019s ability to read, interpret, and engage with personal health information in data visualizations is increasingly critical to one\u2019s quality of care. People with Down Syndrome already experience greater health disparities than their typically developing peers. Inaccessible health information and technologies have the potential to magnify inequities further. Inaccessible health data can be an additional barrier to people with Down Syndrome\u2019s ability to adopt and use health systems or devices, make informed decisions about their bodies, and advocate for themselves in health contexts. By examining their underlying data visualization literacy skills, our exploratory study involving ten young adults with Down Syndrome identifies several design opportunities to improve the accessibility of health data visualizations (HDVs) by addressing the cascade of negative effects caused by inference-making barriers in HDVs.",
      "year": "2024",
      "journal": "ACM Transactions on Accessible Computing",
      "authors": "Rachel Wood et al.",
      "keywords": "Health literacy; Inference; Literacy; Health care; Psychology; Computer science; Internet privacy; Data science; Artificial intelligence; Pedagogy; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3648621",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388284553",
      "doi": "10.1145/3631611",
      "title": "Quantifying Levels of Influence and Causal Responsibility in Dynamic Decision Making Events",
      "abstract": "Intelligent systems support human operators\u2019 decision-making processes, many of which are dynamic and involve temporal changes in the decision-related parameters. As we increasingly depend on automation, it becomes imperative to understand and quantify its influence on the operator\u2019s decisions and to evaluate its implications for the human\u2019s causal responsibility for outcomes. Past studies proposed a model for human responsibility in static decision-making processes involving intelligent systems. We present a model for dynamic, non-stationary decision-making events based on the concept of causation strength. We apply it to a test case of a dynamic binary categorization decision. The results show that for automation to influence humans significantly, it must have high detection sensitivity. However, this condition is insufficient since it is unlikely that automation, irrespective of its sensitivity, will sway humans with high detection sensitivity away from their original position. Specific combinations of automation and human detection sensitivities are required for automation to have a major influence. Moreover, the automation influence and the human causal responsibility that can be derived from it are sensitive to possible changes in the human\u2019s detection capabilities due to fatigue or other factors, creating a \u201cResponsibility Cliff.\u201d This should be considered during system design and when policies and regulations are defined. This model constitutes a basis for further analyses of complex events in which human and automation sensitivity levels change over time and for evaluating human involvement in such events.",
      "year": "2023",
      "journal": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Yossef Saad et al.",
      "keywords": "Automation; Computer science; Categorization; Risk analysis (engineering); Sensitivity (control systems); Artificial intelligence; Machine learning; Data science; Data mining; Operations research; Engineering; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3631611",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387614610",
      "doi": "10.1145/3626525",
      "title": "The Development and Teaching Application of Japanese Peripheral Language Phenomenon Based on Big Data Corpus",
      "abstract": "Since the introduction of the concept of big data corpus into language analysis, many scholars have conducted research on Japanese big data corpus, especially the subject, from different language views and perspectives, and have drawn many valuable conclusions. However, due to scholars' different theories and different thinking modes, their understanding of the Japanese big data corpus is still quite different. The seminar teaching method, as a teaching mode for the cultivation of innovative talents in Japanese peripheral languages, has distinctive features such as interactivity, democracy, motivation, and extension. It has been widely used in postgraduate and undergraduate courses at home and abroad and applied to A wide range of disciplines. Especially in Japan, each university has Seminar courses. Because of its strong practicality, it is conducive to cultivating students' independent learning ability, organization and coordination ability, and communication ability, so whether it can be applied and promoted in the teaching of Japanese peripheral languages, this research is carried out. Although experts have always been committed to the innovation of Japanese teaching, the advancement of teaching materials, and the continuous innovation of design, they also need the teaching practice and experimentation of front-line teachers. After years of practice in basic Japanese teaching by generations of teachers, we still encounter this problem: students cannot use the language fluently, they can only memorize words, grammar, and the usage of some fixed terms by rote; Some students with strong writing ability are not strong in conversation and expression. According to these problems in teaching, the author found that students could not use language well, probably because they did not have the awareness and desire to communicate. Sometimes the single teaching method and the boring teaching content make students uninterested in learning Japanese, and the large number of pseudonyms, Chinese characters, and complex grammatical structures make students dazzled. The experimental results show that the new teaching method proposed by the experimental model is suitable for the learning of Japanese peripheral languages, which improves the student's learning and thinking ability, which proves that the optimized NN-SLVM model is good.",
      "year": "2023",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Wei Yi",
      "keywords": "Memorization; Interactivity; Grammar; Mathematics education; Communicative language teaching; Conversation; Computer science; Language education; Teaching method; Pedagogy; Psychology; Linguistics; Multimedia; Communication",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3626525",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4372348592",
      "doi": "10.1145/3594534",
      "title": "Casual Games, Cognition, and Play across the Lifespan: A Critical Synthesis",
      "abstract": "Games, including video games have long been associated with both rhetorics of progress and frivolity, simultaneously recruiting efforts to employ games toward furthering cognitive skills, while also eliciting concerns about the decadence of players. Casual games, defined as games with a low barrier to entry and quick play sessions often focus on cognitively-oriented challenges and are perceived by many players to promote cognitive, social, and emotional benefits. Research on the cognitive, social, and emotional impact of casual games now spans games marketed as entertainment, \u201cbrain games,\u201d and digital therapeutics; despite these games sharing similar qualities, the bodies of research literature on them remains largely distinct. This review finds little support for the cognitive benefits of playing casual games, with exception of the elderly or those with dementia. This research synthesis finds evidence for the social and emotional benefits of casual games when they are sought for these purposes, played mindfully, and within robust social contexts. However, the same games, when played in different contexts can have negative consequences, consistent with findings from the mindset literature more broadly. Researchers thus should take seriously the context of game play, perhaps treating the emergent phenomena of play as the unit of analysis, rather than the media artifact.",
      "year": "2023",
      "journal": "Games Research and Practice",
      "authors": "Kurt Squire et al.",
      "keywords": "Casual; Psychology; Mindset; Cognition; Context (archaeology); Entertainment; Social psychology; Cognitive psychology; Computer science; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3594534",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413968316",
      "doi": "10.1145/3749502",
      "title": "Unobtrusive Perceived Sleep Quality Monitoring in the Wild",
      "abstract": "Perceived sleep quality is a key aspect of sleep health and a crucial factor in mental health. However, predicting it accurately is difficult because of its deeply personal nature and the considerable variability in how individuals perceive their sleep at night. This study presents a robust subject-wise nested cross-validation framework for passive daily monitoring of perceived sleep quality using wearable data through population-level machine learning modeling. A total of 294 participants (mean age 42 (SD = 10) years; 43% female) were monitored over 30 days employing commercial wearable devices in free-living conditions, with daily self-reported sleep quality. A novel adaptation of the person-mean centering approach was employed to split time-varying features into within-person and between-person components, preventing temporal leakage and enabling unbiased daily prediction. Various machine learning models were trained, and SHAP values were used to identify key predictors. Our results show that fully passive prediction of perceived sleep quality is feasible at population-level from the first day of monitoring (ROC AUC 0.715, F1 0.494, BA 0.666), with within-person deviations from individual baselines being the primary predictors. The most influential predictors were found to be deviations in sleep duration and continuity, followed by cardiac, stress-related features, and SF-12 health survey components.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Andrew Dei Rossi et al.",
      "keywords": "Sleep quality; Sleep (system call); Psychology; Quality (philosophy); Computer science; Neuroscience; Cognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749502",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2030558401",
      "doi": "10.1145/71633.71635",
      "title": "On data and their analysis",
      "abstract": "article Free Access Share on On data and their analysis Author: B. I. Blum Johns Hopkins University/Applied Physics Laboratory Johns Hopkins University/Applied Physics LaboratoryView Profile Authors Info & Claims ACM SIGSOFT Software Engineering NotesVolume 14Issue 5July 1989 pp 24\u201334https://doi.org/10.1145/71633.71635Online:01 July 1989Publication History 0citation88DownloadsMetricsTotal Citations0Total Downloads88Last 12 Months1Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
      "year": "1989",
      "journal": "ACM SIGSOFT Software Engineering Notes",
      "authors": "Bruce I. Blum",
      "keywords": "Citation; Computer science; World Wide Web; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/71633.71635",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413968509",
      "doi": "10.1145/3749510",
      "title": "The Manipulative Power of Voice Characteristics: Investigating Deceptive Patterns in Mandarin Chinese Female Synthetic Speech",
      "abstract": "Pervasive voice interaction enables deceptive patterns through subtle voice characteristics, yet empirical investigation into this manipulation lags behind, especially within major non-English language contexts. Addressing this gap, our study presents the first systematic investigation into voice characteristic-based dark patterns employing female synthetic voices in Mandarin Chinese. This focus is crucial given the prevalence of female personas in commercial assistants and the prosodic significance in the Chinese language. Guided by the conceptual framework identifying key influencing factors, we systematically evaluate effectiveness variations by manipulating voice characteristics (five characteristics, three intensities) across different scenarios (shopping vs. question-answering) with different commercial aims. A preliminary study (N=24) validated the experimental materials and the main study (N=36) revealed significant behavioral manipulation (up to +2027.6%). Crucially, the analysis showed that effectiveness varied significantly with voice characteristics and scenario, mediated by user perception (of tone, intonation, timbre) and user demographics (individual preferences, though limited demographic impact). These interconnected findings offer evidence-based insights for ethical design.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Shuning Zhang et al.",
      "keywords": "Mandarin Chinese; Speech recognition; Linguistics; Communication; Computer science; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749510",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4413968603",
      "doi": "10.1145/3749498",
      "title": "Mindfulness Meditation and Respiration: Accelerometer-based Respiration Rate and Mindfulness Progress Estimation to Enhance App Engagement and Mindfulness Skills",
      "abstract": "Mindfulness training is widely recognized for its benefits in reducing depression, anxiety, and loneliness. With the rise of smartphone-based mindfulness apps, digital meditation has become more accessible, but sustaining long-term user engagement remains a challenge. This paper explores whether respiration biosignal feedback and mindfulness skill estimation enhance system usability and skill development. We develop a smartphone's accelerometer-based respiration tracking algorithm, eliminating the need for additional wearables. Unlike existing methods, our approach accurately captures slow breathing patterns typical of mindfulness meditation. Additionally, we introduce the first quantitative framework to estimate mindfulness skills---concentration, sensory clarity, and equanimity---based on accelerometer-derived respiration data. We develop and test our algorithms on 261 mindfulness sessions in both controlled and real-world settings. A user study comparing an experimental group receiving biosignal feedback with a control group using a standard app shows that respiration feedback enhances system usability. Our respiration tracking model achieves a mean absolute error (MAE) of 1.6 breaths per minute, closely aligning with ground truth data, while our mindfulness skill estimation attains F1 scores of 80-84% in tracking skill progression. By integrating respiration tracking and mindfulness estimation into a commercial app, we demonstrate the potential of smartphone sensors to enhance digital mindfulness training.",
      "year": "2025",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Mohammad Nur Hossain Khan et al.",
      "keywords": "Mindfulness; Meditation; Mindfulness meditation; Respiration; Psychology; Psychotherapist; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3749498",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2899027170",
      "doi": "10.1145/3274301",
      "title": "The Internet's Hidden Rules",
      "abstract": "Norms are central to how online communities are governed. Yet, norms are also emergent, arise from interaction, and can vary significantly between communities---making them challenging to study at scale. In this paper, we study community norms on Reddit in a large-scale, empirical manner. Via 2.8M comments removed by moderators of 100 top subreddits over 10 months, we use both computational and qualitative methods to identify three types of norms: macro norms that are universal to most parts of Reddit; meso norms that are shared across certain groups of subreddits; and micro norms that are specific to individual, relatively unique subreddits. Given the size of Reddit's user base---and the wide range of topics covered by different subreddits---we argue this represents the first large-scale census of the norms in broader internet culture. In other words, these findings shed light on what Reddit values, and how widely-held those values are. We conclude by discussing implications for the design of new and existing online communities.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Eshwar Chandrasekharan et al.",
      "keywords": "The Internet; Scale (ratio); Range (aeronautics); Sociology; Macro; Computer science; Online community; Data science; Internet privacy; World Wide Web; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274301",
      "cited_by_count": 260,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2963214893",
      "doi": "10.1145/3161602",
      "title": "Spatio-Temporal Data Mining",
      "abstract": "Large volumes of spatio-temporal data are increasingly collected and studied in diverse domains, including climate science, social sciences, neuroscience, epidemiology, transportation, mobile health, and Earth sciences. Spatio-temporal data differ from relational data for which computational approaches are developed in the data-mining community for multiple decades in that both spatial and temporal attributes are available in addition to the actual measurements/attributes. The presence of these attributes introduces additional challenges that needs to be dealt with. Approaches for mining spatio-temporal data have been studied for over a decade in the data-mining community. In this article, we present a broad survey of this relatively young field of spatio-temporal data mining. We discuss different types of spatio-temporal data and the relevant data-mining questions that arise in the context of analyzing each of these datasets. Based on the nature of the data-mining problem studied, we classify literature on spatio-temporal data mining into six major categories: clustering, predictive learning, change detection, frequent pattern mining, anomaly detection, and relationship mining. We discuss the various forms of spatio-temporal data-mining problems in each of these categories.",
      "year": "2018",
      "journal": "ACM Computing Surveys",
      "authors": "Gowtham Atluri et al.",
      "keywords": "Computer science; Data mining; Field (mathematics); Data science; Data stream mining; Temporal database; Cluster analysis; Anomaly detection; Context (archaeology); Temporal scales; Machine learning; Geography",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3161602",
      "cited_by_count": 426,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2950398529",
      "doi": "10.1145/3485128",
      "title": "Tackling Climate Change with Machine Learning",
      "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.",
      "year": "2022",
      "journal": "ACM Computing Surveys",
      "authors": "David Rolnick et al.",
      "keywords": "Climate change; Wonder; Computer science; Artificial intelligence; Greenhouse gas; Humanity; Machine learning; Data science; Political science; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1145/3485128",
      "cited_by_count": 191,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2899024559",
      "doi": "10.1145/3274351",
      "title": "Linguistic Signals under Misinformation and Fact-Checking",
      "abstract": "Misinformation and fact-checking are opposite forces in the news environment: the former creates inaccuracies to mislead people, while the latter provides evidence to rebut the former. These news articles are often posted on social media and attract user engagement in the form of comments. In this paper, we investigate linguistic (especially emotional and topical) signals expressed in user comments in the presence of misinformation and fact-checking. We collect and analyze a dataset of 5,303 social media posts with 2,614,374 user comments from Facebook, Twitter, and YouTube, and associate these posts to fact-check articles from Snopes and PolitiFact for veracity rulings (i.e., from true to false). We find that linguistic signals in user comments vary significantly with the veracity of posts, e.g., we observe more misinformation-awareness signals and extensive emoji and swear word usage with falser posts. We further show that these signals can help to detect misinformation. In addition, we find that while there are signals indicating positive effects after fact-checking, there are also signals indicating potential \"backfire\" effects.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Shan Jiang et al.",
      "keywords": "Misinformation; Social media; Computer science; Emoji; Psychology; Internet privacy; World Wide Web; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3274351",
      "cited_by_count": 121,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2969638639",
      "doi": "10.1145/3339399",
      "title": "Computational sustainability",
      "abstract": "Computer and information scientists join forces with other fields to help solve societal and environmental challenges facing humanity, in pursuit of a sustainable future.",
      "year": "2019",
      "journal": "Communications of the ACM",
      "authors": "Carla P. Gomes et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3339399",
      "cited_by_count": 115,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4399164841",
      "doi": "10.1145/3664191",
      "title": "Computer Science Curricula 2023",
      "abstract": "",
      "year": "2024",
      "journal": "ACM eBooks",
      "authors": "Amruth N. Kumar et al.",
      "keywords": "Curriculum; Engineering ethics; Computer science; Mathematics education; Engineering; Sociology; Psychology; Pedagogy",
      "mesh_terms": "",
      "pub_types": "book",
      "url": "https://doi.org/10.1145/3664191",
      "cited_by_count": 153,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2986026033",
      "doi": "10.1145/3359240",
      "title": "When Users Control the Algorithms",
      "abstract": "Recent interest in ethical AI has brought a slew of values, including fairness, into conversations about technology design. Research in the area of algorithmic fairness tends to be rooted in questions of distribution that can be subject to precise formalism and technical implementation. We seek to expand this conversation to include the experiences of people subject to algorithmic classification and decision-making. By examining tweets about the \"Twitter algorithm\" we consider the wide range of concerns and desires Twitter users express. We find a concern with fairness (narrowly construed) is present, particularly in the ways users complain that the platform enacts a political bias against conservatives. However, we find another important category of concern, evident in attempts to exert control over the algorithm. Twitter users who seek control do so for a variety of reasons, many well justified. We argue for the need for better and clearer definitions of what constitutes legitimate and illegitimate control over algorithmic processes and to consider support for users who wish to enact their own collective choices.",
      "year": "2019",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Jenna Burrell et al.",
      "keywords": "Conversation; Formalism (music); Computer science; Variety (cybernetics); Control (management); Subject (documents); Politics; Algorithm; Wish; Internet privacy; Sociology; World Wide Web; Artificial intelligence; Political science; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3359240",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3094294413",
      "doi": "10.1145/3415224",
      "title": "Designing Alternative Representations of Confusion Matrices to Support Non-Expert Public Understanding of Algorithm Performance",
      "abstract": "Ensuring effective public understanding of algorithmic decisions that are powered by machine learning techniques has become an urgent task with the increasing deployment of AI systems into our society. In this work, we present a concrete step toward this goal by redesigning confusion matrices for binary classification to support non-experts in understanding the performance of machine learning models. Through interviews (n=7) and a survey (n=102), we mapped out two major sets of challenges lay people have in understanding standard confusion matrices: the general terminologies and the matrix design. We further identified three sub-challenges regarding the matrix design, namely, confusion about the direction of reading the data, layered relations and quantities involved. We then conducted an online experiment with 483 participants to evaluate how effective a series of alternative representations target each of those challenges in the context of an algorithm for making recidivism predictions. We developed three levels of questions to evaluate users' objective understanding. We assessed the effectiveness of our alternatives for accuracy in answering those questions, completion time, and subjective understanding. Our results suggest that (1) only by contextualizing terminologies can we significantly improve users' understanding and (2) flow charts, which help point out the direction of reading the data, were most useful in improving objective understanding. Our findings set the stage for developing more intuitive and generally understandable representations of the performance of machine learning models.",
      "year": "2020",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Hong Shen et al.",
      "keywords": "Confusion matrix; Computer science; Context (archaeology); Set (abstract data type); Artificial intelligence; Machine learning; Confusion; Reading (process); Task (project management); Point (geometry); Data science; Psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3415224",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3135024179",
      "doi": "10.1145/3440754",
      "title": "Data Protection in AI Services",
      "abstract": "Advances in artificial intelligence (AI) have shaped today\u2019s user services, enabling enhanced personalization and better support. As such AI-based services inevitably require user data, the resulting privacy implications are de facto the unacceptable face of this technology. In this article, we categorize and survey the cutting-edge research on privacy and data protection in the context of personalized AI services. We further review the different protection approaches at three different levels, namely, the management, system, and AI levels\u2014showing that (i) not all of them meet our identified requirements of evolving AI services and that (ii) many challenges are addressed separately or fragmentarily by different research communities. Finally, we highlight open research challenges and future directions in data protection research, especially that comprehensive protection requires more interdisciplinary research and a combination of approaches at different levels.",
      "year": "2021",
      "journal": "ACM Computing Surveys",
      "authors": "Christian Meurisch et al.",
      "keywords": "Computer science; Personalization; Data Protection Act 1998; Context (archaeology); Categorization; Open research; Data science; Privacy protection; Information privacy; De facto; World Wide Web; Computer security; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1145/3440754",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2731035550",
      "doi": "10.1145/3090080",
      "title": "Beautiful\u2026but at What Cost?",
      "abstract": "Millions of people use platforms such as Google Maps to search for routes to their desired destinations. Recently, researchers and mapping platforms have shown growing interest in optimizing routes for criteria other than travel time, e.g. simplicity, safety, and beauty. However, despite the ubiquity of algorithmic routing and its potential to define how millions of people move around the world, very little is known about the externalities that arise when adopting these new optimization criteria, e.g. potential redistribution of traffic to certain neighborhoods and increased route complexity (with its associated risks). In this paper, we undertake the first controlled examination of these externalities, doing so across multiple mapping platforms, alternative optimizations, and cities. We find, for example, that scenic routing (i.e. \u201cbeauty\u201d-optimized routing) would remove vehicles from highways, greatly increase traffic around parks, and, in certain cases, do the same for high-income areas. Our results also highlight that the interaction between routing criteria and urban structure is complex and effects vary from city to city, an important consideration for the growing literature on alternative routing strategies. Finally, to address the lack of open implementations of alternative routing algorithms and controlled routing evaluation frameworks, we are releasing our alternative routing and evaluation platform with this paper.",
      "year": "2017",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Isaac Johnson et al.",
      "keywords": "Routing (electronic design automation); Computer science; Externality; Implementation; Destinations; Policy-based routing; Static routing; Transport engineering; Computer network; Routing protocol; Geography; Economics; Tourism; Engineering; Microeconomics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3090080",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4225879562",
      "doi": "10.1145/3512974",
      "title": "True or False: Studying the Work Practices of Professional Fact-Checkers",
      "abstract": "Misinformation has developed into a critical societal threat that can lead to disastrous societal consequences. Although fact-checking plays a key role in combating misinformation, relatively little research has empirically investigated work practices of professional fact-checkers. To address this gap, we conducted semi-structured interviews with 21 fact-checkers from 19 countries. The participants reported being inundated with information that needs filtering and prioritizing prior to fact-checking. The interviews surfaced a pipeline of practices fragmented across disparate tools that lack integration. Importantly, fact-checkers lack effective mechanisms for disseminating the outcomes of their efforts which prevents their work from fully achieving its potential impact. We found that the largely manual and labor intensive nature of current fact-checking practices is a barrier to scale. We apply these findings to propose a number of suggestions that can improve the effectiveness, efficiency, scale, and reach of fact-checking work and its outcomes.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Nicholas Micallef et al.",
      "keywords": "Misinformation; Work (physics); Scale (ratio); Computer science; Pipeline (software); Dissemination; False accusation; Key (lock); Data science; Risk analysis (engineering); Public relations; Psychology; Computer security; Social psychology; Political science; Business; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3512974",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387328606",
      "doi": "10.1145/3610067",
      "title": "How Stated Accuracy of an AI System and Analogies to Explain Accuracy Affect Human Reliance on the System",
      "abstract": "AI systems are increasingly being used to support human decision making. It is important that AI advice is followed appropriately. However, according to existing literature, users typically under-rely or over-rely on AI systems, and this leads to sub-optimal team performance. In this context, we investigate the role of stated system accuracy by contrasting the lack of system information with the presence of system accuracy in a loan prediction task. We explore how the degree to which humans understand system accuracy influences their reliance on the AI system, by investigating numeracy levels and with the aid of analogies to explain system accuracy in a first of its kind between-subjects study (N=281). We found that explaining the stated accuracy of a system using analogies failed to help users rely on the AI systemappropriately (i.e., the tendency of users to rely on the system when the system is correct, or on themselves otherwise). To eliminate the impact of subjective attitudes towards analogy domains, we conducted a within-subjects study (N=248) where each participant worked on tasks with analogy-based explanations from different domains. Results from this second study confirmed that explaining stated accuracy of the system with analogies was not sufficient to facilitate appropriate reliance on the AI system in the context of loan prediction tasks, irrespective of individual user differences. Based on our findings from the two studies, we reason that the under-reliance on the AI system may be a result of users' overestimation of their own ability to solve the given task. Thus, although familiar analogies can be effective in improving the intelligibility of stated accuracy of the system, an improved understanding of system accuracy does not necessarily lead to improved system reliance and team performance.",
      "year": "2023",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Gaole He et al.",
      "keywords": "Analogy; Computer science; Affect (linguistics); Context (archaeology); Loan; Artificial intelligence; Task (project management); Machine learning; Cognitive psychology; Psychology; Finance; Engineering; Communication",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3610067",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4307886640",
      "doi": "10.1145/3569897",
      "title": "Emerging Technologies in K\u201312 Education: A Future HCI Research Agenda",
      "abstract": "This systematic mapping review sheds light on how emerging technologies have been introduced and taught in various K\u201312 learning settings, particularly with regard to artificial intelligence (AI), machine learning (ML), the internet of things (IoT), augmented reality (AR), and virtual reality (VR). These technologies are rapidly being integrated into children's everyday lives, but their functions and implications are rarely understood due to their complex and distributed nature. The review provides a rigorous overview of the state of the art based on 107 records published across the fields of human-computer interaction, learning sciences, computing education, and child\u2013computer interaction between 2010 and 2020. The findings show the urgent need on a global scale for inter- and transdisciplinary research that can integrate these dispersed contributions into a more coherent field of research and practice. The article presents nine discussion points for developing a shared agenda to mature the field. Based on the HCI community's expertise in human-centred approaches to technology and aspects of learning, we argue that the community is ideally positioned to take a leading role in the realisation of this future research agenda.",
      "year": "2022",
      "journal": "ACM Transactions on Computer-Human Interaction",
      "authors": "Maarten Van Mechelen et al.",
      "keywords": "Engineering ethics; Political science; Computer science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3569897",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2782965555",
      "doi": "10.1145/3161184",
      "title": "Predicting the Suitability of Service Animals Using Instrumented Dog Toys",
      "abstract": "Working dogs1 are significantly beneficial to society; however, a substantial number of dogs are released from time consuming and expensive training programs because of unsuitability in behavior. Early prediction of successful service dog placement could save time, resources, and funding. Our research focus is to explore whether aspects of canine temperament can be detected from interactions with sensors, and to develop classifiers that correlate sensor data to predict the success (or failure) of assistance dogs in advanced training. In a 2-year longitudinal study, our team tested a cohort of dogs entering advanced training in the Canine Companions for Independence (CCI) Program with 2 instrumented dog toys: a silicone ball and a silicone tug sensor. We then create a logistic model tree classifier to predict service dog success using only 5 features derived from dog-toy interactions. During randomized 10-fold cross validation where 4 of the 40 dogs were kept in an independent test set for each fold, our classifier predicts the dogs' outcomes with 87.5% average accuracy. We assess the reliability of our model by performing the testing routine 10 times over 1.5 years for a single suitable working dog, which predicts that the dog would pass each time. We calculate the resource benefit of identifying dogs who will fail early in their training, and the value for a cohort of 40 dogs using our toys and our methods for prediction is over $70,000. With CCI's 6 training centers, annual savings could be upwards of $5 million per year.",
      "year": "2018",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Ceara Byrne et al.",
      "keywords": "Cohort; Logistic regression; Computer science; Medicine; Simulation; Psychology; Statistics; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3161184",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4318041103",
      "doi": "10.1145/3581759",
      "title": "A Survey on Edge Intelligence and Lightweight Machine Learning Support for Future Applications and Services",
      "abstract": "As the number of devices connected to the Internet has grown larger, so too has the intensity of the tasks that these devices need to perform. Modern networks are more frequently working to perform computationally intensive tasks on low-power devices and low-end hardware. Current architectures and platforms tend towards centralized and resource-rich cloud computing approaches to address these deficits. However, edge computing presents a much more viable and flexible alternative. Edge computing refers to a distributed and decentralized network architecture in which demanding tasks such as image recognition, smart city services, and high-intensity data processing tasks can be distributed over a number of integrated network devices. In this article, we provide a comprehensive survey for emerging edge intelligence applications, lightweight machine learning algorithms, and their support for future applications and services. We start by analyzing the rise of cloud computing, discuss its weak points, and identify situations in which edge computing provides advantages over traditional cloud computing architectures. We then divulge details of the survey: the first section identifies opportunities and domains for edge computing growth, the second identifies algorithms and approaches that can be used to enhance edge intelligence implementations, and the third specifically analyzes situations in which edge intelligence can be enhanced using any of the aforementioned algorithms or approaches. In this third section, lightweight machine learning approaches are detailed. A more in-depth analysis and discussion of future developments follows. The primary discourse of this article is in service of an effort to ensure that appropriate approaches are applied adequately to artificial intelligence implementations in edge systems, mainly, the lightweight machine learning approaches.",
      "year": "2023",
      "journal": "Journal of Data and Information Quality",
      "authors": "Kyle Hoffpauir et al.",
      "keywords": "Computer science; Cloud computing; Edge computing; Enhanced Data Rates for GSM Evolution; Implementation; Distributed computing; Edge device; Artificial intelligence; Service (business); Architecture; Machine learning; Data science; Software engineering; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3581759",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2606469231",
      "doi": "10.1145/3001934",
      "title": "Fundamental Challenges Toward Making the IoT a Reachable Reality",
      "abstract": "Constantly advancing integration capability is paving the way for the construction of the extremely large scale continuum of the Internet where entities or things from vastly varied domains are uniquely addressable and interacting seamlessly to form a giant networked system of systems known as the Internet-of-Things (IoT). In contrast to this visionary networked system paradigm, prior research efforts on the IoT are still very fragmented and confined to disjoint explorations of different applications, architecture, security, services, protocol, and economical domains, thus preventing design exploration and optimization from a unified and global perspective. In this context, this survey article first proposes a mathematical modeling framework that is rich in expressivity to capture IoT characteristics from a global perspective. It also sets forward a set of fundamental challenges in sensing, decentralized computation, robustness, energy efficiency, and hardware security based on the proposed modeling framework. Possible solutions are discussed to shed light on future development of the IoT system paradigm.",
      "year": "2017",
      "journal": "ACM Transactions on Design Automation of Electronic Systems",
      "authors": "Yuankun Xue et al.",
      "keywords": "Computer science; Internet of Things; Robustness (evolution); Architecture; Distributed computing; Context (archaeology); Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3001934",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2975111084",
      "doi": "10.1145/3241378",
      "title": "A Data-Driven Approach to Designing for Privacy in Household IoT",
      "abstract": "In this article, we extend and improve upon a previously developed data-driven approach to design privacy-setting interfaces for users of household IoT devices. The essence of this approach is to gather users\u2019 feedback on household IoT scenarios before developing the interface, which allows us to create a navigational structure that preemptively maximizes users\u2019 efficiency in expressing their privacy preferences, and develop a series of \u2018privacy profiles\u2019 that allow users to express a complex set of privacy preferences with the single click of a button. We expand upon the existing approach by proposing a more sophisticated translation of statistical results into interface design, and by extensively discussing and analyzing the tradeoff between user-model parsimony and accuracy in developing privacy profiles and default settings.",
      "year": "2019",
      "journal": "ACM Transactions on Interactive Intelligent Systems",
      "authors": "Yangyang He et al.",
      "keywords": "Computer science; Interface (matter); Set (abstract data type); Internet of Things; Human\u2013computer interaction; Computer security; Internet privacy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3241378",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2997357454",
      "doi": "10.1145/3365537",
      "title": "Interaction Models for Detecting Nodal Activities in Temporal Social Media Networks",
      "abstract": "Detecting nodal activities in dynamic social networks has strategic importance in many applications, such as online marketing campaigns and homeland security surveillance. How peer-to-peer exchanges in social media can facilitate nodal activity detection is not well explored. Existing models assume network nodes to be static in time and do not adequately consider features from social theories. This research developed and validated two theory-based models, Random Interaction Model (RIM) and Preferential Interaction Model (PIM), to characterize temporal nodal activities in social media networks of human agents. The models capture the network characteristics of randomness and preferential interaction due to community size, human bias, declining connection cost, and rising reachability. The models were compared against three benchmark models (abbreviated as EAM, TAM, and DBMM) using a social media community consisting of 790,462 users who posted over 3,286,473 tweets and formed more than 3,055,797 links during 2013\u20132015. The experimental results show that both RIM and PIM outperformed EAM and TAM significantly in accuracy across different dates and time windows. Both PIM and RIM scored significantly smaller errors than DBMM did. Structural properties of social networks were found to provide a simple and yet accurate approach to predicting model performances. These results indicate the models\u2019 strong capability of accounting for user interactions in real-world social media networks and temporal activity detection. The research should provide new approaches for temporal network activity detection, develop relevant new measures, and report new findings from large social media datasets.",
      "year": "2019",
      "journal": "ACM Transactions on Management Information Systems",
      "authors": "Wingyan Chung et al.",
      "keywords": "Computer science; Reachability; Benchmark (surveying); Social media; Randomness; Social network (sociolinguistics); Data science; Machine learning; Artificial intelligence; Theoretical computer science; World Wide Web; Mathematics; Geography; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3365537",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388977727",
      "doi": "10.1145/3634686",
      "title": "A Privacy Preserving System for Movie Recommendations Using Federated Learning",
      "abstract": "Recommender systems have become ubiquitous in the past years. They solve the tyranny of choice problem faced by many users, and are utilized by many online businesses to drive engagement and sales. Besides other criticisms, like creating filter bubbles within social networks, recommender systems are often reproved for collecting considerable amounts of personal data. However, to personalize recommendations, personal information is fundamentally required. A recent distributed learning scheme called federated learning has made it possible to learn from personal user data without its central collection. Consequently, we present a recommender system for movie recommendations, which provides privacy and thus trustworthiness on multiple levels: First and foremost, it is trained using federated learning and thus, by its very nature, privacy-preserving, while still enabling users to benefit from global insights. Furthermore, a novel federated learning scheme, called FedQ, is employed, which not only addresses the problem of non-i.i.d.-ness and small local datasets, but also prevents input data reconstruction attacks by aggregating client updates early. Finally, to reduce the communication overhead, compression is applied, which significantly compresses the exchanged neural network parametrizations to a fraction of their original size. We conjecture that this may also improve data privacy through its lossy quantization stage.",
      "year": "2023",
      "journal": "ACM Transactions on Recommender Systems",
      "authors": "David Neumann et al.",
      "keywords": "Computer science; Recommender system; Lossy compression; Overhead (engineering); Scheme (mathematics); Collaborative filtering; Filter (signal processing); World Wide Web; Internet privacy; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3634686",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4401762572",
      "doi": "10.1145/3689485",
      "title": "When Small Decisions Have Big Impact: Fairness Implications of Algorithmic Profiling Schemes",
      "abstract": "Algorithmic profiling is increasingly used in the public sector with the hope of allocating limited public resources more effectively and objectively. One example is the prediction-based profiling of job seekers to guide the allocation of support measures by public employment services. However, empirical evaluations of potential side-effects such as unintended discrimination and fairness concerns are rare in this context. We systematically compare and evaluate statistical models for predicting job seekers\u2019 risk of becoming long-term unemployed concerning subgroup prediction performance, fairness metrics, and vulnerabilities to data analysis decisions. Focusing on Germany as a use case, we evaluate profiling models under realistic conditions using large-scale administrative data. We show that despite achieving high prediction performance on average, profiling models can be considerably less accurate for vulnerable social subgroups. In this setting, different classification policies can have very different fairness implications. We therefore call for rigorous auditing processes before such models are put to practice.",
      "year": "2024",
      "journal": "ACM Journal on Responsible Computing",
      "authors": "Christoph Kern et al.",
      "keywords": "Profiling (computer programming); Computer science; Audit; Unintended consequences; Public sector; Empirical research; Big data; Data science; Data mining; Business; Accounting; Economics; Political science; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3689485",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388230772",
      "doi": "10.1145/3626318",
      "title": "Topic Modeling based Text Classification Regarding Islamophobia using Word Embedding and Transformers Techniques",
      "abstract": "Islamophobia is a rising area of concern in the current era where Muslims face discrimination and receive negative perspectives towards their religion, Islam. Islamophobia is a type of racism that is being practiced by individuals, groups, and organizations worldwide. Moreover, the ease of access to social media platforms and their augmented usage has also contributed to spreading hate speech, false information, and negative opinions about Islam. In this research study, we focused to detect Islamophobic textual content shared on various social media platforms. We explored the state-of-the-art techniques being followed in text data mining and Natural Language Processing (NLP). Topic modelling algorithm Latent Dirichlet Allocation is used to find top topics. Then, word embedding approaches such as Word2Vec and Global Vectors for word representation (GloVe) are used as feature extraction techniques. For text classification, we utilized modern text analysis techniques of transformers-based Deep Learning algorithms named Bidirectional Encoders Representation from Transformers (BERT) and Generative Pre-Trained Transformer (GPT). For results comparison, we conducted an extensive empirical analysis of Machine Learning algorithms and Deep Learning using conventional textual features such as the Term Frequency-Inverse Document Frequency, N-gram, and Bag of words (BoW). The empirical based results evaluated using standard performance evaluation measures show that the proposed approach effectively detects the textual content related to Islamophobia. In the corpus of the study under Machine Learning models Support Vector Machine (SVM) performed best with an F1 score of 91%. The Transformer based core NLP models and the Deep Learning model Convolutional Neural Network (CNN) when combined with GloVe performed best among all the techniques except SVM with BoW. GPT, SVM when combined with BoW and BERT yielded the best F1 score of 92%, 92% and 91.9% respectively, while CNN performed slightly poor with an F1 score of 91%.",
      "year": "2023",
      "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing",
      "authors": "Ammar Saeed et al.",
      "keywords": "Computer science; Word embedding; Artificial intelligence; Islamophobia; Natural language processing; Latent Dirichlet allocation; Word2vec; Sentiment analysis; Transformer; Feature learning; Social media; Support vector machine; Autoencoder; Deep learning; Machine learning; Topic model; Embedding; Engineering; World Wide Web; Islam",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3626318",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3208103085",
      "doi": "10.1145/3457909",
      "title": "Results From Invoking Artificial Neural Networks to Measure Insider Threat Detection &amp; Mitigation",
      "abstract": "Advances on differentiating between malicious intent and natural \u201corganizational evolution\u201d to explain observed anomalies in operational workplace patterns suggest benefit from evaluating collective behaviors observed in the facilities to improve insider threat detection and mitigation (ITDM). Advances in artificial neural networks (ANN) provide more robust pathways for capturing, analyzing, and collating disparate data signals into quantitative descriptions of operational workplace patterns. In response, a joint study by Sandia National Laboratories and the University of Texas at Austin explored the effectiveness of commercial artificial neural network (ANN) software to improve ITDM. This research demonstrates the benefit of learning patterns of organizational behaviors, detecting off-normal (or anomalous) deviations from these patterns, and alerting when certain types, frequencies, or quantities of deviations emerge for improving ITDM. Evaluating nearly 33,000 access control data points and over 1,600 intrusion sensor data points collected over a nearly twelve-month period, this study's results demonstrated the ANN could recognize operational patterns at the Nuclear Engineering Teaching Laboratory (NETL) and detect off-normal behaviors\u2014suggesting that ANNs can be used to support a data-analytic approach to ITDM. Several representative experiments were conducted to further evaluate these conclusions, with the resultant insights supporting collective behavior-based analytical approaches to quantitatively describe insider threat detection and mitigation.",
      "year": "2021",
      "journal": "Digital Threats Research and Practice",
      "authors": "Adam David Williams et al.",
      "keywords": "Insider threat; Artificial neural network; Insider; Computer science; Artificial intelligence; Software; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3457909",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391222150",
      "doi": "10.1145/3639825",
      "title": "Behave Differently when Clustering: A Semi-asynchronous Federated Learning Approach for IoT",
      "abstract": "The Internet of Things (IoT) has revolutionized the connectivity of diverse sensing devices, generating an enormous volume of data. However, applying machine learning algorithms to sensing devices presents substantial challenges due to resource constraints and privacy concerns. Federated learning (FL) emerges as a promising solution allowing for training models in a distributed manner while preserving data privacy on client devices. We contribute SAFI , a semi-asynchronous FL approach based on clustering to achieve a novel in-cluster synchronous and out-cluster asynchronous FL training mode. Specifically, we propose a three-tier architecture to enable IoT data processing on edge devices and design a clustering selection module to effectively group heterogeneous edge devices based on their processing capacities. The performance of SAFI has been extensively evaluated through experiments conducted on a real-world testbed. As the heterogeneity of edge devices increases, SAFI surpasses the baselines in terms of the convergence time, achieving a speedup of approximately \u00d7 3 when the heterogeneity ratio is 7:1. Moreover, SAFI demonstrates favorable performance in non-independent and identically distributed settings and requires lower communication cost compared to FedAsync. Notably, SAFI is the first Java-implemented FL approach and holds significant promise to serve as an efficient FL algorithm in IoT environments.",
      "year": "2024",
      "journal": "ACM Transactions on Sensor Networks",
      "authors": "Boyu Fan et al.",
      "keywords": "Computer science; Asynchronous communication; Cluster analysis; Internet of Things; Distributed computing; Artificial intelligence; Computer network; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3639825",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3157512619",
      "doi": "10.1145/3449252",
      "title": "\"Wiring a City\"",
      "abstract": "We use a sociotechnical perspective to expand upon prior characterizations of deploying end-to-end urban sensor networks that focus primarily on the technical aspects of such systems. Via exploratory, semi-structured interviews with those deploying a number of urban sensor networks in a single American city, we identify ways that human decision-making and collaborative processes influence how these infrastructures are built. We synthesize these findings into a framework in which sociotechnical factors show up across the phases of data collection, management, analysis, and impacts within smart city projects. Each phase can display variability in immediacy, automation, geographic scope, and ownership. Finally, we use our situated work to discuss a generalizable tension within smart city projects between cross-domain data integration and fragmentation and provide implications for CSCW research, the design of smart city data platforms, and municipal policy.",
      "year": "2021",
      "journal": "Proceedings of the ACM on Human-Computer Interaction",
      "authors": "Lucy Van Kleunen et al.",
      "keywords": "Sociotechnical system; Smart city; Situated; Scope (computer science); Computer science; Data science; Knowledge management; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3449252",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4284881342",
      "doi": "10.1145/3534578",
      "title": "Predicting Post-Operative Complications with Wearables",
      "abstract": "Post-operative complications and hospital readmission are of great concern to surgical patients and health care providers. Wearable devices such as Fitbit wristbands enable long-term and non-intrusive monitoring of patients outside clinical environments. To build accurate predictive models based on wearable data, however, requires effective feature engineering to extract high-level features from time series data collected by the wearable sensors. This paper presents a pipeline for developing clinical predictive models based on wearable sensors. The core of the pipeline is a multi-level feature engineering framework for extracting high-level features from fine-grained time series data. The framework integrates a set of techniques tailored for noisy and incomplete wearable data collected in real-world clinical studies: (1) singular spectrum analysis for extracting high-level features from daily features over the course of the study; (2) a set of daily features that are resilient to missing data in wearable time series data; (3) a K-Nearest Neighbors (KNN) method for imputing short missing heart rate segments; (4) the integration of patients' clinical characteristics and wearable features. We evaluated the feature engineering approach and machine learning models in a clinical study involving 61 patients undergoing pancreatic surgery. Linear support vector machine (SVM) with integrated feature engineering achieved an AUROC of 0.8802 for predicting post-operative readmission or severe complications, which significantly outperformed the existing rule-based model used in clinical practice and other state-of-the-art feature engineering approaches.",
      "year": "2022",
      "journal": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
      "authors": "Jingwen Zhang et al.",
      "keywords": "Feature engineering; Wearable computer; Pipeline (software); Computer science; Feature (linguistics); Support vector machine; Machine learning; Artificial intelligence; Data mining; Wearable technology; Data set; Deep learning; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1145/3534578",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    }
  ],
  "query_stats": [
    {
      "id": "Q1",
      "label": "Core: algorithmic bias/fairness + health",
      "search": "algorithmic bias fairness health healthcare clinical medical",
      "results_found": 113,
      "new_unique": 113,
      "cumulative": 113
    },
    {
      "id": "Q2",
      "label": "AI bias mitigation health",
      "search": "AI bias mitigation debiasing health healthcare clinical",
      "results_found": 10,
      "new_unique": 0,
      "cumulative": 113
    },
    {
      "id": "Q3",
      "label": "Machine learning fairness health",
      "search": "machine learning fairness bias health clinical medical",
      "results_found": 142,
      "new_unique": 38,
      "cumulative": 151
    },
    {
      "id": "Q4",
      "label": "Bias assessment AI healthcare",
      "search": "bias assessment evaluation audit artificial intelligence healthcare",
      "results_found": 44,
      "new_unique": 23,
      "cumulative": 174
    },
    {
      "id": "Q5",
      "label": "Racial gender bias clinical AI",
      "search": "racial gender bias clinical prediction algorithm machine learning",
      "results_found": 35,
      "new_unique": 10,
      "cumulative": 184
    },
    {
      "id": "Q6",
      "label": "Health disparities AI algorithm",
      "search": "health disparities algorithmic bias machine learning deep learning",
      "results_found": 134,
      "new_unique": 82,
      "cumulative": 266
    },
    {
      "id": "Q7",
      "label": "Fairness-aware ML health",
      "search": "fairness-aware machine learning equalized odds demographic parity health",
      "results_found": 12,
      "new_unique": 3,
      "cumulative": 269
    },
    {
      "id": "Q8",
      "label": "Bias EHR clinical decision support",
      "search": "bias electronic health record clinical decision support algorithm",
      "results_found": 131,
      "new_unique": 57,
      "cumulative": 326
    },
    {
      "id": "Q9",
      "label": "Bias medical imaging AI",
      "search": "bias medical imaging radiology dermatology deep learning AI",
      "results_found": 3,
      "new_unique": 0,
      "cumulative": 326
    },
    {
      "id": "Q10",
      "label": "Equitable AI health",
      "search": "equitable AI health equity fairness algorithm clinical",
      "results_found": 16,
      "new_unique": 1,
      "cumulative": 327
    },
    {
      "id": "Q11",
      "label": "NLP bias clinical health",
      "search": "natural language processing bias clinical health medical NLP",
      "results_found": 63,
      "new_unique": 16,
      "cumulative": 343
    },
    {
      "id": "Q12",
      "label": "Bias federated learning health",
      "search": "bias fairness federated learning health clinical",
      "results_found": 24,
      "new_unique": 2,
      "cumulative": 345
    },
    {
      "id": "Q13",
      "label": "LLM bias health",
      "search": "large language model bias health clinical medical",
      "results_found": 240,
      "new_unique": 64,
      "cumulative": 409
    },
    {
      "id": "Q14",
      "label": "Disparate impact health prediction",
      "search": "disparate impact health prediction model algorithm bias",
      "results_found": 93,
      "new_unique": 25,
      "cumulative": 434
    },
    {
      "id": "Q15",
      "label": "Bias risk prediction clinical",
      "search": "bias risk prediction mortality readmission clinical algorithm",
      "results_found": 11,
      "new_unique": 1,
      "cumulative": 435
    }
  ],
  "meta": {
    "total_unique": 435,
    "ta_included": 16,
    "ta_excluded": 419,
    "ft_included": 8,
    "ft_excluded": 8
  }
}