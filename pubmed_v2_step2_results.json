{
  "source_file": "[0211] IEEE John_Screening 1 & 2.xlsx \u7684\u526f\u672c.xlsx",
  "source_sheet": "PubMed2",
  "total_pmids_in_sheet": 1899,
  "total_fetched": 1887,
  "reviews_removed": 665,
  "papers_screened": 1222,
  "ta_included_count": 351,
  "ta_excluded_count": 871,
  "ta_exclusion_reasons": {
    "Bias/fairness not central": 835,
    "No AI/ML terms": 24,
    "No health terms": 10,
    "Human cognitive bias only": 2
  },
  "screening_criteria": {
    "ai_terms": [
      "artificial intelligence",
      "machine learning",
      "deep learning",
      "neural network",
      "natural language processing",
      "nlp",
      "computer vision",
      "random forest",
      "decision tree",
      "support vector",
      "svm",
      "logistic regression",
      "gradient boosting",
      "xgboost",
      "ensemble",
      "supervised learning",
      "unsupervised learning",
      "reinforcement learning",
      "transfer learning",
      "federated learning",
      "convolutional neural",
      "recurrent neural",
      "transformer",
      "bert",
      "gpt",
      "large language model",
      "llm",
      "generative ai",
      "foundation model",
      "predictive model",
      "prediction model",
      "clinical prediction",
      "risk prediction",
      "classification model",
      "regression model",
      "clustering",
      "automated",
      "algorithm",
      "computational",
      "data-driven",
      "clinical decision support",
      "computer-aided",
      "image recognition",
      "feature selection",
      "dimensionality reduction"
    ],
    "health_terms": [
      "health",
      "clinical",
      "medical",
      "patient",
      "hospital",
      "disease",
      "diagnosis",
      "treatment",
      "therapy",
      "prognosis",
      "mortality",
      "morbidity",
      "surgical",
      "radiology",
      "pathology",
      "oncology",
      "cardiology",
      "dermatology",
      "ophthalmology",
      "psychiatry",
      "mental health",
      "emergency",
      "icu",
      "intensive care",
      "ehr",
      "electronic health record",
      "biomedical",
      "pharmaceutical",
      "drug",
      "genomic",
      "imaging",
      "screening",
      "vaccination",
      "epidemiology",
      "public health",
      "healthcare",
      "care",
      "nursing",
      "pharmacy",
      "dental",
      "rehabilitation",
      "chronic",
      "acute",
      "outpatient",
      "inpatient",
      "primary care",
      "sepsis",
      "pneumonia",
      "diabetes",
      "cancer",
      "tumor",
      "stroke",
      "heart",
      "lung",
      "kidney",
      "liver",
      "brain"
    ],
    "strong_title_terms": [
      "bias",
      "fairness",
      "fair ",
      "unfair",
      "equity",
      "inequity",
      "disparity",
      "disparities",
      "discrimination",
      "algorithmic bias",
      "racial bias",
      "gender bias",
      "health equity",
      "health disparities",
      "equitable",
      "inequitable"
    ],
    "ai_bias_terms": [
      "algorithmic bias",
      "model bias",
      "prediction bias",
      "data bias",
      "selection bias",
      "label bias",
      "measurement bias",
      "sampling bias",
      "representation bias",
      "training bias",
      "dataset bias",
      "fairness",
      "unfairness",
      "equalized odds",
      "demographic parity",
      "equal opportunity",
      "disparate impact",
      "calibration bias",
      "subgroup",
      "performance gap",
      "performance disparity",
      "underrepresent",
      "overrepresent",
      "health equity",
      "health disparity",
      "health disparities",
      "racial disparity",
      "racial disparities",
      "gender disparity",
      "sex-based",
      "race-based",
      "ethnic",
      "socioeconomic",
      "underserved",
      "marginalized",
      "vulnerable population",
      "minority",
      "bias mitigation",
      "bias detection",
      "bias assessment",
      "bias evaluation",
      "bias audit",
      "debiasing",
      "debias",
      "fair machine learning",
      "fair ai",
      "responsible ai",
      "trustworthy ai",
      "ethical ai"
    ],
    "human_only_terms": [
      "cognitive bias",
      "confirmation bias",
      "anchoring bias",
      "availability bias",
      "recall bias",
      "observer bias",
      "interviewer bias",
      "response bias",
      "reporting bias",
      "publication bias",
      "attrition bias",
      "detection bias",
      "information bias",
      "lead-time bias",
      "length bias",
      "surveillance bias",
      "referral bias",
      "volunteer bias",
      "healthy worker",
      "berkson",
      "neyman"
    ],
    "ai_specific_terms": [
      "algorithmic",
      "algorithm",
      "machine learning",
      "deep learning",
      "artificial intelligence",
      "model bias",
      "prediction bias",
      "training bias",
      "data bias",
      "fairness",
      "fair ",
      "equalized odds",
      "demographic parity",
      "disparate impact"
    ]
  },
  "included": [
    {
      "pmid": "31649194",
      "title": "Dissecting racial bias in an algorithm used to manage the health of populations.",
      "abstract": "Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.",
      "authors": "Obermeyer Ziad; Powers Brian; Vogeli Christine; Mullainathan Sendhil",
      "year": "2019",
      "journal": "Science (New York, N.Y.)",
      "doi": "10.1126/science.aax2342",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31649194/",
      "mesh_terms": "Black or African American; Algorithms; Bias; Chronic Disease; Health Care Costs; Health Status Disparities; Humans; Medical Records; Racism; Risk Assessment; United States; White People",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "30508424",
      "title": "Ensuring Fairness in Machine Learning to Advance Health Equity.",
      "abstract": "Machine learning is used increasingly in clinical care to improve diagnosis, treatment selection, and health system efficiency. Because machine-learning models learn from historically collected data, populations that have experienced human and structural biases in the past-called protected groups-are vulnerable to harm by incorrect predictions or withholding of resources. This article describes how model design, biases in data, and the interactions of model predictions with clinicians and patients may exacerbate health care disparities. Rather than simply guarding against these harms passively, machine-learning systems should be used proactively to advance health equity. For that goal to be achieved, principles of distributive justice must be incorporated into model design, deployment, and evaluation. The article describes several technical implementations of distributive justice-specifically those that ensure equality in patient outcomes, performance, and resource allocation-and guides clinicians as to when they should prioritize each principle. Machine learning is providing increasingly sophisticated decision support and population-level monitoring, and it should encode principles of justice to ensure that models benefit all patients.",
      "authors": "Rajkomar Alvin; Hardt Michaela; Howell Michael D; Corrado Greg; Chin Marshall H",
      "year": "2018",
      "journal": "Annals of internal medicine",
      "doi": "10.7326/M18-1990",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30508424/",
      "mesh_terms": "Critical Care; Health Care Rationing; Health Equity; Healthcare Disparities; Humans; Length of Stay; Machine Learning; Patient Outcome Assessment; Social Justice",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6594166"
    },
    {
      "pmid": "20378467",
      "title": "N4ITK: improved N3 bias correction.",
      "abstract": "A variant of the popular nonparametric nonuniform intensity normalization (N3) algorithm is proposed for bias field correction. Given the superb performance of N3 and its public availability, it has been the subject of several evaluation studies. These studies have demonstrated the importance of certain parameters associated with the B-spline least-squares fitting. We propose the substitution of a recently developed fast and robust B-spline approximation routine and a modified hierarchical optimization scheme for improved bias field correction over the original N3 algorithm. Similar to the N3 algorithm, we also make the source code, testing, and technical documentation of our contribution, which we denote as \"N4ITK,\" available to the public through the Insight Toolkit of the National Institutes of Health. Performance assessment is demonstrated using simulated data from the publicly available Brainweb database, hyperpolarized (3)He lung image data, and 9.4T postmortem hippocampus data.",
      "authors": "Tustison Nicholas J; Avants Brian B; Cook Philip A; Zheng Yuanjie; Egan Alexander; Yushkevich Paul A; Gee James C",
      "year": "2010",
      "journal": "IEEE transactions on medical imaging",
      "doi": "10.1109/TMI.2010.2046908",
      "url": "https://pubmed.ncbi.nlm.nih.gov/20378467/",
      "mesh_terms": "Algorithms; Artifacts; Brain; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Reproducibility of Results; Sensitivity and Specificity",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC3071855"
    },
    {
      "pmid": "37599147",
      "title": "Illness severity assessment of older adults in critical illness using machine learning (ELDER-ICU): an international multicentre study with subgroup bias evaluation.",
      "abstract": "BACKGROUND: Comorbidity, frailty, and decreased cognitive function lead to a higher risk of death in elderly patients (more than 65 years of age) during acute medical events. Early and accurate illness severity assessment can support appropriate decision making for clinicians caring for these patients. We aimed to develop ELDER-ICU, a machine learning model to assess the illness severity of older adults admitted to the intensive care unit (ICU) with cohort-specific calibration and evaluation for potential model bias. METHODS: In this retrospective, international multicentre study, the ELDER-ICU model was developed using data from 14 US hospitals, and validated in 171 hospitals from the USA and Netherlands. Data were extracted from the Medical Information Mart for Intensive Care database, electronic ICU Collaborative Research Database, and Amsterdam University Medical Centers Database. We used six categories of data as predictors, including demographics and comorbidities, physical frailty, laboratory tests, vital signs, treatments, and urine output. Patient data from the first day of ICU stay were used to predict in-hospital mortality. We used the eXtreme Gradient Boosting algorithm (XGBoost) to develop models and the SHapley Additive exPlanations method to explain model prediction. The trained model was calibrated before internal, external, and temporal validation. The final XGBoost model was compared against three other machine learning algorithms and five clinical scores. We performed subgroup analysis based on age, sex, and race. We assessed the discrimination and calibration of models using the area under receiver operating characteristic (AUROC) and standardised mortality ratio (SMR) with 95% CIs. FINDINGS: Using the development dataset (n=50\u2008366) and predictive model building process, the XGBoost algorithm performed the best in all types of validations compared with other machine learning algorithms and clinical scores (internal validation with 5037 patients from 14 US hospitals, AUROC=0\u00b7866 [95% CI 0\u00b7851-0\u00b7880]; external validation in the US population with 20\u2008541 patients from 169 hospitals, AUROC=0\u00b7838 [0\u00b7829-0\u00b7847]; external validation in European population with 2411 patients from one hospital, AUROC=0\u00b7833 [0\u00b7812-0\u00b7853]; temporal validation with 4311 patients from one hospital, AUROC=0\u00b7884 [0\u00b7869-0\u00b7897]). In the external validation set (US population), the median AUROCs of bias evaluations covering eight subgroups were above 0\u00b781, and the overall SMR was 0\u00b799 (0\u00b796-1\u00b703). The top ten risk predictors were the minimum Glasgow Coma Scale score, total urine output, average respiratory rate, mechanical ventilation use, best state of activity, Charlson Comorbidity Index score, geriatric nutritional risk index, code status, age, and maximum blood urea nitrogen. A simplified model containing only the top 20 features (ELDER-ICU-20) had similar predictive performance to the full model. INTERPRETATION: The ELDER-ICU model reliably predicts the risk of in-hospital mortality using routinely collected clinical features. The predictions could inform clinicians about patients who are at elevated risk of deterioration. Prospective validation of this model in clinical practice and a process for continuous performance monitoring and model recalibration are needed. FUNDING: National Institutes of Health, National Natural Science Foundation of China, National Special Health Science Program, Health Science and Technology Plan of Zhejiang Province, Fundamental Research Funds for the Central Universities, Drug Clinical Evaluate Research of Chinese Pharmaceutical Association, and National Key R&D Program of China.",
      "authors": "Liu Xiaoli; Hu Pan; Yeung Wesley; Zhang Zhongheng; Ho Vanda; Liu Chao; Dumontier Clark; Thoral Patrick J; Mao Zhi; Cao Desen; Mark Roger G; Zhang Zhengbo; Feng Mengling; Li Deyu; Celi Leo Anthony",
      "year": "2023",
      "journal": "The Lancet. Digital health",
      "doi": "10.1016/S2589-7500(23)00128-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37599147/",
      "mesh_terms": "United States; Aged; Humans; Critical Illness; Frailty; Retrospective Studies; Intensive Care Units; Machine Learning",
      "keywords": "",
      "pub_types": "Multicenter Study; Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC12557411"
    },
    {
      "pmid": "39453630",
      "title": "Advancing AI Data Ethics in Nursing: Future Directions for Nursing Practice, Research, and Education.",
      "abstract": "The ethics of artificial intelligence (AI) are increasingly recognized due to concerns such as algorithmic bias, opacity, trust issues, data security, and fairness. Specifically, machine learning algorithms, central to AI technologies, are essential in striving for ethically sound systems that mimic human intelligence. These technologies rely heavily on data, which often remain obscured within complex systems and must be prioritized for ethical collection, processing, and usage. The significance of data ethics in achieving responsible AI was first highlighted in the broader context of health care and subsequently in nursing. This viewpoint explores the principles of data ethics, drawing on relevant frameworks and strategies identified through a formal literature review. These principles apply to real-world and synthetic data in AI and machine-learning contexts. Additionally, the data-centric AI paradigm is briefly examined, emphasizing its focus on data quality and the ethical development of AI solutions that integrate human-centered domain expertise. The ethical considerations specific to nursing are addressed, including 4 recommendations for future directions in nursing practice, research, and education and 2 hypothetical nurse-focused ethical case studies. The primary objectives are to position nurses to actively participate in AI and data ethics, thereby contributing to creating high-quality and relevant data for machine learning applications.",
      "authors": "Ball Dunlap Patricia A; Michalowski Martin",
      "year": "2024",
      "journal": "JMIR nursing",
      "doi": "10.2196/62678",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39453630/",
      "mesh_terms": "Artificial Intelligence; Humans; Education, Nursing; Forecasting; Ethics, Nursing; Nursing Research; Machine Learning",
      "keywords": "AI data ethics; artificial intelligence; data literacy; data-centric AI; health care AI; machine learning; nurses; nursing informatics; responsible AI",
      "pub_types": "Journal Article",
      "pmcid": "PMC11529373"
    },
    {
      "pmid": "33981989",
      "title": "Addressing Fairness, Bias, and Appropriate Use of Artificial Intelligence and Machine Learning in Global Health.",
      "abstract": "In Low- and Middle- Income Countries (LMICs), machine learning (ML) and artificial intelligence (AI) offer attractive solutions to address the shortage of health care resources and improve the capacity of the local health care infrastructure. However, AI and ML should also be used cautiously, due to potential issues of fairness and algorithmic bias that may arise if not applied properly. Furthermore, populations in LMICs can be particularly vulnerable to bias and fairness in AI algorithms, due to a lack of technical capacity, existing social bias against minority groups, and a lack of legal protections. In order to address the need for better guidance within the context of global health, we describe three basic criteria (Appropriateness, Fairness, and Bias) that can be used to help evaluate the use of machine learning and AI systems: 1) APPROPRIATENESS is the process of deciding how the algorithm should be used in the local context, and properly matching the machine learning model to the target population; 2) BIAS is a systematic tendency in a model to favor one demographic group vs another, which can be mitigated but can lead to unfairness; and 3) FAIRNESS involves examining the impact on various demographic groups and choosing one of several mathematical definitions of group fairness that will adequately satisfy the desired set of legal, cultural, and ethical requirements. Finally, we illustrate how these principles can be applied using a case study of machine learning applied to the diagnosis and screening of pulmonary disease in Pune, India. We hope that these methods and principles can help guide researchers and organizations working in global health who are considering the use of machine learning and artificial intelligence.",
      "authors": "Fletcher Richard Rib\u00f3n; Nakeshimana Audace; Olubeko Olusubomi",
      "year": "2020",
      "journal": "Frontiers in artificial intelligence",
      "doi": "10.3389/frai.2020.561802",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33981989/",
      "mesh_terms": "",
      "keywords": "appropriate use; artificial intelligence; bias; ethics; fairness; global health; machine learning; medicine",
      "pub_types": "Editorial",
      "pmcid": "PMC8107824"
    },
    {
      "pmid": "35130064",
      "title": "The Potential For Bias In Machine Learning And Opportunities For Health Insurers To Address It.",
      "abstract": "As the use of machine learning algorithms in health care continues to expand, there are growing concerns about equity, fairness, and bias in the ways in which machine learning models are developed and used in clinical and business decisions. We present a guide to the data ecosystem used by health insurers to highlight where bias can arise along machine learning pipelines. We suggest mechanisms for identifying and dealing with bias and discuss challenges and opportunities to increase fairness through analytics in the health insurance industry.",
      "authors": "Gervasi Stephanie S; Chen Irene Y; Smith-McLallen Aaron; Sontag David; Obermeyer Ziad; Vennera Michael; Chawla Ravi",
      "year": "2022",
      "journal": "Health affairs (Project Hope)",
      "doi": "10.1377/hlthaff.2021.01287",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35130064/",
      "mesh_terms": "Algorithms; Bias; Ecosystem; Humans; Insurance Carriers; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36578121",
      "title": "Implicit Bias and Machine Learning in Health Care.",
      "abstract": "",
      "authors": "Zaidi Danish; Miller Taylor",
      "year": "2023",
      "journal": "Southern medical journal",
      "doi": "10.14423/SMJ.0000000000001489",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36578121/",
      "mesh_terms": "Humans; Bias, Implicit; Attitude of Health Personnel; Curriculum; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35615443",
      "title": "Beyond bias and discrimination: redefining the AI ethics principle of fairness in healthcare machine-learning algorithms.",
      "abstract": "The increasing implementation of and reliance on machine-learning (ML) algorithms to perform tasks, deliver services and make decisions in health and healthcare have made the need for fairness in ML, and more specifically in healthcare ML algorithms (HMLA), a very important and urgent task. However, while the debate on fairness in the ethics of artificial intelligence (AI) and in HMLA has grown significantly over the last decade, the very concept of fairness as an ethical value has not yet been sufficiently explored. Our paper aims to fill this gap and address the AI ethics principle of fairness from a conceptual standpoint, drawing insights from accounts of fairness elaborated in moral philosophy and using them to conceptualise fairness as an ethical value and to redefine fairness in HMLA accordingly. To achieve our goal, following a first section aimed at clarifying the background, methodology and structure of the paper, in the second section, we provide an overview of the discussion of the AI ethics principle of fairness in HMLA and show that the concept of fairness underlying this debate is framed in purely distributive terms and overlaps with non-discrimination, which is defined in turn as the absence of biases. After showing that this framing is inadequate, in the third section, we pursue an ethical inquiry into the concept of fairness and argue that fairness ought to be conceived of as an ethical value. Following a clarification of the relationship between fairness and non-discrimination, we show that the two do not overlap and that fairness requires much more than just non-discrimination. Moreover, we highlight that fairness not only has a distributive but also a socio-relational dimension. Finally, we pinpoint the constitutive components of fairness. In doing so, we base our arguments on a renewed reflection on the concept of respect, which goes beyond the idea of equal respect to include respect for individual persons. In the fourth section, we analyse the implications of our conceptual redefinition of fairness as an ethical value in the discussion of fairness in HMLA. Here, we claim that fairness requires more than non-discrimination and the absence of biases as well as more than just distribution; it needs to ensure that HMLA respects persons both as persons and as particular individuals. Finally, in the fifth section, we sketch some broader implications and show how our inquiry can contribute to making HMLA and, more generally, AI promote the social good and a fairer society.",
      "authors": "Giovanola Benedetta; Tiribelli Simona",
      "year": "2023",
      "journal": "AI & society",
      "doi": "10.1007/s00146-022-01455-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35615443/",
      "mesh_terms": "",
      "keywords": "Bias; Discrimination; Ethics of algorithms; Fairness; Healthcare machine-learning algorithms; Respect",
      "pub_types": "Journal Article",
      "pmcid": "PMC9123626"
    },
    {
      "pmid": "35958671",
      "title": "Bias or biology? Importance of model interpretation in machine learning studies from electronic health records.",
      "abstract": "OBJECTIVE: The rate of diabetic complication progression varies across individuals and understanding factors that alter the rate of complication progression may uncover new clinical interventions for personalized diabetes management. MATERIALS AND METHODS: We explore how various machine learning (ML) models and types of electronic health records (EHRs) can predict fast versus slow onset of neuropathy, nephropathy, ocular disease, or cardiovascular disease using only patient data collected prior to diabetes diagnosis. RESULTS: We find that optimized random forest models performed best to accurately predict the diagnosis of a diabetic complication, with the most effective model distinguishing between fast versus slow nephropathy (AUROC\u2009=\u20090.75). Using all data sets combined allowed for the highest model predictive performance, and social history or laboratory alone were most predictive. SHapley Additive exPlanations (SHAP) model interpretation allowed for exploration of predictors of fast and slow complication diagnosis, including underlying biases present in the EHR. Patients in the fast group had more medical visits, incurring a potential informed decision bias. DISCUSSION: Our study is unique in the realm of ML studies as it leverages SHAP as a starting point to explore patient markers not routinely used in diabetes monitoring. A mix of both bias and biological processes is likely present in influencing a model's ability to distinguish between groups. CONCLUSION: Overall, model interpretation is a critical step in evaluating validity of a user-intended endpoint for a model when using EHR data, and predictors affected by bias and those driven by biologic processes should be equally recognized.",
      "authors": "Momenzadeh Amanda; Shamsa Ali; Meyer Jesse G",
      "year": "2022",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooac063",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35958671/",
      "mesh_terms": "",
      "keywords": "SHAP; bias in EHR; clinical model interpretation; diabetes mellitus complication prediction; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC9360778"
    },
    {
      "pmid": "35243993",
      "title": "Mitigating Racial Bias in Machine Learning.",
      "abstract": "When applied in the health sector, AI-based applications raise not only ethical but legal and safety concerns, where algorithms trained on data from majority populations can generate less accurate or reliable results for minorities and other disadvantaged groups.",
      "authors": "Kostick-Quenet Kristin M; Cohen I Glenn; Gerke Sara; Lo Bernard; Antaki James; Movahedi Faezah; Njah Hasna; Schoen Lauren; Estep Jerry E; Blumenthal-Barby J S",
      "year": "2022",
      "journal": "The Journal of law, medicine & ethics : a journal of the American Society of Law, Medicine & Ethics",
      "doi": "10.1017/jme.2022.13",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35243993/",
      "mesh_terms": "Artificial Intelligence; Humans; Machine Learning; Racism",
      "keywords": "Algorithmic Bias; Artificial Intelligence; Ethics; Machine Learning; Racial Bias",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC12140104"
    },
    {
      "pmid": "35049447",
      "title": "On Algorithmic Fairness in Medical Practice.",
      "abstract": "The application of machine-learning technologies to medical practice promises to enhance the capabilities of healthcare professionals in the assessment, diagnosis, and treatment, of medical conditions. However, there is growing concern that algorithmic bias may perpetuate or exacerbate existing health inequalities. Hence, it matters that we make precise the different respects in which algorithmic bias can arise in medicine, and also make clear the normative relevance of these different kinds of algorithmic bias for broader questions about justice and fairness in healthcare. In this paper, we provide the building blocks for an account of algorithmic bias and its normative relevance in medicine.",
      "authors": "Grote Thomas; Keeling Geoff",
      "year": "2022",
      "journal": "Cambridge quarterly of healthcare ethics : CQ : the international journal of healthcare ethics committees",
      "doi": "10.1017/S0963180121000839",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35049447/",
      "mesh_terms": "Data Collection; Delivery of Health Care; Humans; Machine Learning; Social Justice",
      "keywords": "algorithmic bias; discrimination; fairness; machine learning; medical practice",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "36706849",
      "title": "Evaluating and mitigating bias in machine learning models for cardiovascular disease prediction.",
      "abstract": "OBJECTIVE: The study aims to investigate whether machine learning-based predictive models for cardiovascular disease (CVD) risk assessment show equivalent performance across demographic groups (such as race and gender) and if bias mitigation methods can reduce any bias present in the models. This is important as systematic bias may be introduced when collecting and preprocessing health data, which could affect the performance of the models on certain demographic sub-cohorts. The study is to investigate this using electronic health records data and various machine learning models. METHODS: The study used large de-identified Electronic Health Records data from Vanderbilt University Medical Center. Machine learning (ML) algorithms including logistic regression, random forest, gradient-boosting trees, and long short-term memory were applied to build multiple predictive models. Model bias and fairness were evaluated using equal opportunity difference (EOD, 0 indicates fairness) and disparate impact (DI, 1 indicates fairness). In our study, we also evaluated the fairness of a non-ML baseline model, the American Heart Association (AHA) Pooled Cohort Risk Equations (PCEs). Moreover, we compared the performance of three different de-biasing methods: removing protected attributes (e.g., race and gender), resampling the imbalanced training dataset by sample size, and resampling by the proportion of people with CVD outcomes. RESULTS: The study cohort included 109,490 individuals (mean [SD] age 47.4 [14.7] years; 64.5% female; 86.3% White; 13.7% Black). The experimental results suggested that most ML models had smaller EOD and DI than PCEs. For ML models, the mean EOD ranged from -0.001 to 0.018 and the mean DI ranged from 1.037 to 1.094 across race groups. There was a larger EOD and DI across gender groups, with EOD ranging from 0.131 to 0.136 and DI ranging from 1.535 to 1.587. For debiasing methods, removing protected attributes didn't significantly reduced the bias for most ML models. Resampling by sample size also didn't consistently decrease bias. Resampling by case proportion reduced the EOD and DI for gender groups but slightly reduced accuracy in many cases. CONCLUSIONS: Among the VUMC cohort, both PCEs and ML models were biased against women, suggesting the need to investigate and correct gender disparities in CVD risk prediction. Resampling by proportion reduced the bias for gender groups but not for race groups.",
      "authors": "Li Fuchen; Wu Patrick; Ong Henry H; Peterson Josh F; Wei Wei-Qi; Zhao Juan",
      "year": "2023",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2023.104294",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36706849/",
      "mesh_terms": "Humans; Female; Middle Aged; Male; Cardiovascular Diseases; Machine Learning; Algorithms; Random Forest; Logistic Models",
      "keywords": "Bias mitigation; Cardiovascular diseases; Clinical predictive models; Electronic health records; Fairness; Machine learning",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11104322"
    },
    {
      "pmid": "36060496",
      "title": "Enabling Fairness in Healthcare Through Machine Learning.",
      "abstract": "The use of machine learning systems for decision-support in healthcare may exacerbate health inequalities. However, recent work suggests that algorithms trained on sufficiently diverse datasets could in principle combat health inequalities. One concern about these algorithms is that their performance for patients in traditionally disadvantaged groups exceeds their performance for patients in traditionally advantaged groups. This renders the algorithmic decisions unfair relative to the standard fairness metrics in machine learning. In this paper, we defend the permissible use of affirmative algorithms; that is, algorithms trained on diverse datasets that perform better for traditionally disadvantaged groups. Whilst such algorithmic decisions may be unfair, the fairness of algorithmic decisions is not the appropriate locus of moral evaluation. What matters is the fairness of final decisions, such as diagnoses, resulting from collaboration between clinicians and algorithms. We argue that affirmative algorithms can permissibly be deployed provided the resultant final decisions are fair.",
      "authors": "Grote Thomas; Keeling Geoff",
      "year": "2022",
      "journal": "Ethics and information technology",
      "doi": "10.1007/s10676-022-09658-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36060496/",
      "mesh_terms": "",
      "keywords": "Bias; Decision-making; Fairness; Healthcare; Machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC9428374"
    },
    {
      "pmid": "40620096",
      "title": "A practical guide for nephrologist peer reviewers: evaluating artificial intelligence and machine learning research in nephrology.",
      "abstract": "Artificial intelligence (AI) and machine learning (ML) are transforming nephrology by enhancing diagnosis, risk prediction, and treatment optimization for conditions such as acute kidney injury (AKI) and chronic kidney disease (CKD). AI-driven models utilize diverse datasets-including electronic health records, imaging, and biomarkers-to improve clinical decision-making. Applications such as convolutional neural networks for kidney biopsy interpretation, and predictive modeling for renal replacement therapies underscore AI's potential. Nonetheless, challenges including data quality, limited external validation, algorithmic bias, and poor interpretability constrain the clinical reliability of AI/ML models. To address these issues, this article offers a structured framework for nephrologist peer reviewers, integrating the TRIPOD-AI (Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis-AI Extension) checklist. Key evaluation criteria include dataset integrity, feature selection, model validation, reporting transparency, ethics, and real-world applicability. This framework promotes rigorous peer review and enhances the reproducibility, clinical relevance, and fairness of AI research in nephrology. Moreover, AI/ML studies must confront biases-data, selection, and algorithmic-that adversely affect model performance. Mitigation strategies such as data diversification, multi-center validation, and fairness-aware algorithms are essential. Overfitting in AI is driven by small patient cohorts faced with thousands of candidate features; our framework spotlights this imbalance and offers concrete remedies. Future directions in AI-driven nephrology include multimodal data fusion for improved predictive modeling, deep learning for automated imaging analysis, wearable-based monitoring, and clinical decision support systems (CDSS) that integrate comprehensive patient data. A visual summary of key manuscript sections is included.",
      "authors": "Wang Yanni; Cheungpasitporn Wisit; Ali Hatem; Qing Jianbo; Thongprayoon Charat; Kaewput Wisit; Soliman Karim M; Huang Zhengxing; Yang Min; Zhang Zhongheng",
      "year": "2025",
      "journal": "Renal failure",
      "doi": "10.1080/0886022X.2025.2513002",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40620096/",
      "mesh_terms": "Humans; Acute Kidney Injury; Artificial Intelligence; Machine Learning; Nephrologists; Nephrology; Peer Review, Research; Renal Insufficiency, Chronic; Reproducibility of Results",
      "keywords": "Artificial intelligence; kidney diseases; machine learning; nephrology; peer review; personalized treatment",
      "pub_types": "Editorial",
      "pmcid": "PMC12239107"
    },
    {
      "pmid": "39116187",
      "title": "Targeting Machine Learning and Artificial Intelligence Algorithms in Health Care to Reduce Bias and Improve Population Health.",
      "abstract": "Policy Points Artificial intelligence (AI) is disruptively innovating health care and surpassing our ability to define its boundaries and roles in health care and regulate its application in legal and ethical ways. Significant progress has been made in governance in the United States and the European Union. It is incumbent on developers, end users, the public, providers, health care systems, and policymakers to collaboratively ensure that we adopt a national AI health strategy that realizes the Quintuple Aim; minimizes race-based medicine; prioritizes transparency, equity, and algorithmic vigilance; and integrates the patient and community voices throughout all aspects of AI development and deployment.",
      "authors": "Hurd Thelma C; Cobb Payton Fay; Hood Darryl B",
      "year": "2024",
      "journal": "The Milbank quarterly",
      "doi": "10.1111/1468-0009.12712",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39116187/",
      "mesh_terms": "Humans; Artificial Intelligence; Machine Learning; Population Health; United States; Delivery of Health Care; Algorithms; Bias",
      "keywords": "algorithmic bias; artificial intelligence; ethics; machine learning; minority health",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, Non-P.H.S.; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11576591"
    },
    {
      "pmid": "39049285",
      "title": "Fairness in Classifying and Grouping Health Equity Information.",
      "abstract": "This paper explores the balance between fairness and performance in machine learning classification, predicting the likelihood of a patient receiving anti-microbial treatment using structured data in community nursing wound care electronic health records. The data includes two important predictors (gender and language) of the social determinants of health, which we used to evaluate the fairness of the classifiers. At the same time, the impact of various groupings of language codes on classifiers' performance and fairness is analyzed. Most common statistical learning-based classifiers are evaluated. The findings indicate that while K-Nearest Neighbors offers the best fairness metrics among different grouping settings, the performance of all classifiers is generally consistent across different language code groupings. Also, grouping more variables tends to improve the fairness metrics over all classifiers while maintaining their performance.",
      "authors": "Jin Ruinan; Li Xiaoxiao; Block Lorraine J; Beschastnikh Ivan; Currie Leanne M; Ronquillo Charlene E",
      "year": "2024",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI240171",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39049285/",
      "mesh_terms": "Health Equity; Electronic Health Records; Machine Learning; Humans; Social Determinants of Health",
      "keywords": "Electronic Health Record; Fairness and Bias; Feature Engineering",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40775971",
      "title": "AI Bias and Confounding Risk in Health Feature Engineering for Machine Learning Classification Task.",
      "abstract": "Recent advancements in machine learning bring unique opportunities in health fields but also pose considerable challenges. Due to stringent ethical considerations and resource constraints, health data can vary in scope, population coverage, and collection granularity, prone to different AI bias and confounding risks in the performance of a classification task. This experimental study explored the impact on hidden confounding risk of model performance in a cardiovascular readmission prediction task using real-life health data from 'Data-derived Risk assessment using the Electronic medical record through Application of Machine Learning' (DREAM). Five commonly used machine learning models-k-nearest neighbors (KNN), random forest (RF), decision tree (DT), Catboost and Xgboost-were selected for this task. Model performance was assessed via the area under the receiver operating characteristics curve (AUC) and F1 score, both before and after propensity score adjustment. Based on density plot comparison of the adjustment, the difference mainly contributed from patients aged 20 and 40. High fluctuation on the model performance has been noted by including and excluding patients under this age group. After reasoning, high-risk pregnant females may serve as a confounding factor in the original model generation. The pregnancy rate in the non-readmitted group is significantly higher than that in the readmitted group (x2 = 10.2, p < 0.001). However, pregnant status required additional information query from a different hospital system. Without carefully consideration of confounding risks, traditional pipeline may generate a less robotic classifier in the clinical setting. Incorporating propensity score matching could be a solution to randomise invisible confounding factors between the classes.",
      "authors": "Guo Ruihua; Ritchie Angus; Smith Ross; Lu Yang; Min Haeri; Poon Simon K",
      "year": "2025",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI250953",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40775971/",
      "mesh_terms": "Machine Learning; Humans; Electronic Health Records; Female; Risk Assessment; Bias; Adult; Patient Readmission; Cardiovascular Diseases; Pregnancy; Confounding Factors, Epidemiologic",
      "keywords": "AI bias; Classification; Confounding bias; Feature Engineering; Machine Learning; Quality Control; Readmission risk prediction",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37729839",
      "title": "Cardiometabolic risk estimation using exposome data and machine learning.",
      "abstract": "BACKGROUND: The human exposome encompasses all exposures that individuals encounter throughout their lifetime. It is now widely acknowledged that health outcomes are influenced not only by genetic factors but also by the interactions between these factors and various exposures. Consequently, the exposome has emerged as a significant contributor to the overall risk of developing major diseases, such as cardiovascular disease (CVD) and diabetes. Therefore, personalized early risk assessment based on exposome attributes might be a promising tool for identifying high-risk individuals and improving disease prevention. OBJECTIVE: Develop and evaluate a novel and fair machine learning (ML) model for CVD and type 2 diabetes (T2D) risk prediction based on a set of readily available exposome factors. We evaluated our model using internal and external validation groups from a multi-center cohort. To be considered fair, the model was required to demonstrate consistent performance across different sub-groups of the cohort. METHODS: From the UK Biobank, we identified 5,348 and 1,534 participants who within 13 years from the baseline visit were diagnosed with CVD and T2D, respectively. An equal number of participants who did not develop these pathologies were randomly selected as the control group. 109 readily available exposure variables from six different categories (physical measures, environmental, lifestyle, mental health events, sociodemographics, and early-life factors) from the participant's baseline visit were considered. We adopted the XGBoost ensemble model to predict individuals at risk of developing the diseases. The model's performance was compared to that of an integrative ML model which is based on a set of biological, clinical, physical, and sociodemographic variables, and, additionally for CVD, to the Framingham risk score. Moreover, we assessed the proposed model for potential bias related to sex, ethnicity, and age. Lastly, we interpreted the model's results using SHAP, a state-of-the-art explainability method. RESULTS: The proposed ML model presents a comparable performance to the integrative ML model despite using solely exposome information, achieving a ROC-AUC of 0.78\u00b10.01 and 0.77\u00b10.01 for CVD and T2D, respectively. Additionally, for CVD risk prediction, the exposome-based model presents an improved performance over the traditional Framingham risk score. No bias in terms of key sensitive variables was identified. CONCLUSIONS: We identified exposome factors that play an important role in identifying patients at risk of CVD and T2D, such as naps during the day, age completed full-time education, past tobacco smoking, frequency of tiredness/unenthusiasm, and current work status. Overall, this work demonstrates the potential of exposome-based machine learning as a fair CVD and T2D risk assessment tool.",
      "authors": "Atehort\u00faa Ang\u00e9lica; Gkontra Polyxeni; Camacho Marina; Diaz Oliver; Bulgheroni Maria; Simonetti Valentina; Chadeau-Hyam Marc; Felix Janine F; Sebert Sylvain; Lekadir Karim",
      "year": "2023",
      "journal": "International journal of medical informatics",
      "doi": "10.1016/j.ijmedinf.2023.105209",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37729839/",
      "mesh_terms": "Humans; Exposome; Diabetes Mellitus, Type 2; Risk Factors; Cardiovascular Diseases; Machine Learning",
      "keywords": "Cardiovascular disease; Explainability; Exposure data; Fairness; Type 2 diabetes; XGBoost",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37921762",
      "title": "Fairness of Machine Learning Algorithms for Predicting Foregone Preventive Dental Care for Adults.",
      "abstract": "IMPORTANCE: Access to routine dental care prevents advanced dental disease and improves oral and overall health. Identifying individuals at risk of foregoing preventive dental care can direct prevention efforts toward high-risk populations. OBJECTIVE: To predict foregone preventive dental care among adults overall and in sociodemographic subgroups and to assess the algorithmic fairness. DESIGN, SETTING, AND PARTICIPANTS: This prognostic study was a secondary analyses of longitudinal data from the US Medical Expenditure Panel Survey (MEPS) from 2016 to 2019, each with 2 years of follow-up. Participants included adults aged 18 years and older. Data analysis was performed from December 2022 to June 2023. EXPOSURE: A total of 50 predictors, including demographic and socioeconomic characteristics, health conditions, behaviors, and health services use, were assessed. MAIN OUTCOMES AND MEASURES: The outcome of interest was foregoing preventive dental care, defined as either cleaning, general examination, or an appointment with the dental hygienist, in the past year. RESULTS: Among 32\u202f234 participants, the mean (SD) age was 48.5 (18.2) years and 17\u202f386 participants (53.9%) were female; 1935 participants (6.0%) were Asian, 5138 participants (15.9%) were Black, 7681 participants (23.8%) were Hispanic, 16\u202f503 participants (51.2%) were White, and 977 participants (3.0%) identified as other (eg, American Indian and Alaska Native) or multiple racial or ethnic groups. There were 21\u202f083 (65.4%) individuals who missed preventive dental care in the past year. The algorithms demonstrated high performance, achieving an area under the receiver operating characteristic curve (AUC) of 0.84 (95% CI, 0.84-0.85) in the overall population. While the full sample model performed similarly when applied to White individuals and older adults (AUC, 0.88; 95% CI, 0.87-0.90), there was a loss of performance for other subgroups. Removing the subgroup-sensitive predictors (ie, race and ethnicity, age, and income) did not impact model performance. Models stratified by race and ethnicity performed similarly or worse than the full model for all groups, with the lowest performance for individuals who identified as other or multiple racial groups (AUC, 0.76; 95% CI, 0.70-0.81). Previous pattern of dental visits, health care utilization, dental benefits, and sociodemographic characteristics were the highest contributing predictors to the models' performance. CONCLUSIONS AND RELEVANCE: Findings of this prognostic study using cohort data suggest that tree-based ensemble machine learning models could accurately predict adults at risk of foregoing preventive dental care and demonstrated bias against underrepresented sociodemographic groups. These results highlight the importance of evaluating model fairness during development and testing to avoid exacerbating existing biases.",
      "authors": "Schuch Helena Silveira; Furtado Mariane; Silva Gabriel Ferreira Dos Santos; Kawachi Ichiro; Chiavegatto Filho Alexandre D P; Elani Hawazin W",
      "year": "2023",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2023.41625",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37921762/",
      "mesh_terms": "Humans; Aged; Ethnicity; Racial Groups; Algorithms; Machine Learning; Dental Care",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10625037"
    },
    {
      "pmid": "36714611",
      "title": "Fairness in the prediction of acute postoperative pain using machine learning models.",
      "abstract": "INTRODUCTION: Overall performance of machine learning-based prediction models is promising; however, their generalizability and fairness must be vigorously investigated to ensure they perform sufficiently well for all patients. OBJECTIVE: This study aimed to evaluate prediction bias in machine learning models used for predicting acute postoperative pain. METHOD: We conducted a retrospective review of electronic health records for patients undergoing orthopedic surgery from June 1, 2011, to June 30, 2019, at the University of Florida Health system/Shands Hospital. CatBoost machine learning models were trained for predicting the binary outcome of low (\u22644) and high pain (>4). Model biases were assessed against seven protected attributes of age, sex, race, area deprivation index (ADI), speaking language, health literacy, and insurance type. Reweighing of protected attributes was investigated for reducing model bias compared with base models. Fairness metrics of equal opportunity, predictive parity, predictive equality, statistical parity, and overall accuracy equality were examined. RESULTS: The final dataset included 14,263 patients [age: 60.72 (16.03) years, 53.87% female, 39.13% low acute postoperative pain]. The machine learning model (area under the curve, 0.71) was biased in terms of age, race, ADI, and insurance type, but not in terms of sex, language, and health literacy. Despite promising overall performance in predicting acute postoperative pain, machine learning-based prediction models may be biased with respect to protected attributes. CONCLUSION: These findings show the need to evaluate fairness in machine learning models involved in perioperative pain before they are implemented as clinical decision support tools.",
      "authors": "Davoudi Anis; Sajdeya Ruba; Ison Ron; Hagen Jennifer; Rashidi Parisa; Price Catherine C; Tighe Patrick J",
      "year": "2022",
      "journal": "Frontiers in digital health",
      "doi": "10.3389/fdgth.2022.970281",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36714611/",
      "mesh_terms": "",
      "keywords": "algorithmic bias; clinical decision support systems; machine learing; orthopedic procedures; postoperative pain",
      "pub_types": "Journal Article",
      "pmcid": "PMC9874861"
    },
    {
      "pmid": "39163597",
      "title": "Mitigating Sociodemographic Bias in Opioid Use Disorder Prediction: Fairness-Aware Machine Learning Framework.",
      "abstract": "BACKGROUND: Opioid use disorder (OUD) is a critical public health crisis in the United States, affecting >5.5 million Americans in 2021. Machine learning has been used to predict patient risk of incident OUD. However, little is known about the fairness and bias of these predictive models. OBJECTIVE: The aims of this study are two-fold: (1) to develop a machine learning bias mitigation algorithm for sociodemographic features and (2) to develop a fairness-aware weighted majority voting (WMV) classifier for OUD prediction. METHODS: We used the 2020 National Survey on Drug and Health data to develop a neural network (NN) model using stochastic gradient descent (SGD; NN-SGD) and an NN model using Adam (NN-Adam) optimizers and evaluated sociodemographic bias by comparing the area under the curve values. A bias mitigation algorithm, based on equality of odds, was implemented to minimize disparities in specificity and recall. Finally, a WMV classifier was developed for fairness-aware prediction of OUD. To further analyze bias detection and mitigation, we did a 1-N matching of OUD to non-OUD cases, controlling for socioeconomic variables, and evaluated the performance of the proposed bias mitigation algorithm and WMV classifier. RESULTS: Our bias mitigation algorithm substantially reduced bias with NN-SGD, by 21.66% for sex, 1.48% for race, and 21.04% for income, and with NN-Adam by 16.96% for sex, 8.87% for marital status, 8.45% for working condition, and 41.62% for race. The fairness-aware WMV classifier achieved a recall of 85.37% and 92.68% and an accuracy of 58.85% and 90.21% using NN-SGD and NN-Adam, respectively. The results after matching also indicated remarkable bias reduction with NN-SGD and NN-Adam, respectively, as follows: sex (0.14% vs 0.97%), marital status (12.95% vs 10.33%), working condition (14.79% vs 15.33%), race (60.13% vs 41.71%), and income (0.35% vs 2.21%). Moreover, the fairness-aware WMV classifier achieved high performance with a recall of 100% and 85.37% and an accuracy of 73.20% and 89.38% using NN-SGD and NN-Adam, respectively. CONCLUSIONS: The application of the proposed bias mitigation algorithm shows promise in reducing sociodemographic bias, with the WMV classifier confirming bias reduction and high performance in OUD prediction.",
      "authors": "Yaseliani Mohammad; Noor-E-Alam Md; Hasan Md Mahmudul",
      "year": "2024",
      "journal": "JMIR AI",
      "doi": "10.2196/55820",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39163597/",
      "mesh_terms": "",
      "keywords": "bias mitigation; fairness and bias; machine learning; majority voting; opioid use disorder",
      "pub_types": "Journal Article",
      "pmcid": "PMC11372321"
    },
    {
      "pmid": "39119589",
      "title": "Deconstructing demographic bias in speech-based machine learning models for digital health.",
      "abstract": "INTRODUCTION: Machine learning (ML) algorithms have been heralded as promising solutions to the realization of assistive systems in digital healthcare, due to their ability to detect fine-grain patterns that are not easily perceived by humans. Yet, ML algorithms have also been critiqued for treating individuals differently based on their demography, thus propagating existing disparities. This paper explores gender and race bias in speech-based ML algorithms that detect behavioral and mental health outcomes. METHODS: This paper examines potential sources of bias in the data used to train the ML, encompassing acoustic features extracted from speech signals and associated labels, as well as in the ML decisions. The paper further examines approaches to reduce existing bias via using the features that are the least informative of one's demographic information as the ML input, and transforming the feature space in an adversarial manner to diminish the evidence of the demographic information while retaining information about the focal behavioral and mental health state. RESULTS: Results are presented in two domains, the first pertaining to gender and race bias when estimating levels of anxiety, and the second pertaining to gender bias in detecting depression. Findings indicate the presence of statistically significant differences in both acoustic features and labels among demographic groups, as well as differential ML performance among groups. The statistically significant differences present in the label space are partially preserved in the ML decisions. Although variations in ML performance across demographic groups were noted, results are mixed regarding the models' ability to accurately estimate healthcare outcomes for the sensitive groups. DISCUSSION: These findings underscore the necessity for careful and thoughtful design in developing ML models that are capable of maintaining crucial aspects of the data and perform effectively across all populations in digital healthcare applications.",
      "authors": "Yang Michael; El-Attar Abd-Allah; Chaspari Theodora",
      "year": "2024",
      "journal": "Frontiers in digital health",
      "doi": "10.3389/fdgth.2024.1351637",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39119589/",
      "mesh_terms": "",
      "keywords": "anxiety; demographic bias; depression; fairness; machine learning; speech",
      "pub_types": "Journal Article",
      "pmcid": "PMC11306200"
    },
    {
      "pmid": "37347528",
      "title": "Artificial Intelligence Bias in Health Care: Web-Based Survey.",
      "abstract": "BACKGROUND: Resources are increasingly spent on artificial intelligence (AI) solutions for medical applications aiming to improve diagnosis, treatment, and prevention of diseases. While the need for transparency and reduction of bias in data and algorithm development has been addressed in past studies, little is known about the knowledge and perception of bias among AI developers. OBJECTIVE: This study's objective was to survey AI specialists in health care to investigate developers' perceptions of bias in AI algorithms for health care applications and their awareness and use of preventative measures. METHODS: A web-based survey was provided in both German and English language, comprising a maximum of 41 questions using branching logic within the REDCap web application. Only the results of participants with experience in the field of medical AI applications and complete questionnaires were included for analysis. Demographic data, technical expertise, and perceptions of fairness, as well as knowledge of biases in AI, were analyzed, and variations among gender, age, and work environment were assessed. RESULTS: A total of 151 AI specialists completed the web-based survey. The median age was 30 (IQR 26-39) years, and 67% (101/151) of respondents were male. One-third rated their AI development projects as fair (47/151, 31%) or moderately fair (51/151, 34%), 12% (18/151) reported their AI to be barely fair, and 1% (2/151) not fair at all. One participant identifying as diverse rated AI developments as barely fair, and among the 2 undefined gender participants, AI developments were rated as barely fair or moderately fair, respectively. Reasons for biases selected by respondents were lack of fair data (90/132, 68%), guidelines or recommendations (65/132, 49%), or knowledge (60/132, 45%). Half of the respondents worked with image data (83/151, 55%) from 1 center only (76/151, 50%), and 35% (53/151) worked with national data exclusively. CONCLUSIONS: This study shows that the perception of biases in AI overall is moderately fair. Gender minorities did not once rate their AI development as fair or very fair. Therefore, further studies need to focus on minorities and women and their perceptions of AI. The results highlight the need to strengthen knowledge about bias in AI and provide guidelines on preventing biases in AI health care applications.",
      "authors": "Vorisek Carina Nina; Stellmach Caroline; Mayer Paula Josephine; Klopfenstein Sophie Anne Ines; Bures Dominik Martin; Diehl Anke; Henningsen Maike; Ritter Kerstin; Thun Sylvia",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/41089",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37347528/",
      "mesh_terms": "Humans; Female; Male; Adult; Artificial Intelligence; Algorithms; Bias; Delivery of Health Care; Internet",
      "keywords": "AI; FAIR data; age; application; artificial intelligence; bias; clinical; deep learning; development; diagnosis; digital health; disease; gender; health care; machine learning; online; prevention; survey; treatment",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10337406"
    },
    {
      "pmid": "36942183",
      "title": "Racial Equity in Healthcare Machine Learning: Illustrating Bias in Models With Minimal Bias Mitigation.",
      "abstract": "Background and objective While the potential of\u00a0machine learning (ML) in healthcare to positively impact human health\u00a0continues to grow, the potential for inequity in these methods must be assessed. In this study, we aimed to evaluate the presence of racial bias when five of the most common ML algorithms are used to create models with minimal processing to reduce racial bias. Methods By utilizing a CDC public database, we constructed models for the prediction of healthcare access (binary variable). Using area under the curve (AUC) as our performance metric, we calculated race-specific performance comparisons for each ML algorithm. We bootstrapped our entire analysis 20 times to produce confidence intervals\u00a0for our AUC performance metrics. Results With the exception of only a few cases, we found that the performance for the White group was, in general, significantly higher than that of the other racial groups across all ML algorithms. Additionally, we found that the most accurate algorithm in our modeling was Extreme Gradient Boosting (XGBoost) followed by random forest, naive Bayes, support vector machine (SVM), and k-nearest neighbors (KNN). Conclusion Our study illustrates the predictive perils of incorporating minimal racial bias mitigation in ML models, resulting in predictive disparities by race. This is particularly concerning in the setting of evidence for limited bias mitigation in healthcare-related ML. There needs to be more conversation, research, and guidelines surrounding methods for racial bias assessment and mitigation in healthcare-related ML models, both those currently used and those in development.",
      "authors": "Barton Michael; Hamza Mahmoud; Guevel Borna",
      "year": "2023",
      "journal": "Cureus",
      "doi": "10.7759/cureus.35037",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36942183/",
      "mesh_terms": "",
      "keywords": "data science; health equity; healthcare technology; machine learning; racial bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC10023594"
    },
    {
      "pmid": "35652218",
      "title": "Artificial Intelligence and Machine Learning Technologies in Cancer Care: Addressing Disparities, Bias, and Data Diversity.",
      "abstract": "Artificial intelligence (AI) and machine learning (ML) technologies have not only tremendous potential to augment clinical decision-making and enhance quality care and precision medicine efforts, but also the potential to worsen existing health disparities without a thoughtful, transparent, and inclusive approach that includes addressing bias in their design and implementation along the cancer discovery and care continuum. We discuss applications of AI/ML tools in cancer and provide recommendations for addressing and mitigating potential bias with AI and ML technologies while promoting cancer health equity.",
      "authors": "Dankwa-Mullan Irene; Weeraratne Dilhan",
      "year": "2022",
      "journal": "Cancer discovery",
      "doi": "10.1158/2159-8290.CD-22-0373",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35652218/",
      "mesh_terms": "Artificial Intelligence; Humans; Machine Learning; Neoplasms; Precision Medicine",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9662931"
    },
    {
      "pmid": "39850650",
      "title": "Bioethics Principles in Machine Learning-Healthcare Application Design: Achieving Health Justice and Health Equity.",
      "abstract": "Health technologies featuring artificial intelligence (AI) are becoming more common. Some healthcare AIs are exhibiting bias towards underrepresented persons and populations. Although many computer scientists and healthcare professionals agree that eliminating or mitigating bias in healthcare AIs is needed, little information exists regarding how to operationalize bioethics principles like autonomy in product design and implementation. This short course is framed with a Social Determinants of Health lens and a health justice and health equity stance to support computer scientists and healthcare professionals in building and deploying ethical healthcare AI. In this short course we introduce the bioethics principle of autonomy in the context of human-centered design (Module 1) and share options for design thinking models, suggesting four activities to embed ethics principles during design (Module 2). We then discuss the importance of gaining the perspectives of diverse groups to minimize harm and support the fundamental human values of underrepresented persons in support of health equity and health justice ideals (Module 3).",
      "authors": "Fritz Roschelle L; Nguyen-Truong Connie Kim Yen; May Thomas; Wuestney Katherine; Cook Diane J",
      "year": "2024",
      "journal": "Harvard public health review (Cambridge, Mass.)",
      "doi": "10.54111/0001/aaaa1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39850650/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11756589"
    },
    {
      "pmid": "38260285",
      "title": "Evaluating and Improving the Performance and Racial Fairness of Algorithms for GFR Estimation.",
      "abstract": "Data-driven clinical prediction algorithms are used widely by clinicians. Understanding what factors can impact the performance and fairness of data-driven algorithms is an important step towards achieving equitable healthcare. To investigate the impact of modeling choices on the algorithmic performance and fairness, we make use of a case study to build a prediction algorithm for estimating glomerular filtration rate (GFR) based on the patient's electronic health record (EHR). We compare three distinct approaches for estimating GFR: CKD-EPI equations, epidemiological models, and EHR-based models. For epidemiological models and EHR-based models, four machine learning models of varying computational complexity (i.e., linear regression, support vector machine, random forest regression, and neural network) were compared. Performance metrics included root mean squared error (RMSE), median difference, and the proportion of GFR estimates within 30% of the measured GFR value (P30). Differential performance between non-African American and African American group was used to assess algorithmic fairness with respect to race. Our study showed that the variable race had a negligible effect on error, accuracy, and differential performance. Furthermore, including more relevant clinical features (e.g., common comorbidities of chronic kidney disease) and using more complex machine learning models, namely random forest regression, significantly lowered the estimation error of GFR. However, the difference in performance between African American and non-African American patients did not decrease, where the estimation error for African American patients remained consistently higher than non-African American patients, indicating that more objective patient characteristics should be discovered and included to improve algorithm performance.",
      "authors": "Zhang Linying; Richter Lauren R; Kim Tevin; Hripcsak George",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.01.07.24300943",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38260285/",
      "mesh_terms": "",
      "keywords": "algorithmic fairness; electronic health record; glomerular filtration rate; machine learning; predictive modeling",
      "pub_types": "Preprint; Journal Article",
      "pmcid": "PMC10802656"
    },
    {
      "pmid": "41351059",
      "title": "A fairness-aware machine learning framework for maternal health in Ghana: integrating explainability, bias mitigation, and causal inference for ethical AI deployment.",
      "abstract": "BACKGROUND: Antenatal care (ANC) uptake in Ghana remains inequitable, with socioeconomic and geographic disparities limiting progress toward universal maternal health coverage (SDG 3). We present a novel, fairness-aware machine learning framework for predicting antenatal care uptake among women in Ghana, integrating explainability, bias mitigation, and causal inference to support ethical artificial intelligence (AI) deployment in low- and middle-income countries. METHODS: Using the 2022 Ghana Demographic and Health Survey (n\u2009=\u20093,314 eligible women with a recent live birth), we applied multiple imputation by chained equations (m\u2009=\u200910), appropriate categorical encoding, and synthetic minority oversampling (SMOTE) within training folds. Four supervised models (logistic regression, random forest, XGBoost, support vector machine) underwent stratified 5\u2011fold nested cross\u2011validation with cost\u2011sensitive threshold optimization (selected probability threshold\u2009=\u20090.45). Explainability (SHAP), fairness auditing (AIF360; metrics: statistical parity difference, disparate impact, equal opportunity difference, average odds difference, theil index), preprocessing mitigation (reweighing), counterfactual explanations (DiCE), and cautious treatment effect estimation (causal forests within a double machine learning framework) were integrated. Performance metrics included accuracy, precision, recall, F1, ROC\u2011AUC, minority class PR\u2011AUC, balanced accuracy, calibration (Brier score), and decision curve net benefit. RESULTS: The optimized random forest model achieved the highest accuracy (0.68) and recall (0.84) in identifying women with inadequate ANC contacts. Calibration was strong, with a brier score of 0.158, a calibration slope of 0.97, and an intercept of \u2212\u20090.02. Fairness auditing revealed baseline disparities in model predictions across wealth, region, ethnicity, and religion, with a statistical parity difference for wealth status of 0.182 and a Disparate Impact of 1.62. Following reweighting, disparate impact improved into the fairness range (0.92; within the recommended 0.8\u20131.25 interval), and statistical parity difference reduced to \u2212\u20090.028. Counterfactual analysis indicated that education, wealth, media exposure, and health worker contacts were the most modifiable factors for improving ANC uptake. Exploratory causal inference using double machine learning suggested that improving wealth status and education could be associated with a 16% (Average Treatment Effect [ATE]\u2009=\u20090.163) and 14% (ATE\u2009=\u20090.142) increase, respectively, in the probability of adequate ANC, with greater effects observed among urban and educated subgroups. Adjusted odds ratio (AOR) analysis showed that women in the richest quintile were nearly twice as likely to receive adequate ANC (AOR\u2009=\u20091.91, 95% CI: 1.44\u20132.53; p\u2009<\u20090.001), while those in the poorest quintile had significantly lower odds (AOR\u2009=\u20090.58, 95% CI: 0.45\u20130.75; p\u2009<\u20090.001). Additional significant predictors included health insurance coverage (AOR\u2009=\u20091.74, 95% CI: 1.19\u20132.55), health worker contacts (AOR\u2009=\u20091.33, 95% CI: 1.11\u20131.58), and pregnancy intention (AOR\u2009=\u20091.54, 95% CI: 1.30\u20131.82). CONCLUSION: This integrated, fairness-aware machine learning framework suggest robust, equitable, and actionable prediction of ANC uptake among Ghanaian women. Key modifiable determinants include wealth, education, and healthcare access barriers. The framework offers a replicable, ethical blueprint for transparent and fair AI deployment in maternal health, supporting targeted interventions to advance universal access to quality care in Ghana. Policymakers and health managers can leverage these AI tools to identify high-risk women, monitor intervention impacts, and allocate resources more equitably, advancing progress toward universal access to quality maternal care in Ghana.",
      "authors": "Osborne Augustus; Usani Kobloobase",
      "year": "2025",
      "journal": "BioData mining",
      "doi": "10.1186/s13040-025-00505-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41351059/",
      "mesh_terms": "",
      "keywords": "Antenatal care; Causal forests; Counterfactuals; Explainable AI; Fairness; Ghana; Health equity; Machine learning; Maternal health",
      "pub_types": "Journal Article",
      "pmcid": "PMC12781815"
    },
    {
      "pmid": "39495385",
      "title": "Evaluating machine learning model bias and racial disparities in non-small cell lung cancer using SEER registry data.",
      "abstract": "BACKGROUND: Despite decades of pursuing health equity, racial and ethnic disparities persist in healthcare in America. For cancer specifically, one of the leading observed disparities is worse mortality among non-Hispanic Black patients compared to non-Hispanic White patients across the cancer care continuum. These real-world disparities are reflected in the data used to inform the decisions made to alleviate such inequities. Failing to account for inherently biased data underlying these observations could intensify racial cancer disparities and lead to misguided efforts that fail to appropriately address the real causes of health inequity. OBJECTIVE: Estimate the racial/ethnic bias of machine learning models in predicting two-year survival and surgery treatment recommendation for non-small cell lung cancer (NSCLC) patients. METHODS: A Cox survival model, and a LOGIT model as well as three other machine learning models for predicting surgery recommendation were trained using SEER data from NSCLC patients diagnosed from 2000-2018. Models were trained with a 70/30 train/test split (both including and excluding race/ethnicity) and evaluated using performance and fairness metrics. The effects of oversampling the training data were also evaluated. RESULTS: The survival models show disparate impact towards non-Hispanic Black patients regardless of whether race/ethnicity is used as a predictor. The models including race/ethnicity amplified the disparities observed in the data. The exclusion of race/ethnicity as a predictor in the survival and surgery recommendation models improved fairness metrics without degrading model performance. Stratified oversampling strategies reduced disparate impact while reducing the accuracy of the model. CONCLUSION: NSCLC disparities are complex and multifaceted. Yet, even when accounting for age and stage at diagnosis, non-Hispanic Black patients with NSCLC are less often recommended to have surgery than non-Hispanic White patients. Machine learning models amplified the racial/ethnic disparities across the cancer care continuum (which are reflected in the data used to make model decisions). Excluding race/ethnicity lowered the bias of the models but did not affect disparate impact. Developing analytical strategies to improve fairness would in turn improve the utility of machine learning approaches analyzing population-based cancer data.",
      "authors": "Trentz Cameron; Engelbart Jacklyn; Semprini Jason; Kahl Amanda; Anyimadu Eric; Buatti John; Casavant Thomas; Charlton Mary; Canahuate Guadalupe",
      "year": "2024",
      "journal": "Health care management science",
      "doi": "10.1007/s10729-024-09691-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39495385/",
      "mesh_terms": "Aged; Female; Humans; Male; Middle Aged; Bias; Black or African American; Carcinoma, Non-Small-Cell Lung; Ethnicity; Healthcare Disparities; Lung Neoplasms; Machine Learning; Proportional Hazards Models; Racial Groups; SEER Program; United States; White",
      "keywords": "Fairness in AI; Health disparities; Non-small cell lung cancer survival; Racial disparities",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39479339",
      "title": "Big data and AI for gender equality in health: bias is a big challenge.",
      "abstract": "Artificial intelligence and machine learning are rapidly evolving fields that have the potential to transform women's health by improving diagnostic accuracy, personalizing treatment plans, and building predictive models of disease progression leading to preventive care. Three categories of women's health issues are discussed where machine learning can facilitate accessible, affordable, personalized, and evidence-based healthcare. In this perspective, firstly the promise of big data and machine learning applications in the context of women's health is elaborated. Despite these promises, machine learning applications are not widely adapted in clinical care due to many issues including ethical concerns, patient privacy, informed consent, algorithmic biases, data quality and availability, and education and training of health care professionals. In the medical field, discrimination against women has a long history. Machine learning implicitly carries biases in the data. Thus, despite the fact that machine learning has the potential to improve some aspects of women's health, it can also reinforce sex and gender biases. Advanced machine learning tools blindly integrated without properly understanding and correcting for socio-cultural sex and gender biased practices and policies is therefore unlikely to result in sex and gender equality in health.",
      "authors": "Joshi Anagha",
      "year": "2024",
      "journal": "Frontiers in big data",
      "doi": "10.3389/fdata.2024.1436019",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39479339/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; bias; biomarkers; machine learning; sex and gender; women's health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11521869"
    },
    {
      "pmid": "38820189",
      "title": "Equity and AI governance at academic medical centers.",
      "abstract": "OBJECTIVES: To understand whether and how equity is considered in artificial intelligence/machine learning governance processes at academic medical centers. STUDY DESIGN: Qualitative analysis of interview data. METHODS: We created a database of academic medical centers from the full list of Association of American Medical Colleges hospital and health system members in 2022. Stratifying by census region and restricting to nonfederal and nonspecialty centers, we recruited chief medical informatics officers and similarly positioned individuals from academic medical centers across the country. We created and piloted a semistructured interview guide focused on (1) how academic medical centers govern artificial intelligence and prediction and (2) to what extent equity is considered in these processes. A total of 17 individuals representing 13 institutions across 4 census regions of the US were interviewed. RESULTS: A minority of participants reported considering inequity, racism, or bias in governance. Most participants conceptualized these issues as characteristics of a tool, using frameworks such as algorithmic bias or fairness. Fewer participants conceptualized equity beyond the technology itself and asked broader questions about its implications for patients. Disparities in health information technology resources across health systems were repeatedly identified as a threat to health equity. CONCLUSIONS: We found a lack of consistent equity consideration among academic medical centers as they develop their governance processes for predictive technologies despite considerable national attention to the ways these technologies can cause or reproduce inequities. Health systems and policy makers will need to specifically prioritize equity literacy among health system leadership, design oversight policies, and promote critical engagement with these tools and their implications to prevent the further entrenchment of inequities in digital health care.",
      "authors": "Nong Paige; Hamasha Reema; Platt Jodyn",
      "year": "2024",
      "journal": "The American journal of managed care",
      "doi": "10.37765/ajmc.2024.89555",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38820189/",
      "mesh_terms": "Academic Medical Centers; Humans; United States; Artificial Intelligence; Qualitative Research; Health Equity; Interviews as Topic; Racism",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": ""
    },
    {
      "pmid": "39126673",
      "title": "Predictive roles of cognitive biases in health anxiety: A machine learning approach.",
      "abstract": "Prior work suggests that cognitive biases may contribute to health anxiety. Yet there is little research investigating how biased attention, interpretation, and memory for health threats are collectively associated with health anxiety, as well as the relative importance of these cognitive processes in predicting health anxiety. This study aimed to build a prediction model for health anxiety with multiple cognitive biases as potential predictors and to identify the biased cognitive processes that best predict individual differences in health anxiety. A machine learning algorithm (elastic net) was performed to recognise the predictors of health anxiety, using various tasks of attention, interpretation, and memory measured across behavioural, self-reported, and computational modelling approaches. Participants were 196 university students with a range of health anxiety severity from mild to severe. The results showed that only the interpretation bias for illness and the attention bias towards symptoms significantly contributed to the prediction model of health anxiety, with both biases having positive weights and the former being the most important predictor. These findings underscore the central role of illness-related interpretation bias and suggest that combined cognitive bias modification may be a promising method for alleviating health anxiety.",
      "authors": "Shi Congrong; Du Xiayu; Chen Wenke; Ren Zhihong",
      "year": "2024",
      "journal": "Stress and health : journal of the International Society for the Investigation of Stress",
      "doi": "10.1002/smi.3463",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39126673/",
      "mesh_terms": "Humans; Machine Learning; Male; Female; Young Adult; Adult; Anxiety; Cognition; Adolescent; Attention",
      "keywords": "attention bias; health anxiety; interpretation bias; machine learning; memory bias",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38269933",
      "title": "Equitable Machine Learning for Hypoglycaemia Risk Management.",
      "abstract": "We developed a machine learning (ML) model for the detection of patients with high risk of hypoglycaemic events during their hospital stay to improve the detection and management of hypoglycaemia. Our model was trained on data from a regional local health care district in Australia. The model was found to have good predictive performance in the general case (AUC 0.837). We conducted subgroup analysis to ensure that the model performed in a way that did not disadvantage population subgroups, in this case based on gender or indigenous status. We found that our specific problem domain assisted us in reducing unwanted bias within the model, because it did not rely on practice patterns or subjective judgements for the outcome measure. With careful analysis for equity there is great potential for ML models to automate the detection of high-risk cohorts and automate mitigation strategies to reduce preventable errors.",
      "authors": "Rodriguez Jhordany; Padilla Daniel; Bruce Lenert; Thow Ben; Pradhan Malcolm",
      "year": "2024",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI231089",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38269933/",
      "mesh_terms": "Humans; Hypoglycemia; Hypoglycemic Agents; Australia; Machine Learning; Risk Management",
      "keywords": "AI; Machine learning; diabetes; emr; equity; fairness; hypoglycaemia",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33090117",
      "title": "A Racially Unbiased, Machine Learning Approach to Prediction of Mortality: Algorithm Development Study.",
      "abstract": "BACKGROUND: Racial disparities in health care are well documented in the United States. As machine learning methods become more common in health care settings, it is important to ensure that these methods do not contribute to racial disparities through biased predictions or differential accuracy across racial groups. OBJECTIVE: The goal of the research was to assess a machine learning algorithm intentionally developed to minimize bias in in-hospital mortality predictions between white and nonwhite patient groups. METHODS: Bias was minimized through preprocessing of algorithm training data. We performed a retrospective analysis of electronic health record data from patients admitted to the intensive care unit (ICU) at a large academic health center between 2001 and 2012, drawing data from the Medical Information Mart for Intensive Care-III database. Patients were included if they had at least 10 hours of available measurements after ICU admission, had at least one of every measurement used for model prediction, and had recorded race/ethnicity data. Bias was assessed through the equal opportunity difference. Model performance in terms of bias and accuracy was compared with the Modified Early Warning Score (MEWS), the Simplified Acute Physiology Score II (SAPS II), and the Acute Physiologic Assessment and Chronic Health Evaluation (APACHE). RESULTS: The machine learning algorithm was found to be more accurate than all comparators, with a higher sensitivity, specificity, and area under the receiver operating characteristic. The machine learning algorithm was found to be unbiased (equal opportunity difference 0.016, P=.20). APACHE was also found to be unbiased (equal opportunity difference 0.019, P=.11), while SAPS II and MEWS were found to have significant bias (equal opportunity difference 0.038, P=.006 and equal opportunity difference 0.074, P<.001, respectively). CONCLUSIONS: This study indicates there may be significant racial bias in commonly used severity scoring systems and that machine learning algorithms may reduce bias while improving on the accuracy of these methods.",
      "authors": "Allen Angier; Mataraso Samson; Siefkas Anna; Burdick Hoyt; Braden Gregory; Dellinger R Phillip; McCoy Andrea; Pellegrini Emily; Hoffman Jana; Green-Saxena Abigail; Barnes Gina; Calvert Jacob; Das Ritankar",
      "year": "2020",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/22400",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33090117/",
      "mesh_terms": "APACHE; Adult; Aged; Algorithms; Cohort Studies; Early Warning Score; Electronic Health Records; Female; Forecasting; Hospital Mortality; Humans; Machine Learning; Male; Middle Aged; Retrospective Studies; Simplified Acute Physiology Score",
      "keywords": "health disparities; machine learning; mortality; prediction; racial disparities",
      "pub_types": "Journal Article",
      "pmcid": "PMC7644374"
    },
    {
      "pmid": "38985468",
      "title": "Fairness in Predicting Cancer Mortality Across Racial Subgroups.",
      "abstract": "IMPORTANCE: Machine learning has potential to transform cancer care by helping clinicians prioritize patients for serious illness conversations. However, models need to be evaluated for unequal performance across racial groups (ie, racial bias) so that existing racial disparities are not exacerbated. OBJECTIVE: To evaluate whether racial bias exists in a predictive machine learning model that identifies 180-day cancer mortality risk among patients with solid malignant tumors. DESIGN, SETTING, AND PARTICIPANTS: In this cohort study, a machine learning model to predict cancer mortality for patients aged 21 years or older diagnosed with cancer between January 2016 and December 2021 was developed with a random forest algorithm using retrospective data from the Mount Sinai Health System cancer registry, Social Security Death Index, and electronic health records up to the date when databases were accessed for cohort extraction (February 2022). EXPOSURE: Race category. MAIN OUTCOMES AND MEASURES: The primary outcomes were model discriminatory performance (area under the receiver operating characteristic curve [AUROC], F1 score) among each race category (Asian, Black, Native American, White, and other or unknown) and fairness metrics (equal opportunity, equalized odds, and disparate impact) among each pairwise comparison of race categories. True-positive rate ratios represented equal opportunity; both true-positive and false-positive rate ratios, equalized odds; and the percentage of predictive positive rate ratios, disparate impact. All metrics were estimated as a proportion or ratio, with variability captured through 95% CIs. The prespecified criterion for the model's clinical use was a threshold of at least 80% for fairness metrics across different racial groups to ensure the model's prediction would not be biased against any specific race. RESULTS: The test validation dataset included 43\u202f274 patients with balanced demographics. Mean (SD) age was 64.09 (14.26) years, with 49.6% older than 65 years. A total of 53.3% were female; 9.5%, Asian; 18.9%, Black; 0.1%, Native American; 52.2%, White; and 19.2%, other or unknown race; 0.1% had missing race data. A total of 88.9% of patients were alive, and 11.1% were dead. The AUROCs, F1 scores, and fairness metrics maintained reasonable concordance among the racial subgroups: the AUROCs ranged from 0.75 (95% CI, 0.72-0.78) for Asian patients and 0.75 (95% CI, 0.73-0.77) for Black patients to 0.77 (95% CI, 0.75-0.79) for patients with other or unknown race; F1 scores, from 0.32 (95% CI, 0.32-0.33) for White patients to 0.40 (95% CI, 0.39-0.42) for Black patients; equal opportunity ratios, from 0.96 (95% CI, 0.95-0.98) for Black patients compared with White patients to 1.02 (95% CI, 1.00-1.04) for Black patients compared with patients with other or unknown race; equalized odds ratios, from 0.87 (95% CI, 0.85-0.92) for Black patients compared with White patients to 1.16 (1.10-1.21) for Black patients compared with patients with other or unknown race; and disparate impact ratios, from 0.86 (95% CI, 0.82-0.89) for Black patients compared with White patients to 1.17 (95% CI, 1.12-1.22) for Black patients compared with patients with other or unknown race. CONCLUSIONS AND RELEVANCE: In this cohort study, the lack of significant variation in performance or fairness metrics indicated an absence of racial bias, suggesting that the model fairly identified cancer mortality risk across racial groups. It remains essential to consistently review the model's application in clinical settings to ensure equitable patient care.",
      "authors": "Ganta Teja; Kia Arash; Parchure Prathamesh; Wang Min-Heng; Besculides Melanie; Mazumdar Madhu; Smith Cardinale B",
      "year": "2024",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2024.21290",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38985468/",
      "mesh_terms": "Humans; Neoplasms; Female; Male; Middle Aged; Aged; Machine Learning; Retrospective Studies; Adult; Racial Groups; Cohort Studies; Racism",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11238025"
    },
    {
      "pmid": "38478455",
      "title": "Harvard Glaucoma Fairness: A Retinal Nerve Disease Dataset for Fairness Learning and Fair Identity Normalization.",
      "abstract": "Fairness (also known as equity interchangeably) in machine learning is important for societal well-being, but limited public datasets hinder its progress. Currently, no dedicated public medical datasets with imaging data for fairness learning are available, though underrepresented groups suffer from more health issues. To address this gap, we introduce Harvard Glaucoma Fairness (Harvard-GF), a retinal nerve disease dataset including 3,300 subjects with both 2D and 3D imaging data and balanced racial groups for glaucoma detection. Glaucoma is the leading cause of irreversible blindness globally with Blacks having doubled glaucoma prevalence than other races. We also propose a fair identity normalization (FIN) approach to equalize the feature importance between different identity groups. Our FIN approach is compared with various state-of-the-art fairness learning methods with superior performance in the racial, gender, and ethnicity fairness tasks with 2D and 3D imaging data, demonstrating the utilities of our dataset Harvard-GF for fairness learning. To facilitate fairness comparisons between different models, we propose an equity-scaled performance measure, which can be flexibly used to compare all kinds of performance metrics in the context of fairness. The dataset and code are publicly accessible via https://ophai.hms.harvard.edu/datasets/harvard-gf3300/.",
      "authors": "Luo Yan; Tian Yu; Shi Min; Pasquale Louis R; Shen Lucy Q; Zebardast Nazlee; Elze Tobias; Wang Mengyu",
      "year": "2024",
      "journal": "IEEE transactions on medical imaging",
      "doi": "10.1109/TMI.2024.3377552",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38478455/",
      "mesh_terms": "Humans; Glaucoma; Machine Learning; Male; Databases, Factual; Female; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Middle Aged; Aged",
      "keywords": "",
      "pub_types": "Journal Article; Dataset; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11251413"
    },
    {
      "pmid": "38552451",
      "title": "Minimizing bias when using artificial intelligence in critical care medicine.",
      "abstract": "",
      "authors": "Ranard Benjamin L; Park Soojin; Jia Yugang; Zhang Yiye; Alwan Fatima; Celi Leo Anthony; Lusczek Elizabeth R",
      "year": "2024",
      "journal": "Journal of critical care",
      "doi": "10.1016/j.jcrc.2024.154796",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38552451/",
      "mesh_terms": "Humans; Artificial Intelligence; Critical Care; Bias",
      "keywords": "Artificial intelligence; Bias; Critical Care; Disparities; Fairness; Health equity; Machine learning",
      "pub_types": "Editorial",
      "pmcid": "PMC11139594"
    },
    {
      "pmid": "41039915",
      "title": "Getting Started on Artificial Intelligence in Health Care and Clinical Research: Includes Rigor Checklist for Authors and Reviewers.",
      "abstract": "Artificial intelligence (AI) is rapidly transforming biomedical research and health care, offering new paradigms for discovery, diagnosis, and decision-making. This article provides a roadmap for researchers, clinicians, and reviewers seeking to understand and apply AI with rigor and relevance. It begins with a historical anchor: the birth of AI in health care at the University of Pittsburgh in the 1970s, where the INTERNIST-1 system pioneered diagnostic reasoning through symbolic logic, a milestone that laid the foundation for today's intelligent systems. Structured into three tiers-foundations, core techniques, and applications-the article addresses the full spectrum of biomedical AI. It introduces foundational concepts such as data engineering and preprocessing, knowledge representation and reasoning, and symbolic AI, which together enable structured, interpretable intelligence. Core techniques including expert systems, machine learning, deep learning, and explainable AI are presented with clinical examples, highlighting their role in wound care, image analysis, and predictive modeling. The applications tier showcases natural language processing, non-machine learning computer vision, robotics and automation, and distributed AI/multi-agent systems, demonstrating how AI integrates into real-world workflows. Ethical considerations and bias mitigation strategies are addressed with emphasis on Institutional Review Board oversight and fairness frameworks. Crucially, the article emphasizes that successful AI adoption begins not with technology, but with people. It outlines a systematic approach to building a biomedical AI workforce from within, empowering clinicians, researchers, and staff to become AI-literate contributors and leaders. With rigor checklists, practical guidance, and a vision for human-AI collaboration, this article invites readers to move beyond hype and toward responsible, transformative innovation in health care and biomedical science. [Figure: see text].",
      "authors": "Sen Chandan K; DeMazumder Deeptankar",
      "year": "2025",
      "journal": "Advances in wound care",
      "doi": "10.1177/21621918251380217",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41039915/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; machine learning; smart care",
      "pub_types": "Editorial",
      "pmcid": ""
    },
    {
      "pmid": "38876453",
      "title": "Assessing fairness in machine learning models: A study of racial bias using matched counterparts in mortality prediction for patients with chronic diseases.",
      "abstract": "OBJECTIVE: Existing approaches to fairness evaluation often overlook systematic differences in the social determinants of health, like demographics and socioeconomics, among comparison groups, potentially leading to inaccurate or even contradictory conclusions. This study aims to evaluate racial disparities in predicting mortality among patients with chronic diseases using a fairness detection method that considers systematic differences. METHODS: We created five datasets from Mass General Brigham's electronic health records (EHR), each focusing on a different chronic condition: congestive heart failure (CHF), chronic kidney disease (CKD), chronic obstructive pulmonary disease (COPD), chronic liver disease (CLD), and dementia. For each dataset, we developed separate machine learning models to predict 1-year mortality and examined racial disparities by comparing prediction performances between Black and White individuals. We compared racial fairness evaluation between the overall Black and White individuals versus their counterparts who were Black and matched White individuals identified by propensity score matching, where the systematic differences were mitigated. RESULTS: We identified significant differences between Black and White individuals in age, gender, marital status, education level, smoking status, health insurance type, body mass index, and Charlson comorbidity index (p-value\u00a0<\u00a00.001). When examining matched Black and White subpopulations identified through propensity score matching, significant differences between particular covariates existed. We observed weaker significance levels in the CHF cohort for insurance type (p\u00a0=\u00a00.043), in the CKD cohort for insurance type (p\u00a0=\u00a00.005) and education level (p\u00a0=\u00a00.016), and in the dementia cohort for body mass index (p\u00a0=\u00a00.041); with no significant differences for other covariates. When examining mortality prediction models across the five study cohorts, we conducted a comparison of fairness evaluations before and after mitigating systematic differences. We revealed significant differences in the CHF cohort with p-values of 0.021 and 0.001 in terms of F1 measure and Sensitivity for the AdaBoost model, and p-values of 0.014 and 0.003 in terms of F1 measure and Sensitivity for the MLP model, respectively. DISCUSSION AND CONCLUSION: This study contributes to research on fairness assessment by focusing on the examination of systematic disparities and underscores the potential for revealing racial bias in machine learning models used in clinical settings.",
      "authors": "Wang Yifei; Wang Liqin; Zhou Zhengyang; Laurentiev John; Lakin Joshua R; Zhou Li; Hong Pengyu",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2024.104677",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38876453/",
      "mesh_terms": "Aged; Female; Humans; Male; Middle Aged; Black or African American; Chronic Disease; Electronic Health Records; Heart Failure; Machine Learning; Pulmonary Disease, Chronic Obstructive; Racism; White; Health Status Disparities",
      "keywords": "Chronic Disease; Electronic Health Records; Fairness Analysis; Machine Learning; Mortality Prediction; Racism",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11272432"
    },
    {
      "pmid": "34568771",
      "title": "Quantifying representativeness in randomized clinical trials using machine learning fairness metrics.",
      "abstract": "OBJECTIVE: We help identify subpopulations underrepresented in randomized clinical trials (RCTs) cohorts with respect to national, community-based or health system target populations by formulating population representativeness of RCTs as a machine learning (ML) fairness problem, deriving new representation metrics, and deploying them in easy-to-understand interactive visualization tools. MATERIALS AND METHODS: We represent RCT cohort enrollment as random binary classification fairness problems, and then show how ML fairness metrics based on enrollment fraction can be efficiently calculated using easily computed rates of subpopulations in RCT cohorts and target populations. We propose standardized versions of these metrics and deploy them in an interactive tool to analyze 3 RCTs with respect to type 2 diabetes and hypertension target populations in the National Health and Nutrition Examination Survey. RESULTS: We demonstrate how the proposed metrics and associated statistics enable users to rapidly examine representativeness of all subpopulations in the RCT defined by a set of categorical traits (eg, gender, race, ethnicity, smoking status, and blood pressure) with respect to target populations. DISCUSSION: The normalized metrics provide an intuitive standardized scale for evaluating representation across subgroups, which may have vastly different enrollment fractions and rates in RCT study cohorts. The metrics are beneficial complements to other approaches (eg, enrollment fractions) used to identify generalizability and health equity of RCTs. CONCLUSION: By quantifying the gaps between RCT and target populations, the proposed methods can support generalizability evaluation of existing RCT cohorts. The interactive visualization tool can be readily applied to identified underrepresented subgroups with respect to any desired source or target populations.",
      "authors": "Qi Miao; Cahan Owen; Foreman Morgan A; Gruen Daniel M; Das Amar K; Bennett Kristin P",
      "year": "2021",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooab077",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34568771/",
      "mesh_terms": "",
      "keywords": "health equity; machine learning; population representativeness; randomized clinical trials; subgroup",
      "pub_types": "Journal Article",
      "pmcid": "PMC8460438"
    },
    {
      "pmid": "38782170",
      "title": "Causal fairness assessment of treatment allocation with electronic health records.",
      "abstract": "OBJECTIVE: Healthcare continues to grapple with the persistent issue of treatment disparities, sparking concerns regarding the equitable allocation of treatments in clinical practice. While various fairness metrics have emerged to assess fairness in decision-making processes, a growing focus has been on causality-based fairness concepts due to their capacity to mitigate confounding effects and reason about bias. However, the application of causal fairness notions in evaluating the fairness of clinical decision-making with electronic health record (EHR) data remains an understudied domain. This study aims to address the methodological gap in assessing causal fairness of treatment allocation with electronic health records data. In addition, we investigate the impact of social determinants of health on the assessment of causal fairness of treatment allocation. METHODS: We propose a causal fairness algorithm to assess fairness in clinical decision-making. Our algorithm accounts for the heterogeneity of patient populations and identifies potential unfairness in treatment allocation by conditioning on patients who have the same likelihood to benefit from the treatment. We apply this framework to a patient cohort with coronary artery disease derived from an EHR database to evaluate the fairness of treatment decisions. RESULTS: Our analysis reveals notable disparities in coronary artery bypass grafting (CABG) allocation among different patient groups. Women were found to be 4.4%-7.7% less likely to receive CABG than men in two out of four treatment response strata. Similarly, Black or African American patients were 5.4%-8.7% less likely to receive CABG than others in three out of four response strata. These results were similar when social determinants of health (insurance and area deprivation index) were dropped from the algorithm. These findings highlight the presence of disparities in treatment allocation among similar patients, suggesting potential unfairness in the clinical decision-making process. CONCLUSION: This study introduces a novel approach for assessing the fairness of treatment allocation in healthcare. By incorporating responses to treatment into fairness framework, our method explores the potential of quantifying fairness from a causal perspective using EHR data. Our research advances the methodological development of fairness assessment in healthcare and highlight the importance of causality in determining treatment fairness.",
      "authors": "Zhang Linying; Richter Lauren R; Wang Yixin; Ostropolets Anna; Elhadad No\u00e9mie; Blei David M; Hripcsak George",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2024.104656",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38782170/",
      "mesh_terms": "Humans; Electronic Health Records; Algorithms; Male; Female; Clinical Decision-Making; Coronary Artery Disease; Healthcare Disparities; Middle Aged; Social Determinants of Health; Causality",
      "keywords": "Causal fairness; Electronic health record; Health equity; Machine learning; Principal fairness",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11180553"
    },
    {
      "pmid": "35396996",
      "title": "Assessing socioeconomic bias in machine learning algorithms in health care: a case study of the HOUSES index.",
      "abstract": "OBJECTIVE: Artificial intelligence (AI) models may propagate harmful biases in performance and hence negatively affect the underserved. We aimed to assess the degree to which data quality of electronic health records (EHRs) affected by inequities related to low socioeconomic status (SES), results in differential performance of AI models across SES. MATERIALS AND METHODS: This study utilized existing machine learning models for predicting asthma exacerbation in children with asthma. We compared balanced error rate (BER) against different SES levels measured by HOUsing-based SocioEconomic Status measure (HOUSES) index. As a possible mechanism for differential performance, we also compared incompleteness of EHR information relevant to asthma care by SES. RESULTS: Asthmatic children with lower SES had larger BER than those with higher SES (eg, ratio = 1.35 for HOUSES Q1 vs Q2-Q4) and had a higher proportion of missing information relevant to asthma care (eg, 41% vs 24% for missing asthma severity and 12% vs 9.8% for undiagnosed asthma despite meeting asthma criteria). DISCUSSION: Our study suggests that lower SES is associated with worse predictive model performance. It also highlights the potential role of incomplete EHR data in this differential performance and suggests a way to mitigate this bias. CONCLUSION: The HOUSES index allows AI researchers to assess bias in predictive model performance by SES. Although our case study was based on a small sample size and a single-site study, the study results highlight a potential strategy for identifying bias by using an innovative SES measure.",
      "authors": "Juhn Young J; Ryu Euijung; Wi Chung-Il; King Katherine S; Malik Momin; Romero-Brufau Santiago; Weng Chunhua; Sohn Sunghwan; Sharp Richard R; Halamka John D",
      "year": "2022",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocac052",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35396996/",
      "mesh_terms": "Artificial Intelligence; Asthma; Bias; Child; Delivery of Health Care; Humans; Machine Learning; Social Class",
      "keywords": "HOUSES; algorithmic bias; artificial intelligence; electronic health records; social determinants of health",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9196683"
    },
    {
      "pmid": "41292296",
      "title": "Real-world prediction of early-onset dementia by health record data: A multi-center machine learning study.",
      "abstract": "INTRODUCTION: We aimed to develop risk and prognostic prediction tools for early-onset dementia (EOD) using health record data shared across five major international cohorts. METHODS: More than 400,000 dementia-free individuals younger than age 65 at baseline were included. Ensemble learning was used to construct the models. Cumulative incidence and Kaplan-Meier curves were used to visualize risk stratification, and subgroup analyses were conducted to evaluate potential disparities. RESULTS: The CatBoost-based risk model achieved an area under the receiver-operating characteristic curve (AUROC) of 0.814 (<70 years) and 0.892 (<65 years). The Random Survival Forest (RF) prognostic model reached 5-year AUROC of 0.656. Key predictors included age, employment status, and education. DISCUSSION: Based on health record data, this study provides practical and scalable tools for EOD risk screening and prognosis prediction, with potential for implementation in community and primary care settings. HIGHLIGHTS: We developed risk and prognostic prediction models for early-onset dementia (EOD) using indicators shared across five international cohorts. Models showed good discrimination and calibration across internal and external sets, with key predictors including age and work status confirmed by shapley additive explanation (SHAP) analysis. Subgroup analyses supported fairness across sex, age, and comorbidity groups. Our study provides accessible and cost-effective yet effective tools for the screening, prevention, and prognostic prediction of EOD in large community populations and primary care settings.",
      "authors": "Rong Xuewen; Zhang Weijin; Luan Shanjie; Feng Du; Wang Ningning; Xiao Jingyu; He Junyi; Liu Jun; Shu Liming",
      "year": "2025",
      "journal": "Alzheimer's & dementia : the journal of the Alzheimer's Association",
      "doi": "10.1002/alz.70921",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41292296/",
      "mesh_terms": "Humans; Dementia; Male; Female; Machine Learning; Prognosis; Middle Aged; Age of Onset; Risk Assessment; Risk Factors; Aged; Cohort Studies; Incidence",
      "keywords": "CHARLS; HRS; KLoSA; SHARE; UK Biobank; early\u2010onset dementia; ensemble learning; multi\u2010center; prognosis prediction; real\u2010world; risk prediction; volunteer bias",
      "pub_types": "Journal Article; Multicenter Study",
      "pmcid": "PMC12647925"
    },
    {
      "pmid": "38100101",
      "title": "Guiding Principles to Address the Impact of Algorithm Bias on Racial and Ethnic Disparities in Health and Health Care.",
      "abstract": "IMPORTANCE: Health care algorithms are used for diagnosis, treatment, prognosis, risk stratification, and allocation of resources. Bias in the development and use of algorithms can lead to worse outcomes for racial and ethnic minoritized groups and other historically marginalized populations such as individuals with lower income. OBJECTIVE: To provide a conceptual framework and guiding principles for mitigating and preventing bias in health care algorithms to promote health and health care equity. EVIDENCE REVIEW: The Agency for Healthcare Research and Quality and the National Institute for Minority Health and Health Disparities convened a diverse panel of experts to review evidence, hear from stakeholders, and receive community feedback. FINDINGS: The panel developed a conceptual framework to apply guiding principles across an algorithm's life cycle, centering health and health care equity for patients and communities as the goal, within the wider context of structural racism and discrimination. Multiple stakeholders can mitigate and prevent bias at each phase of the algorithm life cycle, including problem formulation (phase 1); data selection, assessment, and management (phase 2); algorithm development, training, and validation (phase 3); deployment and integration of algorithms in intended settings (phase 4); and algorithm monitoring, maintenance, updating, or deimplementation (phase 5). Five principles should guide these efforts: (1) promote health and health care equity during all phases of the health care algorithm life cycle; (2) ensure health care algorithms and their use are transparent and explainable; (3) authentically engage patients and communities during all phases of the health care algorithm life cycle and earn trustworthiness; (4) explicitly identify health care algorithmic fairness issues and trade-offs; and (5) establish accountability for equity and fairness in outcomes from health care algorithms. CONCLUSIONS AND RELEVANCE: Multiple stakeholders must partner to create systems, processes, regulations, incentives, standards, and policies to mitigate and prevent algorithmic bias. Reforms should implement guiding principles that support promotion of health and health care equity in all phases of the algorithm life cycle as well as transparency and explainability, authentic community engagement and ethical partnerships, explicit identification of fairness issues and trade-offs, and accountability for equity and fairness.",
      "authors": "Chin Marshall H; Afsar-Manesh Nasim; Bierman Arlene S; Chang Christine; Col\u00f3n-Rodr\u00edguez Caleb J; Dullabh Prashila; Duran Deborah Guadalupe; Fair Malika; Hernandez-Boussard Tina; Hightower Maia; Jain Anjali; Jordan William B; Konya Stephen; Moore Roslyn Holliday; Moore Tamra Tyree; Rodriguez Richard; Shaheen Gauher; Snyder Lynne Page; Srinivasan Mithuna; Umscheid Craig A; Ohno-Machado Lucila",
      "year": "2023",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2023.45050",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38100101/",
      "mesh_terms": "United States; Humans; Health Promotion; Racial Groups; Academies and Institutes; Algorithms; Health Equity",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC11181958"
    },
    {
      "pmid": "38938093",
      "title": "Mitigating Racial Bias in Health Care Algorithms: Improving Fairness in Access to Supportive Housing.",
      "abstract": "Algorithms for guiding health care decisions have come under increasing scrutiny for being unfair to certain racial and ethnic groups. The authors describe their multistep process, using data from 3,465 individuals, to reduce racial and ethnic bias in an algorithm developed to identify state Medicaid beneficiaries experiencing homelessness and chronic health needs who were eligible for coordinated health care and housing supports. Through an iterative process of adjusting inputs, reviewing outputs with diverse stakeholders, and performing quality assurance, the authors developed an algorithm that achieved racial and ethnic parity in the selection of eligible Medicaid beneficiaries.",
      "authors": "Noam Krista R; Schmutte Timothy; Bory Christopher; Plant Robert W",
      "year": "2024",
      "journal": "Psychiatric services (Washington, D.C.)",
      "doi": "10.1176/appi.ps.20230359",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38938093/",
      "mesh_terms": "Humans; United States; Algorithms; Ill-Housed Persons; Medicaid; Racism; Health Services Accessibility; Healthcare Disparities; Housing",
      "keywords": "health equity; racial-ethnic disparities; research design and methodology; responsible AI",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37902833",
      "title": "Architectural Design of a Blockchain-Enabled, Federated Learning Platform for Algorithmic Fairness in Predictive Health Care: Design Science Study.",
      "abstract": "BACKGROUND: Developing effective and generalizable predictive models is critical for disease prediction and clinical decision-making, often requiring diverse samples to mitigate population bias and address algorithmic fairness. However, a major challenge is to retrieve learning models across multiple institutions without bringing in local biases and inequity, while preserving individual patients' privacy at each site. OBJECTIVE: This study aims to understand the issues of bias and fairness in the machine learning process used in the predictive health care domain. We proposed a software architecture that integrates federated learning and blockchain to improve fairness, while maintaining acceptable prediction accuracy and minimizing overhead costs. METHODS: We improved existing federated learning platforms by integrating blockchain through an iterative design approach. We used the design science research method, which involves 2 design cycles (federated learning for bias mitigation and decentralized architecture). The design involves a bias-mitigation process within the blockchain-empowered federated learning framework based on a novel architecture. Under this architecture, multiple medical institutions can jointly train predictive models using their privacy-protected data effectively and efficiently and ultimately achieve fairness in decision-making in the health care domain. RESULTS: We designed and implemented our solution using the Aplos smart contract, microservices, Rahasak blockchain, and Apache Cassandra-based distributed storage. By conducting 20,000 local model training iterations and 1000 federated model training iterations across 5 simulated medical centers as peers in the Rahasak blockchain network, we demonstrated how our solution with an improved fairness mechanism can enhance the accuracy of predictive diagnosis. CONCLUSIONS: Our study identified the technical challenges of prediction biases faced by existing predictive models in the health care domain. To overcome these challenges, we presented an innovative design solution using federated learning and blockchain, along with the adoption of a unique distributed architecture for a fairness-aware system. We have illustrated how this design can address privacy, security, prediction accuracy, and scalability challenges, ultimately improving fairness and equity in the predictive health care domain.",
      "authors": "Liang Xueping; Zhao Juan; Chen Yan; Bandara Eranga; Shetty Sachin",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/46547",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37902833/",
      "mesh_terms": "Humans; Blockchain; Hospitals; Awareness; Clinical Decision-Making; Machine Learning",
      "keywords": "bias; blockchain; fairness; federated learning; health care; implementation; privacy; proof of concept; software",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC10644196"
    },
    {
      "pmid": "37600144",
      "title": "Translating Intersectionality to Fair Machine Learning in Health Sciences.",
      "abstract": "Fairness approaches in machine learning should involve more than assessment of performance metrics across groups. Shifting the focus away from model metrics, we reframe fairness through the lens of intersectionality, a Black feminist theoretical framework that contextualizes individuals in interacting systems of power and oppression.",
      "authors": "Lett Elle; La Cava William G",
      "year": "2023",
      "journal": "Nature machine intelligence",
      "doi": "10.1038/s42256-023-00651-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37600144/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10437125"
    },
    {
      "pmid": "41354230",
      "title": "Development and validation of a novel machine learning-based algorithm to predict incident atrial fibrillation: A multicohort analysis.",
      "abstract": "BACKGROUND: Existing atrial fibrillation (AF) risk prediction models incorporate race as a covariate, systematically underestimating AF risk in black individuals and potentially perpetuating health care disparities. OBJECTIVE: This study aimed to develop and validate machine learning (ML)-based race-agnostic risk scores to predict AF risk and assess differences in risk stratification and bias compared with the CHARGE-AF score. METHODS: The derivation cohort included 16,719 participants free of AF at baseline (Atherosclerosis Risk in Communities visit 5, 2011-2013; Cardiovascular Health Study baseline, 1989-1990), and the validation cohort included 13,928 (Multi-Ethnic Study of Atherosclerosis and Framingham Offspring and Generation 3 studies). The primary outcome was the incidence of AF within 5 years. Model performance was assessed using concordance index, Brier score, and index of prediction accuracy. Bias was evaluated using disparate impact, equal opportunity difference, and Theil index. Population-attributable risk percentage was calculated across racial groups. RESULTS: During the 5-year follow-up, incident AF occurred in 507 participants (3.0%) in the derivation cohort and 262 (1.9%) in the validation cohort. The ML model demonstrated superior performance compared with CHARGE-AF, with better discrimination (concordance index 0.83 [95% confidence interval 0.80-0.85] vs 0.77 [95% confidence interval 0.74-0.79]; P < .001) and improved calibration (Brier score 1.82 vs 1.92; P < .001). Key predictors included age, clinical factors (electrocardiographic parameters, cardiac biomarkers, and blood pressure), and education level. Population-attributable risk analysis demonstrated marked racial differences in AF risk contribution from age (non-Hispanic black 14.3% vs white participants 34.6%). The ML model reduced algorithmic bias vs CHARGE-AF across all metrics. CONCLUSION: Race-agnostic ML models demonstrated superior predictive performance and reduced bias compared with CHARGE-AF, potentially improving clinical risk stratification while promoting health equity.",
      "authors": "Segar Matthew W; Keshvani Neil; Jaeger Byron; Rosenblatt Anna; Razavi Mehdi; Saeed Mohammad; Rodriguez Carlos J; Khan Sadiya S; Kao David; Pandey Ambarish",
      "year": "2025",
      "journal": "Heart rhythm",
      "doi": "10.1016/j.hrthm.2025.12.008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41354230/",
      "mesh_terms": "",
      "keywords": "Algorithmic bias; Atrial fibrillation; Machine learning; Race; Risk prediction",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40435158",
      "title": "Is there a competitive advantage to using multivariate statistical or machine learning methods over the Bross formula in the hdPS framework for bias and variance estimation?",
      "abstract": "PURPOSE: We aim to evaluate various proxy selection methods within the context of high-dimensional propensity score (hdPS) analysis. This study aimed to systematically evaluate and compare the performance of traditional statistical methods and machine learning approaches within the hdPS framework, focusing on key metrics such as bias, standard error (SE), and coverage, under various exposure and outcome prevalence scenarios. METHODS: We conducted a plasmode simulation study using data from the National Health and Nutrition Examination Survey (NHANES) cycles from 2013 to 2018. We compared methods including the kitchen sink model, Bross-based hdPS, Hybrid hdPS, LASSO, Elastic Net, Random Forest, XGBoost, and Genetic Algorithm (GA). The performance of each inverse probability weighted method was assessed based on bias, MSE, coverage probability, and SE estimation across three epidemiological scenarios: frequent exposure and outcome, rare exposure and frequent outcome, and frequent exposure and rare outcome. RESULTS: XGBoost consistently demonstrated strong performance in terms of MSE and coverage, making it effective for scenarios prioritizing precision. However, it exhibited higher bias, particularly in rare exposure scenarios, suggesting it is less suited when minimizing bias is critical. In contrast, GA showed significant limitations, with consistently high bias and MSE, making it the least reliable method. Bross-based hdPS, and Hybrid hdPS methods provided a balanced approach, with low bias and moderate MSE, though coverage varied depending on the scenario. Rare outcome scenarios generally resulted in lower MSE and better precision, while rare exposure scenarios were associated with higher bias and MSE. Notably, traditional statistical approaches such as forward selection and backward elimination performed comparably to more sophisticated machine learning methods in terms of bias and coverage, suggesting that these simpler approaches may be viable alternatives due to their computational efficiency. CONCLUSION: The results highlight the importance of selecting hdPS methods based on the specific characteristics of the data, such as exposure and outcome prevalence. While advanced machine learning methods such as XGBoost can enhance precision, simpler methods such as forward selection or backward elimination may offer similar performance in terms of bias and coverage with fewer computational demands. Tailoring the choice of method to the epidemiological scenario is essential for optimizing the balance between bias reduction and precision.",
      "authors": "Ehsanul Karim Mohammad; Lei Yang",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0324639",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40435158/",
      "mesh_terms": "Machine Learning; Humans; Bias; Propensity Score; Nutrition Surveys; Algorithms; Multivariate Analysis; Models, Statistical; Computer Simulation",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12118903"
    },
    {
      "pmid": "36576182",
      "title": "Assessing machine learning for fair prediction of ADHD in school pupils using a retrospective cohort study of linked education and healthcare data.",
      "abstract": "OBJECTIVES: Attention deficit hyperactivity disorder (ADHD) is a prevalent childhood disorder, but often goes unrecognised and untreated. To improve access to services, accurate predictions of populations at high risk of ADHD are needed for effective resource allocation. Using a unique linked health and education data resource, we examined how machine learning (ML) approaches can predict risk of ADHD. DESIGN: Retrospective population cohort study. SETTING: South London (2007-2013). PARTICIPANTS: n=56\u2009258 pupils with linked education and health data. PRIMARY OUTCOME MEASURES: Using area under the curve (AUC), we compared the predictive accuracy of four ML models and one neural network for ADHD diagnosis. Ethnic group and language biases were weighted using a fair pre-processing algorithm. RESULTS: Random forest and logistic regression prediction models provided the highest predictive accuracy for ADHD in population samples (AUC 0.86 and 0.86, respectively) and clinical samples (AUC 0.72 and 0.70). Precision-recall curve analyses were less favourable. Sociodemographic biases were effectively reduced by a fair pre-processing algorithm without loss of accuracy. CONCLUSIONS: ML approaches using linked routinely collected education and health data offer accurate, low-cost and scalable prediction models of ADHD. These approaches could help identify areas of need and inform resource allocation. Introducing 'fairness weighting' attenuates some sociodemographic biases which would otherwise underestimate ADHD risk within minority groups.",
      "authors": "Ter-Minassian Lucile; Viani Natalia; Wickersham Alice; Cross Lauren; Stewart Robert; Velupillai Sumithra; Downs Johnny",
      "year": "2022",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2021-058058",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36576182/",
      "mesh_terms": "Humans; Child; Attention Deficit Disorder with Hyperactivity; Retrospective Studies; Cohort Studies; Schools; Delivery of Health Care; Machine Learning",
      "keywords": "Child & adolescent psychiatry; EPIDEMIOLOGY; MENTAL HEALTH",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9723859"
    },
    {
      "pmid": "39282853",
      "title": "Characterizing Veteran suicide decedents that were not classified as high-suicide-risk.",
      "abstract": "BACKGROUND: Although the Department of Veterans Affairs (VA) has made important suicide prevention advances, efforts primarily target high-risk patients with documented suicide risk, such as suicidal ideation, prior suicide attempts, and recent psychiatric hospitalization. Approximately 90% of VA patients that go on to die by suicide do not meet these high-risk criteria and therefore do not receive targeted suicide prevention services. In this study, we used national VA data to focus on patients that were not classified as high-risk, but died by suicide. METHODS: Our sample included all VA patients who died by suicide in 2017 or 2018. We determined whether patients were classified as high-risk using the VA's machine learning risk prediction algorithm. After excluding these patients, we used principal component analysis to identify moderate-risk and low-risk patients and investigated demographics, service-usage, diagnoses, and social determinants of health differences across high-, moderate-, and low-risk subgroups. RESULTS: High-risk (n = 452) patients tended to be younger, White, unmarried, homeless, and have more mental health diagnoses compared to moderate- (n = 2149) and low-risk (n = 2209) patients. Moderate- and low-risk patients tended to be older, married, Black, and Native American or Pacific Islander, and have more physical health diagnoses compared to high-risk patients. Low-risk patients had more missing data than higher-risk patients. CONCLUSIONS: Study expands epidemiological understanding about non-high-risk suicide decedents, historically understudied and underserved populations. Findings raise concerns about reliance on machine learning risk prediction models that may be biased by relative underrepresentation of racial/ethnic minorities within health system.",
      "authors": "Levis Maxwell; Dimambro Monica; Levy Joshua; Dufort Vincent; Fraade Abby; Winer Max; Shiner Brian",
      "year": "2024",
      "journal": "Psychological medicine",
      "doi": "10.1017/S0033291724001296",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39282853/",
      "mesh_terms": "Humans; Veterans; Male; Female; Middle Aged; United States; Aged; Adult; Suicide; United States Department of Veterans Affairs; Risk Factors; Risk Assessment; Mental Disorders; Machine Learning; Suicide, Attempted; Suicidal Ideation",
      "keywords": "machine learning; machine learning bias; suicide prevention; veterans and military",
      "pub_types": "Journal Article",
      "pmcid": "PMC11839400"
    },
    {
      "pmid": "36976634",
      "title": "Predicting Social Determinants of Health in Patient Navigation: Case Study.",
      "abstract": "BACKGROUND: Patient navigation (PN) programs have demonstrated efficacy in improving health outcomes for marginalized populations across a range of clinical contexts by addressing barriers to health care, including social determinants of health (SDoHs). However, it can be challenging for navigators to identify SDoHs by asking patients directly because of many factors, including patients' reluctance to disclose information, communication barriers, and the variable resources and experience levels of patient navigators. Navigators could benefit from strategies that augment their ability to gather SDoH data. Machine learning can be leveraged as one of these strategies to identify SDoH-related barriers. This could further improve health outcomes, particularly in underserved populations. OBJECTIVE: In this formative study, we explored novel machine learning-based approaches to predict SDoHs in 2 Chicago area PN studies. In the first approach, we applied machine learning to data that include comments and interaction details between patients and navigators, whereas the second approach augmented patients' demographic information. This paper presents the results of these experiments and provides recommendations for data collection and the application of machine learning techniques more generally to the problem of predicting SDoHs. METHODS: We conducted 2 experiments to explore the feasibility of using machine learning to predict patients' SDoHs using data collected from PN research. The machine learning algorithms were trained on data collected from 2 Chicago area PN studies. In the first experiment, we compared several machine learning algorithms (logistic regression, random forest, support vector machine, artificial neural network, and Gaussian naive Bayes) to predict SDoHs from both patient demographics and navigator's encounter data over time. In the second experiment, we used multiclass classification with augmented information, such as transportation time to a hospital, to predict multiple SDoHs for each patient. RESULTS: In the first experiment, the random forest classifier achieved the highest accuracy among the classifiers tested. The overall accuracy to predict SDoHs was 71.3%. In the second experiment, multiclass classification effectively predicted a few patients' SDoHs based purely on demographic and augmented data. The best accuracy of these predictions overall was 73%. However, both experiments yielded high variability in individual SDoH predictions and correlations that become salient among SDoHs. CONCLUSIONS: To our knowledge, this study is the first approach to applying PN encounter data and multiclass learning algorithms to predict SDoHs. The experiments discussed yielded valuable lessons, including the awareness of model limitations and bias, planning for standardization of data sources and measurement, and the need to identify and anticipate the intersectionality and clustering of SDoHs. Although our focus was on predicting patients' SDoHs, machine learning can have a broad range of applications in the field of PN, from tailoring intervention delivery (eg, supporting PN decision-making) to informing resource allocation for measurement, and PN supervision.",
      "authors": "Iacobelli Francisco; Yang Anna; Tom Laura; Leung Ivy S; Crissman John; Salgado Rufino; Simon Melissa",
      "year": "2023",
      "journal": "JMIR formative research",
      "doi": "10.2196/42683",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36976634/",
      "mesh_terms": "",
      "keywords": "case study; health care disparities; health equity; machine learning; patient navigation; social determinants of health",
      "pub_types": "Journal Article",
      "pmcid": "PMC10131925"
    },
    {
      "pmid": "38548006",
      "title": "Participant flow diagrams for health equity in AI.",
      "abstract": "Selection bias can arise through many aspects of a study, including recruitment, inclusion/exclusion criteria, input-level exclusion and outcome-level exclusion, and often reflects the underrepresentation of populations historically disadvantaged in medical research. The effects of selection bias can be further amplified when non-representative samples are used in artificial intelligence (AI) and machine learning (ML) applications to construct clinical algorithms. Building on the \"Data Cards\" initiative for transparency in AI research, we advocate for the addition of a participant flow diagram for AI studies detailing relevant sociodemographic and/or clinical characteristics of excluded participants across study phases, with the goal of identifying potential algorithmic biases before their clinical implementation. We include both a model for this flow diagram as well as a brief case study explaining how it could be implemented in practice. Through standardized reporting of participant flow diagrams, we aim to better identify potential inequities embedded in AI applications, facilitating more reliable and equitable clinical algorithms.",
      "authors": "Ellen Jacob G; Matos Jo\u00e3o; Viola Martin; Gallifant Jack; Quion Justin; Anthony Celi Leo; Abu Hussein Nebal S",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2024.104631",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38548006/",
      "mesh_terms": "Humans; Artificial Intelligence; Health Equity; Algorithms; Machine Learning; Biomedical Research",
      "keywords": "Data cards; Flow diagram; Health equity; Machine learning; Selection bias",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34383925",
      "title": "Bias and fairness assessment of a natural language processing opioid misuse classifier: detection and mitigation of electronic health record data disadvantages across racial subgroups.",
      "abstract": "OBJECTIVES: To assess fairness and bias of a previously validated machine learning opioid misuse classifier. MATERIALS & METHODS: Two experiments were conducted with the classifier's original (n\u2009=\u20091000) and external validation (n\u2009=\u200953 974) datasets from 2 health systems. Bias was assessed via testing for differences in type II error rates across racial/ethnic subgroups (Black, Hispanic/Latinx, White, Other) using bootstrapped 95% confidence intervals. A local surrogate model was estimated to interpret the classifier's predictions by race and averaged globally from the datasets. Subgroup analyses and post-hoc recalibrations were conducted to attempt to mitigate biased metrics. RESULTS: We identified bias in the false negative rate (FNR = 0.32) of the Black subgroup compared to the FNR (0.17) of the White subgroup. Top features included \"heroin\" and \"substance abuse\" across subgroups. Post-hoc recalibrations eliminated bias in FNR with minimal changes in other subgroup error metrics. The Black FNR subgroup had higher risk scores for readmission and mortality than the White FNR subgroup, and a higher mortality risk score than the Black true positive subgroup (P\u2009<\u2009.05). DISCUSSION: The Black FNR subgroup had the greatest severity of disease and risk for poor outcomes. Similar features were present between subgroups for predicting opioid misuse, but inequities were present. Post-hoc mitigation techniques mitigated bias in type II error rate without creating substantial type I error rates. From model design through deployment, bias and data disadvantages should be systematically addressed. CONCLUSION: Standardized, transparent bias assessments are needed to improve trustworthiness in clinical machine learning models.",
      "authors": "Thompson Hale M; Sharma Brihat; Bhalla Sameer; Boley Randy; McCluskey Connor; Dligach Dmitriy; Churpek Matthew M; Karnik Niranjan S; Afshar Majid",
      "year": "2021",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocab148",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34383925/",
      "mesh_terms": "Electronic Health Records; Hispanic or Latino; Humans; Machine Learning; Natural Language Processing; Opioid-Related Disorders",
      "keywords": "bias and fairness; interpretability; machine learning; natural language processing; opioid use disorder; structural racism",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC8510285"
    },
    {
      "pmid": "39628837",
      "title": "Active learning with human heuristics: an algorithm robust to labeling bias.",
      "abstract": "Active learning enables prediction models to achieve better performance faster by adaptively querying an oracle for the labels of data points. Sometimes the oracle is a human, for example when a medical diagnosis is provided by a doctor. According to the behavioral sciences, people, because they employ heuristics, might sometimes exhibit biases in labeling. How does modeling the oracle as a human heuristic affect the performance of active learning algorithms? If there is a drop in performance, can one design active learning algorithms robust to labeling bias? The present article provides answers. We investigate two established human heuristics (fast-and-frugal tree, tallying model) combined with four active learning algorithms (entropy sampling, multi-view learning, conventional information density, and, our proposal, inverse information density) and three standard classifiers (logistic regression, random forests, support vector machines), and apply their combinations to 15 datasets where people routinely provide labels, such as health and other domains like marketing and transportation. There are two main results. First, we show that if a heuristic provides labels, the performance of active learning algorithms significantly drops, sometimes below random. Hence, it is key to design active learning algorithms that are robust to labeling bias. Our second contribution is to provide such a robust algorithm. The proposed inverse information density algorithm, which is inspired by human psychology, achieves an overall improvement of 87% over the best of the other algorithms. In conclusion, designing and benchmarking active learning algorithms can benefit from incorporating the modeling of human heuristics.",
      "authors": "Ravichandran Sriram; Sudarsanam Nandan; Ravindran Balaraman; Katsikopoulos Konstantinos V",
      "year": "2024",
      "journal": "Frontiers in artificial intelligence",
      "doi": "10.3389/frai.2024.1491932",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39628837/",
      "mesh_terms": "",
      "keywords": "active learning; biases; fast-and-frugal heuristics; human behavior; human in the loop; robustness",
      "pub_types": "Journal Article",
      "pmcid": "PMC11611880"
    },
    {
      "pmid": "36378761",
      "title": "Improving Fairness in the Prediction of Heart Failure Length of Stay and Mortality by Integrating Social Determinants of Health.",
      "abstract": "BACKGROUND: Machine learning (ML) approaches have been broadly applied to the prediction of length of stay and mortality in hospitalized patients. ML may also reduce societal health burdens, assist in health resources planning and improve health outcomes. However, the fairness of these ML models across ethnoracial or socioeconomic subgroups is rarely assessed or discussed. In this study, we aim (1) to quantify the algorithmic bias of ML models when predicting the probability of long-term hospitalization or in-hospital mortality for different heart failure (HF) subpopulations, and (2) to propose a novel method that can improve the fairness of our models without compromising predictive power. METHODS: We built 5 ML classifiers to predict the composite outcome of hospitalization length-of-stay and in-hospital mortality for 210\u2009368 HF patients extracted from the Get With The Guidelines-Heart Failure registry data set. We integrated 15 social determinants of health variables, including the Social Deprivation Index and the Area Deprivation Index, into the feature space of ML models based on patients' geographies to mitigate the algorithmic bias. RESULTS: The best-performing random forest model demonstrated modest predictive power but selectively underdiagnosed underserved subpopulations, for example, female, Black, and socioeconomically disadvantaged patients. The integration of social determinants of health variables can significantly improve fairness without compromising model performance. CONCLUSIONS: We quantified algorithmic bias against underserved subpopulations in the prediction of the composite outcome for HF patients. We provide a potential direction to reduce disparities of ML-based predictive models by integrating social determinants of health variables. We urge fellow researchers to strongly consider ML fairness when developing predictive models for HF patients.",
      "authors": "Li Yikuan; Wang Hanyin; Luo Yuan",
      "year": "2022",
      "journal": "Circulation. Heart failure",
      "doi": "10.1161/CIRCHEARTFAILURE.122.009473",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36378761/",
      "mesh_terms": "Humans; Female; Heart Failure; Length of Stay; Social Determinants of Health; Hospitalization; Hospital Mortality",
      "keywords": "bias; healthcare disparities; heart failure; machine learning; social determinants of health",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9673161"
    },
    {
      "pmid": "30794127",
      "title": "Can AI Help Reduce Disparities in General Medical and Mental Health Care?",
      "abstract": "BACKGROUND: As machine learning becomes increasingly common in health care applications, concerns have been raised about bias in these systems' data, algorithms, and recommendations. Simply put, as health care improves for some, it might not improve for all. METHODS: Two case studies are examined using a machine learning algorithm on unstructured clinical and psychiatric notes to predict intensive care unit (ICU) mortality and 30-day psychiatric readmission with respect to race, gender, and insurance payer type as a proxy for socioeconomic status. RESULTS: Clinical note topics and psychiatric note topics were heterogenous with respect to race, gender, and insurance payer type, which reflects known clinical findings. Differences in prediction accuracy and therefore machine bias are shown with respect to gender and insurance type for ICU mortality and with respect to insurance policy for psychiatric 30-day readmission. CONCLUSIONS: This analysis can provide a framework for assessing and identifying disparate impacts of artificial intelligence in health care.",
      "authors": "Chen Irene Y; Szolovits Peter; Ghassemi Marzyeh",
      "year": "2019",
      "journal": "AMA journal of ethics",
      "doi": "10.1001/amajethics.2019.167",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30794127/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Artificial Intelligence; Delivery of Health Care; Female; Healthcare Disparities; Humans; Intensive Care Units; Male; Mental Health Services; Middle Aged; Mortality; Patient Readmission; Sex Factors",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": ""
    },
    {
      "pmid": "38241250",
      "title": "A scientometric analysis of fairness in health AI literature.",
      "abstract": "Artificial intelligence (AI) and machine learning are central components of today's medical environment. The fairness of AI, i.e. the ability of AI to be free from bias, has repeatedly come into question. This study investigates the diversity of members of academia whose scholarship poses questions about the fairness of AI. The articles that combine the topics of fairness, artificial intelligence, and medicine were selected from Pubmed, Google Scholar, and Embase using keywords. Eligibility and data extraction from the articles were done manually and cross-checked by another author for accuracy. Articles were selected for further analysis, cleaned, and organized in Microsoft Excel; spatial diagrams were generated using Public Tableau. Additional graphs were generated using Matplotlib and Seaborn. Linear and logistic regressions were conducted using Python to measure the relationship between funding status, number of citations, and the gender demographics of the authorship team. We identified 375 eligible publications, including research and review articles concerning AI and fairness in healthcare. Analysis of the bibliographic data revealed that there is an overrepresentation of authors that are white, male, and are from high-income countries, especially in the roles of first and last author. Additionally, analysis showed that papers whose authors are based in higher-income countries were more likely to be cited more often and published in higher impact journals. These findings highlight the lack of diversity among the authors in the AI fairness community whose work gains the largest readership, potentially compromising the very impartiality that the AI fairness community is working towards.",
      "authors": "Alberto Isabelle Rose I; Alberto Nicole Rose I; Altinel Yuksel; Blacker Sarah; Binotti William Warr; Celi Leo Anthony; Chua Tiffany; Fiske Amelia; Griffin Molly; Karaca Gulce; Mokolo Nkiruka; Naawu David Kojo N; Patscheider Jonathan; Petushkov Anton; Quion Justin Michael; Senteio Charles; Taisbak Simon; T\u0131rnova \u0130smail; Tokashiki Harumi; Velasquez Adrian; Yaghy Antonio; Yap Keagan",
      "year": "2024",
      "journal": "PLOS global public health",
      "doi": "10.1371/journal.pgph.0002513",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38241250/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10798451"
    },
    {
      "pmid": "37252970",
      "title": "Cohort bias in predictive risk assessments of future criminal justice system involvement.",
      "abstract": "Risk assessment instruments (RAIs) are widely used to aid high-stakes decision-making in criminal justice settings and other areas such as health care and child welfare. These tools, whether using machine learning or simpler algorithms, typically assume a time-invariant relationship between predictors and outcome. Because societies are themselves changing and not just individuals, this assumption may be violated in many behavioral settings, generating what we call cohort bias. Analyzing criminal histories in a cohort-sequential longitudinal study of children, we demonstrate that regardless of model type or predictor sets, a tool trained to predict the likelihood of arrest between the ages of 17 and 24 y on older birth cohorts systematically overpredicts the likelihood of arrest for younger birth cohorts over the period 1995 to 2020. Cohort bias is found for both relative and absolute risks, and it persists for all racial groups and within groups at highest risk for arrest. The results imply that cohort bias is an underappreciated mechanism generating inequality in contacts with the criminal legal system that is distinct from racial bias. Cohort bias is a challenge not only for predictive instruments with respect to crime and justice, but also for RAIs more broadly.",
      "authors": "Montana Erika; Nagin Daniel S; Neil Roland; Sampson Robert J",
      "year": "2023",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "doi": "10.1073/pnas.2301990120",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37252970/",
      "mesh_terms": "Child; Humans; Adolescent; Young Adult; Adult; Longitudinal Studies; Criminal Law; Crime; Cohort Studies; Risk Assessment",
      "keywords": "bias; cohort; criminal justice; risk assessment; social change",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC10265989"
    },
    {
      "pmid": "37266959",
      "title": "Awareness of Racial and Ethnic Bias and Potential Solutions to Address Bias With Use of Health Care Algorithms.",
      "abstract": "IMPORTANCE: Algorithms are commonly incorporated into health care decision tools used by health systems and payers and thus affect quality of care, access, and health outcomes. Some algorithms include a patient's race or ethnicity among their inputs and can lead clinicians and decision-makers to make choices that vary by race and potentially affect inequities. OBJECTIVE: To inform an evidence review on the use of race- and ethnicity-based algorithms in health care by gathering public and stakeholder perspectives about the repercussions of and efforts to address algorithm-related bias. DESIGN, SETTING, AND PARTICIPANTS: Qualitative methods were used to analyze responses. Responses were initially open coded and then consolidated to create a codebook, with themes and subthemes identified and finalized by consensus. This qualitative study was conducted from May 4, 2021, through December 7, 2022. Forty-two organization representatives (eg, clinical professional societies, universities, government agencies, payers, and health technology organizations) and individuals responded to the request for information. MAIN OUTCOMES AND MEASURES: Identification of algorithms with the potential for race- and ethnicity-based biases and qualitative themes. RESULTS: Forty-two respondents identified 18 algorithms currently in use with the potential for bias, including, for example, the Simple Calculated Osteoporosis Risk Estimation risk prediction tool and the risk calculator for vaginal birth after cesarean section. The 7 qualitative themes, with 31 subthemes, included the following: (1) algorithms are in widespread use and have significant repercussions, (2) bias can result from algorithms whether or not they explicitly include race, (3) clinicians and patients are often unaware of the use of algorithms and potential for bias, (4) race is a social construct used as a proxy for clinical variables, (5) there is a lack of standardization in how race and social determinants of health are collected and defined, (6) bias can be introduced at all stages of algorithm development, and (7) algorithms should be discussed as part of shared decision-making between the patient and clinician. CONCLUSIONS AND RELEVANCE: This qualitative study found that participants perceived widespread and increasing use of algorithms in health care and lack of oversight, potentially exacerbating racial and ethnic inequities. Increasing awareness for clinicians and patients and standardized, transparent approaches for algorithm development and implementation may be needed to address racial and ethnic biases related to algorithms.",
      "authors": "Jain Anjali; Brooks Jasmin R; Alford Cleothia C; Chang Christine S; Mueller Nora M; Umscheid Craig A; Bierman Arlene S",
      "year": "2023",
      "journal": "JAMA health forum",
      "doi": "10.1001/jamahealthforum.2023.1197",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37266959/",
      "mesh_terms": "Pregnancy; Humans; Female; Cesarean Section; Delivery of Health Care; Ethnicity; Health Facilities; Bias",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10238944"
    },
    {
      "pmid": "37130756",
      "title": "Addressing bias in artificial intelligence for public health surveillance.",
      "abstract": "Components of artificial intelligence (AI) for analysing social big data, such as natural language processing (NLP) algorithms, have improved the timeliness and robustness of health data. NLP techniques have been implemented to analyse large volumes of text from social media platforms to gain insights on disease symptoms, understand barriers to care and predict disease outbreaks. However, AI-based decisions may contain biases that could misrepresent populations, skew results or lead to errors. Bias, within the scope of this paper, is described as the difference between the predictive values and true values within the modelling of an algorithm. Bias within algorithms may lead to inaccurate healthcare outcomes and exacerbate health disparities when results derived from these biased algorithms are applied to health interventions. Researchers who implement these algorithms must consider when and how bias may arise. This paper explores algorithmic biases as a result of data collection, labelling and modelling of NLP algorithms. Researchers have a role in ensuring that efforts towards combating bias are enforced, especially when drawing health conclusions derived from social media posts that are linguistically diverse. Through the implementation of open collaboration, auditing processes and the development of guidelines, researchers may be able to reduce bias and improve NLP algorithms that improve health surveillance.",
      "authors": "Flores Lidia; Kim Seungjun; Young Sean D",
      "year": "2024",
      "journal": "Journal of medical ethics",
      "doi": "10.1136/jme-2022-108875",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37130756/",
      "mesh_terms": "Humans; Artificial Intelligence; Public Health Surveillance; Bias; Data Collection; Disease Outbreaks",
      "keywords": "decision making; ethics; ethics- medical; ethics- research; information technology",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39176898",
      "title": "How Data Infrastructure Deals with Bias Problems in Medical Imaging.",
      "abstract": "The paper discusses biases in medical imaging analysis, particularly focusing on the challenges posed by the development of machine learning algorithms and generative models. It introduces a taxonomy of bias problems and addresses them through a data infrastructure initiative: the PADME (Platform for Analytics and Distributed Machine-Learning for Enterprises), which is a part of the National Research Data Infrastructure for Personal Health Data (NFDI4Health) project. The PADME facilitates the structuring and sharing of health data while ensuring privacy and adherence to FAIR principles. The paper presents experimental results that show that generative methods can be effective in data augmentation. Complying with PADME infrastructure, this work proposes a solution framework to deal with bias in the different data stations and preserve privacy when transferring images. It highlights the importance of standardized data infrastructure in mitigating biases and promoting FAIR, reusable, and privacy-preserving research environments in healthcare.",
      "authors": "Li Feifei; Kutafina Ekaterina; Schoneck Mirjam; Caldeira Liliana Lourenco; Beyan Oya",
      "year": "2024",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI240517",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39176898/",
      "mesh_terms": "Diagnostic Imaging; Humans; Machine Learning; Bias; Algorithms; Confidentiality; Computer Security",
      "keywords": "Bias; Data Infrastructure; Differential Privacy; Federated Learning; Machine Learning; Medical Imaging",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "35685000",
      "title": "Designing Equitable Health Care Outreach Programs From Machine Learning Patient Risk Scores.",
      "abstract": "There is growing interest in ensuring equity and guarding against bias in the use of risk scores produced by machine learning and artificial intelligence models. Risk scores are used to select patients who will receive outreach and support. Inappropriate use of risk scores, however, can perpetuate disparities. Commonly advocated solutions to improve equity are nontrivial to implement and may not pass legal scrutiny. In this article, we introduce pragmatic tools that support better use of risk scores for more equitable outreach programs. Our model output charts allow modeling and care management teams to see the equity consequences of different threshold choices and to select the optimal risk thresholds to trigger outreach. For best results, as with any health equity tool, we recommend that these charts be used by a diverse team and shared with relevant stakeholders.",
      "authors": "Hane Christopher A; Wasserman Melanie",
      "year": "2023",
      "journal": "Medical care research and review : MCRR",
      "doi": "10.1177/10775587221098831",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35685000/",
      "mesh_terms": "Humans; Artificial Intelligence; Delivery of Health Care; Machine Learning",
      "keywords": "artificial intelligence; civil rights; health care disparities; health equity; health status disparities; structural inequity",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35914194",
      "title": "Predicting Race And Ethnicity To Ensure Equitable Algorithms For Health Care Decision Making.",
      "abstract": "Algorithms are currently used to assist in a wide array of health care decisions. Despite the general utility of these health care algorithms, there is growing recognition that they may lead to unintended racially discriminatory practices, raising concerns about the potential for algorithmic bias. An intuitive precaution against such bias is to remove race and ethnicity information as an input to health care algorithms, mimicking the idea of \"race-blind\" decisions. However, we argue that this approach is misguided. Knowledge, not ignorance, of race and ethnicity is necessary to combat algorithmic bias. When race and ethnicity are observed, many methodological approaches can be used to enforce equitable algorithmic performance. When race and ethnicity information is unavailable, which is often the case, imputing them can expand opportunities to not only identify and assess algorithmic bias but also combat it in both clinical and nonclinical settings. A valid imputation method, such as Bayesian Improved Surname Geocoding, can be applied to standard data collected by public and private payers and provider entities. We describe two applications in which imputation of race and ethnicity can help mitigate potential algorithmic biases: equitable disease screening algorithms using machine learning and equitable pay-for-performance incentives.",
      "authors": "Cabreros Irineo; Agniel Denis; Martino Steven C; Damberg Cheryl L; Elliott Marc N",
      "year": "2022",
      "journal": "Health affairs (Project Hope)",
      "doi": "10.1377/hlthaff.2022.00095",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35914194/",
      "mesh_terms": "Algorithms; Bayes Theorem; Decision Making; Delivery of Health Care; Ethnicity; Humans; Reimbursement, Incentive",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38875540",
      "title": "Developing Ethics and Equity Principles, Terms, and Engagement Tools to Advance Health Equity and Researcher Diversity in AI and Machine Learning: Modified Delphi Approach.",
      "abstract": "BACKGROUND: Artificial intelligence (AI) and machine learning (ML) technology design and development continues to be rapid, despite major limitations in its current form as a practice and discipline to address all sociohumanitarian issues and complexities. From these limitations emerges an imperative to strengthen AI and ML literacy in underserved communities and build a more diverse AI and ML design and development workforce engaged in health research. OBJECTIVE: AI and ML has the potential to account for and assess a variety of factors that contribute to health and disease and to improve prevention, diagnosis, and therapy. Here, we describe recent activities within the Artificial Intelligence/Machine Learning Consortium to Advance Health Equity and Researcher Diversity (AIM-AHEAD) Ethics and Equity Workgroup (EEWG) that led to the development of deliverables that will help put ethics and fairness at the forefront of AI and ML applications to build equity in biomedical research, education, and health care. METHODS: The AIM-AHEAD EEWG was created in 2021 with 3 cochairs and 51 members in year 1 and 2 cochairs and ~40 members in year 2. Members in both years included AIM-AHEAD principal investigators, coinvestigators, leadership fellows, and research fellows. The EEWG used a modified Delphi approach using polling, ranking, and other exercises to facilitate discussions around tangible steps, key terms, and definitions needed to ensure that ethics and fairness are at the forefront of AI and ML applications to build equity in biomedical research, education, and health care. RESULTS: The EEWG developed a set of ethics and equity principles, a glossary, and an interview guide. The ethics and equity principles comprise 5 core principles, each with subparts, which articulate best practices for working with stakeholders from historically and presently underrepresented communities. The glossary contains 12 terms and definitions, with particular emphasis on optimal development, refinement, and implementation of AI and ML in health equity research. To accompany the glossary, the EEWG developed a concept relationship diagram that describes the logical flow of and relationship between the definitional concepts. Lastly, the interview guide provides questions that can be used or adapted to garner stakeholder and community perspectives on the principles and glossary. CONCLUSIONS: Ongoing engagement is needed around our principles and glossary to identify and predict potential limitations in their uses in AI and ML research settings, especially for institutions with limited resources. This requires time, careful consideration, and honest discussions around what classifies an engagement incentive as meaningful to support and sustain their full engagement. By slowing down to meet historically and presently underresourced institutions and communities where they are and where they are capable of engaging and competing, there is higher potential to achieve needed diversity, ethics, and equity in AI and ML implementation in health research.",
      "authors": "Hendricks-Sturrup Rachele; Simmons Malaika; Anders Shilo; Aneni Kammarauche; Wright Clayton Ellen; Coco Joseph; Collins Benjamin; Heitman Elizabeth; Hussain Sajid; Joshi Karuna; Lemieux Josh; Lovett Novak Laurie; Rubin Daniel J; Shanker Anil; Washington Talitha; Waters Gabriella; Webb Harris Joyce; Yin Rui; Wagner Teresa; Yin Zhijun; Malin Bradley",
      "year": "2023",
      "journal": "JMIR AI",
      "doi": "10.2196/52888",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38875540/",
      "mesh_terms": "",
      "keywords": "AI; Delphi; ML; artificial intelligence; disparities; disparity; engagement; equitable; equities; equity; ethic; ethical; ethics; fair; fairness; health disparities; health equity; humanitarian; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11041493"
    },
    {
      "pmid": "38929638",
      "title": "The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective.",
      "abstract": "Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.",
      "authors": "Franklin Gillian; Stephens Rachel; Piracha Muhammad; Tiosano Shmuel; Lehouillier Frank; Koppel Ross; Elkin Peter L",
      "year": "2024",
      "journal": "Life (Basel, Switzerland)",
      "doi": "10.3390/life14060652",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38929638/",
      "mesh_terms": "",
      "keywords": "algorithms; artificial intelligence; bias; biomedical informatics; electronic health records; health care; machine learning; models; sociodemographic",
      "pub_types": "Journal Article",
      "pmcid": "PMC11204917"
    },
    {
      "pmid": "36719717",
      "title": "Black and Latinx Primary Caregiver Considerations for Developing and Implementing a Machine Learning-Based Model for Detecting Child Abuse and Neglect With Implications for Racial Bias Reduction: Qualitative Interview Study With Primary Caregivers.",
      "abstract": "BACKGROUND: Child abuse and neglect, once viewed as a social problem, is now an epidemic. Moreover, health providers agree that existing stereotypes may link racial and social class issues to child abuse. The broad adoption of electronic health records (EHRs) in clinical settings offers a new avenue for addressing this epidemic. To reduce racial bias and improve the development, implementation, and outcomes of machine learning (ML)-based models that use EHR data, it is crucial to involve marginalized members of the community in the process. OBJECTIVE: This study elicited Black and Latinx primary caregivers' viewpoints regarding child abuse and neglect while living in underserved communities to highlight considerations for designing an ML-based model for detecting child abuse and neglect in emergency departments (EDs) with implications for racial bias reduction and future interventions. METHODS: We conducted a qualitative study using in-depth interviews with 20 Black and Latinx primary caregivers whose children were cared for at a single pediatric tertiary-care ED to gain insights about child abuse and neglect and their experiences with health providers. RESULTS: Three central themes were developed in the coding process: (1) primary caregivers' perspectives on the definition of child abuse and neglect, (2) primary caregivers' experiences with health providers and medical documentation, and (3) primary caregivers' perceptions of child protective services. CONCLUSIONS: Our findings highlight essential considerations from primary caregivers for developing an ML-based model for detecting child abuse and neglect in ED settings. This includes how to define child abuse and neglect from a primary caregiver lens. Miscommunication between patients and health providers can potentially lead to a misdiagnosis, and therefore, have a negative impact on medical documentation. Additionally, the outcome and application of the ML-based models for detecting abuse and neglect may cause additional harm than expected to the community. Further research is needed to validate these findings and integrate them into creating an ML-based model.",
      "authors": "Landau Aviv Y; Blanchard Ashley; Atkins Nia; Salazar Stephanie; Cato Kenrick; Patton Desmond U; Topaz Maxim",
      "year": "2023",
      "journal": "JMIR formative research",
      "doi": "10.2196/40194",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36719717/",
      "mesh_terms": "",
      "keywords": "abuse; child; child abuse and neglect; community; development; electronic health records; epidemic; implementation; machine learning; machine learning\u2013based risk models; model; neglect; pediatric emergency departments; primary caregivers",
      "pub_types": "Journal Article",
      "pmcid": "PMC9929722"
    },
    {
      "pmid": "37579574",
      "title": "Algorithmic bias in artificial intelligence is a problem-And the root issue is power.",
      "abstract": "BACKGROUND: Artificial intelligence (AI) in health care continues to expand at a rapid rate, impacting both nurses and communities we accompany in care. PURPOSE: We argue algorithmic bias is but a symptom of a more systemic and longstanding problem: power imbalances related to the creation, development, and use of health care technologies. METHODS: This commentary responds to Drs. O'Connor and Booth's 2022 article, \"Algorithmic bias in health care: Opportunities for nurses to improve equality in the age of artificial intelligence.\" DISCUSSION: Nurses need not 'reinvent the wheel' when it comes to AI policy, curricula, or ethics. We can and should follow the lead of communities already working 'from the margins' who provide ample guidance. CONCLUSION: Its neither feasible nor just to expect individual nurses to counter systemic injustice in health care through individual actions, more technocentric curricula, or industry partnerships. We need disciplinary supports for collective action to renegotiate power for AI tech.",
      "authors": "Walker Rae; Dillard-Wright Jess; Iradukunda Favorite",
      "year": "2023",
      "journal": "Nursing outlook",
      "doi": "10.1016/j.outlook.2023.102023",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37579574/",
      "mesh_terms": "Humans; Artificial Intelligence; Delivery of Health Care",
      "keywords": "Algorithms; Artificial intelligence; Bias; Machine learning; Nursing ethics; Racism",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39186324",
      "title": "Sex-Based Performance Disparities in Machine Learning Algorithms for Cardiac Disease Prediction: Exploratory Study.",
      "abstract": "BACKGROUND: The presence of bias in artificial intelligence has garnered increased attention, with inequities in algorithmic performance being exposed across the fields of criminal justice, education, and welfare services. In health care, the inequitable performance of algorithms across demographic groups may widen health inequalities. OBJECTIVE: Here, we identify and characterize bias in cardiology algorithms, looking specifically at algorithms used in the management of heart failure. METHODS: Stage 1 involved a literature search of PubMed and Web of Science for key terms relating to cardiac machine learning (ML) algorithms. Papers that built ML models to predict cardiac disease were evaluated for their focus on demographic bias in model performance, and open-source data sets were retained for our investigation. Two open-source data sets were identified: (1) the University of California Irvine Heart Failure data set and (2) the University of California Irvine Coronary Artery Disease data set. We reproduced existing algorithms that have been reported for these data sets, tested them for sex biases in algorithm performance, and assessed a range of remediation techniques for their efficacy in reducing inequities. Particular attention was paid to the false negative rate (FNR), due to the clinical significance of underdiagnosis and missed opportunities for treatment. RESULTS: In stage 1, our literature search returned 127 papers, with 60 meeting the criteria for a full review and only 3 papers highlighting sex differences in algorithm performance. In the papers that reported sex, there was a consistent underrepresentation of female patients in the data sets. No papers investigated racial or ethnic differences. In stage 2, we reproduced algorithms reported in the literature, achieving mean accuracies of 84.24% (SD 3.51%) for data set 1 and 85.72% (SD 1.75%) for data set 2 (random forest models). For data set 1, the FNR was significantly higher for female patients in 13 out of 16 experiments, meeting the threshold of statistical significance (-17.81% to -3.37%; P<.05). A smaller disparity in the false positive rate was significant for male patients in 13 out of 16 experiments (-0.48% to +9.77%; P<.05). We observed an overprediction of disease for male patients (higher false positive rate) and an underprediction of disease for female patients (higher FNR). Sex differences in feature importance suggest that feature selection needs to be demographically tailored. CONCLUSIONS: Our research exposes a significant gap in cardiac ML research, highlighting that the underperformance of algorithms for female patients has been overlooked in the published literature. Our study quantifies sex disparities in algorithmic performance and explores several sources of bias. We found an underrepresentation of female patients in the data sets used to train algorithms, identified sex biases in model error rates, and demonstrated that a series of remediation techniques were unable to address the inequities present.",
      "authors": "Straw Isabel; Rees Geraint; Nachev Parashkev",
      "year": "2024",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/46936",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39186324/",
      "mesh_terms": "Humans; Machine Learning; Female; Male; Algorithms; Heart Diseases; Sex Factors",
      "keywords": "artificial intelligence; cardiac; cardiac disease; cardiology; health care; health equity; heart failure; inequality; machine learning; management; medicine; performance; quantitative evaluation; sex",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11384168"
    },
    {
      "pmid": "38876452",
      "title": "Identify and mitigate bias in electronic phenotyping: A comprehensive study from computational perspective.",
      "abstract": "Electronic phenotyping is a fundamental task that identifies the special group of patients, which plays an important role in precision medicine in the era of digital health. Phenotyping provides real-world evidence for other related biomedical research and clinical tasks, e.g., disease diagnosis, drug development, and clinical trials, etc. With the development of electronic health records, the performance of electronic phenotyping has been significantly boosted by advanced machine learning techniques. In the healthcare domain, precision and fairness are both essential aspects that should be taken into consideration. However, most related efforts are put into designing phenotyping models with higher accuracy. Few attention is put on the fairness perspective of phenotyping. The neglection of bias in phenotyping leads to subgroups of patients being underrepresented which will further affect the following healthcare activities such as patient recruitment in clinical trials. In this work, we are motivated to bridge this gap through a comprehensive experimental study to identify the bias existing in electronic phenotyping models and evaluate the widely-used debiasing methods' performance on these models. We choose pneumonia and sepsis as our phenotyping target diseases. We benchmark 9 kinds of electronic phenotyping methods spanning from rule-based to data-driven methods. Meanwhile, we evaluate the performance of the 5 bias mitigation strategies covering pre-processing, in-processing, and post-processing. Through the extensive experiments, we summarize several insightful findings from the bias identified in the phenotyping and key points of the bias mitigation strategies in phenotyping.",
      "authors": "Ding Sirui; Zhang Shenghan; Hu Xia; Zou Na",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2024.104671",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38876452/",
      "mesh_terms": "Bias; Benchmarking; Data Mining; Electronic Health Records; Algorithms; Pneumonia; Sepsis; Cohort Studies; Machine Learning; Phenotype; Humans; Male; Female; Racial Groups; Sex Factors; Datasets as Topic",
      "keywords": "Algorithm fairness; Bias mitigation; Electronic phenotyping; Fairness in healthcare",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33713239",
      "title": "Towards a pragmatist dealing with algorithmic bias in medical machine learning.",
      "abstract": "Machine Learning (ML) is on the rise in medicine, promising improved diagnostic, therapeutic and prognostic clinical tools. While these technological innovations are bound to transform health care, they also bring new ethical concerns to the forefront. One particularly elusive challenge regards discriminatory algorithmic judgements based on biases inherent in the training data. A common line of reasoning distinguishes between justified differential treatments that mirror true disparities between socially salient groups, and unjustified biases which do not, leading to misdiagnosis and erroneous treatment. In the curation of training data this strategy runs into severe problems though, since distinguishing between the two can be next to impossible. We thus plead for a pragmatist dealing with algorithmic bias in healthcare environments. By recurring to a recent reformulation of William James's pragmatist understanding of truth, we recommend that, instead of aiming at a supposedly objective truth, outcome-based therapeutic usefulness should serve as the guiding principle for assessing ML applications in medicine.",
      "authors": "Starke Georg; De Clercq Eva; Elger Bernice S",
      "year": "2021",
      "journal": "Medicine, health care, and philosophy",
      "doi": "10.1007/s11019-021-10008-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33713239/",
      "mesh_terms": "Bias; Delivery of Health Care; Education, Medical; Humans; Machine Learning; Morals",
      "keywords": "Algorithmic bias; Artificial intelligence; Fairness; Machine learning; Philosophy of Science; Pragmatism",
      "pub_types": "Journal Article",
      "pmcid": "PMC7955212"
    },
    {
      "pmid": "38681759",
      "title": "Analyzing the Impact of Personalization on Fairness in Federated Learning for Healthcare.",
      "abstract": "As machine learning (ML) usage becomes more popular in the healthcare sector, there are also increasing concerns about potential biases and risks such as privacy. One countermeasure is to use federated learning (FL) to support collaborative learning without the need for patient data sharing across different organizations. However, the inherent heterogeneity of data distributions among participating FL parties poses challenges for exploring group fairness in FL. While personalization within FL can handle performance degradation caused by data heterogeneity, its influence on group fairness is not fully investigated. Therefore, the primary focus of this study is to rigorously assess the impact of personalized FL on group fairness in the healthcare domain, offering a comprehensive understanding of how personalized FL affects group fairness in clinical outcomes. We conduct an empirical analysis using two prominent real-world Electronic Health Records (EHR) datasets, namely eICU and MIMIC-IV. Our methodology involves a thorough comparison between personalized FL and two baselines: standalone training, where models are developed independently without FL collaboration, and standard FL, which aims to learn a global model via the FedAvg algorithm. We adopt Ditto as our personalized FL approach, which enables each client in FL to develop its own personalized model through multi-task learning. Our assessment is achieved through a series of evaluations, comparing the predictive performance (i.e., AUROC and AUPRC) and fairness gaps (i.e., EOPP, EOD, and DP) of these methods. Personalized FL demonstrates superior predictive accuracy and fairness over standalone training across both datasets. Nevertheless, in comparison with standard FL, personalized FL shows improved predictive accuracy but does not consistently offer better fairness outcomes. For instance, in the 24-h in-hospital mortality prediction task, personalized FL achieves an average EOD of 27.4% across racial groups in the eICU dataset and 47.8% in MIMIC-IV. In comparison, standard FL records a better EOD of 26.2% for eICU and 42.0% for MIMIC-IV, while standalone training yields significantly worse EOD of 69.4% and 54.7% on these datasets, respectively. Our analysis reveals that personalized FL has the potential to enhance fairness in comparison to standalone training, yet it does not consistently ensure fairness improvements compared to standard FL. Our findings also show that while personalization can improve fairness for more biased hospitals (i.e., hospitals having larger fairness gaps in standalone training), it can exacerbate fairness issues for less biased ones. These insights suggest that the integration of personalized FL with additional strategic designs could be key to simultaneously boosting prediction accuracy and reducing fairness disparities. The findings and opportunities outlined in this paper can inform the research agenda for future studies, to overcome the limitations and further advance health equity research.",
      "authors": "Wang Tongnian; Zhang Kai; Cai Jiannan; Gong Yanmin; Choo Kim-Kwang Raymond; Guo Yuanxiong",
      "year": "2024",
      "journal": "Journal of healthcare informatics research",
      "doi": "10.1007/s41666-024-00164-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38681759/",
      "mesh_terms": "",
      "keywords": "Federated learning; Group fairness; Health disparities; Personalization; Privacy",
      "pub_types": "Journal Article",
      "pmcid": "PMC11052754"
    },
    {
      "pmid": "38554069",
      "title": "The selective deployment of AI in healthcare: An ethical algorithm for algorithms.",
      "abstract": "Machine-learning algorithms have the potential to revolutionise diagnostic and prognostic tasks in health care, yet algorithmic performance levels can be materially worse for subgroups that have been underrepresented in algorithmic training data. Given this epistemic deficit, the inclusion of underrepresented groups in algorithmic processes can result in harm. Yet delaying the deployment of algorithmic systems until more equitable results can be achieved would avoidably and foreseeably lead to a significant number of unnecessary deaths in well-represented populations. Faced with this dilemma between equity and utility, we draw on two case studies involving breast cancer and melanoma to argue for the selective deployment of diagnostic and prognostic tools for some well-represented groups, even if this results in the temporary exclusion of underrepresented patients from algorithmic approaches. We argue that this approach is justifiable when the inclusion of underrepresented patients would cause them to be harmed. While the context of historic injustice poses a considerable challenge for the ethical acceptability of selective algorithmic deployment strategies, we argue that, at least for the case studies addressed in this article, the issue of historic injustice is better addressed through nonalgorithmic measures, including being transparent with patients about the nature of the current epistemic deficits, providing additional services to algorithmically excluded populations, and through urgent commitments to gather additional algorithmic training data from excluded populations, paving the way for universal algorithmic deployment that is accurate for all patient groups. These commitments should be supported by regulation and, where necessary, government funding to ensure that any delays for excluded groups are kept to the minimum. We offer an ethical algorithm for algorithms-showing when to ethically delay, expedite, or selectively deploy algorithmic systems in healthcare settings.",
      "authors": "Vandersluis Robert; Savulescu Julian",
      "year": "2024",
      "journal": "Bioethics",
      "doi": "10.1111/bioe.13281",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38554069/",
      "mesh_terms": "Humans; Algorithms; Female; Artificial Intelligence; Breast Neoplasms; Melanoma; Delivery of Health Care; Machine Learning; Social Justice; Prognosis",
      "keywords": "algorithm; artificial intelligence; bias; exclusion; machine learning; melanoma",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7616300"
    },
    {
      "pmid": "32574353",
      "title": "Latent bias and the implementation of artificial intelligence in medicine.",
      "abstract": "Increasing recognition of biases in artificial intelligence (AI) algorithms has motivated the quest to build fair models, free of biases. However, building fair models may be only half the challenge. A seemingly fair model could involve, directly or indirectly, what we call \"latent biases.\" Just as latent errors are generally described as errors \"waiting to happen\" in complex systems, latent biases are biases waiting to happen. Here we describe 3 major challenges related to bias in AI algorithms and propose several ways of managing them. There is an urgent need to address latent biases before the widespread implementation of AI algorithms in clinical practice.",
      "authors": "DeCamp Matthew; Lindvall Charlotta",
      "year": "2020",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaa094",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32574353/",
      "mesh_terms": "Algorithms; Artificial Intelligence; Bias; Decision Support Systems, Clinical; Humans; Prejudice",
      "keywords": "artificial intelligence; bias; clinical decision support; health informatics; machine learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7727353"
    },
    {
      "pmid": "40776043",
      "title": "Algorithmic Fairness in Machine Learning Prediction of Autism Using Electronic Health Records.",
      "abstract": "Efforts to improve early diagnosis of autism spectrum disorder (ASD) in children are beginning to use machine learning (ML) approaches applied to real-world clinical datasets, such as electronic health records (EHRs). However, sex-based disparities in ASD diagnosis highlight the need for fair prediction models that ensure equitable performance across demographic groups for ASD identification. This retrospective case-control study aimed to develop ML-based prediction models for ASD diagnosis using risk factors found in EHRs and assess their algorithmic fairness. The study cohorts included 70,803 children diagnosed with ASD and 212,409 matched controls without ASD. We built logistic regression and Xgboost models and evaluated their performance using standard metrics, including accuracy, recall, precision, F1-score, and area under the curve (AUC). To assess fairness, we examined model performance by sex and calculated fairness-specific metrics, such as equal opportunity (recall parity) and equalized odds, to identify potential biases in model predictions between boys and girls. Our results revealed significant fairness issues in ML models for ASD prediction using EHRs.",
      "authors": "Angell Amber M; Li Yongqiu; Bian Jiang; Parchment Camille; Yin Larry; Chamala Srikar; Hakimjavadi Hesamedin; Thompson Lindsay; Guo Yi",
      "year": "2025",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI251025",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40776043/",
      "mesh_terms": "Humans; Electronic Health Records; Machine Learning; Male; Female; Retrospective Studies; Case-Control Studies; Child; Autism Spectrum Disorder; Algorithms; Child, Preschool",
      "keywords": "Autism; electronic health records; predictive modeling",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37978250",
      "title": "Ethnic disparity in diagnosing asymptomatic bacterial vaginosis using machine learning.",
      "abstract": "While machine learning (ML) has shown great promise in medical diagnostics, a major challenge is that ML models do not always perform equally well among ethnic groups. This is alarming for women's health, as there are already existing health disparities that vary by ethnicity. Bacterial Vaginosis (BV) is a common vaginal syndrome among women of reproductive age and has clear diagnostic differences among ethnic groups. Here, we investigate the ability of four ML algorithms to diagnose BV. We determine the fairness in the prediction of asymptomatic BV using 16S rRNA sequencing data from Asian, Black, Hispanic, and white women. General purpose ML model performances vary based on ethnicity. When evaluating the metric of false positive or false negative rate, we find that models perform least effectively for Hispanic and Asian women. Models generally have the highest performance for white women and the lowest for Asian women. These findings demonstrate a need for improved methodologies to increase model fairness for predicting BV.",
      "authors": "Celeste Cameron; Ming Dion; Broce Justin; Ojo Diandra P; Drobina Emma; Louis-Jacques Adetola F; Gilbert Juan E; Fang Ruogu; Parker Ivana K",
      "year": "2023",
      "journal": "NPJ digital medicine",
      "doi": "10.1038/s41746-023-00953-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37978250/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10656445"
    },
    {
      "pmid": "33220494",
      "title": "An empirical characterization of fair machine learning for clinical risk prediction.",
      "abstract": "The use of machine learning to guide clinical decision making has the potential to worsen existing health disparities. Several recent works frame the problem as that of algorithmic fairness, a framework that has attracted considerable attention and criticism. However, the appropriateness of this framework is unclear due to both ethical as well as technical considerations, the latter of which include trade-offs between measures of fairness and model performance that are not well-understood for predictive models of clinical outcomes. To inform the ongoing debate, we conduct an empirical study to characterize the impact of penalizing group fairness violations on an array of measures of model performance and group fairness. We repeat the analysis across multiple observational healthcare databases, clinical outcomes, and sensitive attributes. We find that procedures that penalize differences between the distributions of predictions across groups induce nearly-universal degradation of multiple performance metrics within groups. On examining the secondary impact of these procedures, we observe heterogeneity of the effect of these procedures on measures of fairness in calibration and ranking across experimental conditions. Beyond the reported trade-offs, we emphasize that analyses of algorithmic fairness in healthcare lack the contextual grounding and causal awareness necessary to reason about the mechanisms that lead to health disparities, as well as about the potential of algorithmic fairness methods to counteract those mechanisms. In light of these limitations, we encourage researchers building predictive models for clinical use to step outside the algorithmic fairness frame and engage critically with the broader sociotechnical context surrounding the use of machine learning in healthcare.",
      "authors": "Pfohl Stephen R; Foryciarz Agata; Shah Nigam H",
      "year": "2021",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2020.103621",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33220494/",
      "mesh_terms": "Delivery of Health Care; Empirical Research; Machine Learning",
      "keywords": "Algorithmic fairness; Bias; Clinical risk prediction",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC7871979"
    },
    {
      "pmid": "38960729",
      "title": "Fair prediction of 2-year stroke risk in patients with atrial fibrillation.",
      "abstract": "OBJECTIVE: This study aims to develop machine learning models that provide both accurate and equitable predictions of 2-year stroke risk for patients with atrial fibrillation across diverse racial groups. MATERIALS AND METHODS: Our study utilized structured electronic health records (EHR) data from the All of Us Research Program. Machine learning models (LightGBM) were utilized to capture the relations between stroke risks and the predictors used by the widely recognized CHADS2 and CHA2DS2-VASc scores. We mitigated the racial disparity by creating a representative tuning set, customizing tuning criteria, and setting binary thresholds separately for subgroups. We constructed a hold-out test set that not only supports temporal validation but also includes a larger proportion of Black/African Americans for fairness validation. RESULTS: Compared to the original CHADS2 and CHA2DS2-VASc scores, significant improvements were achieved by modeling their predictors using machine learning models (Area Under the Receiver Operating Characteristic curve from near 0.70 to above 0.80). Furthermore, applying our disparity mitigation strategies can effectively enhance model fairness compared to the conventional cross-validation approach. DISCUSSION: Modeling CHADS2 and CHA2DS2-VASc risk factors with LightGBM and our disparity mitigation strategies achieved decent discriminative performance and excellent fairness performance. In addition, this approach can provide a complete interpretation of each predictor. These highlight its potential utility in clinical practice. CONCLUSIONS: Our research presents a practical example of addressing clinical challenges through the All of Us Research Program data. The disparity mitigation framework we proposed is adaptable across various models and data modalities, demonstrating broad potential in clinical informatics.",
      "authors": "Gao Jifan; Mar Philip; Tang Zheng-Zheng; Chen Guanhua",
      "year": "2024",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocae170",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38960729/",
      "mesh_terms": "Aged; Female; Humans; Male; Middle Aged; Atrial Fibrillation; Black or African American; Electronic Health Records; Machine Learning; Risk Assessment; Risk Factors; ROC Curve; Stroke; Racial Groups",
      "keywords": "atrial fibrillation; bias; fairness; machine learning; stroke",
      "pub_types": "Journal Article",
      "pmcid": "PMC11631105"
    },
    {
      "pmid": "33328054",
      "title": "Ethical limitations of algorithmic fairness solutions in health care machine learning.",
      "abstract": "",
      "authors": "McCradden Melissa D; Joshi Shalmali; Mazwi Mjaye; Anderson James A",
      "year": "2020",
      "journal": "The Lancet. Digital health",
      "doi": "10.1016/S2589-7500(20)30065-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33328054/",
      "mesh_terms": "Algorithms; Delivery of Health Care; Female; Health Equity; Humans; Machine Learning; Male; Models, Biological; Social Justice",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39731446",
      "title": "De-biasing the bias: methods for improving disparity assessments with noisy group measurements.",
      "abstract": "Health care decisions are increasingly informed by clinical decision support algorithms, but these algorithms may perpetuate or increase racial and ethnic disparities in access to and quality of health care. Further complicating the problem, clinical data often have missing or poor quality racial and ethnic information, which can lead to misleading assessments of algorithmic bias. We present novel statistical methods that allow for the use of probabilities of racial/ethnic group membership in assessments of algorithm performance and quantify the statistical bias that results from error in these imputed group probabilities. We propose a sensitivity analysis approach to estimating the statistical bias that allows practitioners to assess disparities in algorithm performance under a range of assumed levels of group probability error. We also prove theoretical bounds on the statistical bias for a set of commonly used fairness metrics and describe real-world scenarios where our theoretical results are likely to apply. We present a case study using imputed race and ethnicity from the modified Bayesian Improved First and Surname Geocoding algorithm for estimation of disparities in a clinical decision support algorithm used to inform osteoporosis treatment. Our novel methods allow policymakers to understand the range of potential disparities under a given algorithm even when race and ethnicity information is missing and to make informed decisions regarding the implementation of machine learning for clinical decision support.",
      "authors": "Wastvedt Solvejg; Snoke Joshua; Agniel Denis; Lai Julie; Elliott Marc N; Martino Steven C",
      "year": "2024",
      "journal": "Biometrics",
      "doi": "10.1093/biomtc/ujae155",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39731446/",
      "mesh_terms": "Humans; Algorithms; Bias; Bayes Theorem; Healthcare Disparities; Ethnicity; Osteoporosis; Racial Groups; Decision Support Systems, Clinical; Biometry; Models, Statistical",
      "keywords": "Bayesian improved surname geocoding; algorithmic fairness; race imputation; sensitivity analysis",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35727616",
      "title": "The Benefits of Crowdsourcing to Seed and Align an Algorithm in an mHealth Intervention for African American and Hispanic Adults: Survey Study.",
      "abstract": "BACKGROUND: The lack of publicly available and culturally relevant data sets on African American and bilingual/Spanish-speaking Hispanic adults' disease prevention and health promotion priorities presents a major challenge for researchers and developers who want to create and test personalized tools built on and aligned with those priorities. Personalization depends on prediction and performance data. A recommender system (RecSys) could predict the most culturally and personally relevant preventative health information and serve it to African American and Hispanic users via a novel smartphone app. However, early in a user's experience, a RecSys can face the \"cold start problem\" of serving untailored and irrelevant content before it learns user preferences. For underserved African American and Hispanic populations, who are consistently being served health content targeted toward the White majority, the cold start problem can become an example of algorithmic bias. To avoid this, a RecSys needs population-appropriate seed data aligned with the app's purposes. Crowdsourcing provides a means to generate population-appropriate seed data. OBJECTIVE: Our objective was to identify and test a method to address the lack of culturally specific preventative personal health data and sidestep the type of algorithmic bias inherent in a RecSys not trained in the population of focus. We did this by collecting a large amount of data quickly and at low cost from members of the population of focus, thereby generating a novel data set based on prevention-focused, population-relevant health goals. We seeded our RecSys with data collected anonymously from self-identified Hispanic and self-identified non-Hispanic African American/Black adult respondents, using Amazon Mechanical Turk (MTurk). METHODS: MTurk provided the crowdsourcing platform for a web-based survey in which respondents completed a personal profile and a health information-seeking assessment, and provided data on family health history and personal health history. Respondents then selected their top 3 health goals related to preventable health conditions, and for each goal, reviewed and rated the top 3 information returns by importance, personal utility, whether the item should be added to their personal health library, and their satisfaction with the quality of the information returned. This paper reports the article ratings because our intent was to assess the benefits of crowdsourcing to seed a RecSys. The analysis of the data from health goals will be reported in future papers. RESULTS: The MTurk crowdsourcing approach generated 985 valid responses from 485 (49%) self-identified Hispanic and 500 (51%) self-identified non-Hispanic African American adults over the course of only 64 days at a cost of US $6.74 per respondent. Respondents rated 92 unique articles to inform the RecSys. CONCLUSIONS: Researchers have options such as MTurk as a quick, low-cost means to avoid the cold start problem for algorithms and to sidestep bias and low relevance for an intended population of app users. Seeding a RecSys with responses from people like the intended users allows for the development of a digital health tool that can recommend information to users based on similar demography, health goals, and health history. This approach minimizes the potential, initial gaps in algorithm performance; allows for quicker algorithm refinement in use; and may deliver a better user experience to individuals seeking preventative health information to improve health and achieve health goals.",
      "authors": "Sehgal Neil Jay; Huang Shuo; Johnson Neil Mason; Dickerson John; Jackson Devlon; Baur Cynthia",
      "year": "2022",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/30216",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35727616/",
      "mesh_terms": "Adult; Black or African American; Algorithms; Crowdsourcing; Humans; Surveys and Questionnaires; Telemedicine",
      "keywords": "African American, Black, Latino, and Hispanic populations; MTurk; Mechanical Turk; RecSys; crowdsourcing; health information; health promotion; machine learning; mobile phone; prevention; public health informatics; recommender system",
      "pub_types": "Journal Article",
      "pmcid": "PMC9257620"
    },
    {
      "pmid": "38686337",
      "title": "Explainable machine learning for predicting conversion to neurological disease: Results from 52,939 medical records.",
      "abstract": "OBJECTIVE: This study assesses the application of interpretable machine learning modeling using electronic medical record data for the prediction of conversion to neurological disease. METHODS: A retrospective dataset of Cleveland Clinic patients diagnosed with Alzheimer's disease, amyotrophic lateral sclerosis, multiple sclerosis, or Parkinson's disease, and matched controls based on age, sex, race, and ethnicity was compiled. Individualized risk prediction models were created using eXtreme Gradient Boosting for each neurological disease at four timepoints in patient history. The prediction models were assessed for transparency and fairness. RESULTS: At timepoints 0-months, 12-months, 24-months, and 60-months prior to diagnosis, Alzheimer's disease models achieved the area under the receiver operating characteristic curve on a holdout test dataset of 0.794, 0.742, 0.709, and 0.645; amyotrophic lateral sclerosis of 0.883, 0.710, 0.658, and 0.620; multiple sclerosis of 0.922, 0.877, 0.849, and 0.781; and Parkinson's disease of 0.809, 0.738, 0.700, and 0.651, respectively. CONCLUSIONS: The results demonstrate that electronic medical records contain latent information that can be used for risk stratification for neurological disorders. In particular, patient-reported outcomes, sleep assessments, falls data, additional disease diagnoses, and longitudinal changes in patient health, such as weight change, are important predictors.",
      "authors": "Felix Christina; Johnston Joshua D; Owen Kelsey; Shirima Emil; Hinds Sidney R; Mandl Kenneth D; Milinovich Alex; Alberts Jay L",
      "year": "2024",
      "journal": "Digital health",
      "doi": "10.1177/20552076241249286",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38686337/",
      "mesh_terms": "",
      "keywords": "Machine learning; disease; elderly; medicine; neurology; personalized medicine; public health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11057348"
    },
    {
      "pmid": "41482239",
      "title": "Interpretable machine learning for cognitive impairment screening: Development and external validation of a clinical prediction model based on NHANES data.",
      "abstract": "BACKGROUND: Cognitive impairment in older adults poses a growing public health challenge, yet accessible screening tools remain limited. We aimed to develop and validate an interpretable machine learning model for cognitive impairment prediction by routinely collecting clinical data. METHODS: We analyzed 1061 participants from the U.S. National Health and Nutrition Examination Survey (NHANES 2011-2014). Feature selection combined multivariable regression, restricted cubic splines, and the Boruta algorithm to identify 40 clinical, demographic, and socioeconomic variables. Twelve machine learning models (including Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), and Random Forest (RF)) were trained and externally validated on NHANES 2001-2002 (n\u00a0=\u00a0531). Model performance was evaluated by area under the receiver operating characteristic curve (AUC-ROC), calibration (Brier score), accuracy, and sensitivity. Additionally, an assessment of fairness was conducted across racial subgroups. Interpretability was enhanced via SHapley Additive exPlanations (SHAP). RESULTS: The SVM model demonstrated optimal generalizability, achieving an external validation AUC of 0.8265 (95\u00a0%CI: 0.7867-0.8582) with sustained calibration (Brier score\u00a0=\u00a00.1703). Subgroup analyses showed no statistically significant AUC differences (all P\u00a0>\u00a00.05). SHAP analysis identified socioeconomic factors, systemic inflammation indices, and metabolic markers as key predictors. LIMITATIONS: Generalizability may be limited to U.S. populations, and unmeasured biomarkers (e.g., amyloid-\u03b2) could affect prediction accuracy. Subgroup analyses for minorities were constrained by sample size. CONCLUSION: Our interpretable prediction strategy enables rapid cognitive risk assessment using routine clinical data, providing a cost-effective decision support tool adaptable to electronic health record systems.",
      "authors": "Chen Kang; Yu Guran; Li Hao",
      "year": "2026",
      "journal": "Experimental gerontology",
      "doi": "10.1016/j.exger.2025.113019",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41482239/",
      "mesh_terms": "Humans; Cognitive Dysfunction; Male; Female; Aged; Nutrition Surveys; Machine Learning; Middle Aged; United States; ROC Curve; Support Vector Machine; Mass Screening; Area Under Curve; Aged, 80 and over",
      "keywords": "Cognitive impairment; Machine learning; NHANES; Prediction model; SHAP",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": ""
    },
    {
      "pmid": "39868946",
      "title": "AI for all: bridging data gaps in machine learning and health.",
      "abstract": "Artificial intelligence (AI) and its subset, machine learning, have tremendous potential to transform health care, medicine, and population health through improved diagnoses, treatments, and patient care. However, the effectiveness of these technologies hinges on the quality and diversity of the data used to train them. Many datasets currently used in machine learning are inherently biased and lack diversity, leading to inaccurate predictions that may perpetuate existing health disparities. This commentary highlights the challenges of biased datasets, the impact on marginalized communities, and the critical need for strategies to address these disparities throughout the research continuum. To overcome these challenges, it is essential to adopt more inclusive data collection practices, engage collaboratively with community stakeholders, and leverage innovative approaches like federated learning. These steps can help mitigate bias and enhance the accuracy and fairness of AI-assisted or informed\u00a0health care solutions. By addressing systemic biases embedded across research phases, we can build a better foundation for AI to enhance diagnostic and treatment capabilities and move society closer to the goal where improved health and\u00a0health care can be a fundamental right for all, and not just for some.",
      "authors": "Wang Monica L; Bertrand Kimberly A",
      "year": "2025",
      "journal": "Translational behavioral medicine",
      "doi": "10.1093/tbm/ibae075",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39868946/",
      "mesh_terms": "Humans; Machine Learning; Artificial Intelligence; Delivery of Health Care",
      "keywords": "artificial intelligence; data practices; disparities; health equity; inclusion; machine learning; medicine",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37992791",
      "title": "A transformer-based deep learning approach for fairly predicting post-liver transplant risk factors.",
      "abstract": "Liver transplantation is a life-saving procedure for patients with end-stage liver disease. There are two main challenges in liver transplant: finding the best matching patient for a donor and ensuring transplant equity among different subpopulations. The current MELD scoring system evaluates a patient's mortality risk if not receiving an organ within 90\u00a0days. However, the donor-patient matching should also consider post-transplant risk factors, such as cardiovascular disease, chronic rejection, etc., which are all common complications after transplant. Accurate prediction of these risk scores remains a significant challenge. In this study, we used predictive models to solve the above challenges. Specifically, we proposed a deep learning model to predict multiple risk factors after a liver transplant. By formulating it as a multi-task learning problem, the proposed deep neural network was trained to simultaneously predict the five post-transplant risks and achieve equal good performance by exploiting task-balancing techniques. We also proposed a novel fairness-achieving algorithm to ensure prediction fairness across different subpopulations. We used electronic health records of 160,360 liver transplant patients, including demographic information, clinical variables, and laboratory values, collected from the liver transplant records of the United States from 1987 to 2018. The model's performance was evaluated using various performance metrics such as AUROC and AUPRC. Our experiment results highlighted the success of our multi-task model in achieving task balance while maintaining accuracy. The model significantly reduced the task discrepancy by 39\u00a0%. Further application of the fairness-achieving algorithm substantially reduced fairness disparity among all sensitive attributes (gender, age group, and race/ethnicity) in each risk factor. It underlined the potency of integrating fairness considerations into the task-balancing framework, ensuring robust and fair predictions across multiple tasks and diverse demographic groups.",
      "authors": "Li Can; Jiang Xiaoqian; Zhang Kai",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2023.104545",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37992791/",
      "mesh_terms": "Humans; United States; Liver Transplantation; Deep Learning; Tissue Donors; Neural Networks, Computer; Risk Factors",
      "keywords": "Fairness; Liver transplantation; Multi-task learning; Risk prediction",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC11619923"
    },
    {
      "pmid": "38315667",
      "title": "Assessment of differentially private synthetic data for utility and fairness in end-to-end machine learning pipelines for tabular data.",
      "abstract": "Differentially private (DP) synthetic datasets are a solution for sharing data while preserving the privacy of individual data providers. Understanding the effects of utilizing DP synthetic data in end-to-end machine learning pipelines impacts areas such as health care and humanitarian action, where data is scarce and regulated by restrictive privacy laws. In this work, we investigate the extent to which synthetic data can replace real, tabular data in machine learning pipelines and identify the most effective synthetic data generation techniques for training and evaluating machine learning models. We systematically investigate the impacts of differentially private synthetic data on downstream classification tasks from the point of view of utility as well as fairness. Our analysis is comprehensive and includes representatives of the two main types of synthetic data generation algorithms: marginal-based and GAN-based. To the best of our knowledge, our work is the first that: (i) proposes a training and evaluation framework that does not assume that real data is available for testing the utility and fairness of machine learning models trained on synthetic data; (ii) presents the most extensive analysis of synthetic dataset generation algorithms in terms of utility and fairness when used for training machine learning models; and (iii) encompasses several different definitions of fairness. Our findings demonstrate that marginal-based synthetic data generators surpass GAN-based ones regarding model training utility for tabular data. Indeed, we show that models trained using data generated by marginal-based algorithms can exhibit similar utility to models trained using real data. Our analysis also reveals that the marginal-based synthetic data generated using AIM and MWEM PGM algorithms can train models that simultaneously achieve utility and fairness characteristics close to those obtained by models trained with real data.",
      "authors": "Pereira Mayana; Kshirsagar Meghana; Mukherjee Sumit; Dodhia Rahul; Lavista Ferres Juan; de Sousa Rafael",
      "year": "2024",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0297271",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38315667/",
      "mesh_terms": "Algorithms; Health Facilities; Interior Design and Furnishings; Knowledge; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10843030"
    },
    {
      "pmid": "39682584",
      "title": "Mitigating Algorithmic Bias in AI-Driven Cardiovascular Imaging for Fairer Diagnostics.",
      "abstract": "Background/Objectives: The research addresses algorithmic bias in deep learning models for cardiovascular risk prediction, focusing on fairness across demographic and socioeconomic groups to mitigate health disparities. It integrates fairness-aware algorithms, susceptible carrier-infected-recovered (SCIR) models, and interpretability frameworks to combine fairness with actionable AI insights supported by robust segmentation and classification metrics. Methods: The research utilised quantitative 3D/4D heart magnetic resonance imaging and tabular datasets from the Cardiac Atlas Project's (CAP) open challenges to explore AI-driven methodologies for mitigating algorithmic bias in cardiac imaging. The SCIR model, known for its robustness, was adapted with the Capuchin algorithm, adversarial debiasing, Fairlearn, and post-processing with equalised odds. The robustness of the SCIR model was further demonstrated in the fairness evaluation metrics, which included demographic parity, equal opportunity difference (0.037), equalised odds difference (0.026), disparate impact (1.081), and Theil Index (0.249). For interpretability, YOLOv5, Mask R-CNN, and ResNet18 were implemented with LIME and SHAP. Bias mitigation improved disparate impact (0.80 to 0.95), reduced equal opportunity difference (0.20 to 0.05), and decreased false favourable rates for males (0.0059 to 0.0033) and females (0.0096 to 0.0064) through balanced probability adjustment. Results: The SCIR model outperformed the SIR model (recovery rate: 1.38 vs 0.83) with a -10% transmission bias impact. Parameters (\u03b2=0.5, \u03b4=0.2, \u03b3=0.15) reduced susceptible counts to 2.53\u00d710-12 and increased recovered counts to 9.98 by t=50. YOLOv5 achieved high Intersection over Union (IoU) scores (94.8%, 93.7%, 80.6% for normal, severe, and abnormal cases). Mask R-CNN showed 82.5% peak confidence, while ResNet demonstrated a 10.4% accuracy drop under noise. Performance metrics (IoU: 0.91-0.96, Dice: 0.941-0.980, Kappa: 0.95) highlighted strong predictive accuracy and reliability. Conclusions: The findings validate the effectiveness of fairness-aware algorithms in addressing cardiovascular predictive model biases. The integration of fairness and explainable AI not only promotes equitable diagnostic precision but also significantly reduces diagnostic disparities across vulnerable populations. This reduction in disparities is a key outcome of the research, enhancing clinical trust in AI-driven systems. The promising results of this study pave the way for future work that will explore scalability in real-world clinical settings and address limitations such as computational complexity in large-scale data processing.",
      "authors": "Sufian Md Abu; Alsadder Lujain; Hamzi Wahiba; Zaman Sadia; Sagar A S M Sharifuzzaman; Hamzi Boumediene",
      "year": "2024",
      "journal": "Diagnostics (Basel, Switzerland)",
      "doi": "10.3390/diagnostics14232675",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39682584/",
      "mesh_terms": "",
      "keywords": "LIME; Mask R-CNN; ResNet-18; SCIR model; SHAP; YOLOv5; adversarial debiasing; algorithmic bias; cardiovascular risk prediction; demographic fairness; fairness-aware AI; predictive analytics",
      "pub_types": "Journal Article",
      "pmcid": "PMC11640708"
    },
    {
      "pmid": "35699997",
      "title": "Fairness in Mobile Phone-Based Mental Health Assessment Algorithms: Exploratory Study.",
      "abstract": "BACKGROUND: Approximately 1 in 5 American adults experience mental illness every year. Thus, mobile phone-based mental health prediction apps that use phone data and artificial intelligence techniques for mental health assessment have become increasingly important and are being rapidly developed. At the same time, multiple artificial intelligence-related technologies (eg, face recognition and search results) have recently been reported to be biased regarding age, gender, and race. This study moves this discussion to a new domain: phone-based mental health assessment algorithms. It is important to ensure that such algorithms do not contribute to gender disparities through biased predictions across gender groups. OBJECTIVE: This research aimed to analyze the susceptibility of multiple commonly used machine learning approaches for gender bias in mobile mental health assessment and explore the use of an algorithmic disparate impact remover (DIR) approach to reduce bias levels while maintaining high accuracy. METHODS: First, we performed preprocessing and model training using the data set (N=55) obtained from a previous study. Accuracy levels and differences in accuracy across genders were computed using 5 different machine learning models. We selected the random forest model, which yielded the highest accuracy, for a more detailed audit and computed multiple metrics that are commonly used for fairness in the machine learning literature. Finally, we applied the DIR approach to reduce bias in the mental health assessment algorithm. RESULTS: The highest observed accuracy for the mental health assessment was 78.57%. Although this accuracy level raises optimism, the audit based on gender revealed that the performance of the algorithm was statistically significantly different between the male and female groups (eg, difference in accuracy across genders was 15.85%; P<.001). Similar trends were obtained for other fairness metrics. This disparity in performance was found to reduce significantly after the application of the DIR approach by adapting the data used for modeling (eg, the difference in accuracy across genders was 1.66%, and the reduction is statistically significant with P<.001). CONCLUSIONS: This study grounds the need for algorithmic auditing in phone-based mental health assessment algorithms and the use of gender as a protected attribute to study fairness in such settings. Such audits and remedial steps are the building blocks for the widespread adoption of fair and accurate mental health assessment algorithms in the future.",
      "authors": "Park Jinkyung; Arunachalam Ramanathan; Silenzio Vincent; Singh Vivek K",
      "year": "2022",
      "journal": "JMIR formative research",
      "doi": "10.2196/34366",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35699997/",
      "mesh_terms": "",
      "keywords": "algorithmic bias; gender bias; health equity; health information systems; medical informatics; mental health; mobile phone",
      "pub_types": "Journal Article",
      "pmcid": "PMC9240929"
    },
    {
      "pmid": "37827839",
      "title": "Ethical Considerations for Artificial Intelligence in Medical Imaging: Data Collection, Development, and Evaluation.",
      "abstract": "The development of artificial intelligence (AI) within nuclear imaging involves several ethically fraught components at different stages of the machine learning pipeline, including during data collection, model training and validation, and clinical use. Drawing on the traditional principles of medical and research ethics, and highlighting the need to ensure health justice, the AI task force of the Society of Nuclear Medicine and Molecular Imaging has identified 4 major ethical risks: privacy of data subjects, data quality and model efficacy, fairness toward marginalized populations, and transparency of clinical performance. We provide preliminary recommendations to developers of AI-driven medical devices for mitigating the impact of these risks on patients and populations.",
      "authors": "Herington Jonathan; McCradden Melissa D; Creel Kathleen; Boellaard Ronald; Jones Elizabeth C; Jha Abhinav K; Rahmim Arman; Scott Peter J H; Sunderland John J; Wahl Richard L; Zuehlsdorff Sven; Saboury Babak",
      "year": "2023",
      "journal": "Journal of nuclear medicine : official publication, Society of Nuclear Medicine",
      "doi": "10.2967/jnumed.123.266080",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37827839/",
      "mesh_terms": "Humans; Artificial Intelligence; Data Collection; Machine Learning; Advisory Committees; Molecular Imaging",
      "keywords": "AI as medical device; AI ethics; health disparity; socioeconomic determinants of health; software as medical device",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10690124"
    },
    {
      "pmid": "37097792",
      "title": "Post-Processing Fairness Evaluation of Federated Models: An Unsupervised Approach in Healthcare.",
      "abstract": "Modern Healthcare cyberphysical systems have begun to rely more and more on distributed AI leveraging the power of Federated Learning (FL). Its ability to train Machine Learning (ML) and Deep Learning (DL) models for the wide variety of medical fields, while at the same time fortifying the privacy of the sensitive information that are present in the medical sector, makes the FL technology a necessary tool in modern health and medical systems. Unfortunately, due to the polymorphy of distributed data and the shortcomings of distributed learning, the local training of Federated models sometimes proves inadequate and thus negatively imposes the federated learning optimization process and in extend in the subsequent performance of the rest Federated models. Badly trained models can cause dire implications in the healthcare field due to their critical nature. This work strives to solve this problem by applying a post-processing pipeline to models used by FL. In particular, the proposed work ranks the model by finding how fair they are by discovering and inspecting micro-Manifolds that cluster each neural model's latent knowledge. The produced work applies a completely unsupervised both model and data agnostic methodology that can be leveraged for general model fairness discovery. The proposed methodology is tested against a variety of benchmark DL architectures and in the FL environment, showing an average 8.75% increase in Federated model accuracy in comparison with similar work.",
      "authors": "Siniosoglou Ilias; Argyriou Vasileios; Sarigiannidis Panagiotis; Lagkas Thomas; Sarigiannidis Antonios; Goudos Sotirios K; Wan Shaohua",
      "year": "2023",
      "journal": "IEEE/ACM transactions on computational biology and bioinformatics",
      "doi": "10.1109/TCBB.2023.3269767",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37097792/",
      "mesh_terms": "Benchmarking; Machine Learning; Delivery of Health Care",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "34830566",
      "title": "Artificial Intelligence, Heuristic Biases, and the Optimization of Health Outcomes: Cautionary Optimism.",
      "abstract": "The use of artificial intelligence (AI) and machine learning (ML) in clinical care offers great promise to improve patient health outcomes and reduce health inequity across patient populations. However, inherent biases in these applications, and the subsequent potential risk of harm can limit current use. Multi-modal workflows designed to minimize these limitations in the development, implementation, and evaluation of ML systems in real-world settings are needed to improve efficacy while reducing bias and the risk of potential harms. Comprehensive consideration of rapidly evolving AI technologies and the inherent risks of bias, the expanding volume and nature of data sources, and the evolving regulatory landscapes, can contribute meaningfully to the development of AI-enhanced clinical decision making and the reduction in health inequity.",
      "authors": "Feehan Michael; Owen Leah A; McKinnon Ian M; DeAngelis Margaret M",
      "year": "2021",
      "journal": "Journal of clinical medicine",
      "doi": "10.3390/jcm10225284",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34830566/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; bias; electronic health record; health outcomes; heuristics; machine learning; ophthalmology; population health",
      "pub_types": "Journal Article",
      "pmcid": "PMC8620813"
    },
    {
      "pmid": "38554626",
      "title": "Comparing survival of older ovarian cancer patients treated with neoadjuvant chemotherapy versus primary cytoreductive surgery: Reducing bias through machine learning.",
      "abstract": "OBJECTIVE: To develop and evaluate a multidimensional comorbidity index (MCI) that identifies ovarian cancer patients at risk of early mortality more accurately than the Charlson Comorbidity Index (CCI) for use in health services research. METHODS: We utilized SEER-Medicare data to identify patients with stage IIIC and IV ovarian cancer, diagnosed in 2010-2015. We employed partial least squares regression, a supervised machine learning algorithm, to develop the MCI by extracting latent factors that optimally captured the variation in health insurance claims made in the year preceding cancer diagnosis, and 1-year mortality. We assessed the discrimination and calibration of the MCI for 1-year mortality and compared its performance to the commonly-used CCI. Finally, we evaluated the MCI's ability to reduce confounding in the association of neoadjuvant chemotherapy (NACT) and all-cause mortality. RESULTS: We included 4723 patients in the development cohort and 933 in the validation cohort. The MCI demonstrated good discrimination for 1-year mortality (c-index: 0.75, 95% CI: 0.72-0.79), while the CCI had poor discrimination (c-index: 0.59, 95% CI: 0.56-0.63). Calibration plots showed better agreement between predicted and observed 1-year mortality risk for the MCI compared with CCI. When comparing all-cause mortality between NACT with primary cytoreductive surgery, NACT was associated with a higher hazard of death (HR: 1.13, 95% CI: 1.04-1.23) after controlling for tumor characteristics, demographic factors, and the CCI. However, when controlling for the MCI instead of the CCI, there was no longer a significant difference (HR: 1.05, 95% CI: 0.96-1.14). CONCLUSIONS: The MCI outperformed the conventional CCI in predicting 1-year mortality, and reducing confounding due to differences in baseline health status in comparative effectiveness analysis of NACT versus primary surgery.",
      "authors": "Huang Yongmei; Rauh-Hain J Alejandro; McCoy Thomas H; Hou June Y; Hillyer Grace; Ferris Jennifer S; Hershman Dawn; Wright Jason D; Melamed Alexander",
      "year": "2024",
      "journal": "Gynecologic oncology",
      "doi": "10.1016/j.ygyno.2024.03.016",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38554626/",
      "mesh_terms": "Humans; Female; Cytoreduction Surgical Procedures; Neoadjuvant Therapy; Aged; Ovarian Neoplasms; Machine Learning; SEER Program; Aged, 80 and over; United States; Chemotherapy, Adjuvant; Bias; Carcinoma, Ovarian Epithelial; Neoplasm Staging; Medicare",
      "keywords": "All-cause mortality; Machine learning; Multidimensional comorbidity index; Neoadjuvant chemotherapy; Primary cytoreductive surgery",
      "pub_types": "Journal Article; Comparative Study; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "35308985",
      "title": "Data and Model Biases in Social Media Analyses: A Case Study of COVID-19 Tweets.",
      "abstract": "During the coronavirus disease pandemic (COVID-19), social media platforms such as Twitter have become a venue for individuals, health professionals, and government agencies to share COVID-19 information. Twitter has been a popular source of data for researchers, especially for public health studies. However, the use of Twitter data for research also has drawbacks and barriers. Biases appear everywhere from data collection methods to modeling approaches, and those biases have not been systematically assessed. In this study, we examined six different data collection methods and three different machine learning (ML) models-commonly used in social media analysis-to assess data collection bias and measure ML models' sensitivity to data collection bias. We showed that (1) publicly available Twitter data collection endpoints with appropriate strategies can collect data that is reasonably representative of the Twitter universe; and (2) careful examinations of ML models' sensitivity to data collection bias are critical.",
      "authors": "Zhao Yunpeng; Yin Pengfei; Li Yongqiu; He Xing; Du Jingcheng; Tao Cui; Guo Yi; Prosperi Mattia; Veltri Pierangelo; Yang Xi; Wu Yonghui; Bian Jiang",
      "year": "2021",
      "journal": "AMIA ... Annual Symposium proceedings. AMIA Symposium",
      "doi": "10.1145/3400806.3400839",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35308985/",
      "mesh_terms": "Bias; COVID-19; Data Collection; Humans; Machine Learning; Social Media",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC8861742"
    },
    {
      "pmid": "38106012",
      "title": "A Fair Individualized Polysocial Risk Score for Identifying Increased Social Risk in Type 2 Diabetes.",
      "abstract": "BACKGROUND: Racial and ethnic minority groups and individuals facing social disadvantages, which often stem from their social determinants of health (SDoH), bear a disproportionate burden of type 2 diabetes (T2D) and its complications. It is crucial to implement effective social risk management strategies at the point of care. OBJECTIVE: To develop an electronic health records (EHR)-based machine learning (ML) analytical pipeline to address unmet social needs associated with hospitalization risk in patients with T2D. METHODS: We identified real-world patients with T2D from the EHR data from University of Florida (UF) Health Integrated Data Repository (IDR), incorporating both contextual SDoH (e.g., neighborhood deprivation) and individual-level SDoH (e.g., housing instability). The 2015-2020 data were used for training and validation and 2021-2022 data for independent testing. We developed a machine learning analytic pipeline, namely individualized polysocial risk score (iPsRS), to identify high social risk associated with hospitalizations in T2D patients, along with explainable AI (XAI) and fairness optimization. RESULTS: The study cohort included 10,192 real-world patients with T2D, with a mean age of 59 years and 58% female. Of the cohort, 50% were non-Hispanic White, 39% were non-Hispanic Black, 6% were Hispanic, and 5% were other races/ethnicities. Our iPsRS, including both contextual and individual-level SDoH as input factors, achieved a C statistic of 0.72 in predicting 1-year hospitalization after fairness optimization across racial and ethnic groups. The iPsRS showed excellent utility for capturing individuals at high hospitalization risk because of SDoH, that is, the actual 1-year hospitalization rate in the top 5% of iPsRS was 28.1%, ~13 times as high as the bottom decile (2.2% for 1-year hospitalization rate). CONCLUSION: Our ML pipeline iPsRS can fairly and accurately screen for patients who have increased social risk leading to hospitalization in real word patients with T2D.",
      "authors": "Huang Yu; Guo Jingchuan; Donahoo William T; Fan Zhengkang; Lu Ying; Chen Wei-Han; Tang Huilin; Bilello Lori; Saguil Aaron A; Rosenberg Eric; Shenkman Elizabeth A; Bian Jiang",
      "year": "2023",
      "journal": "Research square",
      "doi": "10.21203/rs.3.rs-3684698/v1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38106012/",
      "mesh_terms": "",
      "keywords": "Fairness; Machine Learning; Machine learning; Prediction; Type 2 diabetes",
      "pub_types": "Preprint; Journal Article",
      "pmcid": "PMC10723535"
    },
    {
      "pmid": "31278181",
      "title": "Benefits, Pitfalls, and Potential Bias in Health Care AI.",
      "abstract": "As the health care industry adopts artificial intelligence, machine learning, and other modeling techniques, it is seeing benefits to both patient outcomes and cost reduction; however, it needs to be cognizant of and ensure proper management of the risks, including bias. Lessons learned from other industries may provide a framework for acknowledging and managing data, machine, and human biases that arise while implementing AI.",
      "authors": "Hague Douglas C",
      "year": "2019",
      "journal": "North Carolina medical journal",
      "doi": "10.18043/ncm.80.4.219",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31278181/",
      "mesh_terms": "Artificial Intelligence; Bias; Data Analysis; Delivery of Health Care; Humans; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39369018",
      "title": "A fair individualized polysocial risk score for identifying increased social risk in type 2 diabetes.",
      "abstract": "Racial and ethnic minorities bear a disproportionate burden of type 2 diabetes (T2D) and its complications, with social determinants of health (SDoH) recognized as key drivers of these disparities. Implementing efficient and effective social needs management strategies is crucial. We propose a machine learning analytic pipeline to calculate the individualized polysocial risk score (iPsRS), which can identify T2D patients at high social risk for hospitalization, incorporating explainable AI techniques and algorithmic fairness optimization. We use electronic health records (EHR) data from T2D patients in the University of Florida Health Integrated Data Repository, incorporating both contextual SDoH (e.g., neighborhood deprivation) and person-level SDoH (e.g., housing instability). After fairness optimization across racial and ethnic groups, the iPsRS achieved a C statistic of 0.71 in predicting 1-year hospitalization. Our iPsRS can fairly and accurately screen patients with T2D who are at increased social risk for hospitalization.",
      "authors": "Huang Yu; Guo Jingchuan; Donahoo William T; Lee Yao An; Fan Zhengkang; Lu Ying; Chen Wei-Han; Tang Huilin; Bilello Lori; Saguil Aaron A; Rosenberg Eric; Shenkman Elizabeth A; Bian Jiang",
      "year": "2024",
      "journal": "Nature communications",
      "doi": "10.1038/s41467-024-52960-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39369018/",
      "mesh_terms": "Adult; Aged; Female; Humans; Male; Middle Aged; Diabetes Mellitus, Type 2; Electronic Health Records; Ethnicity; Florida; Hospitalization; Machine Learning; Risk Assessment; Risk Factors; Social Determinants of Health; Racial Groups",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11455957"
    },
    {
      "pmid": "35728803",
      "title": "Reducing Nonresponse and Data Linkage Consent Bias in Large-Scale Panel Surveys.",
      "abstract": "Selection bias is an ongoing concern in large-scale panel surveys where the cumulative effects of unit nonresponse increase at each subsequent wave of\u00a0data collection. A second source of selection bias in panel studies is the inability to link respondents to supplementary administrative records, either because respondents do not consent to link or the matching algorithm fails to locate their administrative records. Both sources of selection bias can affect the validity of conclusions drawn from these data sources. In this article, I discuss recently proposed methods of reducing both sources of selection bias in panel studies, with a special emphasis on reducing selection bias in the US Health and Retirement Study.",
      "authors": "Sakshaug Joseph W",
      "year": "2022",
      "journal": "Forum for health economics & policy",
      "doi": "10.1515/fhep-2021-0060",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35728803/",
      "mesh_terms": "Bias; Surveys and Questionnaires; Selection Bias; Longitudinal Studies; Information Storage and Retrieval",
      "keywords": "health and retirement study; post-survey adjustments; questionnaire design; selection bias",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38322109",
      "title": "Accelerating health disparities research with artificial intelligence.",
      "abstract": "",
      "authors": "Green B Lee; Murphy Anastasia; Robinson Edmondo",
      "year": "2024",
      "journal": "Frontiers in digital health",
      "doi": "10.3389/fdgth.2024.1330160",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38322109/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; bias; equity; health disparities; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC10844447"
    },
    {
      "pmid": "41286153",
      "title": "Personalized fitness recommendations using machine learning for optimized national health strategy.",
      "abstract": "Rising concerns over public health and chronic disease prevalence have intensified the demand for data-driven, personalized fitness interventions. While national health programs offer general guidelines, they often lack the granularity required to address individual variability in health status, lifestyle, and demographic context. This paper presents a machine learning framework to generate personalized fitness recommendations aligned with national health goals. Leveraging population-scale data, the aim is to optimize physical activity planning while maintaining fairness and clinical relevance across demographic subgroups. The study utilizes the National Health and Nutrition Examination Survey (NHANES) dataset, integrating biometric, behavioral, and demographic features. To enhance the behavioral relevance of our predictions, we integrated supplemental variables from the Behavioral Risk Factor Surveillance System (BRFSS), capturing psychological, motivational, and environmental factors that influence physical activity adherence. After preprocessing, models were developed using XGBoost, Decision Trees, and Artificial Neural Networks. Both regression (to estimate weekly activity minutes) and classification (to assign risk groups) tasks were addressed. Performance was evaluated through MeanIoU, Dice Score, sensitivity, and specificity. Demographic fairness was assessed via subgroup residuals and fairness gap analysis. XGBoost achieved superior performance, with a MeanIoU of 0.789 and F1 scores exceeding 0.79 across all risk categories. Model consistency was observed across age, gender, and ethnicity, with fairness gaps below 0.05. Residual error analysis and risk classification confirmed high reliability and low variance. The proposed system demonstrates the feasibility of using AI to personalize fitness plans at scale. It offers a pathway to integrate precision fitness with national policy, supporting equitable and effective public health strategies.",
      "authors": "Chen Juan; Wang Yan",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-25566-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41286153/",
      "mesh_terms": "Humans; Machine Learning; Male; Female; Middle Aged; Adult; Nutrition Surveys; Exercise; Physical Fitness; Precision Medicine; Aged; Young Adult",
      "keywords": "Machine learning; NHANES; Personalized fitness recommendations; Physical activity prediction; Public health strategy; Risk classification; XGBoost",
      "pub_types": "Journal Article",
      "pmcid": "PMC12645047"
    },
    {
      "pmid": "32585698",
      "title": "Patient safety and quality improvement: Ethical principles for a regulatory approach to bias in healthcare machine learning.",
      "abstract": "Accumulating evidence demonstrates the impact of bias that reflects social inequality on the performance of machine learning (ML) models in health care. Given their intended placement within healthcare decision making more broadly, ML tools require attention to adequately quantify the impact of bias and reduce its potential to exacerbate inequalities. We suggest that taking a patient safety and quality improvement approach to bias can support the quantification of bias-related effects on ML. Drawing from the ethical principles underpinning these approaches, we argue that patient safety and quality improvement lenses support the quantification of relevant performance metrics, in order to minimize harm while promoting accountability, justice, and transparency. We identify specific methods for operationalizing these principles with the goal of attending to bias to support better decision making in light of controllable and uncontrollable factors.",
      "authors": "McCradden Melissa D; Joshi Shalmali; Anderson James A; Mazwi Mjaye; Goldenberg Anna; Zlotnik Shaul Randi",
      "year": "2020",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaa085",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32585698/",
      "mesh_terms": "Artificial Intelligence; Data Collection; Government Regulation; Healthcare Disparities; Humans; Patient Safety; Prejudice; Quality Improvement; Social Determinants of Health",
      "keywords": "healthcare delivery; machine learning; patient safety; quality improvement; systematic bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC7727331"
    },
    {
      "pmid": "40095575",
      "title": "Shaping the Future of Healthcare: Ethical Clinical Challenges and Pathways to Trustworthy AI.",
      "abstract": "Background/Objectives: Artificial intelligence (AI) is transforming healthcare, enabling advances in diagnostics, treatment optimization, and patient care. Yet, its integration raises ethical, regulatory, and societal challenges. Key concerns include data privacy risks, algorithmic bias, and regulatory gaps that struggle to keep pace with AI advancements. This study aims to synthesize a multidisciplinary framework for trustworthy AI in healthcare, focusing on transparency, accountability, fairness, sustainability, and global collaboration. It moves beyond high-level ethical discussions to provide actionable strategies for implementing trustworthy AI in clinical contexts. Methods: A structured literature review was conducted using PubMed, Scopus, and Web of Science. Studies were selected based on relevance to AI ethics, governance, and policy in healthcare, prioritizing peer-reviewed articles, policy analyses, case studies, and ethical guidelines from authoritative sources published within the last decade. The conceptual approach integrates perspectives from clinicians, ethicists, policymakers, and technologists, offering a holistic \"ecosystem\" view of AI. No clinical trials or patient-level interventions were conducted. Results: The analysis identifies key gaps in current AI governance and introduces the Regulatory Genome-an adaptive AI oversight framework aligned with global policy trends and Sustainable Development Goals. It introduces quantifiable trustworthiness metrics, a comparative analysis of AI categories for clinical applications, and bias mitigation strategies. Additionally, it presents interdisciplinary policy recommendations for aligning AI deployment with ethical, regulatory, and environmental sustainability goals. This study emphasizes measurable standards, multi-stakeholder engagement strategies, and global partnerships to ensure that future AI innovations meet ethical and practical healthcare needs. Conclusions: Trustworthy AI in healthcare requires more than technical advancements-it demands robust ethical safeguards, proactive regulation, and continuous collaboration. By adopting the recommended roadmap, stakeholders can foster responsible innovation, improve patient outcomes, and maintain public trust in AI-driven healthcare.",
      "authors": "Goktas Polat; Grzybowski Andrzej",
      "year": "2025",
      "journal": "Journal of clinical medicine",
      "doi": "10.3390/jcm14051605",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40095575/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; bias; ethics; health policy; large language model; machine learning; natural language processing; privacy; regulation",
      "pub_types": "Journal Article",
      "pmcid": "PMC11900311"
    },
    {
      "pmid": "37463884",
      "title": "Detecting shortcut learning for fair medical AI using shortcut testing.",
      "abstract": "Machine learning (ML) holds great promise for improving healthcare, but it is critical to ensure that its use will not propagate or amplify health disparities. An important step is to characterize the (un)fairness of ML models-their tendency to perform differently across subgroups of the population-and to understand its underlying mechanisms. One potential driver of algorithmic unfairness, shortcut learning, arises when ML models base predictions on improper correlations in the training data. Diagnosing this phenomenon is difficult as sensitive attributes may be causally linked with disease. Using multitask learning, we propose a method to directly test for the presence of shortcut learning in clinical ML systems and demonstrate its application to clinical tasks in radiology and dermatology. Finally, our approach reveals instances when shortcutting is not responsible for unfairness, highlighting the need for a holistic approach to fairness mitigation in medical AI.",
      "authors": "Brown Alexander; Tomasev Nenad; Freyberg Jan; Liu Yuan; Karthikesalingam Alan; Schrouff Jessica",
      "year": "2023",
      "journal": "Nature communications",
      "doi": "10.1038/s41467-023-39902-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37463884/",
      "mesh_terms": "Health Facilities; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10354021"
    },
    {
      "pmid": "37819812",
      "title": "Bipartite Ranking Fairness Through a Model Agnostic Ordering Adjustment.",
      "abstract": "Recently, with the applications of algorithms in various risky scenarios, algorithmic fairness has been a serious concern and received lots of interest in machine learning community. In this article, we focus on the bipartite ranking scenario, where the instances come from either the positive or negative class and the goal is to learn a ranking function that ranks positive instances higher than negative ones. We are interested in whether the learned ranking function can cause systematic disparity across different protected groups defined by sensitive attributes. While there could be a trade-off between fairness and performance, we propose a model agnostic post-processing framework xOrder for achieving fairness in bipartite ranking and maintaining the algorithm classification performance. In particular, we optimize a weighted sum of the utility as identifying an optimal warping path across different protected groups and solve it through a dynamic programming process. xOrder is compatible with various classification models and ranking fairness metrics, including supervised and unsupervised fairness metrics. In addition to binary groups, xOrder can be applied to multiple protected groups. We evaluate our proposed algorithm on four benchmark data sets and two real-world patient electronic health record repositories. xOrder consistently achieves a better balance between the algorithm utility and ranking fairness on a variety of datasets with different metrics. From the visualization of the calibrated ranking scores, xOrder mitigates the score distribution shifts of different groups compared with baselines. Moreover, additional analytical results verify that xOrder achieves a robust performance when faced with fewer samples and a bigger difference between training and testing ranking score distributions.",
      "authors": "Cui Sen; Pan Weishen; Zhang Changshui; Wang Fei",
      "year": "2023",
      "journal": "IEEE transactions on pattern analysis and machine intelligence",
      "doi": "10.1109/TPAMI.2023.3290949",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37819812/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41459572",
      "title": "Machine learning-based mortality prediction in critically ill patients with hypertension: comparative analysis, fairness, and interpretability.",
      "abstract": "BACKGROUND: Hypertension is a leading global health concern, significantly contributing to cardiovascular, cerebrovascular, and renal diseases. In critically ill patients, hypertension poses increased risks of complications and mortality. Early and accurate mortality prediction in this population is essential for timely intervention and improved outcomes. Machine learning (ML) and deep learning (DL) approaches offer promising solutions by leveraging high-dimensional electronic health record (EHR) data. OBJECTIVE: To develop and evaluate ML and DL models for predicting in-hospital mortality in hypertensive patients using the MIMIC-IV critical care dataset, and to assess the fairness and interpretability of the models. METHODS: We developed four ML models-gradient boosting machine (GBM), logistic regression, support vector machine (SVM), and random forest-and two DL models-multilayer perceptron (MLP) and long short-term memory (LSTM). A comprehensive set of features, including demographics, lab values, vital signs, comorbidities, and ICU-specific variables, were extracted or engineered. Models were trained using 5-fold cross-validation and evaluated on a separate test set. Feature importance was analyzed using SHapley Additive exPlanations (SHAP) values, and fairness was assessed using demographic parity difference (DPD) and equalized odds difference (EOD), with and without the application of debiasing techniques. RESULTS: The GBM model outperformed all other models, with an AUC-ROC score of 96.3%, accuracy of 89.4%, sensitivity of 87.8%, specificity of 90.7%, and F1 score of 89.2%. Key features contributing to mortality prediction included Glasgow Coma Scale (GCS) scores, Braden Scale scores, blood urea nitrogen, age, red cell distribution width (RDW), bicarbonate, and lactate levels. Fairness analysis revealed that models trained on the top 30 most important features demonstrated lower DPD and EOD, suggesting reduced bias. Debiasing methods improved fairness in models trained with all features but had limited effects on models using the top 30 features. CONCLUSION: ML models show strong potential for mortality prediction in critically ill hypertensive patients. Feature selection not only enhances interpretability and reduces computational complexity but may also contribute to improved model fairness. These findings support the integration of interpretable and equitable AI tools in critical care settings to assist with clinical decision-making.",
      "authors": "Zhang Shenghan; Ding Sirui; Xu Zidu; Ye Jiancheng",
      "year": "2025",
      "journal": "Frontiers in artificial intelligence",
      "doi": "10.3389/frai.2025.1686378",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41459572/",
      "mesh_terms": "",
      "keywords": "SHAP; deep learning; fairness in AI; hypertension; intensive care unit; machine learning; mortality prediction",
      "pub_types": "Journal Article",
      "pmcid": "PMC12738824"
    },
    {
      "pmid": "39705068",
      "title": "Early Attrition Prediction for Web-Based Interpretation Bias Modification to Reduce Anxious Thinking: A Machine Learning Study.",
      "abstract": "BACKGROUND: Digital mental health is a promising paradigm for individualized, patient-driven health care. For example, cognitive bias modification programs that target interpretation biases (cognitive bias modification for interpretation [CBM-I]) can provide practice thinking about ambiguous situations in less threatening ways on the web without requiring a therapist. However, digital mental health interventions, including CBM-I, are often plagued with lack of sustained engagement and high attrition rates. New attrition detection and mitigation strategies are needed to improve these interventions. OBJECTIVE: This paper aims to identify participants at a high risk of dropout during the early stages of 3 web-based trials of multisession CBM-I and to investigate which self-reported and passively detected feature sets computed from the participants interacting with the intervention and assessments were most informative in making this prediction. METHODS: The participants analyzed in this paper were community adults with traits such as anxiety or negative thinking about the future (Study 1: n=252, Study 2: n=326, Study 3: n=699) who had been assigned to CBM-I conditions in 3 efficacy-effectiveness trials on our team's public research website. To identify participants at a high risk of dropout, we created 4 unique feature sets: self-reported baseline user characteristics (eg, demographics), self-reported user context and reactions to the program (eg, state affect), self-reported user clinical functioning (eg, mental health symptoms), and passively detected user behavior on the website (eg, time spent on a web page of CBM-I training exercises, time of day during which the exercises were completed, latency of completing the assessments, and type of device used). Then, we investigated the feature sets as potential predictors of which participants were at high risk of not starting the second training session of a given program using well-known machine learning algorithms. RESULTS: The extreme gradient boosting algorithm performed the best and identified participants at high risk with macro-F1-scores of .832 (Study 1 with 146 features), .770 (Study 2 with 87 features), and .917 (Study 3 with 127 features). Features involving passive detection of user behavior contributed the most to the prediction relative to other features. The mean Gini importance scores for the passive features were as follows: .033 (95% CI .019-.047) in Study 1; .029 (95% CI .023-.035) in Study 2; and .045 (95% CI .039-.051) in Study 3. However, using all features extracted from a given study led to the best predictive performance. CONCLUSIONS: These results suggest that using passive indicators of user behavior, alongside self-reported measures, can improve the accuracy of prediction of participants at a high risk of dropout early during multisession CBM-I programs. Furthermore, our analyses highlight the challenge of generalizability in digital health intervention studies and the need for more personalized attrition prevention strategies.",
      "authors": "Baee Sonia; Eberle Jeremy W; Baglione Anna N; Spears Tyler; Lewis Elijah; Wang Hongning; Funk Daniel H; Teachman Bethany; E Barnes Laura",
      "year": "2024",
      "journal": "JMIR mental health",
      "doi": "10.2196/51567",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39705068/",
      "mesh_terms": "Humans; Machine Learning; Female; Male; Adult; Anxiety; Middle Aged; Patient Dropouts; Cognitive Behavioral Therapy; Internet-Based Intervention; Internet; Young Adult; Thinking",
      "keywords": "CBM-I; attrition prediction; cognitive bias modification; digital mental health intervention; dropout rate; personalization; user engagement",
      "pub_types": "Journal Article",
      "pmcid": "PMC11699492"
    },
    {
      "pmid": "40616933",
      "title": "Evaluating the Performance and Potential Bias of Predictive Models for Detection of Transthyretin Cardiac Amyloidosis.",
      "abstract": "BACKGROUND: Delays in the diagnosis of transthyretin amyloid cardiomyopathy (ATTR-CM) contribute to the significant morbidity of the condition, especially in the era of disease-modifying therapies. Screening for ATTR-CM with artificial intelligence and other algorithms may improve timely diagnosis, but these algorithms have not been directly compared. OBJECTIVES: The aim of this study was to compare the performance of 4 algorithms for ATTR-CM detection in a heart failure population and assess the risk for harms due to model bias. METHODS: We identified patients in an integrated health system from 2010 to 2022 with ATTR-CM and age- and sex-matched them to controls with heart failure to target 5% prevalence. We compared the performance of a claims-based random forest model (Huda et al model), a regression-based score (Mayo ATTR-CM), and 2 deep learning echo models (EchoNet-LVH and EchoGo Amyloidosis). We evaluated for bias using standard fairness metrics. RESULTS: The analytical cohort included 176 confirmed cases of ATTR-CM and 3,192 control patients with 79.2% self-identified as White and 9.0% as Black. The Huda et al model performed poorly (AUC: 0.49). Both deep learning echo models had a higher AUC when compared to the Mayo ATTR-CM Score (EchoNet-LVH 0.88; EchoGo Amyloidosis 0.92; Mayo ATTR-CM Score 0.79; DeLong P < 0.001 for both). Bias auditing met fairness criteria for equal opportunity among patients who identified as Black. CONCLUSIONS: Deep learning, echo-based models to detect ATTR-CM demonstrated best overall discrimination when compared to 2 other models in external validation with low risk of harms due to racial bias.",
      "authors": "Hourmozdi Jonathan; Easton Nicholas; Benigeri Simon; Thomas James D; Narang Akhil; Ouyang David; Duffy Grant; Upton Ross; Hawkes Will; Akerman Ashley; Okwuosa Ike; Kline Adrienne; Kho Abel N; Luo Yuan; Shah Sanjiv J; Ahmad Faraz S",
      "year": "2025",
      "journal": "JACC. Advances",
      "doi": "10.1016/j.jacadv.2025.101901",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40616933/",
      "mesh_terms": "",
      "keywords": "amyloidosis; artificial intelligence; health care disparities; heart failure; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC12272418"
    },
    {
      "pmid": "38160296",
      "title": "Quantifying Health Outcome Disparity in Invasive Methicillin-Resistant Staphylococcus aureus Infection using Fairness Algorithms on Real-World Data.",
      "abstract": "This study quantifies health outcome disparities in invasive Methicillin-Resistant Staphylococcus aureus (MRSA) infections by leveraging a novel artificial intelligence (AI) fairness algorithm, the Fairness-Aware Causal paThs (FACTS) decomposition, and applying it to real-world electronic health record (EHR) data. We spatiotemporally linked 9 years of EHRs from a large healthcare provider in Florida, USA, with contextual social determinants of health (SDoH). We first created a causal structure graph connecting SDoH with individual clinical measurements before/upon diagnosis of invasive MRSA infection, treatments, side effects, and outcomes; then, we applied FACTS to quantify outcome potential disparities of different causal pathways including SDoH, clinical and demographic variables. We found moderate disparity with respect to demographics and SDoH, and all the top ranked pathways that led to outcome disparities in age, gender, race, and income, included comorbidity. Prior kidney impairment, vancomycin use, and timing were associated with racial disparity, while income, rurality, and available healthcare facilities contributed to gender disparity. From an intervention standpoint, our results highlight the necessity of devising policies that consider both clinical factors and SDoH. In conclusion, this work demonstrates a practical utility of fairness AI methods in public health settings.",
      "authors": "Jun Inyoung; Ser Sarah E; Cohen Scott A; Xu Jie; Lucero Robert J; Bian Jiang; Prosperi Mattia",
      "year": "2024",
      "journal": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
      "doi": "10.15620/cdc:82532",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38160296/",
      "mesh_terms": "Humans; Methicillin-Resistant Staphylococcus aureus; Staphylococcal Infections; Artificial Intelligence; Community-Acquired Infections; Computational Biology; Algorithms; Outcome Assessment, Health Care; Anti-Bacterial Agents",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10795837"
    },
    {
      "pmid": "33484133",
      "title": "The risk of racial bias while tracking influenza-related content on social media using machine learning.",
      "abstract": "OBJECTIVE: Machine learning is used to understand and track influenza-related content on social media. Because these systems are used at scale, they have the potential to adversely impact the people they are built to help. In this study, we explore the biases of different machine learning methods for the specific task of detecting influenza-related content. We compare the performance of each model on tweets written in Standard American English (SAE) vs African American English (AAE). MATERIALS AND METHODS: Two influenza-related datasets are used to train 3 text classification models (support vector machine, convolutional neural network, bidirectional long short-term memory) with different feature sets. The datasets match real-world scenarios in which there is a large imbalance between SAE and AAE examples. The number of AAE examples for each class ranges from 2% to 5% in both datasets. We also evaluate each model's performance using a balanced dataset via undersampling. RESULTS: We find that all of the tested machine learning methods are biased on both datasets. The difference in false positive rates between SAE and AAE examples ranges from 0.01 to 0.35. The difference in the false negative rates ranges from 0.01 to 0.23. We also find that the neural network methods generally has more unfair results than the linear support vector machine on the chosen datasets. CONCLUSIONS: The models that result in the most unfair predictions may vary from dataset to dataset. Practitioners should be aware of the potential harms related to applying machine learning to health-related social media data. At a minimum, we recommend evaluating fairness along with traditional evaluation metrics.",
      "authors": "Lwowski Brandon; Rios Anthony",
      "year": "2021",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaa326",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33484133/",
      "mesh_terms": "Black or African American; Datasets as Topic; Humans; Influenza Vaccines; Influenza, Human; Machine Learning; Neural Networks, Computer; Racism; Social Media; Support Vector Machine",
      "keywords": "classification; deep learning; fairness; machine learning; social network",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7973478"
    },
    {
      "pmid": "41141904",
      "title": "Assessment of demographic bias in retinal age prediction machine learning models.",
      "abstract": "The retinal age gap, defined as the difference between the predicted retinal age and chronological age, is an emerging biomarker for many eye conditions and even non-ocular diseases. Machine learning (ML) models are commonly used for retinal age prediction. However, biases in ML models may lead to unfair predictions for some demographic groups, potentially exacerbating health disparities. This retrospective cross-sectional study evaluated demographic biases related to sex and ethnicity in retinal age prediction models using retinal imaging data (color fundus photography [CFP], optical coherence tomography [OCT], and combined CFP\u202f+\u202fOCT) from 9,668 healthy individuals (mean age 56.8\u202fyears; 52% female) in the UK Biobank. The RETFound foundation model was fine-tuned to predict retinal age, and bias was assessed by comparing mean absolute error (MAE) and retinal age gaps across demographic groups. The combined CFP\u202f+\u202fOCT model achieved the lowest MAE (3.01\u202fyears), outperforming CFP-only (3.40\u202fyears) and OCT-only (4.37\u202fyears) models. Significant sex differences were observed only in the CFP model (p\u202f<\u202f0.001), while significant ethnicity differences appeared only in the OCT model (p\u202f<\u202f0.001). No significant sex/ethnicity differences were observed in the combined model. These results demonstrate that retinal age prediction models can exhibit biases, and that these biases, along with model accuracy, are influenced by the choice of imaging modality (CFP, OCT, or combined). Identifying and addressing sources of bias is essential for safe and reliable clinical implementation. Our results emphasize the importance of comprehensive bias assessments and prospective validation, ensuring that advances in machine learning and artificial intelligence benefit all patient populations.",
      "authors": "Nielsen Christopher; Stanley Emma A M; Wilms Matthias; Forkert Nils D",
      "year": "2025",
      "journal": "Frontiers in artificial intelligence",
      "doi": "10.3389/frai.2025.1653153",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41141904/",
      "mesh_terms": "",
      "keywords": "bias; machine learning; multimodal imaging; retinal age prediction; retinal imaging",
      "pub_types": "Journal Article",
      "pmcid": "PMC12549555"
    },
    {
      "pmid": "38723025",
      "title": "Development and preliminary testing of Health Equity Across the AI Lifecycle (HEAAL): A framework for healthcare delivery organizations to mitigate the risk of AI solutions worsening health inequities.",
      "abstract": "The use of data-driven technologies such as Artificial Intelligence (AI) and Machine Learning (ML) is growing in healthcare. However, the proliferation of healthcare AI tools has outpaced regulatory frameworks, accountability measures, and governance standards to ensure safe, effective, and equitable use. To address these gaps and tackle a common challenge faced by healthcare delivery organizations, a case-based workshop was organized, and a framework was developed to evaluate the potential impact of implementing an AI solution on health equity. The Health Equity Across the AI Lifecycle (HEAAL) is co-designed with extensive engagement of clinical, operational, technical, and regulatory leaders across healthcare delivery organizations and ecosystem partners in the US. It assesses 5 equity assessment domains-accountability, fairness, fitness for purpose, reliability and validity, and transparency-across the span of eight key decision points in the AI adoption lifecycle. It is a process-oriented framework containing 37 step-by-step procedures for evaluating an existing AI solution and 34 procedures for evaluating a new AI solution in total. Within each procedure, it identifies relevant key stakeholders and data sources used to conduct the procedure. HEAAL guides how healthcare delivery organizations may mitigate the potential risk of AI solutions worsening health inequities. It also informs how much resources and support are required to assess the potential impact of AI solutions on health inequities.",
      "authors": "Kim Jee Young; Hasan Alifia; Kellogg Katherine C; Ratliff William; Murray Sara G; Suresh Harini; Valladares Alexandra; Shaw Keo; Tobey Danny; Vidal David E; Lifson Mark A; Patel Manesh; Raji Inioluwa Deborah; Gao Michael; Knechtle William; Tang Linda; Balu Suresh; Sendak Mark P",
      "year": "2024",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000390",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38723025/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11081364"
    },
    {
      "pmid": "39671594",
      "title": "Survival After Radical Cystectomy for Bladder Cancer: Development of a Fair Machine Learning Model.",
      "abstract": "BACKGROUND: Prediction models based on machine learning (ML) methods are being increasingly developed and adopted in health care. However, these models may be prone to bias and considered unfair if they demonstrate variable performance in population subgroups. An unfair model is of particular concern in bladder cancer, where disparities have been identified in sex and racial subgroups. OBJECTIVE: This study aims (1) to develop a ML model to predict survival after radical cystectomy for bladder cancer and evaluate for potential model bias in sex and racial subgroups; and (2) to compare algorithm unfairness mitigation techniques to improve model fairness. METHODS: We trained and compared various ML classification algorithms to predict 5-year survival after radical cystectomy using the National Cancer Database. The primary model performance metric was the F1-score. The primary metric for model fairness was the equalized odds ratio (eOR). We compared 3 algorithm unfairness mitigation techniques to improve eOR. RESULTS: We identified 16,481 patients; 23.1% (n=3800) were female, and 91.5% (n=15,080) were \"White,\" 5% (n=832) were \"Black,\" 2.3% (n=373) were \"Hispanic,\" and 1.2% (n=196) were \"Asian.\" The 5-year mortality rate was 75% (n=12,290). The best naive model was extreme gradient boosting (XGBoost), which had an F1-score of 0.860 and eOR of 0.619. All unfairness mitigation techniques increased the eOR, with correlation remover showing the highest increase and resulting in a final eOR of 0.750. This mitigated model had F1-scores of 0.86, 0.904, and 0.824 in the full, Black male, and Asian female test sets, respectively. CONCLUSIONS: The ML model predicting survival after radical cystectomy exhibited bias across sex and racial subgroups. By using algorithm unfairness mitigation techniques, we improved algorithmic fairness as measured by the eOR. Our study highlights the role of not only evaluating for model bias but also actively mitigating such disparities to ensure equitable health care delivery. We also deployed the first web-based fair ML model for predicting survival after radical cystectomy.",
      "authors": "Carbunaru Samuel; Neshatvar Yassamin; Do Hyungrok; Murray Katie; Ranganath Rajesh; Nayan Madhur",
      "year": "2024",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/63289",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39671594/",
      "mesh_terms": "Humans; Urinary Bladder Neoplasms; Cystectomy; Machine Learning; Female; Male; Aged; Middle Aged; Algorithms",
      "keywords": "algorithmic fairness; bias; bladder cancer; fairness; health equity; healthcare disparities; machine learning; model; mortality rate; prediction; radical cystectomy; survival",
      "pub_types": "Journal Article",
      "pmcid": "PMC11694706"
    },
    {
      "pmid": "39220818",
      "title": "Evaluating precision medicine tools in cystic fibrosis for racial and ethnic fairness.",
      "abstract": "INTRODUCTION: Patients with cystic fibrosis (CF) experience frequent episodes of acute decline in lung function called pulmonary exacerbations (PEx). An existing clinical and place-based precision medicine algorithm that accurately predicts PEx could include racial and ethnic biases in clinical and geospatial training data, leading to unintentional exacerbation of health inequities. METHODS: We estimated receiver operating characteristic curves based on predictions from a nonstationary Gaussian stochastic process model for PEx within 3, 6, and 12 months among 26,392 individuals aged 6 years and above (2003-2017) from the US CF Foundation Patient Registry. We screened predictors to identify reasons for discriminatory model performance. RESULTS: The precision medicine algorithm performed worse predicting a PEx among Black patients when compared with White patients or to patients of another race for all three prediction horizons. There was little to no difference in prediction accuracies among Hispanic and non-Hispanic patients for the same prediction horizons. Differences in F508del, smoking households, secondhand smoke exposure, primary and secondary road densities, distance and drive time to the CF center, and average number of clinical evaluations were key factors associated with race. CONCLUSIONS: Racial differences in prediction accuracies from our PEx precision medicine algorithm exist. Misclassification of future PEx was attributable to several underlying factors that correspond to race: CF mutation, location where the patient lives, and clinical awareness. Associations of our proxies with race for CF-related health outcomes can lead to systemic racism in data collection and in prediction accuracies from precision medicine algorithms constructed from it.",
      "authors": "Colegate Stephen P; Palipana Anushka; Gecili Emrah; Szczesniak Rhonda D; Brokamp Cole",
      "year": "2024",
      "journal": "Journal of clinical and translational science",
      "doi": "10.1017/cts.2024.532",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39220818/",
      "mesh_terms": "",
      "keywords": "Cystic fibrosis; group fairness; lung function; medical monitoring; precision medicine; pulmonary function tests",
      "pub_types": "Journal Article",
      "pmcid": "PMC11362628"
    },
    {
      "pmid": "40672707",
      "title": "Misattribution Bias of COVID-19 Hospitalizations in Alberta Using an Admission Algorithm.",
      "abstract": "BACKGROUND: With initial waves of COVID-19, many public health systems assumed each COVID-19 positive hospitalization was a direct cause from COVID-19 infection. Since January 2022, Alberta Health Services Communicable Disease Control Hospitalization Team (CDC-HT) implemented an admission criteria algorithm to adjudicate COVID-19 as a direct, contributing, or unrelated cause for all COVID-19 admissions in Alberta. METHODS: This quality improvement initiative sought to improve the admission algorithm's precision in reporting COVID-19 admissions. Patient hospitalization records from January-February 2022 with a positive COVID-19 test in the last 30 days were proportionally sampled in a geographically stratified manner across Alberta health zones. 261 patient records were sampled and determination of COVID-19 attribution by CDC-HT algorithm was compared to adjudication by a panel of infectious diseases physicians with extensive COVID-19 clinical experience. RESULTS: Of 261 sampled COVID-19 admissions, blinded physician adjudication determined 39.9% were direct-cause, 17.2% contributing-cause, and 37.6% unrelated-cause. Within the same cohort the CDC-HT admission algorithm adjudicated 42.9% direct-cause, 24.5% contributing-cause, and 30.3% unrelated-cause. Cohen's kappa was 0.475, providing only moderate agreement. The majority of discrepancy was from over-attribution of unrelated hospitalizations as contributing cause. Implementation of this algorithm in Alberta throughout 2022 showed a fluctuating proportion of direct plus contributing COVID-19 hospitalizations as low as 40%. CONCLUSION: There was misattribution bias in COVID-19 hospitalization determination using the admission algorithm. The findings from this analysis led to improvements in the algorithm to improve precision. Public health jurisdictions should review their COVID-19 hospitalization reporting approaches to ensure validity and consideration of incidental cases.",
      "authors": "Dinh Tri; Ross Jordan; James Samantha; Klein Kristin; Chandran A Uma; Larios Oscar; Strong David; Conly John M",
      "year": "2024",
      "journal": "Journal of the Association of Medical Microbiology and Infectious Disease Canada = Journal officiel de l'Association pour la microbiologie medicale et l'infectiologie Canada",
      "doi": "10.3138/jammi-2024-0011",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40672707/",
      "mesh_terms": "",
      "keywords": "COVID-19; SARS-COV-2; admission; hospitalization; incidental; misattribution bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC12258636"
    },
    {
      "pmid": "34833435",
      "title": "Hybrid Feature Selection Framework for the Parkinson Imbalanced Dataset Prediction Problem.",
      "abstract": "Background and Objectives: Recently, many studies have focused on the early detection of Parkinson's disease (PD). This disease belongs to a group of neurological problems that immediately affect brain cells and influence the movement, hearing, and various cognitive functions. Medical data sets are often not equally distributed in their classes and this gives a bias in the classification of patients. We performed a Hybrid feature selection framework that can deal with imbalanced datasets like PD. Use the SOMTE algorithm to deal with unbalanced datasets. Removing the contradiction from the features in the dataset and decrease the processing time by using Recursive Feature Elimination (RFE), and Principle Component Analysis (PCA). Materials and Methods: PD acoustic datasets and the characteristics of control subjects were used to construct classification models such as Bagging, K-nearest neighbour (KNN), multilayer perceptron, and the support vector machine (SVM). In the prepressing stage, the synthetic minority over-sampling technique (SMOTE) with two-feature selection RFE and PCA were used. The PD dataset comprises a large difference between the numbers of the infected and uninfected patients, which causes the classification bias problem. Therefore, SMOTE was used to resolve this problem. Results: For model evaluation, the train-test split technique was used for the experiment. All the models were Grid-search tuned, the evaluation results of the SVM model showed the highest accuracy of 98.2%, and the KNN model exhibited the highest specificity of 99%. Conclusions: the proposed method is compared with the current modern methods of detecting Parkinson's disease and other methods for medical diseases, it was noted that our developed system could treat data bias and reach a high prediction of PD and this can be beneficial for health organizations to properly prioritize assets.",
      "authors": "Qasim Hayder Mohammed; Ata Oguz; Ansari Mohammad Azam; Alomary Mohammad N; Alghamdi Saad; Almehmadi Mazen",
      "year": "2021",
      "journal": "Medicina (Kaunas, Lithuania)",
      "doi": "10.3390/medicina57111217",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34833435/",
      "mesh_terms": "Algorithms; Cluster Analysis; Humans; Neural Networks, Computer; Parkinson Disease; Support Vector Machine",
      "keywords": "PCA; Parkinson detection; RFE; SMOTE; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC8619928"
    },
    {
      "pmid": "33315263",
      "title": "The Emerging Hazard of AI-Related Health Care Discrimination.",
      "abstract": "Artificial intelligence holds great promise for improved health-care outcomes. But it also poses substantial new hazards, including algorithmic discrimination. For example, an algorithm used to identify candidates for beneficial \"high risk care management\" programs routinely failed to select racial minorities. Furthermore, some algorithms deliberately adjust for race in ways that divert resources away from minority patients. To illustrate, algorithms have underestimated African Americans' risks of kidney stones and death from heart failure. Algorithmic discrimination can violate Title VI of the Civil Rights Act and Section 1557 of the Affordable Care Act when it unjustifiably disadvantages underserved populations. This article urges that both legal and technical tools be deployed to promote AI fairness. Plaintiffs should be able to assert disparate impact claims in health-care litigation, and Congress should enact an Algorithmic Accountability Act. In addition, fairness should be a key element in designing, implementing, validating, and employing AI.",
      "authors": "Hoffman Sharona",
      "year": "2021",
      "journal": "The Hastings Center report",
      "doi": "10.1002/hast.1203",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33315263/",
      "mesh_terms": "Artificial Intelligence; Civil Rights; Delivery of Health Care; Humans; Minority Groups; Patient Protection and Affordable Care Act; United States",
      "keywords": "algorithmic fairness; artificial intelligence; civil rights; discrimination; disparate impact",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40056436",
      "title": "Large language models are less effective at clinical prediction tasks than locally trained machine learning models.",
      "abstract": "OBJECTIVES: To determine the extent to which current large language models (LLMs) can serve as substitutes for traditional machine learning (ML) as clinical predictors using data from electronic health records (EHRs), we investigated various factors that can impact their adoption, including overall performance, calibration, fairness, and resilience to privacy protections that reduce data fidelity. MATERIALS AND METHODS: We evaluated GPT-3.5, GPT-4, and traditional ML (as gradient-boosting trees) on clinical prediction tasks in EHR data from Vanderbilt University Medical Center (VUMC) and MIMIC IV. We measured predictive performance with area under the receiver operating characteristic (AUROC) and model calibration using Brier Score. To evaluate the impact of data privacy protections, we assessed AUROC when demographic variables are generalized. We evaluated algorithmic fairness using equalized odds and statistical parity across race, sex, and age of patients. We also considered the impact of using in-context learning by incorporating labeled examples within the prompt. RESULTS: Traditional ML [AUROC: 0.847, 0.894 (VUMC, MIMIC)] substantially outperformed GPT-3.5 (AUROC: 0.537, 0.517) and GPT-4 (AUROC: 0.629, 0.602) (with and without in-context learning) in predictive performance and output probability calibration [Brier Score (ML vs GPT-3.5 vs GPT-4): 0.134 vs 0.384 vs 0.251, 0.042 vs 0.06 vs 0.219)]. DISCUSSION: Traditional ML is more robust than GPT-3.5 and GPT-4 in generalizing demographic information to protect privacy. GPT-4 is the fairest model according to our selected metrics but at the cost of poor model performance. CONCLUSION: These findings suggest that non-fine-tuned LLMs are less effective and robust than locally trained ML for clinical prediction tasks, but they are improving across releases.",
      "authors": "Brown Katherine E; Yan Chao; Li Zhuohang; Zhang Xinmeng; Collins Benjamin X; Chen You; Clayton Ellen Wright; Kantarcioglu Murat; Vorobeychik Yevgeniy; Malin Bradley A",
      "year": "2025",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf038",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40056436/",
      "mesh_terms": "Machine Learning; Humans; Electronic Health Records; Female; ROC Curve; Male; Algorithms; Middle Aged; Large Language Models",
      "keywords": "clinical prediction models; fairness; large language models; privacy",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC12012369"
    },
    {
      "pmid": "38962581",
      "title": "Challenges in Reducing Bias Using Post-Processing Fairness for Breast Cancer Stage Classification with Deep Learning.",
      "abstract": "Breast cancer is the most common cancer affecting women globally. Despite the significant impact of deep learning models on breast cancer diagnosis and treatment, achieving fairness or equitable outcomes across diverse populations remains a challenge when some demographic groups are underrepresented in the training data. We quantified the bias of models trained to predict breast cancer stage from a dataset consisting of 1000 biopsies from 842 patients provided by AIM-Ahead (Artificial Intelligence/Machine Learning Consortium to Advance Health Equity and Researcher Diversity). Notably, the majority of data (over 70%) were from White patients. We found that prior to post-processing adjustments, all deep learning models we trained consistently performed better for White patients than for non-White patients. After model calibration, we observed mixed results, with only some models demonstrating improved performance. This work provides a case study of bias in breast cancer medical imaging models and highlights the challenges in using post-processing to attempt to achieve fairness.",
      "authors": "Soltan Armin; Washington Peter",
      "year": "2024",
      "journal": "Algorithms",
      "doi": "10.3390/a17040141",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38962581/",
      "mesh_terms": "",
      "keywords": "algorithmic fairness; breast cancer; deep learning; equalized odds; equalized opportunity; post-processing method",
      "pub_types": "Journal Article",
      "pmcid": "PMC11221567"
    },
    {
      "pmid": "34573790",
      "title": "The Problem of Fairness in Synthetic Healthcare Data.",
      "abstract": "Access to healthcare data such as electronic health records (EHR) is often restricted by laws established to protect patient privacy. These restrictions hinder the reproducibility of existing results based on private healthcare data and also limit new research. Synthetically-generated healthcare data solve this problem by preserving privacy and enabling researchers and policymakers to drive decisions and methods based on realistic data. Healthcare data can include information about multiple in- and out- patient visits of patients, making it a time-series dataset which is often influenced by protected attributes like age, gender, race etc. The COVID-19 pandemic has exacerbated health inequities, with certain subgroups experiencing poorer outcomes and less access to healthcare. To combat these inequities, synthetic data must \"fairly\" represent diverse minority subgroups such that the conclusions drawn on synthetic data are correct and the results can be generalized to real data. In this article, we develop two fairness metrics for synthetic data, and analyze all subgroups defined by protected attributes to analyze the bias in three published synthetic research datasets. These covariate-level disparity metrics revealed that synthetic data may not be representative at the univariate and multivariate subgroup-levels and thus, fairness should be addressed when developing data generation methods. We discuss the need for measuring fairness in synthetic healthcare data to enable the development of robust machine learning models to create more equitable synthetic healthcare datasets.",
      "authors": "Bhanot Karan; Qi Miao; Erickson John S; Guyon Isabelle; Bennett Kristin P",
      "year": "2021",
      "journal": "Entropy (Basel, Switzerland)",
      "doi": "10.3390/e23091165",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34573790/",
      "mesh_terms": "",
      "keywords": "covariate; disparate impact; fairness; health inequities; healthcare; synthetic data; temporal; time-series",
      "pub_types": "Journal Article",
      "pmcid": "PMC8468495"
    },
    {
      "pmid": "33910923",
      "title": "Equity in essence: a call for operationalising fairness in machine learning for healthcare.",
      "abstract": "",
      "authors": "Wawira Gichoya Judy; McCoy Liam G; Celi Leo Anthony; Ghassemi Marzyeh",
      "year": "2021",
      "journal": "BMJ health & care informatics",
      "doi": "10.1136/bmjhci-2020-100289",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33910923/",
      "mesh_terms": "Delivery of Health Care; Humans; Machine Learning",
      "keywords": "BMJ health informatics",
      "pub_types": "Journal Article",
      "pmcid": "PMC8733939"
    },
    {
      "pmid": "38740316",
      "title": "A roadmap to artificial intelligence (AI): Methods for designing and building AI ready data to promote fairness.",
      "abstract": "OBJECTIVES: We evaluated methods for preparing electronic health record data to reduce bias before applying artificial intelligence (AI). METHODS: We created methods for transforming raw data into a data framework for applying machine learning and natural language processing techniques for predicting falls and fractures. Strategies such as inclusion and reporting for multiple races, mixed data sources such as outpatient, inpatient, structured codes, and unstructured notes, and addressing missingness were applied to raw data to promote a reduction in bias. The raw data was carefully curated using validated definitions to create data variables such as age, race, gender, and healthcare utilization. For the formation of these variables, clinical, statistical, and data expertise were used. The research team included a variety of experts with diverse professional and demographic backgrounds to include diverse perspectives. RESULTS: For the prediction of falls, information extracted from radiology reports was converted to a matrix for applying machine learning. The processing of the data resulted in an input of 5,377,673 reports to the machine learning algorithm, out of which 45,304 were flagged as positive and 5,332,369 as negative for falls. Processed data resulted in lower missingness and a better representation of race and diagnosis codes. For fractures, specialized algorithms extracted snippets of text around keywork \"femoral\" from dual x-ray absorptiometry (DXA) scans to identify femoral neck T-scores that are important for predicting fracture risk. The natural language processing algorithms yielded 98% accuracy and 2% error rate The methods to prepare data for input to artificial intelligence processes are reproducible and can be applied to other studies. CONCLUSION: The life cycle of data from raw to analytic form includes data governance, cleaning, management, and analysis. When applying artificial intelligence methods, input data must be prepared optimally to reduce algorithmic bias, as biased output is harmful. Building AI-ready data frameworks that improve efficiency can contribute to transparency and reproducibility. The roadmap for the application of AI involves applying specialized techniques to input data, some of which are suggested here. This study highlights data curation aspects to be considered when preparing data for the application of artificial intelligence to reduce bias.",
      "authors": "Kidwai-Khan Farah; Wang Rixin; Skanderson Melissa; Brandt Cynthia A; Fodeh Samah; Womack Julie A",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2024.104654",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38740316/",
      "mesh_terms": "Humans; Electronic Health Records; Artificial Intelligence; Natural Language Processing; Accidental Falls; Algorithms; Machine Learning; Fractures, Bone; Female",
      "keywords": "Algorithms; Artificial Intelligence; Data preparation; Diversity; Fairness; Inclusion",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11144439"
    },
    {
      "pmid": "37609241",
      "title": "Enhancing Fairness in Disease Prediction by Optimizing Multiple Domain Adversarial Networks.",
      "abstract": "Predictive models in biomedicine need to ensure equitable and reliable outcomes for the populations they are applied to. Unfortunately, biases in medical predictions can lead to unfair treatment and widening disparities, underscoring the need for effective techniques to address these issues. To enhance fairness, we introduce a framework based on a Multiple Domain Adversarial Neural Network (MDANN), which incorporates multiple adversarial components. In an MDANN, an adversarial module is applied to learn a fair pattern by negative gradients back-propagating across multiple sensitive features (i.e., characteristics of individuals that should not be used to discriminate unfairly between individuals when making predictions or decisions.) We leverage loss functions based on the Area Under the Receiver Operating Characteristic Curve (AUC) to address the class imbalance, promoting equitable classification performance for minority groups (e.g., a subset of the population that is underrepresented or disadvantaged.) Moreover, we utilize pre-trained convolutional autoencoders (CAEs) to extract deep representations of data, aiming to enhance prediction accuracy and fairness. Combining these mechanisms, we alleviate biases and disparities to provide reliable and equitable disease prediction. We empirically demonstrate that the MDANN approach leads to better accuracy and fairness in predicting disease progression using brain imaging data for Alzheimer's Disease and Autism populations than state-of-the-art techniques.",
      "authors": "Li Bin; Shi Xinghua; Gao Hongchang; Jiang Xiaoqian; Zhang Kai; Harmanci Arif O; Malin Bradley",
      "year": "2023",
      "journal": "bioRxiv : the preprint server for biology",
      "doi": "10.1101/2023.08.04.551906",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37609241/",
      "mesh_terms": "",
      "keywords": "Fairness; adversarial training; biases; health disparities; machine learning",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC10441334"
    },
    {
      "pmid": "41001459",
      "title": "Racial and Ethnic Disparities in Brain Age Algorithm Performance: Investigating Bias Across Six Popular Methods.",
      "abstract": "Brain age algorithms, which estimate biological aging from neuroimaging data, are increasingly used as biomarkers for health and disease. However, most algorithms are trained on datasets with limited racial and ethnic diversity, raising concerns about potential algorithmic bias that could exacerbate health disparities. To probe this potential, we evaluated six popular brain age algorithms using data from the Health and Aging Brain Study-Health Disparities (HABS-HD), comprising 1,123 White American, 1,107 Hispanic American, and 678 African American participants, ages \u226550. Comparing correlations between brain age and chronological age across racial/ethnic groups, relations were consistently weaker for African American participants compared to White and Hispanic American participants across most algorithms (ranging from r=0.51-0.85 for African Americans vs. r=0.57-0.89 for other groups). We also examined error for brain age v. chronological age and found significant differences in median errors across racial/ethnic groups, though specific patterns varied by algorithm. Sensitivity models weighting for age, sex, and scan quality noted similar patterns, with all algorithms maintaining significant differences in correlation or median prediction error between groups. Our findings reveal systematic performance differences in brain age algorithms across racial and ethnic groups, with most algorithms consistently showing reduced algorithm accuracy for African American and/or Hispanic-American participants. These biases, which are likely introduced at multiple stages of algorithm development, could impact clinical utility and diagnostic accuracy. Results highlight the urgent need for more inclusive algorithm development and validation to ensure equitable healthcare applications of neuroimaging biomarkers.",
      "authors": "Adkins Dorthea J; Hanson Jamie L",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.09.18.25336117",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41001459/",
      "mesh_terms": "",
      "keywords": "algorithm; brain age; chronological age; correlation; ethnicity; median error; race",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12458499"
    },
    {
      "pmid": "40354171",
      "title": "Mitigating Bias in Machine Learning Models with Ethics-Based Initiatives: The Case of Sepsis.",
      "abstract": "This paper discusses ethics-based strategies for mitigating bias in machine learning models used to predict sepsis onset. The first part discusses how various kinds of bias and their potential synergies can reduce predictive accuracy, especially as those biases derive from social determinants of health (SDOHs) and from the design and construction of the predictive model. The second part of the essay discusses how certain ethically-based strategies might mitigate the potential for disparate or unfair treatment produced by these models, not only as they might apply to sepsis but to any syndrome that witnesses the impact of adverse SDOHs on socioeconomically disadvantaged or marginalized populations.",
      "authors": "D Banja John; Xie Yao; R Smith Jeffrey; Rana Shaheen; L Holder Andre",
      "year": "2026",
      "journal": "The American journal of bioethics : AJOB",
      "doi": "10.1080/15265161.2025.2497971",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40354171/",
      "mesh_terms": "Humans; Machine Learning; Sepsis; Social Determinants of Health; Bias",
      "keywords": "Bias; equity; ethics; machine learning; sepsis; social determinants of health",
      "pub_types": "Journal Article",
      "pmcid": "PMC12353398"
    },
    {
      "pmid": "40550353",
      "title": "Dental services use prediction among adults in Southern Brazil: A gender and racial fairness-oriented machine learning approach.",
      "abstract": "OBJECTIVE: To develop machine learning models to predict the use of dental services among adults aged 18 and older. METHODS: This is a prospective cohort study that uses data from the survey \"EAI Pelotas?\". The sample consisted of individuals who participated in both the baseline and follow-up, totaling 3461 people. Predictors were collected as baseline and comprised 47 sociodemographic, behavioral, oral and general health characteristics. The outcome was dental service use in the last year assessed during the one-year follow-up. Data was divided into training (80 %) and test (20 %) sets. Five machine learning models were tested. Hyperparameter tuning was optimized through 10-fold cross-validation, utilizing 30 iterations. Model performance was assessed based on the area under the Receiver Operating Characteristic (ROC) curve (AUC), accuracy, recall, precision, and F1-score. RESULTS: The prevalence of dental service use in the follow-up was 47.2 % (95 % CI, 45.5 - 48.9). All models in the test set demonstrated an AUC-ROC between 0.76 and 0.77. The CatBoost Classifier model exhibited the highest performance in the test dataset among the models concerning the AUC metric (AUC = 0.77, CI95 %,[0.73-0.80]), displaying an accuracy = 0.69, recall = 0.69, precision = 0.68, and F1-score = 0.69. Fairness estimations for the best model indicated consistent performance across gender categories. However, disparities were observed among racial groups, AUC = 0.57 for individuals who self-reported mixed (\"pardos\") skin color. The explainability analysis shows that the most important features were the last dental visit at baseline and education level. CONCLUSION: Despite our findings suggesting a sufficient prediction of overall dental services' use, performance varied across racial groups. CLINICAL SIGNIFICANCE: Our findings highlight the potential of machine learning models to predict dental service use with good overall accuracy. However, the significantly lower performance for mixed-race individuals raises concerns about fairness and equity. Therefore, despite promising results, the model requires further refinement before it can be applied in real-world public health settings.",
      "authors": "Chisini Luiz Alexandre; Ara\u00fajo C\u00ednthia Fonseca; Delpino Felipe Mendes; Figueiredo L\u00edlian Munhoz; Filho Alexandre Dias Porto Chiavegatto; Schuch Helena Silveira; Nunes Bruno Pereira; Demarco Fl\u00e1vio Fernando",
      "year": "2025",
      "journal": "Journal of dentistry",
      "doi": "10.1016/j.jdent.2025.105929",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40550353/",
      "mesh_terms": "Humans; Adult; Female; Male; Machine Learning; Prospective Studies; Middle Aged; Brazil; Sex Factors; Young Adult; Dental Health Services; Adolescent; Aged; Dental Care; ROC Curve",
      "keywords": "Artificial intelligence; Dental health services; Longitudinal study; Machine learning; Oral health",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39953146",
      "title": "Improving medical machine learning models with generative balancing for equity and excellence.",
      "abstract": "Applying machine learning to clinical outcome prediction is challenging due to imbalanced datasets and sensitive tasks that contain rare yet critical outcomes and where equitable treatment across diverse patient groups is essential. Despite attempts, biases in predictions persist, driven by disparities in representation and exacerbated by the scarcity of positive labels, perpetuating health inequities. This paper introduces FairPlay, a synthetic data generation approach leveraging large language models, to address these issues. FairPlay enhances algorithmic performance and reduces bias by creating realistic, anonymous synthetic patient data that improves representation and augments dataset patterns while preserving privacy. Through experiments on multiple datasets, we demonstrate that FairPlay boosts mortality prediction performance across diverse subgroups, achieving up to a 21% improvement in F1 Score without requiring additional data or altering downstream training pipelines. Furthermore, FairPlay consistently reduces subgroup performance gaps, as shown by universal improvements in performance and fairness metrics across four experimental setups.",
      "authors": "Theodorou Brandon; Danek Benjamin; Tummala Venkat; Kumar Shivam Pankaj; Malin Bradley; Sun Jimeng",
      "year": "2025",
      "journal": "NPJ digital medicine",
      "doi": "10.1038/s41746-025-01438-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39953146/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11828851"
    },
    {
      "pmid": "33856478",
      "title": "Comparison of Methods to Reduce Bias From Clinical Prediction Models of Postpartum Depression.",
      "abstract": "IMPORTANCE: The lack of standards in methods to reduce bias for clinical algorithms presents various challenges in providing reliable predictions and in addressing health disparities. OBJECTIVE: To evaluate approaches for reducing bias in machine learning models using a real-world clinical scenario. DESIGN, SETTING, AND PARTICIPANTS: Health data for this cohort study were obtained from the IBM MarketScan Medicaid Database. Eligibility criteria were as follows: (1) Female individuals aged 12 to 55 years with a live birth record identified by delivery-related codes from January 1, 2014, through December 31, 2018; (2) greater than 80% enrollment through pregnancy to 60 days post partum; and (3) evidence of coverage for depression screening and mental health services. Statistical analysis was performed in 2020. EXPOSURES: Binarized race (Black individuals and White individuals). MAIN OUTCOMES AND MEASURES: Machine learning models (logistic regression [LR], random forest, and extreme gradient boosting) were trained for 2 binary outcomes: postpartum depression (PPD) and postpartum mental health service utilization. Risk-adjusted generalized linear models were used for each outcome to assess potential disparity in the cohort associated with binarized race (Black or White). Methods for reducing bias, including reweighing, Prejudice Remover, and removing race from the models, were examined by analyzing changes in fairness metrics compared with the base models. Baseline characteristics of female individuals at the top-predicted risk decile were compared for systematic differences. Fairness metrics of disparate impact (DI, 1 indicates fairness) and equal opportunity difference (EOD, 0 indicates fairness). RESULTS: Among 573\u202f634 female individuals initially examined for this study, 314\u202f903 were White (54.9%), 217\u202f899 were Black (38.0%), and the mean (SD) age was 26.1 (5.5) years. The risk-adjusted odds ratio comparing White participants with Black participants was 2.06 (95% CI, 2.02-2.10) for clinically recognized PPD and 1.37 (95% CI, 1.33-1.40) for postpartum mental health service utilization. Taking the LR model for PPD prediction as an example, reweighing reduced bias as measured by improved DI and EOD metrics from 0.31 and -0.19 to 0.79 and 0.02, respectively. Removing race from the models had inferior performance for reducing bias compared with the other methods (PPD: DI\u2009=\u20090.61; EOD\u2009=\u2009-0.05; mental health service utilization: DI\u2009=\u20090.63; EOD\u2009=\u2009-0.04). CONCLUSIONS AND RELEVANCE: Clinical prediction models trained on potentially biased data may produce unfair outcomes on the basis of the chosen metrics. This study's results suggest that the performance varied depending on the model, outcome label, and method for reducing bias. This approach toward evaluating algorithmic bias can be used as an example for the growing number of researchers who wish to examine and address bias in their data and models.",
      "authors": "Park Yoonyoung; Hu Jianying; Singh Moninder; Sylla Issa; Dankwa-Mullan Irene; Koski Eileen; Das Amar K",
      "year": "2021",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2021.3909",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33856478/",
      "mesh_terms": "Adolescent; Adult; Algorithms; Cohort Studies; Depression, Postpartum; Female; Humans; Middle Aged; Models, Statistical; Odds Ratio; Patient-Specific Modeling; Postpartum Period; Pregnancy; Prognosis; Retrospective Studies; Risk Assessment; Risk Factors; United States; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC8050742"
    },
    {
      "pmid": "40100898",
      "title": "What makes clinical machine learning fair? A practical ethics framework.",
      "abstract": "Machine learning (ML) can offer a tremendous contribution to medicine by streamlining decision-making, reducing mistakes, improving clinical accuracy and ensuring better patient outcomes. The prospects of a widespread and rapid integration of machine learning in clinical workflow have attracted considerable attention including due to complex ethical implications-algorithmic bias being among the most frequently discussed ML models. Here we introduce and discuss a practical ethics framework inductively-generated via normative analysis of the practical challenges in developing an actual clinical ML model (see case study). The framework is usable to identify, measure and address bias in clinical machine learning models, thus improving fairness as to both model performance and health outcomes. We detail a proportionate approach to ML bias by defining the demands of fair ML in light of what is ethically justifiable and, at the same time, technically feasible in light of inevitable trade-offs. Our framework enables ethically robust and transparent decision-making both in the design and the context-dependent aspects of ML bias mitigation, thus improving accountability for both developers and clinical users.",
      "authors": "Hoche Marine; Mineeva Olga; R\u00e4tsch Gunnar; Vayena Effy; Blasimme Alessandro",
      "year": "2025",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000728",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40100898/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11918422"
    },
    {
      "pmid": "39677419",
      "title": "Not the Models You Are Looking For: Traditional ML Outperforms LLMs in Clinical Prediction Tasks.",
      "abstract": "OBJECTIVES: To determine the extent to which current Large Language Models (LLMs) can serve as substitutes for traditional machine learning (ML) as clinical predictors using data from electronic health records (EHRs), we investigated various factors that can impact their adoption, including overall performance, calibration, fairness, and resilience to privacy protections that reduce data fidelity. MATERIALS AND METHODS: We evaluated GPT-3.5, GPT-4, and ML (as gradient-boosting trees) on clinical prediction tasks in EHR data from Vanderbilt University Medical Center and MIMIC IV. We measured predictive performance with AUROC and model calibration using Brier Score. To evaluate the impact of data privacy protections, we assessed AUROC when demographic variables are generalized. We evaluated algorithmic fairness using equalized odds and statistical parity across race, sex, and age of patients. We also considered the impact of using in-context learning by incorporating labeled examples within the prompt. RESULTS: Traditional ML (AUROC: 0.847, 0.894 (VUMC, MIMIC)) substantially outperformed GPT-3.5 (AUROC: 0.537, 0.517) and GPT-4 (AUROC: 0.629, 0.602) (with and without in-context learning) in predictive performance and output probability calibration (Brier Score (ML vs GPT-3.5 vs GPT-4): 0.134 versus 0.384 versus 0.251, 0.042 versus 0.06 versus 0.219). Traditional ML is more robust than GPT-3.5 and GPT-4 to generalizing demographic information to protect privacy. GPT-4 is the fairest model according to our selected metrics but at the cost of poor model performance. CONCLUSION: These findings suggest that LLMs are much less effective and robust than locally-trained ML for clinical prediction tasks, but they are getting better over time.",
      "authors": "Brown Katherine E; Yan Chao; Li Zhuohang; Zhang Xinmeng; Collins Benjamin X; Chen You; Clayton Ellen Wright; Kantarcioglu Murat; Vorobeychik Yevgeniy; Malin Bradley A",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.12.03.24318400",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39677419/",
      "mesh_terms": "",
      "keywords": "Large language models; clinical prediction models; fairness; privacy",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC11643212"
    },
    {
      "pmid": "29998588",
      "title": "Technology-induced bias in the theory of evidence-based medicine.",
      "abstract": "Designing trials and studies to minimize confounding and bias is central to evidence-based medicine (EBM). The widespread use of recent technologies such as machine learning, smartphones, and the World Wide Web to collect, analyse, and disseminate information can improve the efficiency, reliability, and availability of medical research. However, it also has the potential to introduce new sources of significant, technology-induced evidential bias. This paper assesses the extent of the impact by reviewing some of the methods by and principles according to which evidence is collected, analysed, and disseminated in EBM, supported by specific examples. It considers the effect of personal health tracking via smartphones, the current proliferation of research data and the influence of search engine \"filter bubbles\", the possibility of machine learning-driven study design, and the implications of using machine learning to seek patterns in large quantities of data, for example from observational studies and medical record databases. It concludes that new technology may introduce profound new sources of bias that current EBM frameworks do not accommodate. It also proposes new approaches that could be incorporated in to EBM theory to mitigate the most obvious risks, and suggests where further assessment of the practical implications is needed.",
      "authors": "Eustace Scott",
      "year": "2018",
      "journal": "Journal of evaluation in clinical practice",
      "doi": "10.1111/jep.12972",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29998588/",
      "mesh_terms": "Bias; Biomedical Research; Biomedical Technology; Evidence-Based Medicine; Humans; Information Dissemination; Medical Informatics; Philosophy, Medical; Reproducibility of Results; Research Design",
      "keywords": "data proliferation; evidence-based medicine; machine learning; philosophy of medicine; search engine; technology-induced bias",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41296741",
      "title": "Evaluating algorithmic fairness of machine learning models in predicting underweight, overweight, and adiposity across socioeconomic and caste groups in India: evidence from the longitudinal ageing study in India.",
      "abstract": "Machine learning (ML) models are increasingly applied to predict body mass index (BMI) and related outcomes, yet their fairness across socioeconomic and caste groups remains uncertain, particularly in contexts of structural inequality. Using nationally representative data from more than 55,000 adults aged 45 years and older in the Longitudinal Ageing Study in India (LASI), we evaluated the accuracy and fairness of multiple ML algorithms-including Random Forest, XGBoost, Gradient Boosting, LightGBM, Deep Neural Networks, and Deep Cross Networks-alongside logistic regression for predicting underweight, overweight, and central adiposity. Models were trained on 80% of the data and tested on 20%, with performance assessed using AUROC, accuracy, sensitivity, specificity, and precision. Fairness was evaluated through subgroup analyses across socioeconomic and caste groups and equity-based metrics such as Equalized Odds and Demographic Parity. Feature importance was examined using SHAP values, and bias-mitigation methods were implemented at pre-processing, in-processing, and post-processing stages. Tree-based models, particularly LightGBM and Gradient Boosting, achieved the highest AUROC values (0.79-0.84). Incorporating socioeconomic and health-related variables improved prediction, but fairness gaps persisted: performance declined for scheduled tribes and lower socioeconomic groups. SHAP analyses identified grip strength, gender, and residence as key drivers of prediction differences. Among mitigation strategies, Reject Option Classification and Equalized Odds Post-processing moderately reduced subgroup disparities but sometimes decreased overall performance, whereas other approaches yielded minimal gains. ML models can effectively predict obesity and adiposity risk in India, but addressing bias is essential for equitable application. Continued refinement of fairness-aware ML methods is needed to support inclusive and effective public-health decision-making.",
      "authors": "Lee John Tayu; Hsu Sheng Hui; Li Vincent Cheng-Sheng; Anindya Kanya; Chen Meng-Huan; Wang Charlotte; Shen Toby Kai-Bo; Liu Valerie Tzu Ning; Chen Hsiao-Hui; Atun Rifat",
      "year": "2025",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000951",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41296741/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12654920"
    },
    {
      "pmid": "41292658",
      "title": "Develop and Validate A Fair Machine Learning Model to Indentify Patients with High Care-Continuity in Electronic Health Records Data.",
      "abstract": "OBJECTIVES: Electronic health record (EHR) data often missed care outside a given health system, resulting in data discontinuity. We aimed to: (1) quantify misclassification across levels of EHR data discontinuity and identify an optimal continuity threshold. (2) develop a machine learning (ML) model to predict EHR continuity and optimize fairness across racial and ethnic groups, and (3) externally validate the EHR continuity prediction model using an independent dataset. MATERIALS AND METHODS: We used linked OneFlorida+ EHR-Medicaid claims data for model development and REACHnet EHR-Louisiana Blue Cross Blue Shield (LABlue) claims data for external validation. A novel Harmonized Encounter Proportion Score (HEPS) was applied to quantify patient-level EHR data continuity and the impact on misclassification of 42 clinical variables. ML models were trained using routinely available demographic, clinical, and healthcare utilization features derived from structured EHR data. RESULTS: Higher EHR data continuity was associated with lower rates of misclassification. A HEPS threshold of approximately 30% effectively distinguished patients with sufficient data continuity. ML models demonstrated strong performance in predicting high continuity (AUROC=0.77). Fairness assessments showed bias against Hispanic group, which was substantially improved following bias mitigation procedures. Model performance remained robust and fair in the external validation. DISCUSSION: Our study offers a practical metric for quantifying care continuity in EHR networks. The current ML model incorporating EHR-routinely collected information can accurately identify patients with high care continuity. CONCLUSIONS: We developed a generalizable care-continuity classification tool that can be easily applied across EHR systems, strengthening the rigor of EHR-based research.",
      "authors": "Lee Yao An; Tang Tiange; Huang Yu; Bian Jiang; Shi Lizheng; Guo Jingchuan",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.11.11.25339938",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41292658/",
      "mesh_terms": "",
      "keywords": "Data continuity; EHR; Machine learning prediction",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12642717"
    },
    {
      "pmid": "40318249",
      "title": "Building competency in artificial intelligence and bias mitigation for nurse scientists and aligned health researchers.",
      "abstract": "Healthcare systems are increasingly integrating artificial intelligence and machine learning (AI/ML) tools into patient care, potentially influencing clinical decisions for millions. However, concerns are growing about these tools reinforcing systemic inequities. To address bias in AI/ML tools and promote equitable outcomes, guidelines for mitigating this bias and comprehensive workforce training programs are necessary. In response, we developed the multifaceted Human-Centered Use of Multidisciplinary AI for Next-Gen Education and Research (HUMAINE), informed by a comprehensive scoping review, training workshops, and a research symposium. The curriculum, which focuses on structural inequities in algorithms that contribute to health disparities, is designed to equip scientists with AI/ML competencies that allow them to effectively address these structural inequities and promote health equity. The curriculum incorporates the perspectives of clinicians, biostatisticians, engineers, and policymakers to harness AI's transformative potential, with the goal of building an inclusive ecosystem where cutting-edge technology and ethical AI governance converge to create a more equitable healthcare future for all.",
      "authors": "Cary Michael P; Grady Siobahn D; McMillian-Bohler Jacquelyn; Bessias Sophia; Silcox Christina; Silva Susan; Guilamo-Ramos Vincent; McCall Jonathan; Sperling Jessica; Goldstein Benjamin A",
      "year": "2025",
      "journal": "Nursing outlook",
      "doi": "10.1016/j.outlook.2025.102395",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40318249/",
      "mesh_terms": "Humans; Artificial Intelligence; Research Personnel; Curriculum",
      "keywords": "Algorithmic bias; Artificial intelligence; Ethics in AI; Health equity; Healthcare disparities; Machine learning; Social determinants of health; Structural racism; Workforce training",
      "pub_types": "Journal Article",
      "pmcid": "PMC12178818"
    },
    {
      "pmid": "41256428",
      "title": "A Systematic Fairness Evaluation of Racial Bias in Alzheimer's Disease Diagnosis Using Machine Learning Models.",
      "abstract": "INTRODUCTION: Alzheimer's disease (AD) is a major global health concern, expected to affect 12.7 million Americans by 2050. Machine learning (ML) algorithms have been developed for AD diagnosis and progression prediction, but the lack of racial diversity in clinical datasets raises concerns about their generalizability across demographic groups, particularly underrepresented populations. Studies show ML algorithms can inherit biases from data, leading to biased AD predictions. METHODS: This study investigates the fairness of ML models in AD diagnosis. We hypothesize that models trained on a single racial group perform well within that group but poorly in others. We employ feature selection and model training techniques to improve fairness. RESULTS: Our findings support our hypothesis that ML models trained on one group underperform on others. We also demonstrated that applying fairness techniques to ML models reduces their bias. DISCUSSION: This study highlights the need for racial diversity in datasets and fair models for AD prediction.",
      "authors": "Baddam Neha Goud; Pijani Bizhan Alipour; Bozdag Serdar",
      "year": "2025",
      "journal": "bioRxiv : the preprint server for biology",
      "doi": "10.1101/2025.09.30.678854",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41256428/",
      "mesh_terms": "",
      "keywords": "Algorithmic Bias; Alzheimer\u2019s Disease; Fairness; Machine Learning",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12622001"
    },
    {
      "pmid": "41036091",
      "title": "Evaluating the impact of data biases on algorithmic fairness and clinical utility of machine learning models for prolonged opioid use prediction.",
      "abstract": "OBJECTIVES: The growing use of machine learning (ML) in healthcare raises concerns about how data biases affect real-world model performance. While existing frameworks evaluate algorithmic fairness, they often overlook the impact of bias on generalizability and clinical utility, which are critical for safe deployment. Building on prior methods, this study extends bias analysis to include clinical utility, addressing a key gap between fairness evaluation and decision-making. MATERIALS AND METHODS: We applied a 3-phase evaluation to a previously developed model predicting prolonged opioid use (POU), validated on Veterans Health Administration (VHA) data. The analysis included internal and external validation, model retraining on VHA data, and subgroup evaluation across demographic, vulnerable, risk, and comorbidity groups. We assessed performance using area under the receiver operating characteristic curve (AUROC), calibration, and decision curve analysis, incorporating standardized net-benefits to evaluate clinical utility alongside fairness and generalizability. RESULTS: The internal cohort (N\u2009=\u200941\u2009929) had a 14.7% POU prevalence, compared to 34.3% in the external VHA cohort (N\u2009=\u2009397\u2009150). The model's AUROC decreased from 0.74 in the internal test cohort to 0.70 in the full external cohort. Subgroup-level performance averaged 0.69 (SD\u2009=\u20090.01), showing minimal deviation from the external cohort overall. Retraining on VHA data improved AUROCs to 0.82. Clinical utility analysis showed systematic shifts in net-benefit across threshold probabilities. DISCUSSION: While the POU model showed generalizability and fairness internally, external validation and retraining revealed performance and utility shifts across subgroups. CONCLUSION: Population-specific biases affect clinical utility-an often-overlooked dimension in fairness evaluation-a key need to ensure equitable benefits across diverse patient groups.",
      "authors": "Naderalvojoud Behzad; Curtin Catherine; Asch Steven M; Humphreys Keith; Hernandez-Boussard Tina",
      "year": "2025",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooaf115",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41036091/",
      "mesh_terms": "",
      "keywords": "algorithmic fairness; clinical utility; data bias; generalizability; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC12483547"
    },
    {
      "pmid": "38925281",
      "title": "Assessing racial bias in healthcare predictive models: Practical lessons from an empirical evaluation of 30-day hospital readmission models.",
      "abstract": "OBJECTIVE: Despite increased availability of methodologies to identify algorithmic bias, the operationalization of bias evaluation for healthcare predictive models is still limited. Therefore, this study proposes a process for bias evaluation through an empirical assessment of common hospital readmission models. The process includes selecting bias measures, interpretation, determining disparity impact and potential mitigations. METHODS: This retrospective analysis evaluated racial bias of four common models predicting 30-day unplanned readmission (i.e., LACE Index, HOSPITAL Score, and the CMS readmission measure applied as is and retrained). The models were assessed using 2.4 million adult inpatient discharges in Maryland from 2016 to 2019. Fairness metrics that are model-agnostic, easy to compute, and interpretable were implemented and apprised to select the most appropriate bias measures. The impact of changing model's risk thresholds on these measures was further assessed to guide the selection of optimal thresholds to control and mitigate bias. RESULTS: Four bias measures were selected for the predictive task: zero-one-loss difference, false negative rate (FNR) parity, false positive rate (FPR) parity, and generalized entropy index. Based on these measures, the HOSPITAL score and the retrained CMS measure demonstrated the lowest racial bias. White patients showed a higher FNR while Black patients resulted in a higher FPR and zero-one-loss. As the models' risk threshold changed, trade-offs between models' fairness and overall performance were observed, and the assessment showed all models' default thresholds were reasonable for balancing accuracy and bias. CONCLUSIONS: This study proposes an Applied Framework to Assess Fairness of Predictive Models (AFAFPM) and demonstrates the process using 30-day hospital readmission model as the example. It suggests the feasibility of applying algorithmic bias assessment to determine optimized risk thresholds so that predictive models can be used more equitably and accurately. It is evident that a combination of qualitative and quantitative methods and a multidisciplinary team are necessary to identify, understand and respond to algorithm bias in real-world healthcare settings. Users should also apply multiple bias measures to ensure a more comprehensive, tailored, and balanced view. The results of bias measures, however, must be interpreted with caution and consider the larger operational, clinical, and policy context.",
      "authors": "Wang H Echo; Weiner Jonathan P; Saria Suchi; Lehmann Harold; Kharrazi Hadi",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2024.104683",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38925281/",
      "mesh_terms": "Humans; Patient Readmission; Racism; Retrospective Studies; Male; Female; Middle Aged; Adult; Aged; Maryland; Algorithms; Healthcare Disparities",
      "keywords": "Algorithmic Bias; Algorithmic Fairness; Health Disparity; Hospital Readmission; Population Health Management; Predictive Models",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41005257",
      "title": "Fairness in machine learning-based hand load estimation: A case study on load carriage tasks.",
      "abstract": "Predicting external hand load from sensor data is essential for ergonomic exposure assessments, as obtaining this information typically requires direct observation or supplementary data. While machine learning can estimate hand load from posture or force data, we found systematic bias tied to biological sex, with predictive disparities worsening in imbalanced training datasets. To address this, we developed a fair predictive model using a Variational Autoencoder with feature disentanglement, which separates sex-agnostic from sex-specific motion features. This enables predictions based only on sex-agnostic patterns. Our proposed algorithm outperformed conventional machine learning models, including k-Nearest Neighbors, Support Vector Machine, and Random Forest, achieving a mean absolute error of 3.42 and improving fairness metrics like statistical parity and positive and negative residual differences, even when trained on imbalanced sex datasets. These results underscore the importance of fairness-aware algorithms in avoiding health and safety disadvantages for specific worker groups in the workplace.",
      "authors": "Rahman Arafat; Lim Sol; Chung Seokhyun",
      "year": "2025",
      "journal": "Applied ergonomics",
      "doi": "10.1016/j.apergo.2025.104642",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41005257/",
      "mesh_terms": "",
      "keywords": "Algorithmic bias; Fairness; Gait kinematics; Load carriage; Machine learning",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36573157",
      "title": "\"Just\" accuracy? Procedural fairness demands explainability in AI-based medical resource allocations.",
      "abstract": "The increasing application of artificial intelligence (AI) to healthcare raises both hope and ethical concerns. Some advanced machine learning methods provide accurate clinical predictions at the expense of a significant lack of explainability. Alex John London has defended that accuracy is a more important value than explainability in AI medicine. In this article, we locate the trade-off between accurate performance and explainable algorithms in the context of distributive justice. We acknowledge that accuracy is cardinal from outcome-oriented justice because it helps to maximize patients' benefits and optimizes limited resources. However, we claim that the opaqueness of the algorithmic black box and its absence of explainability threatens core commitments of procedural fairness such as accountability, avoidance of bias, and transparency. To illustrate this, we discuss liver transplantation as a case of critical medical resources in which the lack of explainability in AI-based allocation algorithms is procedurally unfair. Finally, we provide a number of ethical recommendations for when considering the use of unexplainable algorithms in the distribution of health-related resources.",
      "authors": "Rueda Jon; Rodr\u00edguez Janet Delgado; Jounou Iris Parra; Hortal-Carmona Joaqu\u00edn; Aus\u00edn Txetxu; Rodr\u00edguez-Arias David",
      "year": "2022",
      "journal": "AI & society",
      "doi": "10.1007/s00146-022-01614-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36573157/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Distributive justice; Explainability; Medical AI; Procedural fairness",
      "pub_types": "Journal Article",
      "pmcid": "PMC9769482"
    },
    {
      "pmid": "39541598",
      "title": "Reducing bias in healthcare artificial intelligence: A white paper.",
      "abstract": "Objective: Mitigation of racism in artificial intelligence (AI) is needed to improve health outcomes, yet no consensus exists on how this might be achieved. Methods: At an international conference in 2022, experts gathered to discuss strategies for reducing bias in healthcare AI. Results: This paper delineates these strategies along with their corresponding strengths and weaknesses and reviews the existing literature on these strategies. Conclusions: Five major themes resulted: reducing dataset bias, accurate modeling of existing data, transparency of artificial intelligence, regulation of artificial intelligence and the people who develop it, and bringing stakeholders to the table.",
      "authors": "Sun Carolyn; Harris Shannon L",
      "year": "2024",
      "journal": "Health informatics journal",
      "doi": "10.1177/14604582241291410",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39541598/",
      "mesh_terms": "Artificial Intelligence; Humans; Bias; Racism; Delivery of Health Care",
      "keywords": "AI; bias; healthcare; machine learning; policy",
      "pub_types": "Journal Article; Consensus Statement",
      "pmcid": ""
    },
    {
      "pmid": "41283058",
      "title": "Development of machine learning models with explainable AI for frailty risk prediction and their web-based application in community public health.",
      "abstract": "BACKGROUND: Frailty is a public health concern linked to falls, disability, and mortality. Early screening and tailored interventions can mitigate adverse outcomes, but community settings require tools that are accurate and explainable. Korea is entering a super-aged phase, yet few approaches have used nationally representative survey data. OBJECTIVE: This study aimed to identify key predictors of frailty risk using the K-FRAIL scale using explainable machine learning (ML), based on data from the 2023 National Survey of Older Koreans (NSOK). It also sought to develop and internally validate prediction models. To demonstrate the potential applicability of these models in community public health and clinical practice, a web-based application was implemented. METHODS: Data from 10,078 older adults were analyzed, with frailty defined by the K-FRAIL scale (robust\u202f=\u202f0, pre-frail\u202f=\u202f1-2, and frail\u202f=\u202f3-5). A total of 132 candidate variables were constructed through selection and derivation. Using CatBoost with out-of-fold (OOF) SHapley Additive exPlanations (SHAP, a game-theoretic approach to quantify feature contributions), 15 key predictors were identified and applied across 10 algorithms under nested cross-validation (CV). Model performance was evaluated using receiver operating characteristic-area under the curve (ROC-AUC), precision-recall area under the curve (PR-AUC), F1-score, balanced accuracy, and the Brier score. To assess feasibility, a single-page bilingual web application was developed, integrating the CatBoost inference pipeline for offline use. RESULTS: SHAP analysis identified depression score, age, instrumental activities of daily living (IADL) count, sleep quality, and cognition as the leading predictors, followed by smartphone use, number of medications, province, driving status, hospital use, physical activity, osteoporosis, eating alone, digital adaptation difficulty, and sex, yielding 15 key predictors across the mental, functional, lifestyle, social, and digital domains. Using these predictors, boosting models outperformed other algorithms, with CatBoost achieving the best performance (ROC-AUC\u202f=\u202f0.813\u202f\u00b1\u202f0.014; PR-AUC\u202f=\u202f0.748\u202f\u00b1\u202f0.019). CONCLUSION: An explainable machine learning model with strong discrimination performance and adequate calibration was developed, accompanied by a lightweight web application for potential use in community and clinical settings. However, external validation, recalibration, and subgroup fairness assessments are needed to ensure generalizability and clinical adoption.",
      "authors": "Kim Seungmi; Choi Byung Kwan; Cho Jeong Su; Huh Up; Shin Myung-Jun; Obradovic Zoran; Rubin Daniel J; Lee Jae Il; Park Jong-Hwan",
      "year": "2025",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2025.1698062",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41283058/",
      "mesh_terms": "Humans; Machine Learning; Aged; Male; Republic of Korea; Female; Frailty; Public Health; Aged, 80 and over; Internet; Risk Assessment; Geriatric Assessment; Frail Elderly",
      "keywords": "SHAP; digital health; explainable AI; frailty; machine learning; prediction model",
      "pub_types": "Journal Article",
      "pmcid": "PMC12629939"
    },
    {
      "pmid": "37615359",
      "title": "Toward Advancing Precision Environmental Health: Developing a Customized Exposure Burden Score to PFAS Mixtures to Enable Equitable Comparisons Across Population Subgroups, Using Mixture Item Response Theory.",
      "abstract": "Quantifying a person's cumulative exposure burden to per- and polyfluoroalkyl substances (PFAS) mixtures is important for risk assessment, biomonitoring, and reporting of results to participants. However, different people may be exposed to different sets of PFASs due to heterogeneity in the exposure sources and patterns. Applying a single measurement model for the entire population (e.g., by summing concentrations of all PFAS analytes) assumes that each PFAS analyte is equally informative to PFAS exposure burden for all individuals. This assumption may not hold if PFAS exposure sources systematically differ within the population. However, the sociodemographic, dietary, and behavioral characteristics that underlie systematic exposure differences may not be known, or may be due to a combination of these factors. Therefore, we used mixture item response theory, an unsupervised psychometrics and data science method, to develop a customized PFAS exposure burden scoring algorithm. This scoring algorithm ensures that PFAS burden scores can be equitably compared across population subgroups. We applied our methods to PFAS biomonitoring data from the United States National Health and Nutrition Examination Survey (2013-2018). Using mixture item response theory, we found that participants with higher household incomes had higher PFAS burden scores. Asian Americans had significantly higher PFAS burden compared with non-Hispanic Whites and other race/ethnicity groups. However, some disparities were masked when using summed PFAS concentrations as the exposure metric. This work demonstrates that our summary PFAS burden metric, accounting for sources of exposure variation, may be a more fair and informative estimate of PFAS exposure.",
      "authors": "Liu Shelley H; Feuerstahler Leah; Chen Yitong; Braun Joseph M; Buckley Jessie P",
      "year": "2023",
      "journal": "Environmental science & technology",
      "doi": "10.1021/acs.est.3c00343",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37615359/",
      "mesh_terms": "Humans; United States; Environmental Pollutants; Alkanesulfonic Acids; Nutrition Surveys; Fluorocarbons; Environmental Health",
      "keywords": "algorithmic bias; chemical mixtures; fairness; item response theory; latent variables; per- and polyfluoroalkyl substances; precision environmental health; psychometrics",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11106720"
    },
    {
      "pmid": "30288421",
      "title": "Efficient and Fair Heart Allocation Policies for Transplantation.",
      "abstract": "Background: The optimal allocation of limited donated hearts to patients on the waiting list is one of the top priorities in heart transplantation management. We developed a simulation model of the US waiting list for heart transplantation to investigate the potential impacts of allocation policies on several outcomes such as pre- and posttransplant mortality. Methods: We used data from the United Network for Organ Sharing (UNOS) and the Scientific Registry of Transplant Recipient (SRTR) to simulate the heart allocation system. The model is validated by comparing the outcomes of the simulation with historical data. We also adapted fairness schemes studied in welfare economics to provide a framework to assess the fairness of allocation policies for transplantation. We considered three allocation policies, each a modification to the current UNOS allocation policy, and analyzed their performance via simulation. The first policy broadens the geographical allocation zones, the second modifies the health status order for receiving hearts, and the third prioritizes patients according to their waiting time. Results: Our results showed that the allocation policy similar to the current UNOS practice except that it aggregates the three immediate geographical allocation zones, improves the health outcomes, and is \"closer\" to an optimal fair policy compared to all other policies considered in this study. Specifically, this policy could have saved 319 total deaths (out of 3738 deaths) during the 2006 to 2014 time horizon, in average. This policy slightly differs from the current UNOS allocation policy and allows for easy implementation. Conclusion: We developed a model to compare the outcomes of heart allocation policies. Combining the three immediate geographical zones in the current allocation algorithm could potentially reduce mortality rate and is closer to an optimal fair policy.",
      "authors": "Hasankhani Farhad; Khademi Amin",
      "year": "2017",
      "journal": "MDM policy & practice",
      "doi": "10.1177/2381468317709475",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30288421/",
      "mesh_terms": "",
      "keywords": "allocation policy; fairness; heart failure; simulation; survival; transplantation",
      "pub_types": "Journal Article",
      "pmcid": "PMC6125046"
    },
    {
      "pmid": "40880105",
      "title": "Algorithms to Improve Fairness in Medicare Risk Adjustment.",
      "abstract": "IMPORTANCE: Payment system design creates incentives that affect health care spending, access, and outcomes. With Medicare Advantage accounting for more than half of Medicare spending, changes to its risk adjustment algorithm have the potential for broad consequences. OBJECTIVE: To assess the potential for algorithmic tools to achieve more equitable plan payment for Medicare risk adjustment while maintaining current levels of performance, flexibility, feasibility, transparency, and interpretability. DESIGN, SETTING, AND PARTICIPANTS: This diagnostic study included a retrospective analysis of traditional Medicare enrollment and claims data generated between January 1, 2017, and December 31, 2020, from a random 20% sample of non-dual-eligible Medicare beneficiaries with documented residence in the US or Puerto Rico. Race and ethnicity were designated using the Research Triangle Institute enhanced indicator. Diagnoses in claims were mapped to hierarchical condition categories. Algorithms used demographic indicators and hierarchical condition categories from 1 calendar year to predict Medicare spending in the subsequent year. Data analysis was conducted between August 16, 2023, and January 27, 2025. MAIN OUTCOMES AND MEASURES: The main outcome was prospective health care spending by Medicare. Overall performance was measured by payment system fit and mean absolute error. Net compensation was used to assess group-level fairness. RESULTS: The main analysis of Medicare risk adjustment algorithms included 4\u202f398\u202f035 Medicare beneficiaries with a mean (SD) age of 75.2 (7.4) years and mean (SD) annual Medicare spending of $8345 ($18\u202f581); 44% were men; fewer than 1% were American Indian or Alaska Native, 2% were Asian or Other Pacific Islander, 6% were Black, 3% were Hispanic, 86% were non-Hispanic White, and 1% were part of an additional group (termed as other in the Centers for Medicare & Medicaid Services data). Out-of-sample payment system fit for the baseline regression was 12.7%. Constrained regression and postprocessing both achieved fair spending targets while maintaining payment system fit (constrained regression, 12.6%; postprocessing, 12.7%). Whereas postprocessing increased mean payments for beneficiaries in minoritized racial and ethnic groups (American Indian or Alaska Native, Asian or Other Pacific Islander, Black, and Hispanic individuals) only, constrained regression increased mean payments for beneficiaries in minoritized racial and ethnic groups and beneficiaries in other groups residing in counties with greater exposure to socioeconomic factors that can adversely affect health outcomes. CONCLUSIONS AND RELEVANCE: Results of this study suggest that constrained regression and postprocessing can incorporate fairness objectives into the Medicare risk adjustment algorithm with minimal reduction in overall fit. These feasible changes to the Medicare risk adjustment algorithm could be considered by policymakers aiming to address health care disparities through payment system reform.",
      "authors": "Reitsma Marissa B; McGuire Thomas G; Rose Sherri",
      "year": "2025",
      "journal": "JAMA health forum",
      "doi": "10.1001/jamahealthforum.2025.2640",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40880105/",
      "mesh_terms": "Humans; United States; Algorithms; Risk Adjustment; Medicare; Male; Retrospective Studies; Female; Aged; Health Expenditures; Aged, 80 and over; Medicare Part C",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12397885"
    },
    {
      "pmid": "40598240",
      "title": "Implicit bias in ICU electronic health record data: measurement frequencies and missing data rates of clinical variables.",
      "abstract": "BACKGROUND: Systematic disparities in data collection within electronic health records (EHRs), defined as non-random patterns in the measurement and recording of clinical variables across demographic groups, can be reflective of underlying implicit bias and may affect patient outcome. Identifying and mitigating these biases is critical for ensuring equitable healthcare. This study aims to develop an analytical framework for measurement patterns, defined as the combination of measurement frequency (how often variables are collected) and missing data rates (the frequency of missing recordings), evaluate the association between them and demographic factors, and assess their impact on in-hospital mortality prediction. METHODS: We conducted a retrospective cohort study using the Medical Information Mart for Intensive Care III (MIMIC-III) database, which includes data on over 40,000 ICU patients from Beth Israel Deaconess Medical Center (2001-2012). Adult patients with ICU stays longer than 24\u00a0h were included. Measurement patterns, including missing data rates and measurement frequencies, were derived from EHR data and analyzed. Targeted Machine Learning (TML) methods were used to assess potential systematic disparities in measurement patterns across demographic factors (age, gender, race/ethnicity) while controlling for confounders such as other demographics and disease severity. The predictive power of measurement patterns on in-hospital mortality was evaluated. RESULTS: Among 23,426 patients, significant demographic systematic disparities were observed in the first 24\u00a0h of ICU stays. Elderly patients (\u2265\u200965 years) had more frequent temperature measurements compared to younger patients, while males had slightly fewer missing temperature measurements than females. Racial disparities were notable: White patients had more frequent blood pressure and oxygen saturation (SpO2) measurements compared to Black and Hispanic patients. Measurement patterns were associated with ICU mortality, with models based solely on these patterns achieving an area under the receiver operating characteristic curve (AUC) of 0.76 (95% CI: 0.74-0.77). CONCLUSIONS: This study underscores the significance of measurement patterns in ICU EHR data, which are associated with patient demographics and ICU mortality. Analyzing patterns of missing data and measurement frequencies provides valuable insights into patient monitoring practices and potential systemic disparities in healthcare delivery. Understanding these disparities is critical for improving the fairness of healthcare delivery and developing more accurate predictive models in critical care settings. CLINICAL TRIAL NUMBER: Not applicable.",
      "authors": "Shi Junming; Hubbard Alan E; Fong Nicholas; Pirracchio Romain",
      "year": "2025",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-025-03058-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40598240/",
      "mesh_terms": "Humans; Electronic Health Records; Female; Male; Intensive Care Units; Middle Aged; Retrospective Studies; Aged; Hospital Mortality; Adult; Bias; Machine Learning",
      "keywords": "Bias detection; Critical care; Data completeness; Electronic health records (EHRs); Health equity; Healthcare applications; Implicit bias; MIMIC-III dataset; Measurement frequency; Systematic disparities",
      "pub_types": "Journal Article",
      "pmcid": "PMC12220764"
    },
    {
      "pmid": "41512215",
      "title": "Understanding algorithmic fairness for clinical prediction in terms of subgroup net benefit and health equity.",
      "abstract": "There are concerns about the fairness of clinical prediction models. 'Fair' models are defined as those for which their performance or predictions are not inappropriately influenced by protected attributes such as ethnicity, gender, or socio-economic status. Researchers have raised concerns that current algorithmic fairness paradigms enforce strict egalitarianism in healthcare, leveling down the performance of models in higher-performing subgroups instead of improving it in lower-performing ones. We propose assessing the fairness of a prediction model by expanding the concept of net benefit, using it to quantify and compare the clinical impact of a model in different subgroups. We use this to explore how a model distributes benefit across a population, its impact on health inequalities, and its role in the achievement of health equity. We show how resource constraints might introduce necessary trade-offs between health equity and other objectives of healthcare systems. We showcase our proposed approach with the development of two clinical prediction models: 1) a prognostic type 2 diabetes model used by clinicians to enrol patients into a preventive care lifestyle intervention programme, and 2) a lung cancer screening algorithm used to allocate diagnostic scans across the population. This approach helps modelers better understand if a model upholds health equity by considering its performance in a clinical and social context.",
      "authors": "Benitez-Aurioles Jose; Joules Alice; Brusini Irene; Peek Niels; Sperrin Matthew",
      "year": "2025",
      "journal": "Epidemiology (Cambridge, Mass.)",
      "doi": "10.1097/EDE.0000000000001949",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41512215/",
      "mesh_terms": "",
      "keywords": "Clinical prediction models; UK Biobank; fairness; health equity; net benefit",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40417536",
      "title": "Does Cohort Selection Affect Machine Learning from Clinical Data?",
      "abstract": "This study investigates cohort selection and its effects on the quality of machine learning (ML) models trained on clinical data, focusing on measurements taken within the first 48 hours of hospital admission. It discusses the potential repercussions of making arbitrary decisions during data processing prior to applying ML methods. Experiments are performed within the framework of the National COVID Cohort Collaborative (N3C) dataset. The research aims to unravel biases and assess the fairness of machine learning models used to predict outcomes for hospitalized patients. Detailed discussions cover the data, decision-making processes, and the resulting impact on model predictions regarding patient outcomes. An experiment is conducted in which four arbitrary decisions are made, resulting in 16 distinct datasets characterized by varying sizes and properties. The findings demonstrate significant differences in the obtained datasets and indicate a high potential for bias based on inclusion or exclusion decisions. The results also confirm significant differences in the performance of models constructed on different cohorts, especially when cross-compared between ones based on different inclusion criteria. The study specifically chose to analyze gender, race, and ethnicity as these social determinants of health played a significant role in COVID-19 outcomes.",
      "authors": "Haghighathoseini Atefehsadat; Wojtusiak Janusz; Min Hua; Leslie Timothy; Frankenfeld Cara; Menon Nirup M",
      "year": "2024",
      "journal": "AMIA ... Annual Symposium proceedings. AMIA Symposium",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40417536/",
      "mesh_terms": "Machine Learning; Humans; COVID-19; Cohort Studies; SARS-CoV-2; Female; Male",
      "keywords": "Data Processing; Machine Learning; National COVID Cohort Collaborative (N3C); Prediction; Selection Bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC12099332"
    },
    {
      "pmid": "36396503",
      "title": "Algorithmic bias in health care: Opportunities for nurses to improve equality in the age of artificial intelligence.",
      "abstract": "",
      "authors": "O'Connor Siobhan; Booth Richard G",
      "year": "2022",
      "journal": "Nursing outlook",
      "doi": "10.1016/j.outlook.2022.09.003",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36396503/",
      "mesh_terms": "Humans; Artificial Intelligence; Bias; Delivery of Health Care",
      "keywords": "Algorithms; Artificial Intelligence; Bias; Health care; Machine learning; Natural language processing; Neural networks; Nursing",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39979842",
      "title": "Optimized machine learning framework for cardiovascular disease diagnosis: a novel ethical perspective.",
      "abstract": "Alignment of advanced cutting-edge technologies such as Artificial Intelligence (AI) has emerged as a significant driving force to achieve greater precision and timeliness in identifying cardiovascular diseases (CVDs). However, it is difficult to achieve high accuracy and reliability in CVD diagnostics due to complex clinical data and the selection and modeling process of useful features. Therefore, this paper studies advanced AI-based feature selection techniques and the application of AI technologies in the CVD classification. It uses methodologies such as Chi-square, Info Gain, Forward Selection, and Backward Elimination as an essence of cardiovascular health indicators into a refined eight-feature subset. This study emphasizes ethical considerations, including transparency, interpretability, and bias mitigation. This is achieved by employing unbiased datasets, fair feature selection techniques, and rigorous validation metrics to ensure fairness and trustworthiness in the AI-based diagnostic process. In addition, the integration of various Machine Learning (ML) models, encompassing Random Forest (RF), XGBoost, Decision Trees (DT), and Logistic Regression (LR), facilitates a comprehensive exploration of predictive performance. Among this diverse range of models, XGBoost stands out as the top performer, achieving exceptional scores with a 99% accuracy rate, 100% recall, 99% F1-measure, and 99% precision. Furthermore, we venture into dimensionality reduction, applying Principal Component Analysis (PCA) to the eight-feature subset, effectively refining it to a compact six-attribute feature subset. Once again, XGBoost shines as the model of choice, yielding outstanding results. It achieves accuracy, recall, F1-measure, and precision scores of 98%, 100%, 98%, and 97%, respectively, when applied to the feature subset derived from the combination of Chi-square and Forward Selection methods.",
      "authors": "Alwakid Ghadah; Ul Haq Farman; Tariq Noshina; Humayun Mamoona; Shaheen Momina; Alsadun Marwa",
      "year": "2025",
      "journal": "BMC cardiovascular disorders",
      "doi": "10.1186/s12872-025-04550-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39979842/",
      "mesh_terms": "Humans; Machine Learning; Cardiovascular Diseases; Predictive Value of Tests; Reproducibility of Results; Diagnosis, Computer-Assisted; Decision Support Techniques; Decision Trees",
      "keywords": "Artificial intelligence; Cardiovascular diseases; Chi-square; Decision trees; Feature selection; K-nearest neighbours; Logistic regression; Machine learning; Principal component analysis; Random forest; XGBoost",
      "pub_types": "Journal Article",
      "pmcid": "PMC11844188"
    },
    {
      "pmid": "41111097",
      "title": "Development and Validation of an Electronic Health Record-Derived Prediction Model for Preventing COVID-19 Hospitalization and Death.",
      "abstract": "Hospitalization and death following COVID-19 infection continue to pose a major public health concern and place strain on health system resources. Outpatient antiviral medication can reduce the risk of COVID-19 hospitalization and death for those at risk of poor outcomes, but identifying high-risk populations who may benefit most from treatment is challenging. The objective of this study was to develop and validate a prediction model for the composite outcome of hospitalization or death in the 14\u00a0days following COVID-19 infection. Our sample included 67,530 COVID-19 infections documented in outpatient care and occurring between April 1, 2020, and November 1, 2022, for 64,529 Kaiser Permanente Washington patients who did not receive outpatient antiviral treatment; 1378 (2.0%) of these infections resulted in hospitalization or death. Our prediction model, estimated using logistic regression with LASSO variable selection and ridge penalization, included 19 risk factors and showed high performance, including an area under the curve of 0.825 (95% confidence interval 0.813-0.836). Among the 10% of infections with the highest risk predictions, the true positive rate was 48% (46-51%) and the positive predictive value was 9.9% (9.2-10.6%). Supplemental analyses confirmed strong model performance across racial and ethnic subgroups and over time. We also present our process for selecting a risk threshold above which to recommend antiviral treatment and discuss considerations for prospective clinical implementation. This project demonstrates that machine learning tools can be used by health systems to deliver timely, targeted secondary prevention to reduce the risk of serious illness or death.",
      "authors": "Coley R Yates; Hays Rachel; Pardee Roy E; Fuller Sharon; Rogers Kristine; Allen Claire L; Arterburn David E; Frazier Robert K; Kent Daniel J; Mun Sophia; Mwatha Tolani; Thottingal Paul; Westbrook Emily O",
      "year": "2025",
      "journal": "Prevention science : the official journal of the Society for Prevention Research",
      "doi": "10.1007/s11121-025-01844-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41111097/",
      "mesh_terms": "",
      "keywords": "Algorithm fairness; Clinical prediction model; Health equity; Learning health system; Nirmatrelvir/ritonavir (Paxlovid\u00ae); Prospective validation",
      "pub_types": "Journal Article",
      "pmcid": "8531997"
    },
    {
      "pmid": "35353048",
      "title": "Leveraging Machine Learning to Understand How Emotions Influence Equity Related Education: Quasi-Experimental Study.",
      "abstract": "BACKGROUND: Teaching and learning about topics such as bias are challenging due to the emotional nature of bias-related discourse. However, emotions can be challenging to study in health professions education for numerous reasons. With the emergence of machine learning and natural language processing, sentiment analysis (SA) has the potential to bridge the gap. OBJECTIVE: To improve our understanding of the role of emotions in bias-related discourse, we developed and conducted a SA of bias-related discourse among health professionals. METHODS: We conducted a 2-stage quasi-experimental study. First, we developed a SA (algorithm) within an existing archive of interviews with health professionals about bias. SA refers to a mechanism of analysis that evaluates the sentiment of textual data by assigning scores to textual components and calculating and assigning a sentiment value to the text. Next, we applied our SA algorithm to an archive of social media discourse on Twitter that contained equity-related hashtags to compare sentiment among health professionals and the general population. RESULTS: When tested on the initial archive, our SA algorithm was highly accurate compared to human scoring of sentiment. An analysis of bias-related social media discourse demonstrated that health professional tweets (n=555) were less neutral than the general population (n=6680) when discussing social issues on professionally associated accounts (\u03c72 [2, n=555)]=35.455; P<.001), suggesting that health professionals attach more sentiment to their posts on Twitter than seen in the general population. CONCLUSIONS: The finding that health professionals are more likely to show and convey emotions regarding equity-related issues on social media has implications for teaching and learning about sensitive topics related to health professions education. Such emotions must therefore be considered in the design, delivery, and evaluation of equity and bias-related education.",
      "authors": "Sukhera Javeed; Ahmed Hasan",
      "year": "2022",
      "journal": "JMIR medical education",
      "doi": "10.2196/33934",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35353048/",
      "mesh_terms": "",
      "keywords": "bias; education; emotion; equity; medical education; sentiment analysis",
      "pub_types": "Journal Article",
      "pmcid": "PMC9008524"
    },
    {
      "pmid": "40905712",
      "title": "Detecting, Characterizing, and Mitigating Implicit and Explicit Racial Biases in Health Care Datasets With Subgroup Learnability: Algorithm Development and Validation Study.",
      "abstract": "BACKGROUND: The growing adoption of diagnostic and prognostic algorithms in health care has led to concerns about the perpetuation of algorithmic bias against disadvantaged groups of individuals. Deep learning methods to detect and mitigate bias have revolved around modifying models, optimization strategies, and threshold calibration with varying levels of success and tradeoffs. However, there have been limited substantive efforts to address bias at the level of the data used to generate algorithms in health care datasets. OBJECTIVE: The aim of this study is to create a simple metric (AEquity) that uses a learning curve approximation to distinguish and mitigate bias via guided dataset collection or relabeling. METHODS: We demonstrate this metric in 2 well-known examples, chest X-rays and health care cost utilization, and detect novel biases in the National Health and Nutrition Examination Survey. RESULTS: We demonstrated that using AEquity to guide data-centric collection for each diagnostic finding in the chest radiograph dataset decreased bias by between 29% and 96.5% when measured by differences in area under the curve. Next, we wanted to examine (1) whether AEquity worked on intersectional populations and (2) if AEquity is invariant to different types of fairness metrics, not just area under the curve. Subsequently, we examined the effect of AEquity on mitigating bias when measured by false negative rate, precision, and false discovery rate for Black patients on Medicaid. When we examined Black patients on Medicaid, at the intersection of race and socioeconomic status, we found that AEquity-based interventions reduced bias across a number of different fairness metrics including overall false negative rate by 33.3% (bias reduction absolute=1.88\u00d710-1, 95% CI 1.4\u00d710-1 to 2.5\u00d710-1; bias reduction of 33.3%, 95% CI 26.6%-40%; precision bias by 7.50\u00d710-2, 95% CI 7.48\u00d710-2 to 7.51\u00d710-2; bias reduction of 94.6%, 95% CI 94.5%-94.7%; false discovery rate by 94.5%; absolute bias reduction=3.50\u00d710-2, 95% CI 3.49\u00d710-2 to 3.50\u00d710-2). Similarly, AEquity-guided data collection demonstrated bias reduction of up to 80% on mortality prediction with the National Health and Nutrition Examination Survey (bias reduction absolute=0.08, 95% CI 0.07-0.09). Then, we wanted to compare AEquity to state-of-the-art data-guided debiasing measures such as balanced empirical risk minimization and calibration. Consequently, we benchmarked against balanced empirical risk minimization and calibration and showed that AEquity-guided data collection outperforms both standard approaches. Moreover, we demonstrated that AEquity works on fully connected networks; convolutional neural networks such as ResNet-50; transformer architectures such as VIT-B-16, a vision transformer with 86 million parameters; and nonparametric methods such as Light Gradient-Boosting Machine. CONCLUSIONS: In short, we demonstrated that AEquity is a robust tool by applying it to different datasets, algorithms, and intersectional analyses and measuring its effectiveness with respect to a range of traditional fairness metrics.",
      "authors": "Gulamali Faris; Sawant Ashwin Shreekant; Liharska Lora; Horowitz Carol; Chan Lili; Hofer Ira; Singh Karandeep; Richardson Lynne; Mensah Emmanuel; Charney Alexander; Reich David; Hu Jianying; Nadkarni Girish",
      "year": "2025",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/71757",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40905712/",
      "mesh_terms": "Bias; Humans; Datasets as Topic; Routinely Collected Health Data; Radiography, Thoracic; Health Care Costs; Black or African American; Medicaid; Race Factors; Social Class; Nutrition Surveys; Machine Learning; Data Curation; Mortality; United States",
      "keywords": "bias; data-centric artificial intelligence; fairness; machine learning",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC12410029"
    },
    {
      "pmid": "29104450",
      "title": "Optimizing Variance-Bias Trade-off in the TWANG Package for Estimation of Propensity Scores.",
      "abstract": "While propensity score weighting has been shown to reduce bias in treatment effect estimation when selection bias is present, it has also been shown that such weighting can perform poorly if the estimated propensity score weights are highly variable. Various approaches have been proposed which can reduce the variability of the weights and the risk of poor performance, particularly those based on machine learning methods. In this study, we closely examine approaches to fine-tune one machine learning technique (generalized boosted models [GBM]) to select propensity scores that seek to optimize the variance-bias trade-off that is inherent in most propensity score analyses. Specifically, we propose and evaluate three approaches for selecting the optimal number of trees for the GBM in the twang package in R. Normally, the twang package in R iteratively selects the optimal number of trees as that which maximizes balance between the treatment groups being considered. Because the selected number of trees may lead to highly variable propensity score weights, we examine alternative ways to tune the number of trees used in the estimation of propensity score weights such that we sacrifice some balance on the pre-treatment covariates in exchange for less variable weights. We use simulation studies to illustrate these methods and to describe the potential advantages and disadvantages of each method. We apply these methods to two case studies: one examining the effect of dog ownership on the owner's general health using data from a large, population-based survey in California, and a second investigating the relationship between abstinence and a long-term economic outcome among a sample of high-risk youth.",
      "authors": "Parast Layla; McCaffrey Daniel F; Burgette Lane F; de la Guardia Fernando Hoces; Golinelli Daniela; Miles Jeremy N V; Griffin Beth Ann",
      "year": "2017",
      "journal": "Health services & outcomes research methodology",
      "doi": "10.1007/s10742-016-0168-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29104450/",
      "mesh_terms": "",
      "keywords": "causal inference; machine learning; propensity score",
      "pub_types": "Journal Article",
      "pmcid": "PMC5667923"
    },
    {
      "pmid": "36865610",
      "title": "Identification of Social and Racial Disparities in Risk of HIV Infection in Florida using Causal AI Methods.",
      "abstract": "Florida -the 3rd most populous state in the USA-has the highest rates of Human Immunodeficiency Virus (HIV) infections and of unfavorable HIV outcomes, with marked social and racial disparities. In this work, we leveraged large-scale, real-world data, i.e., statewide surveillance records and publicly available data resources encoding social determinants of health (SDoH), to identify social and racial disparities contributing to individuals' risk of HIV infection. We used the Florida Department of Health's Syndromic Tracking and Reporting System (STARS) database (including 100,000+ individuals screened for HIV infection and their partners), and a novel algorithmic fairness assessment method -the Fairness-Aware Causal paThs decompoSition (FACTS)- merging causal inference and artificial intelligence. FACTS deconstructs disparities based on SDoH and individuals' characteristics, and can discover novel mechanisms of inequity, quantifying to what extent they could be reduced by interventions. We paired the deidentified demographic information (age, gender, drug use) of 44,350 individuals in STARS -with non-missing data on interview year, county of residence, and infection status- to eight SDoH, including access to healthcare facilities, % uninsured, median household income, and violent crime rate. Using an expert-reviewed causal graph, we found that the risk of HIV infection for African Americans was higher than for non- African Americans (both in terms of direct and total effect), although a null effect could not be ruled out. FACTS identified several paths leading to racial disparity in HIV risk, including multiple SDoH: education, income, violent crime, drinking, smoking, and rurality.",
      "authors": "Prosperi Mattia; Xu Jie; Guo Jingchuan Serena; Bian Jiang; Chen Wei-Han William; Canidate Shantrel; Marini Simone; Wang Mo",
      "year": "2022",
      "journal": "Proceedings. IEEE International Conference on Bioinformatics and Biomedicine",
      "doi": "10.1109/bibm55620.2022.9995662",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36865610/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; causal inference; disparity; epidemiology; human immunodeficiency virus; machine learning; real-world data; social determinants of health; surveillance",
      "pub_types": "Journal Article",
      "pmcid": "PMC9977319"
    },
    {
      "pmid": "41107862",
      "title": "Navigating fairness aspects of clinical prediction models.",
      "abstract": "BACKGROUND: Algorithms are increasingly used in healthcare, yet most algorithms lack thorough evaluation and impact assessment across diverse populations. This absence of comprehensive scrutiny introduces a significant risk of inequitable clinical outcomes, particularly between different demographic and socioeconomic groups. MAIN BODY: Societal biases-rooted in structural inequalities and systemic discrimination-often shape the data used to develop these algorithms. When such biases become embedded into predictive models, algorithms frequently favor privileged populations, further deepening existing inequalities. Without proactive efforts to identify and mitigate these biases, algorithms risk disproportionately harming already marginalized groups, widening the gap between advantaged and disadvantaged patients. Various statistical metrics are available to assess algorithmic fairness, each addressing different dimensions of disparity in predictive performance across population groups. However, understanding and applying these fairness metrics in real-world healthcare settings remains limited. Transparency in both the development and communication of algorithms is essential to building a more equitable healthcare system. Openly addressing fairness concerns fosters trust and accountability, ensuring that fairness considerations become an integral part of algorithm design and implementation rather than an afterthought. Using a participatory approach involving three clinicians and three patients with lived experience of type 2 diabetes, we developed a set of guiding questions to help healthcare professionals assess algorithms critically, challenge existing practices, and stimulate discussions. CONCLUSIONS: We aim to direct healthcare professionals on navigating the complexities of bias in healthcare algorithms by encouraging critical thinking about biases present in society, data, algorithms, and healthcare systems.",
      "authors": "Chakradeo Kaustubh; Huynh Inchuen; Balaganeshan Sedrah B; Dollerup Ole L; Gade-J\u00f8rgensen Hj\u00f8rdis; Laupstad Susanne K; Malham Mikkel; Nguyen Tri-Long; Hulman Adam; Varga Tibor V",
      "year": "2025",
      "journal": "BMC medicine",
      "doi": "10.1186/s12916-025-04340-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41107862/",
      "mesh_terms": "Humans; Algorithms; Diabetes Mellitus, Type 2; Healthcare Disparities",
      "keywords": "Algorithmic fairness; Algorithms; Clinical decision rules; Clinical decision-making; Delivery of healthcare; Fairness; Health inequities; Health personnel; Prediction algorithms; Risk factors",
      "pub_types": "Journal Article",
      "pmcid": "PMC12535043"
    },
    {
      "pmid": "40718760",
      "title": "A fair machine learning model to predict flares of systemic lupus erythematosus.",
      "abstract": "OBJECTIVE: Systemic lupus erythematosus (SLE) is a chronic autoimmune disease that disproportionately affects women and racial/ethnic minority groups. Predicting disease flares is essential for improving patient outcomes, yet few studies integrate both clinical and social determinants of health (SDoH). We therefore developed FLAME (FLAre Machine learning prediction of SLE), a machine learning pipeline that uses electronic health records (EHRs) and contextual-level SDoH to predict 3-month flare risk, emphasizing explainability and fairness. MATERIALS AND METHODS: We conducted a retrospective cohort study of 28\u2009433 patients with SLE from the University of Florida Health (2011-2022), linked to 675 contextual-level SDoH variables. We used XGBoost and logistic regression models to predict 3-month flare risk, evaluating model performance using the area under the receiver operating characteristic (AUROC). We applied SHapley Additive exPlanations (SHAP) values and causal structure learning to identify key predictors. Fairness was assessed using the equality of opportunity metric, measured by the false-negative rate across racial/ethnic groups. RESULTS: The FLAME model, incorporating clinical and contextual-level SDoH, achieved an AUROC of 0.66. The clinical-only model performed slightly better (AUROC of 0.67), while the SDoH-only model had lower performance (AUROC of 0.54). SHAP analysis identified headache, organic brain syndrome, and pyuria as key predictors. Causal learning revealed interactions between clinical factors and contextual-level SDoH. Fairness assessments showed no significant biases across groups. DISCUSSION: FLAME offers a fair and interpretable approach to predicting SLE flares, providing meaningful insights that may guide future clinical interventions. CONCLUSIONS: FLAME shows promise as an EHR-based tool to support personalized, equitable, and holistic SLE care.",
      "authors": "Li Yongqiu; Yao Lixia; Lee Yao An; Huang Yu; Merkel Peter A; Vina Ernest; Yeh Ya-Yun; Li Yujia; Allen John M; Bian Jiang; Guo Jingchuan",
      "year": "2025",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooaf072",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40718760/",
      "mesh_terms": "",
      "keywords": "fairness; machine learning; prediction; social determinants of health; systemic lupus erythematosus",
      "pub_types": "Journal Article",
      "pmcid": "PMC12296391"
    },
    {
      "pmid": "39252056",
      "title": "Clinician voices on ethics of LLM integration in healthcare: a thematic analysis of ethical concerns and implications.",
      "abstract": "OBJECTIVES: This study aimed to explain and categorize key ethical concerns about integrating large language models (LLMs) in healthcare, drawing particularly from the perspectives of clinicians in online discussions. MATERIALS AND METHODS: We analyzed 3049 posts and comments extracted from a self-identified clinician subreddit using unsupervised machine learning via Latent Dirichlet Allocation and a structured qualitative analysis methodology. RESULTS: Analysis uncovered 14 salient themes of ethical implications, which we further consolidated into 4 overarching domains reflecting ethical issues around various clinical applications of LLM in healthcare, LLM coding, algorithm, and data governance, LLM's role in health equity and the distribution of public health services, and the relationship between users (human) and LLM systems (machine). DISCUSSION: Mapping themes to ethical frameworks in literature illustrated multifaceted issues covering transparent LLM decisions, fairness, privacy, access disparities, user experiences, and reliability. CONCLUSION: This study emphasizes the need for ongoing ethical review from stakeholders to ensure responsible innovation and advocates for tailored governance to enhance LLM use in healthcare, aiming to improve clinical outcomes ethically and effectively.",
      "authors": "Mirzaei Tala; Amini Leila; Esmaeilzadeh Pouyan",
      "year": "2024",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-024-02656-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39252056/",
      "mesh_terms": "Humans; Attitude of Health Personnel; Delivery of Health Care; Qualitative Research",
      "keywords": "Artificial Intelligence; Ethics; LLM; Thematic analysis; Theme",
      "pub_types": "Journal Article",
      "pmcid": "PMC11382443"
    },
    {
      "pmid": "40721333",
      "title": "Predicting Missed Appointments in Primary Care: A Personalized Machine Learning Approach.",
      "abstract": "PURPOSE: Factors influencing missed appointments are complex and difficult to anticipate and intervene against. To optimize appointment adherence, we aimed to use personalized machine learning and big data analytics to predict the risk of and contributing factors for no-shows and late cancellations in primary care practices. METHODS: We conducted a retrospective longitudinal study leveraging geolinked clinical, care utilization, socioeconomic, and climate data from 15 family medicine clinics at a regional academic health center in Pennsylvania from January 2019 to June 2023. We developed multiclass machine learning models using gradient boost, random forest, neural network, and logistic regression to predict appointment outcomes, followed by feature importance analysis to identify contributing factors for no-shows or late cancellations at the population and patient levels. We performed stratified analysis to evaluate the prediction performance by sex and race/ethnicity to ensure the fairness of the final model among sensitive features. RESULTS: The analysis consisted of 109,328 patients and 1,118,236 appointments, including 77,322 (6.9%) no-shows and 75,545 (6.8%) late cancellations. The gradient boost model achieved the best performance with an area under the receiver operating characteristic curve of 0.852 for predicting no-shows and 0.921 for late cancellations. No bias against patient characteristics was detected. Schedule lead time was identified as the most important predictor of missed appointments. CONCLUSIONS: Missed appointments remain a challenge for primary care. This study provided a practical and robust framework to predict missed appointments, laying the foundation for developing personalized strategies to improve patients' adherence to primary care appointments.",
      "authors": "Tuan Wen-Jan; Yan Yifang; Abou Al Ardat Bilal; Felix Todd; Chen Qiushi",
      "year": "2025",
      "journal": "Annals of family medicine",
      "doi": "10.1370/afm.240316",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40721333/",
      "mesh_terms": "Humans; Machine Learning; Primary Health Care; Male; Retrospective Studies; Female; Appointments and Schedules; Middle Aged; No-Show Patients; Longitudinal Studies; Pennsylvania; Adult; Aged; Logistic Models",
      "keywords": "continuity of care; health disparity; late cancellation; machine learning; no-show",
      "pub_types": "Journal Article",
      "pmcid": "PMC12306982"
    },
    {
      "pmid": "38531676",
      "title": "Preparing for the bedside-optimizing a postpartum depression risk prediction model for clinical implementation in a health system.",
      "abstract": "OBJECTIVE: We developed and externally validated a machine-learning model to predict postpartum depression (PPD) using data from electronic health records (EHRs). Effort is under way to implement the PPD prediction model within the EHR system for clinical decision support. We describe the pre-implementation evaluation process that considered model performance, fairness, and clinical appropriateness. MATERIALS AND METHODS: We used EHR data from an academic medical center (AMC) and a clinical research network database from 2014 to 2020 to evaluate the predictive performance and net benefit of the PPD risk model. We used area under the curve and sensitivity as predictive performance and conducted a decision curve analysis. In assessing model fairness, we employed metrics such as disparate impact, equal opportunity, and predictive parity with the White race being the privileged value. The model was also reviewed by multidisciplinary experts for clinical appropriateness. Lastly, we debiased the model by comparing 5 different debiasing approaches of fairness through blindness and reweighing. RESULTS: We determined the classification threshold through a performance evaluation that prioritized sensitivity and decision curve analysis. The baseline PPD model exhibited some unfairness in the AMC data but had a fair performance in the clinical research network data. We revised the model by fairness through blindness, a debiasing approach that yielded the best overall performance and fairness, while considering clinical appropriateness suggested by the expert reviewers. DISCUSSION AND CONCLUSION: The findings emphasize the need for a thorough evaluation of intervention-specific models, considering predictive performance, fairness, and appropriateness before clinical implementation.",
      "authors": "Liu Yifan; Joly Rochelle; Reading Turchioe Meghan; Benda Natalie; Hermann Alison; Beecy Ashley; Pathak Jyotishman; Zhang Yiye",
      "year": "2024",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocae056",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38531676/",
      "mesh_terms": "Humans; Depression, Postpartum; Female; Electronic Health Records; Machine Learning; Risk Assessment; Decision Support Systems, Clinical",
      "keywords": "electronic health record; health equity; machine learning implementation; postpartum depression",
      "pub_types": "Journal Article",
      "pmcid": "PMC11105144"
    },
    {
      "pmid": "34812384",
      "title": "Bias Analysis on Public X-Ray Image Datasets of Pneumonia and COVID-19 Patients.",
      "abstract": "Chest X-ray images are useful for early COVID-19 diagnosis with the advantage that X-ray devices are already available in health centers and images are obtained immediately. Some datasets containing X-ray images with cases (pneumonia or COVID-19) and controls have been made available to develop machine-learning-based methods to aid in diagnosing the disease. However, these datasets are mainly composed of different sources coming from pre-COVID-19 datasets and COVID-19 datasets. Particularly, we have detected a significant bias in some of the released datasets used to train and test diagnostic systems, which might imply that the results published are optimistic and may overestimate the actual predictive capacity of the techniques proposed. In this article, we analyze the existing bias in some commonly used datasets and propose a series of preliminary steps to carry out before the classic machine learning pipeline in order to detect possible biases, to avoid them if possible and to report results that are more representative of the actual predictive power of the methods under analysis.",
      "authors": "Catala Omar Del Tejo; Igual Ismael Salvador; Perez-Benito Francisco Javier; Escriva David Millan; Castello Vicent Ortiz; Llobet Rafael; Perez-Cortes Juan-Carlos",
      "year": "2021",
      "journal": "IEEE access : practical innovations, open solutions",
      "doi": "10.1109/ACCESS.2021.3065456",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34812384/",
      "mesh_terms": "",
      "keywords": "COVID-19; Deep learning; bias; chest X-ray; convolutional neural networks; saliency map; segmentation",
      "pub_types": "Journal Article",
      "pmcid": "PMC8545228"
    },
    {
      "pmid": "35401342",
      "title": "From Cognitive Bias Toward Advanced Computational Intelligence for Smart Infrastructure Monitoring.",
      "abstract": "Visual inspections have been typically used in condition assessment of infrastructure. However, they are based on human judgment and their interpretation of data can differ from acquired results. In psychology, this difference is called cognitive bias which directly affects Structural Health Monitoring (SHM)-based decision making. Besides, the confusion between condition state and safety of a bridge is another example of cognitive bias in bridge monitoring. Therefore, integrated computer-based approaches as powerful tools can be significantly applied in SHM systems. This paper explores the relationship between the use of advanced computational intelligence and the development of SHM solutions through conducting an infrastructure monitoring methodology. Artificial Intelligence (AI)-based algorithms, i.e., Artificial Neural Network (ANN), hybrid ANN-based Imperial Competitive Algorithm, and hybrid ANN-based Genetic Algorithm, are developed for damage assessment using a lab-scale composite bridge deck structure. Based on the comparison of the results, the employed evolutionary algorithms could improve the prediction error of the pre-developed network by enhancing the learning procedure of the ANN.",
      "authors": "Gordan Meisam; Chao Ong Zhi; Sabbagh-Yazdi Saeed-Reza; Wee Lai Khin; Ghaedi Khaled; Ismail Zubaidah",
      "year": "2022",
      "journal": "Frontiers in psychology",
      "doi": "10.3389/fpsyg.2022.846610",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35401342/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; bridge monitoring; cognitive bias; infrastructure health monitoring; safety",
      "pub_types": "Journal Article",
      "pmcid": "PMC8990332"
    },
    {
      "pmid": "35396247",
      "title": "Evaluating algorithmic fairness in the presence of clinical guidelines: the case of atherosclerotic cardiovascular disease risk estimation.",
      "abstract": "OBJECTIVES: The American College of Cardiology and the American Heart Association guidelines on primary prevention of atherosclerotic cardiovascular disease (ASCVD) recommend using 10-year ASCVD risk estimation models to initiate statin treatment. For guideline-concordant decision-making, risk estimates need to be calibrated. However, existing models are often miscalibrated for race, ethnicity and sex based subgroups. This study evaluates two algorithmic fairness approaches to adjust the risk estimators (group recalibration and equalised odds) for their compatibility with the assumptions underpinning the guidelines' decision rules.MethodsUsing an updated pooled cohorts data set, we derive unconstrained, group-recalibrated and equalised odds-constrained versions of the 10-year ASCVD risk estimators, and compare their calibration at guideline-concordant decision thresholds. RESULTS: We find that, compared with the unconstrained model, group-recalibration improves calibration at one of the relevant thresholds for each group, but exacerbates differences in false positive and false negative rates between groups. An equalised odds constraint, meant to equalise error rates across groups, does so by miscalibrating the model overall and at relevant decision thresholds. DISCUSSION: Hence, because of induced miscalibration, decisions guided by risk estimators learned with an equalised odds fairness constraint are not concordant with existing guidelines. Conversely, recalibrating the model separately for each group can increase guideline compatibility, while increasing intergroup differences in error rates. As such, comparisons of error rates across groups can be misleading when guidelines recommend treating at fixed decision thresholds. CONCLUSION: The illustrated tradeoffs between satisfying a fairness criterion and retaining guideline compatibility underscore the need to evaluate models in the context of downstream interventions.",
      "authors": "Foryciarz Agata; Pfohl Stephen R; Patel Birju; Shah Nigam",
      "year": "2022",
      "journal": "BMJ health & care informatics",
      "doi": "10.1136/bmjhci-2021-100460",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35396247/",
      "mesh_terms": "American Heart Association; Atherosclerosis; Cardiology; Cardiovascular Diseases; Humans; Hydroxymethylglutaryl-CoA Reductase Inhibitors; United States",
      "keywords": "BMJ Health Informatics; clinical; decision support systems; health equity; machine learning; medical informatics",
      "pub_types": "Journal Article",
      "pmcid": "PMC8996004"
    },
    {
      "pmid": "40026843",
      "title": "Equitable hospital length of stay prediction for patients with learning disabilities and multiple long-term conditions using machine learning.",
      "abstract": "PURPOSE: Individuals with learning disabilities (LD) often face higher rates of premature mortality and prolonged hospital stays compared to the general population. Predicting the length of stay (LOS) for patients with LD and multiple long-term conditions (MLTCs) is critical for improving patient care and optimising medical resource allocation. However, there is limited research on the application of machine learning (ML) models to this population. Furthermore, approaches designed for the general population often lack generalisability and fairness, particularly when applied across sensitive groups within their cohort. METHOD: This study analyses hospitalisations of 9,618 patients with LD in Wales using electronic health records (EHR) from the SAIL Databank. A Random Forest (RF) ML model was developed to predict hospital LOS, incorporating demographics, medication history, lifestyle factors, and 39 long-term conditions. To address fairness concerns, two bias mitigation techniques were applied: a post-processing threshold optimiser and an in-processing reductions method using an exponentiated gradient. These methods aimed to minimise performance discrepancies across ethnic groups while ensuring robust model performance. RESULTS: The RF model outperformed other state-of-the-art models, achieving an area under the curve of 0.759 for males and 0.756 for females, a false negative rate of 0.224 for males and 0.229 for females, and a balanced accuracy of 0.690 for males and 0.689 for females. Bias mitigation algorithms reduced disparities in prediction performance across ethnic groups, with the threshold optimiser yielding the most notable improvements. Performance metrics, including false positive rate and balanced accuracy, showed significant enhancements in fairness for the male cohort. CONCLUSION: This study demonstrates the feasibility of applying ML models to predict LOS for patients with LD and MLTCs, while addressing fairness through bias mitigation techniques. The findings highlight the potential for equitable healthcare predictions using EHR data, paving the way for improved clinical decision-making and resource management.",
      "authors": "Abakasanga Emeka; Kousovista Rania; Cosma Georgina; Akbari Ashley; Zaccardi Francesco; Kaur Navjot; Fitt Danielle; Jun Gyuchan Thomas; Kiani Reza; Gangadharan Satheesh",
      "year": "2025",
      "journal": "Frontiers in digital health",
      "doi": "10.3389/fdgth.2025.1538793",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40026843/",
      "mesh_terms": "",
      "keywords": "bias mitigation; exponentiated gradient; learning disabilities; length of stay; threshold optimiser",
      "pub_types": "Journal Article",
      "pmcid": "PMC11868268"
    },
    {
      "pmid": "40577645",
      "title": "A Responsible Framework for Assessing, Selecting, and Explaining Machine Learning Models in Cardiovascular Disease Outcomes Among People With Type 2 Diabetes: Methodology and Validation Study.",
      "abstract": "BACKGROUND: Building machine learning models that are interpretable, explainable, and fair is critical for their trustworthiness in clinical practice. Interpretability, which refers to how easily a human can comprehend the mechanism by which a model makes predictions, is often seen as a primary consideration when adopting a machine learning model in health care. However, interpretability alone does not necessarily guarantee explainability, which offers stakeholders insights into a model's predicted outputs. Moreover, many existing frameworks for model evaluation focus primarily on maximizing predictive accuracy, overlooking the broader need for interpretability, fairness, and explainability. OBJECTIVE: This study proposes a 3-stage machine learning framework for responsible model development through model assessment, selection, and explanation. We demonstrate the application of this framework for predicting cardiovascular disease (CVD) outcomes, specifically myocardial infarction (MI) and stroke, among people with type 2 diabetes (T2D). METHODS: We extracted participant data comprised of people with T2D from the ACCORD (Action to Control Cardiovascular Risk in Diabetes) dataset (N=9635), including demographic, clinical, and biomarker records. Then, we applied hold-out cross-validation to develop several interpretable machine learning models (linear, tree-based, and ensemble) to predict the risks of MI and stroke among patients with diabetes. Our 3-stage framework first assesses these models via predictive accuracy and fairness metrics. Then, in the model selection stage, we quantify the trade-off between accuracy and fairness using area under the curve (AUC) and Relative Parity of Performance Scores (RPPS), wherein RPPS measures the greatest deviation of all subpopulations compared with the population-wide AUC. Finally, we quantify the explainability of the chosen models using methods such as SHAP (Shapley Additive Explanations) and partial dependence plots to investigate the relationship between features and model outputs. RESULTS: Our proposed framework demonstrates that the GLMnet model offers the best balance between predictive performance and fairness for both MI and stroke. For MI, GLMnet achieves the highest RPPS (0.979 for gender and 0.967 for race), indicating minimal performance disparities, while maintaining a high AUC of 0.705. For stroke, GLMnet has a relatively high AUC of 0.705 and the second-highest RPPS (0.961 for gender and 0.979 for race), suggesting it is effective across both subgroups. Our model explanation method further highlights that the history of CVD and age are the key predictors of MI, while HbA1c and systolic blood pressure significantly influence stroke classification. CONCLUSIONS: This study establishes a responsible framework for assessing, selecting, and explaining machine learning models, emphasizing accuracy-fairness trade-offs in predictive modeling. Key insights include: (1) simple models perform comparably to complex ensembles; (2) models with strong accuracy may harbor substantial differences in accuracy across demographic groups; and (3) explanation methods reveal the relationships between features and risk for MI and stroke. Our results underscore the need for holistic approaches that consider accuracy, fairness, and explainability in interpretable model design and selection, potentially enhancing health care technology adoption.",
      "authors": "Yang Yang; Liao Che-Yi; Keyvanshokooh Esmaeil; Shao Hui; Weber Mary Beth; Pasquel Francisco J; Garcia Gian-Gabriel P",
      "year": "2025",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/66200",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40577645/",
      "mesh_terms": "Humans; Machine Learning; Diabetes Mellitus, Type 2; Cardiovascular Diseases; Male; Female; Middle Aged; Aged; Risk Assessment",
      "keywords": "MI; T2D; cardiology; cardiovascular; cardiovascular disease; clinical practice; diabetes; explainability; fairness; interpretable machine learning; machine learning; myocardial infarction; prediction; responsible framework; stroke; type 2 diabetes",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC12256707"
    },
    {
      "pmid": "40726749",
      "title": "Empirical Comparison of Post-processing Debiasing Methods for Machine Learning Classifiers in Healthcare.",
      "abstract": "UNLABELLED: Machine learning classifiers in healthcare tend to reproduce or exacerbate existing health disparities due to inherent biases in training data. This relevant issue has brought the attention of researchers in both healthcare and other domains, proposing techniques that deal with it in different stages of the machine learning process. Post-processing methods adjust model predictions to ensure fairness without interfering in the learning process nor requiring access to the original training data, preserving privacy and enabling the application to any trained model. This study rigorously compares state-of-the-art debiasing methods within the family of post-processing techniques across a wide range of synthetic and real-world (healthcare) datasets, by means of different performance and fairness metrics. Our experiments reveal the strengths and weaknesses of each method, examining the trade-offs between group fairness and predictive performance, as well as among different notions of group fairness. Additionally, we analyze the impact on untreated attributes to ensure overall bias mitigation. Our comprehensive evaluation provides insights into how these debiasing methods can be optimally implemented in healthcare settings to balance accuracy and fairness. SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1007/s41666-025-00196-7.",
      "authors": "Dang Vien Ngoc; Campello V\u00edctor M; Hern\u00e1ndez-Gonz\u00e1lez Jer\u00f3nimo; Lekadir Karim",
      "year": "2025",
      "journal": "Journal of healthcare informatics research",
      "doi": "10.1007/s41666-025-00196-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40726749/",
      "mesh_terms": "",
      "keywords": "Algorithmic bias; Fairness; Healthcare; Machine learning classifiers; Post-processing",
      "pub_types": "Journal Article",
      "pmcid": "PMC12290158"
    },
    {
      "pmid": "40339458",
      "title": "Comparing the influence of social risk factors on machine learning model performance across racial and ethnic groups in home healthcare.",
      "abstract": "This study examined the impact of social risk factors on machine learning model performance for predicting hospitalization and emergency department visits in home healthcare. Using retrospective data from one U.S. home healthcare agency, four models were developed with unstructured social information documented in clinical notes. Performance was compared with and without social factors. A subgroup analyses was conducted by race and ethnicity to assess for fairness. LightGBM performed best overall. Social factors had a modest effect, but findings highlight the feasibility of integrating unstructured social information into machine learning models and the importance of fairness evaluation in home healthcare.",
      "authors": "Hobensack Mollie; Davoudi Anahita; Song Jiyoun; Cato Kenrick; Bowles Kathryn H; Topaz Maxim",
      "year": "2025",
      "journal": "Nursing outlook",
      "doi": "10.1016/j.outlook.2025.102431",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40339458/",
      "mesh_terms": "Humans; Machine Learning; Female; Male; Retrospective Studies; Ethnicity; Home Care Services; Middle Aged; Risk Factors; Aged; Racial Groups; United States; Hospitalization; Aged, 80 and over; Adult; Emergency Service, Hospital",
      "keywords": "Home healthcare; Hospitalization; Machine learning; Nursing informatics; Social determinants of health",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": "PMC12178806"
    },
    {
      "pmid": "39974004",
      "title": "Algorithms to Improve Fairness in Medicare Risk Adjustment.",
      "abstract": "IMPORTANCE: Payment system design creates incentives that impact healthcare spending, access, and outcomes. With Medicare Advantage accounting for more than half of Medicare spending, changes to its risk adjustment algorithm have the potential for broad consequences. OBJECTIVE: To develop risk adjustment algorithms that can achieve fair spending targets, and compare their performance to a baseline that emulates the least squares regression approach used by the Centers for Medicare and Medicaid Services. DESIGN: Retrospective analysis of Traditional Medicare enrollment and claims data between January 2017 and December 2020. Diagnoses in claims were mapped to Hierarchical Condition Categories (HCCs). Algorithms used demographic indicators and HCCs from one calendar year to predict Medicare spending in the subsequent year. SETTING: Data from Medicare beneficiaries with documented residence in the United States or Puerto Rico. PARTICIPANTS: A random 20% sample of beneficiaries enrolled in Traditional Medicare. Included beneficiaries were aged 65 years and older, and did not have Medicaid dual eligibility. Race/ethnicity was assigned using the Research Triangle Institute enhanced indicator. MAIN OUTCOME AND MEASURES: Prospective healthcare spending by Medicare. Overall performance was measured by payment system fit and mean absolute error. Net compensation was used to assess group-level fairness. RESULTS: The main analysis included 4,398,035 Medicare beneficiaries with a mean age of 75.2 years and mean annual Medicare spending of $8,345. Out-of-sample payment system fit for the baseline regression was 12.7%. Constrained regression and post-processing both achieved fair spending targets, while maintaining payment system fit values of 12.6% and 12.7%, respectively. Whereas post-processing only increased mean payments for beneficiaries in minoritized racial/ethnic groups, constrained regression increased mean payments for beneficiaries in minoritized racial/ethnic groups and beneficiaries in other groups residing in counties with greater exposure to socioeconomic factors that can adversely affect health outcomes. CONCLUSIONS AND RELEVANCE: Constrained regression and post-processing can incorporate fairness objectives in the Medicare risk adjustment algorithm with minimal reduction in overall fit.",
      "authors": "Reitsma Marissa B; McGuire Thomas G; Rose Sherri",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.01.25.25321057",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39974004/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC11838972"
    },
    {
      "pmid": "39441784",
      "title": "Conceptualizing bias in EHR data: A case study in performance disparities by demographic subgroups for a pediatric obesity incidence classifier.",
      "abstract": "Electronic Health Records (EHRs) are increasingly used to develop machine learning models in predictive medicine. There has been limited research on utilizing machine learning methods to predict childhood obesity and related disparities in classifier performance among vulnerable patient subpopulations. In this work, classification models are developed to recognize pediatric obesity using temporal condition patterns obtained from patient EHR data in a U.S. study population. We trained four machine learning algorithms (Logistic Regression, Random Forest, Gradient Boosted Trees, and Neural Networks) to classify cases and controls as obesity positive or negative, and optimized hyperparameter settings through a bootstrapping methodology. To assess the classifiers for bias, we studied model performance by population subgroups then used permutation analysis to identify the most predictive features for each model and the demographic characteristics of patients with these features. Mean AUC-ROC values were consistent across classifiers, ranging from 0.72-0.80. Some evidence of bias was identified, although this was through the models performing better for minority subgroups (African Americans and patients enrolled in Medicaid). Permutation analysis revealed that patients from vulnerable population subgroups were over-represented among patients with the most predictive diagnostic patterns. We hypothesize that our models performed better on under-represented groups because the features more strongly associated with obesity were more commonly observed among minority patients. These findings highlight the complex ways that bias may arise in machine learning models and can be incorporated into future research to develop a thorough analytical approach to identify and mitigate bias that may arise from features and within EHR datasets when developing more equitable models.",
      "authors": "Campbell Elizabeth A; Bose Saurav; Masino Aaron J",
      "year": "2024",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000642",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39441784/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11498669"
    },
    {
      "pmid": "40825541",
      "title": "Efficient Detection of Stigmatizing Language in Electronic Health Records via In-Context Learning: Comparative Analysis and Validation Study.",
      "abstract": "BACKGROUND: The presence of stigmatizing language within electronic health records (EHRs) poses significant risks to patient care by perpetuating biases. While numerous studies have explored the use of supervised machine learning models to detect stigmatizing language automatically, these models require large, annotated datasets, which may not always be readily available. In-context learning (ICL) has emerged as a data-efficient alternative, allowing large language models to adapt to tasks using only instructions and examples. OBJECTIVE: We aimed to investigate the efficacy of ICL in detecting stigmatizing language within EHRs under data-scarce conditions. METHODS: We analyzed 5043 sentences from the Medical Information Mart for Intensive Care-IV dataset, which contains EHRs from patients admitted to the emergency department at the Beth Israel Deaconess Medical Center. We compared ICL with zero-shot (textual entailment), few-shot (SetFit), and supervised fine-tuning approaches. The ICL approach used 4 prompting strategies: generic, chain of thought, clue and reasoning prompting, and a newly introduced stigma detection guided prompt. Model fairness was evaluated using the equal performance criterion, measuring true positive rate, false positive rate, and F1-score disparities across protected attributes, including sex, age, and race. RESULTS: In the zero-shot setting, the best-performing ICL model, GEMMA-2, achieved a mean F1-score of 0.858 (95% CI 0.854-0.862), showing an 18.7% improvement over the best textual entailment model, DEBERTA-M (mean F1-score 0.723, 95% CI 0.718-0.728; P<.001). In the few-shot setting, the top ICL model, LLAMA-3, outperformed the leading SetFit models by 21.2%, 21.4%, and 12.3% with 4, 8, and 16 annotations per class, respectively (P<.001). Using 32 labeled instances, the best ICL model achieved a mean F1-score of 0.901 (95% CI 0.895-0.907), only 3.2% lower than the best supervised fine-tuning model, ROBERTA (mean F1-score 0.931, 95% CI 0.924-0.938), which was trained on 3543 labeled instances. Under the conditions tested, fairness evaluation revealed that supervised fine-tuning models exhibited greater bias compared with ICL models in the zero-shot, 4-shot, 8-shot, and 16-shot settings, as measured by true positive rate, false positive rate, and F1-score disparities. CONCLUSIONS: ICL offers a robust and flexible solution for detecting stigmatizing language in EHRs, offering a more data-efficient and equitable alternative to conventional machine learning methods. These findings suggest that ICL could enhance bias detection in clinical documentation while reducing the reliance on extensive labeled datasets.",
      "authors": "Chen Hongbo; Alfred Myrtede; Cohen Eldan",
      "year": "2025",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/68955",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40825541/",
      "mesh_terms": "Humans; Electronic Health Records; Machine Learning; Language; Social Stigma; Stereotyping; Male; Female",
      "keywords": "artificial intelligence; electronic health record; fairness; few-shot; in-context learning; large language model; machine learning; prompting strategy; stigmatizing language; text classification; zero-shot",
      "pub_types": "Journal Article; Comparative Study; Validation Study",
      "pmcid": "PMC12402740"
    },
    {
      "pmid": "36190605",
      "title": "Scheduling mobile dental clinics: A heuristic approach considering fairness among school districts.",
      "abstract": "Mobile dental clinics (MDCs) are suitable solutions for servicing people living in rural and urban areas that require dental healthcare. MDCs can provide dental care to the most vulnerable high-school students. However, scheduling MDCs to visit patients is critical to developing efficient dental programs. Here, we study a mobile dental clinic scheduling problem that arises from the real-life logistics management challenge faced by a school-based mobile dental care program in Southern Chile. This problem involves scheduling MDCs to treat high-school students at public schools while considering a fairness constraint among districts. Schools are circumscribed into districts, and by program regulations, at least 50% of the students in each district must receive dental care during the first semester. Fairness prevents some districts from waiting more time to receive dental care than others. We model the problem as a parallel machine scheduling problem with sequence-dependent setup costs and batch due dates and propose a mathematical model and a genetic algorithm-based solution to solve the problem. Our computational results demonstrate the effectiveness of our approaches in obtaining near-optimal solutions. Finally, dental program managers can use the methodologies presented in this work to schedule mobile dental clinics and improve their operations.",
      "authors": "Sep\u00falveda Ignacio A; Aguayo Maichel M; De la Fuente Rodrigo; Latorre-N\u00fa\u00f1ez Guillermo; Obreque Carlos; Orrego Camila V\u00e1squez",
      "year": "2024",
      "journal": "Health care management science",
      "doi": "10.1007/s10729-022-09612-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36190605/",
      "mesh_terms": "Humans; Dental Clinics; Heuristics; Delivery of Health Care; Students; Costs and Cost Analysis",
      "keywords": "Dental care; Health care management; Mobile dental clinic; Operations research; Scheduling",
      "pub_types": "Journal Article",
      "pmcid": "8184733"
    },
    {
      "pmid": "40484312",
      "title": "AI4CDI: Introducing a novel machine learning approach to demonstrate feasibility of timely and early identification of at-risk populations for Clostridioides difficile infections.",
      "abstract": "OBJECTIVE: We evaluated machine learning (ML) model feasibility to predict Clostridioides difficile infection (CDI) six months prior to onset and to identify early predictors over a longer period. METHODS: A retrospective analysis was performed using electronic health records data from US adults (Optum Market Clarity). Cases with CDI and non-CDI controls were identified. A 1:1 coarsened exact matching algorithm was applied, with final analysis cohorts of 4736 cases and 4732 controls. CDI-relevant features were identified from the published literature, and information was extracted for >900 features. The final model was trained on 597 mostly binary features. Feature information during the 6 months prior to date of first CDI diagnosis was hidden to the model to identify patients at risk for CDI with a longer time horizon. Sensitivity analysis was conducted on cases aged 65-80 years. RESULTS: Median age was 65 years (19-88) in case and control cohorts. The Gradient Boosted Trees ML model had an Area Under the Curve Receiver Operating Characteristic (AUC-ROC) of 0.79. Post-model bias evaluation revealed disparities in sensitivity (race). Long-term predictors included hospitalization days. While some predictors were exclusive to the 65-80 years model, others were more strongly associated with CDI in the overall model. CONCLUSIONS: We developed a ML model that can identify patient groups at increased risk for primary CDI. While the predictive capability of this ML model is promising, validation is needed before exploring its readiness for use in healthcare settings to inform preventive measures for CDI.",
      "authors": "Karatzia Anastasia; Aristeridou Danai; Kantz Wawi; Colavecchia A Carmine; Madhava Harish; Ateya Mohammad; Czudek Carole; Kelly Patrick H; Halsby Kate",
      "year": "2025",
      "journal": "Anaerobe",
      "doi": "10.1016/j.anaerobe.2025.102978",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40484312/",
      "mesh_terms": "Humans; Clostridium Infections; Machine Learning; Aged; Middle Aged; Retrospective Studies; Male; Female; Adult; Aged, 80 and over; Young Adult; Clostridioides difficile; Electronic Health Records; Feasibility Studies; Risk Factors; ROC Curve; Risk Assessment; Early Diagnosis",
      "keywords": "CDI; Classification algorithm; Clostridioides difficile infection; Machine learning; Predictive model",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40152140",
      "title": "Predicting postoperative chronic opioid use with fair machine learning models integrating multi-modal data sources: a demonstration of ethical machine learning in healthcare.",
      "abstract": "OBJECTIVE: Building upon our previous work on predicting chronic opioid use using electronic health records (EHR) and wearable data, this study leveraged the Health Equity Across the AI Lifecycle (HEAAL) framework to (a) fine tune the previously built model with genomic data and evaluate model performance in predicting chronic opioid use and (b) apply IBM's AIF360 pre-processing toolkit to mitigate bias related to gender and race and evaluate the model performance using various fairness metrics. MATERIALS AND METHODS: Participants included approximately 271 All of Us Research Program subjects with EHR, wearable, and genomic data. We fine-tuned 4 machine learning models on the new dataset. The SHapley Additive exPlanations (SHAP) technique identified the best-performing predictors. A preprocessing toolkit boosted fairness by gender and race. RESULTS: The genetic data enhanced model performance from the prior model, with the area under the curve improving from 0.90 (95% CI, 0.88-0.92) to 0.95 (95% CI, 0.89-0.95). Key predictors included Dopamine D1 Receptor (DRD1) rs4532, general type of surgery, and time spent in physical activity. The reweighing preprocessing technique applied to the stacking algorithm effectively improved the model's fairness across racial and gender groups without compromising performance. CONCLUSION: We leveraged 2 dimensions of the HEAAL framework to build a fair artificial intelligence (AI) solution. Multi-modal datasets (including wearable and genetic data) and applying bias mitigation strategies can help models to more fairly and accurately assess risk across diverse populations, promoting fairness in AI in healthcare.",
      "authors": "Soley Nidhi; Rattsev Ilia; Speed Traci J; Xie Anping; Ferryman Kadija S; Taylor Casey Overby",
      "year": "2025",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf053",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40152140/",
      "mesh_terms": "Humans; Machine Learning; Electronic Health Records; Male; Female; Opioid-Related Disorders; Postoperative Pain; Wearable Electronic Devices; Analgesics, Opioid; Middle Aged; Adult; Information Sources",
      "keywords": "All of Us; chronic opioid use; ethical machine learning; multimodal dataset; responsible AI",
      "pub_types": "Journal Article",
      "pmcid": "PMC12089784"
    },
    {
      "pmid": "32322144",
      "title": "Gender and Parity in Statistical Prediction of Anterior Carry Hand-Loads from Inertial Sensor Data.",
      "abstract": "The objective of this study was to examine potential gender effects on the performance of a statistical algorithm for predicting hand-load levels that uses body-worn inertial sensor data. Torso and pelvic kinematic data was obtained from 11 men and 11 women in a laboratory experiment while they carried anterior hand-loads of 13.6 kg, and 22.7 kg, and during unloaded walking. Nine kinematic variables expressed as relative changes from unloaded gait were calculated and used as predictors in a statistical classification model predicting load-level (no-load, 13.6 kg, and 22.7 kg). To compare effects of gender on prediction accuracy, prediction models were built using both, gender-balanced gait data and gender-specific data (i.e., separate models for men and women) and evaluated using hold-out validation techniques. The gender-balanced model correctly classified load levels with an accuracy of 74.2% and 80.0% for men and women, respectively. The gender-specific models had accuracies of 68.3% and 85.0% for men and women, respectively. Findings indicated a lack of classification parity across gender, and possibly across other types of personal attributes such as age, ethnicity, and health condition. While preliminary, this study hopes to draw attention to challenges in algorithmic bias, parity and fairness, particularly as machine learning techniques gain popularity in ergonomics practice.",
      "authors": "Lim Sol; D'Souza Clive",
      "year": "2019",
      "journal": "Proceedings of the Human Factors and Ergonomics Society ... Annual Meeting. Human Factors and Ergonomics Society. Annual meeting",
      "doi": "10.1177/1071181319631193",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32322144/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC7176367"
    },
    {
      "pmid": "33989164",
      "title": "Authors' Reply to: Minimizing Selection and Classification Biases Comment on \"Clinical Characteristics and Prognostic Factors for Intensive Care Unit Admission of Patients With COVID-19: Retrospective Study Using Machine Learning and Natural Language Processing\".",
      "abstract": "",
      "authors": "Izquierdo Jose Luis; Soriano Joan B",
      "year": "2021",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/29405",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33989164/",
      "mesh_terms": "Bias; COVID-19; Humans; Intensive Care Units; Machine Learning; Natural Language Processing; Prognosis; Retrospective Studies; SARS-CoV-2",
      "keywords": "COVID-19; SARS-CoV-2; artificial intelligence; big data; classification bias; critical care; electronic health records; predictive model; prognosis; tachypnea",
      "pub_types": "Letter; Comment",
      "pmcid": "PMC8190644"
    },
    {
      "pmid": "33989163",
      "title": "Minimizing Selection and Classification Biases. Comment on \"Clinical Characteristics and Prognostic Factors for Intensive Care Unit Admission of Patients With COVID-19: Retrospective Study Using Machine Learning and Natural Language Processing\".",
      "abstract": "",
      "authors": "Martos P\u00e9rez Francisco; Gomez Huelgas Ricardo; Mart\u00edn Escalante Mar\u00eda Dolores; Casas Rojo Jos\u00e9 Manuel",
      "year": "2021",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/27142",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33989163/",
      "mesh_terms": "Bias; COVID-19; Humans; Intensive Care Units; Machine Learning; Natural Language Processing; Prognosis; Retrospective Studies; SARS-CoV-2",
      "keywords": "COVID-19; SARS-CoV-2; artificial intelligence; big data; classification bias; critical care; electronic health records; predictive model; prognosis; tachypnea",
      "pub_types": "Journal Article; Comment",
      "pmcid": "PMC8190647"
    },
    {
      "pmid": "38725085",
      "title": "Preoperative prediction model for risk of readmission after total joint replacement surgery: a random forest approach leveraging NLP and unfairness mitigation for improved patient care and cost-effectiveness.",
      "abstract": "BACKGROUND: The Center for Medicare and Medicaid Services (CMS) imposes payment penalties for readmissions following total joint replacement surgeries. This study focuses on total hip, knee, and shoulder arthroplasty procedures as they account for most joint replacement surgeries. Apart from being a burden to healthcare systems, readmissions are also troublesome for patients. There are several studies which only utilized structured data from Electronic Health Records (EHR) without considering any gender and payor bias adjustments. METHODS: For this study, dataset of 38,581 total knee, hip, and shoulder replacement surgeries performed from 2015 to 2021 at Novant Health was gathered. This data was used to train a random forest machine learning model to predict the combined endpoint of emergency department (ED) visit or unplanned readmissions within 30 days of discharge or discharge to Skilled Nursing Facility (SNF) following the surgery. 98 features of laboratory results, diagnoses, vitals, medications, and utilization history were extracted. A natural language processing (NLP) model finetuned from Clinical BERT was used to generate an NLP risk score feature for each patient based on their clinical notes. To address societal biases, a feature bias analysis was performed in conjunction with propensity score matching. A threshold optimization algorithm from the Fairlearn toolkit was used to mitigate gender and payor biases to promote fairness in predictions. RESULTS: The model achieved an Area Under the Receiver Operating characteristic Curve (AUROC) of 0.738 (95% confidence interval, 0.724 to 0.754) and an Area Under the Precision-Recall Curve (AUPRC) of 0.406 (95% confidence interval, 0.384 to 0.433). Considering an outcome prevalence of 16%, these metrics indicate the model's ability to accurately discriminate between readmission and non-readmission cases within the context of total arthroplasty surgeries while adjusting patient scores in the model to mitigate bias based on patient gender and payor. CONCLUSION: This work culminated in a model that identifies the most predictive and protective features associated with the combined endpoint. This model serves as a tool to empower healthcare providers to proactively intervene based on these influential factors without introducing bias towards protected patient classes, effectively mitigating the risk of negative outcomes and ultimately improving quality of care regardless of socioeconomic factors.",
      "authors": "Digumarthi Varun; Amin Tapan; Kanu Samuel; Mathew Joshua; Edwards Bryan; Peterson Lisa A; Lundy Matthew E; Hegarty Karen E",
      "year": "2024",
      "journal": "Journal of orthopaedic surgery and research",
      "doi": "10.1186/s13018-024-04774-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38725085/",
      "mesh_terms": "Humans; Patient Readmission; Female; Male; Machine Learning; Aged; Cost-Benefit Analysis; Natural Language Processing; Middle Aged; Arthroplasty, Replacement, Knee; Arthroplasty, Replacement, Hip; Arthroplasty, Replacement; Risk Assessment; Preoperative Period; Aged, 80 and over; Quality Improvement; Random Forest",
      "keywords": "Classification; Fairlearn; Natural language processing; Orthopedic; Predictive model",
      "pub_types": "Journal Article",
      "pmcid": "PMC11084055"
    },
    {
      "pmid": "41479444",
      "title": "Predicting Metabolic Dysfunction-Associated Steatotic Liver Disease using Machine Learning Methods.",
      "abstract": "BACKGROUND: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD) affects ~33% of U.S. adults and is the most common chronic liver disease. Although often asymptomatic, progression can lead to cirrhosis. Early detection is important, as lifestyle interventions can prevent disease progression. We developed a fair, rigorous, and reproducible MASLD prediction model and compared it to prior methods using a large electronic health record database. METHODS: We evaluated LASSO logistic regression, random forest, XGBoost, and a neural network for MASLD prediction using clinical feature subsets, including the top 10 SHAP-ranked features. To reduce disparities in true positive rates across racial and ethnic subgroups, we applied an equal opportunity postprocessing method. RESULTS: This study included 59,492 patients in the training data, 24,198 in the validating data, and 25,188 in the testing data. The LASSO logistic regression model with the top 10 features was selected for its interpretability and comparable performance. Before fairness adjustment, the model achieved AUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and F1-score of 0.617. After equal opportunity postprocessing, accuracy modestly increased to 81% and specificity to 94%, while sensitivity decreased to 41% and F1-score to 0.515, reflecting the fairness trade-off. CONCLUSIONS: We developed the MASER prediction model (MASLD Static EHR Risk Prediction), a LASSO logistic regression model which achieved competitive performance for MASLD prediction (AUROC 0.836, accuracy 77.6%), comparable to previously reported ensemble and tree-based models. Overall, this approach demonstrates that interpretable models can achieve a balance of predictive performance and fairness in diverse patient populations.",
      "authors": "An Mary Elena; Griffin Paul; Stine Jonathan G; Balakrishnan Ramakrishna; Kumara Soundar",
      "year": "2025",
      "journal": "ArXiv",
      "doi": "10.3350/cmh.2024.0431",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41479444/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12755246"
    },
    {
      "pmid": "40865290",
      "title": "Machine learning-based prediction of suicide risk using adult attention-deficit/hyperactivity disorder symptoms and depression indicators: insights from a nationally representative south korean survey.",
      "abstract": "BACKGROUND: Suicide is a major global health issue. Evidence shows adult ADHD symptoms increase suicide risk, particularly with depression. We aimed to develop a predictive ML model. METHODS: We analyzed data from the 2021 Korean National Mental Health Survey. We defined suicide risk as serious suicidal ideation. Employing complex survey-weighted logistic regression and random forest (RF) classifier with age and sex covariates, we predicted suicidal ideation. We applied the synthetic minority over-sampling technique (SMOTE) to address class imbalance in model training. RESULTS: The SMOTE-balanced RF model exhibited higher recall (\u2248 0.76) for suicide risk than logistic regression (recall 0.08-0.48), with balanced overall performance and minimal bias between classes. Inattention symptoms demonstrated the strongest associations with suicidal ideation (odds ratio \u2248 3.2, p < 0.001). CONCLUSION: In a nationwide sample, adult ADHD symptoms-particularly inattention-and depression indicators were significantly correlated with suicidal ideation. Compared to traditional methods, an ML model substantially enhanced the identification of individuals exhibiting suicidal ideation, while maintaining fairness. These findings indicate that incorporating adult ADHD screening and ML-based models into suicide prevention strategies can facilitate the early detection of high-risk individuals in the general population.",
      "authors": "Kim Sunhae; Lee Kounseok",
      "year": "2025",
      "journal": "Psychiatry research",
      "doi": "10.1016/j.psychres.2025.116702",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40865290/",
      "mesh_terms": "Humans; Attention Deficit Disorder with Hyperactivity; Republic of Korea; Male; Female; Adult; Suicidal Ideation; Middle Aged; Machine Learning; Depression; Young Adult; Suicide; Health Surveys; Risk Assessment; Adolescent; Aged",
      "keywords": "Attention-deficit/hyperactivity disorder; Depression; Machine Learning; Suicidal ideation; Suicide Risk",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40940655",
      "title": "FanFAIR: sensitive data sets semi-automatic fairness assessment.",
      "abstract": "BACKGROUND: Research has shown how data sets convey social bias in Artificial Intelligence systems, especially those based on machine learning. A biased data set is not representative of reality and might contribute to perpetuate societal biases within the model. To tackle this problem, it is important to understand how to avoid biases, errors, and unethical practices while creating the data sets. In order to provide guidance for the use of data sets in contexts of critical decision-making, such as health decisions, we identified six fundamental data set features (balance, numerosity, unevenness, compliance, quality, incompleteness) that could affect model fairness. These features were the foundation for the FanFAIR framework. RESULTS: We extended the FanFAIR framework for the semi-automated evaluation of fairness in data sets, by combining statistical information on data with qualitative features. In particular, we present an improved version of FanFAIR which introduces novel outlier detection capabilities working in multivariate fashion, using two state-of-the-art methods: the Empirical Cumulative-distribution Outlier Detection (ECOD) and Isolation Forest. We also introduce a novel metric for data set balance, based on an entropy measure. CONCLUSION: We addressed the issue of how much (un)fairness can be included in a data set used for machine learning research, focusing on classification issues. We developed a rule-based approach based on fuzzy logic that combines these characteristics into a single score and enables a semi-automatic evaluation of a data set in algorithmic fairness research. Our tool produces a detailed visual report about the fairness of the data set. We show the effectiveness of FanFAIR by applying the method on two open data sets.",
      "authors": "Gallese Chiara; Scantamburlo Teresa; Manzoni Luca; Giannerini Simone; Nobile Marco S",
      "year": "2025",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-025-03184-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40940655/",
      "mesh_terms": "",
      "keywords": "Data bias; Fairness; Fuzzy logic; Trustworthy artificial intelligence",
      "pub_types": "Journal Article",
      "pmcid": "PMC12427094"
    },
    {
      "pmid": "39901158",
      "title": "The Data Artifacts Glossary: a community-based repository for bias on health datasets.",
      "abstract": "BACKGROUND: The deployment of Artificial Intelligence (AI) in healthcare has the potential to transform patient care through improved diagnostics, personalized treatment plans, and more efficient resource management. However, the effectiveness and fairness of AI are critically dependent on the data it learns from. Biased datasets can lead to AI outputs that perpetuate disparities, particularly affecting social minorities and marginalized groups. OBJECTIVE: This paper introduces the \"Data Artifacts Glossary\", a dynamic, open-source framework designed to systematically document and update potential biases in healthcare datasets. The aim is to provide a comprehensive tool that enhances the transparency and accuracy of AI applications in healthcare and contributes to understanding and addressing health inequities. METHODS: Utilizing a methodology inspired by the Delphi method, a diverse team of experts conducted iterative rounds of discussions and literature reviews. The team synthesized insights to develop a comprehensive list of bias categories and designed the glossary's structure. The Data Artifacts Glossary was piloted using the MIMIC-IV dataset to validate its utility and structure. RESULTS: The Data Artifacts Glossary adopts a collaborative approach modeled on successful open-source projects like Linux and Python. Hosted on GitHub, it utilizes robust version control and collaborative features, allowing stakeholders from diverse backgrounds to contribute. Through a rigorous peer review process managed by community members, the glossary ensures the continual refinement and accuracy of its contents. The implementation of the Data Artifacts Glossary with the MIMIC-IV dataset illustrates its utility. It categorizes biases, and facilitates their identification and understanding. CONCLUSION: The Data Artifacts Glossary serves as a vital resource for enhancing the integrity of AI applications in healthcare by providing a mechanism to recognize and mitigate dataset biases before they impact AI outputs. It not only aids in avoiding bias in model development but also contributes to understanding and addressing the root causes of health disparities.",
      "authors": "Gameiro Rodrigo R; Woite Naira Link; Sauer Christopher M; Hao Sicheng; Fernandes Chrystinne Oliveira; Premo Anna E; Teixeira Alice Rangel; Resli Isabelle; Wong An-Kwok Ian; Celi Leo Anthony",
      "year": "2025",
      "journal": "Journal of biomedical science",
      "doi": "10.1186/s12929-024-01106-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39901158/",
      "mesh_terms": "Humans; Artificial Intelligence; Datasets as Topic; Bias",
      "keywords": "Artificial intelligence; Bias; Data Artifacts Glossary; Dataset; Health equity; Machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11792693"
    },
    {
      "pmid": "39371141",
      "title": "Evaluating and Reducing Subgroup Disparity in AI Models: An Analysis of Pediatric COVID-19 Test Outcomes.",
      "abstract": "Artificial Intelligence (AI) fairness in healthcare settings has attracted significant attention due to the concerns to propagate existing health disparities. Despite ongoing research, the frequency and extent of subgroup fairness have not been sufficiently studied. In this study, we extracted a nationally representative pediatric dataset (ages 0-17, n=9,935) from the US National Health Interview Survey (NHIS) concerning COVID-19 test outcomes. For subgroup disparity assessment, we trained 50 models using five machine learning algorithms. We assessed the models' area under the curve (AUC) on 12 small (<15% of the total n) subgroups defined using social economic factors versus the on the overall population. Our results show that subgroup disparities were prevalent (50.7%) in the models. Subgroup AUCs were generally lower, with a mean difference of 0.01, ranging from -0.29 to +0.41. Notably, the disparities were not always statistically significant, with four out of 12 subgroups having statistically significant disparities across models. Additionally, we explored the efficacy of synthetic data in mitigating identified disparities. The introduction of synthetic data enhanced subgroup disparity in 57.7% of the models. The mean AUC disparities for models with synthetic data decreased on average by 0.03 via resampling and 0.04 via generative adverbial network methods.",
      "authors": "Libin Alexander; Treitler Jonah T; Vasaitis Tadas; Shao Yijun",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.09.18.24313889",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39371141/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC11451670"
    },
    {
      "pmid": "40463575",
      "title": "Leveraging neighborhood-level Information to Improve Model Fairness in Predicting Prenatal Depression.",
      "abstract": "IMPORTANCE: Perinatal depression (PND) affects 10-20% of pregnant women, with significant racial disparities in prevalence, screening, and treatment. Neighborhood-level factors significantly influence PND risk, particularly among women of color, but current machine learning models using electronic medical records (EMRs) rarely incorporate neighborhood characteristics. OBJECTIVE: To determine whether integrating neighborhood-level information with EMRs improves fairness in PND prediction while identifying key neighborhood factors influencing model bias across racial/ethnic groups. DESIGN SETTING AND PARTICIPANTS: Study of 6,137 pregnant women who received care at a large urban academic hospital from 2010-2019, comprising 58% Non-Hispanic Black (NHB), 10% Non-Hispanic White (NHW), and 28% Hispanic (H) individuals, with depression status determined by PHQ-9 scores. EXPOSURES: 125 neighborhood-level factors from Chicago Health Atlas merged with 61 EMR features based on residential location. MAIN OUTCOMES AND MEASURES: Model performance (ROCAUC, PRAUC) and fairness metrics (disparate impact, equal opportunity difference, equalized odds). Feature importance analyzed using Shapley values and the impact of each neighborhood factor on model bias were evaluated. Results Models integrating neighborhood-level measures showed moderate predictive performance (ROCAUC: NHB 55%, NHW 57%, H 58%) while significantly improving fairness metrics compared to EMR-only models (p<0.05). Factors, such as suicide mortality rate and neighborhood safety rate, helped reduce bias. NHB women showed stronger correlations between PND risk factors and neighborhood variables compared to other groups. Most neighborhood factors had differential impacts across racial/ethnic groups, increasing bias for NHB women while reducing it for Hispanic women. CONCLUSIONS AND RELEVANCE: Incorporating neighborhood-level information enhances fairness in PND prediction while maintaining predictive capability. The differential impact of neighborhood factors across racial/ethnic groups highlights the importance of considering neighborhood context in clinical risk assessment to reduce disparities in prenatal depression care.",
      "authors": "Huang Yongchao; Alvernaz Suzanne; Kim Sage J; Maki Pauline M; Boyd Andrew D; Dai Yang; Bernab\u00e9 Beatriz Pe\u00f1alver",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.05.12.25327329",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40463575/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12132113"
    },
    {
      "pmid": "36601036",
      "title": "Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness.",
      "abstract": "Biases have marked medical history, leading to unequal care affecting marginalised groups. The patterns of missingness in observational data often reflect these group discrepancies, but the algorithmic fairness implications of group-specific missingness are not well understood. Despite its potential impact, imputation is too often an overlooked preprocessing step. When explicitly considered, attention is placed on overall performance, ignoring how this preprocessing can reinforce groupspecific inequities. Our work questions this choice by studying how imputation affects downstream algorithmic fairness. First, we provide a structured view of the relationship between clinical presence mechanisms and groupspecific missingness patterns. Then, through simulations and real-world experiments, we demonstrate that the imputation choice influences marginalised group performance and that no imputation strategy consistently reduces disparities. Importantly, our results show that current practices may endanger health equity as similarly performing imputation strategies at the population level can affect marginalised groups differently. Finally, we propose recommendations for mitigating inequities that may stem from a neglected step of the machine learning pipeline.",
      "authors": "Jeanselme Vincent; De-Arteaga Maria; Zhang Zhe; Barrett Jessica; Tom Brian",
      "year": "2022",
      "journal": "Proceedings of machine learning research",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36601036/",
      "mesh_terms": "",
      "keywords": "Clinical Presence; Fairness; Imputation",
      "pub_types": "Journal Article",
      "pmcid": "PMC7614014"
    },
    {
      "pmid": "40666330",
      "title": "Auditor Models to Suppress Poor AI Predictions Can Improve Human-AI Collaborative Performance.",
      "abstract": "OBJECTIVE: Healthcare decisions are increasingly made with the assistance of machine learning (ML). ML has been known to have unfairness - inconsistent outcomes across subpopulations. Clinicians interacting with these systems can perpetuate such unfairness by overreliance. Recent work exploring ML suppression - silencing predictions based on auditing the ML - shows promise in mitigating performance issues originating from overreliance. This study aims to evaluate the impact of suppression on collaboration fairness and evaluate ML uncertainty as desiderata to audit the ML. MATERIALS AND METHODS: We used data from the Vanderbilt University Medical Center electronic health record (n = 58,817) and the MIMIC-IV-ED dataset (n = 363,145) to predict likelihood of death or ICU transfer and likelihood of 30-day readmission. Our simulation study used gradient-boosted trees as well as an artificially high-performing oracle model. We derived clinician decisions directly from the dataset and simulated clinician acceptance of ML predictions based on previous empirical work on acceptance of CDS alerts. We measured performance as area under the receiver operating characteristic curve and algorithmic fairness using absolute averaged odds difference. RESULTS: When the ML outperforms humans, suppression outperforms the human alone (p < 0.034) and at least does not degrade fairness. When the human outperforms the ML, suppression outperforms the human (p < 5.2 \u00d7 10-5) but the human is fairer than suppression (p < 0.0019). Finally, incorporating uncertainty quantification into suppression approaches can improve performance. CONCLUSION: Suppression of poor-quality ML predictions through an auditor model shows promise in improving collaborative human-AI performance and fairness.",
      "authors": "Brown Katherine E; Wrenn Jesse O; Jackson Nicholas J; Cauley Michael R; Collins Benjamin; Novak Laurie Lovett; Malin Bradley A; Ancker Jessica S",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.06.24.25330212",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40666330/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; human-AI collaboration; machine learning",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12262782"
    },
    {
      "pmid": "40866555",
      "title": "Quantifying device type and handedness biases in a remote Parkinson's disease AI-powered assessment.",
      "abstract": "We investigate issues pertaining to algorithmic fairness and digital health equity within the context of using machine learning to predict Parkinson's Disease (PD) with data recorded from structured assessments of finger and hand movements. We evaluate the impact of demographic bias and bias related to device type and handedness. We collected data from 251 participants (99 with PD or suspected PD, 152 without PD or any suspicion of PD). Using a random forest model, we observe 92% accuracy, 94% AUROC, 86% sensitivity, 92% specificity, and 84% F1-score. When examining only F1-score differences across groups, no significant bias appears. However, a closer look reveals bias regarding positive prediction and error rates. While we find that sex and ethnicity have no statistically significant impact on PD predictions, biases exist regarding device type and dominant hand, as evidenced by disparate impact and equalized odds. Our findings suggest that remote digital health diagnostics may exhibit underrecognized biases related to handedness and device characteristics, the latter of which can act as a proxy for socioeconomic factors.",
      "authors": "Tumpa Zerin Nasrin; Zawad Md Rahat Shahriar; Sollis Lydia; Parab Shubham; Chen Irene Y; Washington Peter",
      "year": "2025",
      "journal": "NPJ digital medicine",
      "doi": "10.1038/s41746-025-01934-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40866555/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12391457"
    },
    {
      "pmid": "39689864",
      "title": "Building a Time-Series Model to Predict Hospitalization Risks in Home Health Care: Insights Into Development, Accuracy, and Fairness.",
      "abstract": "OBJECTIVES: Home health care (HHC) serves more than 5 million older adults annually in the United States, aiming to prevent unnecessary hospitalizations and emergency department (ED) visits. Despite efforts, up to 25% of patients in HHC experience these adverse events. The underutilization of clinical notes, aggregated data approaches, and potential demographic biases have limited previous HHC risk prediction models. This study aimed to develop a time-series risk model to predict hospitalizations and ED visits in patients in HHC, examine model performance over various prediction windows, identify top predictive variables and map them to data standards, and assess model fairness across demographic subgroups. SETTING AND PARTICIPANTS: A total of 27,222 HHC episodes between 2015 and\u00a02017. METHODS: The study used health care process modeling of electronic health records, including clinical notes processed with natural language processing techniques and Medicare claims data. A Light Gradient Boosting Machine algorithm was used to develop the risk prediction model, with performance evaluated using 5-fold cross-validation. Model fairness was assessed across gender, race/ethnicity, and socioeconomic subgroups. RESULTS: The model achieved high predictive performance, with an F1 score of 0.84 for a 5-day prediction window. Twenty top predictive variables were identified, including novel indicators such as the length of nurse-patient visits and visit frequency. Eighty-five percent of these variables mapped completely to the US Core Data for Interoperability standard. Fairness assessment revealed performance disparities across demographic and socioeconomic groups, with lower model effectiveness for more historically underserved populations. CONCLUSIONS AND IMPLICATIONS: This study developed a robust time-series risk model for predicting adverse events in patients in HHC, incorporating diverse data types and demonstrating high predictive accuracy. The findings highlight the importance of considering established and novel risk factors in HHC. Importantly, the observed performance disparities across subgroups emphasize the need for fairness adjustments to ensure equitable risk prediction across all patient populations.",
      "authors": "Topaz Maxim; Davoudi Anahita; Evans Lauren; Sridharan Sridevi; Song Jiyoun; Chae Sena; Barr\u00f3n Yolanda; Hobensack Mollie; Scharp Danielle; Cato Kenrick; Rossetti Sarah Collins; Kapela Piotr; Xu Zidu; Gupta Pallavi; Zhang Zhihong; Mcdonald Margaret V; Bowles Kathryn H",
      "year": "2025",
      "journal": "Journal of the American Medical Directors Association",
      "doi": "10.1016/j.jamda.2024.105417",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39689864/",
      "mesh_terms": "Humans; Male; Female; Aged; Hospitalization; Home Care Services; United States; Risk Assessment; Aged, 80 and over; Emergency Service, Hospital; Electronic Health Records",
      "keywords": "Home health care service; model fairness; natural language processing; risk prediction",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41032562",
      "title": "Enhancing Fairness and Accuracy in Diagnosing Type 2 Diabetes in Young Adult Population.",
      "abstract": "While type 2 diabetes is predominantly found in the elderly population, recent publications indicate an increasing prevalence in the young adult population. Failing to diagnose it in the minority younger age group could have significant adverse effects on their health. Several previous works acknowledge the bias of machine learning models towards different gender and race groups and propose various approaches to mitigate it. However, those works failed to propose any effective methodologies to diagnose diabetes in the young population, which is the minority group in the diabetic population. This is the first paper where we mention digital ageism towards the young adult population diagnosing diabetes. In this paper, we identify this deficiency in traditional machine learning models and propose an algorithm to mitigate the bias towards the young population when predicting diabetes. Deviating from the traditional concept of one-model-fits-all, we train customized machine-learning models for each age group. Our pipeline trains a separate machine learning model for every 5-year age band (i.e., age groups 30-34, 35-39, and 40-44). The proposed solution consistently improves recall of diabetes class by 26% to 40% in the young age group (30-44). Moreover, our technique outperforms 7 commonly used whole-group resampling techniques (i.e., random oversampling, random undersampling, SMOTE, ADASYN, Tomek-links, ENN, and Near Miss) by at least 36% in terms of diabetes recall in the young age group. Feature important analysis shows that the age attribute has a significant contribution to the decision of the original model, which was marginalized in the age-personalized model. Our method shows improved performance (e.g., balanced accuracy improved 7-12%) over multiple machine learning models and multiple sampling algorithms.",
      "authors": "Pias Tanmoy Sarkar; Su Yiqi; Tang Xuxin; Wang Haohui; Faghani Shahriar; Yao Danfeng",
      "year": "2025",
      "journal": "IEEE journal of biomedical and health informatics",
      "doi": "10.1109/JBHI.2025.3616312",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41032562/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41030569",
      "title": "Predicting Childhood Anaemia in Nigeria: A Machine Learning Approach to Uncover Key Risk Factors.",
      "abstract": "BACKGROUND: Childhood anaemia is a major public health challenge in Nigeria, with high prevalence among children under five. This study identifies key determinants and develops a predictive model using advanced machine learning technique. METHODS: A total of 13,136 children aged 6-59 months from the 2018 National Demographic and Health Survey (NDHS) were analysed. Sixteen machine learning algorithms were evaluated on the basis of their ability to predict childhood anaemia using a wide range of individual, community and environmental factors. The Extra Trees (ET) classifier, demonstrating the highest predictive performance, was used to identify the top 10 predictors of childhood anaemia. A fairness and demographic bias assessment framework was incorporated to evaluate the model's performance across different regions, wealth index categories, ethnic groups and gender. RESULTS: The ET classifier achieved an area under the curve (AUC) of 0.8319, an accuracy of 0.7565 and a recall of 0.7565. The top 10 predictors identified by the model included the number of under-five children in the household, birth order, child age, media access, maternal health-seeking behaviour, child gender, proximity to water, money problems, day land surface temperature and all population count. The demographic bias assessment revealed variations in model performance across different subgroups, with the lowest AUCs observed in the north-east region (0.79), the poorest wealth index category (0.80) and the Hausa/Fulani ethnic group (0.81). CONCLUSION: This study shows that machine learning can accurately predict childhood anaemia in Nigeria and identify key risk factors, supporting targeted interventions. Future work should focus on refining models and integrating AI-based interventions to reduce anaemia.",
      "authors": "Ja'afar Ibrahim Khalil; Uthman Olalekan A",
      "year": "2025",
      "journal": "Public health challenges",
      "doi": "10.1002/puh2.70135",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41030569/",
      "mesh_terms": "",
      "keywords": "Nigeria; childhood anaemia; demographic bias; machine learning; predictive modelling; risk factors",
      "pub_types": "Journal Article",
      "pmcid": "PMC12477793"
    },
    {
      "pmid": "40484798",
      "title": "Reimagining Resilience in Aging: Leveraging AI/ML, Big Data Analytics, and Systems Innovation.",
      "abstract": "As the aging population in the United States grows, the need for an integrated approach to support older adults has become increasingly urgent. The SUNSHINE framework, Seniors Uniting Nationwide to Support Health, INtegrated Care, and Evolution, offers a model for advancing resilience, defined as the capacity of individuals, families, systems, and communities to adapt and thrive in the face of adversity. SUNSHINE promotes this goal through the alignment of older and aging adults, families, healthcare systems, public health agencies, social services, and community resources. Using the Theory of Change modeling, SUNSHINE emphasizes whole-person health, interdisciplinary collaboration, and the strategic use of technology to address the evolving needs of aging populations. The framework promotes systems integration supported by research infrastructure and multi-sector collaboration to enhance the well-being of older adults and family caregivers. SUNSHINE places a strong emphasis on mental health, particularly depression, and highlights the importance of social connection and prevention in addressing health disparities and care gaps associated with aging. It conceptualizes resilience as both a desired outcome and a driver of transformation, guiding the redesign and evaluation of health and social systems. The framework also identifies opportunities to leverage artificial intelligence and machine learning (AI/ML) technologies, grounded in scientific evidence, to support personalized prevention, treatment, and care strategies. These technologies are critical for optimizing decision-making, improving care delivery, and enhancing system flexibility. Finally, SUNSHINE aspires to advance a future of aging that is healthy, resilient, and fair, guided by principles of equity, defined as fairness and impartiality in health opportunities and outcomes.",
      "authors": "Chen Jie; Maguire Teagan K; McCoy Rozalina G; Thomas Stephen; Reynolds Charles F",
      "year": "2025",
      "journal": "The American journal of geriatric psychiatry : official journal of the American Association for Geriatric Psychiatry",
      "doi": "10.1016/j.jagp.2025.05.007",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40484798/",
      "mesh_terms": "Humans; Resilience, Psychological; Aging; Artificial Intelligence; Big Data; Aged; United States; Data Science; Data Analytics",
      "keywords": "AI/ML; Aging health; Collaboration; Depression; Health disparities; Integration; Resilience",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38533919",
      "title": "Accurate, Robust, and Scalable Machine Abstraction of Mayo Endoscopic Subscores From Colonoscopy Reports.",
      "abstract": "BACKGROUND: The Mayo endoscopic subscore (MES) is an important quantitative measure of disease activity in ulcerative colitis. Colonoscopy reports in routine clinical care usually characterize ulcerative colitis disease activity using free text description, limiting their utility for clinical research and quality improvement. We sought to develop algorithms to classify colonoscopy reports according to their MES. METHODS: We annotated 500 colonoscopy reports from 2 health systems. We trained and evaluated 4 classes of algorithms. Our primary outcome was accuracy in identifying scorable reports (binary) and assigning an MES (ordinal). Secondary outcomes included learning efficiency, generalizability, and fairness. RESULTS: Automated machine learning models achieved 98% and 97% accuracy on the binary and ordinal prediction tasks, outperforming other models. Binary models trained on the University of California, San Francisco data alone maintained accuracy (96%) on validation data from Zuckerberg San Francisco General. When using 80% of the training data, models remained accurate for the binary task (97% [n = 320]) but lost accuracy on the ordinal task (67% [n = 194]). We found no evidence of bias by gender (P\u2005=\u2005.65) or area deprivation index (P\u2005=\u2005.80). CONCLUSIONS: We derived a highly accurate pair of models capable of classifying reports by their MES and recognizing when to abstain from prediction. Our models were generalizable on outside institution validation. There was no evidence of algorithmic bias. Our methods have the potential to enable retrospective studies of treatment effectiveness, prospective identification of patients meeting study criteria, and quality improvement efforts in inflammatory bowel diseases.",
      "authors": "Silverman Anna L; Bhasuran Balu; Mosenia Arman; Yasini Fatema; Ramasamy Gokul; Banerjee Imon; Gupta Saransh; Mardirossian Taline; Narain Rohan; Sewell Justin; Butte Atul J; Rudrapatna Vivek A",
      "year": "2025",
      "journal": "Inflammatory bowel diseases",
      "doi": "10.1093/ibd/izae068",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38533919/",
      "mesh_terms": "Humans; Colonoscopy; Female; Male; Machine Learning; Algorithms; Colitis, Ulcerative; Severity of Illness Index; Middle Aged; Adult",
      "keywords": "endoscopic disease activity scores; healthcare applied AI; natural language processing; ulcerative colitis",
      "pub_types": "Journal Article",
      "pmcid": "PMC11879245"
    },
    {
      "pmid": "39386055",
      "title": "The Impact of Race, Ethnicity, and Sex on Fairness in Artificial Intelligence for Glaucoma Prediction Models.",
      "abstract": "OBJECTIVE: Despite advances in artificial intelligence (AI) in glaucoma prediction, most works lack multicenter focus and do not consider fairness concerning sex, race, or ethnicity. This study aims to examine the impact of these sensitive attributes on developing fair AI models that predict glaucoma progression to necessitating incisional glaucoma surgery. DESIGN: Database study. PARTICIPANTS: Thirty-nine thousand ninety patients with glaucoma, as identified by International Classification of Disease codes from 7 academic eye centers participating in the Sight OUtcomes Research Collaborative. METHODS: We developed XGBoost models using 3 approaches: (1) excluding sensitive attributes as input features, (2) including them explicitly as input features, and (3) training separate models for each group. Model input features included demographic details, diagnosis codes, medications, and clinical information (intraocular pressure, visual acuity, etc.), from electronic health records. The models were trained on patients from 5 sites (N\u00a0=\u00a027\u00a0999) and evaluated on a held-out internal test set (N\u00a0=\u00a03499) and 2 external test sets consisting of N\u00a0=\u00a01550 and N\u00a0=\u00a02542 patients. MAIN OUTCOMES AND MEASURES: Area under the receiver operating characteristic curve (AUROC) and equalized odds on the test set and external sites. RESULTS: Six thousand six hundred eighty-two (17.1%) of 39\u00a0090 patients underwent glaucoma surgery with a mean age of 70.1 (standard deviation 14.6) years, 54.5% female, 62.3% White, 22.1% Black, and 4.7% Latinx/Hispanic. We found that not including the sensitive attributes led to better classification performance (AUROC: 0.77-0.82) but worsened fairness when evaluated on the internal test set. However, on external test sites, the opposite was true: including sensitive attributes resulted in better classification performance (AUROC: external #1 - [0.73-0.81], external #2 - [0.67-0.70]), but varying degrees of fairness for sex and race as measured by equalized odds. CONCLUSIONS: Artificial intelligence models predicting whether patients with glaucoma progress to surgery demonstrated bias with respect to sex, race, and ethnicity. The effect of sensitive attribute inclusion and exclusion on fairness and performance varied based on internal versus external test sets. Prior to deployment, AI models should be evaluated for fairness on the target population. FINANCIAL DISCLOSURES: Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.",
      "authors": "Ravindranath Rohith; Stein Joshua D; Hernandez-Boussard Tina; Fisher A Caroline; Wang Sophia Y",
      "year": "2025",
      "journal": "Ophthalmology science",
      "doi": "10.1016/j.xops.2024.100596",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39386055/",
      "mesh_terms": "",
      "keywords": "Bias; Fairness; Glaucoma; Health disparities; Machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11462200"
    },
    {
      "pmid": "39904407",
      "title": "Evaluating the Bias, type I error and statistical power of the prior Knowledge-Guided integrated likelihood estimation (PIE) for bias reduction in EHR based association studies.",
      "abstract": "OBJECTIVES: Binary outcomes in electronic health records (EHR) derived using automated phenotype algorithms may suffer from phenotyping error, resulting in bias in association estimation. Huang et al. [1] proposed the Prior Knowledge-Guided Integrated Likelihood Estimation (PIE) method to mitigate the estimation bias, however, their investigation focused on point estimation without statistical inference, and the evaluation of PIE therein using simulation was a proof-of-concept with only a limited scope of scenarios. This study aims to comprehensively assess PIE's performance including (1) how well PIE performs under a wide spectrum of operating characteristics of phenotyping algorithms under real-world scenarios (e.\u00a0g., low prevalence, low sensitivity, high specificity); (2) beyond point estimation, how much variation of the PIE estimator was introduced by the prior distribution; and (3) from a hypothesis testing point of view, if PIE improves type I error and statistical power relative to the na\u00efve method (i.e., ignoring the phenotyping error). METHODS: Synthetic data and use-case analysis were utilized to evaluate PIE. The synthetic data were generated under diverse outcome prevalence, phenotyping algorithm sensitivity, and association effect sizes. Simulation studies compared PIE under different prior distributions with the na\u00efve method, assessing bias, variance, type I error, and power. Use-case analysis compared the performance of PIE and the na\u00efve method in estimating the association of multiple predictors with COVID-19 infection. RESULTS: PIE exhibited reduced bias compared to the na\u00efve method across varied simulation settings, with comparable type I error and power. As the effect size became larger, the bias reduced by PIE was larger. PIE has superior performance when prior distributions aligned closely with true phenotyping algorithm characteristics. Impact of prior quality was minor for low-prevalence outcomes but large for common outcomes. In use-case analysis, PIE maintains a relatively accurate estimation across different scenarios, particularly outperforming the na\u00efve approach under large effect sizes. CONCLUSION: PIE effectively mitigates estimation bias in a wide spectrum of real-world settings, particularly with accurate prior information. Its main benefit lies in bias reduction rather than hypothesis testing. The impact of the prior is small for low-prevalence outcomes.",
      "authors": "Jing Naimin; Lu Yiwen; Tong Jiayi; Weaver James; Ryan Patrick; Xu Hua; Chen Yong",
      "year": "2025",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2025.104787",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39904407/",
      "mesh_terms": "Electronic Health Records; Humans; Algorithms; Likelihood Functions; Bias; COVID-19; Phenotype; SARS-CoV-2; Computer Simulation",
      "keywords": "Association study; Bias reduction; Electronic health record; Phenotyping error",
      "pub_types": "Journal Article",
      "pmcid": "PMC12180398"
    },
    {
      "pmid": "39371143",
      "title": "Federated Multiple Imputation for Variables that Are Missing Not At Random in Distributed Electronic Health Records.",
      "abstract": "Large electronic health records (EHR) have been widely implemented and are available for research activities. The magnitude of such databases often requires storage and computing infrastructure that are distributed at different sites. Restrictions on data-sharing due to privacy concerns have been another driving force behind the development of a large class of distributed and/or federated machine learning methods. While missing data problem is also present in distributed EHRs, albeit potentially more complex, distributed multiple imputation (MI) methods have not received as much attention. An important advantage of distributed MI, as well as distributed analysis, is that it allows researchers to borrow information across data sites, mitigating potential fairness issues for minority groups that do not have enough volume at certain sites. In this paper, we propose a communication-efficient and privacy-preserving distributed MI algorithms for variables that are missing not at random.",
      "authors": "Lian Yi; Jiang Xiaoqian; Long Qi",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.09.15.24313479",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39371143/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC11451631"
    },
    {
      "pmid": "24525488",
      "title": "Evaluating treatment effectiveness under model misspecification: A comparison of targeted maximum likelihood estimation with bias-corrected matching.",
      "abstract": "Statistical approaches for estimating treatment effectiveness commonly model the endpoint, or the propensity score, using parametric regressions such as generalised linear models. Misspecification of these models can lead to biased parameter estimates. We compare two approaches that combine the propensity score and the endpoint regression, and can make weaker modelling assumptions, by using machine learning approaches to estimate the regression function and the propensity score. Targeted maximum likelihood estimation is a double-robust method designed to reduce bias in the estimate of the parameter of interest. Bias-corrected matching reduces bias due to covariate imbalance between matched pairs by using regression predictions. We illustrate the methods in an evaluation of different types of hip prosthesis on the health-related quality of life of patients with osteoarthritis. We undertake a simulation study, grounded in the case study, to compare the relative bias, efficiency and confidence interval coverage of the methods. We consider data generating processes with non-linear functional form relationships, normal and non-normal endpoints. We find that across the circumstances considered, bias-corrected matching generally reported less bias, but higher variance than targeted maximum likelihood estimation. When either targeted maximum likelihood estimation or bias-corrected matching incorporated machine learning, bias was much reduced, compared to using misspecified parametric models.",
      "authors": "Kreif No\u00e9mi; Gruber Susan; Radice Rosalba; Grieve Richard; Sekhon Jasjeet S",
      "year": "2016",
      "journal": "Statistical methods in medical research",
      "doi": "10.1177/0962280214521341",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24525488/",
      "mesh_terms": "Aged; Bias; Computer Simulation; Confidence Intervals; Data Interpretation, Statistical; Hip Prosthesis; Humans; Likelihood Functions; Machine Learning; Male; Models, Statistical; Osteoarthritis; Quality of Life; Treatment Outcome",
      "keywords": "bias-corrected matching; double robustness; machine learning; model misspecification; targeted maximum likelihood estimation; treatment effectiveness",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": "PMC5051604"
    },
    {
      "pmid": "41062083",
      "title": "Reinforcement Learning to Prevent Acute Care Events Among Medicaid Populations: Mixed Methods Study.",
      "abstract": "BACKGROUND: Multidisciplinary care management teams must rapidly prioritize interventions for patients with complex medical and social needs. Current approaches rely on individual training, judgment, and experience, missing opportunities to learn from longitudinal trajectories and prevent adverse outcomes through recommender systems. OBJECTIVE: This study aims to evaluate whether a reinforcement learning approach could outperform standard care management practices in recommending optimal interventions for patients with complex needs. METHODS: Using data from 3175 Medicaid beneficiaries in care management programs across 2 states from 2023 to 2024, we compared alternative approaches for recommending \"next best step\" interventions: the standard experience-based approach (status quo) and a state-action-reward-state-action (SARSA) reinforcement learning model. We evaluated performance using clinical impact metrics, conducted counterfactual causal inference analyses to estimate reductions in acute care events, assessed fairness across demographic subgroups, and performed qualitative chart reviews where the models differed. RESULTS: In counterfactual analyses, SARSA-guided care management reduced acute care events by 12 percentage points (95% CI 2.2-21.8 percentage points, a 20.7% relative reduction; P=.02) compared to the status quo approach, with a number needed to treat of 8.3 (95% CI 4.6-45.2) to prevent 1 acute event. The approach showed improved fairness across demographic groups, including gender (3.8% vs 5.3% disparity in acute event rates, reduction 1.5%, 95% CI 0.3%-2.7%) and race and ethnicity (5.6% vs 8.9% disparity, reduction 3.3%, 95% CI 1.1%-5.5%). In qualitative reviews, the SARSA model detected and recommended interventions for specific medical-social interactions, such as respiratory issues associated with poor housing quality or food insecurity in individuals with diabetes. CONCLUSIONS: SARSA-guided care management shows potential to reduce acute care use compared to standard practice. The approach demonstrates how reinforcement learning can improve complex decision-making in situations where patients face concurrent clinical and social factors while maintaining safety and fairness across demographic subgroups.",
      "authors": "Basu Sanjay; Muralidharan Bhairavi; Sheth Parth; Wanek Dan; Morgan John; Patel Sadiq",
      "year": "2025",
      "journal": "JMIR AI",
      "doi": "10.2196/74264",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41062083/",
      "mesh_terms": "",
      "keywords": "AI; artificial intelligence; care management; clinical decision support; community health worker; machine learning; reinforcement learning; social determinants of health",
      "pub_types": "Journal Article",
      "pmcid": "PMC12547335"
    },
    {
      "pmid": "40994240",
      "title": "Racing Against the Algorithm: Leveraging Inclusive AI as an Antiracist Tool for Brain Health.",
      "abstract": "Artificial intelligence (AI) is transforming medicine, including neurology and mental health. Yet without equity-centered design, AI risks reinforcing systemic racism. This article explores how algorithmic bias and phenotypic exclusion disproportionately affect marginalized communities in brain health. Drawing on lived experience and scientific evidence, the essay outlines five design principles-centered on inclusion, transparency, and accountability-to ensure AI promotes equity. By reimagining AI as a tool for justice, we can reshape translational science to serve all populations.",
      "authors": "Ekuta Victor",
      "year": "2025",
      "journal": "Clinical and translational science",
      "doi": "10.1111/cts.70364",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40994240/",
      "mesh_terms": "Humans; Artificial Intelligence; Algorithms; Systemic Racism; Mental Health; Health Equity; Brain",
      "keywords": "artificial intelligence; brain health; clinical algorithms; health equity; inclusive design; machine learning; racial disparities; translational science",
      "pub_types": "Journal Article",
      "pmcid": "PMC12461116"
    },
    {
      "pmid": "41273675",
      "title": "Equity-promoting integer programming approaches for medical resident rotation scheduling.",
      "abstract": "Motivated by our collaboration with a residency program at an academic health system, we propose new integer programming (IP) approaches for the resident-to-rotation assignment problem (RRAP). Given sets of residents, resident classes, and departments, as well as a block structure for each class, staffing needs, rotation requirements for each class, program rules, and resident vacation requests, the RRAP involves finding a feasible year-long rotation schedule that specifies resident assignments to rotations and vacation times. We first present an IP formulation for the RRAP, which mimics the manual method for generating rotation schedules in practice and can be easily implemented and efficiently solved using off-the-shelf optimization software. However, it can lead to disparities in satisfying vacation requests among residents. To mitigate such disparities, we derive an equity-promoting counterpart that finds an optimal rotation schedule, maximizing the number of satisfied vacation requests while minimizing a measure of disparity in satisfying these requests. Then, we propose a computationally efficient Pareto Search Algorithm capable of finding the complete set of Pareto optimal solutions to the equity-promoting IP within a time that is suitable for practical implementation. Additionally, we present a user-friendly tool that implements the proposed models to automate the generation of the rotation schedule. Finally, we construct diverse RRAP instances based on data from our collaborator and conduct extensive experiments to illustrate the potential practical benefits of our proposed approaches. Our results demonstrate the computational efficiency and implementability of our approaches and underscore their potential to enhance fairness in resident rotation scheduling.",
      "authors": "Li Shutian; Shehadeh Karmel S; Curtis Frank E; Hochman Beth R",
      "year": "2025",
      "journal": "Health care management science",
      "doi": "10.1007/s10729-025-09736-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41273675/",
      "mesh_terms": "Internship and Residency; Humans; Personnel Staffing and Scheduling; Algorithms; Academic Medical Centers",
      "keywords": "Fairness; Integer programming; Operations management; Operations research; Optimization; Resident scheduling",
      "pub_types": "Journal Article",
      "pmcid": "PMC12743667"
    },
    {
      "pmid": "41543310",
      "title": "Machine Learning-Based Bias-Corrected Future Projections of Ozone Concentrations from a Chemistry-Climate Model.",
      "abstract": "Reliable projections of future surface ozone are crucial for air quality management and health risk assessment. However, potential biases in spatial distribution, magnitude, and trends in ozone simulated by global chemistry-climate models limit their applicability in regional evaluations. In this study, LightGBM, a machine learning (ML) algorithm, is applied to correct biases in CESM2-simulated ozone over China, the United States, and Europe and to calibrate future projections under two Shared Socioeconomic Pathways (SSP1-2.6 and SSP5-8.5) from 2020 to 2060. The ML-based correction significantly improves spatial distribution and reduces bias by 40 to 60%, also reversing the potentially incorrect trend under SSP1-2.6 in eastern China. When the ML-based correction is applied to CESM2 projections, the warm-season mean ozone shows substantial changes from 2020 to 2060. Under SSP1-2.6, corrected ozone decreases by 13.5, 17.9, and 13.7 \u03bcg/m3 in China, the United States, and Europe, respectively. In contrast, under SSP5-8.5, ozone increases over the same period by 9.4, 2.0, and 5.2 \u03bcg/m3 in these regions. The decomposition analysis shows that anthropogenic emission changes dominate future ozone trends, while a strong climate penalty occurs in polluted eastern China and climate benefits are found in western China, the United States, and Europe under SSP5-8.5. These findings demonstrate the value of combining ML with chemistry-climate models to produce more accurate air quality projections, indicating more effective and region-specific environmental protection strategies.",
      "authors": "Ni Yiqian; Yang Yang; Wang Hailong; Wang Pinya; Li Ke; Chen Lei; Zhu Jia; Li Baojie; Liao Hong",
      "year": "2026",
      "journal": "Environmental science & technology",
      "doi": "10.1021/acs.est.5c11992",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41543310/",
      "mesh_terms": "Ozone; Machine Learning; Climate Models; Air Pollutants; China; Climate; Air Pollution; United States",
      "keywords": "bias correction; future projection; machine learning; ozone",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "21906253",
      "title": "Rational rationing or discrimination: balancing equity and efficiency considerations in kidney allocation.",
      "abstract": "After 6 years of deliberation, the Organ Procurement and Transplantation Network recently released a concept document proposing changes to the kidney allocation algorithm, sparking a heated debate about priority-setting of scarce health resources and discrimination. Proponents of the proposal argue that it will result in an additional 15,223 life years following transplant annually for recipients, yet the benefit will not be equally distributed and will likely benefit younger patients. Critics argue that the new model will promote age discrimination and may lead to a further decrease in live kidney donation. If true, these concerns could undermine fairness and damage public trust in the organ allocation system. We address these objections and consider their merit, highlighting both benefits and shortcomings of the proposal. We argue that, despite weaknesses of the proposal and the importance of maintaining consistency in patient and provider expectations over time, the proposal represents a needed first step in balancing equity and efficiency.",
      "authors": "Ladin K; Hanto D W",
      "year": "2011",
      "journal": "American journal of transplantation : official journal of the American Society of Transplantation and the American Society of Transplant Surgeons",
      "doi": "10.1111/j.1600-6143.2011.03726.x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/21906253/",
      "mesh_terms": "Age Factors; Health Care Rationing; Humans; Kidney Transplantation; Patient Selection; Resource Allocation; Tissue Donors; Tissue and Organ Procurement; Waiting Lists",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC3203330"
    },
    {
      "pmid": "41146192",
      "title": "Reducing inequalities using an unbiased machine learning approach to identify births with the highest risk of preventable neonatal deaths.",
      "abstract": "BACKGROUND: Despite contemporaneous declines in neonatal mortality, recent studies show the existence of left-behind populations that continue to have higher mortality rates than the national averages. Additionally, many of these deaths are from preventable causes. This reality creates the need for more precise methods to identify high-risk births, allowing policymakers to target them more effectively. This study fills this gap by developing unbiased machine-learning approaches to more accurately identify births with a high risk of neonatal deaths from preventable causes. METHODS: We link administrative databases from the Brazilian health ministry to obtain birth and death records in the country from 2015 to 2017. The final dataset comprises 8,797,968 births, of which 59,615 newborns died before reaching 28 days alive (neonatal deaths). These neonatal deaths are categorized into preventable deaths (42,290) and non-preventable deaths (17,325). Our analysis identifies the death risk of the former group, as they are amenable to policy interventions. We train six machine-learning algorithms, test their performance on unseen data, and evaluate them using a new policy-oriented metric. To avoid biased policy recommendations, we also investigate how our approach impacts disadvantaged populations. RESULTS: XGBoost was the best-performing algorithm for our task, with the 5% of births identified as highest risk by the model accounting for over 85% of the observed deaths. Furthermore, the risk predictions exhibit no statistical differences in the proportion of actual preventable deaths from disadvantaged populations, defined by race, education, marital status, and maternal age. These results are similar for other threshold levels. CONCLUSIONS: We show that, by using publicly available administrative data sets and ML methods, it is possible to identify the births with the highest risk of preventable deaths with a high degree of accuracy. This is useful for policymakers as they can target health interventions to those who need them the most and where they can be effective without producing bias against disadvantaged populations. Overall, our approach can guide policymakers in reducing neonatal mortality rates and their health inequalities. Finally, it can be adapted for use in other developing countries.",
      "authors": "Ramos Antonio P; Caldieraro Fabio; Nascimento Marcus L; Saldanha Raphael",
      "year": "2025",
      "journal": "Population health metrics",
      "doi": "10.1186/s12963-025-00420-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41146192/",
      "mesh_terms": "Humans; Machine Learning; Infant, Newborn; Brazil; Infant Mortality; Female; Infant; Perinatal Death; Socioeconomic Factors; Male; Cause of Death; Algorithms; Databases, Factual; Risk Factors",
      "keywords": "Algorithmic bias; Health inequality; Machine learning; Neonatal mortality; Program targeting",
      "pub_types": "Journal Article",
      "pmcid": "PMC12557940"
    },
    {
      "pmid": "41040729",
      "title": "Reducing Inequalities Using an Unbiased Machine Learning Approach to Identify Births with the Highest Risk of Preventable Neonatal Deaths.",
      "abstract": "BACKGROUND: Despite contemporaneous declines in neonatal mortality, recent studies show the existence of left-behind populations that continue to have higher mortality rates than the national averages. Additionally, many of these deaths are from preventable causes. This reality creates the need for more precise methods to identify high-risk births, allowing policymakers to target them more effectively. This study fills this gap by developing unbiased machine-learning approaches to more accurately identify births with a high risk of neonatal deaths from preventable causes. METHODS: We link administrative databases from the Brazilian health ministry to obtain birth and death records in the country from 2015 to 2017. The final dataset comprises 8,797,968 births, of which 59,615 newborns died before reaching 28 days alive (neonatal deaths). These neonatal deaths are categorized into preventable deaths (42,290) and non-preventable deaths (17,325). Our analysis identifies the death risk of the former group, as they are amenable to policy interventions. We train six machine-learning algorithms, test their performance on unseen data, and evaluate them using a new policy-oriented metric. To avoid biased policy recommendations, we also investigate how our approach impacts disadvantaged populations. RESULTS: XGBoost was the best-performing algorithm for our task, with the 5% of births identified as highest risk by the model accounting for over 85% of the observed deaths. Furthermore, the risk predictions exhibit no statistical differences in the proportion of actual preventable deaths from disadvantaged populations, defined by race, education, marital status, and maternal age. These results are similar for other threshold levels. CONCLUSIONS: We show that, by using publicly available administrative data sets and ML methods, it is possible to identify the births with the highest risk of preventable deaths with a high degree of accuracy. This is useful for policymakers as they can target health interventions to those who need them the most and where they can be effective without producing bias against disadvantaged populations. Overall, our approach can guide policymakers in reducing neonatal mortality rates and their health inequalities. Finally, it can be adapted for use in other developing countries.",
      "authors": "Ramos Antonio P; Caldieraro Fabio; Nascimento Marcus L; Saldanha Raphael",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.01.12.24301163",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41040729/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12486022"
    },
    {
      "pmid": "40965098",
      "title": "Advancing equity in generative AI dermatology requires representative data and transparent evaluation.",
      "abstract": "",
      "authors": "Kabakova Margaret; Joerg Lucie; Jagdeo Jared",
      "year": "2025",
      "journal": "Journal of the European Academy of Dermatology and Venereology : JEADV",
      "doi": "10.1111/jdv.70052",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40965098/",
      "mesh_terms": "",
      "keywords": "algorithmic bias; artificial intelligence; dermatology; health equity; machine learning; skin pigmentation",
      "pub_types": "Letter",
      "pmcid": ""
    },
    {
      "pmid": "27411847",
      "title": "Estimating causal contrasts involving intermediate variables in the presence of selection bias.",
      "abstract": "An important goal across the biomedical and social sciences is the quantification of the role of intermediate factors in explaining how an exposure exerts an effect on an outcome. Selection bias has the potential to severely undermine the validity of inferences on direct and indirect causal effects in observational as well as in randomized studies. The phenomenon of selection may arise through several mechanisms, and we here focus on instances of missing data. We study the sign and magnitude of selection bias in the estimates of direct and indirect effects when data on any of the factors involved in the analysis is either missing at random or not missing at random. Under some simplifying assumptions, the bias formulae can lead to nonparametric sensitivity analyses. These sensitivity analyses can be applied to causal effects on the risk difference and risk-ratio scales irrespectively of the estimation approach employed. To incorporate parametric assumptions, we also develop a sensitivity analysis for selection bias in mediation analysis in the spirit of the expectation-maximization algorithm. The approaches are applied to data from a health disparities study investigating the role of stage at diagnosis on racial disparities in colorectal cancer survival. Copyright \u00a9 2016 John Wiley & Sons, Ltd.",
      "authors": "Valeri Linda; Coull Brent A",
      "year": "2016",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.7025",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27411847/",
      "mesh_terms": "Bias; Humans; Randomized Controlled Trials as Topic; Risk; Selection Bias",
      "keywords": "EM algorithm; controlled direct effects; mediation analysis; missing at random; natural direct and indirect effects; not missing at random; selection bias; sensitivity analyses",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "17328979",
      "title": "Economic evaluation of services for a National Health scheme: the case for a fairness-based framework.",
      "abstract": "In this paper we argue that the usual framework for evaluating health services may need modification in the context of a National Health Scheme (NHS). Some costs and benefits may need to be ignored or discounted, others included at face value, and some transfer payments included in the decision algorithm. In contrast with the standard framework, we argue that economic evaluation in the context of an NHS should focus on 'social transfers' between taxpayers and beneficiaries, and that the nature and scope of these transfers is determined by the level of social generosity. Some of the implications of a modified framework are illustrated with a re-examination of (i) costs and transfer payments, (ii) unrelated future costs, (iii) moral hazard, and (iv) the rule that marginal costs should equal marginal benefits. We argue that an explicitly 'fairness-based' framework is needed for the evaluation of services in an NHS. In contrast, the usual welfare economic theoretic framework facilitates the sidelining of issues of fairness.",
      "authors": "Richardson Jeff; McKie John",
      "year": "2007",
      "journal": "Journal of health economics",
      "doi": "10.1016/j.jhealeco.2006.11.004",
      "url": "https://pubmed.ncbi.nlm.nih.gov/17328979/",
      "mesh_terms": "Evaluation Studies as Topic; Health Services Accessibility; Humans; National Health Programs; Social Justice; Victoria",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41528321",
      "title": "Auditor models to suppress poor artificial intelligence predictions can improve human-artificial intelligence collaborative performance.",
      "abstract": "OBJECTIVE: Healthcare decisions are increasingly made with the assistance of machine learning (ML). ML has been known to have unfairness-inconsistent outcomes across subpopulations. Clinicians interacting with these systems can perpetuate such unfairness by overreliance. Recent work exploring ML suppression-silencing predictions based on auditing the ML-shows promise in mitigating performance issues originating from overreliance. This study aims to evaluate the impact of suppression on collaboration fairness and evaluate ML uncertainty as desiderata to audit the ML. MATERIALS AND METHODS: We used data from the Vanderbilt University Medical Center electronic health record (n\u2009=\u200958\u2009817) and the MIMIC-IV-ED dataset (n\u2009=\u2009363\u2009145) to predict likelihood of death or intensive care unit transfer and likelihood of 30-day readmission using gradient-boosted trees and an artificially high-performing oracle model. We derived clinician decisions directly from the dataset and simulated clinician acceptance of ML predictions based on previous empirical work on acceptance of clinical decision support alerts. We measured performance as area under the receiver operating characteristic curve and algorithmic fairness using absolute averaged odds difference. RESULTS: When the ML outperforms humans, suppression outperforms the human alone (P\u2009<\u20098.2\u2009\u00d7\u200910-6) and at least does not degrade fairness. When the human outperforms the ML, the human is either fairer than suppression (P\u2009<\u20098.2\u2009\u00d7\u200910-4) or there is no statistically significant difference in fairness. Incorporating uncertainty quantification into suppression approaches can improve performance. CONCLUSION: Suppression of poor-quality ML predictions through an auditor model shows promise in improving collaborative human-AI performance and fairness.",
      "authors": "Brown Katherine E; Wrenn Jesse O; Jackson Nicholas J; Cauley Michael R; Collins Benjamin X; Novak Laurie L; Malin Bradley A; Ancker Jessica S",
      "year": "2026",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf235",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41528321/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; human-AI collaboration; machine learning",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40417515",
      "title": "Federated Multiple Imputation for Variables that Are Missing Not At Random in Distributed Electronic Health Records.",
      "abstract": "Large electronic health records (EHR) have been widely implemented and are available for research activities. The magnitude of such databases often requires storage and computing infrastructure that are distributed at different sites. Restrictions on data-sharing due to privacy concerns have been another driving force behind the development of a large class of distributed and/or federated machine learning methods. While missing data problem is also present in distributed EHRs, albeit potentially more complex, distributed multiple imputation (MI) methods have not received as much attention. An important advantage of distributed MI, as well as distributed analysis, is that it allows researchers to borrow information across data sites, mitigating potential fairness issues for minority groups that do not have enough volume at certain sites. In this paper, we propose a communication-efficient and privacy-preserving distributed MI algorithms for variables that are missing not at random.",
      "authors": "Lian Yi; Jiang Xiaoqian; Long Qi",
      "year": "2024",
      "journal": "AMIA ... Annual Symposium proceedings. AMIA Symposium",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40417515/",
      "mesh_terms": "Electronic Health Records; Algorithms; Humans; Machine Learning; Confidentiality; Privacy",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12099382"
    },
    {
      "pmid": "40776262",
      "title": "FairFML: A Unified Approach to Algorithmic Fair Federated Learning with Applications to Reducing Gender Disparities in Cardiac Arrest Outcomes.",
      "abstract": "Addressing algorithmic bias in healthcare is crucial for ensuring equity in patient outcomes, particularly in cross-institutional collaborations where privacy constraints often limit data sharing. Federated learning (FL) offers a solution by enabling institutions to collaboratively train models without sharing sensitive data, but challenges related to fairness remain. To tackle this, we propose Fair Federated Machine Learning (FairFML), a model-agnostic framework designed to reduce algorithmic disparities while preserving patient privacy. Validated in a real-world study on gender disparities in cardiac arrest outcomes, FairFML improved fairness by up to 65% compared to centralized models, without compromising predictive performance.",
      "authors": "Li Siqi; Wu Qiming; Li Xin; Miao Di; Hong Chuan; Gu Wenjun; Ning Yilin; Shang Yuqing; Liu Nan",
      "year": "2025",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI251245",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40776262/",
      "mesh_terms": "Humans; Machine Learning; Female; Male; Heart Arrest; Algorithms; Healthcare Disparities; Sex Factors; Federated Learning",
      "keywords": "Clinical decision-making; Demographic disparity; Electronic health records; Federated Learning; Model fairness",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41531745",
      "title": "Fairness-aware K-means clustering in digital mental health for higher education students: a generalizable framework for equitable clustering.",
      "abstract": "OBJECTIVES: Higher education students, particularly those from underrepresented backgrounds, experience heightened levels of anxiety, depression, and burnout. Clinical informatics approaches leveraging K-means clustering can aid in mental health risk stratification, yet they often exacerbate disparities. We present a socially fair clustering framework that ensures equitable clustering costs across demographic groups while minimizing within-cluster variability. MATERIALS AND METHODS: Our framework compares standard and socially fair K-means clustering to assess the impact of demographic disparities. It identifies factors affecting clustering across demographics using omnibus and post hoc statistical tests. Subsequently, it quantifies the influence of statistically significant factors on cluster development. We illustrate our approach by identifying racially equitable clusters of mental health among students surveyed by the Healthy Minds Network. RESULTS: The socially fair clustering approach reduces disparities in clustering costs by as much as 30% across racial groups while maintaining consistency with standard K-means solutions in socioeconomically homogenous populations. Discrimination experiences were the strongest indicator of poorer mental health, whereas stable financial conditions and robust social engagement promoted resilience. DISCUSSION: Integrating fairness constraints into clustering algorithms reduces disparities in risk stratification and provides insights into socioeconomic drivers of student well-being. Our findings suggest that standard models may overpathologize middle-risk cohorts, whereas fairness-aware clustering yields partitions that better capture disparities. CONCLUSION: Our work demonstrates how integrating fairness-aware objectives into clustering algorithms can enhance equity in partitioning systems. The framework we present is broadly applicable to clustering problems across various biomedical informatics domains.",
      "authors": "Alluri Priyanshu; Chen Zequn; Thesen Thomas; Jacobson Nicholas C; Marrero Wesley J",
      "year": "2026",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooaf174",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41531745/",
      "mesh_terms": "",
      "keywords": "cluster analysis; machine learning; medical informatics; mental health; risk assessment",
      "pub_types": "Journal Article",
      "pmcid": "PMC12794019"
    },
    {
      "pmid": "37318804",
      "title": "Racial and Ethnic Bias in Risk Prediction Models for Colorectal Cancer Recurrence When Race and Ethnicity Are Omitted as Predictors.",
      "abstract": "IMPORTANCE: Including race and ethnicity as a predictor in clinical risk prediction algorithms has received increased scrutiny, but there continues to be a lack of empirical studies addressing whether simply omitting race and ethnicity from the algorithms will ultimately affect decision-making for patients of minoritized racial and ethnic groups. OBJECTIVE: To examine whether including race and ethnicity as a predictor in a colorectal cancer recurrence risk algorithm is associated with racial bias, defined as racial and ethnic differences in model accuracy that could potentially lead to unequal treatment. DESIGN, SETTING, AND PARTICIPANTS: This retrospective prognostic study was conducted using data from a large integrated health care system in Southern California for patients with colorectal cancer who received primary treatment between 2008 and 2013 and follow-up until December 31, 2018. Data were analyzed from January 2021 to June 2022. MAIN OUTCOMES AND MEASURES: Four Cox proportional hazards regression prediction models were fitted to predict time from surveillance start to cancer recurrence: (1) a race-neutral model that explicitly excluded race and ethnicity as a predictor, (2) a race-sensitive model that included race and ethnicity, (3) a model with 2-way interactions between clinical predictors and race and ethnicity, and (4) separate models by race and ethnicity. Algorithmic fairness was assessed using model calibration, discriminative ability, false-positive and false-negative rates, positive predictive value (PPV), and negative predictive value (NPV). RESULTS: The study cohort included 4230 patients (mean [SD] age, 65.3 [12.5] years; 2034 [48.1%] female; 490 [11.6%] Asian, Hawaiian, or Pacific Islander; 554 [13.1%] Black or African American; 937 [22.1%] Hispanic; and 2249 [53.1%] non-Hispanic White). The race-neutral model had worse calibration, NPV, and false-negative rates among racial and ethnic minority subgroups than non-Hispanic White individuals (eg, false-negative rate for Hispanic patients: 12.0% [95% CI, 6.0%-18.6%]; for non-Hispanic White patients: 3.1% [95% CI, 0.8%-6.2%]). Adding race and ethnicity as a predictor improved algorithmic fairness in calibration slope, discriminative ability, PPV, and false-negative rates (eg, false-negative rate for Hispanic patients: 9.2% [95% CI, 3.9%-14.9%]; for non-Hispanic White patients: 7.9% [95% CI, 4.3%-11.9%]). Inclusion of race interaction terms or using race-stratified models did not improve model fairness, likely due to small sample sizes in subgroups. CONCLUSIONS AND RELEVANCE: In this prognostic study of the racial bias in a cancer recurrence risk algorithm, removing race and ethnicity as a predictor worsened algorithmic fairness in multiple measures, which could lead to inappropriate care recommendations for patients who belong to minoritized racial and ethnic groups. Clinical algorithm development should include evaluation of fairness criteria to understand the potential consequences of removing race and ethnicity for health inequities.",
      "authors": "Khor Sara; Haupt Eric C; Hahn Erin E; Lyons Lindsay Joe L; Shankaran Veena; Bansal Aasthaa",
      "year": "2023",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2023.18495",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37318804/",
      "mesh_terms": "Aged; Female; Humans; Male; Middle Aged; Black or African American; Colorectal Neoplasms; Ethnicity; Hispanic or Latino; Minority Groups; Retrospective Studies; White; Asian American Native Hawaiian and Pacific Islander",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC10273018"
    },
    {
      "pmid": "38635456",
      "title": "Understanding and Mitigating Bias in Imaging Artificial Intelligence.",
      "abstract": "Artificial intelligence (AI) algorithms are prone to bias at multiple stages of model development, with potential for exacerbating health disparities. However, bias in imaging AI is a complex topic that encompasses multiple coexisting definitions. Bias may refer to unequal preference to a person or group owing to preexisting attitudes or beliefs, either intentional or unintentional. However, cognitive bias refers to systematic deviation from objective judgment due to reliance on heuristics, and statistical bias refers to differences between true and expected values, commonly manifesting as systematic error in model prediction (ie, a model with output unrepresentative of real-world conditions). Clinical decisions informed by biased models may lead to patient harm due to action on inaccurate AI results or exacerbate health inequities due to differing performance among patient populations. However, while inequitable bias can harm patients in this context, a mindful approach leveraging equitable bias can address underrepresentation of minority groups or rare diseases. Radiologists should also be aware of bias after AI deployment such as automation bias, or a tendency to agree with automated decisions despite contrary evidence. Understanding common sources of imaging AI bias and the consequences of using biased models can guide preventive measures to mitigate its impact. Accordingly, the authors focus on sources of bias at stages along the imaging machine learning life cycle, attempting to simplify potentially intimidating technical terminology for general radiologists using AI tools in practice or collaborating with data scientists and engineers for AI tool development. The authors review definitions of bias in AI, describe common sources of bias, and present recommendations to guide quality control measures to mitigate the impact of bias in imaging AI. Understanding the terms featured in this article will enable a proactive approach to identifying and mitigating bias in imaging AI. Published under a CC BY 4.0 license. Test Your Knowledge questions for this article are available in the supplemental material. See the invited commentary by Rouzrokh and Erickson in this issue.",
      "authors": "Tejani Ali S; Ng Yee Seng; Xi Yin; Rayan Jesse C",
      "year": "2024",
      "journal": "Radiographics : a review publication of the Radiological Society of North America, Inc",
      "doi": "10.1148/rg.230067",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38635456/",
      "mesh_terms": "Humans; Artificial Intelligence; Algorithms; Automation; Machine Learning; Bias",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "3853482",
      "title": "A computer algorithm for the assessment of age reporting bias in censal population estimates using Myers' 'blended' method.",
      "abstract": "A population's age structure is widely used in the computation of many vital statistics. The importance of highly accurate vital statistics cannot be overemphasized--such statistics are used extensively by governments to determine the proper allocation of health resources and services, and by demographers, sociologists and epidemiologists to study secular trends. A computer program has been developed for use on an Apple II+ microcomputer for the analysis of population age profiles and determination of age reporting bias.",
      "authors": "Ayiomamitis A",
      "year": "1985",
      "journal": "Computer methods and programs in biomedicine",
      "doi": "10.1016/0169-2607(85)90069-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/3853482/",
      "mesh_terms": "Adolescent; Adult; Age Factors; Aged; Child; Computers; Demography; Female; Humans; Life Expectancy; Male; Microcomputers; Middle Aged; Software; Vital Statistics",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36463866",
      "title": "Special Section on Inclusive Digital Health: Notable Papers on Addressing Bias, Equity, and Literacy to Strengthen Health Systems.",
      "abstract": "OBJECTIVE: To summarize significant research contributions on addressing bias, equity, and literacy in health delivery systems published in 2021. METHODS: An extensive search using PubMed and Scopus was conducted to identify peer-reviewed articles published in 2021 that examined ways that informatics methods, approaches, and tools could address bias, equity, and literacy in health systems and care delivery processes. The selection process comprised three steps: (1) 15 candidate best papers were first selected by the two section editors; (2) external reviewers from internationally renowned research teams reviewed each candidate best paper; and (3) the final selection of three best papers was conducted by the editorial committee of the Yearbook. RESULTS: Selected best papers represent studies that characterized significant challenges facing biomedical informatics with respect to equity and practices that support equity and literacy in the design of health information systems. Selected papers represent the full spectrum of this year's yearbook theme. In general, papers identified in the search fell into one of the following categories: (1) descriptive accounts of algorithmic bias in medical software or machine learning approaches; (2) enabling health information systems to appropriately encode for gender identity and sex; (3) approaches to support health literacy among individuals who interact with information systems and mobile applications; and (4) approaches to engage diverse populations in the use of health information systems and the biomedical informatics workforce CONCLUSIONS: : Although the selected papers are notable, our collective efforts as a biomedical informatics community to address equity, literacy, and bias remain nascent. More work is needed to ensure health information systems are just in their use of advanced computing approaches and all persons have equal access to health care and informatics tools.",
      "authors": "Dixon Brian E; Holmes John H",
      "year": "2022",
      "journal": "Yearbook of medical informatics",
      "doi": "10.1055/s-0042-1742536",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36463866/",
      "mesh_terms": "Female; Humans; Male; Gender Identity; Bias; Health Literacy; Health Information Systems; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9719755"
    },
    {
      "pmid": "36768092",
      "title": "Evaluation of AIML + HDR-A Course to Enhance Data Science Workforce Capacity for Hispanic Biomedical Researchers.",
      "abstract": "Artificial intelligence (AI) and machine learning (ML) facilitate the creation of revolutionary medical techniques. Unfortunately, biases in current AI and ML approaches are perpetuating minority health inequity. One of the strategies to solve this problem is training a diverse workforce. For this reason, we created the course \"Artificial Intelligence and Machine Learning applied to Health Disparities Research (AIML + HDR)\" which applied general Data Science (DS) approaches to health disparities research with an emphasis on Hispanic populations. Some technical topics covered included the Jupyter Notebook Framework, coding with R and Python to manipulate data, and ML libraries to create predictive models. Some health disparities topics covered included Electronic Health Records, Social Determinants of Health, and Bias in Data. As a result, the course was taught to 34 selected Hispanic participants and evaluated by a survey on a Likert scale (0-4). The surveys showed high satisfaction (more than 80% of participants agreed) regarding the course organization, activities, and covered topics. The students strongly agreed that the activities were relevant to the course and promoted their learning (3.71 \u00b1 0.21). The students strongly agreed that the course was helpful for their professional development (3.76 \u00b1 0.18). The open question was quantitatively analyzed and showed that seventy-five percent of the comments received from the participants confirmed their great satisfaction.",
      "authors": "Heredia-Negron Frances; Alamo-Rodriguez Natalie; Oyola-Velazquez Lenamari; Nieves Brenda; Carrasquillo Kelvin; Hochheiser Harry; Fristensky Brian; Daluz-Santana Istoni; Fernandez-Repollet Emma; Roche-Lima Abiel",
      "year": "2023",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph20032726",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36768092/",
      "mesh_terms": "Humans; Artificial Intelligence; Data Science; Hispanic or Latino; Machine Learning; Workforce; Biomedical Research",
      "keywords": "artificial intelligence; data science; health disparities; hispanic biomedical research; machine learning",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9914971"
    },
    {
      "pmid": "39591156",
      "title": "EMSIG: Uncovering Factors Influencing COVID-19 Vaccination Across Different Subgroups Characterized by Embedding-Based Spatial Information Gain.",
      "abstract": "Background/Objectives: COVID-19 and its variants continue to pose significant threats to public health, with considerable uncertainty surrounding their impact. As of September 2024, the total number of deaths reached 8.8 million worldwide. Vaccination remains the most effective strategy for preventing COVID-19. However, vaccination rates in the Deep South, U.S., are notably lower than the national average due to various factors. Methods: To address this challenge, we developed the Embedding-based Spatial Information Gain (EMSIG) method, an innovative tool using machine learning techniques for subgroup modeling. EMSIG helps identify subgroups where participants share similar perceptions but exhibit high variance in COVID-19 vaccine doses. It introduces spatial information gain (SIG) to screen regions of interest (ROI) subgroups and reveals their specific concerns. Results: We analyzed survey data from 1020 participants in Alabama. EMSIG identified 16 factors encompassing COVID-19 hesitancy and trust in medical doctors, pharmacists, and public health authorities and revealed four distinct ROI subgroups. The five factors, including COVID-19 perceived detriment, fear, skepticism, side effects related to COVID-19, and communication with pharmacists, were commonly shared across at least three subgroups. A subgroup primarily composed of Democrats with a high flu-shot rate expressed concerns about pharmacist communication, government fairness, and responsibility. Another subgroup, characterized by older, white Republicans with a relatively low flu-shot rate, expressed concerns about doctor trust and the intelligence of public health authorities. Conclusions: EMSIG enhances our understanding of specific concerns across different demographics, characterizes these demographics, and informs targeted interventions to increase vaccination uptake and ensure equitable prevention strategies.",
      "authors": "Yue Zongliang; McCormick Nicholas P; Ezeala Oluchukwu M; Durham Spencer H; Westrick Salisa C",
      "year": "2024",
      "journal": "Vaccines",
      "doi": "10.3390/vaccines12111253",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39591156/",
      "mesh_terms": "",
      "keywords": "COVID-19; embedding; factor; hesitancy; machine learning; spatial information gain; subgroup; uptake; vaccination",
      "pub_types": "Journal Article",
      "pmcid": "PMC11599077"
    },
    {
      "pmid": "41106548",
      "title": "Evaluating Long-Term Health Disparity Impacts of Clinical Algorithms Using a Patient-Level Simulation Framework.",
      "abstract": "OBJECTIVES: This study applies a simulation framework to evaluate the long-term effects of omitting race from a colon cancer decision algorithm for adjuvant chemotherapy, assessing impacts on health outcomes, costs, and disparities while accounting for measurement errors across racial groups. METHODS: We developed a patient-level state-transition model using electronic health records from a large Southern California health system to project outcomes for 4839 adults with stage II and III colon cancer after surgery. We compared 30-year quality-adjusted life-years (QALYs), healthcare costs, and QALY distribution among racial groups under 3 chemotherapy treatment scenarios: (1) current practice, (2) treatment guided by an algorithm that includes race, and (3) the same algorithm with race omitted. An additional health state addressed racial bias in cancer recurrence ascertainment, and probabilistic sensitivity analysis (PSA) assessed uncertainty. RESULTS: The clinical algorithm, compared with current practice, could improve average health by 0.048 QALYs and reduce racial health disparity by 0.20 QALYs at an incremental cost of $3221, with the disparity gap decreasing in 96% of PSA iterations. Omitting race showed minimal effects on overall health or costs but resulted in 13% fewer Black patients receiving treatment, decreasing their QALYs by 0.07 and widening the disparity gap by 0.13 QALY. Health disparity increased in 94% of PSA iterations. CONCLUSIONS: A cancer decision algorithm can improve population health and reduce health disparities, but omitting race may harm disadvantaged groups and limit reductions in disparities. Patient-level simulations can be routinely used to evaluate the potential health disparity impacts of algorithms before implementation.",
      "authors": "Khor Sara; Basu Anirban; Shankaran Veena; Lee Kyueun; Haupt Eric C; Hahn Erin E; Carlson Josh J; Bansal Aasthaa",
      "year": "2025",
      "journal": "Value in health : the journal of the International Society for Pharmacoeconomics and Outcomes Research",
      "doi": "10.1016/j.jval.2025.09.3066",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41106548/",
      "mesh_terms": "",
      "keywords": "clinical algorithms; health disparity; microsimulation; patient-level simulation; racial disparity",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32819343",
      "title": "In Defence of informed consent for health record research\u00a0- why arguments from 'easy rescue', 'no harm' and 'consent bias' fail.",
      "abstract": "BACKGROUND: Health data holds great potential for improved treatments. Big data research and machine learning models have been shown to hold great promise for improved diagnostics and treatment planning. The potential is tied, however, to the availability of personal health data. In recent years, it has been argued that data from health records should be available for health research, and that individuals have a duty to make the data available for such research. A central point of debate is whether such secondary use of health data requires informed consent. MAIN BODY: In response to recent writings this paper argues that a requirement of informed consent for health record research must be upheld. It does so by exploring different contrasting notions of the duty of easy rescue and arguing that none of them entail a perfect duty to participate in health record research. In part because the costs of participation cannot be limited to 1) the threat of privacy breaches, but includes 2) the risk of reduced trust and 3) suboptimal treatment, 4) stigmatization and 5) medicalisation, 6) further stratification of solidarity and 7) increased inequality in access to treatment and medicine. And finally, it defends the requirement of informed consent by arguing that the mere possibility of consent bias provides a rather weak reason for making research participation mandatory, and that there are strong, independent reasons for making. CONCLUSION: Arguments from the duty of easy rescue in combination with claims about little risk of harm and potential consent bias fail to establish not only a perfect duty to participate in health record research, but also that participation in such research should be mandatory. On the contrary, an analysis of these arguments indicates that the duty to participate in research is most adequately construed as an imperfect duty, and reveals a number of strong reasons for insisting that participation in health records research is based on informed consent.",
      "authors": "Ploug Thomas",
      "year": "2020",
      "journal": "BMC medical ethics",
      "doi": "10.1186/s12910-020-00519-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32819343/",
      "mesh_terms": "Dissent and Disputes; Humans; Informed Consent; Trust",
      "keywords": "Consent bias; Duty of easy rescue; Equality in health; Harm; Health data; Informed consent; Medicalization; Privacy; Solidarity; Stigmatization; Trust",
      "pub_types": "Journal Article",
      "pmcid": "PMC7441538"
    },
    {
      "pmid": "31360060",
      "title": "On the Bias of Precision Estimation Under Separate Sampling.",
      "abstract": "Observational case-control studies for biomarker discovery in cancer studies often collect data that are sampled separately from the case and control populations. We present an analysis of the bias in the estimation of the precision of classifiers designed on separately sampled data. The analysis consists of both theoretical and numerical results, which show that classifier precision estimates can display strong bias under separating sampling, with the bias magnitude depending on the difference between the true case prevalence in the population and the sample prevalence in the data. We show that this bias is systematic in the sense that it cannot be reduced by increasing sample size. If information about the true case prevalence is available from public health records, then a modified precision estimator that uses the known prevalence displays smaller bias, which can in fact be reduced to zero as sample size increases under regularity conditions on the classification algorithm. The accuracy of the theoretical analysis and the performance of the precision estimators under separate sampling are confirmed by numerical experiments using synthetic and real data from published observational case-control studies. The results with real data confirmed that under separately sampled data, the usual estimator produces larger, ie, more optimistic, precision estimates than the estimator using the true prevalence value.",
      "authors": "Xie Shuilian; Braga-Neto Ulisses M",
      "year": "2019",
      "journal": "Cancer informatics",
      "doi": "10.1177/1176935119860822",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31360060/",
      "mesh_terms": "",
      "keywords": "Precision; bias; classification; experimental design; observational study; recall",
      "pub_types": "Journal Article",
      "pmcid": "PMC6636226"
    },
    {
      "pmid": "39767481",
      "title": "AI in Biomedicine-A Forward-Looking Perspective on Health Equity.",
      "abstract": "As new artificial intelligence (AI) tools are being developed and as AI continues to revolutionize healthcare, its potential to advance health equity is increasingly recognized. The 2024 Research Centers in Minority Institutions (RCMI) Consortium National Conference session titled \"Artificial Intelligence: Safely, Ethically, and Responsibly\" brought together experts from diverse institutions to explore AI's role and challenges in advancing health equity. This report summarizes presentations and discussions from the conference focused on AI's potential and its challenges, particularly algorithmic bias, transparency, and the under-representation of minority groups in AI datasets. Key topics included AI's predictive and generative capabilities in healthcare, ethical governance, and key national initiatives, like AIM-AHEAD. The session highlighted the critical role of RCMI institutions in fostering diverse AI/machine learning research and in developing culturally competent AI tools. Other discussions included AI's capacity to improve patient outcomes, especially for underserved communities, and underscored the necessity for robust ethical standards, a diverse AI and scientific workforce, transparency, and inclusive data practices. The engagement of RCMI institutions is critical to ensure practices in AI development and deployment which prioritize health equity, thus paving the way for a more inclusive AI-driven healthcare system.",
      "authors": "Kumar Deepak; Malin Bradley A; Vishwanatha Jamboor K; Wu Lang; Hedges Jerris R",
      "year": "2024",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph21121642",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39767481/",
      "mesh_terms": "Health Equity; Artificial Intelligence; Humans; Biomedical Research",
      "keywords": "RCMI; artificial intelligence; augmented intelligence; health disparities; health equity; health ethics; machine learning",
      "pub_types": "Journal Article; Conference Proceedings",
      "pmcid": "PMC11675414"
    },
    {
      "pmid": "39399154",
      "title": "Predicting Prenatal Depression and Assessing Model Bias Using Machine Learning Models.",
      "abstract": "BACKGROUND: Perinatal depression is one of the most common medical complications during pregnancy and postpartum period, affecting 10% to 20% of pregnant individuals, with higher rates among Black and Latina women who are also less likely to be diagnosed and treated. Machine learning (ML) models based on electronic medical records (EMRs) have effectively predicted postpartum depression in middle-class White women but have rarely included sufficient proportions of racial/ethnic minorities, which has contributed to biases in ML models. Our goal is to determine whether ML models could predict depression in early pregnancy in racial/ethnic minority women by leveraging EMR data. METHODS: We extracted EMRs from a large U.S. urban hospital serving mostly low-income Black and Hispanic women (n\u00a0= 5875). Depressive symptom severity was assessed using the Patient Health Questionnaire-9 self-report questionnaire. We investigated multiple ML classifiers using Shapley additive explanations for model interpretation and determined prediction bias with 4 metrics: disparate impact, equal opportunity difference, and equalized odds (standard deviations of true positives and false positives). RESULTS: Although the best-performing ML model's (elastic net) performance was low (area under the receiver operating characteristic curve\u00a0= 0.61), we identified known perinatal depression risk factors such as unplanned pregnancy and being single and underexplored factors such as self-reported pain, lower prenatal vitamin intake, asthma, carrying a male fetus, and lower platelet levels. Despite the sample comprising mostly low-income minority women (54% Black, 27% Latina), the model performed worse for these communities (area under the receiver operating characteristic curve: 57% Black, 59% Latina women vs. 64% White women). CONCLUSIONS: EMR-based ML models could moderately predict early pregnancy depression but exhibited biased performance against low-income minority women.",
      "authors": "Huang Yongchao; Alvernaz Suzanne; Kim Sage J; Maki Pauline; Dai Yang; Pe\u00f1alver Bernab\u00e9 Beatriz",
      "year": "2024",
      "journal": "Biological psychiatry global open science",
      "doi": "10.1016/j.bpsgos.2024.100376",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39399154/",
      "mesh_terms": "",
      "keywords": "Electronic medical records; Health disparities; Machine learning; Model performance bias; Perinatal depression",
      "pub_types": "Journal Article",
      "pmcid": "PMC11470166"
    },
    {
      "pmid": "41260014",
      "title": "Knowledge-informed deep learning to mitigate bias in joint air pollutant prediction.",
      "abstract": "Accurate prediction of atmospheric air pollutants is critical for public health protection and environmental management. Traditional machine learning (ML) methods achieve high spatial resolution but lack physicochemical constraints, leading to systematic biases that compromise exposure estimates for epidemiological studies. Chemical transport models incorporate atmospheric physics but require expensive parameterization and often fail to capture local-scale variability crucial for health impact assessment. This gap between data-driven accuracy and physical realism presents a major obstacle to advancing air quality science. We address this challenge through a novel physics-informed deep learning framework that integrates advection-diffusion equations and fluid dynamics constraints directly into neural network architectures for multi-pollutant prediction. Our approach models air pollutant pairs across geographically distinct domains (NO2/NOx for California; PM2.5/PM10 for mainland China), providing a comprehensive framework for physics-constrained atmospheric modeling at high resolution. Through an efficient framework, our methodology demonstrates that incorporating proxy advection and diffusion fields as physical constraints fundamentally alters learning dynamics, reducing generalization error and eliminating systematic bias inherent in data-driven approaches while improving computational efficiency compared to graph networks. Site-based validation reveals unprecedented bias reduction: 21%-42% for nitrogen oxides and 16%-17% for particulate matter compared to the baseline deep learning methods. Our methodology uniquely generates physically interpretable parameters while providing explicit uncertainty quantification through ensemble techniques. The substantial bias reduction coupled with physically interpretable parameters has immediate implications for improving air pollutant exposure assessment and understanding in epidemiological research, potentially transforming health effect evaluations that rely on accurate spatial predictions.",
      "authors": "Li Lianfa; Khalili Roxana; Lurmann Frederick; Pavlovic Nathan; Wu Jun; Xu Yan; Liu Yisi; O'Sharkey Karl; Ritz Beate; Oman Luke; Franklin Meredith; Bastain Theresa; Farzan Shohreh F; Breton Carrie; Habre Rima",
      "year": "2025",
      "journal": "Environment international",
      "doi": "10.1016/j.envint.2025.109915",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41260014/",
      "mesh_terms": "Deep Learning; Air Pollutants; Air Pollution; Particulate Matter; Environmental Monitoring; California; China; Nitrogen Oxides",
      "keywords": "Air pollution; Bias mitigation; Deep learning; Joint prediction; Knowledge fusion; Physics-informed modeling",
      "pub_types": "Journal Article",
      "pmcid": "PMC12810719"
    },
    {
      "pmid": "35044842",
      "title": "Negative Patient Descriptors: Documenting Racial Bias In The Electronic Health Record.",
      "abstract": "Little is known about how racism and bias may be communicated in the medical record. This study used machine learning to analyze electronic health records (EHRs) from an urban academic medical center and to investigate whether providers' use of negative patient descriptors varied by patient race or ethnicity. We analyzed a sample of 40,113 history and physical notes (January 2019-October 2020) from 18,459 patients for sentences containing a negative descriptor (for example, resistant or noncompliant) of the patient or the patient's behavior. We used mixed effects logistic regression to determine the odds of finding at least one negative descriptor as a function of the patient's race or ethnicity, controlling for sociodemographic and health characteristics. Compared with White patients, Black patients had 2.54 times the odds of having at least one negative descriptor in the history and physical notes. Our findings raise concerns about stigmatizing language in the EHR and its potential to exacerbate racial and ethnic health care disparities.",
      "authors": "Sun Michael; Oliwa Tomasz; Peek Monica E; Tung Elizabeth L",
      "year": "2022",
      "journal": "Health affairs (Project Hope)",
      "doi": "10.1377/hlthaff.2021.01423",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35044842/",
      "mesh_terms": "Black People; Electronic Health Records; Ethnicity; Healthcare Disparities; Humans; Racism",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC8973827"
    },
    {
      "pmid": "36639799",
      "title": "Ethics and governance of trustworthy medical artificial intelligence.",
      "abstract": "BACKGROUND: The growing application of artificial intelligence (AI) in healthcare has brought technological breakthroughs to traditional diagnosis and treatment, but it is accompanied by many risks and challenges. These adverse effects are also seen as ethical issues and affect trustworthiness in medical AI and need to be managed through identification, prognosis and monitoring. METHODS: We adopted a multidisciplinary approach and summarized five subjects that influence the trustworthiness of medical AI: data quality, algorithmic bias, opacity, safety and security, and responsibility attribution, and discussed these factors from the perspectives of technology, law, and healthcare stakeholders and institutions. The ethical framework of ethical values-ethical principles-ethical norms is used to propose corresponding ethical governance countermeasures for trustworthy medical AI from the ethical, legal, and regulatory aspects. RESULTS: Medical data are primarily unstructured, lacking uniform and standardized annotation, and data quality will directly affect the quality of medical AI algorithm models. Algorithmic bias can affect AI clinical predictions and exacerbate health disparities. The opacity of algorithms affects patients' and doctors' trust in medical AI, and algorithmic errors or security vulnerabilities can pose significant risks and harm to patients. The involvement of medical AI in clinical practices may threaten doctors 'and patients' autonomy and dignity. When accidents occur with medical AI, the responsibility attribution is not clear. All these factors affect people's trust in medical AI. CONCLUSIONS: In order to make medical AI trustworthy, at the ethical level, the ethical value orientation of promoting human health should first and foremost be considered as the top-level design. At the legal level, current medical AI does not have moral status and humans remain the duty bearers. At the regulatory level, strengthening data quality management, improving algorithm transparency and traceability to reduce algorithm bias, and regulating and reviewing the whole process of the AI industry to control risks are proposed. It is also necessary to encourage multiple parties to discuss and assess AI risks and social impacts, and to strengthen international cooperation and communication.",
      "authors": "Zhang Jie; Zhang Zong-Ming",
      "year": "2023",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-023-02103-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36639799/",
      "mesh_terms": "Humans; Artificial Intelligence; Algorithms; Delivery of Health Care; Prognosis; Data Management",
      "keywords": "Algorithms; Artificial intelligence; Data; Ethics; Governance; Healthcare; Regulation; Responsibility attribution",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9840286"
    },
    {
      "pmid": "41409534",
      "title": "Refined Algorithm for Identifying Recurrence Among Patients with Non-Metastatic Colorectal Cancer Based on Danish National Health Data Registries.",
      "abstract": "PURPOSE: In the Danish and other national health registries, colorectal cancer (CRC) recurrence is not routinely registered. Algorithms to label patients with recurrence in Denmark exist but produce cohorts with a risk of selection bias due to either pre- or postoperative exclusion criteria. In this study, we aimed to refine and increase the generalizability of an existing registry-based algorithm. PATIENTS AND METHODS: Data from 5077 patients from an institution and a regional database, encompassing several departments of surgery in Denmark, were retrieved. Patients with non-metastatic CRC were included from 2008 to 2019. Electronic health journal-based recurrence registration was used as reference for the algorithm. Patients were linked with data from the Danish Colorectal Cancer Group database, the Danish National Health Registry, the Danish Cancer Registry, and the Danish Pathology Registry. The algorithm utilized metastasis, chemotherapy, pathology, and local recurrence codes. Refinement of the algorithm included the addition of targeted and radiation therapy codes and including patients who died within 180 days after surgery, along with revising the pathology codes and removing any preoperative exclusion criteria. Performance metrics were evaluated in 10,000 bootstrapped runs, while all-stage and stage-specific cumulative incidence of recurrence and overall survival were estimated. RESULTS: The refined algorithm included more patients than the conventional algorithm (4388 vs 3684) and performed marginally better in terms of sensitivity (0.92 (95% CI 0.89-0.94) vs 0.90 (95% CI 0.87-0.92)) and specificity (0.97 (95% CI 0.97-0.98) vs 0.96 (95% CI 0.95-0.96). A significant difference in cumulative incidence of recurrence for UICC stage I was detected between the conventional algorithm and reference, which was not significant when using the refined algorithm. CONCLUSION: The refined algorithm improves identification of CRC recurrence in national data, enabling broader inclusion and better representation of population subgroups.",
      "authors": "G\u00f6genur Mikail; Br\u00e4uner Karoline Bendix; L\u00f6ffler Lea; Olsen Anna Sofie Friis; Gundestrup Anders Kierkegaard; Jakobsen Peter Cornelius Helbo; Kleif Jakob; Bertelsen Claus Anders; G\u00f6genur Ismail",
      "year": "2025",
      "journal": "Clinical epidemiology",
      "doi": "10.2147/CLEP.S532957",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41409534/",
      "mesh_terms": "",
      "keywords": "colorectal cancer; recurrence; registry-based algorithm",
      "pub_types": "Journal Article",
      "pmcid": "PMC12706160"
    },
    {
      "pmid": "24913296",
      "title": "Bias in the proportionate mortality ratio analysis of small study populations: a case on analyses of radiation and mesothelioma.",
      "abstract": "UNLABELLED: Abstract Purpose: To quantify bias in the proportionate mortality ratio (PMR) analysis of small study populations and develop a bias correction methodology. MATERIALS AND METHODS: Bias in the PMR analysis of small study populations is quantified through algebraic derivation. A simulation procedure is developed to evaluate the relationship between bias and study population size. A recently published PMR analysis of radiation and mesothelioma among 329 deceased registrants in the United States Transuranium and Uranium Registries (USTUR) is used as an illustrated example. RESULTS: The proportionate mortality ratios are biased and overestimated in small population studies; the smaller the study population, the larger the overestimation. As such, the average overestimation of PMR for mesothelioma in the analyses of radiation and mesothelioma in USTUR is 7.2% (95% confidence interval = 5.1%, 9.7%); the PMR overestimation is 22.5% (95% confidence interval = 16.8%, 29.1%) when stratified by quartiles of radiation doses. CONCLUSIONS: The degree of PMR small sample bias is mainly determined by the sample size ratio, which is defined as the ratio of the sample size to the number of disease categories in the reference population. Correction for the bias is recommended when the sample size ratio is less than 5. The quantification and correction algorithm of the PMR small sample bias developed in this research supplements the PMR methodology.",
      "authors": "Zhou Joey Y",
      "year": "2014",
      "journal": "International journal of radiation biology",
      "doi": "10.3109/09553002.2014.931611",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24913296/",
      "mesh_terms": "Global Health; Humans; Mesothelioma; Models, Statistical; Mortality; Neoplasms, Radiation-Induced; Occupational Diseases; Poisson Distribution; Radiation Dosage; Reproducibility of Results; Research Design; Risk Factors; Sample Size; Treatment Outcome; United States",
      "keywords": "Radiation health effect; mesothelioma; proportionate mortality ratio; small sample bias",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34986109",
      "title": "Personalized On-Device E-Health Analytics With Decentralized Block Coordinate Descent.",
      "abstract": "Actuated by the growing attention to personal healthcare and the pandemic, the popularity of E-health is proliferating. Nowadays, enhancement on medical diagnosis via machine learning models has been highly effective in many aspects of e-health analytics. Nevertheless, in the classic cloud-based/centralized e-health paradigms, all the data will be centrally stored on the server to facilitate model training, which inevitably incurs privacy concerns and high time delay. Distributed solutions like Decentralized Stochastic Gradient Descent (D-SGD) are proposed to provide safe and timely diagnostic results based on personal devices. However, methods like D-SGD are subject to the gradient vanishing issue and usually proceed slowly at the early training stage, thereby impeding the effectiveness and efficiency of training. In addition, existing methods are prone to learning models that are biased towards users with dense data, compromising the fairness when providing E-health analytics for minority groups. In this paper, we propose a Decentralized Block Coordinate Descent (D-BCD) learning framework that can better optimize deep neural network-based models distributed on decentralized devices for E-health analytics. As a gradient-free optimization method, Block Coordinate Descent (BCD) mitigates the gradient vanishing issue and converges faster at the early stage compared with the conventional gradient-based optimization. To overcome the potential data scarcity issues for users' local data, we propose similarity-based model aggregation that allows each on-device model to leverage knowledge from similar neighbor models, so as to achieve both personalization and high accuracy for the learned models. Benchmarking experiments on three real-world datasets illustrate the effectiveness and practicality of our proposed D-BCD, where additional simulation study showcases the strong applicability of D-BCD in real-life E-health scenarios.",
      "authors": "Ye Guanhua; Yin Hongzhi; Chen Tong; Xu Miao; Nguyen Quoc Viet Hung; Song Jiangning",
      "year": "2022",
      "journal": "IEEE journal of biomedical and health informatics",
      "doi": "10.1109/JBHI.2022.3140455",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34986109/",
      "mesh_terms": "Computer Simulation; Humans; Machine Learning; Neural Networks, Computer; Privacy; Telemedicine",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40298901",
      "title": "External validation of a proprietary risk model for 1-year mortality in community-dwelling adults aged 65 years or older.",
      "abstract": "OBJECTIVE: To examine the discrimination, calibration, and algorithmic fairness of the Epic End of Life Care Index (EOL-CI). MATERIALS AND METHODS: We assessed the EOL-CI's performance by estimating area under the receiver operating characteristic curve (AUC), sensitivity, and positive and negative predictive values in community-dwelling adults \u226565 years of age in a single health system in the Southeastern United States. Algorithmic fairness was examined by comparing the model's performance across sex, race, and ethnicity subgroups. Using a machine learning approach, we also explored local re-calibration of the EOL-CI considering additional information on past hospitalizations and frailty. RESULTS: Among 215\u00a0731 patients (median age\u2009=\u200974 years, 57% female, 12% of Black race), 10% were classified as medium risk (15-44) and 3% as high risk (\u226545) by the EOL-CI. The observed 1-year mortality rate was 3%. The EOL-CI had an AUC 0.82 for 1-year mortality, with a positive predictive value of 22%. Predictive performance was generally similar across sex and race subgroups, though the EOL-CI displayed better performance with increasing age and in older adults with 2 or more outpatient encounters in the past 24 months. Local re-calibration of the EOL-CI was required to provide absolute estimates of mortality risk, and calibration was further improved when the EOL-CI was augmented with data on inpatient hospitalizations and frailty. DISCUSSION: The EOL-CI demonstrates reasonable discrimination, albeit with better performance in older adults and in those with greater health system contact. CONCLUSION: Local refinement and calibration of the EOL-CI score is required to provide direct estimates of prognosis, with the goal of making the EOL-CI a more a valuable tool at the point of care for identifying patients who would benefit from targeted palliative care interventions and proactive care planning.",
      "authors": "Frechman Erica; Jaeger Byron C; Kowalkowski Marc; Williamson Jeff D; Lenoir Kristin M; Palakshappa Jessica A; Wells Brian J; Callahan Kathryn E; Pajewski Nicholas M; Gabbard Jennifer L",
      "year": "2025",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf062",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40298901/",
      "mesh_terms": "Humans; Aged; Female; Male; Risk Assessment; Aged, 80 and over; Mortality; Independent Living; ROC Curve; Terminal Care; Algorithms; Machine Learning; Area Under Curve; Southeastern United States",
      "keywords": "clinical decision-making; electronic health records; palliative care; prognosis",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC12199354"
    },
    {
      "pmid": "38551630",
      "title": "The Implementation of Recommender Systems for Mental Health Recovery Narratives: Evaluation of Use and Performance.",
      "abstract": "BACKGROUND: Recommender systems help narrow down a large range of items to a smaller, personalized set. NarraGive is a first-in-field hybrid recommender system for mental health recovery narratives, recommending narratives based on their content and narrator characteristics (using content-based filtering) and on narratives beneficially impacting other similar users (using collaborative filtering). NarraGive is integrated into the Narrative Experiences Online (NEON) intervention, a web application providing access to the NEON Collection of recovery narratives. OBJECTIVE: This study aims to analyze the 3 recommender system algorithms used in NarraGive to inform future interventions using recommender systems for lived experience narratives. METHODS: Using a recently published framework for evaluating recommender systems to structure the analysis, we compared the content-based filtering algorithm and collaborative filtering algorithms by evaluating the accuracy (how close the predicted ratings are to the true ratings), precision (the proportion of the recommended narratives that are relevant), diversity (how diverse the recommended narratives are), coverage (the proportion of all available narratives that can be recommended), and unfairness (whether the algorithms produce less accurate predictions for disadvantaged participants) across gender and ethnicity. We used data from all participants in 2 parallel-group, waitlist control clinical trials of the NEON intervention (NEON trial: N=739; NEON for other [eg, nonpsychosis] mental health problems [NEON-O] trial: N=1023). Both trials included people with self-reported mental health problems who had and had not used statutory mental health services. In addition, NEON trial participants had experienced self-reported psychosis in the previous 5 years. Our evaluation used a database of Likert-scale narrative ratings provided by trial participants in response to validated narrative feedback questions. RESULTS: Participants from the NEON and NEON-O trials provided 2288 and 1896 narrative ratings, respectively. Each rated narrative had a median of 3 ratings and 2 ratings, respectively. For the NEON trial, the content-based filtering algorithm performed better for coverage; the collaborative filtering algorithms performed better for accuracy, diversity, and unfairness across both gender and ethnicity; and neither algorithm performed better for precision. For the NEON-O trial, the content-based filtering algorithm did not perform better on any metric; the collaborative filtering algorithms performed better on accuracy and unfairness across both gender and ethnicity; and neither algorithm performed better for precision, diversity, or coverage. CONCLUSIONS: Clinical population may be associated with recommender system performance. Recommender systems are susceptible to a wide range of undesirable biases. Approaches to mitigating these include providing enough initial data for the recommender system (to prevent overfitting), ensuring that items can be accessed outside the recommender system (to prevent a feedback loop between accessed items and recommended items), and encouraging participants to provide feedback on every narrative they interact with (to prevent participants from only providing feedback when they have strong opinions).",
      "authors": "Slade Emily; Rennick-Egglestone Stefan; Ng Fiona; Kotera Yasuhiro; Llewellyn-Beardsley Joy; Newby Chris; Glover Tony; Keppens Jeroen; Slade Mike",
      "year": "2024",
      "journal": "JMIR mental health",
      "doi": "10.2196/45754",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38551630/",
      "mesh_terms": "Humans; Mental Health Recovery; Neon; Algorithms; Software; Narration",
      "keywords": "NEON trial; Narrative Experiences Online trial; fairness across users; intralist diversity; item space coverage; lived experience narrative; mean absolute error; precision; psychosis; recommender system; recovery story",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11015364"
    },
    {
      "pmid": "40444224",
      "title": "The effectiveness, equity and explainability of health service resource allocation-with applications in kidney transplantation & family planning.",
      "abstract": "INTRODUCTION: Halfway to the deadline of the 2030 agenda, humankind continues to face long-standing yet urgent policy and management challenges to address resource shortages and deliver on Sustainable Development Goal 3; health and well-being for all at all ages. More than half of the global population lacks access to essential health services. Additional resources are required and need to be allocated effectively and equitably. Resource allocation models, however, have struggled to accurately predict effects and to present optimal allocations, thus hampering effectiveness and equity improvement. The current advances in machine learning present opportunities to better predict allocation effects and to prescribe solutions that better balance effectiveness and equity. The most advanced of these models tend to be \"black box\" models that lack explainability. This lack of explainability is problematic as it can clash with professional values and hide biases that negatively impact effectiveness and equity. METHODS: Through a novel theoretical framework and two diverse case studies, this manuscript explores the trade-offs between effectiveness, equity, and explainability. The case studies consider family planning in a low income country and kidney allocation in a high income country. RESULTS: Both case studies find that the least explainable models hardly offer improvements in effectiveness and equity over explainable alternatives. DISCUSSION: As this may more widely apply to health resource allocation decisions, explainable analytics, which are more likely to be trusted and used, might better enable progress towards SDG3 for now. Future research on explainability, also in relation to equity and fairness of allocation policies, can help deliver on the promise of advanced predictive and prescriptive analytics.",
      "authors": "van de Klundert Joris; de Vries Harwin; P\u00e9rez-Galarce Francisco; Valdes Nieves; Simon Felipe",
      "year": "2025",
      "journal": "Frontiers in health services",
      "doi": "10.3389/frhs.2025.1545864",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40444224/",
      "mesh_terms": "",
      "keywords": "effectiveness; equity; explainability; explainable AI; family planning; healthcare analytics; kidney allocation",
      "pub_types": "Journal Article",
      "pmcid": "PMC12119484"
    },
    {
      "pmid": "34966957",
      "title": "Big Data/AI in Neurocritical Care: Maybe/Summary.",
      "abstract": "Big data (BD) and artificial intelligence (AI) have increasingly been used in neurocritical care. \"BD\" can be operationally defined as extremely large datasets that are so large and complex that they cannot be analyzed by using traditional statistical modeling. \"AI\" means the ability of machines to perform tasks similar to those performed by human intelligence. We present a brief overview of the most commonly applied AI techniques to perform BD analytics and discuss some of the recent promising examples in the field of neurocritical care. The latter include the following: cognitive motor dissociation in disorders of consciousness, hypoxic-ischemic injury following cardiac arrest, delayed cerebral ischemia and vasospasm after subarachnoid hemorrhage, and monitoring of intracranial pressure. It is imperative that we develop multicenter collaborations to tackle BD. These collaborations will allow us to share data, combine predictive algorithms, and analyze multiple and cumulative sources of data retrospectively and prospectively. Once AI algorithms are validated at multiple centers, they should be tested in randomized controlled trials investigating their impact on clinical outcome. The neurocritical care community must work to ensure that AI incorporates standards to ensure fairness and health equity rather than reflect our biases present in our collective conscience.",
      "authors": "Suarez Jose I",
      "year": "2022",
      "journal": "Neurocritical care",
      "doi": "10.1007/s12028-021-01422-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34966957/",
      "mesh_terms": "Algorithms; Artificial Intelligence; Big Data; Humans; Machine Learning; Retrospective Studies",
      "keywords": "Artificial intelligence; Big data; Deep learning; Machine learning; Precision medicine",
      "pub_types": "Journal Article; Multicenter Study",
      "pmcid": "3897241"
    },
    {
      "pmid": "39397594",
      "title": "Accessing the Impact of TikTok's Algorithm on Regional Inequality in Health Information.",
      "abstract": "This study aims to audit the potential algorithmic bias in TikTok's health-related video recommendation toward geographically diverse groups in China. We employed 120 cloud phones and conducted two agent-based testing experiments simulating users' geographical locations and online behaviors. The results indicated significant regional inequality in video sources recommended by the TikTok algorithm, t(118)\u2009=\u20093.02, p\u2009=\u2009.003, with users from developed cities encountering a higher proportion of professional videos than those from underdeveloped cities. However, when users from both regions expressed a similar preference for the same type of information, an equal proportion of professional videos was recommended. Our findings suggest that widely used algorithms may covertly perpetuate social inequities and reinforce preexisting class-based inequalities, particularly affecting vulnerable population from low-income regions. This study also highlights the importance of enhancing eHealth literacy among disadvantaged users to mitigate problematic outcomes in the AI-based communication landscape.",
      "authors": "Li Jinhui; Shi Wen",
      "year": "2025",
      "journal": "Health communication",
      "doi": "10.1080/10410236.2024.2414882",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39397594/",
      "mesh_terms": "Humans; China; Algorithms; Socioeconomic Factors; Video Recording; Consumer Health Information",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "27694664",
      "title": "HTA - Algorithm or Process? Comment on \"Expanded HTA: Enhancing Fairness and Legitimacy\".",
      "abstract": "Daniels, Porteny and Urrutia et al make a good case for the idea that that public decisions ought to be made not only \"in the light of\" evidence but also \"on the basis of\" budget impact, financial protection and equity. Health technology assessment (HTA) should, they say, be accordingly expanded to consider matters additional to safety and cost-effectiveness. They also complain that most HTA reports fail to develop ethical arguments and generally do not even mention ethical issues. This comment argues that some of these defects are more apparent than real and are not inherent in HTA - as distinct from being common characteristics found in poorly conducted HTAs. More generally, HTA does not need \"extension\" since (1) ethical issues are already embedded in HTA processes, not least in their scoping phases, and (2) HTA processes are already sufficiently flexible to accommodate evidence about a wide range of factors, and will not need fundamental change in order to accommodate the new forms of decision-relevant evidence about distributional impact and financial protection that are now starting to emerge. HTA and related techniques are there to support decision-makers who have authority to make decisions. Analysts like us are there to support and advise them (and not to assume the responsibilities for which they, and not we, are accountable). The required quality in HTA then becomes its effectiveness as a means of addressing the issues of concern to decision-makers. What is also required is adherence by competent analysts to a standard template of good analytical practice. The competencies include not merely those of the usual disciplines (particularly biostatistics, cognitive psychology, health economics, epidemiology, and ethics) but also the imaginative and interpersonal skills for exploring the \"real\" question behind the decision-maker's brief (actual or postulated) and eliciting the social values that necessarily pervade the entire analysis. The product of such exploration defines the authoritative scope of an HTA.",
      "authors": "Culyer Anthony J",
      "year": "2016",
      "journal": "International journal of health policy and management",
      "doi": "10.15171/ijhpm.2016.59",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27694664/",
      "mesh_terms": "Algorithms; Biomedical Technology; Cost-Benefit Analysis; Decision Making; Decision Support Techniques; Health Policy; Humans; Morals; Social Responsibility; Technology Assessment, Biomedical",
      "keywords": "Deliberation; Economic Evaluation; Equity; Extended Cost-Effectiveness; HTA Processes; Quality-Adjusted Life-Year (QALY) Algorithm; Reference Case",
      "pub_types": "Journal Article; Comment",
      "pmcid": "PMC4968254"
    },
    {
      "pmid": "38685924",
      "title": "Health equity assessment of machine learning performance (HEAL): a framework and dermatology AI model case study.",
      "abstract": "BACKGROUND: Artificial intelligence (AI) has repeatedly been shown to encode historical inequities in healthcare. We aimed to develop a framework to quantitatively assess the performance equity of health AI technologies and to illustrate its utility via a case study. METHODS: Here, we propose a methodology to assess whether health AI technologies prioritise performance for patient populations experiencing worse outcomes, that is complementary to existing fairness metrics. We developed the Health Equity Assessment of machine Learning performance (HEAL) framework designed to quantitatively assess the performance equity of health AI technologies via a four-step interdisciplinary process to understand and quantify domain-specific criteria, and the resulting HEAL metric. As an illustrative case study (analysis conducted between October 2022 and January 2023), we applied the HEAL framework to a dermatology AI model. A set of 5420 teledermatology cases (store-and-forward cases from patients of 20 years or older, submitted from primary care providers in the USA and skin cancer clinics in Australia), enriched for diversity in age, sex and race/ethnicity, was used to retrospectively evaluate the AI model's HEAL metric, defined as the likelihood that the AI model performs better for subpopulations with worse average health outcomes as compared to others. The likelihood that AI performance was anticorrelated to pre-existing health outcomes was estimated using bootstrap methods as the probability that the negated Spearman's rank correlation coefficient (i.e., \"R\") was greater than zero. Positive values of R suggest that subpopulations with poorer health outcomes have better AI model performance. Thus, the HEAL metric, defined as p (R\u00a0>0), measures how likely the AI technology is to prioritise performance for subpopulations with worse average health outcomes as compared to others (presented as a percentage below). Health outcomes were quantified as disability-adjusted life years (DALYs) when grouping by sex and age, and years of life lost (YLLs) when grouping by race/ethnicity. AI performance was measured as top-3 agreement with the reference diagnosis from a panel of 3 dermatologists per case. FINDINGS: Across all dermatologic conditions, the HEAL metric was 80.5% for prioritizing AI performance of racial/ethnic subpopulations based on YLLs, and 92.1% and 0.0% respectively for prioritizing AI performance of sex and age subpopulations based on DALYs. Certain dermatologic conditions were significantly associated with greater AI model performance compared to a reference category of less common conditions. For skin cancer conditions, the HEAL metric was 73.8% for prioritizing AI performance of age subpopulations based on DALYs. INTERPRETATION: Analysis using the proposed HEAL framework showed that the dermatology AI model prioritised performance for race/ethnicity, sex (all conditions) and age (cancer conditions) subpopulations with respect to pre-existing health disparities. More work is needed to investigate ways of promoting equitable AI performance across age for non-cancer conditions and to better understand how AI models can contribute towards improving equity in health outcomes. FUNDING: Google LLC.",
      "authors": "Schaekermann Mike; Spitz Terry; Pyles Malcolm; Cole-Lewis Heather; Wulczyn Ellery; Pfohl Stephen R; Martin Donald; Jaroensri Ronnachai; Keeling Geoff; Liu Yuan; Farquhar Stephanie; Xue Qinghan; Lester Jenna; Hughes C\u00edan; Strachan Patricia; Tan Fraser; Bui Peggy; Mermel Craig H; Peng Lily H; Matias Yossi; Corrado Greg S; Webster Dale R; Virmani Sunny; Semturs Christopher; Liu Yun; Horn Ivor; Cameron Chen Po-Hsuan",
      "year": "2024",
      "journal": "EClinicalMedicine",
      "doi": "10.1016/j.eclinm.2024.102479",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38685924/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Dermatology; Health equity; Machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11056401"
    },
    {
      "pmid": "32935131",
      "title": "Reporting of demographic data and representativeness in machine learning models using electronic health records.",
      "abstract": "OBJECTIVE: The development of machine learning (ML) algorithms to address a variety of issues faced in clinical practice has increased rapidly. However, questions have arisen regarding biases in their development that can affect their applicability in specific populations. We sought to evaluate whether studies developing ML models from electronic health record (EHR) data report sufficient demographic data on the study populations to demonstrate representativeness and reproducibility. MATERIALS AND METHODS: We searched PubMed for articles applying ML models to improve clinical decision-making using EHR data. We limited our search to papers published between 2015 and 2019. RESULTS: Across the 164 studies reviewed, demographic variables were inconsistently reported and/or included as model inputs. Race/ethnicity was not reported in 64%; gender and age were not reported in 24% and 21% of studies, respectively. Socioeconomic status of the population was not reported in 92% of studies. Studies that mentioned these variables often did not report if they were included as model inputs. Few models (12%) were validated using external populations. Few studies (17%) open-sourced their code. Populations in the ML studies include higher proportions of White and Black yet fewer Hispanic subjects compared to the general US population. DISCUSSION: The demographic characteristics of study populations are poorly reported in the ML literature based on EHR data. Demographic representativeness in training data and model transparency is necessary to ensure that ML models are deployed in an equitable and reproducible manner. Wider adoption of reporting guidelines is warranted to improve representativeness and reproducibility.",
      "authors": "Bozkurt Selen; Cahan Eli M; Seneviratne Martin G; Sun Ran; Lossio-Ventura Juan A; Ioannidis John P A; Hernandez-Boussard Tina",
      "year": "2020",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaa164",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32935131/",
      "mesh_terms": "Demography; Electronic Health Records; Ethnicity; Female; Humans; Machine Learning; Male; Nutrition Surveys; Socioeconomic Factors",
      "keywords": "clinical decision support, bias, transparency; demographic data; electronic health record; machine learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7727384"
    },
    {
      "pmid": "40927497",
      "title": "Beyond the Algorithm: A Perspective on Tackling Bias and Cultural Sensitivity in AI-Guided Aesthetic Standards for Cosmetic Surgery in the Middle East and North Africa (MENA) Region.",
      "abstract": "Artificial intelligence (AI) is increasingly reshaping cosmetic surgery by enhancing surgical planning, predicting outcomes, and enabling objective aesthetic assessment. Through narrative synthesis of existing literature and case studies, this perspective paper explores the issue of algorithmic bias in AI-powered aesthetic technologies and presents a framework for culturally sensitive application within cosmetic surgery practices in the Middle East and North Africa (MENA) region. Existing AI systems are predominantly trained on datasets that underrepresent MENA phenotypes, resulting in aesthetic recommendations that disproportionately reflect Western beauty ideals. The MENA region, however, encompasses a broad spectrum of beauty standards that merge traditional cultural aesthetics with modern global trends, posing unique challenges for AI integration. To ensure ethical and clinically relevant deployment, AI systems must undergo fundamental changes in algorithm design, including the incorporation of culturally diverse datasets with adequate MENA representation, implementation of cultural competency principles, and active collaboration with regional healthcare professionals. The framework outlines concrete criteria for evaluating cultural representativeness in AI training data and outcome assessments, supporting future empirical validation. Developing culturally aware AI tools is both a moral obligation and a clinical priority. This framework provides both a moral imperative and clinical pathway for ensuring AI serves to support, rather than homogenize, the region's diverse aesthetic traditions.",
      "authors": "Makhseed Abdulrahman; Arian Husain; Shuaib Ali",
      "year": "2025",
      "journal": "Clinical, cosmetic and investigational dermatology",
      "doi": "10.2147/CCID.S543045",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40927497/",
      "mesh_terms": "",
      "keywords": "MENA region; aesthetic medicine; algorithmic bias; artificial intelligence; cosmetic surgery; cultural competency; facial analysis; health equity; medical ethics",
      "pub_types": "Journal Article",
      "pmcid": "PMC12416507"
    },
    {
      "pmid": "39753967",
      "title": "Evaluating generalizability of oncology trial results to real-world patients using machine learning-based trial emulations.",
      "abstract": "Randomized controlled trials (RCTs) evaluating anti-cancer agents often lack generalizability to real-world oncology patients. Although restrictive eligibility criteria contribute to this issue, the role of selection bias related to prognostic risk remains unclear. In this study, we developed TrialTranslator, a framework designed to systematically evaluate the generalizability of RCTs for oncology therapies. Using a nationwide database of electronic health records from Flatiron Health, this framework emulates RCTs across three prognostic phenotypes identified through machine learning models. We applied this approach to 11 landmark RCTs that investigated anti-cancer regimens considered standard of care for the four most prevalent advanced solid malignancies. Our analyses reveal that patients in low-risk and medium-risk phenotypes exhibit survival times and treatment-associated survival benefits similar to those observed in RCTs. In contrast, high-risk phenotypes show significantly lower survival times and treatment-associated survival benefits compared to RCTs. Our results were corroborated by a comprehensive robustness assessment, including examinations of specific patient subgroups, holdout validation and semi-synthetic data simulation. These findings suggest that the prognostic heterogeneity among real-world oncology patients plays a substantial role in the limited generalizability of RCT results. Machine learning frameworks may facilitate individual patient-level decision support and estimation of real-world treatment benefits to guide trial design.",
      "authors": "Orcutt Xavier; Chen Kan; Mamtani Ronac; Long Qi; Parikh Ravi B",
      "year": "2025",
      "journal": "Nature medicine",
      "doi": "10.1038/s41591-024-03352-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39753967/",
      "mesh_terms": "Humans; Machine Learning; Neoplasms; Randomized Controlled Trials as Topic; Prognosis; Electronic Health Records; Female; Antineoplastic Agents; Male; Medical Oncology",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11835724"
    },
    {
      "pmid": "38240671",
      "title": "Disparities in the Demographic Composition of The Cancer Imaging Archive.",
      "abstract": "Purpose To characterize the demographic distribution of The Cancer Imaging Archive (TCIA) studies and compare them with those of the U.S. cancer population. Materials and Methods In this retrospective study, data from TCIA studies were examined for the inclusion of demographic information. Of 189 studies in TCIA up until April 2023, a total of 83 human cancer studies were found to contain supporting demographic data. The median patient age and the sex, race, and ethnicity proportions of each study were calculated and compared with those of the U.S. cancer population, provided by the Surveillance, Epidemiology, and End Results Program and the Centers for Disease Control and Prevention U.S. Cancer Statistics Data Visualizations Tool. Results The median age of TCIA patients was found to be 6.84 years lower than that of the U.S. cancer population (P = .047) and contained more female than male patients (53% vs 47%). American Indian and Alaska Native, Black or African American, and Hispanic patients were underrepresented in TCIA studies by 47.7%, 35.8%, and 14.7%, respectively, compared with the U.S. cancer population. Conclusion The results demonstrate that the patient demographics of TCIA data sets do not reflect those of the U.S. cancer population, which may decrease the generalizability of artificial intelligence radiology tools developed using these imaging data sets. Keywords: Ethics, Meta-Analysis, Health Disparities, Cancer Health Disparities, Machine Learning, Artificial Intelligence, Race, Ethnicity, Sex, Age, Bias Published under a CC BY 4.0 license.",
      "authors": "Dulaney Aidan; Virostko John",
      "year": "2024",
      "journal": "Radiology. Imaging cancer",
      "doi": "10.1148/rycan.230100",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38240671/",
      "mesh_terms": "Female; Humans; Male; Artificial Intelligence; Ethnicity; Neoplasms; Retrospective Studies; Racial Groups; Datasets as Topic",
      "keywords": "Age; Artificial Intelligence; Bias; Cancer Health Disparities; Ethics; Ethnicity; Health Disparities; Machine Learning; Meta-Analysis; Race; Sex",
      "pub_types": "Journal Article",
      "pmcid": "PMC10825717"
    },
    {
      "pmid": "32107061",
      "title": "'Should I vaccinate my child?' comparing the displayed stances of vaccine information retrieved from Google, Facebook and YouTube.",
      "abstract": "Whether to vaccinate or not is currently a hot topic in social discourse. Despite the majority view that childhood vaccination is safe and effective, websites and social media content opposing such vaccination are common. In this study, we searched the internet platforms Google, Facebook and YouTube for childhood vaccine information. We made every attempt to minimise selection bias generated by internet algorithms. We compared the displayed stances of vaccine information retrieved. Most of the information had a clearly stated stance on vaccines or made some sort of recommendation on whether or not to vaccinate. Despite our careful attempt to search comprehensively and systematically for vaccine information with as little bias as possible, this search yielded a sizeable minority of vaccine negative information. This research shows that negative vaccine information persists and is readily accessible online despite algorithm and policy changes in recent years, even when searching in the least biased way possible. It is important that vaccine-promoting entities and agencies continue to make every effort to maximize their presence online so that parents searching the internet to answer the question 'should I vaccinate my child?' continue to receive vaccine positive information.",
      "authors": "Elkin Lucy E; Pullon Susan R H; Stubbe Maria H",
      "year": "2020",
      "journal": "Vaccine",
      "doi": "10.1016/j.vaccine.2020.02.041",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32107061/",
      "mesh_terms": "Child; Humans; Information Dissemination; Information Seeking Behavior; Internet; Parents; Selection Bias; Social Media; Vaccination; Vaccines",
      "keywords": "Health communication; Internet; Public health; Social media; Vaccination; Vaccine criticism",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "38214974",
      "title": "Enhancing Health Equity by Predicting Missed Appointments in Health Care: Machine Learning Study.",
      "abstract": "BACKGROUND: The phenomenon of patients missing booked appointments without canceling them-known as Did Not Show (DNS), Did Not Attend (DNA), or Failed To Attend (FTA)-has a detrimental effect on patients' health and results in massive health care resource wastage. OBJECTIVE: Our objective was to develop machine learning (ML) models and evaluate their performance in predicting the likelihood of DNS for hospital outpatient appointments at the MidCentral District Health Board (MDHB) in New Zealand. METHODS: We sourced 5 years of MDHB outpatient records (a total of 1,080,566 outpatient visits) to build the ML prediction models. We developed 3 ML models using logistic regression, random forest, and Extreme Gradient Boosting (XGBoost). Subsequently, 10-fold cross-validation and hyperparameter tuning were deployed to minimize model bias and boost the algorithms' prediction strength. All models were evaluated against accuracy, sensitivity, specificity, and area under the receiver operating characteristic (AUROC) curve metrics. RESULTS: Based on 5 years of MDHB data, the best prediction classifier was XGBoost, with an area under the curve (AUC) of 0.92, sensitivity of 0.83, and specificity of 0.85. The patients' DNS history, age, ethnicity, and appointment lead time significantly contributed to DNS prediction. An ML system trained on a large data set can produce useful levels of DNS prediction. CONCLUSIONS: This research is one of the very first published studies that use ML technologies to assist with DNS management in New Zealand. It is a proof of concept and could be used to benchmark DNS predictions for the MDHB and other district health boards. We encourage conducting additional qualitative research to investigate the root cause of DNS issues and potential solutions. Addressing DNS using better strategies potentially can result in better utilization of health care resources and improve health equity.",
      "authors": "Yang Yi; Madanian Samaneh; Parry David",
      "year": "2024",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/48273",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38214974/",
      "mesh_terms": "",
      "keywords": "Did Not Attend; Did Not Show; appointment nonadherence; data analytics; decision support system; health care operation; health equity; machine learning; patients no-show; prediction; predictive modeling",
      "pub_types": "Journal Article",
      "pmcid": "PMC10818230"
    },
    {
      "pmid": "40206564",
      "title": "AI's ongoing impact: Implications of AI's effects on health equity for women's healthcare providers.",
      "abstract": "OBJECTIVE: To assess the effects of the current use of artificial intelligence (AI) in women's health on health equity, specifically in primary and secondary prevention efforts among women. METHODS: Two databases, Scopus and PubMed, were used to conduct this narrative review. The keywords included \"artificial intelligence,\" \"machine learning,\" \"women's health,\" \"screen,\" \"risk factor,\" and \"prevent,\" and papers were filtered only to include those about AI models that general practitioners may use. RESULTS: Of the 18 articles reviewed, 8 articles focused on risk factor modeling under primary prevention, and 10 articles focused on screening tools under secondary prevention. Gaps were found in the ability of AI models to train using large, diverse datasets that were reflective of the population it is intended for. Lack of these datasets was frequently identified as a limitation in the papers reviewed (n = 7). CONCLUSIONS: Minority, low-income women have poor access to health care and are, therefore, not well represented in the datasets AI uses to train, which risks introducing bias in its output. To mitigate this, more datasets should be developed to validate AI models, and AI in women's health should expand to include conditions that affect men and women to provide a gendered lens on these conditions. Public health, medical, and technology entities need to collaborate to regulate the development and use of AI in health care at a standard that reduces bias.",
      "authors": "Vadlamani Suman; Wachira Elizabeth",
      "year": "2025",
      "journal": "Revista panamericana de salud publica = Pan American journal of public health",
      "doi": "10.26633/RPSP.2025.19",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40206564/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; ethics; primary prevention; secondary prevention; women\u2019s health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11980523"
    },
    {
      "pmid": "40099281",
      "title": "In-Hospital Mortality Prediction among Intensive Care Unit Patients with Acute Ischemic Stroke: A Machine Learning Approach.",
      "abstract": "Background: Acute ischemic stroke is a leading cause of death in the United States. Identifying patients with stroke at high risk of mortality is crucial for timely intervention and optimal resource allocation. This study aims to develop and validate machine learning-based models to predict in-hospital mortality risk for intensive care unit (ICU) patients with acute ischemic stroke and identify important associated factors. Methods: Our data include 3,489 acute ischemic stroke admissions to the ICU for patients not discharged or dead within 48 h from the Medical Information Mart for Intensive Care-IV (MIMIC-IV) database. Demographic, hospitalization type, procedure, medication, intake (intravenous and oral), laboratory, vital signs, and clinical assessment [e.g., Glasgow Coma Scale Scores (GCS)] during the initial 48 h of admissions were used to predict in-hospital mortality after 48 h of ICU admission. We explored 3 machine learning models (random forests, logistic regression, and XGBoost) and applied Bayesian optimization for hyperparameter tuning. Important features were identified using learned coefficients. Results: Experiments show that XGBoost tuned for area under the receiver operating characteristic curve (AUC ROC) was the best performing model (AUC ROC 0.86, F1 0.52), compared to random forests (AUC ROC 0.85, F1 0.47) and logistic regression (AUC ROC 0.75, F1 0.40). Top features include GCS, blood urea nitrogen, and Richmond RASS score. The model also demonstrates good fairness for males versus females and across racial/ethnic groups. Conclusions: Machine learning has shown great potential in predicting in-hospital mortality risk for people with acute ischemic stroke in the ICU setting. However, more ethical considerations need to be applied to ensure that performance differences across different racial/ethnic groups will not exacerbate existing health disparities and will not harm historically marginalized populations.",
      "authors": "Cummins Jack A; Gerber Ben S; Fukunaga Mayuko Ito; Henninger Nils; Kiefe Catarina I; Liu Feifan",
      "year": "2025",
      "journal": "Health data science",
      "doi": "10.34133/hds.0179",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40099281/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11912875"
    },
    {
      "pmid": "35511151",
      "title": "An objective framework for evaluating unrecognized bias in medical AI models predicting COVID-19 outcomes.",
      "abstract": "OBJECTIVE: The increasing translation of artificial intelligence (AI)/machine learning (ML) models into clinical practice brings an increased risk of direct harm from modeling bias; however, bias remains incompletely measured in many medical AI applications. This article aims to provide a framework for objective evaluation of medical AI from multiple aspects, focusing on binary classification models. MATERIALS AND METHODS: Using data from over 56\u00a0000 Mass General Brigham (MGB) patients with confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), we evaluate unrecognized bias in 4 AI models developed during the early months of the pandemic in Boston, Massachusetts that predict risks of hospital admission, ICU admission, mechanical ventilation, and death after a SARS-CoV-2 infection purely based on their pre-infection longitudinal medical records. Models were evaluated both retrospectively and prospectively using model-level metrics of discrimination, accuracy, and reliability, and a novel individual-level metric for error. RESULTS: We found inconsistent instances of model-level bias in the prediction models. From an individual-level aspect, however, we found most all models performing with slightly higher error rates for older patients. DISCUSSION: While a model can be biased against certain protected groups (ie, perform worse) in certain tasks, it can be at the same time biased towards another protected group (ie, perform better). As such, current bias evaluation studies may lack a full depiction of the variable effects of a model on its subpopulations. CONCLUSION: Only a holistic evaluation, a diligent search for unrecognized bias, can provide enough information for an unbiased judgment of AI bias that can invigorate follow-up investigations on identifying the underlying roots of bias and ultimately make a change.",
      "authors": "Estiri Hossein; Strasser Zachary H; Rashidian Sina; Klann Jeffrey G; Wagholikar Kavishwar B; McCoy Thomas H; Murphy Shawn N",
      "year": "2022",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocac070",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35511151/",
      "mesh_terms": "Artificial Intelligence; COVID-19; Humans; Reproducibility of Results; Retrospective Studies; SARS-CoV-2",
      "keywords": "COVID-19; bias; electronic health records; medical AI; predictive model",
      "pub_types": "Journal Article",
      "pmcid": "PMC9277645"
    },
    {
      "pmid": "31665002",
      "title": "Key challenges for delivering clinical impact with artificial intelligence.",
      "abstract": "BACKGROUND: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. MAIN BODY: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. CONCLUSION: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.",
      "authors": "Kelly Christopher J; Karthikesalingam Alan; Suleyman Mustafa; Corrado Greg; King Dominic",
      "year": "2019",
      "journal": "BMC medicine",
      "doi": "10.1186/s12916-019-1426-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31665002/",
      "mesh_terms": "Algorithms; Artificial Intelligence; Delivery of Health Care; Humans; Peer Review",
      "keywords": "Algorithms; Artificial intelligence; Evaluation; Machine learning; Regulation; Translation",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6821018"
    },
    {
      "pmid": "29895513",
      "title": "Mobile Phone Cognitive Bias Modification Research Platform for Substance Use Disorders: Protocol for a Feasibility Study.",
      "abstract": "BACKGROUND: Cognitive biases refer to automatic attentional and interpretational tendencies, which could be retained by cognitive bias modification interventions. Cristea et al and Jones et al have published reviews (in 2016 and 2017 respectively) on the effectiveness of such interventions. The advancement of technologies such as electronic health (eHealth) and mobile health (mHealth) has led to them being harnessed for the delivery of cognitive bias modification. To date, at least eight studies have demonstrated the feasibility of mobile technologies for the delivery of cognitive bias modification. Most of the studies are limited to a description of the conventional cognitive bias modification methodology that has been adopted. None of the studies shared the developmental process for the methodology involved, such that future studies could adopt it in the cost-effective replication of such interventions. OBJECTIVE: It is important to have a common platform that could facilitate the design and customization of cognitive bias modification interventions for a variety of psychiatric and addictive disorders. It is the aim of the current research protocol to describe the design of a research platform that allows for customization of cognitive bias modification interventions for addictive disorders. METHODS: A multidisciplinary team of 2 addiction psychiatrists, a psychologist with expertise in cognitive bias modification, and a computer engineer, were involved in the development of the intervention. The proposed platform would comprise of a mobile phone version of the cognitive bias task which is controlled by a server that could customize the algorithm for the tasks and collate the reaction-time data in realtime. The server would also allow the researcher to program the specific set of images that will be present in the task. The mobile phone app would synchronize with the backend server in real-time. An open-sourced cross-platform gaming software from React Native was used in the current development. RESULTS: Multimedia Appendix 1 contains a video demonstrating the operation of the app, as well as a sample dataset of the reaction times (used for the computation of attentional biases) captured by the app. CONCLUSIONS: The current design can be utilized for cognitive bias modification across a spectrum of disorders and is not limited to one disorder. It will be of value for future research to utilize the above platform and compare the efficacy of mHealth approaches, such as the one described in this study, with conventional Web-based approaches in the delivery of attentional bias modification interventions. REGISTERED REPORT IDENTIFIER: RR1-10.2196/9740.",
      "authors": "Zhang Melvyn; Ying JiangBo; Song Guo; Fung Daniel Ss; Smith Helen",
      "year": "2018",
      "journal": "JMIR research protocols",
      "doi": "10.2196/resprot.9740",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29895513/",
      "mesh_terms": "",
      "keywords": "attention bias modification; development; eHealth; mHealth",
      "pub_types": "Journal Article",
      "pmcid": "PMC6019844"
    },
    {
      "pmid": "39747461",
      "title": "Predicting pediatric patient rehabilitation outcomes after spinal deformity surgery with artificial intelligence.",
      "abstract": "BACKGROUND: Adolescent idiopathic scoliosis (AIS) is the most common type of scoliosis, affecting 1-4% of adolescents. The Scoliosis Research Society-22R (SRS-22R), a health-related quality-of-life instrument for AIS, has allowed orthopedists to measure subjective patient outcomes before and after corrective surgery beyond objective radiographic measurements. However, research has revealed that there is no significant correlation between the correction rate in major radiographic parameters and improvements in patient-reported outcomes (PROs), making it difficult to incorporate PROs into personalized surgical planning. METHODS: The objective of this study is to develop an artificial intelligence (AI)-enabled surgical planning and counseling support system for post-operative patient rehabilitation outcomes prediction in order to facilitate personalized AIS patient care. A unique multi-site cohort of 455 pediatric patients undergoing spinal fusion surgery at two Shriners Children's hospitals from 2010 is investigated in our analysis. In total, 171 pre-operative clinical features are used to train six machine-learning models for post-operative outcomes prediction. We further employ explainability analysis to quantify the contribution of pre-operative radiographic and questionnaire parameters in predicting patient surgical outcomes. Moreover, we enable responsible AI by calibrating model confidence for human intervention and mitigating health disparities for algorithm fairness. RESULTS: The best prediction model achieves an area under receiver operating curve (AUROC) performance of 0.86, 0.85, and 0.83 for individual SRS-22R question response prediction over three-time horizons from pre-operation to 6-month, 1-year, and 2-year post-operation, respectively. Additionally, we demonstrate the efficacy of our proposed prediction method to predict other patient rehabilitation outcomes based on minimal clinically important differences (MCID) and correction rates across all three-time horizons. CONCLUSIONS: Based on the relationship analysis, we suggest additional attention to sagittal parameters (e.g., lordosis, sagittal vertical axis) and patient self-image beyond major Cobb angles to improve surgical decision-making for AIS patients. In the age of personalized medicine, the proposed responsible AI-enabled clinical decision-support system may facilitate pre-operative counseling and shared decision-making within real-world clinical settings.",
      "authors": "Shi Wenqi; Giuste Felipe O; Zhu Yuanda; Tamo Ben J; Nnamdi Micky C; Hornback Andrew; Carpenter Ashley M; Hilton Coleman; Iwinski Henry J; Wattenbarger J Michael; Wang May D",
      "year": "2025",
      "journal": "Communications medicine",
      "doi": "10.1038/s43856-024-00726-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39747461/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11697361"
    },
    {
      "pmid": "39701480",
      "title": "The misclassification of depression and anxiety disorders in the multiple sclerosis prodrome: A probabilistic bias analysis.",
      "abstract": "BACKGROUND: Studies suggest that depression/anxiety form part of the multiple sclerosis (MS) prodrome. However, several biases have not been addressed. We re-examined this association after correcting for: (i) misclassification of individuals not seeking healthcare, (ii) differential surveillance of depression/anxiety in the health system, and (iii) misclassified person-time from using the date of the first MS-related diagnostic claim (i.e., a demyelinating event) as a proxy for MS onset. METHODS: In this cohort study, we applied a validated algorithm to health administrative ('claims') data in British Columbia, Canada (1991-2020) to identify MS cases, and matched to general population controls. The neurologist-recorded date of MS symptom onset was available for a subset of the MS cases. We identified depression/anxiety in the 5-years preceding the first demyelinating claim using a validated algorithm. We compared the prevalence of depression/anxiety using modified Poisson regression. To account for misclassification and differential surveillance, we applied probabilistic bias analyses; for misclassified person-time, we applied time-distribution matching to the MS symptom onset date. RESULTS: Our cohort included 9929 MS cases and 49,574 controls. The prevalence ratio for depression/anxiety was 1.74 (95\u202f%CI: 1.66-1.81). Following correction for misclassification, differential surveillance using a detection ratio of 1.11, and misclassified person-time, the prevalence ratio increased to 3.25 (95\u202f%CI: 1.98-40.54). When the same correction was conducted, but a detection ratio of 1.16 was applied, the prevalence ratio increased to 3.13 (95\u202f%CI: 1.97-33.52). CONCLUSIONS: Previous conventional analyses were biased towards the null, leading to an under-estimation of the association between depression/anxiety and MS in the prodromal period. This first application of probabilistic quantitative bias analysis within MS research demonstrates both its feasibility and utility.",
      "authors": "Yusuf Fardowsa L A; Karim Mohammad Ehsanul; Gustafson Paul; Sutherland Jason M; Zhu Feng; Zhao Yinshan; Marrie Ruth Ann; Tremlett Helen",
      "year": "2025",
      "journal": "Annals of epidemiology",
      "doi": "10.1016/j.annepidem.2024.12.006",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39701480/",
      "mesh_terms": "Humans; Multiple Sclerosis; Female; Male; Adult; Middle Aged; Anxiety Disorders; British Columbia; Prevalence; Depression; Bias; Cohort Studies; Prodromal Symptoms; Algorithms",
      "keywords": "Health care utilization; Misclassification; Multiple sclerosis; Prodrome",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41397987",
      "title": "Development and validation of a simplified time-dependent interpretable machine learning-based survival model for older adults with multimorbidity.",
      "abstract": "Multimorbidity elevates late-life mortality, yet existing tools remain complex. Using two nationally representative Chinese cohorts-the Chinese Longitudinal Healthy Longevity and Happiness Family Study (CLHLS-HF; n\u2009=\u20098675) and the China Health and Retirement Longitudinal Study (CHARLS, n\u2009=\u20094171)-we developed and externally validated a simplified, time-dependent, interpretable survival model. A four-stage feature-selection pipeline (univariate Cox, L1-penalized Cox, multi-model importance with 100 bootstraps, and cumulative performance) identified four routinely available predictors: age, BMI, and cooking and toileting abilities. Among five algorithms, a parsimonious Cox model performed best (C-index 0.7524 internal; 0.7104 external) with a favorable time-Brier Score (0.1417; 0.1157), good calibration, decision-curve net benefit, and subgroup fairness. Time-dependent permutation importance confirmed age as dominant, toileting ability as short-term, and cooking ability as mid- to long-term contributors, while BMI showed modest, stable effects. Implemented as the M-SAGE online tool, this four-item model enables rapid, interpretable mortality risk stratification and supports individualized interventions for older adults with multimorbidity.",
      "authors": "Zhu Junmin; Chen Huanglong; Duan Siyu; Wu Yafei; Fang Ya",
      "year": "2025",
      "journal": "npj aging",
      "doi": "10.1038/s41514-025-00308-y",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41397987/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12816092"
    },
    {
      "pmid": "36101652",
      "title": "Validity of a Computational Linguistics-Derived Automated Health Literacy Measure Across Race/Ethnicity: Findings from The ECLIPPSE Project.",
      "abstract": "Limited health literacy (HL) partially mediates health disparities. Measurement constraints, including lack of validity assessment across racial/ethnic groups and administration challenges, have undermined the field and impeded scaling of HL interventions. We employed computational linguistics to develop an automated and novel HL measure, analyzing >300,000 messages sent by >9,000 diabetes patients via a patient portal to create a Literacy Profiles. We carried out stratified analyses among White/non-Hispanics, Black/non-Hispanics, Hispanics, and Asian/Pacific Islanders to determine if the Literacy Profile has comparable criterion and predictive validities. We discovered that criterion validity was consistently high across all groups (c-statistics 0.82-0.89). We observed consistent relationships across racial/ethnic groups between HL and outcomes, including communication, adherence, hypoglycemia, diabetes control, and ED utilization. While concerns have arisen regarding bias in AI, the automated Literacy Profile appears sufficiently valid across race/ethnicity, enabling HL measurement at a scale that could improve clinical care and population health among diverse populations.",
      "authors": "Schillinger Dean; Balyan Renu; Crossley Scott; McNamara Danielle; Karter Andrew",
      "year": "2021",
      "journal": "Journal of health care for the poor and underserved",
      "doi": "10.1353/hpu.2021.0067",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36101652/",
      "mesh_terms": "Diabetes Mellitus; Ethnicity; Health Literacy; Humans; Linguistics; Racial Groups",
      "keywords": "Health literacy; artificial intelligence; communication; computational linguistics; diabetes; health disparities; machine learning; validation study",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9467454"
    },
    {
      "pmid": "39803613",
      "title": "Validation, bias assessment, and optimization of the UNAFIED 2-year risk prediction model for undiagnosed atrial fibrillation using national electronic health data.",
      "abstract": "BACKGROUND: Prediction models for atrial fibrillation (AF) may enable earlier detection and guideline-directed treatment decisions. However, model bias may lead to inaccurate predictions and unintended consequences. OBJECTIVE: The purpose of this study was to validate, assess bias, and improve generalizability of \"UNAFIED-10,\" a 2-year, 10-variable predictive model of undiagnosed AF in a national data set (originally developed using the Indiana Network for Patient Care regional data). METHODS: UNAFIED-10 was validated and optimized using Optum de-identified electronic health record data set. AF diagnoses were recorded in the January 2018-December 2019 period (outcome period), with January 2016-December 2017 as the baseline period. Validation cohorts (patients with AF and non-AF controls, aged \u226540 years) comprised the full imbalanced and randomly sampled balanced data sets. Model performance and bias in patient subpopulations based on sex, insurance, race, and region were evaluated. RESULTS: Of the 6,058,657 eligible patients (mean age 60 \u00b1 12 years), 4.1% (n = 246,975) had their first AF diagnosis within the outcome period. The validated UNAFIED-10 model achieved a higher C-statistic (0.85 [95% confidence interval 0.85-0.86] vs 0.81 [0.80-0.81]) and sensitivity (86% vs 74%) but lower specificity (66% vs 74%) than the original UNAFIED-10 model. During retraining and optimization, the variables insurance, shock, and albumin were excluded to address bias and improve generalizability. This generated an 8-variable model (UNAFIED-8) with consistent performance. CONCLUSION: UNAFIED-10, developed using regional patient data, displayed consistent performance in a large national data set. UNAFIED-8 is more parsimonious and generalizable for using advanced analytics for AF detection. Future directions include validation on additional data sets.",
      "authors": "Ateya Mohammad; Aristeridou Danai; Sands George H; Zielinski Jessica; Grout Randall W; Colavecchia A Carmine; Wazni Oussama; Haque Saira N",
      "year": "2024",
      "journal": "Heart rhythm O2",
      "doi": "10.1016/j.hroo.2024.09.010",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39803613/",
      "mesh_terms": "",
      "keywords": "Atrial fibrillation; Electronic health record; Machine learning; Predictive model; Screening",
      "pub_types": "Journal Article",
      "pmcid": "PMC11721729"
    },
    {
      "pmid": "37566454",
      "title": "Ethical Considerations of Using ChatGPT in Health Care.",
      "abstract": "ChatGPT has promising applications in health care, but potential ethical issues need to be addressed proactively to prevent harm. ChatGPT presents potential ethical challenges from legal, humanistic, algorithmic, and informational perspectives. Legal ethics concerns arise from the unclear allocation of responsibility when patient harm occurs and from potential breaches of patient privacy due to data collection. Clear rules and legal boundaries are needed to properly allocate liability and protect users. Humanistic ethics concerns arise from the potential disruption of the physician-patient relationship, humanistic care, and issues of integrity. Overreliance on artificial intelligence (AI) can undermine compassion and erode trust. Transparency and disclosure of AI-generated content are critical to maintaining integrity. Algorithmic ethics raise concerns about algorithmic bias, responsibility, transparency and explainability, as well as validation and evaluation. Information ethics include data bias, validity, and effectiveness. Biased training data can lead to biased output, and overreliance on ChatGPT can reduce patient adherence and encourage self-diagnosis. Ensuring the accuracy, reliability, and validity of ChatGPT-generated content requires rigorous validation and ongoing updates based on clinical practice. To navigate the evolving ethical landscape of AI, AI in health care must adhere to the strictest ethical standards. Through comprehensive ethical guidelines, health care professionals can ensure the responsible use of ChatGPT, promote accurate and reliable information exchange, protect patient privacy, and empower patients to make informed decisions about their health care.",
      "authors": "Wang Changyu; Liu Siru; Yang Hao; Guo Jiulin; Wu Yuxuan; Liu Jialin",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/48009",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37566454/",
      "mesh_terms": "Humans; Artificial Intelligence; Reproducibility of Results; Data Collection; Disclosure; Patient Compliance",
      "keywords": "AI; ChatGPT; algorithm; artificial intelligence; artificial intelligence development; development; ethics; health care; large language models; patient privacy; patient safety; privacy; safety",
      "pub_types": "Journal Article",
      "pmcid": "PMC10457697"
    },
    {
      "pmid": "36465087",
      "title": "Personalised depression forecasting using mobile sensor data and ecological momentary assessment.",
      "abstract": "INTRODUCTION: Digital health interventions are an effective way to treat depression, but it is still largely unclear how patients' individual symptoms evolve dynamically during such treatments. Data-driven forecasts of depressive symptoms would allow to greatly improve the personalisation of treatments. In current forecasting approaches, models are often trained on an entire population, resulting in a general model that works overall, but does not translate well to each individual in clinically heterogeneous, real-world populations. Model fairness across patient subgroups is also frequently overlooked. Personalised models tailored to the individual patient may therefore be promising. METHODS: We investigate different personalisation strategies using transfer learning, subgroup models, as well as subject-dependent standardisation on a newly-collected, longitudinal dataset of depression patients undergoing treatment with a digital intervention ( N = 65 patients recruited). Both passive mobile sensor data as well as ecological momentary assessments were available for modelling. We evaluated the models' ability to predict symptoms of depression (Patient Health Questionnaire-2; PHQ-2) at the end of each day, and to forecast symptoms of the next day. RESULTS: In our experiments, we achieve a best mean-absolute-error (MAE) of 0.801 (25% improvement) for predicting PHQ-2 values at the end of the day with subject-dependent standardisation compared to a non-personalised baseline ( MAE = 1.062 ). For one day ahead-forecasting, we can improve the baseline of 1.539 by 12 % to a MAE of 1.349 using a transfer learning approach with shared common layers. In addition, personalisation leads to fairer models at group-level. DISCUSSION: Our results suggest that personalisation using subject-dependent standardisation and transfer learning can improve predictions and forecasts, respectively, of depressive symptoms in participants of a digital depression intervention. We discuss technical and clinical limitations of this approach, avenues for future investigations, and how personalised machine learning architectures may be implemented to improve existing digital interventions for depression.",
      "authors": "Kathan Alexander; Harrer Mathias; K\u00fcster Ludwig; Triantafyllopoulos Andreas; He Xiangheng; Milling Manuel; Gerczuk Maurice; Yan Tianhao; Rajamani Srividya Tirunellai; Heber Elena; Grossmann Inga; Ebert David D; Schuller Bj\u00f6rn W",
      "year": "2022",
      "journal": "Frontiers in digital health",
      "doi": "10.3389/fdgth.2022.964582",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36465087/",
      "mesh_terms": "",
      "keywords": "depression; forecasting; mHealth; machine learning; mental illness; personalised models",
      "pub_types": "Journal Article",
      "pmcid": "PMC9715619"
    },
    {
      "pmid": "39312289",
      "title": "Evaluating the Bias in Hospital Data: Automatic Preprocessing of Patient Pathways Algorithm Development and Validation Study.",
      "abstract": "BACKGROUND: The optimization of patient care pathways is crucial for hospital managers in the context of a scarcity of medical resources. Assuming unlimited capacities, the pathway of a patient would only be governed by pure medical logic to meet at best the patient's needs. However, logistical limitations (eg, resources such as inpatient beds) are often associated with delayed treatments and may ultimately affect patient pathways. This is especially true for unscheduled patients-when a patient in the emergency department needs to be admitted to another medical unit without disturbing the flow of planned hospitalizations. OBJECTIVE: In this study, we proposed a new framework to automatically detect activities in patient pathways that may be unrelated to patients' needs but rather induced by logistical limitations. METHODS: The scientific contribution lies in a method that transforms a database of historical pathways with bias into 2 databases: a labeled pathway database where each activity is labeled as relevant (related to a patient's needs) or irrelevant (induced by logistical limitations) and a corrected pathway database where each activity corresponds to the activity that would occur assuming unlimited resources. The labeling algorithm was assessed through medical expertise. In total, 2 case studies quantified the impact of our method of preprocessing health care data using process mining and discrete event simulation. RESULTS: Focusing on unscheduled patient pathways, we collected data covering 12 months of activity at the Groupe Hospitalier Bretagne Sud in France. Our algorithm had 87% accuracy and demonstrated its usefulness for preprocessing traces and obtaining a clean database. The 2 case studies showed the importance of our preprocessing step before any analysis. The process graphs of the processed data had, on average, 40% (SD 10%) fewer variants than the raw data. The simulation revealed that 30% of the medical units had >1 bed difference in capacity between the processed and raw data. CONCLUSIONS: Patient pathway data reflect the actual activity of hospitals that is governed by medical requirements and logistical limitations. Before using these data, these limitations should be identified and corrected. We anticipate that our approach can be generalized to obtain unbiased analyses of patient pathways for other hospitals.",
      "authors": "Uhl Laura; Augusto Vincent; Dalmas Benjamin; Alexandre Youenn; Bercelli Paolo; Jardinaud Fanny; Aloui Saber",
      "year": "2024",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/58978",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39312289/",
      "mesh_terms": "Humans; Algorithms; Critical Pathways; Data Mining; Bias; Emergency Service, Hospital; Databases, Factual",
      "keywords": "bed management; framework; health care data; patient pathway; preprocessing",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC11459108"
    },
    {
      "pmid": "40072927",
      "title": "Data Obfuscation Through Latent Space Projection for Privacy-Preserving AI Governance: Case Studies in Medical Diagnosis and Finance Fraud Detection.",
      "abstract": "BACKGROUND: The increasing integration of artificial intelligence (AI) systems into critical societal sectors has created an urgent demand for robust privacy-preserving methods. Traditional approaches such as differential privacy and homomorphic encryption often struggle to maintain an effective balance between protecting sensitive information and preserving data utility for AI applications. This challenge has become particularly acute as organizations must comply with evolving AI governance frameworks while maintaining the effectiveness of their AI systems. OBJECTIVE: This paper aims to introduce and validate data obfuscation through latent space projection (LSP), a novel privacy-preserving technique designed to enhance AI governance and ensure responsible AI compliance. The primary goal is to develop a method that can effectively protect sensitive data while maintaining essential features necessary for AI model training and inference, thereby addressing the limitations of existing privacy-preserving approaches. METHODS: We developed LSP using a combination of advanced machine learning techniques, specifically leveraging autoencoder architectures and adversarial training. The method projects sensitive data into a lower-dimensional latent space, where it separates sensitive from nonsensitive information. This separation enables precise control over privacy-utility trade-offs. We validated LSP through comprehensive experiments on benchmark datasets and implemented 2 real-world case studies: a health care application focusing on cancer diagnosis and a financial services application analyzing fraud detection. RESULTS: LSP demonstrated superior performance across multiple evaluation metrics. In image classification tasks, the method achieved 98.7% accuracy while maintaining strong privacy protection, providing 97.3% effectiveness against sensitive attribute inference attacks. This performance significantly exceeded that of traditional anonymization and privacy-preserving methods. The real-world case studies further validated LSP's effectiveness, showing robust performance in both health care and financial applications. Additionally, LSP demonstrated strong alignment with global AI governance frameworks, including the General Data Protection Regulation, the California Consumer Privacy Act, and the Health Insurance Portability and Accountability Act. CONCLUSIONS: LSP represents a significant advancement in privacy-preserving AI, offering a promising approach to developing AI systems that respect individual privacy while delivering valuable insights. By embedding privacy protection directly within the machine learning pipeline, LSP contributes to key principles of fairness, transparency, and accountability. Future research directions include developing theoretical privacy guarantees, exploring integration with federated learning systems, and enhancing latent space interpretability. These developments position LSP as a crucial tool for advancing ethical AI practices and ensuring responsible technology deployment in privacy-sensitive domains.",
      "authors": "Vaijainthymala Krishnamoorthy Mahesh",
      "year": "2025",
      "journal": "JMIRx med",
      "doi": "10.2196/70100",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40072927/",
      "mesh_terms": "",
      "keywords": "AI governance; GDPR; General Data Protection Regulation; HIPAA; Health Insurance Portability and Accountability Act; artificial intelligence; compliance; data obfuscation; data utility; differential privacy; k-anonymity; latent space projection; machine learning privacy; medical imaging privacy; privacy-preserving AI; privacy-utility trade-off; responsible AI; secure data sharing",
      "pub_types": "Journal Article",
      "pmcid": "PMC11922095"
    },
    {
      "pmid": "39625723",
      "title": "Evaluating Bias-Mitigated Predictive Models of Perinatal Mood and Anxiety Disorders.",
      "abstract": "IMPORTANCE: Machine learning for augmented screening of perinatal mood and anxiety disorders (PMADs) requires thorough consideration of clinical biases embedded in electronic health records (EHRs) and rigorous evaluations of model performance. OBJECTIVE: To mitigate bias in predictive models of PMADs trained on commonly available EHRs. DESIGN, SETTING, AND PARTICIPANTS: This diagnostic study collected data as part of a quality improvement initiative from 2020 to 2023 at Cedars-Sinai Medical Center in Los Angeles, California. The study inclusion criteria were birthing patients aged 14 to 59 years with live birth records and admission to the postpartum unit or the maternal-fetal care unit after delivery. EXPOSURE: Patient-reported race and ethnicity (7 levels) obtained through EHRs. MAIN OUTCOMES AND MEASURES: Logistic regression, random forest, and extreme gradient boosting models were trained to predict 2 binary outcomes: moderate to high-risk (positive) screen assessed using the 9-item Patient Health Questionnaire (PHQ-9), and the Edinburgh Postnatal Depression Scale (EPDS). Each model was fitted with or without reweighing data during preprocessing and evaluated through repeated K-fold cross validation. In every iteration, each model was evaluated on its area under the receiver operating curve (AUROC) and on 2 fairness metrics: demographic parity (DP), and difference in false negatives between races and ethnicities (relative to non-Hispanic White patients). RESULTS: Among 19\u202f430 patients in this study, 1402 (7%) identified as African American or Black, 2371 (12%) as Asian American and Pacific Islander; 1842 (10%) as Hispanic White, 10\u202f942 (56.3%) as non-Hispanic White, 606 (3%) as multiple races, 2146 (11%) as other (not further specified), and 121 (<1%) did not provide this information. The mean (SD) age was 34.1 (4.9) years, and all patients identified as female. Racial and ethnic minority patients were significantly more likely than non-Hispanic White patients to screen positive on both the PHQ-9 (odds ratio, 1.47 [95% CI, 1.23-1.77]) and the EPDS (odds ratio, 1.38 [95% CI, 1.20-1.57]). Mean AUROCs ranged from 0.610 to 0.635 without reweighing (baseline), and from 0.602 to 0.622 with reweighing. Baseline models predicted significantly greater prevalence of postpartum depression for patients who were not non-Hispanic White relative to those who were (mean DP, 0.238 [95% CI, 0.231-0.244]; P\u2009<\u2009.001) and displayed significantly lower false-negative rates (mean difference, -0.184 [95% CI, -0.195 to -0.174]; P\u2009<\u2009.001). Reweighing significantly reduced differences in DP (mean DP with reweighing, 0.022 [95% CI, 0.017-0.026]; P\u2009<\u2009.001) and false-negative rates (mean difference with reweighing, 0.018 [95% CI, 0.008-0.028]; P\u2009<\u2009.001) between racial and ethnic groups. CONCLUSIONS AND RELEVANCE: In this diagnostic study of predictive models of postpartum depression, clinical prediction models trained to predict psychometric screening results from commonly available EHRs achieved modest performance and were less likely to widen existing health disparities in PMAD diagnosis and potentially treatment. These findings suggest that is critical for researchers and physicians to consider their model design (eg, desired target and predictor variables) and evaluate model bias to minimize health disparities.",
      "authors": "Wong Emily F; Saini Anil K; Accortt Eynav E; Wong Melissa S; Moore Jason H; Bright Tiffani J",
      "year": "2024",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2024.38152",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39625723/",
      "mesh_terms": "Humans; Female; Adult; Pregnancy; Anxiety Disorders; Mood Disorders; Adolescent; Young Adult; Electronic Health Records; Machine Learning; Bias; Pregnancy Complications; Middle Aged; Logistic Models",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11615713"
    },
    {
      "pmid": "38501988",
      "title": "Identification of group differences in predictive anticipatory biasing of pain during uncertainty: preparing for the worst but hoping for the best.",
      "abstract": "Pain anticipation during conditions of uncertainty can unveil intrinsic biases, and understanding these biases can guide pain treatment interventions. This study used machine learning and functional magnetic resonance imaging to predict anticipatory responses in a pain anticipation experiment. One hundred forty-seven participants that included healthy controls (n = 57) and individuals with current and/or past mental health diagnosis (n = 90) received cues indicating upcoming pain stimuli: 2 cues predicted high and low temperatures, while a third cue introduced uncertainty. Accurate differentiation of neural patterns associated with specific anticipatory conditions was observed, involving activation in the anterior short gyrus of the insula and the nucleus accumbens. Three distinct response profiles emerged: subjects with a negative bias towards high pain anticipation, those with a positive bias towards low pain anticipation, and individuals whose predictions during uncertainty were unbiased. These profiles remained stable over one year, were consistent across diagnosed psychopathologies, and correlated with cognitive coping styles and underlying insula anatomy. The findings suggest that individualized and stable pain anticipation occurs in uncertain conditions.",
      "authors": "Strigo Irina A; Kadlec Molly; Mitchell Jennifer M; Simmons Alan N",
      "year": "2024",
      "journal": "Pain",
      "doi": "10.1097/j.pain.0000000000003207",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38501988/",
      "mesh_terms": "Humans; Uncertainty; Male; Female; Adult; Magnetic Resonance Imaging; Anticipation, Psychological; Pain; Young Adult; Middle Aged; Machine Learning; Brain Mapping; Cues; Pain Measurement",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11247452"
    },
    {
      "pmid": "38026836",
      "title": "Your robot therapist is not your therapist: understanding the role of AI-powered mental health chatbots.",
      "abstract": "Artificial intelligence (AI)-powered chatbots have the potential to substantially increase access to affordable and effective mental health services by supplementing the work of clinicians. Their 24/7 availability and accessibility through a mobile phone allow individuals to obtain help whenever and wherever needed, overcoming financial and logistical barriers. Although psychological AI chatbots have the ability to make significant improvements in providing mental health care services, they do not come without ethical and technical challenges. Some major concerns include providing inadequate or harmful support, exploiting vulnerable populations, and potentially producing discriminatory advice due to algorithmic bias. However, it is not always obvious for users to fully understand the nature of the relationship they have with chatbots. There can be significant misunderstandings about the exact purpose of the chatbot, particularly in terms of care expectations, ability to adapt to the particularities of users and responsiveness in terms of the needs and resources/treatments that can be offered. Hence, it is imperative that users are aware of the limited therapeutic relationship they can enjoy when interacting with mental health chatbots. Ignorance or misunderstanding of such limitations or of the role of psychological AI chatbots may lead to a therapeutic misconception (TM) where the user would underestimate the restrictions of such technologies and overestimate their ability to provide actual therapeutic support and guidance. TM raises major ethical concerns that can exacerbate one's mental health contributing to the global mental health crisis. This paper will explore the various ways in which TM can occur particularly through inaccurate marketing of these chatbots, forming a digital therapeutic alliance with them, receiving harmful advice due to bias in the design and algorithm, and the chatbots inability to foster autonomy with patients.",
      "authors": "Khawaja Zoha; B\u00e9lisle-Pipon Jean-Christophe",
      "year": "2023",
      "journal": "Frontiers in digital health",
      "doi": "10.3389/fdgth.2023.1278186",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38026836/",
      "mesh_terms": "",
      "keywords": "AI ethics; artificial intelligence; chatbot; mental health services; therapeutic misconception",
      "pub_types": "Journal Article",
      "pmcid": "PMC10663264"
    },
    {
      "pmid": "40895087",
      "title": "Improving the FAIRness and Sustainability of the NHGRI Resources Ecosystem.",
      "abstract": "In 2024, individuals funded by NHGRI to support genomic community resources completed a Self-Assessment Tool (SAT) to evaluate their application of the FAIR (Findable, Accessible, Interoperable, and Reusable) principles and assess their sustainability. By collecting insights from the self-administered questionnaires and conducting personal interviews, a valuable perspective was gained on the FAIRness and sustainability of the NHGRI resources. The results highlighted several challenges and key areas the NHGRI resource community could improve by working together to form recommendations to address these challenges. The next step was the formation of an Organizing Committee to identify which challenges could lead to best practices or guidelines for the community. The workshop's Organizing Committee comprised four members from the NHGRI resource community: Carol Bult, PhD, Chris Mungall, PhD, Heidi Rehm, PhD, and Michael Schatz, PhD. In December 2024, the Organizing Committee engaged with the NHGRI resource community to refine these challenges further, inviting feedback on potential focus areas for a future workshop. This collaborative approach led to two informative webinars in December 2024, highlighting specific challenges in data curation, data processing, metadata tools, and variant identifiers within the NHGRI resources. Throughout the workshop planning process, the four Organizing Committee members worked together to create and develop themes, design breakout sessions, and create a detailed agenda. The workshop's agenda was intentionally structured to ensure participants could generate implementable recommendations for the NHGRI resource community. The two-day workshop was held in Bethesda, MD, on March 3-4, 2025. The challenges received from NHGRI resources were classified into four key categories, forming the basis of the workshop. The four key categories are variant identifiers, data processing, data curation, and metadata tools. They are briefly described below, with greater details on their challenges and recommendations in subsequent sections. Metadata Tools:While metadata is vital for capturing context in genomic datasets, its usage and relevance can vary by domain, making it difficult to standardize usage. While various methods exist for annotating and extracting metadata, incomplete or inconsistent annotations often result in ineffective data sharing and interoperability, further reducing data usability and reproducibility.Data Curation:Curation of annotations for genomics data is critical for FAIR-ness. Scalable curation solutions are challenging because of the multiple components for curation, including harmonizing data sets, data cleaning, and annotation. The workshop focused on identifying which aspects of data curation could be streamlined using computational methods while considering the barriers to increased automation.Variant Identifiers:Variant identifiers are standardized representations of genetic variants, crucial for sharing and interpreting genomic data in research and clinical work. They ensure consistent referencing and enable data aggregation. Standardizing variant identifiers is difficult due to varied formats, complex data, and distinct environments for generating and disseminating data.Data Processing:Data processing is a necessary first step in a FAIR environment. As there are many variant workflows, streamlining this process will ensure greater accuracy, reproducibility, interoperability, and FAIRness, driving advancements in clinical research. The workshop focused on addressing these aspects with a key focus on improvements and best practices around data processing for an NHGRI resource. Several recommendations were made throughout the workshop's interactive sessions with the resources' participants. While many recommendations were specific to data processing, data curation, metadata tools, or variant identifiers, they can be grouped into core recommendations addressing common challenges within the NHGRI resource community. These core recommendations highlight the key themes that emerged across sessions and are listed in the nine recommendations below. Increase transparency to enable effective sharing/reproducibility (documenting, benchmarking, publishing, mapping)Develop entity schema and ontology mapping tools (between models, identifiers, etc.)Annotate tools using resources to increase findability and reuse (Examples: EDAM Ontology of Bioscientific data analysis and data management)Use standard nomenclature and identifiersMake workflows usable by researchers with limited programming expertiseImplement APIs to improve data connectivityPresent data in an interpretable manner, along with machine readabilityDevelop artificial intelligence/machine learning (AI/ML) methods for scaling curation processesAssess the impact of resources using an independent group that can assess return on investment and impact to health and scientific advancement. An additional key collaborative outcome was the development of Appendix A, which outlines ongoing and future efforts, including additional workshops, webinars, and meetings through the listed events provided by the NHGRI resource community. We hope that these activities will enable further advances in the implementation of FAIR standards and continue to foster collaboration and exchange across NHGRI resources and the global community.",
      "authors": "Babb Larry; Bult Carol; Carey Vincent J; Carroll Robert J; Hitz Benjamin C; Mungall Chris J; Rehm Heidi L; Schatz Michael C; Wagner Alex",
      "year": "2025",
      "journal": "ArXiv",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40895087/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12393232"
    },
    {
      "pmid": "37289496",
      "title": "Gender Bias When Using Artificial Intelligence to Assess Anorexia Nervosa on Social Media: Data-Driven Study.",
      "abstract": "BACKGROUND: Social media sites are becoming an increasingly important source of information about mental health disorders. Among them, eating disorders are complex psychological problems that involve unhealthy eating habits. In particular, there is evidence showing that signs and symptoms of anorexia nervosa can be traced in social media platforms. Knowing that input data biases tend to be amplified by artificial intelligence algorithms and, in particular, machine learning, these methods should be revised to mitigate biased discrimination in such important domains. OBJECTIVE: The main goal of this study was to detect and analyze the performance disparities across genders in algorithms trained for the detection of anorexia nervosa on social media posts. We used a collection of automated predictors trained on a data set in Spanish containing cases of 177 users that showed signs of anorexia (471,262 tweets) and 326 control cases (910,967 tweets). METHODS: We first inspected the predictive performance differences between the algorithms for male and female users. Once biases were detected, we applied a feature-level bias characterization to evaluate the source of such biases and performed a comparative analysis of such features and those that are relevant for clinicians. Finally, we showcased different bias mitigation strategies to develop fairer automated classifiers, particularly for risk assessment in sensitive domains. RESULTS: Our results revealed concerning predictive performance differences, with substantially higher false negative rates (FNRs) for female samples (FNR=0.082) compared with male samples (FNR=0.005). The findings show that biological processes and suicide risk factors were relevant for classifying positive male cases, whereas age, emotions, and personal concerns were more relevant for female cases. We also proposed techniques for bias mitigation, and we could see that, even though disparities can be mitigated, they cannot be eliminated. CONCLUSIONS: We concluded that more attention should be paid to the assessment of biases in automated methods dedicated to the detection of mental health issues. This is particularly relevant before the deployment of systems that are thought to assist clinicians, especially considering that the outputs of such systems can have an impact on the diagnosis of people at risk.",
      "authors": "Solans Noguero David; Ram\u00edrez-Cifuentes Diana; R\u00edssola Esteban Andr\u00e9s; Freire Ana",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/45184",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37289496/",
      "mesh_terms": "Female; Humans; Male; Anorexia Nervosa; Artificial Intelligence; Sexism; Social Media; Feeding and Eating Disorders",
      "keywords": "anorexia nervosa; artificial intelligence; gender bias; social media",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10288345"
    },
    {
      "pmid": "32188481",
      "title": "A geographic identifier assignment algorithm with Bayesian variable selection to identify neighborhood factors associated with emergency department visit disparities for asthma.",
      "abstract": "BACKGROUND: Ecologic health studies often rely on outcomes from health service utilization data that are limited by relatively coarse spatial resolutions and missing geographic information, particularly neighborhood level identifiers. When fine-scale geographic data are missing, the ramifications and strategies for addressing them are not well researched or developed. This study illustrates a novel spatio-temporal framework that combines a geographic identifier assignment (i.e., geographic imputation) algorithm with predictive Bayesian variable selection to identify neighborhood factors associated with disparities in emergency department (ED) visits for asthma. METHODS: ED visit records with missing fine-scale spatial identifiers (~\u200920%) were geocoded using information from known, coarser, misaligned spatial units using an innovative geographic identifier assignment algorithm. We then employed systematic variable selection in a spatio-temporal Bayesian hierarchical model (BHM) predictive framework within the NIMBLE package in R. Our novel methodology is illustrated in an ecologic case study aimed at identifying neighborhood-level predictors of asthma ED visits in South Carolina, United States, from 1999 to 2015. The health outcome was annual ED visit counts in small areas (i.e., census tracts) with primary diagnoses of asthma (ICD9 codes 493.XX) among children ages 5 to 19\u00a0years. RESULTS: We maintained 96% of ED visit records for this analysis. When the algorithm used areal proportions as probabilities for assignment, which addressed differential missingness of census tract identifiers in rural areas, variable selection consistently identified significant neighborhood-level predictors of asthma ED visit risk including pharmacy proximity, average household size, and carbon monoxide interactions. Contrasted with common solutions of removing geographically incomplete records or scaling up analyses, our methodology identified critical differences in parameters estimated, predictors selected, and inferences. We posit that the differences were attributable to improved data resolution, resulting in greater power and less bias. Importantly, without this methodology, we would have inaccurately identified predictors of risk for asthma ED visits, particularly in rural areas. CONCLUSIONS: Our approach innovatively addressed several issues in ecologic health studies, including missing small-area geographic information, multiple correlated neighborhood covariates, and multiscale unmeasured confounding factors. Our methodology could be widely applied to other small-area studies, useful to a range of researchers throughout the world.",
      "authors": "Bozigar Matthew; Lawson Andrew; Pearce John; King Kathryn; Svendsen Erik",
      "year": "2020",
      "journal": "International journal of health geographics",
      "doi": "10.1186/s12942-020-00203-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32188481/",
      "mesh_terms": "Adolescent; Algorithms; Asthma; Bayes Theorem; Child; Child, Preschool; Emergency Service, Hospital; Geographic Information Systems; Geography; Health Status Disparities; Humans; Residence Characteristics; South Carolina; Young Adult",
      "keywords": "Air pollution; Bayesian spatio-temporal modeling; Geographic imputation; Hospitalization record data; Respiratory diseases; Rural health; SEA-AIR Study; Social determinants of health; Urban health",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC7081565"
    },
    {
      "pmid": "33746859",
      "title": "A Pictorial Dot Probe Task to Assess Food-Related Attentional Bias in Youth With and Without Obesity: Overview of Indices and Evaluation of Their Reliability.",
      "abstract": "Several versions of the dot probe detection task are frequently used to assess maladaptive attentional processes associated with a broad range of psychopathology and health behavior, including eating behavior and weight. However, there are serious concerns about the reliability of the indices derived from the paradigm as measurement of attentional bias toward or away from salient stimuli. The present paper gives an overview of different attentional bias indices used in psychopathology research and scrutinizes three types of indices (the traditional attentional bias score, the dynamic trial-level base scores, and the probability index) calculated from a pictorial version of the dot probe task to assess food-related attentional biases in children and youngsters with and without obesity. Correlational analyses reveal that dynamic scores (but not the traditional and probability indices) are dependent on general response speed. Reliability estimates are low for the traditional and probability indices. The higher reliability for the dynamic indices is at least partially explained by general response speed. No significant group differences between youth with and without obesity are found, and correlations with weight are also non-significant. Taken together, results cast doubt on the applicability of this specific task for both experimental and individual differences research on food-related attentional biases in youth. However, researchers are encouraged to make and test adaptations to the procedure or computational algorithm in an effort to increase psychometric quality of the task and to report psychometric characteristics of their version of the task for their specific sample.",
      "authors": "Vervoort Leentje; Braun Maya; De Schryver Maarten; Naets Tiffany; Koster Ernst H W; Braet Caroline",
      "year": "2021",
      "journal": "Frontiers in psychology",
      "doi": "10.3389/fpsyg.2021.644512",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33746859/",
      "mesh_terms": "",
      "keywords": "attentional bias; children and adolescent; dot probe paradigm; obesity; reliability",
      "pub_types": "Journal Article",
      "pmcid": "PMC7965983"
    },
    {
      "pmid": "37185650",
      "title": "Predictive care: a protocol for a computational ethnographic approach to building fair models of inpatient violence in emergency psychiatry.",
      "abstract": "INTRODUCTION: Managing violence or aggression is an ongoing challenge in emergency psychiatry. Many patients identified as being at risk do not go on to become violent or aggressive. Efforts to automate the assessment of risk involve training machine learning (ML) models on data from electronic health records (EHRs) to predict these behaviours. However, no studies to date have examined which patient groups may be over-represented in false positive predictions, despite evidence of social and clinical biases that may lead to higher perceptions of risk in patients defined by intersecting features (eg, race, gender). Because risk assessment can impact psychiatric care (eg, via coercive measures, such as restraints), it is unclear which patients might be underserved or harmed by the application of ML. METHODS AND ANALYSIS: We pilot a computational ethnography to study how the integration of ML into risk assessment might impact acute psychiatric care, with a focus on how EHR data is compiled and used to predict a risk of violence or aggression. Our objectives include: (1) evaluating an ML model trained on psychiatric EHRs to predict violent or aggressive incidents for intersectional bias; and (2) completing participant observation and qualitative interviews in an emergency psychiatric setting to explore how social, clinical and structural biases are encoded in the training data. Our overall aim is to study the impact of ML applications in acute psychiatry on marginalised and underserved patient groups. ETHICS AND DISSEMINATION: The project was approved by the research ethics board at The Centre for Addiction and Mental Health (053/2021). Study findings will be presented in peer-reviewed journals, conferences and shared with service users and providers.",
      "authors": "Sikstrom Laura; Maslej Marta M; Findlay Zoe; Strudwick Gillian; Hui Katrina; Zaheer Juveria; Hill Sean L; Buchman Daniel Z",
      "year": "2023",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2022-069255",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37185650/",
      "mesh_terms": "Humans; Inpatients; Violence; Aggression; Anthropology, Cultural; Psychiatry",
      "keywords": "ethnography; health equity; machine learning; psychiatry; risk assessment",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10151964"
    },
    {
      "pmid": "35089868",
      "title": "Precision Public Health and Structural Racism in the United States: Promoting Health Equity in the COVID-19 Pandemic Response.",
      "abstract": "The COVID-19 pandemic has revealed deeply entrenched structural inequalities that resulted in an excess of mortality and morbidity in certain racial and ethnic groups in the United States. Therefore, this paper examines from the US perspective how structural racism and defective data collection on racial and ethnic minorities can negatively influence the development of precision public health (PPH) approaches to tackle the ongoing COVID-19 pandemic. Importantly, the effects of structural and data racism on the development of fair and inclusive data-driven components of PPH interventions are discussed, such as with the use of machine learning algorithms to predict public health risks. The objective of this viewpoint is thus to inform public health policymaking with regard to the development of ethically sound PPH interventions against COVID-19. Particular attention is given to components of structural racism (eg, hospital segregation, implicit and organizational bias, digital divide, and sociopolitical influences) that are likely to hinder such approaches from achieving their social justice and health equity goals.",
      "authors": "Genevi\u00e8ve Lester Darryl; Martani Andrea; Wangmo Tenzin; Elger Bernice Simone",
      "year": "2022",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/33277",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35089868/",
      "mesh_terms": "COVID-19; Data Collection; Health Equity; Humans; Pandemics; Public Health; SARS-CoV-2; Systemic Racism; United States",
      "keywords": "COVID-19; SARS-CoV-2; discrimination; disparity; equity; health equity; inequality; morbidity; mortality; pandemic; precision health; precision public health; public health; racism; social justice; stigma; structural racism",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8900917"
    },
    {
      "pmid": "34542183",
      "title": "Highlighting psychological pain avoidance and decision-making bias as key predictors of suicide attempt in major depressive disorder-A novel investigative approach using machine learning.",
      "abstract": "OBJECTIVE: Predicting suicide is notoriously difficult and complex, but a serious public health issue. An innovative approach utilizing machine learning (ML) that incorporates features of psychological mechanisms and decision-making characteristics related to suicidality could create an improved model for identifying suicide risk in patients with major depressive disorder (MDD). METHOD: Forty-four patients with MDD and past suicide attempts (MDD_SA, N\u2009=\u200944); 48 patients with MDD but without past suicide attempts (MDD_NS, N\u2009=\u200948-42 of whom with suicide ideation [MDD_SI, N\u2009=\u200942]), and healthy controls (HCs, N\u2009=\u200951) completed seven psychometric assessments including the Three-dimensional\u2002Psychological Pain Scale (TDPPS), and one behavioral assessment, the Balloon Analogue Risk Task (BART). Descriptive statistics, group comparisons, logistic regressions, and ML were used to explore and compare the groups and generate predictors of suicidal acts. RESULTS: MDD_SA and MDD_NS differed in TDPPS\u2002total score, pain arousal and avoidance subscale scores, suicidal ideation scores, and relevant decision-making indicators in BART. Logistic regression tests linked suicide attempts to psychological pain avoidance and a risk decision-making indicator. The resultant key ML model distinguished MDD_SA/MDD_NS with 88.2% accuracy. The model could also distinguish MDD_SA/MDD_SI with 81.25% accuracy. The ML model using hopelessness could classify MDD_SI/HC with 94.4% accuracy. CONCLUSION: ML analyses showed that motivation to avoid intolerable psychological pain, coupled with impaired decision-making bias toward under-valuing life's worth are highly predictive of suicide attempts. Analyses also demonstrated that suicidal ideation and attempts differed in potential mechanisms, as suicidal ideation was more related to hopelessness. ML algorithms show useful promises as a predictive instrument.",
      "authors": "Ji Xinlei; Zhao Jiahui; Fan Lejia; Li Huanhuan; Lin Pan; Zhang Panwen; Fang Shulin; Law Samuel; Yao Shuqiao; Wang Xiang",
      "year": "2022",
      "journal": "Journal of clinical psychology",
      "doi": "10.1002/jclp.23246",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34542183/",
      "mesh_terms": "Major Depressive Disorder; Humans; Machine Learning; Pain; Suicidal Ideation; Suicide, Attempted",
      "keywords": "machine learning; major depressive disorder; psychological pain; risk decision-making; suicide",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "24077093",
      "title": "Self-controlled case series and misclassification bias induced by case selection from administrative hospital databases: application to febrile convulsions in pediatric vaccine pharmacoepidemiology.",
      "abstract": "Vaccine safety studies are increasingly conducted by using administrative health databases and self-controlled case series designs that are based on cases only. Often, several criteria are available to define the cases, which may yield different positive predictive values, as well as different sensitivities, and therefore different numbers of selected cases. The question then arises as to which is the best case definition. This article proposes new methodology to guide this choice based on the bias of the relative incidence and the power of the test. We apply this methodology in a validation study of 4 nested algorithms for identifying febrile convulsions from the administrative databases of 10 French hospitals. We used a sample of 695 children aged 1 month to 3 years who were hospitalized in 2008-2009 with at least 1 diagnosis code of febrile convulsions. The positive predictive values of the algorithms ranged from 81% to 98%, and their sensitivities were estimated to be 47%-99% in data from 1 large hospital. When applying our proposed methods, the algorithm we selected used a restricted diagnosis code and position on the discharge abstract. These criteria, which resulted in the selection of 502 cases with a positive predictive value of 95%, provided the best compromise between high power and low relative bias.",
      "authors": "Quantin Catherine; Benzenine Eric; Velten Michel; Huet Fr\u00e9d\u00e9ric; Farrington C Paddy; Tubert-Bitter Pascale",
      "year": "2013",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwt207",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24077093/",
      "mesh_terms": "Algorithms; Bias; Causality; Child, Preschool; Databases, Factual; Female; France; Hospital Administration; Humans; Infant; Male; Pharmacovigilance; Research Design; Seizures, Febrile; Vaccines",
      "keywords": "administrative data; bias; febrile convulsions; pharmacoepidemiology; positive predictive value; power; vaccines",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41038065",
      "title": "Guidance to undertaking systematic evidence maps.",
      "abstract": "Systematic Evidence Maps (SEMs) are a form of evidence synthesis offering structured approaches to categorizing and organizing scientific evidence by identifying trends and gaps. SEMs support researchers and policymakers in navigating complex evidence landscapes. By synthesizing evidence, they lay the foundation for targeted systematic reviews and primary research, supporting evidence-informed decision-making. These outputs can be hosted on websites, providing an interactive tool. In environmental health, SEMs are systematically used to categorize evidence on topics such as pollution control measures, climate change impacts, and health disparities. The methodological framework for conducting SEMs involves defining the research scope, employing a systematic search strategy, screening studies systematically, optionally conducting critical appraisal (risk of bias assessment) when studies are categorized by effect direction or intended to inform subsequent syntheses, and coding data for synthesis and visualization. Narrative synthesis, heatmaps and network diagrams enhance SEMs usability. However, challenges remain, including methodological inconsistencies and the need for standardization. Advances in automation, machine learning, and stakeholder engagement can further refine SEMs methodologies. This commentary situates SEMs within the broader family of evidence synthesis, emphasizing their role in environmental health science. By enhancing methodological clarity and leveraging innovative tools, SEMs can support researchers and decision-makers in navigating complex evidence ecosystems and implementing evidence-based solutions for environmental scientists.",
      "authors": "Khalil H; Welsh V; Grainger M; Campbell F",
      "year": "2025",
      "journal": "Environment international",
      "doi": "10.1016/j.envint.2025.109827",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41038065/",
      "mesh_terms": "Environmental Health; Climate Change; Decision Making; Humans",
      "keywords": "Environmental health; Methodology; Public health; Reviews; Systematic evidence map",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38360543",
      "title": "Calibration and XGBoost reweighting to reduce coverage and non-response biases in overlapping panel surveys: application to the Healthcare and Social Survey.",
      "abstract": "BACKGROUND: Surveys have been used worldwide to provide information on the COVID-19 pandemic impact so as to prepare and deliver an effective Public Health response. Overlapping panel surveys allow longitudinal estimates and more accurate cross-sectional estimates to be obtained thanks to the larger sample size. However, the problem of non-response is particularly aggravated in the case of panel surveys due to population fatigue with repeated surveys. OBJECTIVE: To develop a new reweighting method for overlapping panel surveys affected by non-response. METHODS: We chose the Healthcare and Social Survey which has an overlapping panel survey design with measurements throughout 2020 and 2021, and random samplings stratified by province and degree of urbanization. Each measurement comprises two samples: a longitudinal sample taken from previous measurements and a new sample taken at each measurement. RESULTS: Our reweighting methodological approach is the result of a two-step process: the original sampling design weights are corrected by modelling non-response with respect to the longitudinal sample obtained in a previous measurement using machine learning techniques, followed by calibration using the auxiliary information available at the population level. It is applied to the estimation of totals, proportions, ratios, and differences between measurements, and to gender gaps in the variable of self-perceived general health. CONCLUSION: The proposed method produces suitable estimators for both cross-sectional and longitudinal samples. For addressing future health crises such as COVID-19, it is therefore necessary to reduce potential coverage and non-response biases in surveys by means of utilizing reweighting techniques as proposed in this study.",
      "authors": "Castro Luis; Rueda Mar\u00eda Del Mar; S\u00e1nchez-Cantalejo Carmen; Ferri Ram\u00f3n; Cabrera-Le\u00f3n Andr\u00e9s",
      "year": "2024",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/s12874-024-02171-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38360543/",
      "mesh_terms": "Humans; Cross-Sectional Studies; Calibration; Pandemics; Surveys and Questionnaires; COVID-19; Bias; Delivery of Health Care",
      "keywords": "COVID-19; Machine learning; Non-response bias; Panel surveys; Public health; Sampling",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10868104"
    },
    {
      "pmid": "40745627",
      "title": "Using a large language model (ChatGPT) to assess risk of bias in randomized controlled trials of medical interventions: protocol for a pilot study of interrater agreement with human reviewers.",
      "abstract": "BACKGROUND: Risk of bias (RoB) assessment is an essential part of systematic reviews that requires reading and understanding each eligible trial and RoB tools. RoB assessment is subject to human error and is time-consuming. Machine learning-based tools have been developed to automate RoB assessment using simple models trained on limited corpuses. ChatGPT is a conversational agent based on a large language model (LLM) that was trained on an internet-scale corpus and has demonstrated human-like abilities in multiple areas including healthcare. LLMs might be able to support systematic reviewing tasks such as assessing RoB. We aim to assess interrater agreement in overall (rather than domain-level) RoB assessment between human reviewers and ChatGPT, in randomized controlled trials of interventions within medical interventions. METHODS: We will randomly select 100 individually- or cluster-randomized, parallel, two-arm trials of medical interventions from recent Cochrane systematic reviews that have been assessed using the RoB1 or RoB2 family of tools. We will exclude reviews and trials that were performed under emergency conditions (e.g.,\u00a0COVID-19), as well as public health and welfare interventions. We will use 25 of the trials and human RoB assessments to engineer a ChatGPT prompt for assessing overall RoB, based on trial methods text. We will obtain ChatGPT assessments of RoB for the remaining 75 trials and human assessments. We will then estimate interrater agreement using Cohen's \u03ba. RESULTS: The primary outcome for this study is overall human-ChatGPT interrater agreement. We will report observed agreement with an exact 95% confidence interval, expected agreement under random assessment, Cohen's \u03ba, and a p-value testing the null hypothesis of no difference in agreement. Several other analyses are also planned. CONCLUSIONS: This study is likely to provide the first evidence on interrater agreement between human RoB assessments and those provided by LLMs and will inform subsequent research in this area.",
      "authors": "Rose Christopher James; Bidonde Julia; Ringsten Martin; Glanville Julie; Berg Rigmor C; Cooper Chris; Muller Ashley Elizabeth; Bergsund Hans Bugge; Meneses-Echavez Jose F; Potrebny Thomas",
      "year": "2025",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/s12874-025-02631-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40745627/",
      "mesh_terms": "Humans; Bias; Generative Artificial Intelligence; Large Language Models; Machine Learning; Observer Variation; Pilot Projects; Randomized Controlled Trials as Topic; Research Design; Risk Assessment; Systematic Reviews as Topic",
      "keywords": "Artificial intelligence; ChatGPT; Large language model; Machine learning; Risk of bias; Systematic reviewing",
      "pub_types": "Journal Article",
      "pmcid": "PMC12315198"
    },
    {
      "pmid": "38105749",
      "title": "Some key questions: Pregnancy intention screening by community health workers.",
      "abstract": "BACKGROUND: Unintended pregnancy contributes to a high burden of maternal and fetal morbidity in the United States, and pregnancy intention screening offers a key strategy to improve preconception health and reproductive health equity. The One Key Question\u00a9 is a pregnancy intention screening tool that asks a single question, \"Would you like to become pregnant in the next year?\" to all reproductive-age women. This study explored the perspectives of community health workers on using One Key Question in community-based settings. OBJECTIVES: This study aimed to identify barriers and facilitators to the use of the One Key Question pregnancy intention screening tool by community health workers who serve reproductive-age women in Salt Lake City, Utah. DESIGN: Using reproductive justice as a guiding conceptual framework, this study employed a qualitative descriptive design. Participants were asked to identify barriers and facilitators to the One Key Question, with open-ended discussion to explore community health workers' knowledge and perceptions about pregnancy intention screening. METHODS: We conducted focus groups with 43 community health workers in Salt Lake City, Utah, from December 2017 through January 2018. Participants were trained on the One Key Question algorithm and asked to identify barriers and facilitators to implementation. All focus groups occurred face-to-face in community settings and used a semi-structured facilitation guide developed by the study Principal Investigator with input from community partners. RESULTS: Pregnancy intention screening is perceived positively by community health workers. Barriers identified include traditional cultural beliefs about modesty and sex, lack of trust in health care providers, and female bias in the One Key Question algorithm. Facilitators include the simplicity of the One Key Question algorithm and the flexibility of One Key Question responses. CONCLUSION: One Key Question is an effective pregnancy intention screening tool in primary care settings but is limited in its capacity to reach those outside the health system. Community-based pregnancy intention screening offers an alternative avenue for implementation of One Key Question that could address many of these barriers and reduce disparities for underserved populations.",
      "authors": "St Clair Stephanie; Dearden Susan; Clark Lauren; Simonsen Sara E",
      "year": "2023",
      "journal": "Women's health (London, England)",
      "doi": "10.1177/17455057231213735",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38105749/",
      "mesh_terms": "Pregnancy; Female; Humans; United States; Intention; Community Health Workers; Prenatal Care",
      "keywords": "community health workers; health equity; pregnancy intention screening; primary care; women\u2019s health",
      "pub_types": "Journal Article",
      "pmcid": "PMC10729636"
    },
    {
      "pmid": "41410517",
      "title": "Multidisciplinary Perspectives on Artificial Intelligence in Aging Research and Education: Evolving Uses, Ethics, and Equity Considerations in Gerontology.",
      "abstract": "Artificial intelligence (AI) models and applications are proliferating rapidly throughout gerontological research and education. Machine learning has catapulted gerontological research in diagnosing and treating age-related health conditions. Students and educators have new tools for customized learning and innovation. Yet many of these developments come with persistent challenges, including bias, inaccuracy, and data security. As in other fields, engagement with AI models in gerontology is often siloed within disciplines. Exploring common opportunities and challenges in this space requires collaboration and conversations across disciplines. To fill this gap, the Gerontological Society of America (GSA)'s Public Policy Advisory Panel convened a multidisciplinary panel discussion of experts from the six GSA member groups and three advisory panels in November 2024 to discuss how AI is shaping various disciplines, and what ethical issues exist within or across disciplines. Several common themes emerged across disciplines: (1) human interaction remains critical to offset AI limitations in human experience, abstract reasoning, creativity, and bias; (2) AI provides opportunities for customized support across disciplines for older adults, care partners, practitioners, researchers, and students; (3) ongoing training is essential to navigate this rapidly evolving landscape; and (4) cross-disciplinary collaboration is needed to address overlapping challenges, limitations, and risks concerning AI.",
      "authors": "Perone Angela K; Abadir Peter M; Berlinger Nancy; Carey James R; Guest M Aaron; Hass Zachary J; Stephan Abigail T; Xie Bo",
      "year": "2025",
      "journal": "The Gerontologist",
      "doi": "10.1093/geront/gnaf314",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41410517/",
      "mesh_terms": "",
      "keywords": "geriatrics; interdisciplinary; technology; training",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40696767",
      "title": "Minimizing Racial Algorithmic Bias when Predicting Electronic Health Record Data Completeness.",
      "abstract": "The previously developed algorithm for identifying subjects with high electronic health record (EHR)-continuity performed suboptimally in racially diverse populations. We aimed to improve the performance by optimizing the race modeling strategy. We randomly divided TriNetX claims-linked EHR dataset from 11 US-based healthcare organizations into training (70%) and testing data (30%) to develop and test models with and without race interactions and race-specific models. We held out a Medicaid-linked EHR dataset as validation data. Study subjects were \u226518\u2009years with \u2265365\u2009days of continuous insurance enrollment overlapping an EHR encounter. We used cross-validated least absolute shrinkage and selection operator (LASSO) to select predictors of high EHR-continuity. We compared the model performance using area under receiver operating curve (AUC). There were 550,859, 236,089, and 65,956 subjects in the training, testing, and validation datasets, respectively. In the validation set, the introduction of race-interaction terms resulted in improved model performance in Black (AUC 0.821 vs. 0.812, P\u2009<\u20090.001) and other non-White race (AUC 0.828 vs. 0.812, P\u2009<\u20090.001) subgroups. The performance of the race-specific models did not differ substantially from that of the models with race-interaction terms in the race subgroups. Using the race interactions model, subjects in the top 50% of predicted EHR-continuity had 2-3-fold lesser misclassification of 40 comparative effectiveness research (CER) relevant variables. The inclusion of race-interaction terms improved model performance in the race subgroups. Using the EHR-continuity prediction algorithm with race-interaction terms can potentially reduce algorithmic bias for racial minorities.",
      "authors": "Anand Priyanka; Jin Yinzhu; Liu Jun; Lii Joyce; Belitkar Shruti; Lin Kueiyu Joshua",
      "year": "2025",
      "journal": "Clinical pharmacology and therapeutics",
      "doi": "10.1002/cpt.3758",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40696767/",
      "mesh_terms": "Humans; Electronic Health Records; Algorithms; Male; Female; Adult; United States; Middle Aged; Racial Groups; Medicaid; Bias",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39901187",
      "title": "Accounting for racial bias and social determinants of health in a model of hypertension control.",
      "abstract": "BACKGROUND: Hypertension control remains a critical problem and most of the existing literature views it from a clinical perspective, overlooking the role of sociodemographic factors. This study aims to identify patients with not well-controlled hypertension using readily available demographic and socioeconomic features and elucidate important predictive variables. METHODS: In this retrospective cohort study, records from 1/1/2012 to 1/1/2020 at the Boston Medical Center were used. Patients with either a hypertension diagnosis or related records (\u2265\u2009130\u00a0mmHg systolic or\u2009\u2265\u200990\u00a0mmHg diastolic, n\u2009=\u2009164,041) were selected. Models were developed to predict which patients had uncontrolled hypertension defined as systolic blood pressure (SBP) records exceeding 160\u00a0mmHg. RESULTS: The predictive model of high SBP reached an Area Under the Receiver Operating Characteristic Curve of 74.49%\u2009\u00b1\u20090.23%. Age, race, Social Determinants of Health (SDoH), mental health, and cigarette use were predictive of high SBP. Being Black or having critical social needs led to higher probability of uncontrolled SBP. To mitigate model bias and elucidate differences in predictive variables, two separate models were trained for Black and White patients. Black patients face a 4.7 \u00d7 higher False Positive Rate (FPR) and a 0.58 \u00d7 lower False Negative Rate (FNR) compared to White patients. Decision threshold differentiation was implemented to equalize FNR. Race-specific models revealed different sets of social variables predicting high SBP, with Black patients being affected by structural barriers (e.g., food and transportation) and White patients by personal and demographic factors (e.g., marital status). CONCLUSIONS: Models using non-clinical factors can predict which patients exhibit poorly controlled hypertension. Racial and SDoH variables are significant predictors but lead to biased predictive models. Race-specific models are not sufficient to resolve such biases and require further decision threshold tuning. A host of structural socioeconomic factors are identified to be targeted to reduce disparities in hypertension control.",
      "authors": "Hu Yang; Cordella Nicholas; Mishuris Rebecca G; Paschalidis Ioannis Ch",
      "year": "2025",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-025-02873-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39901187/",
      "mesh_terms": "Humans; Hypertension; Social Determinants of Health; Female; Middle Aged; Male; Retrospective Studies; Aged; Racism; Adult; Boston; Black or African American; White",
      "keywords": "Hypertension; Machine learning; Racial bias; Social determinants of health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11792567"
    },
    {
      "pmid": "39367027",
      "title": "An intelligent learning system based on electronic health records for unbiased stroke prediction.",
      "abstract": "Stroke has a negative impact on people's lives and is one of the leading causes of death and disability worldwide. Early detection of symptoms can significantly help predict stroke and promote a healthy lifestyle. Researchers have developed several methods to predict strokes using machine learning (ML) techniques. However, the proposed systems have suffered from the following two main problems. The first problem is that the machine learning models are biased due to the uneven distribution of classes in the dataset. Recent research has not adequately addressed this problem, and no preventive measures have been taken. Synthetic Minority Oversampling (SMOTE) has been used to remove bias and balance the training of the proposed ML model. The second problem is to solve the problem of lower classification accuracy of machine learning models. We proposed a learning system that combines an autoencoder with a linear discriminant analysis (LDA) model to increase the accuracy of the proposed ML model for stroke prediction. Relevant features are extracted from the feature space using the autoencoder, and the extracted subset is then fed into the LDA model for stroke classification. The hyperparameters of the LDA model are found using a grid search strategy. However, the conventional accuracy metric does not truly reflect the performance of ML models. Therefore, we employed several evaluation metrics to validate the efficiency of the proposed model. Consequently, we evaluated the proposed model's accuracy, sensitivity, specificity, area under the curve (AUC), and receiver operator characteristic (ROC). The experimental results show that the proposed model achieves a sensitivity and specificity of 98.51% and 97.56%, respectively, with an accuracy of 99.24% and a balanced accuracy of 98.00%.",
      "authors": "Saleem Muhammad Asim; Javeed Ashir; Akarathanawat Wasan; Chutinet Aurauma; Suwanwela Nijasri Charnnarong; Kaewplung Pasu; Chaitusaney Surachai; Deelertpaiboon Sunchai; Srisiri Wattanasak; Benjapolakul Watit",
      "year": "2024",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-024-73570-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39367027/",
      "mesh_terms": "Humans; Stroke; Machine Learning; Electronic Health Records; Female; Male; Aged; Middle Aged; Discriminant Analysis",
      "keywords": "Feature extraction; Imbalance classes; Machine learning; Stroke",
      "pub_types": "Journal Article",
      "pmcid": "PMC11452373"
    },
    {
      "pmid": "40124313",
      "title": "Artificial Intelligence Models to Identify Patients with High Probability of Glaucoma Using Electronic Health Records.",
      "abstract": "PURPOSE: Early detection of glaucoma allows for timely treatment to prevent severe vision loss, but screening requires resource-intensive examinations and imaging, which are challenging for large-scale implementation and evaluation. The purpose of this study was to develop artificial intelligence models that can utilize the wealth of data stored in electronic health records (EHRs) to identify patients who have high probability of developing glaucoma, without the use of any dedicated ophthalmic imaging or clinical data. DESIGN: Cohort study. PARTICIPANTS: A total of 64\u00a0735 participants who were \u226518 years of age and had \u22652 separate encounters with eye-related diagnoses recorded in their EHR records in the All of Us Research Program, a national multicenter cohort of patients contributing EHR and survey data, and who were enrolled from May 1, 2018, to July 1,\u00a02022. METHODS: We developed models to predict which patients had a diagnosis of glaucoma, using the following machine learning approaches: (1) penalized logistic regression, (2) XGBoost, and (3) a deep learning architecture that included a 1-dimensional convolutional neural network (1D-CNN) and stacked autoencoders. Model input features included demographics and only the nonophthalmic lab results, measurements, medications, and diagnoses available from structured EHR data. MAIN OUTCOME MEASURES: Evaluation metrics included area under the receiver operating characteristic curve (AUROC). RESULTS: Of 64\u00a0735 patients, 7268 (11.22%) had a glaucoma diagnosis. Overall, AUROC ranged from 0.796 to 0.863. The 1D-CNN model achieved the highest performance with an AUROC score of 0.863 (95% confidence interval [CI], 0.862-0.864). Investigation of 1D-CNN model performance stratified by race/ethnicity showed that AUROC ranged from 0.825 to 0.869 by subpopulation, with the highest performance of 0.869 (95% CI, 0.868-0.870) among the non-Hispanic White subpopulation. CONCLUSIONS: Machine and deep learning models were able to use the extensive systematic data within EHR to identify individuals with glaucoma, without the need for ophthalmic imaging or clinical data. These models could potentially automate identifying high-risk glaucoma patients in EHRs, aiding targeted screening referrals. Additional research is needed to investigate the impact of protected class characteristics such as race/ethnicity on model performance and fairness. FINANCIAL DISCLOSURES: The author(s) have no proprietary or commercial interest in any materials discussed in this article.",
      "authors": "Ravindranath Rohith; Wang Sophia Y",
      "year": "2025",
      "journal": "Ophthalmology science",
      "doi": "10.1016/j.xops.2024.100671",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40124313/",
      "mesh_terms": "",
      "keywords": "Deep learning; Electronic health records; Glaucoma screening; Machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11930135"
    },
    {
      "pmid": "40445905",
      "title": "Towards robust medical machine olfaction: Debiasing GC-MS data enhances prostate cancer diagnosis from urine volatiles.",
      "abstract": "Prostate cancer (PCa) is a major, and increasingly global, health concern with current screening and diagnostic tools' severe limitations causing unnecessary, invasive biopsy procedures. While gas chromatography-mass spectrometry (GC-MS) has been used to detect urinary volatile organic compounds (VOCs) associated with PCa, efforts to identify consistent molecular biomarkers have failed to generalize across studies. Inspired by the olfactory diagnostic capabilities of medical detection dogs, we do not reduce chromatograms to a list of compounds and concentrations. Instead, we deploy a machine learning approach that bypasses molecular identification: PCa \"scent character\" signatures are extracted from raw time series data transformed into image representations for classification via convolutional neural networks. To address confounding factors such as sample-source bias, we implement a multi-step pre-processing and debiasing pipeline, including empirical Bayes correction, baseline drift removal, and domain adversarial learning. The resulting model achieves classification performance on par with similarly trained canines, achieving a recall of 88% and an F1-score of 0.78. These findings demonstrate that, at least in the context of PCa detection from urine, machine learning-based scent signature analysis can serve as a fully non-invasive diagnostic alternative, with these early results being also relevant to the wider emergent field of medical machine olfaction.",
      "authors": "Rotteveel Adan; Lee Wen-Yee; Kountouri Zoi; Stefanou Nikolas; Kivell Howard; Gluck Clifford; Zhang Shuguang; Mershin Andreas",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0314742",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40445905/",
      "mesh_terms": "Male; Prostatic Neoplasms; Volatile Organic Compounds; Gas Chromatography-Mass Spectrometry; Humans; Machine Learning; Dogs; Animals; Smell; Bayes Theorem; Neural Networks, Computer",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12124533"
    },
    {
      "pmid": "36653067",
      "title": "Evaluation of race/ethnicity-specific survival machine learning models for Hispanic and Black patients with breast cancer.",
      "abstract": "OBJECTIVES: Survival machine learning (ML) has been suggested as a useful approach for forecasting future events, but a growing concern exists that ML models have the potential to cause racial disparities through the data used to train them. This study aims to develop race/ethnicity-specific survival ML models for Hispanic and black women diagnosed with breast cancer to examine whether race/ethnicity-specific ML models outperform the general models trained with all races/ethnicity data. METHODS: We used the data from the US National Cancer Institute's Surveillance, Epidemiology and End Results programme registries. We developed the Hispanic-specific and black-specific models and compared them with the general model using the Cox proportional-hazards model, Gradient Boost Tree, survival tree and survival support vector machine. RESULTS: A total of 322\u2009348 female patients who had breast cancer diagnoses between 1 January 2000 and 31 December 2017 were identified. The race/ethnicity-specific models for Hispanic and black women consistently outperformed the general model when predicting the outcomes of specific race/ethnicity. DISCUSSION: Accurately predicting the survival outcome of a patient is critical in determining treatment options and providing appropriate cancer care. The high-performing models developed in this study can contribute to providing individualised oncology care and improving the survival outcome of black and Hispanic women. CONCLUSION: Predicting the individualised survival outcome of breast cancer can provide the evidence necessary for determining treatment options and high-quality, patient-centred cancer care delivery for under-represented populations. Also, the race/ethnicity-specific ML models can mitigate representation bias and contribute to addressing health disparities.",
      "authors": "Park Jung In; Bozkurt Selen; Park Jong Won; Lee Sunmin",
      "year": "2023",
      "journal": "BMJ health & care informatics",
      "doi": "10.1136/bmjhci-2022-100666",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36653067/",
      "mesh_terms": "Humans; Female; Ethnicity; Breast Neoplasms; Hispanic or Latino; Black People; Proportional Hazards Models",
      "keywords": "artificial intelligence; health equity; informatics; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC9853120"
    },
    {
      "pmid": "33981823",
      "title": "Comparing denominator sources for real-time disease incidence modeling: American Community Survey and WorldPop.",
      "abstract": "Across the United States public health community in 2020, in the midst of a pandemic and increased concern regarding racial/ethnic health disparities, there is widespread concern about our ability to accurately estimate small-area disease incidence rates due to the absence of a recent census to obtain reliable population denominators. 2010 decennial census data are likely outdated, and intercensal population estimates from the Census Bureau, which are less temporally misaligned with real-time disease incidence data, are not recommended for use with small areas. Machine learning-based population estimates are an attractive option but have not been validated for use in epidemiologic studies. Treating 2010 decennial census counts as a \"ground truth\", we conduct a case study to compare the performance of alternative small-area population denominator estimates from surrounding years for modeling real-time disease incidence rates. Our case study focuses on modeling health disparities in census tract incidence rates in Massachusetts, using population size estimates from the American Community Survey (ACS), the most commonly-used intercensal small-area population data in epidemiology, and WorldPop, a machine learning model for high-resolution population size estimation. Through simulation studies and an analysis of real premature mortality data, we evaluate whether WorldPop denominators can provide improved performance relative to ACS for quantifying disparities using both census tract-aggregate and race-stratified modeling approaches. We find that biases induced in parameter estimates due to temporally incompatible incidence and denominator data tend to be larger for race-stratified models than for area-aggregate models. In most scenarios considered here, WorldPop denominators lead to greater bias in estimates of health disparities than ACS denominators. These insights will assist researchers in intercensal years to select appropriate population size estimates for modeling disparities in real-time disease incidence. We highlight implications for health disparity studies in the coming decade, as 2020 census counts may introduce new sources of error.",
      "authors": "Nethery Rachel C; Rushovich Tamara; Peterson Emily; Chen Jarvis T; Waterman Pamela D; Krieger Nancy; Waller Lance; Coull Brent A",
      "year": "2021",
      "journal": "SSM - population health",
      "doi": "10.1016/j.ssmph.2021.100786",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33981823/",
      "mesh_terms": "",
      "keywords": "Health disparities; Population denominators; Real-time incidence modeling",
      "pub_types": "Journal Article",
      "pmcid": "PMC8081984"
    },
    {
      "pmid": "33779570",
      "title": "Digital Mental Health Challenges and the Horizon Ahead for Solutions.",
      "abstract": "The demand outstripping supply of mental health resources during the COVID-19 pandemic presents opportunities for digital technology tools to fill this new gap and, in the process, demonstrate capabilities to increase their effectiveness and efficiency. However, technology-enabled services have faced challenges in being sustainably implemented despite showing promising outcomes in efficacy trials since the early 2000s. The ongoing failure of these implementations has been addressed in reconceptualized models and frameworks, along with various efforts to branch out among disparate developers and clinical researchers to provide them with a key for furthering evaluative research. However, the limitations of traditional research methods in dealing with the complexities of mental health care warrant a diversified approach. The crux of the challenges of digital mental health implementation is the efficacy and evaluation of existing studies. Web-based interventions are increasingly used during the pandemic, allowing for affordable access to psychological therapies. However, a lagging infrastructure and skill base has limited the application of digital solutions in mental health care. Methodologies need to be converged owing to the rapid development of digital technologies that have outpaced the evaluation of rigorous digital mental health interventions and strategies to prevent mental illness. The functions and implications of human-computer interaction require a better understanding to overcome engagement barriers, especially with predictive technologies. Explainable artificial intelligence is being incorporated into digital mental health implementation to obtain positive and responsible outcomes. Investment in digital platforms and associated apps for real-time screening, tracking, and treatment offer the promise of cost-effectiveness in vulnerable populations. Although machine learning has been limited by study conduct and reporting methods, the increasing use of unstructured data has strengthened its potential. Early evidence suggests that the advantages outweigh the disadvantages of incrementing such technology. The limitations of an evidence-based approach require better integration of decision support tools to guide policymakers with digital mental health implementation. There is a complex range of issues with effectiveness, equity, access, and ethics (eg, privacy, confidentiality, fairness, transparency, reproducibility, and accountability), which warrant resolution. Evidence-informed policies, development of eminent digital products and services, and skills to use and maintain these solutions are required. Studies need to focus on developing digital platforms with explainable artificial intelligence-based apps to enhance resilience and guide the treatment decisions of mental health practitioners. Investments in digital mental health should ensure their safety and workability. End users should encourage the use of innovative methods to encourage developers to effectively evaluate their products and services and to render them a worthwhile investment. Technology-enabled services in a hybrid model of care are most likely to be effective (eg, specialists using these services among vulnerable, at-risk populations but not severe cases of mental ill health).",
      "authors": "Balcombe Luke; De Leo Diego",
      "year": "2021",
      "journal": "JMIR mental health",
      "doi": "10.2196/26811",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33779570/",
      "mesh_terms": "",
      "keywords": "COVID-19; challenges; digital mental health implementation; explainable artificial intelligence; human-computer interaction; hybrid model of care; resilience; technology",
      "pub_types": "Journal Article",
      "pmcid": "PMC8077937"
    },
    {
      "pmid": "35489789",
      "title": "Closing the Gaps in Racial Disparities in Critical Limb Ischemia Outcome and Amputation Rates: Proceedings from a Society of Interventional Radiology Foundation Research Consensus Panel.",
      "abstract": "Minority patients such as Blacks, Hispanics, and Native Americans are disproportionately impacted by critical limb ischemia and amputation due to multiple factors such as socioeconomic status, type or lack of insurance, lack of access to health care, capacity and expertise of local hospitals, prevalence of diabetes, and unconscious bias. The Society of Interventional Radiology Foundation recognizes that it is imperative to close the disparity gaps and funded a Research Consensus Panel to prioritize a research agenda. The following research priorities were ultimately prioritized: (a) randomized controlled trial with peripheral arterial disease screening of at-risk patients with oversampling of high-risk racial groups, (b) prospective trial with the introduction of an intervention to alter a social determinant of health, and (c) a prospective trial with the implementation of an algorithm that requires criteria be met prior to an amputation. This article presents the proceedings and recommendations from the panel.",
      "authors": "Bryce Yolanda; Katzen Barry; Patel Parag; Moreira Carla C; Fakorede Foluso A; Arya Shipra; D'Andrea Melissa; Mustapha Jihad; Rowe Vincent; Rosenfield Kenneth; Vedantham Suresh; Abi-Jaoudeh Nadine; Rochon Paul J",
      "year": "2022",
      "journal": "Journal of vascular and interventional radiology : JVIR",
      "doi": "10.1016/j.jvir.2022.02.010",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35489789/",
      "mesh_terms": "Amputation, Surgical; Chronic Limb-Threatening Ischemia; Humans; Peripheral Arterial Disease; Prospective Studies; Racial Groups; Radiology, Interventional; Research",
      "keywords": "",
      "pub_types": "Journal Article; Randomized Controlled Trial; Consensus Statement",
      "pmcid": ""
    },
    {
      "pmid": "23113916",
      "title": "The influence of measurement error on calibration, discrimination, and overall estimation of a risk prediction model.",
      "abstract": "BACKGROUND: Self-reported height and weight are commonly collected at the population level; however, they can be subject to measurement error. The impact of this error on predicted risk, discrimination, and calibration of a model that uses body mass index (BMI) to predict risk of diabetes incidence is not known. The objective of this study is to use simulation to quantify and describe the effect of random and systematic error in self-reported height and weight on the performance of a model for predicting diabetes. METHODS: Two general categories of error were examined: random (nondirectional) error and systematic (directional) error on an algorithm relating BMI in kg/m2 to probability of developing diabetes. The cohort used to develop the risk algorithm was derived from 23,403 Ontario residents that responded to the 1996/1997 National Population Health Survey linked to a population-based diabetes registry. The data and algorithm were then simulated to allow for estimation of the impact of these errors on predicted risk using the Hosmer-Lemeshow goodness-of-fit \u03c72 and C-statistic. Simulations were done 500 times with sample sizes of 9,177 for males and 10,618 for females. RESULTS: Simulation data successfully reproduced discrimination and calibration generated from population data. Increasing levels of random error in height and weight reduced the calibration and discrimination of the model. Random error biased the predicted risk upwards whereas systematic error biased predicted risk in the direction of the bias and reduced calibration; however, it did not affect discrimination. CONCLUSION: This study demonstrates that random and systematic errors in self-reported health data have the potential to influence the performance of risk algorithms. Further research that quantifies the amount and direction of error can improve model performance by allowing for adjustments in exposure measurements.",
      "authors": "Rosella Laura C; Corey Paul; Stukel Therese A; Mustard Cam; Hux Jan; Manuel Doug G",
      "year": "2012",
      "journal": "Population health metrics",
      "doi": "10.1186/1478-7954-10-20",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23113916/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC3545925"
    },
    {
      "pmid": "41200127",
      "title": "Predicting Child Development Across Literacy, Physical, Learning, and Social-Emotional Domains Using Supervised Machine Learning: A Cross-Sectional Study Based on MICS 2019 Bangladesh.",
      "abstract": "BACKGROUND AND AIMS: Early childhood development (ECD) plays a vital role in shaping a child's health and well-being, influenced by child, family, and environmental factors. To prevent long-term impairments, early detection and intervention are crucial. Using MICS 2019 data, this study applies supervised machine learning to predict ECD across four key domains and identify the most significant predictors and economic strategies. METHODS: In this study, using data of 9346 children obtained from Multiple Indicator Cluster Surveys (MICS) 2019, we evaluated and compared five classifiers: CART, Random Forest, XGBoost, Logistic Regression, and Support Vector Machines (SVM). We have addressed four early developmental domains as our target variables: literacy, numeracy, physics, learning, and social-emotional development of children. Five-fold cross-validation was used to ensure appropriate test error rate estimations and reduce bias. To handle the data imbalance, the Synthetic Minority Oversampling Technique (SMOTE) is used. RESULTS: The analysis shows that most children are developing normally in the learning (90.58%) and physical (98.70%) domains, while delays are highest in literacy-numeracy (71.37%) and social-emotional (27.57%) domains. Among the machine learning models evaluated, Random Forest consistently performed best across all domains, achieving the highest accuracy, particularly in learning (0.83) and physical (0.97) domains. Feature importance analysis identified maternal education, child age, regional location (Division), and socioeconomic status (Wealth Index) as key predictors. Early childhood education and books read at home also play important roles in cognitive and learning outcomes, guiding targeted interventions for child development. CONCLUSIONS: The results show notable differences in early childhood development, particularly in social-emotional and literacy-numeracy domains. Socioeconomic status, early learning experiences, and parental education are key predictors, while physical and social-emotional development are influenced by resources, regional factors, and nutrition. These findings can guide targeted interventions and policies for holistic child development.",
      "authors": "Islam Faizul; Suhel Golam Morshed; Afroz Mahmud; Apu Md Aminul I; Rana Md Jewel; Hossain Tofajjel; Ziba Zaibunnesa; Shariar Md Fahim; Hasan Mohammad Nayeem",
      "year": "2025",
      "journal": "Health science reports",
      "doi": "10.1002/hsr2.71434",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41200127/",
      "mesh_terms": "",
      "keywords": "algorithms; cognition; early childhood development; machine learning; psychomotor performance; social behavior; statistical models",
      "pub_types": "Journal Article",
      "pmcid": "PMC12586350"
    },
    {
      "pmid": "41040699",
      "title": "Privacy-Enhancing Sequential Learning under Heterogeneous Selection Bias in Multi-Site EHR Data.",
      "abstract": "OBJECTIVE: To develop privacy-enhancing statistical methods for estimation of binary disease risk model association parameters across multiple electronic health record (EHR) sites with heterogeneous selection mechanisms, without sharing raw individual-level data. We illustrate their utility through a cross-biobank analysis of smoking and 97 cancer subtypes using data from the NIH All of Us (AOU) and the Michigan Genomics Initiative (MGI). MATERIALS AND METHODS: Large-scale biobanks often follow heterogeneous recruitment strategies and store data in separate cloud-based platforms, making centralized algorithms infeasible. To address this, we propose two decentralized sequential estimators namely, Sequential Pseudo-likelihood (SPL) and Sequential Augmented Inverse Probability Weighting (SAIPW) that leverage external population-level information to adjust for selection bias, with valid variance estimation. SAIPW additionally protects against misspecification of the selection model using flexible machine learning based auxiliary outcome models. We compare SPL and SAIPW with the existing Sequential Unweighted (SUW) estimator and with centralized and meta learning extensions of IPW and AIPW in simulations under both correctly specified and misspecified selection mechanisms. We apply the methods to harmonized data from MGI ( n = 50,935) and AOU ( n = 241,563) to estimate smoking-cancer associations. RESULTS: In simulations, SUW exhibited substantial bias and poor coverage. SPL and SAIPW yielded unbiased estimates with valid coverage probabilities under correct model specification, with SAIPW remaining robust under selection model misspecification. Both approaches showed no notable efficiency loss relative to centralized methods. Meta-learning methods were efficient for large sites but failed in settings with small cohort sizes and rare outcome prevalence. In real-data analysis, strong associations were consistently identified between smoking and cancers of the lung, bladder, and larynx, aligning with established epidemiological evidence. CONCLUSION: Our framework enables valid, privacy-enhancing inference across EHR cohorts with heterogeneous selection, supporting scalable, decentralized research using real-world data.",
      "authors": "Kundu Ritoban; Shi Xu; Patel Kumar Kshitij; Ohno-Machado Lucila; Salvatore Maxwell; Song Peter X K; Mukherjee Bhramar",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.09.26.25336642",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41040699/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12486029"
    },
    {
      "pmid": "39018490",
      "title": "Applying natural language processing to patient messages to identify depression concerns in cancer patients.",
      "abstract": "OBJECTIVE: This study aims to explore and develop tools for early identification of depression concerns among cancer patients by leveraging the novel data source of messages sent through a secure patient portal. MATERIALS AND METHODS: We developed classifiers based on logistic regression (LR), support vector machines (SVMs), and 2 Bidirectional Encoder Representations from Transformers (BERT) models (original and Reddit-pretrained) on 6600 patient messages from a cancer center (2009-2022), annotated by a panel of healthcare professionals. Performance was compared using AUROC scores, and model fairness and explainability were examined. We also examined correlations between model predictions and depression diagnosis and treatment. RESULTS: BERT and RedditBERT attained AUROC scores of 0.88 and 0.86, respectively, compared to 0.79 for LR and 0.83 for SVM. BERT showed bigger differences in performance across sex, race, and ethnicity than RedditBERT. Patients who sent messages classified as concerning had a higher chance of receiving a depression diagnosis, a prescription for antidepressants, or a referral to the psycho-oncologist. Explanations from BERT and RedditBERT differed, with no clear preference from annotators. DISCUSSION: We show the potential of BERT and RedditBERT in identifying depression concerns in messages from cancer patients. Performance disparities across demographic groups highlight the need for careful consideration of potential biases. Further research is needed to address biases, evaluate real-world impacts, and ensure responsible integration into clinical settings. CONCLUSION: This work represents a significant methodological advancement in the early identification of depression concerns among cancer patients. Our work contributes to a route to reduce clinical burden while enhancing overall patient care, leveraging BERT-based models.",
      "authors": "van Buchem Marieke M; de Hond Anne A H; Fanconi Claudio; Shah Vaibhavi; Schuessler Max; Kant Ilse M J; Steyerberg Ewout W; Hernandez-Boussard Tina",
      "year": "2024",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocae188",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39018490/",
      "mesh_terms": "Humans; Natural Language Processing; Neoplasms; Depression; Male; Female; Support Vector Machine; Logistic Models; Patient Portals; Middle Aged; Adult",
      "keywords": "machine learning; mental health; natural language processing; oncology",
      "pub_types": "Journal Article",
      "pmcid": "PMC11413442"
    },
    {
      "pmid": "38961161",
      "title": "Early detection of pediatric health risks using maternal and child health data.",
      "abstract": "Machine learning (ML)-driven diagnosis systems are particularly relevant in pediatrics given the well-documented impact of early-life health conditions on later-life outcomes. Yet, early identification of diseases and their subsequent impact on length of hospital stay for this age group has so far remained uncharacterized, likely because access to relevant health data is severely limited. Thanks to a confidential data use agreement with the California Department of Health Care Access and Information, we introduce Ped-BERT: a state-of-the-art deep learning model that accurately predicts the likelihood of 100+ conditions and the length of stay in a pediatric patient's next medical visit. We link mother-specific pre- and postnatal period health information to pediatric patient hospital discharge and emergency room visits. Our data set comprises 513.9K mother-baby pairs and contains medical diagnosis codes, length of stay, as well as temporal and spatial pediatric patient characteristics, such as age and residency zip code at the time of visit. Following the popular bidirectional encoder representations from the transformers (BERT) approach, we pre-train Ped-BERT via the masked language modeling objective to learn embedding features for the diagnosis codes contained in our data. We then continue to fine-tune our model to accurately predict primary diagnosis outcomes and length of stay for a pediatric patient's next visit, given the history of previous visits and, optionally, the mother's pre- and postnatal health information. We find that Ped-BERT generally outperforms contemporary and state-of-the-art classifiers when trained with minimum features. We also find that incorporating mother health attributes leads to significant improvements in model performance overall and across all patient subgroups in our data. Our most successful Ped-BERT model configuration achieves an area under the receiver operator curve (ROC AUC) of 0.927 and an average precision score (APS) of 0.408 for the diagnosis prediction task, and a ROC AUC of 0.855 and APS of 0.815 for the length of hospital stay task. Further, we examine Ped-BERT's fairness by determining whether prediction errors are evenly distributed across various subgroups of mother-baby demographics and health characteristics, or if certain subgroups exhibit a higher susceptibility to prediction errors.",
      "authors": "Ilin Cornelia",
      "year": "2024",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-024-65449-8",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38961161/",
      "mesh_terms": "Humans; Female; Child Health; Infant; Child, Preschool; Maternal Health; Child; Early Diagnosis; Length of Stay; Infant, Newborn; Male; Deep Learning; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11222373"
    },
    {
      "pmid": "33958261",
      "title": "Bias in a blink: Shedding light on implicit attitudes toward patients with a cleft lip.",
      "abstract": "INTRODUCTION: Previous studies have shown that patients with cleft lip and/or palate may be stigmatized in society. The objective of this study was to use an implicit association test to evaluate the subconscious biases of non-health care providers and orthodontists against patients with a repaired cleft lip (CL). METHODS: Respondents participated in an implicit association test. Pictures of patients with CL and controls were shown to participants, along with terms representing positive and negative attributes. Participants were prompted to match pictures to the attributes. The software algorithm detected whether the participants were more likely to associate CL with positive or negative terms than controls. Demographic information was collected to measure the association between some sociodemographic factors and implicit biases. RESULTS: Of 130 valid participants, 52 were orthodontists and 78 were non-health care providers. The entire sample displayed a significant implicit bias against CL (P\u00a0<0.001). Overall, orthodontists tended to exhibit slightly higher levels of implicit biases against CL than non-health care providers, but the difference was not significant when controlling for sociodemographic factors (P\u00a0=\u00a00.34). Females showed significantly lower implicit biases against CL than males (P\u00a0=\u00a00.046). Spearman correlations showed that older people and those who reported a more conservative political affiliation tended to show slightly higher levels of implicit biases against CL (P\u00a0<0.007). CONCLUSIONS: Orthodontists and non-health care providers showed moderate but significant levels of implicit biases against patients with clefts. Males, older age groups, and patients with a more conservative political affiliation tended to exhibit slightly higher levels of biases than females, younger people, and those with a more liberal political affiliation.",
      "authors": "Bous Rany M; Lyamichev Anthony; Kmentt Ashleigh; Valiathan Manish",
      "year": "2021",
      "journal": "American journal of orthodontics and dentofacial orthopedics : official publication of the American Association of Orthodontists, its constituent societies, and the American Board of Orthodontics",
      "doi": "10.1016/j.ajodo.2020.04.023",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33958261/",
      "mesh_terms": "Aged; Attitude of Health Personnel; Bias; Cleft Lip; Cleft Palate; Female; Humans; Male",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "31313407",
      "title": "Diffusion gradient nonlinearity bias correction reduces bias of breast cancer bone metastasis ADC values.",
      "abstract": "CONTRACT GRANT SPONSOR: Health Research Fund of Central Denmark Region. BACKGROUND: Diffusion gradient nonlinearity (DGNL) bias causes apparent diffusion coefficient (ADC) values to drop with increasing superior-inferior (SI) isocenter offset. This is a concern when performing quantitative diffusion-weighted imaging (DWI). PURPOSE/HYPOTHESIS: To investigate if DGNL ADC bias can be corrected in breast cancer bone metastases using a clinical DWI protocol and an online correction algorithm. STUDY TYPE: Prospective. SUBJECTS/PHANTOM: A diffusion phantom (Model 128, High Precision Devices, Boulder, CO) was used for in vitro validation. Twenty-three women with bone-metastasizing breast cancer were enrolled to assess DGNL correction in vivo. FIELD STRENGTH/SEQUENCE: DWI was performed on a 1.5T MRI system as single-shot, spin-echo, echo-planar imaging with short-tau inversion recovery (STIR) fat-saturation. ADC maps with and without DGNL correction were created from the b50 and b800 images. ASSESSMENT: Uncorrected and DGNL-corrected ADC values were measured in phantom and bone metastases by placing regions of interest on b800 images and copying them to the ADC map. The SI offset was recorded. STATISTICAL TESTS: In all, 79 bone metastases were assessed. ADC values with and without DGNL correction were compared at 14 cm SI offset using a two-tailed t-test. RESULTS: In the diffusion phantom, DGNL correction increased SI offset, where ADC bias was lower than 5%, from 7.3-13.8 cm. Of the 23 patients examined, six had no metastases in the covered regions. In the remaining patients, bias of uncorrected bone metastasis ADC values was 19.1% (95% confidence interval [CI]: 15.4-22.9%) at 14 cm SI offset. After DGNL correction, ADC bias was significantly reduced to 3.5% (95% CI: 0.7-6.3%, P\u2009<\u20090.001), thus reducing bias due to DGNL by 82%. DATA CONCLUSION: Online DGNL correction corrects DGNL ADC value bias and allows increased station lengths in the SI direction. LEVEL OF EVIDENCE: 2 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2020;51:904-911.",
      "authors": "Buus Thomas W; Jensen Anders B; Pedersen Erik M",
      "year": "2020",
      "journal": "Journal of magnetic resonance imaging : JMRI",
      "doi": "10.1002/jmri.26873",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31313407/",
      "mesh_terms": "Breast Neoplasms; Diffusion Magnetic Resonance Imaging; Female; Humans; Image Interpretation, Computer-Assisted; Prospective Studies; Reproducibility of Results",
      "keywords": "bone marrow diseases; breast neoplasms; diffusion magnetic resonance imaging; software validation",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35399912",
      "title": "Real-time data of COVID-19 detection with IoT sensor tracking using artificial neural network.",
      "abstract": "The coronavirus pandemic has affected people all over the world and posed a great challenge to international health systems. To aid early detection of coronavirus disease-2019 (COVID-19), this study proposes a real-time detection system based on the Internet of Things framework. The system collects real-time data from users to determine potential coronavirus cases, analyses treatment responses for people who have been treated, and accurately collects and analyses the datasets. Artificial intelligence-based algorithms are an alternative decision-making solution to extract valuable information from clinical data. This study develops a deep learning optimisation system that can work with imbalanced datasets to improve the classification of patients. A synthetic minority oversampling technique is applied to solve the problem of imbalance, and a recursive feature elimination algorithm is used to determine the most effective features. After data balance and extraction of features, the data are split into training and testing sets for validating all models. The experimental predictive results indicate good stability and compatibility of the models with the data, providing maximum accuracy of 98% and precision of 97%. Finally, the developed models are demonstrated to handle data bias and achieve high classification accuracy for patients with COVID-19. The findings of this study may be useful for healthcare organisations to properly prioritise assets.",
      "authors": "Mohammedqasem Roa'a; Mohammedqasim Hayder; Ata Oguz",
      "year": "2022",
      "journal": "Computers & electrical engineering : an international journal",
      "doi": "10.1016/j.compeleceng.2022.107971",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35399912/",
      "mesh_terms": "",
      "keywords": "ANN, Artificial Neural Network; AUC, Area Under Curve; CNN, Convolutional Neural Network; COVID-19; COVID-19, Coronavirus disease; DL, Deep learning; Imbalanced Dataset; Internet of Things; IoT, Internet of Things; ML, Machine learning; RFE, Recursive Feature Elimination; RNN, Recurrent Neural Network; Recursive feature elimination; SMOTE, Synthetic Minority Oversampling Technique; Synthetic minority oversampling technique",
      "pub_types": "Journal Article",
      "pmcid": "PMC8985446"
    },
    {
      "pmid": "38905988",
      "title": "Responsible AI for cardiovascular disease detection: Towards a privacy-preserving and interpretable model.",
      "abstract": "BACKGROUND AND OBJECTIVE: Cardiovascular disease (CD) is a major global health concern, affecting millions with symptoms like fatigue and chest discomfort. Timely identification is crucial due to its significant contribution to global mortality. In healthcare, artificial intelligence (AI) holds promise for advancing disease risk assessment and treatment outcome prediction. However, machine learning (ML) evolution raises concerns about data privacy and biases, especially in sensitive healthcare applications. The objective is to develop and implement a responsible AI model for CD prediction that prioritize patient privacy, security, ensuring transparency, explainability, fairness, and ethical adherence in healthcare applications. METHODS: To predict CD while prioritizing patient privacy, our study employed data anonymization involved adding Laplace noise to sensitive features like age and gender. The anonymized dataset underwent analysis using a differential privacy (DP) framework to preserve data privacy. DP ensured confidentiality while extracting insights. Compared with Logistic Regression (LR), Gaussian Na\u00efve Bayes (GNB), and Random Forest (RF), the methodology integrated feature selection, statistical analysis, and SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME) for interpretability. This approach facilitates transparent and interpretable AI decision-making, aligning with responsible AI development principles. Overall, it combines privacy preservation, interpretability, and ethical considerations for accurate CD predictions. RESULTS: Our investigations from the DP framework with LR were promising, with an area under curve (AUC) of 0.848 \u00b1 0.03, an accuracy of 0.797 \u00b1 0.02, precision at 0.789 \u00b1 0.02, recall at 0.797 \u00b1 0.02, and an F1 score of 0.787 \u00b1 0.02, with a comparable performance with the non-privacy framework. The SHAP and LIME based results support clinical findings, show a commitment to transparent and interpretable AI decision-making, and aligns with the principles of responsible AI development. CONCLUSIONS: Our study endorses a novel approach in predicting CD, amalgamating data anonymization, privacy-preserving methods, interpretability tools SHAP, LIME, and ethical considerations. This responsible AI framework ensures accurate predictions, privacy preservation, and user trust, underscoring the significance of comprehensive and transparent ML models in healthcare. Therefore, this research empowers the ability to forecast CD, providing a vital lifeline to millions of CD patients globally and potentially preventing numerous fatalities.",
      "authors": "Ferdowsi Mahbuba; Hasan Md Mahmudul; Habib Wafa",
      "year": "2024",
      "journal": "Computer methods and programs in biomedicine",
      "doi": "10.1016/j.cmpb.2024.108289",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38905988/",
      "mesh_terms": "Humans; Cardiovascular Diseases; Artificial Intelligence; Machine Learning; Bayes Theorem; Female; Male; Privacy; Logistic Models; Confidentiality; Algorithms; Middle Aged; Data Anonymization; Risk Assessment",
      "keywords": "Cardiovascular disease; Differential privacy; Explainable machine learning; Responsible artificial intelligence",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33665879",
      "title": "Accounting for selection bias due to death in estimating the effect of wealth shock on cognition for the Health and Retirement Study.",
      "abstract": "The Health and Retirement Study (HRS) is a longitudinal study of U.S. adults enrolled at age 50 and older. We were interested in investigating the effect of a sudden large decline in wealth on the cognitive ability of subjects measured using a dataset provided composite score. However, our analysis was complicated by the lack of randomization, time-dependent confounding, and a substantial fraction of the sample and population will die during follow-up leading to some of our outcomes being censored. The common method to handle this type of problem is marginal structural models (MSM). Although MSM produces valid estimates, this may not be the most appropriate method to reflect a useful real-world situation because MSM upweights subjects who are more likely to die to obtain a hypothetical population that over time, resembles that would have been obtained in the absence of death. A more refined and practical framework, principal stratification (PS), would be to restrict analysis to the strata of the population that would survive regardless of negative wealth shock experience. In this work, we propose a new algorithm for the estimation of the treatment effect under PS by imputing the counterfactual survival status and outcomes. Simulation studies suggest that our algorithm works well in various scenarios. We found no evidence that a negative wealth shock experience would affect the cognitive score of HRS subjects.",
      "authors": "Tan Yaoyuan Vincent; Flannagan Carol A C; Pool Lindsay R; Elliott Michael R",
      "year": "2021",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.8921",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33665879/",
      "mesh_terms": "Humans; Middle Aged; Bias; Cognition; Longitudinal Studies; Retirement; Selection Bias",
      "keywords": "Bayesian additive regression trees; causal inference; longitudinal study; missing data; penalized spline of propensity methods in treatment comparisons; time-dependent confounding",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41308403",
      "title": "Patient-reported postoperative pain and stigmatizing language in anesthesia notes: a cross-sectional study (2017-2019).",
      "abstract": "BACKGROUND: Stigmatizing language reflects provider bias. Researchers found that documentation of stigmatizing language in obstetric clinical notes differed by patient race and ethnicity. The purpose of this study was to examine associations between postoperative pain and stigmatizing language documented by anesthesiologists. METHODS: We studied the electronic health records of obstetric patients at two hospitals between 2017 and 2019 (n\u00a0=\u00a04383). Pain was defined as a verbal numerical pain score (VNPS) \u2265 1 following cesarean delivery or other operative procedure during the delivery hospitalization. Stigmatizing language was identified in the free-text narratives of postoperative anesthesia notes using a well-performing natural language processing algorithm. Multivariable logistic regression was employed to examine associations between pain and stigmatizing language. RESULTS: Stigmatizing language was found in 9.9% of postoperative notes. Patients with documented pain were significantly more likely to have any stigmatizing language documented by anesthesiologists compared with patients with no pain (adjusted odds ratio [aOR], 1.64; 95% confidence interval [CI], 1.26-2.13). Patients with pain were also significantly more likely to have language labeling them as 'difficult' (aOR, 1.81; 95% CI, 1.34-2.45). There were no significant differences between patients with and without postoperative pain in language related to marginalized language/identities, unilateral/authoritarian decisions, or questioning patient credibility categories. CONCLUSIONS: In this cross-sectional study, postpartum patients with pain had increased odds of stigmatizing language. Findings suggest anesthesiologists may perceive patients who report pain as being 'difficult.' Quality improvement studies should track inequities in pain management as patient-centered, bias-free care is crucial for improving perinatal equity.",
      "authors": "Harkins S E; Thomas C D; Hulchafo I I; Topaz M; Landau R; Barcelona V",
      "year": "2025",
      "journal": "International journal of obstetric anesthesia",
      "doi": "10.1016/j.ijoa.2025.104824",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41308403/",
      "mesh_terms": "",
      "keywords": "Clinician bias; Health equity; Natural language processing; Postpartum pain; Stigmatizing language",
      "pub_types": "Journal Article",
      "pmcid": "PMC12771282"
    },
    {
      "pmid": "40631724",
      "title": "Disaggregating Health Differences and Disparities With Machine Learning and Observed-to-expected Ratios: Application to Major Lower Limb Amputation.",
      "abstract": "BACKGROUND: Major lower limb amputation is a devastating but preventable complication of peripheral artery disease. It is unclear whether racial and ethnic and rural differences in amputation rates are due to clinical, hospital, or structural factors. METHODS: We included all peripheral artery disease hospitalizations of patients \u226540 years old between 2017 and 2019 in Florida, Georgia, Maryland, Mississippi, or New York (HCUP State Inpatient Databases). We estimated the expected number of amputations using three models: (1) unadjusted, (2) adjusted for clinical factors, and (3) adjusted for clinical factors, hospital factors, and social determinants of health using least absolute shrinkage and selection operator (LASSO). We calculated and compared observed-to-expected ratios and quantified the role of these factors in amputation rates. RESULTS: Overall, 1,577,061 hospitalizations (990,152 unique patients) and 21,233 major lower limb amputations (1.4%) were included. After accounting for clinical differences, we observed amputation disparities among rural Black, Hispanic, Native American, and White patients and nonrural Black and Native American patients. After accounting for hospital factors and social determinants of health, disparities were no longer present among rural White adults (0.93, 95% confidence interval [CI]: 0.77, 1.09); however, disparities persisted among rural Black (1.26, 95% CI: 1.01, 1.51), Hispanic (1.50, 95% CI: 0.89, 2.12), and Native American patients (1.13, 95% CI: 0.68, 1.58) and nonrural Black (1.12, 95% CI: 1.09, 1.15) and Native American (1.15, 95% CI: 0.86, 1.44) patients. CONCLUSION: Clinical factors did not fully explain differences in amputation rates, and hospital factors and social determinants of health did not fully explain disparities. These findings provide additional evidence that implicit bias is associated with amputation disparities.",
      "authors": "Strassle Paula D; Minc Samantha D; Kalbaugh Corey A; Donneyong Macarius M; Ko Jamie S; McGinigle Katharine L",
      "year": "2025",
      "journal": "Epidemiology (Cambridge, Mass.)",
      "doi": "10.1097/EDE.0000000000001892",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40631724/",
      "mesh_terms": "Humans; Amputation, Surgical; Male; Female; Middle Aged; Aged; Peripheral Arterial Disease; Lower Extremity; Machine Learning; Healthcare Disparities; Health Status Disparities; Adult; United States; Social Determinants of Health; Hospitalization; Rural Population",
      "keywords": "Healthcare disparities; Machine learning; Major lower limb amputation; Peripheral artery disease; Rural health; Social determinants of health; Surgical",
      "pub_types": "Journal Article",
      "pmcid": "PMC12400468"
    },
    {
      "pmid": "38844546",
      "title": "Assessing calibration and bias of a deployed machine learning malnutrition prediction model within a large healthcare system.",
      "abstract": "Malnutrition is a frequently underdiagnosed condition leading to increased morbidity, mortality, and healthcare costs. The Mount Sinai Health System (MSHS) deployed a machine learning model (MUST-Plus) to detect malnutrition upon hospital admission. However, in diverse patient groups, a poorly calibrated model may lead to misdiagnosis, exacerbating health care disparities. We explored the model's calibration across different variables and methods to improve calibration. Data from adult patients admitted to five MSHS hospitals from January 1, 2021 - December 31, 2022, were analyzed. We compared MUST-Plus prediction to the registered dietitian's formal assessment. Hierarchical calibration was assessed and compared between the recalibration sample (N\u2009=\u200949,562) of patients admitted between January 1, 2021 - December 31, 2022, and the hold-out sample (N\u2009=\u200917,278) of patients admitted between January 1, 2023 - September 30, 2023. Statistical differences in calibration metrics were tested using bootstrapping with replacement. Before recalibration, the overall model calibration intercept was -1.17 (95% CI: -1.20, -1.14), slope was 1.37 (95% CI: 1.34, 1.40), and Brier score was 0.26 (95% CI: 0.25, 0.26). Both weak and moderate measures of calibration were significantly different between White and Black patients and between male and female patients. Logistic recalibration significantly improved calibration of the model across race and gender in the hold-out sample. The original MUST-Plus model showed significant differences in calibration between White vs. Black patients. It also overestimated malnutrition in females compared to males. Logistic recalibration effectively reduced miscalibration across all patient subgroups. Continual monitoring and timely recalibration can improve model accuracy.",
      "authors": "Liou Lathan; Scott Erick; Parchure Prathamesh; Ouyang Yuxia; Egorova Natalia; Freeman Robert; Hofer Ira S; Nadkarni Girish N; Timsina Prem; Kia Arash; Levin Matthew A",
      "year": "2024",
      "journal": "NPJ digital medicine",
      "doi": "10.1038/s41746-024-01141-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38844546/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11156633"
    },
    {
      "pmid": "40933771",
      "title": "Bias correction for nonignorable missing counts of areal HIV new diagnosis.",
      "abstract": "Public health data, such as HIV new diagnoses, are often left-censored due to confidentiality issues. Standard analysis approaches that assume censored values as missing at random often lead to biased estimates and inferior predictions. Motivated by the Philadelphia areal counts of HIV new diagnosis for which all values less than or equal to 5 are suppressed, we propose two methods to reduce the adverse influence of missingness on predictions and imputation of areal HIV new diagnoses. One is the likelihood-based method that integrates the missing mechanism into the likelihood function, and the other is a nonparametric algorithm for matrix factorization imputation. Numerical studies and the Philadelphia data analysis demonstrate that the two proposed methods can significantly improve prediction and imputation based on left-censored HIV data. We also compare the two methods on their robustness to model misspecification and find that both methods appear to be robust for prediction, while their performance for imputation depends on model specification.",
      "authors": "Qu Tianyi; Li Bo; Chan Man-Pui Sally; Albarracin Dolores",
      "year": "2023",
      "journal": "Stat",
      "doi": "10.1002/sta4.555",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40933771/",
      "mesh_terms": "",
      "keywords": "left-censored; likelihood; matrix factorization; missing value; spatiotemporal data",
      "pub_types": "Journal Article",
      "pmcid": "PMC12419480"
    },
    {
      "pmid": "27460603",
      "title": "State-level estimates of childhood obesity prevalence in the United States corrected for report bias.",
      "abstract": "BACKGROUND/OBJECTIVES: State-specific obesity prevalence data are critical to public health efforts to address the childhood obesity epidemic. However, few states administer objectively measured body mass index (BMI) surveillance programs. This study reports state-specific childhood obesity prevalence by age and sex correcting for parent-reported child height and weight bias. SUBJECTS/METHODS: As part of the Childhood Obesity Intervention Cost Effectiveness Study (CHOICES), we developed childhood obesity prevalence estimates for states for the period 2005-2010 using data from the 2010 US Census and American Community Survey (ACS), 2003-2004 and 2007-2008 National Survey of Children's Health (NSCH) (n=133\u2009213), and 2005-2010 National Health and Nutrition Examination Surveys (NHANES) (n=9377; ages 2-17). Measured height and weight data from NHANES were used to correct parent-report bias in NSCH using a non-parametric statistical matching algorithm. Model estimates were validated against surveillance data from five states (AR, FL, MA, PA and TN) that conduct censuses of children across a range of grades. RESULTS: Parent-reported height and weight resulted in the largest overestimation of childhood obesity in males ages 2-5 years (NSCH: 42.36% vs NHANES: 11.44%). The CHOICES model estimates for this group (12.81%) and for all age and sex categories were not statistically different from NHANES. Our modeled obesity prevalence aligned closely with measured data from five validation states, with a 0.64 percentage point mean difference (range: 0.23-1.39) and a high correlation coefficient (r=0.96, P=0.009). Estimated state-specific childhood obesity prevalence ranged from 11.0 to 20.4%. CONCLUSION: Uncorrected estimates of childhood obesity prevalence from NSCH vary widely from measured national data, from a 278% overestimate among males aged 2-5 years to a 44% underestimate among females aged 14-17 years. This study demonstrates the validity of the CHOICES matching methods to correct the bias of parent-reported BMI data and highlights the need for public release of more recent data from the 2011 to 2012 NSCH.",
      "authors": "Long M W; Ward Z J; Resch S C; Cradock A L; Wang Y C; Giles C M; Gortmaker S L",
      "year": "2016",
      "journal": "International journal of obesity (2005)",
      "doi": "10.1038/ijo.2016.130",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27460603/",
      "mesh_terms": "Adolescent; Body Mass Index; Child; Child, Preschool; Female; Humans; Male; Nutrition Surveys; Parents; Pediatric Obesity; Policy Making; Prevalence; Public Health; Public Health Surveillance; Self Report; United States",
      "keywords": "",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC8966206"
    },
    {
      "pmid": "38880237",
      "title": "Assessing inclusion and representativeness on digital platforms for health education: Evidence from YouTube.",
      "abstract": "BACKGROUND: Studies confirm that significant biases exist in online recommendation platforms, exacerbating pre-existing disparities and leading to less-than-optimal outcomes for underrepresented demographics. We study issues of bias in inclusion and representativeness in the context of healthcare information disseminated via videos on the YouTube social media platform, a widely used online channel for multi-media rich information. With one in three US adults using the Internet to learn about a health concern, it is critical to assess inclusivity and representativeness regarding how health information is disseminated by digital platforms such as YouTube. METHODS: Leveraging methods from fair machine learning (ML), natural language processing and voice and facial recognition methods, we examine inclusivity and representativeness of video content presenters using a large corpus of videos and their metadata on a chronic condition (diabetes) extracted from the YouTube platform. Regression models are used to determine whether presenter demographics impact video popularity, measured by the video's average daily view count. A video that generates a higher view count is considered to be more popular. RESULTS: The voice and facial recognition methods predicted the gender and race of the presenter with reasonable success. Gender is predicted through voice recognition (accuracy\u00a0=\u00a078%, AUC\u00a0=\u00a076%), while the gender and race predictions use facial recognition (accuracy\u00a0=\u00a093%, AUC\u00a0=\u00a092% and accuracy\u00a0=\u00a082%, AUC\u00a0=\u00a080%, respectively). The gender of the presenter is more significant for video views only when the face of the presenter is not visible while videos with male presenters with no face visibility have a positive relationship with view counts. Furthermore, videos with white and male presenters have a positive influence on view counts while videos with female and non - white group have high view counts. CONCLUSION: Presenters' demographics do have an influence on average daily view count of videos viewed on social media platforms as shown by advanced voice and facial recognition algorithms used for assessing inclusion and representativeness of the video content. Future research can explore short videos and those at the channel level because popularity of the channel name and the number of videos associated with that channel do have an influence on view counts.",
      "authors": "Pothugunta Krishna; Liu Xiao; Susarla Anjana; Padman Rema",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2024.104669",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38880237/",
      "mesh_terms": "Humans; Social Media; Natural Language Processing; Machine Learning; Health Education; Male; Female; Video Recording; Adult",
      "keywords": "Inclusivity; Machine Learning; Natural Language Processing; Representativeness; Syntactic Analysis; Textual Analytics, Metadata; Voice and Facial Recognition",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": ""
    },
    {
      "pmid": "33651310",
      "title": "Excavating FAIR Data: the Case of the Multicenter Animal Spinal Cord Injury Study (MASCIS), Blood Pressure, and Neuro-Recovery.",
      "abstract": "Meta-analyses suggest that the published literature represents only a small minority of the total data collected in biomedical research, with most becoming 'dark data' unreported in the literature. Dark data is due to publication bias toward novel results that confirm investigator hypotheses and omission of data that do not. Publication bias contributes to scientific irreproducibility and failures in bench-to-bedside translation. Sharing dark data by making it Findable, Accessible, Interoperable, and Reusable (FAIR) may reduce the burden of irreproducible science by increasing transparency and support data-driven discoveries beyond the lifecycle of the original study. We illustrate feasibility of dark data sharing by recovering original raw data from the Multicenter Animal Spinal Cord Injury Study (MASCIS), an NIH-funded multi-site preclinical drug trial conducted in the 1990s that tested efficacy of several therapies after a spinal cord injury (SCI). The original drug treatments did not produce clear positive results and MASCIS data were stored in boxes for more than two decades. The goal of the present study was to independently confirm published machine learning findings that perioperative blood pressure is a major predictor of SCI neuromotor outcome (Nielson et al., 2015). We recovered, digitized, and curated the data from 1125 rats from MASCIS. Analyses indicated that high perioperative blood pressure at the time of SCI is associated with poorer health and worse neuromotor outcomes in more severe SCI, whereas low perioperative blood pressure is associated with poorer health and worse neuromotor outcome in moderate SCI. These findings confirm and expand prior results that a narrow window of blood-pressure control optimizes outcome, and demonstrate the value of recovering dark data for assessing reproducibility of findings with implications for precision therapeutic approaches.",
      "authors": "Almeida Carlos A; Torres-Espin Abel; Huie J Russell; Sun Dongming; Noble-Haeusslein Linda J; Young Wise; Beattie Michael S; Bresnahan Jacqueline C; Nielson Jessica L; Ferguson Adam R",
      "year": "2022",
      "journal": "Neuroinformatics",
      "doi": "10.1007/s12021-021-09512-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33651310/",
      "mesh_terms": "Animals; Blood Pressure; Rats; Reproducibility of Results; Spinal Cord Injuries",
      "keywords": "Autonomic; Data science; Hemodynamics; Metascience; Motor recovery; Neurotrauma; Reproducibility; Spinal contusion",
      "pub_types": "Journal Article; Multicenter Study; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9015816"
    },
    {
      "pmid": "35185011",
      "title": "Use of a community advisory board to build equitable algorithms for participation in clinical trials: a protocol paper for HoPeNET.",
      "abstract": "INTRODUCTION: Participation from racial and ethnic minorities in clinical trials has been burdened by issues surrounding mistrust and access to healthcare. There is emerging use of machine learning (ML) in clinical trial recruitment and evaluation. However, for individuals from groups who are recipients of societal biases, utilisation of ML can lead to the creation and use of biased algorithms. To minimise bias, the design of equitable ML tools that advance health equity could be guided by community engagement processes. The Howard University Partnership with the National Institutes of Health for Equitable Clinical Trial Participation for Racial/Ethnic Communities Underrepresented in Research (HoPeNET) seeks to create an ML-based infrastructure from community advisory board (CAB) experiences to enhance participation of African-Americans/Blacks in clinical trials. METHODS AND ANALYSIS: This triphased cross-sectional study (24 months, n=56) will create a CAB of community members and research investigators. The three phases of the study include: (1) identification of perceived barriers/facilitators to clinical trial engagement through qualitative/quantitative methods and systems-based model building participation; (2) operation of CAB meetings and (3) development of a predictive ML tool and outcome evaluation. Identified predictors from the participant-derived systems-based map will be used for the ML tool development. ETHICS AND DISSEMINATION: We anticipate minimum risk for participants. Institutional review board approval and informed consent has been obtained and patient confidentiality ensured.",
      "authors": "Farmer Nicole; Osei Baah Foster; Williams Faustine; Ortiz-Chapparo Erika; Mitchell Valerie M; Jackson Latifa; Collins Billy; Graham Lennox; Wallen Gwenyth R; Powell-Wiley Tiffany M; Johnson Allan",
      "year": "2022",
      "journal": "BMJ health & care informatics",
      "doi": "10.1136/bmjhci-2021-100453",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35185011/",
      "mesh_terms": "Algorithms; Clinical Trials as Topic; Cross-Sectional Studies; Humans; Patient Selection",
      "keywords": "BMJ health informatics; artificial intelligence; health equity",
      "pub_types": "Journal Article",
      "pmcid": "PMC8860013"
    },
    {
      "pmid": "24049156",
      "title": "Disability and chronic disease among older adults in India: detecting vulnerable populations through the WHO SAGE Study.",
      "abstract": "Chronic noncommunicable diseases (NCDs) are now prevalent in many low- and middle-income countries and confer a heightened risk of disability. It is unclear how public health programs can identify the older adults at highest risk of disability related to NCDs within diverse developing country populations. We studied nationally representative survey data from 7,150 Indian adults older than 50 years of age who participated in the World Health Organization Study on Global Aging and Adult Health (2007-2010) to identify population subgroups who are highly disabled. Using machine-learning algorithms, we identified sociodemographic correlates of disability. Although having 2 or more symptomatic NCDs was a key correlate of disability, the prevalence of symptomatic, undiagnosed NCDs was highest among the lowest 2 wealth quintiles of Indian adults, contrary to prior hypotheses of increased NCDs with wealth. Women and persons from rural populations were also disproportionately affected by nondiagnosed NCDs, with high out-of-pocket health care expenditures increasing the probability of remaining symptomatic from NCDs. These findings also indicate that NCD prevalence surveillance studies in low- and middle-income countries should expand beyond self-reported diagnoses to include more extensive symptom- and examination-based surveys, given the likely high rate of surveillance bias due to barriers to diagnosis among vulnerable populations.",
      "authors": "Basu Sanjay; King Abby C",
      "year": "2013",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwt191",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24049156/",
      "mesh_terms": "Aged; Aged, 80 and over; Algorithms; Artificial Intelligence; Chronic Disease; Cross-Sectional Studies; Developing Countries; Disability Evaluation; Female; Health Surveys; Humans; India; Male; Middle Aged; Population Surveillance; Prevalence; Risk Factors; Self Report; Socioeconomic Factors; Vulnerable Populations; World Health Organization",
      "keywords": "India; chronic disease; developing countries; disability; vulnerable populations",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC3842902"
    },
    {
      "pmid": "39475765",
      "title": "Perceptions Toward Using Artificial Intelligence and Technology for Asthma Attack Risk Prediction: Qualitative Exploration of M\u0101ori Views.",
      "abstract": "BACKGROUND: Asthma is a significant global health issue, impacting over 500,000 individuals in New Zealand and disproportionately affecting M\u0101ori communities in New Zealand, who experience worse asthma symptoms and attacks. Digital technologies, including artificial intelligence (AI) and machine learning (ML) models, are increasingly popular for asthma risk prediction. However, these AI models may underrepresent minority ethnic groups and introduce bias, potentially exacerbating disparities. OBJECTIVE: This study aimed to explore the views and perceptions that M\u0101ori have toward using AI and ML technologies for asthma self-management, identify key considerations for developing asthma attack risk prediction models, and ensure M\u0101ori are represented in ML models without worsening existing health inequities. METHODS: Semistructured interviews were conducted with 20 M\u0101ori participants with asthma, 3 male and 17 female, aged 18-76 years. All the interviews were conducted one-on-one, except for 1 interview, which was conducted with 2 participants. Altogether, 10 web-based interviews were conducted, while the rest were kanohi ki te kanohi (face-to-face). A thematic analysis was conducted to identify the themes. Further, sentiment analysis was carried out to identify the sentiments using a pretrained Bidirectional Encoder Representations from Transformers model. RESULTS: We identified four key themes: (1) concerns about AI use, (2) interest in using technology to support asthma, (3) desired characteristics of AI-based systems, and (4) experience with asthma management and opportunities for technology to improve care. AI was relatively unfamiliar to many participants, and some of them expressed concerns about whether AI technology could be trusted, kanohi ki te kanohi interaction, and inadequate knowledge of AI and technology. These concerns are exacerbated by the M\u0101ori experience of colonization. Most of the participants were interested in using technology to support their asthma management, and we gained insights into user preferences regarding computer-based health care applications. Participants discussed their experiences, highlighting problems with health care quality and limited access to resources. They also mentioned the factors that trigger their asthma control level. CONCLUSIONS: The exploration revealed that there is a need for greater information about AI and technology for M\u0101ori communities and a need to address trust issues relating to the use of technology. Expectations in relation to computer-based applications for health purposes were expressed. The research outcomes will inform future investigations on AI and technology to enhance the health of people with asthma, in particular those designed for Indigenous populations in New Zealand.",
      "authors": "Jayamini Widana Kankanamge Darsha; Mirza Farhaan; Bidois-Putt Marie-Claire; Naeem M Asif; Chan Amy Hai Yan",
      "year": "2024",
      "journal": "JMIR formative research",
      "doi": "10.2196/59811",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39475765/",
      "mesh_terms": "Adolescent; Adult; Aged; Female; Humans; Male; Middle Aged; Young Adult; Artificial Intelligence; Asthma; Maori People; New Zealand; Qualitative Research; Risk Assessment",
      "keywords": "artificial intelligence; asthma risk prediction; health system development; machine learning; mobile phone; m\u0101ori perceptions",
      "pub_types": "Journal Article",
      "pmcid": "PMC11561449"
    },
    {
      "pmid": "30805035",
      "title": "Extending Tests of Random Effects to Assess for Measurement Invariance in Factor Models.",
      "abstract": "Factor analysis models are widely used in health research to summarize hard to measure predictor or outcome variable constructs. For example, in the ELEMENT study, factor models are used to summarize lead exposure biomarkers which are thought to indirectly measure prenatal exposure to lead. Classic latent factor models are fitted assuming that factor loadings are constant across all covariate levels (e.g., maternal age in ELEMENT); that is, measurement invariance (MI) is assumed. When the MI is not met, measurement bias is introduced. Traditionally, MI is examined by defining subgroups of the data based on covariates, fitting multi-group factor analysis, and testing differences in factor loadings across covariate groups. In this paper, we develop novel tests of measurement invariance by modeling the factor loadings as varying coeffcients, i.e., letting the factor loading vary across continuous covariate values instead of groups. These varying coeffcients are estimated using penalized splines, where spline coeffcients are penalized by treating them as random coeffcients. The test of MI is then carried out by conducting a likelihood ratio test for the null hypothesis that the variance of the random spline coeffcients equals zero. We use a Monte-Carlo EM algorithm for estimation, and obtain the likelihood using Monte-Carlo in tegration. Using simulations, we compare the Type I error and power of our testing approach and the multi-group testing method. We apply the proposed methods to to summarize data on prenatal biomarkers of lead exposure from the ELEMENT study and find violations of MI due to maternal age.",
      "authors": "Zhang Zhenzhen; Braun Thomas M; Peterson Karen E; Hu Howard; T\u00e9llez-Rojo Martha M; S\u00e1nchez Brisa N",
      "year": "2018",
      "journal": "Statistics in biosciences",
      "doi": "10.1007/s12561-018-9222-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30805035/",
      "mesh_terms": "",
      "keywords": "Measurement invariance; Monte-Carlo EM algorithm; Testing variance components",
      "pub_types": "Journal Article",
      "pmcid": "PMC6385881"
    },
    {
      "pmid": "38638465",
      "title": "Optimal site selection strategies for urban parks green spaces under the joint perspective of spatial equity and social equity.",
      "abstract": "Urban park green spaces (UPGS) are a crucial element of social public resources closely related to the health and well-being of urban residents, and issues of equity have always been a focal point of concern. This study takes the downtown area of Nanchang as an example and uses more accurate point of interest (POI) and area of interest (AOI) data as analysis sources. The improved Gaussian two-step floating catchment area (G2SFCA) and spatial autocorrelation models are then used to assess the spatial and social equity in the study area, and the results of the two assessments were coupled to determine the optimization objective using the community as the smallest unit. Finally, the assessment results are combined with the k-means algorithm and particle swarm algorithm (PSO) to propose practical optimization strategies with the objectives of minimum walking distance and maximum fairness. The results indicate (1) There are significant differences in UPGS accessibility among residents with different walking distances, with the more densely populated Old Town and Honggu Tan areas having lower average accessibility and being the main areas of hidden blindness, while the fringe areas in the northern and south-western parts of the city are the main areas of visible blindness. (2) Overall, the UPGS accessibility in Nanchang City exhibits a spatial pattern of decreasing from the east, south, and west to the center. Nanchang City is in transition towards improving spatial and social equity while achieving basic regional equity. (3) There is a spatial positive correlation between socioeconomic level and UPGS accessibility, reflecting certain social inequity. (4) Based on the above research results, the UPGS layout optimization scheme was proposed, 29 new UPGS locations and regions were identified, and the overall accessibility was improved by 2.76. The research methodology and framework can be used as a tool to identify the underserved areas of UPGS and optimize the spatial and social equity of UPGS, which is in line with the current trend of urban development in the world and provides a scientific basis for urban infrastructure planning and spatial resource allocation.",
      "authors": "Zhao Youqiang; Gong Peng",
      "year": "2024",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2024.1310340",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38638465/",
      "mesh_terms": "Humans; Parks, Recreational; Cities; Spatial Analysis; Social Class; Blindness",
      "keywords": "Gaussian two-step floating catchment area; accessibility; park quality; social equity; spatial equity; urban park green spaces",
      "pub_types": "Journal Article",
      "pmcid": "PMC11024374"
    },
    {
      "pmid": "34312839",
      "title": "Use of behavioral health care in Medicaid managed care carve-out versus carve-in arrangements.",
      "abstract": "OBJECTIVE: To evaluate differences in access to behavioral health services for Medicaid enrollees covered by a Medicaid entity that integrated the financing of behavioral and physical health care (\"carve-in group\") versus a Medicaid entity that separated this financing (\"carve-out group\"). DATA SOURCES/STUDY SETTING: Medicaid claims data from two Medicaid entities in the Portland, Oregon tri-county area in 2016. STUDY DESIGN: In this cross-sectional study, we compared differences across enrollees in the carve-in versus carve-out group, using a machine learning approach to incorporate a large set of covariates and minimize potential selection bias. Our primary outcomes included behavioral health visits for a variety of different provider types. Secondary outcomes included inpatient, emergency department, and primary care visits. DATA COLLECTION: We used Medicaid claims, including adults with at least 9 months of enrollment. PRINCIPAL FINDINGS: The study population included 45,786 adults with mental health conditions. Relative to the carve-out group, individuals in the carve-in group were more likely to access outpatient behavioral health (2.39 percentage points, p\u00a0<\u20090.0001, with a baseline rate of approximately 73%). The carve-in group was also more likely to access primary care physicians, psychologists, and social workers and less likely to access psychiatrists and behavioral health specialists. Access to outpatient behavioral health visits was more likely in the carve-in arrangement among individuals with mild or moderate mental health conditions (compared to individuals with severe mental illness) and among black enrollees (compared to white enrollees). CONCLUSIONS: Financial integration of physical and behavioral health in Medicaid managed care was associated with greater access to behavioral health services, particularly for individuals with mild or moderate mental health conditions and for black enrollees. Recent changes to incentivize financial integration should be monitored to assess differential impacts by illness severity, race and ethnicity, provider types, and other factors.",
      "authors": "Charlesworth Christina J; Zhu Jane M; Horvitz-Lennon Marcela; McConnell K John",
      "year": "2021",
      "journal": "Health services research",
      "doi": "10.1111/1475-6773.13703",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34312839/",
      "mesh_terms": "Adolescent; Adult; Contracts; Cross-Sectional Studies; Female; Health Care Rationing; Health Services Accessibility; Humans; Male; Managed Care Programs; Medicaid; Mental Health Services; Middle Aged; Oregon; Primary Health Care; Referral and Consultation; Reimbursement, Incentive; Sociodemographic Factors; United States; Young Adult",
      "keywords": "Medicaid; managed care; mental health",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC8522561"
    },
    {
      "pmid": "34083673",
      "title": "Automatic and unbiased segmentation and quantification of myofibers in skeletal muscle.",
      "abstract": "Skeletal muscle has the remarkable ability to regenerate. However, with age and disease muscle strength and function decline. Myofiber size, which is affected by injury and disease, is a critical measurement to assess muscle health. Here, we test and apply Cellpose, a recently developed deep learning algorithm, to automatically segment myofibers within murine skeletal muscle. We first show that tissue fixation is necessary to preserve cellular structures such as primary cilia, small cellular antennae, and adipocyte lipid droplets. However, fixation generates heterogeneous myofiber labeling, which impedes intensity-based segmentation. We demonstrate that Cellpose efficiently delineates thousands of individual myofibers outlined by a variety of markers, even within fixed tissue with highly uneven myofiber staining. We created a novel ImageJ plugin (LabelsToRois) that allows processing\u00a0of multiple Cellpose segmentation images in batch. The plugin also contains a semi-automatic erosion function to correct for the area bias introduced by the different stainings, thereby\u00a0identifying myofibers as accurately as human experts. We successfully applied our segmentation pipeline to uncover myofiber regeneration differences between two different muscle injury models, cardiotoxin and glycerol. Thus, Cellpose combined with LabelsToRois allows for fast, unbiased, and reproducible myofiber quantification for a variety of staining and fixation conditions.",
      "authors": "Waisman Ariel; Norris Alessandra Marie; El\u00edas Costa Mart\u00edn; Kopinke Daniel",
      "year": "2021",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-021-91191-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34083673/",
      "mesh_terms": "Algorithms; Animals; Computational Biology; Histocytochemistry; Image Processing, Computer-Assisted; Mice; Microscopy; Muscle Fibers, Skeletal; Muscle, Skeletal; Software",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8175575"
    },
    {
      "pmid": "40639839",
      "title": "Bias in vital signs? Machine learning models can learn patients' race or ethnicity from the values of vital signs alone.",
      "abstract": "OBJECTIVES: To investigate whether machine learning (ML) algorithms can learn racial or ethnic information from the vital signs alone. METHODS: A retrospective cohort study of critically ill patients between 2014 and 2015 from the multicentre eICU-CRD critical care database involving 335 intensive care units in 208 US hospitals, containing 200\u2009859 admissions. We extracted 10\u2009763 critical care admissions of patients aged 18 and over, alive during the first 24 hours after admission, with recorded race or ethnicity as well as at least two measurements of heart rate, oxygen saturation, respiratory rate and blood pressure. Pairs of subgroups were matched based on age, gender, admission diagnosis and disease severity. XGBoost, Random Forest and Logistic Regression algorithms were used to predict recorded race or ethnicity based on the values of vital signs. RESULTS: Models derived from only four vital signs can predict patients' recorded race or ethnicity with an area under the curve (AUC) of 0.74 (\u00b10.030) between White and Black patients, AUC of 0.74 (\u00b10.030) between Hispanic and Black patients and AUC of 0.67 (\u00b10.072) between Hispanic and White patients, even when controlling for known factors. There were very small, but statistically significant differences between heart rate, oxygen saturation and blood pressure, but not respiration rate and invasively measured oxygen saturation. DISCUSSION: ML algorithms can extract racial or ethnicity information from vital signs alone across diverse patient populations, even when controlling for known biases such as pulse oximetry variations and comorbidities. The model correctly classified the race or ethnicity in two out of three patients, indicating that this outcome is not random. CONCLUSION: Vital signs embed racial information that can be learnt by ML algorithms, posing a significant risk to equitable clinical decision-making. Mitigating measures might be challenging, considering the fundamental role of vital signs in clinical decision-making.",
      "authors": "Velichkovska Bojana; Gjoreski Hristijan; Denkovski Daniel; Kalendar Marija; Mullan Irene Dankwa; Wawira Gichoya Judy; Martinez Nicole; Celi Leo; Osmani Venet",
      "year": "2025",
      "journal": "BMJ health & care informatics",
      "doi": "10.1136/bmjhci-2024-101098",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40639839/",
      "mesh_terms": "Humans; Machine Learning; Vital Signs; Retrospective Studies; Male; Female; Middle Aged; Ethnicity; Aged; Racial Groups; Intensive Care Units; Adult; United States; Critical Illness; Algorithms; Bias; Respiratory Rate; Heart Rate",
      "keywords": "Artificial intelligence; Decision Support Systems, Clinical; Electronic Health Records; Health Equity",
      "pub_types": "Journal Article; Multicenter Study",
      "pmcid": "PMC12258377"
    },
    {
      "pmid": "40144330",
      "title": "Artificial Intelligence to Promote Racial and Ethnic Cardiovascular Health Equity.",
      "abstract": "PURPOSE OF REVIEW: The integration of artificial intelligence (AI) in medicine holds promise for transformative advancements aimed at improving healthcare outcomes. Amidst this promise, AI has been envisioned as a tool to detect and mitigate racial and ethnic inequity known to plague current cardiovascular care. However, this enthusiasm is dampened by the recognition that AI itself can harbor and propagate biases, necessitating a careful approach to ensure equity. This review highlights topics in the landscape of AI in cardiology, its role in identifying and addressing healthcare inequities, promoting diversity in research, concerns surrounding its applications, and proposed strategies for fostering equitable utilization. RECENT FINDINGS: Artificial intelligence has proven to be a valuable tool for clinicians in diagnosing and mitigating racial and ethnic inequities in cardiology, as well as the promotion of diversity in research. This promise is counterbalanced by the cautionary reality that AI can inadvertently perpetuate existent biases stemming from limited diversity in training data, inherent biases within datasets, and inadequate bias detection and monitoring mechanisms. Recognizing these concerns, experts emphasize the need for rigorous efforts to address these limitations in the development and deployment of AI within medicine. SUMMARY: Implementing AI in cardiovascular care to identify and address racial and ethnic inequities requires careful design and execution, beginning with meticulous data collection and a thorough review of training datasets. Furthermore, ensuring equitable performance involves rigorous testing and continuous surveillance of algorithms. Lastly, the promotion of diversity in the AI workforce and engagement of stakeholders are crucial to the advancement of equity to ultimately realize the potential for artificial intelligence for cardiovascular health equity.",
      "authors": "Amponsah Daniel; Thamman Ritu; Brandt Eric; James Cornelius; Spector-Bagdady Kayte; Yong Celina M",
      "year": "2024",
      "journal": "Current cardiovascular risk reports",
      "doi": "10.1007/s12170-024-00745-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40144330/",
      "mesh_terms": "",
      "keywords": "Artificial Intelligence; Cardiovascular Equity; Disparities; Diversity; Machine Learning; Racial and Ethnic Inequity",
      "pub_types": "Journal Article",
      "pmcid": "PMC11938301"
    },
    {
      "pmid": "32298232",
      "title": "The Association Between State-Level Racial Attitudes Assessed From Twitter Data and Adverse Birth Outcomes: Observational Study.",
      "abstract": "BACKGROUND: In the United States, racial disparities in birth outcomes persist and have been widening. Interpersonal and structural racism are leading explanations for the continuing racial disparities in birth outcomes, but research to confirm the role of racism and evaluate trends in the impact of racism on health outcomes has been hampered by the challenge of measuring racism. Most research on discrimination relies on self-reported experiences of discrimination, and few studies have examined racial attitudes and bias at the US national level. OBJECTIVE: This study aimed to investigate the associations between state-level Twitter-derived sentiments related to racial or ethnic minorities and birth outcomes. METHODS: We utilized Twitter's Streaming application programming interface to collect 26,027,740 tweets from June 2015 to December 2017, containing at least one race-related term. Sentiment analysis was performed using support vector machine, a supervised machine learning model. We constructed overall indicators of sentiment toward minorities and sentiment toward race-specific groups. For each year, state-level Twitter-derived sentiment data were merged with birth data for that year. The study participants were women who had singleton births with no congenital abnormalities from 2015 to 2017 and for whom data were available on gestational age (n=9,988,030) or birth weight (n=9,985,402). The main outcomes were low birth weight (birth weight \u22642499 g) and preterm birth (gestational age <37 weeks). We estimated the incidence ratios controlling for individual-level maternal characteristics (sociodemographics, prenatal care, and health behaviors) and state-level demographics, using log binomial regression models. RESULTS: The accuracy for identifying negative sentiments on comparing the machine learning model to manually labeled tweets was 91%. Mothers living in states in the highest tertile for negative sentiment tweets referencing racial or ethnic minorities had greater incidences of low birth weight (8% greater, 95% CI 4%-13%) and preterm birth (8% greater, 95% CI 0%-14%) compared with mothers living in states in the lowest tertile. More negative tweets referencing minorities were associated with adverse birth outcomes in the total population, including non-Hispanic white people and racial or ethnic minorities. In stratified subgroup analyses, more negative tweets referencing specific racial or ethnic minority groups (black people, Middle Eastern people, and Muslims) were associated with poor birth outcomes for black people and minorities. CONCLUSIONS: A negative social context related to race was associated with poor birth outcomes for racial or ethnic minorities, as well as non-Hispanic white people.",
      "authors": "Nguyen Thu T; Adams Nikki; Huang Dina; Glymour M Maria; Allen Amani M; Nguyen Quynh C",
      "year": "2020",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/17103",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32298232/",
      "mesh_terms": "Adult; Female; Geographic Mapping; Humans; Male; Pregnancy; Pregnancy Outcome; Racial Groups; Racism; Social Media; United States",
      "keywords": "birth outcomes; racial bias; racial or ethnic minorities; social media",
      "pub_types": "Journal Article; Observational Study; Research Support, N.I.H., Extramural",
      "pmcid": "PMC7381033"
    },
    {
      "pmid": "29698153",
      "title": "Health-Related Quality-of-Life Measures: Evidence from Tunisian Population Using the SF-12 Health Survey.",
      "abstract": "OBJECTIVE: To explore reporting differences related to sociodemographic characteristics affecting different health status indicators to assess their impact on the measurement of self-reported health status among the Tunisian population using the Tunisian version of the 12-item Short-Form Health Survey (SF-12). METHODS: Psychometric properties of the SF-12 were validated for a random sample of individuals (N = 3864) aged 18 years and older. The SF-12 summary scores were derived using the standard US algorithm. The principal-component analysis was used to confirm the hypothesized component structure of the SF-12 items. RESULTS: \"Known-subgroup\" comparisons showed that the SF-12 discriminated well between groups of respondents on the basis of sex, age, education, and socioeconomic status, providing evidence of construct validity. The results suggest the existence of reporting differences related to the sociodemographic characteristics affecting the health status indicators. For a given latent health status, women and oldest people are more likely to report physical activity limitations and chronic diseases. Mental health problems are overreported by divorced people and underreported by the oldest people. In addition, highly educated and socially advantaged people more often report social activities limitations due to the problems of physical and mental health. CONCLUSIONS: The findings showed that the Tunisian version of the SF-12 is a reliable and valid measure, and suggest its potential for measuring health-related quality of life in large-scale studies, specifically when overall physical and mental health are the outcomes of interest instead of the typical eight-scale profile.",
      "authors": "Younsi Moheddine",
      "year": "2015",
      "journal": "Value in health regional issues",
      "doi": "10.1016/j.vhri.2015.07.004",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29698153/",
      "mesh_terms": "",
      "keywords": "SF-12; Tunisia; health-related quality-of-life measures; reporting bias",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32064914",
      "title": "Assessing and Mitigating Bias in Medical Artificial Intelligence: The Effects of Race and Ethnicity on a Deep Learning Model for ECG Analysis.",
      "abstract": "BACKGROUND: Deep learning algorithms derived in homogeneous populations may be poorly generalizable and have the potential to reflect, perpetuate, and even exacerbate racial/ethnic disparities in health and health care. In this study, we aimed to (1) assess whether the performance of a deep learning algorithm designed to detect low left ventricular ejection fraction using the 12-lead ECG varies by race/ethnicity and to (2) determine whether its performance is determined by the derivation population or by racial variation in the ECG. METHODS: We performed a retrospective cohort analysis that included 97 829 patients with paired ECGs and echocardiograms. We tested the model performance by race/ethnicity for convolutional neural network designed to identify patients with a left ventricular ejection fraction \u226435% from the 12-lead ECG. RESULTS: The convolutional neural network that was previously derived in a homogeneous population (derivation cohort, n=44 959; 96.2% non-Hispanic white) demonstrated consistent performance to detect low left ventricular ejection fraction across a range of racial/ethnic subgroups in a separate testing cohort (n=52 870): non-Hispanic white (n=44 524; area under the curve [AUC], 0.931), Asian (n=557; AUC, 0.961), black/African American (n=651; AUC, 0.937), Hispanic/Latino (n=331; AUC, 0.937), and American Indian/Native Alaskan (n=223; AUC, 0.938). In secondary analyses, a separate neural network was able to discern racial subgroup category (black/African American [AUC, 0.84], and white, non-Hispanic [AUC, 0.76] in a 5-class classifier), and a network trained only in non-Hispanic whites from the original derivation cohort performed similarly well across a range of racial/ethnic subgroups in the testing cohort with an AUC of at least 0.930 in all racial/ethnic subgroups. CONCLUSIONS: Our study demonstrates that while ECG characteristics vary by race, this did not impact the ability of a convolutional neural network to predict low left ventricular ejection fraction from the ECG. We recommend reporting of performance among diverse ethnic, racial, age, and sex groups for all new artificial intelligence tools to ensure responsible use of artificial intelligence in medicine.",
      "authors": "Noseworthy Peter A; Attia Zachi I; Brewer LaPrincess C; Hayes Sharonne N; Yao Xiaoxi; Kapa Suraj; Friedman Paul A; Lopez-Jimenez Francisco",
      "year": "2020",
      "journal": "Circulation. Arrhythmia and electrophysiology",
      "doi": "10.1161/CIRCEP.119.007988",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32064914/",
      "mesh_terms": "Artificial Intelligence; Deep Learning; Electrocardiography; Ethnicity; Female; Follow-Up Studies; Heart Ventricles; Humans; Male; Middle Aged; Racial Groups; Retrospective Studies; Ventricular Function, Left",
      "keywords": "United States; artificial intelligence; electrocardiography; humans; machine learning",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC7158877"
    },
    {
      "pmid": "41299259",
      "title": "Prevalence of headache disorders in Norway: results from the population based PopHEAD study.",
      "abstract": "BACKGROUND: Reliable and up-to-date prevalence estimates of headache disorders are essential for public health planning. Despite previous large-scale studies, there is a lack of validated and up-to-date population-representative prevalence estimates from Europe. Here, we aimed to estimate the one-year prevalence of the major headache disorders in Norway using a validated diagnostic tool. METHODS: PopHEAD is a population-based Norwegian cross-sectional study. A random sample of 28,753 individuals aged 18\u201370 years was invited to complete a digital version of the Headache-Attributed Restriction, Disability, Social Handicap and Impaired Participation (HARDSHIP) questionnaire, adapted and translated into Norwegian. Headache diagnoses were made using a standardized algorithm based on the International Classification of Headache Disorders (ICHD-3) criteria and validated by telephone interview in a sub-sample. Prevalence estimates were calculated as crude proportions with 95% confidence intervals and sequentially adjusted for age and sex, measurement error and selection bias. Associations with demographic variables were investigated. RESULTS: A total of 8,265 participants (3,344 men and 4,921 women; mean age 47.3 years) responded. The crude one-year prevalence was 29.6% for migraine (36.5% in women, 19.4% in men), 52.7% for tension-type headache (TTH) (51.4% in women, 54.6% in men), and 5.1% for probable medication-overuse headache (pMOH) (6.5% in women, 3.1% in men). After adjusting for age, sex, measurement error, and selection bias, the estimated prevalence was 20.3% for migraine, 47.9% for TTH, and 5.9% for pMOH. Migraine prevalence was highest among participants with low income and low education, while TTH prevalence was highest in participants with high socioeconomic status. pMOH prevalence was highest in participants aged 26\u201345 years and in participants with low education. CONCLUSION: The PopHEAD study provides updated, validated and bias-adjusted prevalence estimates for migraine, TTH and pMOH in the Norwegian adult population. These data may inform health resource allocation for headache management in similar populations.",
      "authors": "Argren Maria Bengtson; Engstrand Helene; Hus\u00f8y Andreas Kattem; Kristoffersen Espen Saxhaug; Toft Mathias; Pripp Are Hugo; Zwart John-Anker; Winsvold Bendik Slagsvold",
      "year": "2025",
      "journal": "The journal of headache and pain",
      "doi": "10.1186/s10194-025-02216-8",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41299259/",
      "mesh_terms": "",
      "keywords": "Epidemiology; HARDSHIP questionnaire; Medication-overuse headache; Migraine; Norway; Population-based study; Prevalence; Tension-type headache",
      "pub_types": "Journal Article",
      "pmcid": "PMC12659259"
    },
    {
      "pmid": "40773445",
      "title": "Reducing bias in coronary heart disease prediction using Smote-ENN and PCA.",
      "abstract": "Coronary heart disease (CHD) is a major cardiovascular disorder that poses significant threats to global health and is increasingly affecting younger populations. Its treatment and prevention face challenges such as high costs, prolonged recovery periods, and limited efficacy of traditional methods. Additionally, the complexity of diagnostic indicators and the global shortage of medical professionals further complicate accurate diagnosis. This study employs machine learning techniques to analyze CHD-related pathogenic factors and proposes an efficient diagnostic and predictive framework. To address the data imbalance issue, SMOTE-ENN is utilized, and five machine learning algorithms-Decision Trees, KNN, SVM, XGBoost, and Random Forest-are applied for classification tasks. Principal Component Analysis (PCA) and Grid Search are used to optimize the models, with evaluation metrics including accuracy, precision, recall, F1-score, and AUC. According to the random forest model's optimization experiment, the initial unbalanced data's accuracy was 85.26%, and the F1-score was 12.58%. The accuracy increased to 92.16% and the F1-score reached 93.85% after using SMOTE-ENN for data balancing, which is an increase of 6.90% and 81.27%, respectively; the model accuracy increased to 97.91% and the F1-score increased to 97.88% after adding PCA feature dimensionality reduction processing, which is an increase of 5.75% and 4.03%, respectively, compared with the SMOTE-ENN stage. This indicates that combining data balancing and feature dimensionality reduction techniques significantly improves model accuracy and makes the random forest model the best model. This study provides an efficient diagnostic tool for CHD, alleviates the challenges posed by limited medical resources, and offers a scientific foundation for precise prevention and intervention strategies.",
      "authors": "Wei Xinyi; Shi Boyu",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0327569",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40773445/",
      "mesh_terms": "Humans; Coronary Disease; Principal Component Analysis; Machine Learning; Algorithms; Decision Trees; Male; Support Vector Machine; Bias",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12331108"
    },
    {
      "pmid": "41032683",
      "title": "Regulating AI in Nursing and Healthcare: Ensuring Safety, Equity, and Accessibility in the Era of Federal Innovation Policy.",
      "abstract": "The rapid integration of artificial intelligence in healthcare, accelerated by the Trump administration's 2025 AI Action Plan and private sector innovations from companies like Nvidia and Hippocratic AI, poses urgent challenges for nursing and health policy. This policy analysis examines the intersection of federal AI initiatives, emerging healthcare technologies, and nursing workforce implications through document analysis of regulatory frameworks, the federal AI Action Plan's 90+ initiatives, and insights from the American Academy of Nursing's November 2024 policy dialogue on AI transformation. The analysis reveals that while AI demonstrates measurable improvements in discrete clinical tasks-including 16% better medication assessment accuracy and 43% greater precision in identifying drug interactions at $9 per hour compared to nurses' median $41.38 hourly wage-current federal policy lacks critical healthcare-specific safeguards. The AI Action Plan's emphasis on rapid deployment and deregulation fails to address safety-net infrastructure needs, implementation pathways for vulnerable populations, or mechanisms ensuring health equity. Evidence from the Academy dialogue indicates that AI's \"technosocial reality\" fundamentally alters care delivery while potentially exacerbating disparities in underserved communities, as demonstrated by algorithmic bias in systems like Optum's care allocation algorithm. The findings suggest that achieving equitable AI integration requires comprehensive regulatory frameworks coordinating FDA, CMS, OCR, and HRSA oversight; community-centered governance approaches redistributing decision-making power to affected populations; and nursing leadership in AI development to preserve patient-centered care values. Without proactive nursing engagement in AI governance, healthcare risks adopting technologies that prioritize efficiency over the holistic, compassionate care fundamental to nursing practice.",
      "authors": "Yang Y Tony; Ricciardi Richard",
      "year": "2026",
      "journal": "Policy, politics & nursing practice",
      "doi": "10.1177/15271544251381228",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41032683/",
      "mesh_terms": "Artificial Intelligence; Humans; United States; Health Policy; Health Equity; Health Services Accessibility; Delivery of Health Care; Patient Safety",
      "keywords": "algorithms; artificial intelligence; health care delivery; health equity; health policy; nursing",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40063843",
      "title": "Gamified Adaptive Approach Bias Modification in Individuals With Methamphetamine Use History From Communities in Sichuan: Pilot Randomized Controlled Trial.",
      "abstract": "BACKGROUND: Cognitive bias modification (CBM) programs have shown promise in treating psychiatric conditions, but they can be perceived as boring and repetitive. Incorporating gamified designs and adaptive algorithms in CBM training may address this issue and enhance engagement and effectiveness. OBJECTIVES: This study aims to gather preliminary data and assess the preliminary efficacy of an adaptive approach bias modification (A-ApBM) paradigm in reducing cue-induced craving in individuals with methamphetamine use history. METHODS: A randomized controlled trial with 3 arms was conducted. Individuals aged 18-60 years with methamphetamine dependence and at least 1 year of methamphetamine use were recruited from 12 community-based rehabilitation centers in Sichuan, China. Individuals with the inability to fluently operate a smartphone and the presence of mental health conditions other than methamphetamine use disorder were excluded. The A-ApBM group engaged in ApBM training using a smartphone app for 4 weeks. The A-ApBM used an adaptive algorithm to dynamically adjust the difficulty level based on individual performance. Cue-induced craving scores and relapses were assessed using a visual analogue scale at baseline, postintervention, and at week-16 follow-up. RESULTS: A total of 136 participants were recruited and randomized: 48 were randomized to the A-ApBM group, 48 were randomized to the static approach bias modification (S-ApBM) group, and 40 were randomized to the no-intervention control group. The A-ApBM group showed a significant reduction in cue-induced craving scores at postintervention compared with baseline (Cohen d=0.34; P<.01; 95% CI 0.03-0.54). The reduction remained significant at the week-16 follow-up (Cohen d=0.40; P=.01; 95% CI 0.18-0.57). No significant changes were observed in the S-ApBM and control groups. CONCLUSIONS: The A-ApBM paradigm with gamified designs and dynamic difficulty adjustments may be an effective intervention for reducing cue-induced craving in individuals with methamphetamine use history. This approach improves engagement and personalization, potentially enhancing the effectiveness of CBM programs. Further research is needed to validate these findings and explore the application of A-ApBM in other psychiatric conditions.",
      "authors": "Shen Danlin; Jiao Jianping; Zhang Liqun; Liu Yanru; Liu Xiang; Li Yuanhui; Zhang Tianjiao; Li Dai; Hao Wei",
      "year": "2025",
      "journal": "JMIR serious games",
      "doi": "10.2196/56978",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40063843/",
      "mesh_terms": "",
      "keywords": "cognitive bias modification; digital therapeutics; effectiveness; engagement; game; gamified design; methamphetamine; pilot RCT; psychiatric; randomized controlled trial; smartphone app; substance use disorder",
      "pub_types": "Journal Article",
      "pmcid": "PMC11931399"
    },
    {
      "pmid": "30362919",
      "title": "Evaluating the Presence of Cognitive Biases in Health Care Decision Making: A Survey of U.S. Formulary Decision Makers.",
      "abstract": "BACKGROUND: Behavioral economics is a field of economics that draws on insights from psychology to understand and identify patterns of decision making. Cognitive biases are psychological tendencies to process information in predictable patterns that result in deviations from rational decision making. Previous research has not evaluated the influence of cognitive biases on decision making in a managed care setting. OBJECTIVE: To assess the presence of cognitive biases in formulary decision making. METHODS: An online survey was conducted with a panel of U.S. pharmacy and medical directors who worked at managed care organizations and served on pharmacy and therapeutics committees. Survey questions assessed 4 cognitive biases: relative versus absolute framing effect, risk aversion, zero-risk bias, and delay discounting. Simulated data were presented in various scenarios related to adverse event profiles, drug safety and efficacy, and drug pricing for new hypothetical oncology products. Survey questions prompted participants to select a preferred drug based on the information provided. Survey answers were analyzed to identify decision patterns that could be explained by the cognitive biases. Likelihood of bias was analyzed via chi-square tests for framing effect, risk aversion, and zero-risk bias. The delay discounting section used a published algorithm to characterize discounting patterns. RESULTS: A total of 35 pharmacy directors and 19 medical directors completed the survey. In the framing effect section, 80% of participants selected the suboptimal choice in the relative risk frame, compared with 38.9% in the absolute risk frame (P < 0.0001). When assessing risk aversion, 42.6% and 61.1% of participants displayed risk aversion in the cost- and efficacy-based scenarios, respectively, but these were not statistically significant (P = 0.27 and P = 0.10, respectively). In the zero-risk bias section, results from each scenario diverged. In the first zero-risk bias scenario, 90.7% of participants selected the drug with zero risk (P < 0.001), but in the second scenario, only 32.1% chose the zero-risk option (P < 0.01). In the section assessing delay discounting, 54% of survey participants favored a larger delayed rebate over a smaller immediate discount. A shallow delay discounting curve was produced, which indicated participants discounted delayed rewards to a minimal degree. CONCLUSIONS: Pharmacy and medical directors, like other decision makers, appear to be susceptible to some cognitive biases. Directors demonstrated a tendency to underestimate risks when they were presented in relative risk terms but made more accurate appraisals when information was presented in absolute risk terms. Delay discounting also may be applicable to directors when choosing immediate discounts over delayed rebates. However, directors neither displayed a statistically significant bias for risk aversion when assessing scenarios related to drug pricing or clinical efficacy nor were there significant conclusions for zero-risk biases. Further research with larger samples using real-world health care decisions is necessary to validate these findings. DISCLOSURES: This research was funded by Xcenda. Mezzio, Nguyen, and O'Day are employees of Xcenda. Kiselica was employed by Xcenda at the time the study was conducted. The authors have nothing to disclose. A portion of the preliminary data was presented as posters at the 2017 AMCP Managed Care & Specialty Pharmacy Annual Meeting; March 27-30, 2017; in Denver, CO, and the 2017 International Society for Pharmacoeconomics and Outcomes Research 22nd Annual International Meeting; May 20-24, 2017; in Boston, MA.",
      "authors": "Mezzio Dylan J; Nguyen Victor B; Kiselica Andrew; O'Day Ken",
      "year": "2018",
      "journal": "Journal of managed care & specialty pharmacy",
      "doi": "10.18553/jmcp.2018.24.11.1173",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30362919/",
      "mesh_terms": "Cognition; Decision Making; Economics, Pharmaceutical; Humans; Likelihood Functions; Managed Care Programs; Outcome Assessment, Health Care; Pharmacy; Physician Executives; Prejudice; Risk Assessment; Surveys and Questionnaires",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10397589"
    },
    {
      "pmid": "40587474",
      "title": "Racial disparities in continuous glucose monitoring-based 60-min glucose predictions among people with type 1 diabetes.",
      "abstract": "Non-Hispanic white (White) populations are overrepresented in medical studies. Potential healthcare disparities can happen when machine learning models, used in diabetes technologies, are trained on data from primarily White patients. We aimed to evaluate algorithmic fairness in glucose predictions. This study utilized continuous glucose monitoring (CGM) data from 101 White and 104 Black participants with type 1 diabetes collected by the JAEB Center for Health Research, US. Long short-term memory (LSTM) deep learning models were trained on 11 datasets of different proportions of White and Black participants and tailored to each individual using transfer learning to predict glucose 60 minutes ahead based on 60-minute windows. Root mean squared errors (RMSE) were calculated for each participant. Linear mixed-effect models were used to investigate the association between racial composition and RMSE while accounting for age, sex, and training data size. A median of 9 weeks (IQR: 7, 10) of CGM data was available per participant. The divergence in performance (RMSE slope by proportion) was not statistically significant for either group. However, the slope difference (from 0% White and 100% Black to 100% White and 0% Black) between groups was statistically significant (p\u2009=\u20090.02), meaning the RMSE increased 0.04 [0.01, 0.08] mmol/L more for Black participants compared to White participants when the proportion of White participants increased from 0 to 100% in the training data. This difference was attenuated in the transfer learned models (RMSE: 0.02 [-0.01, 0.05] mmol/L, p\u2009=\u20090.20). The racial composition of training data created a small statistically significant difference in the performance of the models, which was not present after using transfer learning. This demonstrates the importance of diversity in datasets and the potential value of transfer learning for developing more fair prediction models.",
      "authors": "Thomsen Helene Bei; Li Livie Yumeng; Isaksen Anders Aasted; Lebiecka-Johansen Benjamin; Bour Charline; Fagherazzi Guy; van Doorn William P T M; Varga Tibor V; Hulman Adam",
      "year": "2025",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000918",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40587474/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12208448"
    },
    {
      "pmid": "41195704",
      "title": "Ensuring generalizability and clinical utility in mental health care applications: Robust artificial intelligence-based treatment predictions in diverse psychosis populations.",
      "abstract": "AIM: Artificial Intelligence (AI)-based prediction models of treatment response promise to revolutionize psychiatric care by enabling personalized treatment, but very few have been thoroughly tested in different samples or compared to current clinical standards. Here we present models predicting antipsychotic response and assess their clinical utility in a robust methodological framework. METHODS: Machine learning models were trained and cross-validated on clinical and sociodemographic data from 594 individuals with established schizophrenia (NCT00014001) and 323 individuals with first episode psychosis (NCT03510325). Models predicted four measures of antipsychotic response at 3\u2009months after baseline. Clinical utility was assessed using decision curve and calibration curve analyses. Model performance was tested in a reduced feature space and across sex, ethnicity, antipsychotic, and symptom change subgroups to investigate model fairness. RESULTS: Models predicting total symptom severity (r\u2009=\u20090.4-0.68) and symptomatic remission (BAC\u2009=\u200962.4%-69%) performed well in both samples and externally validated successfully in the opposing cohort (r\u2009=\u20090.4-0.5, BAC\u2009= 63.5%-65.7%). Performance remained significant when the models were reduced to 8-9 key variables (r\u2009=\u20090.53 for total symptom severity, BAC\u2009=\u200965.3% for symptomatic remission). Models predicting symptomatic remission had a net benefit across risk thresholds of 0.5-0.9 and were moderately well-calibrated (ECE\u2009=\u20090.16-0.18). Model performance different across sex, ethnicity and medication subgroups. CONCLUSIONS: We present a robust framework for training and assessing the clinical utility of prediction models in psychiatry. Our models generalize across different psychosis populations and show promising calibration and net benefit. However, performance disparities across demographic and treatment subgroups highlight the need for more diverse clinical samples to ensure equitable prediction.",
      "authors": "Coutts Fiona; Mena Sergio; Ucur Esin; Fleischhacker W Wolfgang; Kahn Rene; Lieberman Jeffrey; Hasan Alkomiet; Howes Oliver; Correll Christoph; Koutsouleris Nikolaos; Lalousis Paris Alexandros",
      "year": "2026",
      "journal": "Psychiatry and clinical neurosciences",
      "doi": "10.1111/pcn.13914",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41195704/",
      "mesh_terms": "Adolescent; Adult; Female; Humans; Male; Middle Aged; Young Adult; Antipsychotic Agents; Artificial Intelligence; Machine Learning; Outcome Assessment, Health Care; Psychotic Disorders; Schizophrenia; Randomized Controlled Trials as Topic; Multicenter Studies as Topic; Clinical Trials, Phase III as Topic; Clinical Trials, Phase IV as Topic",
      "keywords": "AI; antipsychotics; psychosis; translational; treatment response",
      "pub_types": "Journal Article",
      "pmcid": "PMC12757767"
    },
    {
      "pmid": "33893525",
      "title": "Race and Gender Disparity in the Surgical Management of Hepatocellular Cancer: Analysis of the Surveillance, Epidemiology, and End Results (SEER) Program Registry.",
      "abstract": "BACKGROUND: The existence of race and gender disparity has been described in numerous areas of medicine. The management of hepatocellular cancer is no different, but in no other area of medicine, is the treatment algorithm more complicated by local, regional, and national health care distribution policy. METHODS: Multivariate logistic regression and Cox-regression were utilized to analyze the treatment of patients with hepatocellular cancer registered in SEER between 1999 and 2013 to determine the incidence and effects of racial and gender disparity. Odd ratios (OR) are relative to Caucasian males, SEER region, and tumor characteristics. RESULTS: The analysis of 57,449 patients identified the minority were female (25.31%) and African-American (16.26%). All tumor interventions were protective (p\u2009<\u20090.001) with respect to survival. The mean survival for all registered patients was 13.01\u00a0months with conditional analysis, confirming that African-American men were less likely to undergo ablation, resection, or transplantation (p\u2009<\u20090.001). Women were more likely to undergo resection (p\u2009<\u20090.001). African-American women had an equivalent OR for resection but had a significantly lower transplant rate (p\u2009<\u20090.001). CONCLUSIONS: Utilizing SEER data as a surrogate for patient navigation in the treatment of hepatocellular cancer, our study identified not only race but gender bias with African-American women suffering the greatest. This is underscored by the lack of navigation of African-Americans to any therapy and a significant bias to navigate female patients to resection potentially limiting subsequent access to definitive therapy namely transplantation.",
      "authors": "Darden Michael; Parker Geoffrey; Monlezun Dominique; Anderson Edward; Buell Joseph F",
      "year": "2021",
      "journal": "World journal of surgery",
      "doi": "10.1007/s00268-021-06091-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33893525/",
      "mesh_terms": "Carcinoma, Hepatocellular; Female; Humans; Liver Neoplasms; Male; Registries; SEER Program; Sexism; United States",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "6556690"
    },
    {
      "pmid": "35974092",
      "title": "A machine learning framework supporting prospective clinical decisions applied to risk prediction in oncology.",
      "abstract": "We present a general framework for developing a machine learning (ML) tool that supports clinician assessment of patient risk using electronic health record-derived real-world data and apply the framework to a quality improvement use case in an oncology setting to identify patients at risk for a near-term (60 day) emergency department (ED) visit who could potentially be eligible for a home-based acute care program. Framework steps include defining clinical quality improvement goals, model development and validation, bias assessment, retrospective and prospective validation, and deployment in clinical workflow. In the retrospective analysis for the use case, 8% of patient encounters were associated with a high risk (pre-defined as predicted probability \u226520%) for a near-term ED visit by the patient. Positive predictive value (PPV) and negative predictive value (NPV) for future ED events was 26% and 91%, respectively. Odds ratio (OR) of ED visit (high- vs. low-risk) was 3.5 (95% CI: 3.4-3.5). The model appeared to be calibrated across racial, gender, and ethnic groups. In the prospective analysis, 10% of patients were classified as high risk, 76% of whom were confirmed by clinicians as eligible for home-based acute care. PPV and NPV for future ED events was 22% and 95%, respectively. OR of ED visit (high- vs. low-risk) was 5.4 (95% CI: 2.6-11.0). The proposed framework for an ML-based tool that supports clinician assessment of patient risk is a stepwise development approach; we successfully applied the framework to an ED visit risk prediction use case.",
      "authors": "Coombs Lorinda; Orlando Abigail; Wang Xiaoliang; Shaw Pooja; Rich Alexander S; Lakhtakia Shreyas; Titchener Karen; Adamson Blythe; Miksad Rebecca A; Mooney Kathi",
      "year": "2022",
      "journal": "NPJ digital medicine",
      "doi": "10.1038/s41746-022-00660-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35974092/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9380664"
    },
    {
      "pmid": "40681191",
      "title": "Curating a knowledge base for patients with neurosyphilis: a study protocol of a DEep learning Framework for pErsonalized prediction of Adverse prognosTic events in NeuroSyphilis (DEFEAT-NS).",
      "abstract": "INTRODUCTION: Adverse prognostic events (APE) of neurosyphilis include ongoing syphilitic meningitis, meningovascular syphilis, parenchymatous neurosyphilis and death. Its complexity and rarity have the potential to result in the underestimated true burden of neurosyphilis worldwide, due to lack of recognition and under-reporting. The unmet need for a modern method of refined and targeted treatment of neurosyphilis is strengthened by the currently various distinct diagnostic criteria. The DEep learning Framework for pErsonalized prediction of Adverse prognosTic events in NeuroSyphilis study will develop and validate prediction models for personalised prediction of APE after initial diagnosis in neurosyphilis to aid shared decision-making and stratify care of patients with neurosyphilis at high risk of severe prognostic course. METHODS AND ANALYSIS: We conducted formative research to conceptualise and design a robust and clinically acceptable deep learning framework. We will conduct a deep learning framework development and validation study using a retrospective, multicentre, longitudinal cohort design and applying unsupervised, semi-supervised machine learning and deep learning. It will be conducted following expert guidance for model development and validation and our previous research experience. This study design consists of six parts: development, calibration, validation, subgroup bias evaluation, clinical utility evaluation and explanation. ETHICS AND DISSEMINATION: This study will be conducted according to the Declaration of Helsinki and the Harmonised Tripartite Guideline for Good Clinical Practice of the International Conference on Harmonisation. No patient will be directly involved in developing the study's research question, design and implementation. This study will be a retrospective analysis of already anonymised data; therefore, ethical approval and informed consent were waived by the institutional review board of School of Public Health (Shenzhen), Sun Yat-sen University. The results will be disseminated through a peer-reviewed publication.",
      "authors": "Lu Zhen; Yang Liuqing; Li Jun; Wang Junfeng; Wu Weibo; Fu Leiwen; Wang Bingyi; Tian Tian; Zhang Hanlin; Peng Zhipeng; Liu Siyang; Zou Jun; Zou Huachun",
      "year": "2025",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2024-092248",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40681191/",
      "mesh_terms": "Humans; Deep Learning; Prognosis; Neurosyphilis; Retrospective Studies; Knowledge Bases; Research Design; Longitudinal Studies; Multicenter Studies as Topic",
      "keywords": "Artificial Intelligence; Machine Learning; Prognosis; Syphilis",
      "pub_types": "Journal Article",
      "pmcid": "PMC12273070"
    },
    {
      "pmid": "11008073",
      "title": "Lung allocation in the United States, 1995-1997: an analysis of equity and utility.",
      "abstract": "BACKGROUND: Waiting time for organ transplantation varies widely between programs of different sizes and by geographic regions. The purpose of this study was to determine if the current lung-allocation policy is equitable for candidates waiting at various-sized centers, and to model how national allocation based solely on waiting time might affect patients and programs. METHODS: UNOS provided data on candidate registrations; transplants and outcomes; waiting times; and deaths while waiting for all U.S. lung-transplant programs during 1995-1997. Transplant centers were categorized based on average yearly volume: small (< or = 10 pounds sterling transplants/year; n = 46), medium (11-30 transplants/year; n = 29), or large (>30 transplants/year; n = 6). This data was used to model national organ allocation based solely on accumulated waiting time for candidates listed at the end of 1997. RESULTS: Median waiting time for patients transplanted was longest at large programs (724-848 days) compared to small and medium centers (371-552 days and 337-553 days, respectively) and increased at programs of all sizes during the study period. Wait-time-adjusted risk of death correlated inversely with program size (365 vs 261 vs 148 deaths per 1,000 patient-years-at-risk at small, medium, and large centers, respectively). Mortality as a percentage of new candidate registrations was similar for all program categories, ranging from 21 to 25%. Survival rates following transplantation were equivalent at medium-sized centers vs large centers (p = 0.50), but statistically lower when small centers were compared to either large- or medium-size centers (p < or = 0.05). Using waiting time as the primary criterion lung allocation would acutely shift 10 to 20% of lung-transplant activity from medium to large programs. CONCLUSIONS: 1) Waiting list mortality rates are not higher at large lung-transplant programs with long average waiting times. 2) A lung-allocation algorithm based primarily on waiting-list seniority would probably disadvantage candidates at medium-size centers without improving overall lung-transplant outcomes. 3) If fairness is measured by equal distribution of opportunity and risk, we conclude that the current allocation system is relatively equitable for patients currently entering the lung-transplant system.",
      "authors": "Pierson R N; Milstone A P; Loyd J E; Lewis B H; Pinson C W; Ely E W",
      "year": "2000",
      "journal": "The Journal of heart and lung transplantation : the official publication of the International Society for Heart Transplantation",
      "doi": "10.1016/s1053-2498(00)00151-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/11008073/",
      "mesh_terms": "Actuarial Analysis; Health Care Rationing; Humans; Lung Transplantation; Retrospective Studies; Tissue and Organ Procurement; United States; Waiting Lists",
      "keywords": "Empirical Approach; Health Care and Public Health",
      "pub_types": "Journal Article; Multicenter Study; Research Support, U.S. Gov't, Non-P.H.S.; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "39316436",
      "title": "Equity in Digital Mental Health Interventions in the United States: Where to Next?",
      "abstract": "Health care technologies have the ability to bridge or hinder equitable care. Advocates of digital mental health interventions (DMHIs) report that such technologies are poised to reduce the documented gross health care inequities that have plagued generations of people seeking care in the United States. This is due to a multitude of factors such as their potential to revolutionize access; mitigate logistical barriers to in-person mental health care; and leverage patient inputs to formulate tailored, responsive, and personalized experiences. Although we agree with the potential of DMHIs to advance health equity, we articulate several steps essential to mobilize and sustain meaningful forward progression in this endeavor, reflecting on decades of research and learnings drawn from multiple fields of expertise and real-world experience. First, DMHI manufacturers must build diversity, equity, inclusion, and belonging (DEIB) processes into the full spectrum of product evolution itself (eg, product design, evidence generation) as well as into the fabric of internal company practices (eg, talent recruitment, communication principles, and advisory boards). Second, awareness of the DEIB efforts-or lack thereof-in DMHI research trials is needed to refine and optimize future study design for inclusivity as well as proactively address potential barriers to doing so. Trials should incorporate thoughtful, inclusive, and creative approaches to recruitment, enrollment, and measurement of social determinants of health and self-identity, as well as a prioritization of planned and exploratory analyses examining outcomes across various groups of people. Third, mental health care advocacy, research funding policies, and local and federal legislation can advance these pursuits, with directives from the US Preventive Services Taskforce, National Institutes of Health, and Food and Drug Administration applied as poignant examples. For products with artificial intelligence/machine learning, maintaining a \"human in the loop\" as well as prespecified and adaptive analytic frameworks to monitor and remediate potential algorithmic bias can reduce the risk of increasing inequity. Last, but certainly not least, is a call for partnership and transparency within and across ecosystems (academic, industry, payer, provider, regulatory agencies, and value-based care organizations) to reliably build health equity into real-world DMHI product deployments and evidence-generation strategies. All these considerations should also extend into the context of an equity-informed commercial strategy for DMHI manufacturers and health care organizations alike. The potential to advance health equity in innovation with DMHI is apparent. We advocate the field's thoughtful and evergreen advancement in inclusivity, thereby redefining the mental health care experience for this generation and those to come.",
      "authors": "Robinson Athena; Flom Megan; Forman-Hoffman Valerie L; Histon Trina; Levy Monique; Darcy Alison; Ajayi Toluwalase; Mohr David C; Wicks Paul; Greene Carolyn; Montgomery Robert M",
      "year": "2024",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/59939",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39316436/",
      "mesh_terms": "Humans; United States; Mental Health Services; Mental Health; Health Equity; Telemedicine; Healthcare Disparities",
      "keywords": "Digital Mental Health Interventions; access to health care; health equity; health plan implementations; mental health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11462105"
    },
    {
      "pmid": "25316533",
      "title": "Posttreatment attrition and its predictors, attrition bias, and treatment efficacy of the anxiety online programs.",
      "abstract": "BACKGROUND: Although relatively new, the field of e-mental health is becoming more popular with more attention given to researching its various aspects. However, there are many areas that still need further research, especially identifying attrition predictors at various phases of assessment and treatment delivery. OBJECTIVE: The present study identified the predictors of posttreatment assessment completers based on 24 pre- and posttreatment demographic and personal variables and 1 treatment variable, their impact on attrition bias, and the efficacy of the 5 fully automated self-help anxiety treatment programs for generalized anxiety disorder (GAD), social anxiety disorder (SAD), panic disorder with or without agoraphobia (PD/A), obsessive-compulsive disorder (OCD), and posttraumatic stress disorder (PTSD). METHODS: A complex algorithm was used to diagnose participants' mental disorders based on the criteria of the Diagnostic and Statistical Manual of Mental Disorders (Fourth Edition, Text Revision; DSM-IV-TR). Those who received a primary or secondary diagnosis of 1 of 5 anxiety disorders were offered an online 12-week disorder-specific treatment program. A total of 3199 individuals did not formally drop out of the 12-week treatment cycle, whereas 142 individuals formally dropped out. However, only 347 participants who completed their treatment cycle also completed the posttreatment assessment measures. Based on these measures, predictors of attrition were identified and attrition bias was examined. The efficacy of the 5 treatment programs was assessed based on anxiety-specific severity scores and 5 additional treatment outcome measures. RESULTS: On average, completers of posttreatment assessment measures were more likely to be seeking self-help online programs; have heard about the program from traditional media or from family and friends; were receiving mental health assistance; were more likely to learn best by reading, hearing and doing; had a lower pretreatment Kessler-6 total score; and were older in age. Predicted probabilities resulting from these attrition variables displayed no significant attrition bias using Heckman's method and thus allowing for the use of completer analysis. Six treatment outcome measures (Kessler-6 total score, number of diagnosed disorders, self-confidence in managing mental health issues, quality of life, and the corresponding pre- and posttreatment severity for each program-specific anxiety disorder and for major depressive episode) were used to assess the efficacy of the 5 anxiety treatment programs. Repeated measures MANOVA revealed a significant multivariate time effect for all treatment outcome measures for each treatment program. Follow-up repeated measures ANOVAs revealed significant improvements on all 6 treatment outcome measures for GAD and PTSD, 5 treatment outcome measures were significant for SAD and PD/A, and 4 treatment outcome measures were significant for OCD. CONCLUSIONS: Results identified predictors of posttreatment assessment completers and provided further support for the efficacy of self-help online treatment programs for the 5 anxiety disorders. TRIAL REGISTRATION: Australian and New Zealand Clinical Trials Registry ACTRN121611000704998; http://www.anzctr.org.au/trial_view.aspx?ID=336143 (Archived by WebCite at http://www.webcitation.org/618r3wvOG).",
      "authors": "Al-Asadi Ali M; Klein Britt; Meyer Denny",
      "year": "2014",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/jmir.3513",
      "url": "https://pubmed.ncbi.nlm.nih.gov/25316533/",
      "mesh_terms": "Adolescent; Adult; Aged; Aged, 80 and over; Anxiety; Bias; Female; Humans; Internet; Male; Middle Aged; Models, Psychological; Outcome Assessment, Health Care; Quality of Life; Randomized Controlled Trials as Topic; Treatment Outcome; Young Adult",
      "keywords": "Internet interventions; Web treatment; cognitive behavioral therapy; e-mental health; fully automated; generalized anxiety disorder; obsessive compulsive disorder; online therapy; posttreatment attrition; posttreatment predictors; self-help; treatment efficacy",
      "pub_types": "Journal Article",
      "pmcid": "PMC4211028"
    },
    {
      "pmid": "40857554",
      "title": "Comparing Multiple Imputation Methods to Address Missing Patient Demographics in Immunization Information Systems: Retrospective Cohort Study.",
      "abstract": "BACKGROUND: Immunization Information Systems (IIS) and surveillance data are essential for public health interventions and programming; however, missing data are often a challenge, potentially introducing bias and impacting the accuracy of vaccine coverage assessments, particularly in addressing disparities. OBJECTIVE: This study aimed to evaluate the performance of 3 multiple imputation methods, Stata's (StataCorp LLC) multiple imputation using chained equations (MICE), scikit-learn's Iterative-Imputer, and Python's miceforest package, in managing missing race and ethnicity data in large-scale surveillance datasets. We compared these methodologies in their ability to preserve demographic distribution, computational efficiency, and performed G-tests on contingency tables to obtain likelihood ratio statistics to assess the association between race and ethnicity and flu vaccination status. METHODS: In this retrospective cohort study, we analyzed 2021-2022 flu vaccination and demographic data from the West Virginia Immunization Information System (N=2,302,036), where race (15%) and ethnicity (34%) were missing. MICE, Iterative Imputer, and miceforest were used to impute missing variables, generating 15 datasets each. Computational efficiency, demographic distribution preservation, and spatial clustering patterns were assessed using G-statistics. RESULTS: After imputation, an additional 780,339 observations were obtained compared with complete case analysis. All imputation methods exhibited significant spatial clustering for race imputation (G-statistics: MICE=26,452.7, Iterative-Imputer=128,280.3, Miceforest=26,891.5; P<.001), while ethnicity imputation showed variable clustering patterns (G-statistics: MICE=1142.2, Iterative-Imputer=1.7, Miceforest=2185.0; P: MICE<.001, Iterative-Imputer=1.7, Miceforest<.001). MICE and miceforest best preserved the proportional distribution of demographics. Computational efficiency varied, with MICE requiring 14 hours, Iterative Imputer 2 minutes, and miceforest 10 minutes for 15 imputations. Postimputation estimates indicated a 0.87%-18% reduction in stratified flu vaccination coverage rates. Overall estimated flu vaccination rates decreased from 26% to 19% after imputations. CONCLUSIONS: Both MICE and Miceforest offer flexible and reliable approaches for imputing missing demographic data while mitigating bias compared with Iterative-Imputer. Our results also highlight that the imputation method can profoundly affect research findings. Though MICE and Miceforest had better effect sizes and reliability, MICE was much more computationally and time-expensive, limiting its use in large, surveillance datasets. Miceforest can use cloud-based computing, which further enhances efficiency by offloading resource-intensive tasks, enabling parallel execution, and minimizing processing delays. The significant decrease in vaccination coverage estimates validates how incomplete or missing data can eclipse real disparities. Our findings support regular application of imputation methods in immunization surveillance to improve health equity evaluations and shape targeted public health interventions and programming.",
      "authors": "Brown Sara; Kudia Ousswa; Kleine Kaye; Kidd Bryndan; Wines Robert; Meckes Nathanael",
      "year": "2025",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/73916",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40857554/",
      "mesh_terms": "Retrospective Studies; Humans; Female; Male; Information Systems; Demography; Child, Preschool; Cohort Studies; Adolescent; Child; Immunization; Adult; Infant; Middle Aged",
      "keywords": "data science; immunization information system; imputation methods; machine learning; missing data; multiple imputation; statistical modeling",
      "pub_types": "Journal Article",
      "pmcid": "PMC12380239"
    },
    {
      "pmid": "26820188",
      "title": "Multivariate analysis of the population representativeness of related clinical studies.",
      "abstract": "OBJECTIVE: To develop a multivariate method for quantifying the population representativeness across related clinical studies and a computational method for identifying and characterizing underrepresented subgroups in clinical studies. METHODS: We extended a published metric named Generalizability Index for Study Traits (GIST) to include multiple study traits for quantifying the population representativeness of a set of related studies by assuming the independence and equal importance among all study traits. On this basis, we compared the effectiveness of GIST and multivariate GIST (mGIST) qualitatively. We further developed an algorithm called \"Multivariate Underrepresented Subgroup Identification\" (MAGIC) for constructing optimal combinations of distinct value intervals of multiple traits to define underrepresented subgroups in a set of related studies. Using Type 2 diabetes mellitus (T2DM) as an example, we identified and extracted frequently used quantitative eligibility criteria variables in a set of clinical studies. We profiled the T2DM target population using the National Health and Nutrition Examination Survey (NHANES) data. RESULTS: According to the mGIST scores for four example variables, i.e., age, HbA1c, BMI, and gender, the included observational T2DM studies had superior population representativeness than the interventional T2DM studies. For the interventional T2DM studies, Phase I trials had better population representativeness than Phase III trials. People at least 65years old with HbA1c value between 5.7% and 7.2% were particularly underrepresented in the included T2DM trials. These results confirmed well-known knowledge and demonstrated the effectiveness of our methods in population representativeness assessment. CONCLUSIONS: mGIST is effective at quantifying population representativeness of related clinical studies using multiple numeric study traits. MAGIC identifies underrepresented subgroups in clinical studies. Both data-driven methods can be used to improve the transparency of design bias in participation selection at the research community level.",
      "authors": "He Zhe; Ryan Patrick; Hoxha Julia; Wang Shuang; Carini Simona; Sim Ida; Weng Chunhua",
      "year": "2016",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2016.01.007",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26820188/",
      "mesh_terms": "Algorithms; Biomedical Research; Clinical Trials as Topic; Databases, Factual; Demography; Diabetes Mellitus, Type 2; Humans; Medical Informatics Computing; Multivariate Analysis; Nutrition Surveys; Observational Studies as Topic; Patient Selection; Selection Bias",
      "keywords": "Clinical trial; Knowledge representation; Selection bias",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC4837055"
    },
    {
      "pmid": "38099504",
      "title": "Using artificial intelligence to promote equitable care for inpatients with language barriers and complex medical needs: clinical stakeholder perspectives.",
      "abstract": "OBJECTIVES: Inpatients with language barriers and complex medical needs suffer disparities in quality of care, safety, and health outcomes. Although in-person interpreters are particularly beneficial for these patients, they are underused. We plan to use machine learning predictive analytics to reliably identify patients with language barriers and complex medical needs to prioritize them for in-person interpreters. MATERIALS AND METHODS: This qualitative study used stakeholder engagement through semi-structured interviews to understand the perceived risks and benefits of artificial intelligence (AI) in this domain. Stakeholders included clinicians, interpreters, and personnel involved in caring for these patients or for organizing interpreters. Data were coded and analyzed using NVIVO software. RESULTS: We completed 49 interviews. Key perceived risks included concerns about transparency, accuracy, redundancy, privacy, perceived stigmatization among patients, alert fatigue, and supply-demand issues. Key perceived benefits included increased awareness of in-person interpreters, improved standard of care and prioritization for interpreter utilization; a streamlined process for accessing interpreters, empowered clinicians, and potential to overcome clinician bias. DISCUSSION: This is the first study that elicits stakeholder perspectives on the use of AI with the goal of improved clinical care for patients with language barriers. Perceived benefits and risks related to the use of AI in this domain, overlapped with known hazards and values of AI but some benefits were unique for addressing challenges with providing interpreter services to patients with language barriers. CONCLUSION: Artificial intelligence to identify and prioritize patients for interpreter services has the potential to improve standard of care and address healthcare disparities among patients with language barriers.",
      "authors": "Barwise Amelia K; Curtis Susan; Diedrich Daniel A; Pickering Brian W",
      "year": "2024",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocad224",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38099504/",
      "mesh_terms": "Humans; Language; Inpatients; Artificial Intelligence; Communication Barriers; Allied Health Personnel",
      "keywords": "LEP; artificial intelligence; complex care; health equity; language barrier; non-English language preferred",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC10873784"
    },
    {
      "pmid": "41220002",
      "title": "Sex-specific machine learning classification models improve outcome prediction for abdominal aortic aneurysms.",
      "abstract": "BACKGROUND: Abdominal aortic aneurysm (AAA) is an abnormal dilation of the abdominal aorta that carries up to a 90% mortality rate when ruptured. Although male patients experience AAA at a higher rate than females, female patients experience AAA rupture at a rate three- to four-fold higher that of their male counterparts. The current standard clinicians use for determining when to surgically intervene is maximum transverse diameter of the AAA perpendicular to the axis of flow. However, some aneurysms below these diameter thresholds rupture. Machine learning (ML) classification models have been previously shown to predict patient outcomes with more discriminability than the diameter criterion. However, these models do not consider sex-based differences. In this proof-of-concept study, we investigate how creating sex-specific ML models impacts patient outcome prediction as compared to a general model encompassing all patients (sex agnostic). METHODS: Computed tomography image sets were acquired from 537 patients (n\u2009=\u2009159 female, n\u2009=\u2009378 male) at the University of Pittsburgh Medical Center (UPMC) and Mayo Clinic Health Systems. Features used as input to the ML models were categorized as clinical, biomechanical, and morphological data. Prior to ML model training, patient data were randomly split for 20% holdout testing. ML models encompassing all patients (general model), only male patients (male-specific model), and only female patients (female-specific model) were trained and tested. RESULTS: A female-specific model and male-specific model both had a higher maximum area under the receiver-operating characteristic curve values than a general model for female patients and male patients, respectively. Equalizing the sample sizes of female and male patients in the model led to improved outcomes for female patients without decreasing performance for male patients. CONCLUSION: ML classification models show promise in improving predictions of patient outcomes for AAA. The higher AAA prevalence rate for males leads to female patients being underrepresented in AAA datasets. In this proof-of-concept study, we demonstrated that sex-specific models outperformed a general model in predicting patient outcomes. Additionally, equalizing sample sizes within the dataset improved predictions for female patients without compromising overall performance of the model. As ML applications in medicine continue to grow, it is important to consider population representation within datasets to reduce model bias.",
      "authors": "Kerr Katherine E; Sen Indrani; Gueldner Pete H; Tallarita Tiziano; Wildenberg Joseph C; Liang Nathan L; Vorp David A; Chung Timothy K",
      "year": "2025",
      "journal": "Biology of sex differences",
      "doi": "10.1186/s13293-025-00765-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41220002/",
      "mesh_terms": "Humans; Aortic Aneurysm, Abdominal; Machine Learning; Male; Female; Sex Characteristics; Aged; Middle Aged; Tomography, X-Ray Computed; Aged, 80 and over",
      "keywords": "AI explainability; Abdominal aortic aneurysm; Biomechanics; Machine learning; Morphology; Outcome prediction; Sex-based differences; Shape analysis; Stress analysis; Vascular surgery",
      "pub_types": "Journal Article",
      "pmcid": "PMC12607067"
    },
    {
      "pmid": "31840093",
      "title": "Eliminating biasing signals in lung cancer images for prognosis predictions with deep learning.",
      "abstract": "Deep learning has shown remarkable results for image analysis and is expected to aid individual treatment decisions in health care. Treatment recommendations are predictions with an inherently causal interpretation. To use deep learning for these applications in the setting of observational data, deep learning methods must be made compatible with the required causal assumptions. We present a scenario with real-world medical images (CT-scans of lung cancer) and simulated outcome data. Through the data simulation scheme, the images contain two distinct factors of variation that are associated with survival, but represent a collider (tumor size) and a prognostic factor (tumor heterogeneity), respectively. When a deep network would use all the information available in the image to predict survival, it would condition on the collider and thereby introduce bias in the estimation of the treatment effect. We show that when this collider can be quantified, unbiased individual prognosis predictions are attainable with deep learning. This is achieved by (1) setting a dual task for the network to predict both the outcome and the collider and (2) enforcing a form of linear independence of the activation distributions of the last layer. Our method provides an example of combining deep learning and structural causal models to achieve unbiased individual prognosis predictions. Extensions of machine learning methods for applications to causal questions are required to attain the long-standing goal of personalized medicine supported by artificial intelligence.",
      "authors": "van Amsterdam W A C; Verhoeff J J C; de Jong P A; Leiner T; Eijkemans M J C",
      "year": "2019",
      "journal": "NPJ digital medicine",
      "doi": "10.1038/s41746-019-0194-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31840093/",
      "mesh_terms": "",
      "keywords": "Computed tomography; Computer science; Epidemiology; Prognosis",
      "pub_types": "Journal Article",
      "pmcid": "PMC6904461"
    },
    {
      "pmid": "33313606",
      "title": "Frequent Causal Pattern Mining: A Computationally Efficient Framework For Estimating Bias-Corrected Effects.",
      "abstract": "Our aging population increasingly suffers from multiple chronic diseases simultaneously, necessitating the comprehensive treatment of these conditions. Finding the optimal set of drugs for a combinatorial set of diseases is a combinatorial pattern exploration problem. Association rule mining is a popular tool for such problems, but the requirement of health care for finding causal, rather than associative, patterns renders association rule mining unsuitable. To address this issue, we propose a novel framework based on the Rubin-Neyman causal model for extracting causal rules from observational data, correcting for a number of common biases. Specifically, given a set of interventions and a set of items that define subpopulations (e.g., diseases), we wish to find all subpopulations in which effective intervention combinations exist and in each such subpopulation, we wish to find all intervention combinations such that dropping any intervention from this combination will reduce the efficacy of the treatment. A key aspect of our framework is the concept of closed intervention sets which extend the concept of quantifying the effect of a single intervention to a set of concurrent interventions. Closed intervention sets also allow for a pruning strategy that is strictly more efficient than the traditional pruning strategy used by the Apriori algorithm. To implement our ideas, we introduce and compare five methods of estimating causal effect from observational data and rigorously evaluate them on synthetic data to mathematically prove (when possible) why they work. We also evaluated our causal rule mining framework on the Electronic Health Records (EHR) data of a large cohort of 152000 patients from Mayo Clinic and showed that the patterns we extracted are sufficiently rich to explain the controversial findings in the medical literature regarding the effect of a class of cholesterol drugs on Type-II Diabetes Mellitus (T2DM).",
      "authors": "Yadav Pranjul; Caraballo Pedro J; Steinbach Michael; Kumar Vipin; Castro M Regina; Simon Gyorgy",
      "year": "2019",
      "journal": "Proceedings : ... IEEE International Conference on Big Data. IEEE International Conference on Big Data",
      "doi": "10.1109/bigdata47090.2019.9005977",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33313606/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC7730315"
    },
    {
      "pmid": "41088416",
      "title": "PURE: policy-guided unbiased REpresentations for structure-constrained molecular generation.",
      "abstract": "Structure-constrained molecular generation (SCMG) generates novel molecules that are structurally similar to a given molecule and have optimized properties. Deep learning solutions for SCMG are limited in that they are predisposed towards existing knowledge, and they suffer from a natural impedance mismatch problem due to the discrete nature of molecules, while deep learning methods for SCMG often operate in continuous space. Moreover, many task-specific evaluation metrics used during training often bias the model towards a particular metric -\"metric-leakage\". To overcome these shortcomings, we propose Policy-guided Unbiased REpresentations (PURE) for SCMG that learns within a framework simulating molecular transformations for drug synthesis. PURE combines self-supervised learning with a policy-based reinforcement\u00a0learning (RL) framework, thereby avoiding the need for external molecular metrics while learning high-quality representations that incorporate an inherent notion of similarity specific to the given task. Along with a semi-supervised training design, PURE utilizes template-based molecular simulations to better explore and navigate the discrete molecular search space. Despite the lack of metric biases, PURE achieves competitive or superior performance to state-of-the-art methods on multiple benchmarks. Our study emphasizes the importance of reevaluating current approaches for SCMG and developing strategies that naturally align with the problem. Finally, we illustrate how our methodology can be applied to combat drug resistance by identifying sorafenib-like compounds as a case study.",
      "authors": "Gupta Abhor; Lenin Barathi; Current Sean; Batra Rohit; Ravindran Balaraman; Raman Karthik; Parthasarathy Srinivasan",
      "year": "2025",
      "journal": "Journal of cheminformatics",
      "doi": "10.1186/s13321-025-01090-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41088416/",
      "mesh_terms": "",
      "keywords": "Cancer drugs; Deep learning; Drug discovery; Drug resistance; Drug synthesis; Human health; Lead optimization; Machine learning; Product innovation; Reinforcement learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC12522651"
    },
    {
      "pmid": "40824638",
      "title": "Performance of 4 Methods to Assess Health-Related Social Needs.",
      "abstract": "IMPORTANCE: Organizations use health-related social needs (HRSN) information to identify patients in need of referrals, to increase clinician awareness, to improve analytics, and for quality reporting. OBJECTIVE: To contrast the performance of screening questionnaires, natural language processing (NLP) of clinical notes, rule-based computable phenotypes, and machine learning (ML) classification models in measuring HRSNs. DESIGN, SETTING, AND PARTICIPANTS: This cross-sectional study assessed 4 measurement approaches for 5 HRSNs in parallel. Each approach was treated as a screening test. Data included notes from adult patients treated at primary care clinics in 2 health systems in Indianapolis, Indiana, from January 2022 to June 2023. Data were analyzed from December 2024 to February 2025. EXPOSURES: Reference standard instruments measured food insecurity, housing instability, financial strain, transportation barriers, and history of legal problems. Participants completed the HRSN screening questions in the electronic health record (EHR). NLP algorithms, gradient-boosted decision tree ML classifiers, and refined versions of human-defined rule-based computable phenotypes were applied to participants' past 12 months EHR data. MAIN OUTCOMES AND MEASURES: Sensitivity, specificity, area under the curve (AUC), and positive predictive values (PPV) described performance of each approach against the reference standard measures. False-negative rates were used to explore fairness. RESULTS: Data from a total of 1252 adult patients (407 [32.51%] aged 30 to 49 years; 821 [65.58%] female) were assessed, including 94 (7.51%) who identified as Hispanic, 602 (48.08%) as non-Hispanic Black or African American, and 442 (35.30%) as non-Hispanic White. The screening questions method had the strongest overall performance for food insecurity (AUC, 0.94; 95% CI, 0.93-0.95), housing instability (AUC, 0.78; 95% CI, 0.75-0.80), transportation barriers (AUC, 0.77; 95% CI, 0.74-0.79), and legal problems (AUC, 0.81; 95% CI, 0.77-0.85). The screening questions had poor performance for financial strain (AUC, 0.62; 95% CI, 0.60-0.65). The PPV for screening tools ranged from 0.77 to 0.92, indicating utility for individual-level decision-making. NLP and rule-based computable phenotypes had poor performance. ML classification resulted in higher sensitivities than the other methods. False-negative rates indicated differential, unfair performance for all measurement approaches by gender, race and ethnicity, and age groups. CONCLUSIONS AND RELEVANCE: In this cross-sectional study of HRSN measurement, no approach performed strongly for every HRSN, and every approach had indication of unfair performance. These findings suggest that practitioners, health care and public health organizations, researchers, and policymakers who rely on a single method to collect HRSN data will likely underestimate patients' true social burden.",
      "authors": "Vest Joshua R; Wu Wei; Gregory Megan E; Kasturi Suranga N; Mendonca Eneida A; Bian Jiang; Magoc Tanja; Grannis Shaun; McNamee Cassidy; Harle Christopher A",
      "year": "2025",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2025.27426",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40824638/",
      "mesh_terms": "Humans; Cross-Sectional Studies; Female; Male; Middle Aged; Adult; Needs Assessment; Electronic Health Records; Machine Learning; Indiana; Surveys and Questionnaires; Natural Language Processing; Sensitivity and Specificity; Aged",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12362220"
    },
    {
      "pmid": "40969781",
      "title": "Using a Large Language Model (ChatGPT-4o) to Assess the Risk of Bias in Randomized Controlled Trials of Medical Interventions: Interrater Agreement With Human Reviewers.",
      "abstract": "BACKGROUND: Risk of bias (RoB) assessment is a highly skilled task that is time-consuming and subject to human error. RoB automation tools have previously used machine learning models built using relatively small task-specific training sets. Large language models (LLMs; e.g., ChatGPT) are complex models built using non-task-specific Internet-scale training sets. They demonstrate human-like abilities and might be able to support tasks like RoB assessment. METHODS: Following a published peer-reviewed protocol, we randomly sampled 100 Cochrane reviews. New or updated reviews that evaluated medical interventions, included \u2265\u20091 eligible trial, and presented human consensus assessments using Cochrane RoB1 or RoB2 were eligible. We excluded reviews performed under emergency conditions (e.g., COVID-19), and those on public health or welfare. We randomly sampled one trial from each review. Trials using individual- or cluster-randomized designs were eligible. We extracted human consensus RoB assessments of the trials from the reviews, and methods texts from the trials. We used 25 review-trial pairs to develop a ChatGPT prompt to assess RoB using trial methods text. We used the prompt and the remaining 75 review-trial pairs to estimate human-ChatGPT agreement for \"Overall RoB\" (primary outcome) and \"RoB due to the randomization process\", and ChatGPT-ChatGPT (intrarater) agreement for \"Overall RoB\". We used ChatGPT-4o (February 2025) throughout. RESULTS: The 75 reviews were sampled from 35 Cochrane review groups, and all used RoB1. The 75 trials spanned five decades, and all but one were published in English. Human-ChatGPT agreement for \"Overall RoB\" assessment was 50.7% (95% CI 39.3%-62.0%), substantially higher than expected by chance (p\u2009=\u20090.0015). Human-ChatGPT agreement for \"RoB due to the randomization process\" was 78.7% (95% CI 69.4%-88.0%; p\u2009<\u20090.001). ChatGPT-ChatGPT agreement was 74.7% (95% CI 64.8%-84.6%; p\u2009<\u20090.001). CONCLUSIONS: ChatGPT appears to have some ability to assess RoB and is unlikely to be guessing or \"hallucinating\". The estimated agreement for \"Overall RoB\" is well above estimates of agreement reported for some human reviewers, but below the highest estimates. LLM-based systems for assessing RoB may be able to help streamline and improve evidence synthesis production.",
      "authors": "Rose Christopher James; Bidonde Julia; Ringsten Martin; Glanville Julie; Potrebny Thomas; Cooper Chris; Muller Ashley Elizabeth; Bergsund Hans Bugge; Meneses-Echavez Jose F; Berg Rigmor C",
      "year": "2025",
      "journal": "Cochrane evidence synthesis and methods",
      "doi": "10.1002/cesm.70048",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40969781/",
      "mesh_terms": "",
      "keywords": "ChatGPT; LLM; RoB; artificial intelligence; evidence synthesis; large language model; risk of bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC12442625"
    },
    {
      "pmid": "34895784",
      "title": "Willingness to vaccinate against SARS-CoV-2: The role of reasoning biases and conspiracist ideation.",
      "abstract": "UNLABELLED: BACKGR1OUND: Widespread vaccine hesitancy and refusal complicate containment of the SARS-CoV-2 pandemic. Extant research indicates that biased reasoning and conspiracist ideation discourage vaccination. However, causal pathways from these constructs to vaccine hesitancy and refusal remain underspecified, impeding efforts to intervene and increase vaccine uptake. METHOD: 554 participants who denied prior SARS-CoV-2 vaccination completed self-report measures of SARS-CoV-2 vaccine intentions, conspiracist ideation, and constructs from the Health Belief Model of medical decision-making (such as perceived vaccine dangerousness) along with tasks measuring reasoning biases (such as those concerning data gathering behavior). Cutting-edge machine learning algorithms (Greedy Fast Causal Inference) and psychometric network analysis were used to elucidate causal pathways to (and from) vaccine intentions. RESULTS: Results indicated that a bias toward reduced data gathering during reasoning may cause paranoia, increasing the perceived dangerousness of vaccines and thereby reducing willingness to vaccinate. Existing interventions that target data gathering and paranoia therefore hold promise for encouraging vaccination. Additionally, reduced willingness to vaccinate was identified as a likely cause of belief in conspiracy theories, subverting the common assumption that the opposite causal relation exists. Finally, perceived severity of SARS-CoV-2 infection and perceived vaccine dangerousness (but not effectiveness) were potential direct causes of willingness to vaccinate, providing partial support for the Health Belief Model's applicability to SARS-CoV-2 vaccine decisions. CONCLUSIONS: These insights significantly advance our understanding of the underpinnings of vaccine intentions and should scaffold efforts to prepare more effective interventions on hesitancy for deployment during future pandemics.",
      "authors": "Bronstein Michael V; Kummerfeld Erich; MacDonald Angus; Vinogradov Sophia",
      "year": "2022",
      "journal": "Vaccine",
      "doi": "10.1016/j.vaccine.2021.11.079",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34895784/",
      "mesh_terms": "Bias; COVID-19; COVID-19 Vaccines; Humans; SARS-CoV-2; Vaccination; Vaccination Hesitancy",
      "keywords": "COVID-19; Conspiracy theories; GFCI; Reasoning; SARS-CoV-2; Vaccines",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC8642163"
    },
    {
      "pmid": "30522989",
      "title": "Characterizing Tweet Volume and Content About Common Health Conditions Across Pennsylvania: Retrospective Analysis.",
      "abstract": "BACKGROUND: Tweets can provide broad, real-time perspectives about health and medical diagnoses that can inform disease surveillance in geographic regions. Less is known, however, about how much individuals post about common health conditions or what they post about. OBJECTIVE: We sought to collect and analyze tweets from 1 state about high prevalence health conditions and characterize the tweet volume and content. METHODS: We collected 408,296,620 tweets originating in Pennsylvania from 2012-2015 and compared the prevalence of 14 common diseases to the frequency of disease mentions on Twitter. We identified and corrected bias induced due to variance in disease term specificity and used the machine learning approach of differential language analysis to determine the content (words and themes) most highly correlated with each disease. RESULTS: Common disease terms were included in 226,802 tweets (174,381 tweets after disease term correction). Posts about breast cancer (39,156/174,381 messages, 22.45%; 306,127/12,702,379 prevalence, 2.41%) and diabetes (40,217/174,381 messages, 23.06%; 2,189,890/12,702,379 prevalence, 17.24%) were overrepresented on Twitter relative to disease prevalence, whereas hypertension (17,245/174,381 messages, 9.89%; 4,614,776/12,702,379 prevalence, 36.33%), chronic obstructive pulmonary disease (1648/174,381 messages, 0.95%; 1,083,627/12,702,379 prevalence, 8.53%), and heart disease (13,669/174,381 messages, 7.84%; 2,461,721/12,702,379 prevalence, 19.38%) were underrepresented. The content of messages also varied by disease. Personal experience messages accounted for 12.88% (578/4487) of prostate cancer tweets and 24.17% (4046/16,742) of asthma tweets. Awareness-themed tweets were more often about breast cancer (9139/39,156 messages, 23.34%) than asthma (1040/16,742 messages, 6.21%). Tweets about risk factors were more often about heart disease (1375/13,669 messages, 10.06%) than lymphoma (105/4927 messages, 2.13%). CONCLUSIONS: Twitter provides a window into the Web-based visibility of diseases and how the volume of Web-based content about diseases varies by condition. Further, the potential value in tweets is in the rich content they provide about individuals' perspectives about diseases (eg, personal experiences, awareness, and risk factors) that are not otherwise easily captured through traditional surveys or administrative data.",
      "authors": "Tufts Christopher; Polsky Daniel; Volpp Kevin G; Groeneveld Peter W; Ungar Lyle; Merchant Raina M; Pelullo Arthur P",
      "year": "2018",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/10834",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30522989/",
      "mesh_terms": "",
      "keywords": "Twitter messaging; disease; prevalence; public health surveillance; social media",
      "pub_types": "Journal Article",
      "pmcid": "PMC6302232"
    },
    {
      "pmid": "38240915",
      "title": "Quantifying bias due to missing data in quality of life surveys of advanced-stage cancer patients.",
      "abstract": "PURPOSE: Many studies on cancer patients investigate the impact of treatment on health-related quality of life (QoL). Typically, QoL is measured longitudinally, at baseline and at predefined timepoints thereafter. The question is whether, at a given timepoint, patients who return their questionnaire (available cases, AC) have a different QoL than those who do not return their questionnaire (non-AC). METHODS: We employed augmented inverse probability weighting (AIPW) to estimate the average QoL of non-AC in two studies on advanced-stage cancer patients. The AIPW estimator assumed data to be missing at random (MAR) and used machine learning (ML)-based methods to estimate answering probabilities of individuals at given timepoints as well as their reported QoL, as a function of auxiliary variables. These auxiliary variables were selected by medical oncologists based on domain expertise. We aggregated results both by timepoint and by time until death and compared AIPW estimates to the AC averages. Additionally, we used a pattern mixture model (PMM) to check sensitivity of our AIPW estimates against violation of the MAR assumption. RESULTS: Our study included 1927 patients with advanced pancreatic and 797 patients with advanced breast cancer. The AIPW estimate for average QoL of non-AC was below the average QoL of AC when aggregated by timepoint. The difference vanished when aggregated by time until death. PMM estimates were below AIPW estimates. CONCLUSIONS: Our results indicate that non-AC have a lower average QoL than AC. However, estimates for QoL of non-AC are subject to unverifiable assumptions about the missingness mechanism.",
      "authors": "Haug Nina; J\u00e4nicke Martina; Kasenda Benjamin; Marschner Norbert; Frank Melanie",
      "year": "2024",
      "journal": "Quality of life research : an international journal of quality of life aspects of treatment, care and rehabilitation",
      "doi": "10.1007/s11136-023-03588-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38240915/",
      "mesh_terms": "Humans; Female; Quality of Life; Breast Neoplasms; Surveys and Questionnaires; Bias",
      "keywords": "Augmented inverse probability weighting; Breast cancer; Double robust methods; Longitudinal studies; Missing data; Oncology; Pancreatic cancer",
      "pub_types": "Journal Article",
      "pmcid": "8789297"
    },
    {
      "pmid": "22092021",
      "title": "Examining multiple sources of differential item functioning on the Clinician & Group CAHPS\u00ae survey.",
      "abstract": "OBJECTIVE: To evaluate psychometric properties of a widely used patient experience survey. DATA SOURCES: English-language responses to the Clinician & Group Consumer Assessment of Healthcare Providers and Systems (CG-CAHPS\u00ae) survey (n = 12,244) from a 2008 quality improvement initiative involving eight southern California medical groups. METHODS: We used an iterative hybrid ordinal logistic regression/item response theory differential item functioning (DIF) algorithm to identify items with DIF related to patient sociodemographic characteristics, duration of the physician-patient relationship, number of physician visits, and self-rated physical and mental health. We accounted for all sources of DIF and determined its cumulative impact. PRINCIPAL FINDINGS: The upper end of the CG-CAHPS\u00ae performance range is measured with low precision. With sensitive settings, some items were found to have DIF. However, overall DIF impact was negligible, as 0.14 percent of participants had salient DIF impact. Latinos who spoke predominantly English at home had the highest prevalence of salient DIF impact at 0.26 percent. CONCLUSIONS: The CG-CAHPS\u00ae functions similarly across commercially insured respondents from diverse backgrounds. Consequently, previously documented racial and ethnic group differences likely reflect true differences rather than measurement bias. The impact of low precision at the upper end of the scale should be clarified.",
      "authors": "Rodriguez Hector P; Crane Paul K",
      "year": "2011",
      "journal": "Health services research",
      "doi": "10.1111/j.1475-6773.2011.01299.x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/22092021/",
      "mesh_terms": "Adult; Age Factors; Algorithms; Body Mass Index; Educational Status; Ethnicity; Female; Health Status; Humans; Language; Logistic Models; Male; Mental Health; Middle Aged; Patient Satisfaction; Physician-Patient Relations; Primary Health Care; Psychometrics; Racial Groups; Sex Factors; Surveys and Questionnaires",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC3393020"
    },
    {
      "pmid": "41148137",
      "title": "Incomplete Family History and Meeting Algorithmic Criteria for Genetic Evaluation of Hereditary Cancer.",
      "abstract": "IMPORTANCE: Incomplete electronic health record (EHR) documentation may limit the effectiveness of clinical decision support (CDS) algorithms designed to identify patients eligible for hereditary cancer genetic evaluation. OBJECTIVES: To determine whether a CDS algorithm can identify patients who meet criteria for hereditary cancer genetic evaluation when family history data are incompletely documented in the EHR, and to examine whether data missingness is associated with identification patterns across patient subgroups. DESIGN, SETTING, AND PARTICIPANTS: This cross-sectional study analyzed EHR data extracted in December 2020 from 2 large US health care systems: University of Utah Health (UHealth) and NYU Langone Health (NYULH). Eligible patients were adults aged 25 to 60 years who visited a primary care clinic within the previous 3 years and had some EHR documentation of cancer family history. Data analysis was conducted in August 2024. EXPOSURES: Patient demographic factors (age, sex, race and ethnicity, and language preference) and cancer family history characteristics (number of cancer history records, number of affected first- and second-degree relatives, relatives with rising mortality cancers, presence of hereditary cancer-related terms in comments, and completeness of documentation). MAIN OUTCOMES AND MEASURES: The primary outcome was meeting at least 1 CDS algorithm criterion for genetic evaluation of hereditary cancer risk based on National Comprehensive Cancer Network guidelines. Missing data patterns were assessed using the Little missing completely at random test, with analyses conducted using complete case analysis and multiple imputation. RESULTS: This study included 157\u202f207 patients: 55\u202f918 from UHealth and 101\u202f289 from NYULH. Their mean (SD) age was 43.5 (9.8) years, and most (65.7%) were female. A total of 5607 UHealth patients (10.0%) and 10 375 NYULH patients (10.2%) met CDS criteria for genetic evaluation. At UHealth, data appeared to be missing completely at random (\u03c7239\u2009=\u200939.09; P\u2009=\u2009.47), and complete case compared with multiple imputation analyses yielded similar results. At NYULH, data were not missing completely at random (\u03c7255\u2009=\u2009914.89; P\u2009<\u2009.001). Compared with multiple imputation, complete case analysis produced different association magnitudes for older age and having relatives with rising mortality cancers, suggesting bias when excluding incomplete records. CONCLUSIONS AND RELEVANCE: In this cross-sectional study, the magnitude of the association between incomplete family history documentation and identification of patients eligible for hereditary cancer genetic evaluation depended on whether data were missing randomly or systematically. These findings suggest that health care organizations implementing CDS algorithms should assess their specific missing data patterns and consider tailored approaches to handling incomplete family history information to ensure equitable identification of all patients who could benefit from genetic evaluation services.",
      "authors": "Harris Adrian; Bather Jemar R; Bradshaw Richard L; Kawamoto Kensaku; Del Fiol Guilherme; Kohlmann Wendy K; Chavez-Yenter Daniel; Monahan Rachel; Chambers Rachelle L; Sigireddi Meenakshi; Goodman Melody S; Kaphingst Kimberly A",
      "year": "2025",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2025.39870",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41148137/",
      "mesh_terms": "Humans; Male; Female; Cross-Sectional Studies; Middle Aged; Algorithms; Adult; Electronic Health Records; Genetic Testing; Neoplasms; Medical History Taking; Decision Support Systems, Clinical; Genetic Predisposition to Disease; Utah",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12569706"
    },
    {
      "pmid": "36414774",
      "title": "Mitigating the impact of biased artificial intelligence in emergency decision-making.",
      "abstract": "BACKGROUND: Prior research has shown that artificial intelligence (AI) systems often encode biases against minority subgroups. However, little work has focused on ways to mitigate the harm discriminatory algorithms can cause in high-stakes settings such as medicine. METHODS: In this study, we experimentally evaluated the impact biased AI recommendations have on emergency decisions, where participants respond to mental health crises by calling for either medical or police assistance. We recruited 438 clinicians and 516 non-experts to participate in our web-based experiment. We evaluated participant decision-making with and without advice from biased and unbiased AI systems. We also varied the style of the AI advice, framing it either as prescriptive recommendations or descriptive flags. RESULTS: Participant decisions are unbiased without AI advice. However, both clinicians and non-experts are influenced by prescriptive recommendations from a biased algorithm, choosing police help more often in emergencies involving African-American or Muslim men. Crucially, using descriptive flags rather than prescriptive recommendations allows respondents to retain their original, unbiased decision-making. CONCLUSIONS: Our work demonstrates the practical danger of using biased models in health contexts, and suggests that appropriately framing decision support can mitigate the effects of AI bias. These findings must be carefully considered in the many real-world clinical scenarios where inaccurate or biased models may be used to inform important decisions.",
      "authors": "Adam Hammaad; Balagopalan Aparna; Alsentzer Emily; Christia Fotini; Ghassemi Marzyeh",
      "year": "2022",
      "journal": "Communications medicine",
      "doi": "10.1038/s43856-022-00214-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36414774/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9681767"
    },
    {
      "pmid": "40993641",
      "title": "Association between geriatric nutritional risk index (GNRI) and asthma in elderly individuals aged 60 and above: a cross-sectional study of the NHANES 2005-2018.",
      "abstract": "OBJECTIVE: The geriatric nutritional risk index (GNRI) is a promising tool for predicting nutrition-related complications in older adults. This study aimed to explore the association between GNRI and asthma in individuals aged 60 and above. METHODS: A retrospective cohort study was conducted using the National Health and Nutrition Examination Survey (NHANES) database. Propensity score matching was used to manage observational data to minimize clinical data bias and confounding variables. Weighted logistic regression with subgroup and sensitivity analyses was used to analyze the potential relationship between GNRI and asthma in elderly individuals aged 60 and above. RESULTS: The study population consisted of individuals aged 60 and above. After adjusting for race, education, emphysema, and chronic bronchitis, the odds ratio (OR) for asthma in relation to the GNRI was 1.021 (95% confidence interval [CI]: 1.016-1.026, P\u2009<\u20090.001), indicating that a lower GNRI is associated with a higher risk of asthma in elderly individuals.The GNRI quartile analysis revealed a significant upward trend (Q4 versus Q1, OR: 1.666, 95% CI: 1.41-1.972, P\u2009<\u20090.001). The significance of the selected factors was assessed using the XGBoost machine learning model, which demonstrated that the GNRI was one of the top five variables influencing the risk of asthma in elderly individuals. Subgroup analysis confirmed the association between GNRI and factors such as gender, race, smoking, alcohol consumption, education level, poverty income ratio, emphysema, and chronic bronchitis. Furthermore, GNRI levels were associated with increased eosinophils, basophils, white blood cells, red blood cells, neutrophils, monocytes, and albumin levels. CONCLUSION: This study demonstrates that GNRI levels are significantly associated with asthma in the elderly.",
      "authors": "Wang Jue; Wang ZiMeng; Zhang Qi; Yu Shiting",
      "year": "2025",
      "journal": "BMC pulmonary medicine",
      "doi": "10.1186/s12890-025-03830-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40993641/",
      "mesh_terms": "Humans; Asthma; Male; Female; Aged; Retrospective Studies; Cross-Sectional Studies; Nutrition Surveys; Middle Aged; Geriatric Assessment; Risk Factors; Nutritional Status; Nutrition Assessment; Propensity Score; Aged, 80 and over; Logistic Models; Risk Assessment; United States",
      "keywords": "Asthma; Cohort analysis; Geriatric nutritional risk index (GNRI); NHANES; Over 60\u00a0years old; XGBoost machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC12462012"
    },
    {
      "pmid": "39199522",
      "title": "Leveraging Artificial Intelligence to Optimize Transcranial Direct Current Stimulation for Long COVID Management: A Forward-Looking Perspective.",
      "abstract": "Long COVID (Coronavirus disease), affecting millions globally, presents unprecedented challenges to healthcare systems due to its complex, multifaceted nature and the lack of effective treatments. This perspective review explores the potential of artificial intelligence (AI)-guided transcranial direct current stimulation (tDCS) as an innovative approach to address the urgent need for effective Long COVID management. The authors examine how AI could optimize tDCS protocols, enhance clinical trial design, and facilitate personalized treatment for the heterogeneous manifestations of Long COVID. Key areas discussed include AI-driven personalization of tDCS parameters based on individual patient characteristics and real-time symptom fluctuations, the use of machine learning for patient stratification, and the development of more sensitive outcome measures in clinical trials. This perspective addresses ethical considerations surrounding data privacy, algorithmic bias, and equitable access to AI-enhanced treatments. It also explores challenges and opportunities for implementing AI-guided tDCS across diverse healthcare settings globally. Future research directions are outlined, including the need for large-scale validation studies and investigations of long-term efficacy and safety. The authors argue that while AI-guided tDCS shows promise for addressing the complex nature of Long COVID, significant technical, ethical, and practical challenges remain. They emphasize the importance of interdisciplinary collaboration, patient-centered approaches, and a commitment to global health equity in realizing the potential of this technology. This perspective article provides a roadmap for researchers, clinicians, and policymakers involved in developing and implementing AI-guided neuromodulation therapies for Long COVID and potentially other neurological and psychiatric conditions.",
      "authors": "Rudroff Thorsten; Rainio Oona; Kl\u00e9n Riku",
      "year": "2024",
      "journal": "Brain sciences",
      "doi": "10.3390/brainsci14080831",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39199522/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; brain stimulation; long COVID; neuroimaging",
      "pub_types": "Journal Article",
      "pmcid": "PMC11353063"
    },
    {
      "pmid": "38286672",
      "title": "Improving our understanding of the social determinants of mental health: a data linkage study of mental health records and the 2011 UK census.",
      "abstract": "OBJECTIVES: To address the lack of individual-level socioeconomic information in electronic healthcare records, we linked the 2011 census of England and Wales to patient records from a large mental healthcare provider. This paper describes the linkage process and methods for mitigating bias due to non-matching. SETTING: South London and Maudsley NHS Foundation Trust (SLaM), a mental healthcare provider in Southeast London. DESIGN: Clinical records from SLaM were supplied to the Office of National Statistics for linkage to the census through a deterministic matching algorithm. We examined clinical (International Classification of Disease-10 diagnosis, history of hospitalisation, frequency of service contact) and socio-demographic (age, gender, ethnicity, deprivation) information recorded in Clinical Record Interactive Search (CRIS) as predictors of linkage success with the 2011 census. To assess and adjust for potential biases caused by non-matching, we evaluated inverse probability weighting for mortality associations. PARTICIPANTS: Individuals of all ages in contact with SLaM up until December 2019 (N=459\u2009374). OUTCOME MEASURES: Likelihood of mental health records' linkage to census. RESULTS: 220\u2009864 (50.4%) records from CRIS linked to the 2011 census. Young adults (prevalence ratio (PR) 0.80, 95%\u2009CI 0.80 to 0.81), individuals living in more deprived areas (PR 0.78, 95% CI 0.78 to 0.79) and minority ethnic groups (eg, Black African, PR 0.67, 0.66 to 0.68) were less likely to match to census. After implementing inverse probability weighting, we observed little change in the strength of association between clinical/demographic characteristics and mortality (eg, presence of any psychiatric disorder: unweighted PR 2.66, 95%\u2009CI 2.52 to 2.80; weighted PR 2.70, 95%\u2009CI 2.56 to 2.84). CONCLUSIONS: Lower response rates to the 2011 census among people with psychiatric disorders may have contributed to lower match rates, a potential concern as the census informs service planning and allocation of resources. Due to its size and unique characteristics, the linked data set will enable novel investigations into the relationship between socioeconomic factors and psychiatric disorders.",
      "authors": "Cybulski Lukasz; Chilman Natasha; Jewell Amelia; Dewey Michael; Hildersley Rosanna; Morgan Craig; Huck Rachel; Hotopf Matthew; Stewart Robert; Pritchard Megan; Wuerth Milena; Das-Munshi Jayati",
      "year": "2024",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2023-073582",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38286672/",
      "mesh_terms": "Young Adult; Humans; Mental Health; Censuses; Social Determinants of Health; England; London; Information Storage and Retrieval; Electronic Health Records",
      "keywords": "mental health; psychiatry; schizophrenia & psychotic disorders",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10826590"
    },
    {
      "pmid": "32568726",
      "title": "Racial and Ethnic Digital Divides in Posting COVID-19 Content on Social Media Among US Adults: Secondary Survey Analysis.",
      "abstract": "BACKGROUND: Public health surveillance experts are leveraging user-generated content on social media to track the spread and effects of COVID-19. However, racial and ethnic digital divides, which are disparities among people who have internet access and post on social media, can bias inferences. This bias is particularly problematic in the context of the COVID-19 pandemic because due to structural inequalities, members of racial and ethnic minority groups are disproportionately vulnerable to contracting the virus and to the deleterious economic and social effects from mitigation efforts. Further, important demographic intersections with race and ethnicity, such as gender and age, are rarely investigated in work characterizing social media users; however, they reflect additional axes of inequality shaping differential exposure to COVID-19 and its effects. OBJECTIVE: The aim of this study was to characterize how the race and ethnicity of US adults are associated with their odds of posting COVID-19 content on social media and how gender and age modify these odds. METHODS: We performed a secondary analysis of a survey conducted by the Pew Research Center from March 19 to 24, 2020, using a national probability sample (N=10,510). Respondents were recruited from an online panel, where panelists without an internet-enabled device were given one to keep at no cost. The binary dependent variable was responses to an item asking whether respondents \"used social media to share or post information about the coronavirus.\" We used survey-weighted logistic regressions to estimate the odds of responding in the affirmative based on the race and ethnicity of respondents (white, black, Latino, other race/ethnicity), adjusted for covariates measuring sociodemographic background and COVID-19 experiences. We examined how gender (female, male) and age (18 to 30 years, 31 to 50 years, 51 to 64 years, and 65 years and older) intersected with race and ethnicity by estimating interactions. RESULTS: Respondents who identified as black (odds ratio [OR] 1.29, 95% CI 1.02-1.64; P=.03), Latino (OR 1.66, 95% CI 1.36-2.04; P<.001), or other races/ethnicities (OR 1.33, 95% CI 1.02-1.72; P=.03) had higher odds than respondents who identified as white of reporting that they posted COVID-19 content on social media. Women had higher odds of posting than men regardless of race and ethnicity (OR 1.58, 95% CI 1.39-1.80; P<.001). Among men, respondents who identified as black, Latino, or members of other races/ethnicities were significantly more likely to post than respondents who identified as white. Older adults (65 years or older) had significantly lower odds (OR 0.73, 95% CI 0.57-0.94; P=.01) of posting compared to younger adults (18-29 years), particularly among those identifying as other races/ethnicities. Latino respondents were the most likely to report posting across all age groups. CONCLUSIONS: In the United States, members of racial and ethnic minority groups are most likely to contribute to COVID-19 content on social media, particularly among groups traditionally less likely to use social media (older adults and men). The next step is to ensure that data collection procedures capture this diversity by encompassing a breadth of search criteria and social media platforms.",
      "authors": "Campos-Castillo Celeste; Laestadius Linnea I",
      "year": "2020",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/20472",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32568726/",
      "mesh_terms": "Adolescent; Black or African American; Age Factors; Aged; Betacoronavirus; COVID-19; Coronavirus Infections; Digital Divide; Ethnicity; Female; Hispanic or Latino; Humans; Male; Middle Aged; Minority Groups; Odds Ratio; Pandemics; Pneumonia, Viral; Racial Groups; SARS-CoV-2; Sex Factors; Social Media; Socioeconomic Factors; Surveys and Questionnaires; United States; White People; Young Adult",
      "keywords": "COVID-19; algorithm bias; bias; digital divides; ethnicity; public health; race; social media; surveillance; user characteristics",
      "pub_types": "Journal Article",
      "pmcid": "PMC7340161"
    },
    {
      "pmid": "41282840",
      "title": "Nonfasting, Telehealth-Ready LDL-C Testing With Machine Learning to Improve Cardiovascular Access and Equity.",
      "abstract": "IMPORTANCE: Current LDL-C testing requires 9-12 hour fasting and in-person visits, creating an access crisis: 40% of lipid panels occur outside fasting windows (yielding unreliable results), 60% of US counties lack cardiology services, and millions of patients with diabetes cannot safely fast. Meanwhile, telehealth infrastructure expanded 38-fold post-COVID, yet lipid workflows remain anchored to 1970s protocols. This mismatch drives ~20 million unnecessary repeat visits annually, disproportionately burdening Medicaid populations, essential workers, and rural communities. OBJECTIVE: To demonstrate that machine learning can transform lipid testing from a fasting-dependent, clinic-based bottleneck into an accurate, equitable, telehealth-ready service-eliminating three structural barriers simultaneously: fasting requirements, in-person visits, and racial algorithmic bias. DESIGN SETTING AND PARTICIPANTS: Cross-sectional analysis of All of Us Research Program (n=3,477; test n=696). Crucially, 40.1% were tested outside traditional fasting windows, reflecting real-world practice. We evaluated performance stratified by fasting status, telehealth feasibility (labs-only configuration), racial equity metrics, and economic impact. MAIN OUTCOMES AND MEASURES: Primary: MAE and calibration in non-fasting states. Secondary: Labs-only non-inferiority (\u00b10.5 mg dL-1margin); racial equity (Black-White performance gap); economic savings from eliminated repeat visits; and classification accuracy at treatment thresholds (70, 100, 130 mg dL-1). RESULTS: The ML system demonstrated paradoxical superiority in non-fasting conditions-precisely when needed most. While equations deteriorated (Friedewald MAE 29.1 vs 25.9 mg dL-1fasting, slopes 0.58-0.61), ML maintained accuracy (24.0 vs 23.2 mg dL-1, slopes 0.99-1.07), achieving 17.2% improvement over Friedewald when non-fasting vs 10.4% fasting. Labs-only configuration proved non-inferior (MAE=-0.12, p<0.001), enabling national retail-pharmacy and home-testing workflows. The system achieved racial equity without race input (Black-White gap -0.19 mg dL-1, CI includes zero) while providing greatest improvement for Black patients (19% vs 11% for White). Economically, eliminating 4,000 repeat visits per 10,000 tests helps address an estimated $2 billion annual repeat-testing cost burden and yields $815,000 total savings per 10,000 tests ($245,000 direct healthcare, $570,000 patient costs), with break-even at just 750 tests. CONCLUSIONS AND RELEVANCE: This ML approach helps address an estimated $2 billion annual problem of repeat testing while tackling three critical quality gaps in cardiovascular prevention: delayed treatment initiation, poor monitoring adherence, and specialty access barriers. By enabling accurate non-fasting, telehealth-compatible, race-free LDL-C estimation, it transforms lipid testing from an access barrier into an access enabler-particularly for the Medicaid, Medicare Advantage, and rural populations who drive both cost and outcomes in value-based care. From a technical standpoint, implementation requires only routine labs and <100 ms computation, making deployment feasible with existing infrastructure.",
      "authors": "Doku Ronald; Osafo Nana Yaw; Kwagyan John; Southerland William M",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.10.27.25338909",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41282840/",
      "mesh_terms": "",
      "keywords": "cardiovascular quality improvement; health equity; healthcare delivery; low-density lipoprotein cholesterol; machine learning; non-fasting lipid panel; telehealth; value-based care",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12636691"
    },
    {
      "pmid": "38426381",
      "title": "Analysis of agreement between measures of subjective cognitive impairment and probable dementia in the National Health and Aging Trends Study.",
      "abstract": "BACKGROUND: Subjective cognitive impairment (SCI) measures in population-based surveys offer potential for dementia surveillance, yet their validation against established dementia measures is lacking. METHODS: We assessed agreement between SCI and a validated probable dementia algorithm in a random one-third sample (n\u00a0=\u00a01936) of participants in the 2012 National Health and Aging Trends Study (NHATS). RESULTS: SCI was more prevalent than probable dementia (12.2%\u00a0vs 8.4%). Agreement between measures was 90.0% and of substantial strength. Misclassification rates were higher among older and less-educated subgroups due to higher prevalence of false-positive misclassification but did not vary by sex or race and ethnicity. DISCUSSION: SCI sensitivity (63.4%) and specificity (92.5%) against dementia were comparable with similar metrics for the NHATS probable dementia measure against the \"gold-standard\" Aging, Demographics, and Memory Study-based dementia criteria, implying that population-based surveys may afford cost-effective opportunities for dementia surveillance to assess risk and inform policy. HIGHLIGHTS: The prevalence of subjective cognitive impairment (SCI) is generally higher than that of a validated measure of probable dementia, particularly within the youngest age group, females, Whites, and persons with a college or higher degree. Percent agreement between SCI and a validated measure of probable dementia was 90.0% and of substantial strength (prevalence- and bias-adjusted kappa, 0.80). Agreement rates were higher in older and less-educated subgroups, driven by the higher prevalence of false-positive disagreement, but did not vary significantly by sex or race and ethnicity. SCI's overall sensitivity and specificity were 63.4% and 92.5%, respectively, against a validated measure of probable dementia, suggesting utility as a low-cost option for dementia surveillance. Heterogeneity in agreement quality across subpopulations warrants caution in its use for subgroup analyses.",
      "authors": "Chyr Linda C; Wolff Jennifer L; Zissimopoulos Julie M; Drabo Emmanuel F",
      "year": "2024",
      "journal": "Alzheimer's & dementia : the journal of the Alzheimer's Association",
      "doi": "10.1002/alz.13758",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38426381/",
      "mesh_terms": "Female; Humans; Aged; Cognition Disorders; Cognitive Dysfunction; Aging; Sensitivity and Specificity; Dementia",
      "keywords": "ADRD; Alzheimer's disease; NHATS; dementia; disability questionnaire; subjective cognitive impairment",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11032562"
    },
    {
      "pmid": "39470636",
      "title": "Electronic Health Record Phenotyping of Pediatric Suicide-Related Emergency Department Visits.",
      "abstract": "IMPORTANCE: Suicide is a leading cause of death among young people. Accurate detection of self-injurious thoughts and behaviors (SITB) underpins equity in youth suicide prevention. OBJECTIVES: To compare methods of detecting SITB using structured electronic health information and measure algorithmic performance across demographics. DESIGN, SETTING, AND PARTICIPANTS: This cross-sectional study used medical records among youths aged 6 to 17 years with at least 1 mental health-related emergency department (ED) visit in 2017 to 2019 to an academic health system in Southern California serving 787\u202f000 unique individuals each year. Analyses were conducted between January and September 2023. EXPOSURES: Multiexpert electronic health record review ascertained the presence of SITB using the Columbia Classification Algorithm of Suicide Assessment. Random forest classifiers with nested cross-validation were developed using (1) International Statistical Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM) codes for nonfatal suicide attempt and self-harm and chief concern and (2) all available structured data, including diagnoses, medications, and laboratory tests. MAIN OUTCOME AND MEASURES: Detection performance was assessed overall and stratified by age group, sex, and race and ethnicity. RESULTS: The sample comprised 2702 unique youths with an MH-related ED visit (1384 youths who identified as female [51.2%]; 131 Asian [4.8%], 266 Black [9.8%], 719 Hispanic [26.6%], 1319 White [48.8%], and 233 other race [8.6%]; median [IQR] age, 14 [12-16] years), including 898 children and 1804 adolescents. Approximately half of visits were related to SITB (1286 visits [47.6%]). Sensitivity of SITB detection using only codes and chief concern varied by age group and increased until age 15 years (6-9 years: 59.3% [95% CI, 48.5%-69.5%]; 10-12 years: 69.0% [95% CI, 63.8%-73.9%]; 13-15 years: 88.4% [95% CI, 85.1%-91.2%]; 16-17 years: 83.1% [95% CI, 79.1%-86.6%]), while specificity remained constant. The area under the receiver operating characteristic curve (AUROC) was lower among preadolescents (0.841 [95% CI, 0.815-0.867]) and male (0.869 [95% CI, 0.848-0.890]), Black (0.859 [95% CI, 0.813-0.905]), and Hispanic (0.861 [95% CI, 0.831-0.891]) youths compared with adolescents (0.925 [95% CI, 0.912-0.938]), female youths (0.923 [95% CI, 0.909-0.937]), and youths of other races and ethnicities (eg, White: 0.901 [95% CI, 0.884-0.918]). Augmented classification (ie, using all available structured data) outperformed classification with codes and chief concern alone (AUROC, 0.975 [95% CI, 0.968-0.980] vs 0.894 [95% CI, 0.882-0.905]; P\u2009<\u2009.001). CONCLUSIONS AND RELEVANCE: In this study, diagnostic codes and chief concern underestimated SITB prevalence, particularly among minoritized youths. These results suggest that priority on algorithmic fairness in suicide prevention strategies must extend to accurate detection of youths with suicide-related emergencies.",
      "authors": "Edgcomb Juliet Beni; Olde Loohuis Loes; Tseng Chi-Hong; Klomhaus Alexandra M; Choi Kristen R; Ponce Chrislie G; Zima Bonnie T",
      "year": "2024",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2024.42091",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39470636/",
      "mesh_terms": "Humans; Adolescent; Male; Female; Emergency Service, Hospital; Child; Cross-Sectional Studies; Electronic Health Records; California; Suicide, Attempted; Self-Injurious Behavior; Suicide; Phenotype; Emergency Room Visits",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11522940"
    },
    {
      "pmid": "40266658",
      "title": "Development and Validation of a Dynamic Real-Time Risk Prediction Model for Intensive Care Units Patients Based on Longitudinal Irregular Data: Multicenter Retrospective Study.",
      "abstract": "BACKGROUND: Timely and accurate prediction of short-term mortality is critical in intensive care units (ICUs), where patients' conditions change rapidly. Traditional scoring systems, such as the Simplified Acute Physiology Score and Acute Physiology and Chronic Health Evaluation, rely on static variables collected within the first 24 hours of admission and do not account for continuously evolving clinical states. These systems lack real-time adaptability, interpretability, and generalizability. With the increasing availability of high-frequency electronic medical record (EMR) data, machine learning (ML) approaches have emerged as powerful tools to model complex temporal patterns and support dynamic clinical decision-making. However, existing models are often limited by their inability to handle irregular sampling and missing values, and many lack rigorous external validation across institutions. OBJECTIVE: We aimed to develop a real-time, interpretable risk prediction model that continuously assesses ICU patient mortality using irregular, longitudinal EMR data, with improved performance and generalizability over traditional static scoring systems. METHODS: A time-aware bidirectional attention-based long short-term memory (TBAL) model was developed using EMR data from the MIMIC-IV (Medical Information Mart for Intensive Care) and eICU Collaborative Research Database (eICU-CRD) databases, comprising 176,344 ICU stays. The model incorporated dynamic variables, including vital signs, laboratory results, and medication data, updated hourly, to perform static and continuous mortality risk assessments. External cross-validation and subgroup sensitivity analyses were conducted to evaluate robustness and fairness. Model performance was assessed using the area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), accuracy, and F1-score. Interpretability was enhanced using integrated gradients to identify key predictors. RESULTS: For the static 12-hour to 1-day mortality prediction task, the TBAL model achieved AUROCs of 95.9 (95% CI 94.2-97.5) and 93.3 (95% CI 91.5-95.3) and AUPRCs of 48.5 and 21.6 in MIMIC-IV and eICU-CRD, respectively. Accuracy and F1-scores reached 94.1 and 46.7 in MIMIC-IV and 92.2 and 28.1 in eICU-CRD. In dynamic prediction tasks, AUROCs reached 93.6 (95% CI 93.2-93.9) and 91.9 (95% CI 91.6-92.1), with AUPRCs of 41.3 and 50, respectively. The model maintained high recall for positive cases (82.6% and 79.1% in MIMIC-IV and eICU-CRD). Cross-database validation yielded AUROCs of 81.3 and 76.1, confirming generalizability. Subgroup analysis showed stable performance across age, sex, and severity strata, with top predictors including lactate, vasopressor use, and Glasgow Coma Scale score. CONCLUSIONS: The TBAL model offers a robust, interpretable, and generalizable solution for dynamic real-time mortality risk prediction in ICU patients. Its ability to adapt to irregular temporal patterns and to provide hourly updated predictions positions it as a promising decision-support tool. Future work should validate its utility in prospective clinical trials and investigate its integration into real-world ICU workflows to enhance patient outcomes.",
      "authors": "Zheng Zhuo; Luo Jiawei; Zhu Yingchao; Du Lei; Lan Lan; Zhou Xiaobo; Yang Xiaoyan; Huang Shixin",
      "year": "2025",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/69293",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40266658/",
      "mesh_terms": "Humans; Intensive Care Units; Retrospective Studies; Electronic Health Records; Risk Assessment; Female; Male; Middle Aged; Machine Learning; Aged; Longitudinal Studies; Hospital Mortality",
      "keywords": "continuous prediction; in-hospital mortality; intensive care units; machine learning; model interpretability",
      "pub_types": "Journal Article; Multicenter Study; Validation Study",
      "pmcid": "PMC12059492"
    },
    {
      "pmid": "29046267",
      "title": "Identifying Sentiment of Hookah-Related Posts on Twitter.",
      "abstract": "BACKGROUND: The increasing popularity of hookah (or waterpipe) use in the United States and elsewhere has consequences for public health because it has similar health risks to that of combustible cigarettes. While hookah use rapidly increases in popularity, social media data (Twitter, Instagram) can be used to capture and describe the social and environmental contexts in which individuals use, perceive, discuss, and are marketed this tobacco product. These data may allow people to organically report on their sentiment toward tobacco products like hookah unprimed by a researcher, without instrument bias, and at low costs. OBJECTIVE: This study describes the sentiment of hookah-related posts on Twitter and describes the importance of debiasing Twitter data when attempting to understand attitudes. METHODS: Hookah-related posts on Twitter (N=986,320) were collected from March 24, 2015, to December 2, 2016. Machine learning models were used to describe sentiment on 20 different emotions and to debias the data so that Twitter posts reflected sentiment of legitimate human users and not of social bots or marketing-oriented accounts that would possibly provide overly positive or overly negative sentiment of hookah. RESULTS: From the analytical sample, 352,116 tweets (59.50%) were classified as positive while 177,537 (30.00%) were classified as negative, and 62,139 (10.50%) neutral. Among all positive tweets, 218,312 (62.00%) were classified as highly positive emotions (eg, active, alert, excited, elated, happy, and pleasant), while 133,804 (38.00%) positive tweets were classified as passive positive emotions (eg, contented, serene, calm, relaxed, and subdued). Among all negative tweets, 95,870 (54.00%) were classified as subdued negative emotions (eg, sad, unhappy, depressed, and bored) while the remaining 81,667 (46.00%) negative tweets were classified as highly negative emotions (eg, tense, nervous, stressed, upset, and unpleasant). Sentiment changed drastically when comparing a corpus of tweets with social bots to one without. For example, the probability of any one tweet reflecting joy was 61.30% from the debiased (or bot free) corpus of tweets. In contrast, the probability of any one tweet reflecting joy was 16.40% from the biased corpus. CONCLUSIONS: Social media data provide researchers the ability to understand public sentiment and attitudes by listening to what people are saying in their own words. Tobacco control programmers in charge of risk communication may consider targeting individuals posting positive messages about hookah on Twitter or designing messages that amplify the negative sentiments. Posts on Twitter communicating positive sentiment toward hookah could add to the normalization of hookah use and is an area of future research. Findings from this study demonstrated the importance of debiasing data when attempting to understand attitudes from Twitter data.",
      "authors": "Allem Jon-Patrick; Ramanujam Jagannathan; Lerman Kristina; Chu Kar-Hai; Boley Cruz Tess; Unger Jennifer B",
      "year": "2017",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/publichealth.8133",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29046267/",
      "mesh_terms": "",
      "keywords": "Twitter; big data; bots; hookah; sentiment; social media; waterpipe",
      "pub_types": "Journal Article",
      "pmcid": "PMC5667930"
    },
    {
      "pmid": "37036329",
      "title": "Craniofacial Soft-Tissue Anthropomorphic Database with Magnetic Resonance Imaging and Unbiased Diffeomorphic Registration.",
      "abstract": "BACKGROUND: Objective assessment of craniofacial surgery outcomes in a pediatric population is challenging because of the complexity of patient presentations, diversity of procedures performed, and rapid craniofacial growth. There is a paucity of robust methods to quantify anatomical measurements by age and objectively compare craniofacial dysmorphology and postoperative outcomes. Here, the authors present data in developing a racially and ethnically sensitive anthropomorphic database, providing plastic and craniofacial surgeons with \"normal\" three-dimensional anatomical parameters with which to appraise and optimize aesthetic and reconstructive outcomes. METHODS: Patients with normal craniofacial anatomy undergoing head magnetic resonance imaging (MRI) scans from 2008 to 2021 were included in this retrospective study. Images were used to construct composite (template) images with diffeomorphic image registration method using the Advanced Normalization Tools package. Composites were thresholded to generate binary three-dimensional segmentations used for anatomical measurements in Materalise Mimics. RESULTS: High-resolution MRI scans from 130 patients generated 12 composites from an average of 10 MRI sequences each: four 3-year-olds, four 4-year-olds, and four 5-year-olds (two male, two female, two Black, and two White). The average head circumference of 3-, 4-, and 5-year-old composites was 50.3, 51.5, and 51.7 cm, respectively, comparable to normative data published by the World Health Organization. CONCLUSIONS: Application of diffeomorphic registration-based image template algorithm to MRI is effective in creating composite templates to represent \"normal\" three-dimensional craniofacial and soft-tissue anatomy. Future research will focus on development of automated computational tools to characterize anatomical normality, generation of indices to grade preoperative severity, and quantification of postoperative results to reduce subjectivity bias.",
      "authors": "Villavisanis Dillan F; Khandelwal Pulkit; Zapatero Zachary D; Wagner Connor S; Blum Jessica D; Cho Daniel Y; Swanson Jordan W; Taylor Jesse A; Yushkevich Paul A; Bartlett Scott P",
      "year": "2024",
      "journal": "Plastic and reconstructive surgery",
      "doi": "10.1097/PRS.0000000000010526",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37036329/",
      "mesh_terms": "Humans; Child; Male; Female; Child, Preschool; Retrospective Studies; Image Processing, Computer-Assisted; Cephalometry; Algorithms; Magnetic Resonance Imaging; Imaging, Three-Dimensional",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "36791660",
      "title": "Algorithmic encoding of protected characteristics in chest X-ray disease detection models.",
      "abstract": "BACKGROUND: It has been rightfully emphasized that the use of AI for clinical decision making could amplify health disparities. An algorithm may encode protected characteristics, and then use this information for making predictions due to undesirable correlations in the (historical) training data. It remains unclear how we can establish whether such information is actually used. Besides the scarcity of data from underserved populations, very little is known about how dataset biases manifest in predictive models and how this may result in disparate performance. This article aims to shed some light on these issues by exploring methodology for subgroup analysis in image-based disease detection models. METHODS: We utilize two publicly available chest X-ray datasets, CheXpert and MIMIC-CXR, to study performance disparities across race and biological sex in deep learning models. We explore test set resampling, transfer learning, multitask learning, and model inspection to assess the relationship between the encoding of protected characteristics and disease detection performance across subgroups. FINDINGS: We confirm subgroup disparities in terms of shifted true and false positive rates which are partially removed after correcting for population and prevalence shifts in the test sets. We find that transfer learning alone is insufficient for establishing whether specific patient information is used for making predictions. The proposed combination of test-set resampling, multitask learning, and model inspection reveals valuable insights about the way protected characteristics are encoded in the feature representations of deep neural networks. INTERPRETATION: Subgroup analysis is key for identifying performance disparities of AI models, but statistical differences across subgroups need to be taken into account when analyzing potential biases in disease detection. The proposed methodology provides a comprehensive framework for subgroup analysis enabling further research into the underlying causes of disparities. FUNDING: European Research Council Horizon 2020, UK Research and Innovation.",
      "authors": "Glocker Ben; Jones Charles; Bernhardt M\u00e9lanie; Winzeck Stefan",
      "year": "2023",
      "journal": "EBioMedicine",
      "doi": "10.1016/j.ebiom.2023.104467",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36791660/",
      "mesh_terms": "Humans; X-Rays; Deep Learning; Neural Networks, Computer; Algorithms; Radiography",
      "keywords": "Algorithmic bias; Artificial intelligence; Image-based disease detection; Subgroup disparities",
      "pub_types": "Journal Article",
      "pmcid": "PMC10025760"
    },
    {
      "pmid": "35839913",
      "title": "Air pollution exposure during pregnancy and childhood, cognitive function, and emotional and behavioral problems in adolescents.",
      "abstract": "BACKGROUND: Exposure to air pollution may impact neurodevelopment during childhood, but current evidence on the association with cognitive function and mental health is inconclusive and primarily focusses on young children. Therefore, we aim to study the association of exposure to air pollution during pregnancy and childhood, with cognitive function and emotional and behavioral problems in adolescents. METHODS: We used data from 5170 participants of a birth cohort in Rotterdam, the Netherlands. Concentrations of fourteen air pollutants at participant's home addresses were estimated during pregnancy and childhood, using land use regression models. We included four cognitive domains (processing speed, working memory, fluid reasoning and verbal intelligence quotient (IQ)) and an estimated full-scale IQ. Internalizing, externalizing, and attention problems were self- and parent-reported. We used linear regression models to assess the association of each air pollutant, with cognitive function and emotional and behavioral problems, adjusting for socioeconomic status and lifestyle characteristics. Then, we performed multipollutant analyses using the Deletion/Substitution/Addition (DSA) algorithm. RESULTS: Air pollution exposure was not associated with full-scale IQ, working memory, or processing speed. Higher exposure to few air pollutants was associated with higher fluid reasoning and verbal IQ scores (e.g. 0.22 points of fluid reasoning (95%CI 0.00; 0.44) per 1\u00a0\u03bcg/m3 increase in organic carbon during pregnancy). Higher exposure to some air pollutants was also associated with less internalizing, externalizing, and attention problems (e.g. -0.27 internalizing problems (95% CI -0.52; -0.02) per each 5\u00a0ng/m3 increase in copper during pregnancy). CONCLUSIONS: Higher exposure to air pollution during pregnancy and childhood was not associated with lower cognitive function or more emotional and behavioral problems in adolescents. Based on previous literature and biological plausibility, the observed protective associations are probably explained by negative residual confounding, selection bias, or chance and do not represent a causal relationship.",
      "authors": "Kusters Michelle S W; Essers Esm\u00e9e; Muetzel Ryan; Ambr\u00f3s Albert; Tiemeier Henning; Guxens M\u00f2nica",
      "year": "2022",
      "journal": "Environmental research",
      "doi": "10.1016/j.envres.2022.113891",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35839913/",
      "mesh_terms": "Adolescent; Air Pollutants; Air Pollution; Child; Child, Preschool; Cognition; Environmental Exposure; Female; Humans; Particulate Matter; Pregnancy; Problem Behavior",
      "keywords": "Adolescents; Air pollution; Cognitive function; Environmental epidemiology; Mental health; Traffic",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40601199",
      "title": "Incident Atherosclerotic Cardiovascular Disease Among Veterans by Gender Identity: A Cohort Study.",
      "abstract": "BACKGROUND: Transgender and gender diverse (trans) populations are at elevated risk for atherosclerotic cardiovascular disease (ASCVD). OBJECTIVE: Measure the association of gender identity and gender-affirming hormone therapy (GAHT) with ASCVD outcomes. DESIGN: Cohort study. PARTICIPANTS: Over 1 million veterans receiving care in the Veterans Health Administration. MAIN MEASURES: Gender identity was identified via a validated natural language processing (NLP) algorithm. Incident ASCVD (acute myocardial infarction, ischemic stroke, or revascularization after the baseline date) was identified via International Classification of Diseases diagnosis codes among veterans without prevalent ASCVD. We calculated sample statistics stratified by gender identity and used Cox proportional hazard regression to assess associations of gender identity and GAHT with incident ASCVD. KEY RESULTS: Among 1,105,082 veterans, 42,149 were classified as trans (8013 transfeminine, 7127 transmasculine, and 27,009 uncategorized trans) while 918,843 were cisgender men and 144,090 were cisgender women. During a median follow-up of 9.39\u00a0years, 92,910 veterans had incident ASCVD (2806 among trans veterans). Adjusting for age, race, Hispanic ethnicity, and sexual orientation, trans veterans had 1.52 [1.45, 1.59] and 0.92 [0.89, 0.96] times the hazard of ASCVD compared to cisgender women and cisgender men, respectively. Compared to trans veterans not receiving GAHT, GAHT among trans veterans assigned female at birth was significantly associated a reduced hazard of ASCVD (0.89 [0.80, 0.98]); GAHT was not associated with ASCVD among trans veterans assigned male at birth (0.99 [0.89, 1.09]). LIMITATIONS: With NLP, there is potential for selection bias as clinicians may preferentially document the gender identity for trans more than cisgender veterans. CONCLUSIONS: This is one of the first studies to examine the association of both gender identity and GAHT with incident ASCVD in veterans. Future research must comprehensively evaluate ASCVD outcomes and the effects of gender-affirming care (including hormone therapy) in trans populations.",
      "authors": "Streed Carl G; Duncan Meredith S; Heier Kory R; Workman T Elizabeth; Beach Lauren B; Jasuja Guneet K; Wolfe Hill L; Hughes Landon D; O'Leary John R; Skanderson Melissa; Goulet Joseph L",
      "year": "2025",
      "journal": "Journal of general internal medicine",
      "doi": "10.1007/s11606-025-09701-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40601199/",
      "mesh_terms": "Humans; Male; Female; Veterans; Middle Aged; Atherosclerosis; Cohort Studies; United States; Gender Identity; Incidence; Aged; Adult; Transgender Persons",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12508330"
    },
    {
      "pmid": "30841773",
      "title": "Bias-corrected estimates of reduction of post-surgery length of stay and corresponding cost savings through the widespread national implementation of fast-tracking after liver transplantation: a quasi-experimental study.",
      "abstract": "Background: Fast-tracking is an approach adopted by Mayo Clinic in Florida's (MCF) liver transplant (LT) program, which consists of early tracheal extubation and transfer of patients to surgical ward, eliminating a stay in the intensive care unit in select patients. Since adopting this approach in 2002, MCF has successfully fast-tracked 54.3% of patients undergoing LT. Objectives: This study evaluated the reduction in post-operative length of stay (LOS) that resulted from the fast-tracking protocol and assessed the potential cost saving in the case of nationwide implementation. Methods: A propensity score for fast-tracking was generated based on MCF liver transplant databases during 2011-2013. Various propensity score matching algorithms were used to form control groups from the United Network of Organ Sharing Standard Analysis and Research (STAR) file that had comparable demographic characteristics and health status to the treatment group identified in MCF. Multiple regression and matching estimators were employed for evaluation of the post-surgery LOS. The algorithm generated from the analysis was also applied to the STAR data to determine the proportion of patients in the US who could potentially be candidates for fast-tracking, and the potential savings. Results: The effect of the fast-tracking on the post-transplant LOS was estimated at approximately from 2.5 (p-value\u2009=\u20090.001) to 3.2 (p-value\u2009<\u20090.001) days based on various matching algorithms. The cost saving from a nationwide implementation of fast-tracking of liver transplant patients was estimated to be at least $78 million during the 2-year period. Conclusion: The fast-track program was found to be effective in reducing post-transplant LOS, although the reduction appeared to be less than previously reported. Nationwide implementation of fast-tracking could result in substantial cost savings without compromising the patient outcome.",
      "authors": "Loh Chung-Ping A; Croome Kristopher P; Burcin Taner C; Keaveny Andrew P",
      "year": "2019",
      "journal": "Journal of medical economics",
      "doi": "10.1080/13696998.2019.1592179",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30841773/",
      "mesh_terms": "Academic Medical Centers; Age Factors; Cohort Studies; Cost Savings; Databases, Factual; Early Ambulation; Female; Florida; Humans; Intensive Care Units; Length of Stay; Liver Transplantation; Logistic Models; Male; Middle Aged; Multivariate Analysis; Postoperative Care; Retrospective Studies; Risk Factors; Selection Bias",
      "keywords": "C40; C90; Fast-tracking; I11; I19; length of stay; liver transplant; matching; propensity score; quasi-experimental study",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40767775",
      "title": "Delirium as a Precursor to Dementia in Elderly Type 2 Diabetes Mellitus Patients.",
      "abstract": "Purpose: This study aimed to investigate the association between delirium and incident dementia in elderly (\u226565 years) type 2 diabetes mellitus (T2DM) patients, addressing the heightened dementia risk in this population. Methods: We conducted a retrospective cohort study using data from the National Health Insurance Research Database (NHIRD) spanning January 1, 2005, to December 31, 2022. The study included elderly (\u226565 years) T2DM patients newly diagnosed between January 1, 2005, and December 31, 2007. Patients were categorized into delirium and no delirium groups. A rigorous propensity score matching algorithm was applied to ensure optimal balance of baseline covariates, thereby minimizing selection bias and confounding, and Cox regression models along with competing risk analyses assessed the risk of incident dementia. Results: The study included 5,128 elderly (\u226565 years) T2DM patients, with 2,564 patients in both the delirium and no delirium groups. Baseline covariates achieved balance, including age, sex, income levels, urbanization, duration of diabetes, types of antidiabetic medications, and comorbidities. The incidence of dementia was significantly higher in the delirium group (42.75%) compared to the no delirium group (22.66%), with a P value <.0001. The data reveal a clear dose-response pattern, wherein each additional delirium episode substantially amplifies dementia risk, underscoring the cumulative impact of repeated episodes on cognitive deterioration: no episodes (4.40 per 100 person-years), 1 episode (7.62 per 100 person-years), and 2 or more episodes (8.41 per 100 person-years). Conclusions: Our findings confirm a strong association between delirium and an increased risk of dementia in elderly (\u226565 years) T2DM patients, suggesting a potential causal link. Effective delirium management in elderly T2DM patients is imperative to mitigate dementia risk. These findings advocate for targeted interventions to alleviate the substantial cognitive burden in this vulnerable population.",
      "authors": "Sun Mingyang; Wang Xiaoling; Lu Zhongyuan; Yang Yitian; Lv Shuang; Miao Mengrong; Chen Wan-Ming; Wu Szu-Yuan; Zhang Jiaqiang",
      "year": "2025",
      "journal": "The Journal of clinical psychiatry",
      "doi": "10.4088/JCP.25m15798",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40767775/",
      "mesh_terms": "Humans; Diabetes Mellitus, Type 2; Delirium; Aged; Male; Female; Dementia; Retrospective Studies; Aged, 80 and over; Incidence; Risk Factors; Comorbidity; Taiwan",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35623797",
      "title": "Development and multimodal validation of a substance misuse algorithm for referral to treatment using artificial intelligence (SMART-AI): a retrospective deep learning study.",
      "abstract": "BACKGROUND: Substance misuse is a heterogeneous and complex set of behavioural conditions that are highly prevalent in hospital settings and frequently co-occur. Few hospital-wide solutions exist to comprehensively and reliably identify these conditions to prioritise care and guide treatment. The aim of this study was to apply natural language processing (NLP) to clinical notes collected in the electronic health record (EHR) to accurately screen for substance misuse. METHODS: The model was trained and developed on a reference dataset derived from a hospital-wide programme at Rush University Medical Center (RUMC), Chicago, IL, USA, that used structured diagnostic interviews to manually screen admitted patients over 27 months (between Oct 1, 2017, and Dec 31, 2019; n=54\u2008915). The Alcohol Use Disorder Identification Test and Drug Abuse Screening Tool served as reference standards. The first 24 h of notes in the EHR were mapped to standardised medical vocabulary and fed into single-label, multilabel, and multilabel with auxillary-task neural network models. Temporal validation of the model was done using data from the subsequent 12 months on a subset of RUMC patients (n=16\u2008917). External validation was done using data from Loyola University Medical Center, Chicago, IL, USA between Jan 1, 2007, and Sept 30, 2017 (n=1991 adult patients). The primary outcome was discrimination for alcohol misuse, opioid misuse, or non-opioid drug misuse. Discrimination was assessed by the area under the receiver operating characteristic curve (AUROC). Calibration slope and intercept were measured with the unreliability index. Bias assessments were performed across demographic subgroups. FINDINGS: The model was trained on a cohort that had 3\u00b75% misuse (n=1\u2008921) with any type of substance. 220 (11%) of 1921 patients with substance misuse had more than one type of misuse. The multilabel convolutional neural network classifier had a mean AUROC of 0\u00b797 (95% CI 0\u00b796-0\u00b798) during temporal validation for all types of substance misuse. The model was well calibrated and showed good face validity with model features containing explicit mentions of aberrant drug-taking behaviour. A false-negative rate of 0\u00b718-0\u00b719 and a false-positive rate of 0\u00b703 between non-Hispanic Black and non-Hispanic White groups occurred. In external validation, the AUROCs for alcohol and opioid misuse were 0\u00b788 (95% CI 0\u00b786-0\u00b790) and 0\u00b794 (0\u00b792-0\u00b795), respectively. INTERPRETATION: We developed a novel and accurate approach to leveraging the first 24 h of EHR notes for screening multiple types of substance misuse. FUNDING: National Institute On Drug Abuse, National Institutes of Health.",
      "authors": "Afshar Majid; Sharma Brihat; Dligach Dmitriy; Oguss Madeline; Brown Randall; Chhabra Neeraj; Thompson Hale M; Markossian Talar; Joyce Cara; Churpek Matthew M; Karnik Niranjan S",
      "year": "2022",
      "journal": "The Lancet. Digital health",
      "doi": "10.1016/S2589-7500(22)00041-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35623797/",
      "mesh_terms": "Adult; Alcoholism; Artificial Intelligence; Deep Learning; Humans; Opioid-Related Disorders; Referral and Consultation; Retrospective Studies; United States",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC9159760"
    },
    {
      "pmid": "34207713",
      "title": "Propensity Score Analysis Assessing the Burden of Non-Communicable Diseases among the Transgender Population in the United States Using the Behavioral Risk Factor Surveillance System (2017-2019).",
      "abstract": "Research to assess the burden of non-communicable diseases (NCDs) among the transgender population needs to be prioritized given the high prevalence of chronic conditions and associated risk factors in this group. Previous cross-sectional studies utilized unmatched samples with a significant covariate imbalance resulting in a selection bias. Therefore, this cross-sectional study attempts to assess and compare the burden of NCDs among propensity score-matched transgender and cisgender population groups. This study analyzed Behavioral Risk Factor Surveillance System data (2017-2019) using complex weighting procedures to generate nationally representative samples. Logistic regression was fit to estimate propensity scores. Transgender and cisgender groups were matched by sociodemographic variables using a 1:1 nearest neighbor matching algorithm. McNemar, univariate, and multivariate logistic regression analyses were conducted among matched cohorts using R and SPSS version 26 software. Compared with the cisgender group, the transgender group was significantly more likely to have hypertension (31.3% vs. 27.6%), hypercholesteremia (30.8% vs. 23.7%), prediabetes (17.3% vs. 10.3%), and were heavy drinkers (6.7% vs. 6.0%) and smokers (22.4% vs. 20.0%). Moreover, the transgender group was more than twice as likely to have depression (aOR: 2.70, 95% CI 2.62-2.72), stroke (aOR: 2.52 95% CI 2.50-2.55), coronary heart disease (aOR: 2.77, 95% CI 2.74-2.81), and heart attack (aOR: 2.90, 95% CI 2.87-2.94). Additionally, the transgender group was 1.2-1.7 times more likely to have metabolic and malignant disorders. Differences were also found between transgender subgroups compared with the cisgender group. This study provides a clear picture of the NCD burden among the transgender population. These findings offer an evidence base to build health equity models to reduce disparities among transgender groups.",
      "authors": "Pharr Jennifer R; Batra Kavita",
      "year": "2021",
      "journal": "Healthcare (Basel, Switzerland)",
      "doi": "10.3390/healthcare9060696",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34207713/",
      "mesh_terms": "",
      "keywords": "Behavioral Risk Factor Surveillance System; non-communicable diseases; propensity score matching; transgender",
      "pub_types": "Journal Article",
      "pmcid": "PMC8226537"
    },
    {
      "pmid": "35731224",
      "title": "Retracted: Exposure to Per- and Polyfluoroalkyl Substances and Mortality in U.S. Adults: A Population-Based Cohort Study.",
      "abstract": "BACKGROUND: Per- and polyfluoroalkyl substances (PFAS) are widespread environmental contaminants associated with diseases such as cancer and dyslipidemia. However, few studies have investigated the association between PFAS mixture exposure and mortality in general populations. OBJECTIVES: This study aimed to explore the association between PFAS mixture, perfluorooctanoic acid (PFOA), and perfluorooctane sulfonic acid (PFOS) and mortality in U.S. adults by a nationally representative cohort. METHODS: Adults \u226518\u2009years of age who were enrolled in the National Health and Nutrition Examination Survey (NHANES) (1999-2014) were included in our study. Baseline serum concentrations of seven PFAS were measured and individuals were followed up to 31 December 2015. Hazard ratios (HRs) and confidence intervals (CIs) were estimated using Cox proportional hazards models. Association between PFAS mixture exposure and mortality was analyzed using the k-means method by clustering PFAS mixtures into subgroups. Association between PFOA/PFOS exposure and mortality was subsequently analyzed in both continuous and categorical models. RESULTS: During the follow-up period, 1,251 participants died. In the mixture analysis, the k-means algorithm clustered participants into low-, medium-, and high-exposure groups. Compared with the low-exposure group, participants in the high-exposure group showed significantly higher risks for all-cause mortality (HR=1.38; 95% CI: 1.07, 1.80), heart disease mortality (HR=1.58; 95% CI: 1.05, 2.51), and cancer mortality (HR=1.70; 95% CI: 1.08, 2.84). In single PFAS analysis, PFOS was found to be positively associated with all-cause mortality (third vs. first tertile HR=1.57; 95% CI: 1.22, 2.07), heart disease mortality (third vs. first tertile HR=1.65; 95% CI: 1.09, 2.57), and cancer mortality (third vs. first tertile HR=1.75; 95% CI: 1.10, 2.83), whereas PFOA exposure had no significant association with mortality. Assuming the observed association is causal, the number of deaths associated with PFOS exposure (\u226517.1 vs. <7.9\u2009ng/mL) was \u223c382,000 (95% CI: 176,000, 588,000) annually between 1999 and 2015, and it decreased to 69,000 (95% CI: 28,000, 119,000) annually between 2015 and 2018. The association between PFOS and mortality was stronger among women and people without diabetes. DISCUSSION: We observed a positive association between PFAS mixture exposure and mortality among U.S. adults. Limitations of this study include the potential for unmeasured confounding, selection bias, a relatively small number of deaths, and only measuring PFAS at one point in time. Further studies with serial measures of PFAS concentrations and longer follow-ups are necessary to elucidate the association between PFAS and mortality from specific causes. https://doi.org/10.1289/EHP10393.",
      "authors": "Wen Xue; Wang Mei; Xu Xuewen; Li Tao",
      "year": "2022",
      "journal": "Environmental health perspectives",
      "doi": "10.1289/EHP10393",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35731224/",
      "mesh_terms": "Adult; Alkanesulfonic Acids; Cohort Studies; Environmental Pollutants; Female; Fluorocarbons; Heart Diseases; Humans; Nutrition Surveys; Research",
      "keywords": "",
      "pub_types": "Journal Article; Retracted Publication",
      "pmcid": "PMC9215707"
    }
  ],
  "excluded": [
    {
      "pmid": "34396058",
      "title": "Ethical Machine Learning in Healthcare.",
      "abstract": "The use of machine learning (ML) in healthcare raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of healthcare. Specifically, we frame ethics of ML in healthcare through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to postdeployment considerations. We close by summarizing recommendations to address these challenges.",
      "authors": "Chen Irene Y; Pierson Emma; Rose Sherri; Joshi Shalmali; Ferryman Kadija; Ghassemi Marzyeh",
      "year": "2021",
      "journal": "Annual review of biomedical data science",
      "doi": "10.1146/annurev-biodatasci-092820-114757",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34396058/",
      "mesh_terms": "Delivery of Health Care; Health Facilities; Machine Learning; Morals; Social Justice",
      "keywords": "bias; ethics; health; health disparities; healthcare; machine learning",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8362902"
    },
    {
      "pmid": "37793703",
      "title": "Prediction of refractive error and its progression: a machine learning-based algorithm.",
      "abstract": "OBJECTIVE: Myopia is the refractive error that shows the highest prevalence for younger ages in Southeast Asia and its projection over the next decades indicates that this situation will worsen. Nowadays, several management solutions are being applied to help fight its onset and development, nonetheless, the applications of these techniques depend on a clear and reliable assessment of risk to develop myopia. METHODS AND ANALYSIS: In this study, population-based data of Chinese children were used to develop a machine learning-based algorithm that enables the risk assessment of myopia's onset and development. Cross-sectional data of 12 780 kids together with longitudinal data of 226 kids containing age, gender, biometry and refractive parameters were used for the development of the models. RESULTS: A combination of support vector regression and Gaussian process regression resulted in the best performing algorithm. The Pearson correlation coefficient between prediction and measured data was 0.77, whereas the bias was -0.05 D and the limits of agreement was 0.85 D (95% CI: -0.91 to 0.80D). DISCUSSION: The developed algorithm uses accessible inputs to provide an estimate of refractive development and may serve as guide for the eye care professional to help determine the individual best strategy for management of myopia.",
      "authors": "Barraza-Bernal Maria J; Ohlendorf Arne; Sanz Diez Pablo; Feng Xiancai; Yang Li-Hua; Lu Mei-Xia; Wahl Siegfried; Kratzer Timo",
      "year": "2023",
      "journal": "BMJ open ophthalmology",
      "doi": "10.1136/bmjophth-2023-001298",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37793703/",
      "mesh_terms": "Child; Humans; Cross-Sectional Studies; Refractive Errors; Myopia; Refraction, Ocular; Machine Learning",
      "keywords": "optics and refraction; public health",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10551949"
    },
    {
      "pmid": "37466257",
      "title": "Stability of clinical prediction models developed using statistical or machine learning methods.",
      "abstract": "Clinical prediction models estimate an individual's risk of a particular health outcome. A developed model is a consequence of the development dataset and model-building strategy, including the sample size, number of predictors, and analysis method (e.g., regression or machine learning). We raise the concern that many models are developed using small datasets that lead to instability in the model and its predictions (estimated risks). We define four levels of model stability in estimated risks moving from the overall mean to the individual level. Through simulation and case studies of statistical and machine learning approaches, we show instability in a model's estimated risks is often considerable, and ultimately manifests itself as miscalibration of predictions in new data. Therefore, we recommend researchers always examine instability at the model development stage and propose instability plots and measures to do so. This entails repeating the model-building steps (those used to develop the original prediction model) in each of multiple (e.g., 1000) bootstrap samples, to produce multiple bootstrap models, and deriving (i) a prediction instability plot of bootstrap model versus original model predictions; (ii) the mean absolute prediction error (mean absolute difference between individuals' original and bootstrap model predictions), and (iii) calibration, classification, and decision curve instability plots of bootstrap models applied in the original sample. A case study illustrates how these instability assessments help reassure (or not) whether model predictions are likely to be reliable (or not), while informing a model's critical appraisal (risk of bias rating), fairness, and further validation requirements.",
      "authors": "Riley Richard D; Collins Gary S",
      "year": "2023",
      "journal": "Biometrical journal. Biometrische Zeitschrift",
      "doi": "10.1002/bimj.202200302",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37466257/",
      "mesh_terms": "Humans; Models, Statistical; Prognosis; Machine Learning; Computer Simulation",
      "keywords": "calibration; fairness; prediction model; stability; uncertainty",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10952221"
    },
    {
      "pmid": "38069455",
      "title": "Academic machine learning researchers' ethical perspectives on algorithm development for health care: a qualitative study.",
      "abstract": "OBJECTIVES: We set out to describe academic machine learning (ML) researchers' ethical considerations regarding the development of ML tools intended for use in clinical care. MATERIALS AND METHODS: We conducted in-depth, semistructured interviews with a sample of ML researchers in medicine (N\u2009=\u200910) as part of a larger study investigating stakeholders' ethical considerations in the translation of ML tools in medicine. We used a qualitative descriptive design, applying conventional qualitative content analysis in order to allow participant perspectives to emerge directly from the data. RESULTS: Every participant viewed their algorithm development work as holding ethical significance. While participants shared positive attitudes toward continued ML innovation, they described concerns related to data sampling and labeling (eg, limitations to mitigating bias; ensuring the validity and integrity of data), and algorithm training and testing (eg, selecting quantitative targets; assessing reproducibility). Participants perceived a need to increase interdisciplinary training across stakeholders and to envision more coordinated and embedded approaches to addressing ethics issues. DISCUSSION AND CONCLUSION: Participants described key areas where increased support for ethics may be needed; technical challenges affecting clinical acceptability; and standards related to scientific integrity, beneficence, and justice that may be higher in medicine compared to other industries engaged in ML innovation. Our results help shed light on the perspectives of ML researchers in medicine regarding the range of ethical issues they encounter or anticipate in their work, including areas where more attention may be needed to support the successful development and integration of medical ML tools.",
      "authors": "Kasun Max; Ryan Katie; Paik Jodi; Lane-McKinley Kyle; Dunn Laura Bodin; Roberts Laura Weiss; Kim Jane Paik",
      "year": "2024",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocad238",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38069455/",
      "mesh_terms": "Humans; Reproducibility of Results; Qualitative Research; Algorithms; Machine Learning; Delivery of Health Care",
      "keywords": "artificial intelligence; biomedical innovation; ethics; machine learning; qualitative research",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10873830"
    },
    {
      "pmid": "36649491",
      "title": "Machine Learning and Health Care: Potential Benefits and Issues.",
      "abstract": "We discuss the potential for machine learning (ML) and artificial intelligence (AI) to improve health care, while detailing caveats and important considerations to ensure unbiased and equitable implementation. If disparities exist in the data used to train ML algorithms, they must be recognized and accounted for, so they do not bias performance accuracy or are not interpreted by the algorithm as simply a lack of need. We pay particular attention to an area in which bias in data composition is particularly striking, that is in large-scale genetics databases, as people of European descent are vastly overrepresented in the existing resources.",
      "authors": "Atkinson J Graham; Atkinson Elizabeth G",
      "year": "2023",
      "journal": "The Journal of ambulatory care management",
      "doi": "10.1097/JAC.0000000000000453",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36649491/",
      "mesh_terms": "Humans; Artificial Intelligence; Machine Learning; Algorithms; Delivery of Health Care",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9974552"
    },
    {
      "pmid": "36808950",
      "title": "A Machine Learning-Combined Flexible Sensor for Tactile Detection and Voice Recognition.",
      "abstract": "Intelligent sensors have attracted substantial attention for various applications, including wearable electronics, artificial intelligence, healthcare monitoring, and human-machine interactions. However, there still remains a critical challenge in developing a multifunctional sensing system for complex signal detection and analysis in practical applications. Here, we develop a machine learning-combined flexible sensor for real-time tactile sensing and voice recognition through laser-induced graphitization. The intelligent sensor with a triboelectric layer can convert local pressure to an electrical signal through a contact electrification effect without external bias, which has a characteristic response behavior when exposed to various mechanical stimuli. With the special patterning design, a smart human-machine interaction controlling system composed of a digital arrayed touch panel is constructed to control electronic devices. Based on machine learning, the real-time monitoring and recognition of the changes of voice are achieved with high accuracy. The machine learning-empowered flexible sensor provides a promising platform for the development of flexible tactile sensing, real-time health detection, human-machine interaction, and intelligent wearable devices.",
      "authors": "Xie Jiawang; Zhao Yuzhi; Zhu Dezhi; Yan Jianfeng; Li Jiaqun; Qiao Ming; He Guangzhi; Deng Shengfa",
      "year": "2023",
      "journal": "ACS applied materials & interfaces",
      "doi": "10.1021/acsami.2c22287",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36808950/",
      "mesh_terms": "Humans; Artificial Intelligence; Voice Recognition; Wearable Electronic Devices; Electricity; Machine Learning",
      "keywords": "flexible sensor; human\u2212machine interaction; laser processing; machine learning; tactile sensing",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36722803",
      "title": "Performance of Multiple Imputation Using Modern Machine Learning Methods in Electronic Health Records Data.",
      "abstract": "BACKGROUND: Missing data are common in studies using electronic health records (EHRs)-derived data. Missingness in EHR data is related to healthcare utilization patterns, resulting in complex and potentially missing not at random missingness mechanisms. Prior research has suggested that machine learning-based multiple imputation methods may outperform traditional methods and may perform well even in settings of missing not at random missingness. METHODS: We used plasmode simulations based on a nationwide EHR-derived de-identified database for patients with metastatic urothelial carcinoma to compare the performance of multiple imputation using chained equations, random forests, and denoising autoencoders in terms of bias and precision of hazard ratio estimates under varying proportions of observations with missing values and missingness mechanisms (missing completely at random, missing at random, and missing not at random). RESULTS: Multiple imputation by chained equations and random forest methods had low bias and similar standard errors for parameter estimates under missingness completely at random. Under missingness at random, denoising autoencoders had higher bias than multiple imputation by chained equations and random forests. Contrary to results of prior studies of denoising autoencoders, all methods exhibited substantial bias under missingness not at random, with bias increasing in direct proportion to the amount of missing data. CONCLUSIONS: We found no advantage of denoising autoencoders for multiple imputation in the setting of an epidemiologic study conducted using EHR data. Results suggested that denoising autoencoders may overfit the data leading to poor confounder control. Use of more flexible imputation approaches does not mitigate bias induced by missingness not at random and can produce estimates with spurious precision.",
      "authors": "Getz Kylie; Hubbard Rebecca A; Linn Kristin A",
      "year": "2023",
      "journal": "Epidemiology (Cambridge, Mass.)",
      "doi": "10.1097/EDE.0000000000001578",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36722803/",
      "mesh_terms": "Humans; Carcinoma, Transitional Cell; Electronic Health Records; Urinary Bladder Neoplasms; Databases, Factual; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC12448120"
    },
    {
      "pmid": "39432484",
      "title": "Learning and diSentangling patient static information from time-series Electronic hEalth Records (STEER).",
      "abstract": "Recent work in machine learning for healthcare has raised concerns about patient privacy and algorithmic fairness. Previous work has shown that self-reported race can be predicted from medical data that does not explicitly contain racial information. However, the extent of data identification is unknown, and we lack ways to develop models whose outcomes are minimally affected by such information. Here we systematically investigated the ability of time-series electronic health record data to predict patient static information. We found that not only the raw time-series data, but also learned representations from machine learning models, can be trained to predict a variety of static information with area under the receiver operating characteristic curve as high as 0.851 for biological sex, 0.869 for binarized age and 0.810 for self-reported race. Such high predictive performance can be extended to various comorbidity factors and exists even when the model was trained for different tasks, using different cohorts, using different model architectures and databases. Given the privacy and fairness concerns these findings pose, we develop a variational autoencoder-based approach that learns a structured latent space to disentangle patient-sensitive attributes from time-series data. Our work thoroughly investigates the ability of machine learning models to encode patient static information from time-series electronic health records and introduces a general approach to protect patient-sensitive information for downstream tasks.",
      "authors": "Liao Wei; Voldman Joel",
      "year": "2024",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000640",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39432484/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11493250"
    },
    {
      "pmid": "39487776",
      "title": "Synthetic Health Data: Real Ethical Promise and Peril.",
      "abstract": "Researchers and practitioners are increasingly using machine-generated synthetic data as a tool for advancing health science and practice, by expanding access to health data while-potentially-mitigating privacy and related ethical concerns around data sharing. While using synthetic data in this way holds promise, we argue that it also raises significant ethical, legal, and policy concerns, including persistent privacy and security problems, accuracy and reliability issues, worries about fairness and bias, and new regulatory challenges. The virtue of synthetic data is often understood to be its detachment from the data subjects whose measurement data is used to generate it. However, we argue that addressing the ethical issues synthetic data raises might require bringing data subjects back into the picture, finding ways that researchers and data subjects can be more meaningfully engaged in the construction and evaluation of datasets and in the creation of institutional safeguards that promote responsible use.",
      "authors": "Susser Daniel; Schiff Daniel S; Gerke Sara; Cabrera Laura Y; Cohen I Glenn; Doerr Megan; Harrod Jordan; Kostick-Quenet Kristin; McNealy Jasmine; Meyer Michelle N; Price W Nicholson; Wagner Jennifer K",
      "year": "2024",
      "journal": "The Hastings Center report",
      "doi": "10.1002/hast.4911",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39487776/",
      "mesh_terms": "Humans; Privacy; Information Dissemination; Confidentiality; Computer Security",
      "keywords": "bioethics; health data; machine learning; privacy; privacy\u2010enhancing technologies; research ethics; synthetic data",
      "pub_types": "Journal Article",
      "pmcid": "PMC11555762"
    },
    {
      "pmid": "38869157",
      "title": "Pitfalls in Developing Machine Learning Models for Predicting Cardiovascular Diseases: Challenge and Solutions.",
      "abstract": "In recent years, there has been explosive development in artificial intelligence (AI), which has been widely applied in the health care field. As a typical AI technology, machine learning models have emerged with great potential in predicting cardiovascular diseases by leveraging large amounts of medical data for training and optimization, which are expected to play a crucial role in reducing the incidence and mortality rates of cardiovascular diseases. Although the field has become a research hot spot, there are still many pitfalls that researchers need to pay close attention to. These pitfalls may affect the predictive performance, credibility, reliability, and reproducibility of the studied models, ultimately reducing the value of the research and affecting the prospects for clinical application. Therefore, identifying and avoiding these pitfalls is a crucial task before implementing the research. However, there is currently a lack of a comprehensive summary on this topic. This viewpoint aims to analyze the existing problems in terms of data quality, data set characteristics, model design, and statistical methods, as well as clinical implications, and provide possible solutions to these problems, such as gathering objective data, improving training, repeating measurements, increasing sample size, preventing overfitting using statistical methods, using specific AI algorithms to address targeted issues, standardizing outcomes and evaluation criteria, and enhancing fairness and replicability, with the goal of offering reference and assistance to researchers, algorithm developers, policy makers, and clinical practitioners.",
      "authors": "Cai Yu-Qing; Gong Da-Xin; Tang Li-Ying; Cai Yue; Li Hui-Jun; Jing Tian-Ci; Gong Mengchun; Hu Wei; Zhang Zhen-Wei; Zhang Xingang; Zhang Guang-Wei",
      "year": "2024",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/47645",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38869157/",
      "mesh_terms": "Humans; Machine Learning; Cardiovascular Diseases; Reproducibility of Results; Algorithms",
      "keywords": "cardiovascular diseases; machine learning; problem; risk prediction models; solution",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11316160"
    },
    {
      "pmid": "36054665",
      "title": "Identifying Protective Drugs for Parkinson's Disease in Health-Care Databases Using Machine Learning.",
      "abstract": "BACKGROUND: Available treatments for Parkinson's disease (PD) are only partially or transiently effective. Identifying existing molecules that may present a therapeutic or preventive benefit for PD (drug repositioning) is thus of utmost interest. OBJECTIVE: We aimed at detecting potentially protective associations between marketed drugs and PD through a large-scale automated screening strategy. METHODS: We implemented a machine learning (ML) algorithm combining subsampling and lasso logistic regression in a case-control study nested in the French national health data system. Our study population comprised 40,760 incident PD patients identified by a validated algorithm during 2016 to 2018 and 176,395 controls of similar age, sex, and region of residence, all followed since 2006. Drug exposure was defined at the chemical subgroup level, then at the substance level of the Anatomical Therapeutic Chemical (ATC) classification considering the frequency of prescriptions over a 2-year period starting 10\u2009years before the index date to limit reverse causation bias. Sensitivity analyses were conducted using a more specific definition of PD status. RESULTS: Six drug subgroups were detected by our algorithm among the 374 screened. Sulfonamide diuretics (ATC-C03CA), in particular furosemide (C03CA01), showed the most robust signal. Other signals included adrenergics in combination with anticholinergics (R03AL) and insulins and analogues (A10AD). CONCLUSIONS: We identified several signals that deserve to be confirmed in large studies with appropriate consideration of the potential for reverse causation. Our results illustrate the value of ML-based signal detection algorithms for identifying drugs inversely associated with PD risk in health-care databases. \u00a9 2022 The Authors. Movement Disorders published by Wiley Periodicals LLC on behalf of International Parkinson and Movement Disorder Society.",
      "authors": "Courtois \u00c9meline; Nguyen Thi Thu Ha; Fournier Agn\u00e8s; Carcaillon-Bentata Laure; Moutengou \u00c9lodie; Escolano Sylvie; Tubert-Bitter Pascale; Elbaz Alexis; Thi\u00e9baut Anne C M; Ahmed Isma\u00efl",
      "year": "2022",
      "journal": "Movement disorders : official journal of the Movement Disorder Society",
      "doi": "10.1002/mds.29205",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36054665/",
      "mesh_terms": "Humans; Parkinson Disease; Case-Control Studies; Machine Learning; Algorithms; Protective Agents",
      "keywords": "French national health data system; Parkinson's disease; drug repositioning; machine learning; reverse causation bias",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10087353"
    },
    {
      "pmid": "37971798",
      "title": "Developer Perspectives on Potential Harms of Machine Learning Predictive Analytics in Health Care: Qualitative Analysis.",
      "abstract": "BACKGROUND: Machine learning predictive analytics (MLPA) is increasingly used in health care to reduce costs and improve efficacy; it also has the potential to harm patients and trust in health care. Academic and regulatory leaders have proposed a variety of principles and guidelines to address the challenges of evaluating the safety of machine learning-based software in the health care context, but accepted practices do not yet exist. However, there appears to be a shift toward process-based regulatory paradigms that rely heavily on self-regulation. At the same time, little research has examined the perspectives about the harms of MLPA developers themselves, whose role will be essential in overcoming the \"principles-to-practice\" gap. OBJECTIVE: The objective of this study was to understand how MLPA developers of health care products perceived the potential harms of those products and their responses to recognized harms. METHODS: We interviewed 40 individuals who were developing MLPA tools for health care at 15 US-based organizations, including data scientists, software engineers, and those with mid- and high-level management roles. These 15 organizations were selected to represent a range of organizational types and sizes from the 106 that we previously identified. We asked developers about their perspectives on the potential harms of their work, factors that influence these harms, and their role in mitigation. We used standard qualitative analysis of transcribed interviews to identify themes in the data. RESULTS: We found that MLPA developers recognized a range of potential harms of MLPA to individuals, social groups, and the health care system, such as issues of privacy, bias, and system disruption. They also identified drivers of these harms related to the characteristics of machine learning and specific to the health care and commercial contexts in which the products are developed. MLPA developers also described strategies to respond to these drivers and potentially mitigate the harms. Opportunities included balancing algorithm performance goals with potential harms, emphasizing iterative integration of health care expertise, and fostering shared company values. However, their recognition of their own responsibility to address potential harms varied widely. CONCLUSIONS: Even though MLPA developers recognized that their products can harm patients, public, and even health systems, robust procedures to assess the potential for harms and the need for mitigation do not exist. Our findings suggest that, to the extent that new oversight paradigms rely on self-regulation, they will face serious challenges if harms are driven by features that developers consider inescapable in health care and business environments. Furthermore, effective self-regulation will require MLPA developers to accept responsibility for safety and efficacy and know how to act accordingly. Our results suggest that, at the very least, substantial education will be necessary to fill the \"principles-to-practice\" gap.",
      "authors": "Nichol Ariadne A; Sankar Pamela L; Halley Meghan C; Federico Carole A; Cho Mildred K",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/47609",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37971798/",
      "mesh_terms": "Humans; Delivery of Health Care; Privacy; Social Behavior; Machine Learning",
      "keywords": "ML; MLPA; algorithms; developers; ethics; health care quality; machine learning; machine learning predictive analytics; responsibility",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10690528"
    },
    {
      "pmid": "38540589",
      "title": "Evaluating Machine Learning Stability in Predicting Depression and Anxiety Amidst Subjective Response Errors.",
      "abstract": "Major Depressive Disorder (MDD) and Generalized Anxiety Disorder (GAD) pose significant burdens on individuals and society, necessitating accurate prediction methods. Machine learning (ML) algorithms utilizing electronic health records and survey data offer promising tools for forecasting these conditions. However, potential bias and inaccuracies inherent in subjective survey responses can undermine the precision of such predictions. This research investigates the reliability of five prominent ML algorithms-a Convolutional Neural Network (CNN), Random Forest, XGBoost, Logistic Regression, and Naive Bayes-in predicting MDD and GAD. A dataset rich in biomedical, demographic, and self-reported survey information is used to assess the algorithms' performance under different levels of subjective response inaccuracies. These inaccuracies simulate scenarios with potential memory recall bias and subjective interpretations. While all algorithms demonstrate commendable accuracy with high-quality survey data, their performance diverges significantly when encountering erroneous or biased responses. Notably, the CNN exhibits superior resilience in this context, maintaining performance and even achieving enhanced accuracy, Cohen's kappa score, and positive precision for both MDD and GAD. This highlights the CNN's superior ability to handle data unreliability, making it a potentially advantageous choice for predicting mental health conditions based on self-reported data. These findings underscore the critical importance of algorithmic resilience in mental health prediction, particularly when relying on subjective data. They emphasize the need for careful algorithm selection in such contexts, with the CNN emerging as a promising candidate due to its robustness and improved performance under data uncertainties.",
      "authors": "Ku Wai Lim; Min Hua",
      "year": "2024",
      "journal": "Healthcare (Basel, Switzerland)",
      "doi": "10.3390/healthcare12060625",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38540589/",
      "mesh_terms": "",
      "keywords": "algorithmic bias; data perturbation; electronic health records; machine learning; mental health prediction; stability; survey data analysis",
      "pub_types": "Journal Article",
      "pmcid": "PMC11154473"
    },
    {
      "pmid": "36160111",
      "title": "Using machine learning to impute legal status of immigrants in the National Health Interview Survey.",
      "abstract": "We describe a novel machine learning method of imputing legal status for immigrants using nationally representative survey data from the Survey of Income and Program Participation (SIPP) and the National Health Interview Survey (NHIS). K-nearest Neighbor (KNN) classifier and Random Forest (RF) Algorithm machine learning were described as novel imputation methods compared to established regression-based imputation. After validating the imputation methods using sensitivity, specificity, positive predictive value (PPV) and accuracy statistics, the Random Forest Algorithm was more accurate in identifying undocumented immigrants and minimized bias in both socio-demographic variables included in the imputation, and unobserved health variables relative to regression-based imputation and KNN.\u2022We developed a new machine learning method of imputing legal status for immigrants that can be used with nationally representative, publicly available data.\u2022Our findings indicate that using machine learning to impute legal status of immigrants, specifically the Random Forest Algorithm, was more accurate in identifying undocumented immigrants and minimized bias relative to other imputation methods.",
      "authors": "Ruhnke Simon A; Wilson Fernando A; Stimpson Jim P",
      "year": "2022",
      "journal": "MethodsX",
      "doi": "10.1016/j.mex.2022.101848",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36160111/",
      "mesh_terms": "",
      "keywords": "Demography; Immigrant; Machine Learning; Population Health; Undocumented Immigrants; United States",
      "pub_types": "Journal Article",
      "pmcid": "PMC9490167"
    },
    {
      "pmid": "31816040",
      "title": "Learning from electronic health records across multiple sites: A communication-efficient and privacy-preserving distributed algorithm.",
      "abstract": "OBJECTIVES: We propose a one-shot, privacy-preserving distributed algorithm to perform logistic regression (ODAL) across multiple clinical sites. MATERIALS AND METHODS: ODAL effectively utilizes the information from the local site (where the patient-level data are accessible) and incorporates the first-order (ODAL1) and second-order (ODAL2) gradients of the likelihood function from other sites to construct an estimator without requiring iterative communication across sites or transferring patient-level data. We evaluated ODAL via extensive simulation studies and an application to a dataset from the University of Pennsylvania Health System. The estimation accuracy was evaluated by comparing it with the estimator based on the combined individual participant data or pooled data (ie, gold standard). RESULTS: Our simulation studies revealed that the relative estimation bias of ODAL1 compared with the pooled estimates was <3%, and the ratio of standard errors was <1.25 for all scenarios. ODAL2 achieved higher accuracy (with relative bias <0.1% and ratio of standard errors <1.05). In real data analysis, we investigated the associations of 100 medications with fetal loss during pregnancy. We found that ODAL1 provided estimates with relative bias <10% for 85% of medications, and ODAL2 has relative bias <10% for 99% of medications. For communication cost, ODAL1 requires transferring p numbers from each site to the local site and ODAL2 requires transferring (p\u00d7p+p) numbers from each site to the local site, where p is the number of parameters in the regression model. CONCLUSIONS: This study demonstrates that ODAL is privacy-preserving and communication-efficient with small bias and high statistical efficiency.",
      "authors": "Duan Rui; Boland Mary Regina; Liu Zixuan; Liu Yue; Chang Howard H; Xu Hua; Chu Haitao; Schmid Christopher H; Forrest Christopher B; Holmes John H; Schuemie Martijn J; Berlin Jesse A; Moore Jason H; Chen Yong",
      "year": "2020",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocz199",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31816040/",
      "mesh_terms": "Algorithms; Computer Simulation; Confidentiality; Data Analysis; Datasets as Topic; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Female; Fetal Death; Humans; Logistic Models; Odds Ratio; Pregnancy",
      "keywords": "distributed algorithm; electronic health record; learning health system; logistic regression",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC7025371"
    },
    {
      "pmid": "39279135",
      "title": "Applying a community-engaged participatory machine learning model.",
      "abstract": "Although predictive algorithms have been described as the definitive solution to bias in health care, machine learning techniques may also propagate existing health inequities within the community context. However, there may be ways in which machine learning techniques can help community psychologists, public health researchers and practitioners identify patterns in data in a way that empowers improved outcomes. Incorporating community insight in all stages of machine learning research mitigates bias by positioning members of underrepresented communities as the experts of their lived experiences. As community psychologists already prioritize community-based participatory practices, we propose three core guiding principles for a community-engaged participatory model for research using machine learning techniques: shared decision-making, reflexivity and structural humility, and flexibility and adaptability. Guided by these three principles, we emphasize grounding priority setting, problem formation, model assumptions, and interpretation of the resulting algorithmic patterns in the truths born from the lived experiences of people closest to the problem. We also suggest opportunities for bidirectional and mutually empowering partnerships between algorithmic scientists and the communities to which their algorithms will be applied. Inclusion of community stakeholders in all stages of machine learning for health research provides an opportunity to develop algorithms that are both highly effective and ethically grounded in the lived experiences of target populations.",
      "authors": "Asabor Emmanuella Ngozi; Aneni Kammarauche; Weerakoon Sitara; Opara Ijeoma",
      "year": "2024",
      "journal": "American journal of community psychology",
      "doi": "10.1002/ajcp.12765",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39279135/",
      "mesh_terms": "Humans; Machine Learning; Community-Based Participatory Research; Decision Making; Algorithms",
      "keywords": "bias in health care; biased algorithms; community\u2010based participatory research; machine learning; racism",
      "pub_types": "Journal Article",
      "pmcid": "PMC12901535"
    },
    {
      "pmid": "30779668",
      "title": "Data Engineering for Machine Learning in Women's Imaging and Beyond.",
      "abstract": "OBJECTIVE. Data engineering is the foundation of effective machine learning model development and research. The accuracy and clinical utility of machine learning models fundamentally depend on the quality of the data used for model development. This article aims to provide radiologists and radiology researchers with an understanding of the core elements of data preparation for machine learning research. We cover key concepts from an engineering perspective, including databases, data integrity, and characteristics of data suitable for machine learning projects, and from a clinical perspective, including the HIPAA, patient consent, avoidance of bias, and ethical concerns related to the potential to magnify health disparities. The focus of this article is women's imaging; nonetheless, the principles described apply to all domains of medical imaging. CONCLUSION. Machine learning research is inherently interdisciplinary: effective collaboration is critical for success. In medical imaging, radiologists possess knowledge essential for data engineers to develop useful datasets for machine learning model development.",
      "authors": "Cui Chen; Chou Shinn-Huey S; Brattain Laura; Lehman Constance D; Samir Anthony E",
      "year": "2019",
      "journal": "AJR. American journal of roentgenology",
      "doi": "10.2214/AJR.18.20464",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30779668/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; breast imaging; data engineering; machine learning; women's imaging",
      "pub_types": "Journal Article",
      "pmcid": "PMC7518717"
    },
    {
      "pmid": "35048111",
      "title": "Digital Ageism: Challenges and Opportunities in Artificial Intelligence for Older Adults.",
      "abstract": "Artificial intelligence (AI) and machine learning are changing our world through their impact on sectors including health care, education, employment, finance, and law. AI systems are developed using data that reflect the implicit and explicit biases of society, and there are significant concerns about how the predictive models in AI systems amplify inequity, privilege, and power in society. The widespread applications of AI have led to mainstream discourse about how AI systems are perpetuating racism, sexism, and classism; yet, concerns about ageism have been largely absent in the AI bias literature. Given the globally aging population and proliferation of AI, there is a need to critically examine the presence of age-related bias in AI systems. This forum article discusses ageism in AI systems and introduces a conceptual model that outlines intersecting pathways of technology development that can produce and reinforce digital ageism in AI systems. We also describe the broader ethical and legal implications and considerations for future directions in digital ageism research to advance knowledge in the field and deepen our understanding of how ageism in AI is fostered by broader cycles of injustice.",
      "authors": "Chu Charlene H; Nyrup Rune; Leslie Kathleen; Shi Jiamin; Bianchi Andria; Lyn Alexandra; McNicholl Molly; Khan Shehroz; Rahimi Samira; Grenier Amanda",
      "year": "2022",
      "journal": "The Gerontologist",
      "doi": "10.1093/geront/gnab167",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35048111/",
      "mesh_terms": "Aged; Ageism; Artificial Intelligence; Delivery of Health Care; Humans; Machine Learning; Racism",
      "keywords": "Bias; Gerontology; Machine learning; Technology",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9372891"
    },
    {
      "pmid": "38852004",
      "title": "Comparing cadence-based and machine learning based estimates for physical activity intensity classification: The UK Biobank.",
      "abstract": "OBJECTIVES: Cadence thresholds have been widely used to categorize physical activity intensity in health-related research. We examined the convergent validity of two cadence-based intensity classification approaches against a machine-learning-based intensity schema in 84,315 participants (\u226540\u202fyears) with wrist-worn accelerometers. DESIGN: Validity study. METHODS: Both cadence-based methods (one-level cadence, two-level cadence) calculated intensity-specific time based on cadence-thresholds while the two-level cadence identified stepping behaviors first. We used an overlapping plot, mean absolute error, and Spearman's correlation coefficient to examine agreements between the cadence-based and machine-learning methods. We also evaluated agreements between methods based on practically-important-difference (moderate-to-vigorous-physical activity: \u00b120\u202fmin/day, moderate-physical activity: \u00b115, vigorous-physical activity: \u00b12.5, light-physical activity: \u00b130). RESULTS: The group-level (median) minutes of moderate-to-vigorous- and moderate-physical activity estimated by one-level cadence were within the range of practically-important-difference compared to the machine-learning method (bias of median: moderate-to-vigorous-physical activity, -3.5, interquartile range [-15.8, 12.2]; moderate-physical activity, -6.0 [-17.2, 4.1]). The group-level vigorous- and light-physical activity minutes derived by two-level cadence were within practically-important-difference range (vigorous-physical activity: -0.9 [-3.1, 0.5]; light-physical activity, -1.3 [-28.2, 28.9]). The individual-level differences between the cadence-based and machine learning methods were high across intensities (e.g., moderate-to-vigorous-physical activity: mean absolute error [one-level cadence: 24.2\u202fmin/day; two-level cadence: 26.2]), with the proportion of participants within the practically-important-difference ranging from 8.4\u202f% to 61.6\u202f%. CONCLUSIONS: One-level cadence showed acceptable group-level estimates of moderate-to-vigorous and moderate-physical activity while two-level cadence showed acceptable group-level estimates of vigorous- and light-physical activity. The cadence-based methods might not be appropriate for individual-level intensity-specific time estimation.",
      "authors": "Wei Le; Ahmadi Matthew N; Hamer Mark; Blodgett Joanna M; Small Scott; Trost Stewart; Stamatakis Emmanuel",
      "year": "2024",
      "journal": "Journal of science and medicine in sport",
      "doi": "10.1016/j.jsams.2024.05.002",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38852004/",
      "mesh_terms": "Humans; Machine Learning; Exercise; Male; Middle Aged; Female; Accelerometry; United Kingdom; Adult; Aged; Biological Specimen Banks; UK Biobank",
      "keywords": "Accelerometer; Algorithm; Steps; Threshold; Wearables; Wrist-worn",
      "pub_types": "Journal Article; Comparative Study; Validation Study",
      "pmcid": ""
    },
    {
      "pmid": "37347537",
      "title": "Digital Education for the Deployment of Artificial Intelligence in Health Care.",
      "abstract": "Artificial Intelligence (AI) represents a significant milestone in health care's digital transformation. However, traditional health care education and training often lack digital competencies. To promote safe and effective AI implementation, health care professionals must acquire basic knowledge of machine learning and neural networks, critical evaluation of data sets, integration within clinical workflows, bias control, and human-machine interaction in clinical settings. Additionally, they should understand the legal and ethical aspects of digital health care and the impact of AI adoption. Misconceptions and fears about AI systems could jeopardize its real-life implementation. However, there are multiple barriers to promoting electronic health literacy, including time constraints, overburdened curricula, and the shortage of capacitated professionals. To overcome these challenges, partnerships among developers, professional societies, and academia are essential. Integrating specialists from different backgrounds, including data specialists, lawyers, and social scientists, can significantly contribute to combating digital illiteracy and promoting safe AI implementation in health care.",
      "authors": "Malerbi Fernando Korn; Nakayama Luis Filipe; Gayle Dychiao Robyn; Zago Ribeiro Lucas; Villanueva Cleva; Celi Leo Anthony; Regatieri Caio Vinicius",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/43333",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37347537/",
      "mesh_terms": "Humans; Artificial Intelligence; Educational Status; Curriculum; Neural Networks, Computer; Machine Learning",
      "keywords": "artificial intelligence; clinical; data; dataset; digital; digital education; digital health; education; evaluation; health education; machine learning; network; neural; set; transformation",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10337407"
    },
    {
      "pmid": "35115129",
      "title": "Predicting liver cancers using skewed epidemiological data.",
      "abstract": "Liver Cancer is a threat to human health and life over the world. The key to reduce liver cancer incidence is to identify high-risk populations and carry out individualized interventions before cancer occurrence. Building predictive models based on machine learning algorithms is an effective and economical way to forecast potential liver cancers. However, since the dataset is usually extremely skewed (negative samples are much more than positive samples), machine learning models suffer from severe bias and make unreliable predictions. In this paper, we systematically evaluate existing approaches in tackling class-imbalance problem and introduce two undersampling methods. The first is based on K-means++, where robust clustering centers are appointed as negative samples. The second is based on learning vector quantization, which considers diagnostic labels during clustering, and the prototypes are used as negative data. In this way, positive and negative samples are rebalanced. The algorithm is applied to five-year liver cancer prediction in Early Diagnosis and Treatment of Urban Cancer project in China. We achieve an AUC of 0.76 when no clinical measure except for epidemiological information is used. Experimental results show the advantage of our method over existing oversampling, undersampling, ensemble algorithms, and state-of-the-art outlier detection algorithms. This work explores a feasible and practical roadmap to tackle skewed medical data in cancer prediction and benefits applications targeted to human health and well-being.",
      "authors": "Li Jinpeng; Tao Yaling; Cong Huaiwei; Zhu Enwei; Cai Ting",
      "year": "2022",
      "journal": "Artificial intelligence in medicine",
      "doi": "10.1016/j.artmed.2021.102234",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35115129/",
      "mesh_terms": "Algorithms; China; Cluster Analysis; Humans; Liver Neoplasms; Machine Learning",
      "keywords": "Cancer prediction; Clustering; Liver cancer; Machine learning; Risk assessment",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37783691",
      "title": "An integrated pipeline for prediction of Clostridioides difficile infection.",
      "abstract": "With the expansion of electronic health records(EHR)-linked genomic data comes the development of machine learning-enable models. There is a pressing need to develop robust pipelines to evaluate the performance of integrated models and minimize systemic bias. We developed a prediction model of symptomatic Clostridioides difficile\u00a0infection(CDI) by integrating common EHR-based and genetic risk factors(rs2227306/IL8). Our pipeline includes (1) leveraging phenotyping algorithm to minimize temporal bias, (2) performing simulation studies to determine the predictive power in samples without genetic information, (3) propensity score matching to control for the confoundings, (4) selecting machine learning algorithms to capture complex feature interactions, (5) performing oversampling to address data imbalance, and (6) optimizing models and ensuring proper bias-variance trade-off. We evaluate the performance of prediction models of CDI when including common clinical risk factors and the benefit of incorporating genetic feature(s) into the models. We emphasize the importance of building a robust integrated pipeline to avoid systemic bias and thoroughly evaluating genetic features when integrated into the prediction models in the general population and subgroups.",
      "authors": "Li Jiang; Chaudhary Durgesh; Sharma Vaibhav; Sharma Vishakha; Avula Venkatesh; Ssentongo Paddy; Wolk Donna M; Zand Ramin; Abedi Vida",
      "year": "2023",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-023-41753-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37783691/",
      "mesh_terms": "Humans; Algorithms; Clostridium Infections; Computer Simulation; Electronic Health Records; Genomics",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10545794"
    },
    {
      "pmid": "30256126",
      "title": "Automatic glomerular identification and quantification of histological phenotypes using image analysis and machine learning.",
      "abstract": "Current methods of scoring histological kidney samples, specifically glomeruli, do not allow for collection of quantitative data in a high-throughput and consistent manner. Neither untrained individuals nor computers are presently capable of identifying glomerular features, so expert pathologists must do the identification and score using a categorical matrix, complicating statistical analysis. Critical information regarding overall health and physiology is encoded in these samples. Rapid comprehensive histological scoring could be used, in combination with other physiological measures, to significantly advance renal research. Therefore, we used machine learning to develop a high-throughput method to automatically identify and collect quantitative data from glomeruli. Our method requires minimal human interaction between steps and provides quantifiable data independent of user bias. The method uses free existing software and is usable without extensive image analysis training. Validation of the classifier and feature scores in mice is highlighted in this work and shows the power of applying this method in murine research. Preliminary results indicate that the method can be applied to data sets from different species after training on relevant data, allowing for fast glomerular identification and quantitative measurements of glomerular features. Validation of the classifier and feature scores are highlighted in this work and show the power of applying this method. The resulting data are free from user bias. Continuous data, such that statistical analysis can be performed, allows for more precise and comprehensive interrogation of samples. These data can then be combined with other physiological data to broaden our overall understanding of renal function.",
      "authors": "Sheehan Susan M; Korstanje Ron",
      "year": "2018",
      "journal": "American journal of physiology. Renal physiology",
      "doi": "10.1152/ajprenal.00629.2017",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30256126/",
      "mesh_terms": "Animals; Automation, Laboratory; Biopsy; Diagnosis, Computer-Assisted; Disease Models, Animal; Female; Humans; Image Interpretation, Computer-Assisted; Kidney Diseases; Kidney Glomerulus; Machine Learning; Male; Mice, Inbred C57BL; Mice, Transgenic; Microscopy; Pattern Recognition, Automated; Phenotype; Predictive Value of Tests; Rats; Reproducibility of Results; Software; Species Specificity; Workflow",
      "keywords": "digital pathology; histology; machine learning",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6336999"
    },
    {
      "pmid": "37545628",
      "title": "Feasibility of wearable devices and machine learning for sleep classification in children with Rett syndrome: A pilot study.",
      "abstract": "Sleep is vital to many processes involved in the well-being and health of children; however, it is estimated that 80% of children with Rett syndrome suffer from sleep disorders. Caregiver reports and questionnaires, which are the current method of studying sleep, are prone to observer bias and missed information. Polysomnography is considered the gold standard for sleep analysis but is labor and cost-intensive and limits the frequency of data collection for sleep disorder studies. Wearable digital health technologies, such as actigraphy devices, have shown potential and feasibility as a method for sleep analysis in Rett syndrome, but have not been validated against polysomnography. Furthermore, the collected accelerometer data has limitations due to the rigidity, periodic limb movement, and involuntary muscle contractions prevalent in Rett syndrome. Heart rate and electrodermal activity, along with other physiological signals, have been linked to sleep stages and can be utilized with machine learning to provide better resistance to noise and false positives than actigraphy. This research aims to address the gap in Rett syndrome sleep analysis by comparing the performance of a machine learning model utilizing both accelerometer data and physiological data features to the gold-standard polysomnography for sleep analysis in Rett syndrome. Our analytical validation pilot study (n = 7) found that using physiological and accelerometer features, our machine learning models can differentiate between awake, non-rapid eye movement sleep, and rapid eye movement sleep in Rett syndrome children with an accuracy of 85.1% when using an individual model. Additionally, this work demonstrates that it is feasible to use digital health technologies in Rett syndrome, even at a young age, without data loss or interference from repetitive movements that are characteristic of Rett syndrome.",
      "authors": "Migovich Miroslava; Ullal Akshith; Fu Cary; Peters Sarika U; Sarkar Nilanjan",
      "year": "2023",
      "journal": "Digital health",
      "doi": "10.1177/20552076231191622",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37545628/",
      "mesh_terms": "",
      "keywords": "Rett syndrome; machine learning; sleep analysis; wearable physiological sensors",
      "pub_types": "Journal Article",
      "pmcid": "PMC10399268"
    },
    {
      "pmid": "39406791",
      "title": "Exploring online public survey lifestyle datasets with statistical analysis, machine learning and semantic ontology.",
      "abstract": "Lifestyle diseases significantly contribute to the global health burden, with lifestyle factors playing a crucial role in the development of depression. The COVID-19 pandemic has intensified many determinants of depression. This study aimed to identify lifestyle and demographic factors associated with depression symptoms among Indians during the pandemic, focusing on a sample from Kolkata, India. An online public survey was conducted, gathering data from 1,834 participants (with 1,767 retained post-cleaning) over three months via social media and email. The survey consisted of 44 questions and was distributed anonymously to ensure privacy. Data were analyzed using statistical methods and machine learning, with principal component analysis (PCA) and analysis of variance (ANOVA) employed for feature selection. K-means clustering divided the pre-processed dataset into five clusters, and a support vector machine (SVM) with a linear kernel achieved 96% accuracy in a multi-class classification problem. The Local Interpretable Model-agnostic Explanations (LIME) algorithm provided local explanations for the SVM model predictions. Additionally, an OWL (web ontology language) ontology facilitated the semantic representation and reasoning of the survey data. The study highlighted a pipeline for collecting, analyzing, and representing data from online public surveys during the pandemic. The identified factors were correlated with depressive symptoms, illustrating the significant influence of lifestyle and demographic variables on mental health. The online survey method proved advantageous for data collection, visualization, and cost-effectiveness while maintaining anonymity and reducing bias. Challenges included reaching the target population, addressing language barriers, ensuring digital literacy, and mitigating dishonest responses and sampling errors. In conclusion, lifestyle and demographic factors significantly impact depression during the COVID-19 pandemic. The study's methodology offers valuable insights into addressing mental health challenges through scalable online surveys, aiding in the understanding and mitigation of depression risk factors.",
      "authors": "Chatterjee Ayan; Riegler Michael A; Johnson Miriam Sinkerud; Das Jishnu; Pahari Nibedita; Ramachandra Raghavendra; Ghosh Bikramaditya; Saha Arpan; Bajpai Ram",
      "year": "2024",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-024-74539-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39406791/",
      "mesh_terms": "Humans; Male; Female; COVID-19; Life Style; Adult; Depression; Machine Learning; India; Middle Aged; Surveys and Questionnaires; Semantics; Young Adult; Support Vector Machine; Principal Component Analysis; Adolescent; SARS-CoV-2; Pandemics; Aged",
      "keywords": "COVID-19; Datasets; Depression; LIME; Machine learning; Semantics; Survey",
      "pub_types": "Journal Article",
      "pmcid": "PMC11480510"
    },
    {
      "pmid": "38623549",
      "title": "RHMCD-20 dataset: Identify rapid human mental health depression during quarantine life using machine learning.",
      "abstract": "The RHMCD-20 dataset offers a thorough investigation of the dynamics of mental health in Bangladesh while under quarantine. The structured survey that was distributed to different demographic groups yielded a dataset that included a wide range of variables, such as age, gender, occupation, and stress levels. Predictive modelling, understanding the effects of quarantine on the workplace and society, and intergenerational insights are all greatly enhanced by this dataset. The dataset allows intelligent algorithms to be developed by bridging the gap between machine learning and healthcare. Although sampling bias is one of the limitations of correlation analysis, it does improve understanding. This presents opportunities for improving precision in mental health management, fostering interdisciplinary collaborations, and creating dynamic forecasting models. Researchers and policymakers can benefit greatly from the RHMCD-20 dataset, which offers nuanced insights into mental health experiences during quarantine and informs evidence-based interventions and policies. groundwork for innovative methodologies, steering the trajectory of informed decision-making in dynamic energy landscapes.",
      "authors": "Amin Nazrul; Salehin Imrus; Baten Md Abu; Noman Rabbi Al",
      "year": "2024",
      "journal": "Data in brief",
      "doi": "10.1016/j.dib.2024.110376",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38623549/",
      "mesh_terms": "",
      "keywords": "COVID-19 quarantine; Isolation effects; Machine learning; Mental health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11016953"
    },
    {
      "pmid": "38389375",
      "title": "Machine Learning-based Deep Analysis of Human Blood using NIR Spectrophotometry Signatures.",
      "abstract": "BACKGROUND: Non-invasive bio-diagnostics are essential for providing patients with safer treatment. In this subject, significant growth is attained for noninvasive anaemia detection in terms of Hb concentration by means of spectroscopic and image analysis. The lower satisfaction rate is found due to inconsistent results in various patient settings. OBJECTIVE: This observational study aims to present an adaptable point-of-care Near-Infrared (NIR) spectrophotometric approach with a constructive Machine Learning (ML) algorithm for monitoring Haemoglobin (Hb) concentration by considering dominating influencing factors into account. METHODS: To accomplish this objective, 121 subjects (19.2-55.4 years) were enrolled in the study, having a wide range of Hb concentrations (8.2-17.4 g/dL) obtained from two standard Laboratory analyzers. To inspect the performance, the unique dimensionality reduction approaches are applied with numerous regression models using 5-fold cross-validation. RESULTS: The optimum accuracy is found using support vector regression (SVR) and mutual information having 3 independent features i.e. Pearson correlation (r)= 0.79, standard deviation (SD)= 1.07 g/dL, bias=-0.13 g/dL and limits of agreement (LoA)=-2.22 to 1.97 g/dL. Additionally, comparability between two standard laboratory analyzers is found as; r=0.97, SD=0.50 g/dL, bias=0.21 g/dL, and LoA= -0.77 to 1.19 g/dL. CONCLUSION: The precision of \u00b11 g/dL in 5-fold cross-validation ensures the same performance irrespective of different age groups, gender, BMI, smoking level, drinking level, and skin type. The outcomes with the offered NIR sensing system and an exclusive ML algorithm can accelerate its' requirement at remote locative rural areas and critical care units where continuous Hb monitoring is compulsory.",
      "authors": "Kumar Yogesh; Dogra Ayush; Dhiman Varun; Singh Vishavpreet; Kaushik Ajeet; Kumar Sanjeev",
      "year": "2024",
      "journal": "Current medical imaging",
      "doi": "10.2174/0115734056271761231204093832",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38389375/",
      "mesh_terms": "Humans; Hemoglobins; Spectrophotometry; Point-of-Care Testing; Spectroscopy, Near-Infrared; Young Adult; Adult; Middle Aged; Male; Female",
      "keywords": "Haemoglobin; Innovations and health.; Machine Learning; Non-Invasive; Point-of-care; Spectrophotometry",
      "pub_types": "Observational Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "35107127",
      "title": "Considerations for the implementation of machine learning into acute care settings.",
      "abstract": "INTRODUCTION: Management of patients in the acute care setting requires accurate diagnosis and rapid initiation of validated treatments; therefore, this setting is likely to be an environment in which cognitive augmentation of the clinician's provision of care with technology rooted in artificial intelligence, such as machine learning (ML), is likely to eventuate. SOURCES OF DATA: PubMed and Google Scholar with search terms that included ML, intensive/critical care unit, electronic health records (EHR), anesthesia information management systems and clinical decision support were the primary sources for this report. AREAS OF AGREEMENT: Different categories of learning of large clinical datasets, often contained in EHRs, are used for training in ML. Supervised learning uses algorithm-based models, including support vector machines, to pair patients' attributes with an expected outcome. Unsupervised learning uses clustering algorithms to define to which disease grouping a patient's attributes most closely approximates. Reinforcement learning algorithms use ongoing environmental feedback to deterministically pursue likely patient outcome. AREAS OF CONTROVERSY: Application of ML can result in undesirable outcomes over concerns related to fairness, transparency, privacy and accountability. Whether these ML technologies irrevocably change the healthcare workforce remains unresolved. GROWING POINTS: Well-resourced Learning Health Systems are likely to exploit ML technology to gain the fullest benefits for their patients. How these clinical advantages can be extended to patients in health systems that are neither well-endowed, nor have the necessary data gathering technologies, needs to be urgently addressed to avoid further disparities in healthcare.",
      "authors": "Bishara Andrew; Maze Elijah H; Maze Mervyn",
      "year": "2022",
      "journal": "British medical bulletin",
      "doi": "10.1093/bmb/ldac001",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35107127/",
      "mesh_terms": "Algorithms; Artificial Intelligence; Critical Care; Electronic Health Records; Humans; Machine Learning",
      "keywords": "acute care; algorithms; machine learning",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36812626",
      "title": "Interpretable machine learning for automated left ventricular scar quantification in hypertrophic cardiomyopathy patients.",
      "abstract": "Scar quantification on cardiovascular magnetic resonance (CMR) late gadolinium enhancement (LGE) images is important in risk stratifying patients with hypertrophic cardiomyopathy (HCM) due to the importance of scar burden in predicting clinical outcomes. We aimed to develop a machine learning (ML) model that contours left ventricular (LV) endo- and epicardial borders and quantifies CMR LGE images from HCM patients.We retrospectively studied 2557 unprocessed images from 307 HCM patients followed at the University Health Network (Canada) and Tufts Medical Center (USA). LGE images were manually segmented by two experts using two different software packages. Using 6SD LGE intensity cutoff as the gold standard, a 2-dimensional convolutional neural network (CNN) was trained on 80% and tested on the remaining 20% of the data. Model performance was evaluated using the Dice Similarity Coefficient (DSC), Bland-Altman, and Pearson's correlation. The 6SD model DSC scores were good to excellent at 0.91 \u00b1 0.04, 0.83 \u00b1 0.03, and 0.64 \u00b1 0.09 for the LV endocardium, epicardium, and scar segmentation, respectively. The bias and limits of agreement for the percentage of LGE to LV mass were low (-0.53 \u00b1 2.71%), and correlation high (r = 0.92). This fully automated interpretable ML algorithm allows rapid and accurate scar quantification from CMR LGE images. This program does not require manual image pre-processing, and was trained with multiple experts and software, increasing its generalizability.",
      "authors": "Navidi Zeinab; Sun Jesse; Chan Raymond H; Hanneman Kate; Al-Arnawoot Amna; Munim Alif; Rakowski Harry; Maron Martin S; Woo Anna; Wang Bo; Tsang Wendy",
      "year": "2023",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000159",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36812626/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9931226"
    },
    {
      "pmid": "35805533",
      "title": "Multiobjective Emergency Resource Allocation under the Natural Disaster Chain with Path Planning.",
      "abstract": "Public safety and health cannot be secured without the comprehensive recognition of characteristics and reliable emergency response schemes under the disaster chain. Distinct from emergency resource allocation that focuses primarily on a single disaster, dynamic response, periodic supply, and assisted decision-making are necessary. Therefore, we propose a multiobjective emergency resource allocation model considering uncertainty under the natural disaster chain. Resource allocation was creatively combined with path planning through the proposed multiobjective cellular genetic algorithm (MOCGA) and the improved A* algorithm with avoidance of unexpected road elements. Furthermore, timeliness, efficiency, and fairness in actual rescue were optimized by MOCGA. The visualization of emergency trips and intelligent avoidance of risk areas were achieved by the improved A* algorithm. The effects of logistics performance, coupling of disaster factors, and government regulation on emergency resource allocation were discussed based on different disaster chain scenarios. The results show that disruption in infrastructure support, cascading effect of disasters, and time urgency are additional environmental challenges. The proposed model and algorithm work in obtaining the optimal solution for potential regional coordination and resilient supply, with a 22.2% increase in the total supply rate. Cooperative allocation complemented by political regulation can be a positive action for successfully responding to disaster chains.",
      "authors": "Wang Feiyue; Xie Ziling; Liu Hui; Pei Zhongwei; Liu Dingli",
      "year": "2022",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph19137876",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35805533/",
      "mesh_terms": "Algorithms; Disaster Planning; Disasters; Natural Disasters; Resource Allocation",
      "keywords": "emergency resource allocation; multiobjective optimization; natural disaster chain; path planning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9265372"
    },
    {
      "pmid": "35065153",
      "title": "Estimation of low-density lipoprotein cholesterol levels using machine learning.",
      "abstract": "BACKGROUND: Low-density lipoprotein-cholesterol (LDL-C) is used as a threshold and target for treating dyslipidemia. Although the Friedewald equation is widely used to estimate LDL-C, it has been known to be inaccurate in the case of high triglycerides (TG) or non-fasting states. We aimed to propose a novel method to estimate LDL-C using machine learning. METHODS: Using a large, single-center electronic health record database, we derived a ML algorithm to estimate LDL-C from standard lipid profiles. From 1,029,572 cases with both standard lipid profiles (total cholesterol, high-density lipoprotein-cholesterol, and TG) and direct LDL-C measurements, 823,657 tests were used to derive LDL-C estimation models. Patient characteristics such as sex, age, height, weight, and other laboratory values were additionally used to create separate data sets and algorithms. RESULTS: Machine learning with gradient boosting (LDL-CX) and neural network (LDL-CN) showed better correlation with directly measured LDL-C, compared with conventional methods (r\u00a0=\u00a00.9662, 0.9668, 0.9563, 0.9585; for LDL-CX, LDL-CN, Friedewald [LDL-CF], and Martin [LDL-CM] equations, respectively). The overall bias of LDL-CX (-0.27\u00a0mg/dL, 95% CI -0.30 to -0.23) and LDL-CN (-0.01\u00a0mg/dL, 95% CI -0.04-0.03) were significantly smaller compared with both LDL-CF (-3.80\u00a0mg/dL, 95% CI -3.80 to -3.60) or LDL-CM (-2.00\u00a0mg/dL, 95% CI -2.00 to -1.94), especially at high TG levels. CONCLUSIONS: Machine learning algorithms were superior in estimating LDL-C compared with the conventional Friedewald or the more contemporary Martin equations. Through external validation and modification, machine learning could be incorporated into electronic health records to substitute LDL-C estimation.",
      "authors": "Oh Gyu Chul; Ko Taehoon; Kim Jin-Hyu; Lee Min Ho; Choi Sae Won; Bae Ye Seul; Kim Kyung Hwan; Lee Hae-Young",
      "year": "2022",
      "journal": "International journal of cardiology",
      "doi": "10.1016/j.ijcard.2022.01.029",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35065153/",
      "mesh_terms": "Algorithms; Cholesterol, HDL; Cholesterol, LDL; Dyslipidemias; Humans; Machine Learning; Triglycerides",
      "keywords": "Cost-effectiveness; Hypercholesterolemia; Low-density lipoprotein cholesterol; Machine-learning; Triglycerides",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41134979",
      "title": "Machine Learning Applications in Population and Public Health: Guidelines for Development, Testing, and Implementation.",
      "abstract": "Machine learning (ML), a subset of artificial intelligence, uses large datasets to identify patterns between potential predictors and outcomes. ML involves iterative learning from data and is increasingly used in population and public health. Examples include early warning of infectious disease outbreaks, predicting the future burden of noncommunicable diseases, and assessing public health interventions. However, ML can inadvertently produce biased outputs related to the quality and quantity of data, who is engaged and helping direct the analysis, and how findings are interpreted. Specific guidelines for using ML in population and public health have not yet been created. We assembled a diverse team of experts in computer science, statistical modeling, clinical and population health epidemiology, health economics, ethics, sociology, and public health. Drawing on literature reviews and a modified Delphi process, we identified five key recommendations: (1) prioritize partnerships and interventions to support communities considered structurally disadvantaged; (2) use ML for dynamic situations, such as public health emergencies, while adhering to ethical standards; (3) conduct risk assessments and bias mitigation strategies aligned with identified risks; (4) ensure technical transparency and reproducibility by publicly sharing data sources and methodologies; and (5) foster multidisciplinary dialogue to discuss the potential harms of ML-related bias and raise awareness among the public and public health community. The proposed guidelines provide operational steps for stakeholders, ensuring that ML tools are not only effective but also ethically grounded and feasible in real-world scenarios.",
      "authors": "Pinto Andrew D; Birdi Sharon; Durant Steve; Rabet Roxana; Parekh Rahul; Ali Shehzad; Buckeridge David; Ghassemi Marzyeh; Gibson Jennifer; John-Baptiste Ava; Macklin Jillian; McCradden Melissa D; McKenzie Kwame; Naraei Parisa; Owusu-Bempah Akwasi; Rosella Laura C; Shaw James; Upshur Ross; Mishra Sharmistha",
      "year": "2025",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/68952",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41134979/",
      "mesh_terms": "Humans; Machine Learning; Public Health; Guidelines as Topic",
      "keywords": "AI; algorithmic bias; artificial intelligence; guideline; health equity; machine learning; population health; public health",
      "pub_types": "Journal Article",
      "pmcid": "PMC12551935"
    },
    {
      "pmid": "39613447",
      "title": "Development, validation and economic evaluation of a machine learning algorithm for predicting the probability of kidney damage in patients with hyperuricaemia: protocol for a retrospective study.",
      "abstract": "INTRODUCTION: Accurate identification of the risk factors is essential for the effective prevention of hyperuricaemia (HUA)-related kidney damage. Previous studies have established the efficacy of machine learning (ML) methodologies in predicting kidney damage due to other chronic diseases. Nevertheless, a scarcity of precise and clinically applicable prediction models exists for assessing the risk of HUA-related kidney damage. This study aims to accurately predict the risk of developing HUA-related kidney damage using a ML algorithm, which is based on a retrospective database. METHODS AND ANALYSIS: This retrospective study aims to collect clinical data on outpatients and inpatients from the Sichuan Provincial People's Hospital, China, covering the period from 1 January 2018 to 31 December 2021 with a focus on patients diagnosed with 'hyperuricaemia' or 'gout'. Predictive models will be constructed using techniques such as data imputation, sampling, feature selection and ML algorithms. This research will evaluate the predictive accuracy, interpretability and fairness of the developed models to determine their clinical applicability. The net benefit and net saving will be calculated to gauge the economic value of the model. The most effective model will then undergo external validation and be made available as an online predictive tool to facilitate user access. ETHICS AND DISSEMINATION: The Ethics Review Committee at Sichuan Provincial People's Hospital granted approval for the ethical review of this study without requiring informed consent. The findings of the study will be disseminated in a peer-reviewed journal.",
      "authors": "Hou Zhengyao; Yang Yong; Deng Bo; Gao Guangjie; Li Mengting; Liu Xinyu; Chang Huan; Shen Hao; Zou Linke; Li Jinqi; Wu Xingwei",
      "year": "2024",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2024-086032",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39613447/",
      "mesh_terms": "Humans; Retrospective Studies; Machine Learning; Hyperuricemia; Algorithms; China; Risk Factors; Kidney Diseases; Risk Assessment; Male; Female",
      "keywords": "Factor Analysis, Statistical; Machine Learning; PUBLIC HEALTH",
      "pub_types": "Journal Article",
      "pmcid": "PMC11605815"
    },
    {
      "pmid": "37114417",
      "title": "Healthcare personnel interactive pathogen exposure response system.",
      "abstract": "Exposure investigations are labor intensive and vulnerable to recall bias. We developed an algorithm to identify healthcare personnel (HCP) interactions from the electronic health record (EHR), and we evaluated its accuracy against conventional exposure investigations. The EHR algorithm identified every known transmission and used ranking to produce a manageable contact list.",
      "authors": "Smith Leigh L; Fallon Susan A; Virk Zunaira Q; Salinas Alejandra B; Curless Melanie S; Cosgrove Sara E; Maragakis Lisa L; Rock Clare; Klein Eili Y",
      "year": "2023",
      "journal": "Infection control and hospital epidemiology",
      "doi": "10.1017/ice.2022.261",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37114417/",
      "mesh_terms": "Humans; Health Personnel; Electronic Health Records; Attitude of Health Personnel",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC11767607"
    },
    {
      "pmid": "40747249",
      "title": "Interpretable machine learning-based prediction of mortality in critical cancer patients with delirium: A retrospective cohort study.",
      "abstract": "OBJECTIVE: Delirium in cancer patients presents a significant clinical challenge, often leading to increased mortality, prolonged hospital stays, and higher healthcare costs. This study aimed to develop an interpretable and generalizable machine learning (ML) model for early prediction of mortality risk in cancer patients with delirium. METHODS: A retrospective cohort study design was employed, utilizing data from the Medical Information Mart for Intensive Care IV (MIMIC-IV) database. Five ML models were subsequently constructed and evaluated. RESULTS: A total of 1893 cancer patients with delirium were included in the analysis, of whom 685 (36.2%) died within 28 days who were admitted to the intensive care unit at Beth Israel Deaconess Medical Center between 2008 and 2022. The Category Boosting (CatBoost) algorithm outperformed other ML models, achieving the highest area under the curve (AUC) on both training and validation datasets. Its robustness was supported by a bias-corrected performance curve closely aligned with the ideal line and the greatest net benefit in decision curve analysis across all threshold probabilities (0-1). The top five predictors of 28-day mortality were high Glasgow Coma Scale and Acute Physiology and Chronic Health Evaluation II scores, use of antibiotics, propofol, and vasopressors. CONCLUSIONS: This study developed an optimal and explainable ML model for predicting 28-day mortality in cancer patients with delirium. The CatBoost algorithm demonstrated stable and robust performance, and interpretability analysis highlighted key predictors. These findings may aid early clinical decision-making and targeted interventions for this high-risk population.",
      "authors": "He Yang; Liu Ning; Hao Sicheng; Xu Mimei; Zeng Yingchun",
      "year": "2025",
      "journal": "Asia-Pacific journal of oncology nursing",
      "doi": "10.1016/j.apjon.2025.100760",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40747249/",
      "mesh_terms": "",
      "keywords": "Cancer patients; Delirium; Machine learning; Mortality; Shapley additive explanations",
      "pub_types": "Journal Article",
      "pmcid": "PMC12311572"
    },
    {
      "pmid": "38937447",
      "title": "Data-driven prediction of continuous renal replacement therapy survival.",
      "abstract": "Continuous renal replacement therapy (CRRT) is a form of dialysis prescribed to severely ill patients who cannot tolerate regular hemodialysis. However, as the patients are typically very ill to begin with, there is always uncertainty whether they will survive during or after CRRT treatment. Because of outcome uncertainty, a large percentage of patients treated with CRRT do not survive, utilizing scarce resources and raising false hope in patients and their families. To address these issues, we present a machine\u00a0learning-based algorithm to predict short-term survival in patients being initiated on CRRT. We use information extracted from electronic health records from patients who were placed on CRRT at multiple institutions to train a model that predicts CRRT survival outcome; on a held-out test set, the model achieves an area under the receiver operating curve of 0.848 (CI\u2009=\u20090.822-0.870). Feature importance, error, and subgroup analyses provide insight into bias and relevant features for model prediction. Overall, we demonstrate the potential for predictive machine\u00a0learning models to assist clinicians in alleviating the uncertainty of CRRT patient survival outcomes, with opportunities for future improvement through further data collection and advanced modeling.",
      "authors": "Zamanzadeh Davina; Feng Jeffrey; Petousis Panayiotis; Vepa Arvind; Sarrafzadeh Majid; Karumanchi S Ananth; Bui Alex A T; Kurtz Ira",
      "year": "2024",
      "journal": "Nature communications",
      "doi": "10.1038/s41467-024-49763-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38937447/",
      "mesh_terms": "Humans; Continuous Renal Replacement Therapy; Machine Learning; Male; Female; Algorithms; Middle Aged; Electronic Health Records; Aged; ROC Curve; Renal Replacement Therapy",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11211317"
    },
    {
      "pmid": "38835075",
      "title": "Optimizing clinico-genomic disease prediction across ancestries: a machine learning strategy with Pareto improvement.",
      "abstract": "BACKGROUND: Accurate prediction of an individual's predisposition to diseases is vital for preventive medicine and early intervention. Various statistical and machine learning models have been developed for disease prediction using clinico-genomic data. However, the accuracy of clinico-genomic prediction of diseases may vary significantly across ancestry groups due to their unequal representation in clinical genomic datasets. METHODS: We introduced a deep transfer learning approach to improve the performance of clinico-genomic prediction models for data-disadvantaged ancestry groups. We conducted machine learning experiments on multi-ancestral genomic datasets of lung cancer, prostate cancer, and Alzheimer's disease, as well as on synthetic datasets with built-in data inequality and distribution shifts across ancestry groups. RESULTS: Deep transfer learning significantly improved disease prediction accuracy for data-disadvantaged populations in our multi-ancestral machine learning experiments. In contrast, transfer learning based on linear frameworks did not achieve comparable improvements for these data-disadvantaged populations. CONCLUSIONS: This study shows that deep transfer learning can enhance fairness in multi-ancestral machine learning by improving prediction accuracy for data-disadvantaged populations without compromising prediction accuracy for other populations, thus providing a Pareto improvement towards equitable clinico-genomic prediction of diseases.",
      "authors": "Gao Yan; Cui Yan",
      "year": "2024",
      "journal": "Genome medicine",
      "doi": "10.1186/s13073-024-01345-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38835075/",
      "mesh_terms": "Humans; Machine Learning; Genomics; Genetic Predisposition to Disease; Alzheimer Disease; Male; Prostatic Neoplasms; Lung Neoplasms",
      "keywords": "Deep neural network; Disease prediction; Health equity; Transfer learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11149372"
    },
    {
      "pmid": "32784193",
      "title": "Early Stage Machine Learning-Based Prediction of US County Vulnerability to the COVID-19 Pandemic: Machine Learning Approach.",
      "abstract": "BACKGROUND: The rapid spread of COVID-19 means that government and health services providers have little time to plan and design effective response policies. It is therefore important to quickly provide accurate predictions of how vulnerable geographic regions such as counties are to the spread of this virus. OBJECTIVE: The aim of this study is to develop county-level prediction around near future disease movement for COVID-19 occurrences using publicly available data. METHODS: We estimated county-level COVID-19 occurrences for the period March 14 to 31, 2020, based on data fused from multiple publicly available sources inclusive of health statistics, demographics, and geographical features. We developed a three-stage model using XGBoost, a machine learning algorithm, to quantify the probability of COVID-19 occurrence and estimate the number of potential occurrences for unaffected counties. Finally, these results were combined to predict the county-level risk. This risk was then used as an estimated after-five-day-vulnerability of the county. RESULTS: The model predictions showed a sensitivity over 71% and specificity over 94% for models built using data from March 14 to 31, 2020. We found that population, population density, percentage of people aged >70 years, and prevalence of comorbidities play an important role in predicting COVID-19 occurrences. We observed a positive association at the county level between urbanicity and vulnerability to COVID-19. CONCLUSIONS: The developed model can be used for identification of vulnerable counties and potential data discrepancies. Limited testing facilities and delayed results introduce significant variation in reported cases, which produces a bias in the model.",
      "authors": "Mehta Mihir; Julaiti Juxihong; Griffin Paul; Kumara Soundar",
      "year": "2020",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/19446",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32784193/",
      "mesh_terms": "Aged; Algorithms; Betacoronavirus; COVID-19; Comorbidity; Coronavirus Infections; Humans; Machine Learning; Models, Statistical; Pandemics; Pneumonia, Viral; Population Density; Population Surveillance; Risk Assessment; SARS-CoV-2; United States; Urban Population",
      "keywords": "COVID-19; XGBoost; coronavirus; county-level vulnerability; machine learning; prediction model",
      "pub_types": "Journal Article",
      "pmcid": "PMC7490002"
    },
    {
      "pmid": "35098584",
      "title": "Split and combine simulation extrapolation algorithm to correct geocoding coarsening of built environment exposures.",
      "abstract": "A major challenge in studies relating built environment features to health is measurement error in exposure due to geocoding errors. Faulty geocodes in built environment data introduce errors to exposure assessments that may induce bias in the corresponding health effect estimates. In this study, we examine the distribution of the measurement error in measures constructed from point-referenced exposures, quantify the extent of bias in exposure effect estimates due to geocode coarsening, and extend the simulation extrapolation (SIMEX) method to correct the bias. The motivating example focuses on the association between children's body mass index and exposure to the junk food environment, represented by the number of junk food outlets within a buffer area near their schools. We show, algebraically and through simulation studies, that coarsening of food outlet coordinates results in exposure measurement errors that have heterogeneous variance and nonzero mean, and that the resulting bias in the health effect can be away from the null. The proposed SC-SIMEX procedure accommodates the nonstandard measurement error distribution, without requiring external data, and provides the best bias correction compared to other SIMEX approaches.",
      "authors": "Won Jung Y; Sanchez-Vaznaugh Emma V; Zhai Yuqi; S\u00e1nchez Brisa N",
      "year": "2022",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.9338",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35098584/",
      "mesh_terms": "Algorithms; Bias; Built Environment; Child; Computer Simulation; Geographic Mapping; Humans",
      "keywords": "bias; geocode coarsening; measurement error; simulation-extrapolation",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9018528"
    },
    {
      "pmid": "38726224",
      "title": "Closing the Digital Divide in Interventions for Substance Use Disorder.",
      "abstract": "Digital health interventions are exploding in today's medical practice and have tremendous potential to support the treatment of substance use disorders (SUD). Developers and healthcare providers alike must be cognizant of the potential for digital interventions to exacerbate existing inequities in SUD treatment, particularly as they relate to Social Determinants of Health (SDoH). To explore this evolving area of study, this manuscript will review the existing concepts of the digital divide and digital inequities, and the role SDoH play as drivers of digital inequities. We will then explore how the data used and modeling strategies can create bias in digital health tools for SUD. Finally, we will discuss potential solutions and future directions to bridge these gaps including smartphone ownership, Wi-Fi access, digital literacy, and mitigation of historical, algorithmic, and measurement bias. Thoughtful design of digital interventions is quintessential to reduce the risk of bias, decrease the digital divide, and create equitable health outcomes for individuals with SUD.",
      "authors": "Hampton Jazmin; Mugambi Purity; Caggiano Emily; Eugene Reynalde; Valente Alycia; Taylor Melissa; Carreiro Stephanie",
      "year": "2024",
      "journal": "Journal of psychiatry and brain science",
      "doi": "10.20900/jpbs.20240002",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38726224/",
      "mesh_terms": "",
      "keywords": "algorithmic bias; artificial intelligence; digital divide; digital health; digital inequities; mHealth; machine learning; social determinants of health; substance use disorder",
      "pub_types": "Journal Article",
      "pmcid": "PMC11081399"
    },
    {
      "pmid": "33413920",
      "title": "Right population, right resources, right algorithm: Using machine learning efficiently and effectively in surgical systems where data are a limited resource.",
      "abstract": "There is a growing interest in using machine learning algorithms to support surgical care, diagnostics, and public health surveillance in low- and middle-income countries. From our own experience and the literature, we share several lessons for developing such models in settings where the data necessary for algorithm training and implementation is a limited resource. First, the training cohort should be as similar as possible to the population of interest, and recalibration can be used to improve risk estimates when a model is transported to a new context. Second, algorithms should incorporate existing data sources or data that is easily obtainable by frontline health workers or assistants in order to optimize available resources and facilitate integration into clinical practice. Third, the Super Learner ensemble machine learning algorithm can be used to define the optimal model for a given prediction problem while minimizing bias in the algorithm selection process. By considering the right population, right resources, and right algorithm, researchers can train prediction models that are both context-appropriate and resource-conscious. There remain gaps in data availability, affordable computing capacity, and implementation studies that hinder clinical algorithm development and use in low-resource settings, although these barriers are decreasing over time. We advocate for researchers to create open-source code, apps, and training materials to allow new machine learning models to be adapted to different populations and contexts in order to support surgical providers and health care systems in low- and middle-income countries worldwide.",
      "authors": "Eyler Dang Lauren; Hubbard Alan; Dissak-Delon Fanny Nadia; Chichom Mefire Alain; Juillard Catherine",
      "year": "2021",
      "journal": "Surgery",
      "doi": "10.1016/j.surg.2020.11.043",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33413920/",
      "mesh_terms": "Algorithms; Clinical Decision Rules; Clinical Decision-Making; Data Collection; Decision Support Techniques; Delivery of Health Care; Developing Countries; Humans; Machine Learning; Surgical Procedures, Operative",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39324329",
      "title": "Automated Speech Analysis for Risk Detection of Depression, Anxiety, Insomnia, and Fatigue: Algorithm Development and Validation Study.",
      "abstract": "BACKGROUND: While speech analysis holds promise for mental health assessment, research often focuses on single symptoms, despite symptom co-occurrences and interactions. In addition, predictive models in mental health do not properly assess the limitations of speech-based systems, such as uncertainty, or fairness for a safe clinical deployment. OBJECTIVE: We investigated the predictive potential of mobile-collected speech data for detecting and estimating depression, anxiety, fatigue, and insomnia, focusing on other factors than mere accuracy, in the general population. METHODS: We included 865 healthy adults and recorded their answers regarding their perceived mental and sleep states. We asked how they felt and if they had slept well lately. Clinically validated questionnaires measuring depression, anxiety, insomnia, and fatigue severity were also used. We developed a novel speech and machine learning pipeline involving voice activity detection, feature extraction, and model training. We automatically modeled speech with pretrained deep learning models that were pretrained on a large, open, and free database, and we selected the best one on the validation set. Based on the best speech modeling approach, clinical threshold detection, individual score prediction, model uncertainty estimation, and performance fairness across demographics (age, sex, and education) were evaluated. We used a train-validation-test split for all evaluations: to develop our models, select the best ones, and assess the generalizability of held-out data. RESULTS: The best model was Whisper M with a max pooling and oversampling method. Our methods achieved good detection performance for all symptoms, depression (Patient Health Questionnaire-9: area under the curve [AUC]=0.76; F1-score=0.49 and Beck Depression Inventory: AUC=0.78; F1-score=0.65), anxiety (Generalized Anxiety Disorder 7-item scale: AUC=0.77; F1-score=0.50), insomnia (Athens Insomnia Scale: AUC=0.73; F1-score=0.62), and fatigue (Multidimensional Fatigue Inventory total score: AUC=0.68; F1-score=0.88). The system performed well when it needed to abstain from making predictions, as demonstrated by low abstention rates in depression detection with the Beck Depression Inventory and fatigue, with risk-coverage AUCs below 0.4. Individual symptom scores were accurately predicted (correlations were all significant with Pearson strengths between 0.31 and 0.49). Fairness analysis revealed that models were consistent for sex (average disparity ratio [DR] 0.86, SD 0.13), to a lesser extent for education level (average DR 0.47, SD 0.30), and worse for age groups (average DR 0.33, SD 0.30). CONCLUSIONS: This study demonstrates the potential of speech-based systems for multifaceted mental health assessment in the general population, not only for detecting clinical thresholds but also for estimating their severity. Addressing fairness and incorporating uncertainty estimation with selective classification are key contributions that can enhance the clinical utility and responsible implementation of such systems.",
      "authors": "Riad Rachid; Denais Martin; de Gennes Marc; Lesage Adrien; Oustric Vincent; Cao Xuan Nga; Mouchabac St\u00e9phane; Bourla Alexis",
      "year": "2024",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/58572",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39324329/",
      "mesh_terms": "Humans; Adult; Male; Female; Sleep Initiation and Maintenance Disorders; Depression; Fatigue; Anxiety; Middle Aged; Algorithms; Speech; Surveys and Questionnaires; Young Adult",
      "keywords": "anxiety; computer-aided diagnosis; depression; fatigue; machine learning; mental health; mental health symptom detection; speech analysis; speech biomarkers; speech-based systems; voice analysis; voice detection",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC11565087"
    },
    {
      "pmid": "32246035",
      "title": "Classifying post-traumatic stress disorder using the magnetoencephalographic connectome and machine learning.",
      "abstract": "Given the subjective nature of conventional diagnostic methods for post-traumatic stress disorder (PTSD), an objectively measurable biomarker is highly desirable; especially to clinicians and researchers. Macroscopic neural circuits measured using magnetoencephalography (MEG) has previously been shown to be indicative of the PTSD phenotype and severity. In the present study, we employed a machine learning-based classification framework using MEG neural synchrony to distinguish combat-related PTSD from trauma-exposed controls. Support vector machine (SVM) was used as the core classification algorithm. A recursive random forest feature selection step was directly incorporated in the nested SVM cross validation process (CV-SVM-rRF-FS) for identifying the most important features for PTSD classification. For the five frequency bands tested, the CV-SVM-rRF-FS analysis selected the minimum numbers of edges per frequency that could serve as a PTSD signature and be used as the basis for SVM modelling. Many of the selected edges have been reported previously to be core in PTSD pathophysiology, with frequency-specific patterns also observed. Furthermore, the independent partial least squares discriminant analysis suggested low bias in the machine learning process. The final SVM models built with selected features showed excellent PTSD classification performance (area-under-curve value up to 0.9). Testament to its robustness when distinguishing individuals from a heavily traumatised control group, these developments for a classification model for PTSD also provide a comprehensive machine learning-based computational framework for classifying other mental health challenges using MEG connectome profiles.",
      "authors": "Zhang Jing; Richardson J Don; Dunkley Benjamin T",
      "year": "2020",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-020-62713-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32246035/",
      "mesh_terms": "Adult; Algorithms; Brain; Canada; Computational Biology; Connectome; Humans; Machine Learning; Magnetoencephalography; Male; Middle Aged; Stress Disorders, Post-Traumatic; Support Vector Machine; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7125168"
    },
    {
      "pmid": "39419495",
      "title": "Identifying Marijuana Use Behaviors Among Youth Experiencing Homelessness Using a Machine Learning-Based Framework: Development and Evaluation Study.",
      "abstract": "BACKGROUND: Youth experiencing homelessness face substance use problems disproportionately compared to other youth. A study found that 69% of youth experiencing homelessness meet the criteria for dependence on at least 1 substance, compared to 1.8% for all US adolescents. In addition, they experience major structural and social inequalities, which further undermine their ability to receive the care they need. OBJECTIVE: The goal of this study was to develop a machine learning-based framework that uses the social media content (posts and interactions) of youth experiencing homelessness to predict their substance use behaviors (ie, the probability of using marijuana). With this framework, social workers and care providers can identify and reach out to youth experiencing homelessness who are at a higher risk of substance use. METHODS: We recruited 133 young people experiencing homelessness at a nonprofit organization located in a city in the western United States. After obtaining their consent, we collected the participants' social media conversations for the past year before they were recruited, and we asked the participants to complete a survey on their demographic information, health conditions, sexual behaviors, and substance use behaviors. Building on the social sharing of emotions theory and social support theory, we identified important features that can potentially predict substance use. Then, we used natural language processing techniques to extract such features from social media conversations and reactions and built a series of machine learning models to predict participants' marijuana use. RESULTS: We evaluated our models based on their predictive performance as well as their conformity with measures of fairness. Without predictive features from survey information, which may introduce sex and racial biases, our machine learning models can reach an area under the curve of 0.72 and an accuracy of 0.81 using only social media data when predicting marijuana use. We also evaluated the false-positive rate for each sex and age segment. CONCLUSIONS: We showed that textual interactions among youth experiencing homelessness and their friends on social media can serve as a powerful resource to predict their substance use. The framework we developed allows care providers to allocate resources efficiently to youth experiencing homelessness in the greatest need while costing minimal overhead. It can be extended to analyze and predict other health-related behaviors and conditions observed in this vulnerable community.",
      "authors": "Deng Tianjie; Urbaczewski Andrew; Lee Young Jin; Barman-Adhikari Anamika; Dewri Rinku",
      "year": "2024",
      "journal": "JMIR AI",
      "doi": "10.2196/53488",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39419495/",
      "mesh_terms": "",
      "keywords": "digital intervention; infodemiology; machine learning; natural language processing; social good; youth experiencing homelessness",
      "pub_types": "Journal Article",
      "pmcid": "PMC11528171"
    },
    {
      "pmid": "35537195",
      "title": "Beware the Grizzlyman: A comparison of job- and industry-based noise exposure estimates using manual coding and the NIOSH NIOCCS machine learning algorithm.",
      "abstract": "Recently, the National Institute for Occupational Safety and Health (NIOSH) released an updated version of the NIOSH Industry and Occupation Computerized Coding System (NIOCCS), which uses supervised machine learning to assign industry and occupational codes based on provided free-text information. However, no efforts have been made to externally verify the quality of assigned industry and job titles when the algorithm is provided with inputs of varying quality. This study sought to evaluate whether the NIOCCS algorithm was sufficiently robust with low-quality inputs and how variable quality could impact subsequent job estimated exposures in a large job-exposure matrix for noise (NoiseJEM). Using free-text industry and job descriptions from >700,000 noise measurements in the NoiseJEM, three files were created and input into NIOCCS: (1) N1, \"raw\" industries and job titles; (2) N2, \"refined\" industries and \"raw\" job titles; and (3) N3, \"refined\" industries and job titles. Standardized industry and occupation codes were output by NIOCCS. Descriptive statistics of performance metrics (e.g., misclassification/discordance of occupation codes) were evaluated for each input relative to the original NoiseJEM dataset (N0). Across major Standardized Occupational Classifications (SOC), total discordance rates for N1, N2, and N3 compared to N0 were 53.6%, 42.3%, and 5.0%, respectively. The impact of discordance on the major SOC group varied and included both over- and under-estimates of average noise exposure compared to N0. N2 had the most accurate noise exposure estimates (i.e., smallest bias) across major SOC groups compared to N1 and N3. Further refinement of job titles in N3 showed little improvement. Some variation in classification efficacy was seen over time, particularly prior to 1985. Machine learning algorithms can systematically and consistently classify data but are highly dependent on the quality and amount of input data. The greatest benefit for an end-user may come from cleaning industry information before applying this method for job classification. Our results highlight the need for standardized classification methods that remain constant over time.",
      "authors": "Roberts Benjamin; Shkembi Abas; Smith Lauren M; Neitzel Richard L",
      "year": "2022",
      "journal": "Journal of occupational and environmental hygiene",
      "doi": "10.1080/15459624.2022.2076860",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35537195/",
      "mesh_terms": "Algorithms; Machine Learning; National Institute for Occupational Safety and Health, U.S.; Occupational Exposure; Occupations; United States",
      "keywords": "Big data; SOC; machine learning; noise",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32685596",
      "title": "Machine Learning for Precision Health Economics and Outcomes Research (P-HEOR): Conceptual Review of Applications and Next Steps.",
      "abstract": "Precision health economics and outcomes research (P-HEOR) integrates economic and clinical value assessment by explicitly discovering distinct clinical and health care utilization phenotypes among patients. Through a conceptualized example, the objective of this review is to highlight the capabilities and limitations of machine learning (ML) applications to P-HEOR and to contextualize the potential opportunities and challenges for the wide adoption of ML for health economics. We outline a P-HEOR conceptual framework extending the ML methodology to comparatively assess the economic value of treatment regimens. Latest methodology developments on bias and confounding control in ML applications to precision medicine are also summarized.",
      "authors": "Chen Yixi; Chirikov Viktor V; Marston Xiaocong L; Yang Jingang; Qiu Haibo; Xie Jianfeng; Sun Ning; Gu Chengming; Dong Peng; Gao Xin",
      "year": "2020",
      "journal": "Journal of health economics and outcomes research",
      "doi": "10.36469/jheor.2020.12698",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32685596/",
      "mesh_terms": "",
      "keywords": "cost-effectiveness; net monetary benefit; patient heterogeneity; random forest",
      "pub_types": "Journal Article",
      "pmcid": "PMC7299485"
    },
    {
      "pmid": "38738397",
      "title": "A fast bootstrap algorithm for causal inference with large data.",
      "abstract": "Estimating causal effects from large experimental and observational data has become increasingly prevalent in both industry and research. The bootstrap is an intuitive and powerful technique used to construct standard errors and confidence intervals of estimators. Its application however can be prohibitively demanding in settings involving large data. In addition, modern causal inference estimators based on machine learning and optimization techniques exacerbate the computational burden of the bootstrap. The bag of little bootstraps has been proposed in non-causal settings for large data but has not yet been applied to evaluate the properties of estimators of causal effects. In this article, we introduce a new bootstrap algorithm called causal bag of little bootstraps for causal inference with large data. The new algorithm significantly improves the computational efficiency of the traditional bootstrap while providing consistent estimates and desirable confidence interval coverage. We describe its properties, provide practical considerations, and evaluate the performance of the proposed algorithm in terms of bias, coverage of the true 95% confidence intervals, and computational time in a simulation study. We apply it in the evaluation of the effect of hormone therapy on the average time to coronary heart disease using a large observational data set from the Women's Health Initiative.",
      "authors": "Kosko Matthew; Wang Lin; Santacatterina Michele",
      "year": "2024",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.10075",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38738397/",
      "mesh_terms": "Algorithms; Humans; Causality; Computer Simulation; Female; Confidence Intervals; Coronary Disease; Models, Statistical; Data Interpretation, Statistical; Bias; Observational Studies as Topic",
      "keywords": "causal bootstrap; covariate balance; machine learning; propensity score; real\u2010world data",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "31743494",
      "title": "Detecting prolonged sitting bouts with the ActiGraph GT3X.",
      "abstract": "The ActiGraph has a high ability to measure physical activity; however, it lacks an accurate posture classification to measure sedentary behavior. The aim of the present study was to develop an ActiGraph (waist-worn, 30\u00a0Hz) posture classification to detect prolonged sitting bouts, and to compare the classification to proprietary ActiGraph data. The activPAL, a highly valid posture classification device, served as reference criterion. Both sensors were worn by 38 office workers over a median duration of 9\u00a0days. An automated feature selection extracted the relevant signal information for a minute-based posture classification. The machine learning algorithm with optimal feature number to predict the time in prolonged sitting bouts (\u22655 and \u226510\u00a0minutes) was searched and compared to the activPAL using Bland-Altman statistics. The comparison included optimized and frequently used cut-points (100 and 150 counts per minute (cpm), with and without low-frequency-extension (LFE) filtering). The new algorithm predicted the time in prolonged sitting bouts most accurate (bias\u00a0\u2264\u00a07\u00a0minutes/d). Of all proprietary ActiGraph methods, only 150\u00a0cpm without LFE predicted the time in prolonged sitting bouts non-significantly different from the activPAL (bias\u00a0\u2264\u00a018\u00a0minutes/d). However, the frequently used 100\u00a0cpm with LFE accurately predicted total sitting time (bias\u00a0\u2264\u00a07\u00a0minutes/d). To study the health effects of ActiGraph measured prolonged sitting, we recommend using the new algorithm. In case a cut-point is used, we recommend 150\u00a0cpm without LFE to measure prolonged sitting and 100\u00a0cpm with LFE to measure total sitting time. However, both cpm cut-points are not recommended for a detailed bout analysis.",
      "authors": "Kuster Roman P; Grooten Wilhelmus J A; Baumgartner Daniel; Blom Victoria; Hagstr\u00f6mer Maria; Ekblom \u00d6rjan",
      "year": "2020",
      "journal": "Scandinavian journal of medicine & science in sports",
      "doi": "10.1111/sms.13601",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31743494/",
      "mesh_terms": "Actigraphy; Adult; Algorithms; Female; Humans; Machine Learning; Male; Middle Aged; Sedentary Behavior; Sitting Position; Time",
      "keywords": "activPAL; automated feature selection; bout analysis; machine learning; posture prediction; sedentary behavior",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35210958",
      "title": "Artificial intelligence behind the scenes: PubMed's Best Match algorithm.",
      "abstract": "This article focuses on PubMed's Best Match sorting algorithm, presenting a simplified explanation of how it operates and highlighting how artificial intelligence affects search results in ways that are not seen by users. We further discuss user search behaviors and the ethical implications of algorithms, specifically for health care practitioners. PubMed recently began using artificial intelligence to improve the sorting of search results using a Best Match option. In 2020, PubMed deployed this algorithm as the default search method, necessitating serious discussion around the ethics of this and similar algorithms, as users do not always know when an algorithm uses artificial intelligence, what artificial intelligence is, and how it may impact their everyday tasks. These implications resonate strongly in health care, in which the speed and relevancy of search results is crucial but does not negate the importance of a lack of bias in how those search results are selected or presented to the user. As a health care provider will not often venture past the first few results in search of a clinical decision, will Best Match help them find the answers they need more quickly? Or will the algorithm bias their results, leading to the potential suppression of more recent or relevant results?",
      "authors": "Kiester Lucy; Turp Clara",
      "year": "2022",
      "journal": "Journal of the Medical Library Association : JMLA",
      "doi": "10.5195/jmla.2022.1236",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35210958/",
      "mesh_terms": "Algorithms; Artificial Intelligence; PubMed",
      "keywords": "Best Match; PubMed; artificial intelligence; information systems; information-seeking behavior",
      "pub_types": "Journal Article",
      "pmcid": "PMC8830327"
    },
    {
      "pmid": "39311424",
      "title": "New horizons in prediction modelling using machine learning in older people's healthcare research.",
      "abstract": "Machine learning (ML) and prediction modelling have become increasingly influential in healthcare, providing critical insights and supporting clinical decisions, particularly in the age of big data. This paper serves as an introductory guide for health researchers and readers interested in prediction modelling and explores how these technologies support clinical decisions, particularly with big data, and covers all aspects of the development, assessment and reporting of a model using ML. The paper starts with the importance of prediction modelling for precision medicine. It outlines different types of prediction and machine learning approaches, including supervised, unsupervised and semi-supervised learning, and provides an overview of popular algorithms for various outcomes and settings. It also introduces key theoretical ML concepts. The importance of data quality, preprocessing and unbiased model performance evaluation is highlighted. Concepts of apparent, internal and external validation will be introduced along with metrics for discrimination and calibration for different types of outcomes. Additionally, the paper addresses model interpretation, fairness and implementation in clinical practice. Finally, the paper provides recommendations for reporting and identifies common pitfalls in prediction modelling and machine learning. The aim of the paper is to help readers understand and critically evaluate research papers that present ML models and to serve as a first guide for developing, assessing and implementing their own.",
      "authors": "Stahl Daniel",
      "year": "2024",
      "journal": "Age and ageing",
      "doi": "10.1093/ageing/afae201",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39311424/",
      "mesh_terms": "Aged; Humans; Big Data; Health Services Research; Machine Learning; Precision Medicine",
      "keywords": "machine learning; older people; precision medicine; prediction modelling",
      "pub_types": "Journal Article",
      "pmcid": "PMC11417961"
    },
    {
      "pmid": "40214105",
      "title": "Machine learning for prediction of childhood mental health problems in social care.",
      "abstract": "BACKGROUND: Rates of childhood mental health problems are increasing in the UK. Early identification of childhood mental health problems is challenging but critical to children's future psychosocial development. This is particularly important for children with social care contact because earlier identification can facilitate earlier intervention. Clinical prediction tools could improve these early intervention efforts. AIMS: Characterise a novel cohort consisting of children in social care and develop effective machine learning models for prediction of childhood mental health problems. METHOD: We used linked, de-identified data from the Secure Anonymised Information Linkage Databank to create a cohort of 26 820 children in Wales, UK, receiving social care services. Integrating health, social care and education data, we developed several machine learning models aimed at predicting childhood mental health problems. We assessed the performance, interpretability and fairness of these models. RESULTS: Risk factors strongly associated with childhood mental health problems included age, substance misuse and being a looked after child. The best-performing model, a gradient boosting classifier, achieved an area under the receiver operating characteristic curve of 0.75 (95% CI 0.73-0.78). Assessments of algorithmic fairness showed potential biases within these models. CONCLUSIONS: Machine learning performance on this prediction task was promising. Predictive performance in social care settings can be bolstered by linking diverse routinely collected data-sets, making available a range of heterogenous risk factors relating to clinical, social and environmental exposures.",
      "authors": "Crowley Ryan; Parkin Katherine; Rocheteau Emma; Massou Efthalia; Friedmann Yasmin; John Ann; Sippy Rachel; Li\u00f2 Pietro; Moore Anna",
      "year": "2025",
      "journal": "BJPsych open",
      "doi": "10.1192/bjo.2025.32",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40214105/",
      "mesh_terms": "",
      "keywords": "Mental health services; community mental health teams; machine learning methods; medical technology; precision medicine",
      "pub_types": "Journal Article",
      "pmcid": "PMC12052593"
    },
    {
      "pmid": "35393726",
      "title": "Prediction of femoral strength of elderly men based on quantitative computed tomography images using machine learning.",
      "abstract": "Hip fracture is the most common complication of osteoporosis, and its major contributor is compromised femoral strength. This study aimed to develop practical machine learning models based on clinical quantitative computed tomography (QCT) images for predicting proximal femoral strength. Eighty subjects with entire QCT data of the right hip region were randomly selected from the full MrOS cohorts, and their proximal femoral strengths were calculated by QCT-based finite element analysis (QCT/FEA). A total of 50 parameters of each femur were extracted from QCT images as the candidate predictors of femoral strength, including grayscale distribution, regional cortical bone mapping (CBM) measurements, and geometric parameters. These parameters were simplified by using feature selection and dimensionality reduction. Support vector regression (SVR) was used as the machine learning algorithm to develop the prediction models, and the performance of each SVR model was quantified by the mean squared error (MSE), the coefficient of determination (R2 ), the mean bias, and the SD of bias. For feature selection, the best prediction performance of SVR models was achieved by integrating the grayscale value of 30% percentile and specific regional CBM measurements (MSE\u2009\u2264\u20090.016, R2 \u2265\u20090.93); and for dimensionality reduction, the best prediction performance of SVR models was achieved by extracting principal components with eigenvalues greater than 1.0 (MSE\u2009\u2264\u20090.014, R2 \u2265\u20090.93). The femoral strengths predicted from the well-trained SVR models were in good agreement with those derived from QCT/FEA. This study provided effective machine learning models for femoral strength prediction, and they may have great potential in clinical bone health assessments.",
      "authors": "Zhang Meng; Gong He; Zhang Ming",
      "year": "2023",
      "journal": "Journal of orthopaedic research : official publication of the Orthopaedic Research Society",
      "doi": "10.1002/jor.25334",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35393726/",
      "mesh_terms": "Humans; Aged; Machine Learning; Tomography",
      "keywords": "QCT; bone strength prediction; finite element analysis; machine learning; proximal femur",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "35493616",
      "title": "Integrated Evolutionary Learning: An Artificial Intelligence Approach to Joint Learning of Features and Hyperparameters for Optimized, Explainable Machine Learning.",
      "abstract": "Artificial intelligence and machine learning techniques have proved fertile methods for attacking difficult problems in medicine and public health. These techniques have garnered strong interest for the analysis of the large, multi-domain open science datasets that are increasingly available in health research. Discovery science in large datasets is challenging given the unconstrained nature of the learning environment where there may be a large number of potential predictors and appropriate ranges for model hyperparameters are unknown. As well, it is likely that explainability is at a premium in order to engage in future hypothesis generation or analysis. Here, we present a novel method that addresses these challenges by exploiting evolutionary algorithms to optimize machine learning discovery science while exploring a large solution space and minimizing bias. We demonstrate that our approach, called integrated evolutionary learning (IEL), provides an automated, adaptive method for jointly learning features and hyperparameters while furnishing explainable models where the original features used to make predictions may be obtained even with artificial neural networks. In IEL the machine learning algorithm of choice is nested inside an evolutionary algorithm which selects features and hyperparameters over generations on the basis of an information function to converge on an optimal solution. We apply IEL to three gold standard machine learning algorithms in challenging, heterogenous biobehavioral data: deep learning with artificial neural networks, decision tree-based techniques and baseline linear models. Using our novel IEL approach, artificial neural networks achieved \u2265 95% accuracy, sensitivity and specificity and 45-73% R 2 in classification and substantial gains over default settings. IEL may be applied to a wide range of less- or unconstrained discovery science problems where the practitioner wishes to jointly learn features and hyperparameters in an adaptive, principled manner within the same algorithmic process. This approach offers significant flexibility, enlarges the solution space and mitigates bias that may arise from manual or semi-manual hyperparameter tuning and feature selection and presents the opportunity to select the inner machine learning algorithm based on the results of optimized learning for the problem at hand.",
      "authors": "de Lacy Nina; Ramshaw Michael J; Kutz J Nathan",
      "year": "2022",
      "journal": "Frontiers in artificial intelligence",
      "doi": "10.3389/frai.2022.832530",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35493616/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; automated; deep learning; explainability; feature selection; hyperparameter tuning; machine learning; optimization",
      "pub_types": "Journal Article",
      "pmcid": "PMC9038845"
    },
    {
      "pmid": "39004110",
      "title": "Leveraging error-prone algorithm-derived phenotypes: Enhancing association studies for risk factors in EHR data.",
      "abstract": "OBJECTIVES: It has become increasingly common for multiple computable phenotypes from electronic health records (EHR) to be developed for a given phenotype. However, EHR-based association studies often focus on a single phenotype. In this paper, we develop a method aiming to simultaneously make use of multiple EHR-derived phenotypes for reduction of bias due to phenotyping error and improved efficiency of phenotype/exposure associations. MATERIALS AND METHODS: The proposed method combines multiple algorithm-derived phenotypes with a small set of validated outcomes to reduce bias and improve estimation accuracy and efficiency. The performance of our method was evaluated through simulation studies and real-world application to an analysis of colon cancer recurrence using EHR data from Kaiser Permanente Washington. RESULTS: In settings where there was no single surrogate performing uniformly better than all others in terms of both sensitivity and specificity, our method achieved substantial bias reduction compared to using a single algorithm-derived phenotype. Our method also led to higher estimation efficiency by up to 30% compared to an estimator that used only one algorithm-derived phenotype. DISCUSSION: Simulation studies and application to real-world data demonstrated the effectiveness of our method in integrating multiple phenotypes, thereby enhancing bias reduction, statistical accuracy and efficiency. CONCLUSIONS: Our method combines information across multiple surrogates using a statistically efficient seemingly unrelated regression framework. Our method provides a robust alternative to single-surrogate-based bias correction, especially in contexts lacking information on which surrogate is superior.",
      "authors": "Lu Yiwen; Tong Jiayi; Chubak Jessica; Lumley Thomas; Hubbard Rebecca A; Xu Hua; Chen Yong",
      "year": "2024",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2024.104690",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39004110/",
      "mesh_terms": "Electronic Health Records; Algorithms; Humans; Phenotype; Risk Factors; Computer Simulation; Colonic Neoplasms; Bias",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC12235754"
    },
    {
      "pmid": "35067382",
      "title": "A comparative analysis of machine learning approaches to predict C. difficile infection in hospitalized patients.",
      "abstract": "BACKGROUND: Interventions to better prevent or manage Clostridioides difficile infection (CDI) may significantly reduce morbidity, mortality, and healthcare spending. METHODS: We present a retrospective study using electronic health record data from over 700 United States hospitals. A subset of hospitals was used to develop machine learning algorithms (MLAs); the remaining hospitals served as an external test set. Three MLAs were evaluated: gradient-boosted decision trees (XGBoost), Deep Long Short Term Memory neural network, and one-dimensional convolutional neural network. MLA performance was evaluated with area under the receiver operating characteristic curve (AUROC), sensitivity, specificity, diagnostic odds ratios and likelihood ratios. RESULTS: The development dataset contained 13,664,840 inpatient encounters with 80,046 CDI encounters; the external dataset contained 1,149,088 inpatient encounters with 7,107 CDI encounters. The highest AUROCs were achieved for XGB, Deep Long Short Term Memory neural network, and one-dimensional convolutional neural network via abstaining from use of specialized training techniques, resampling in isolation, and resampling and output bias in combination, respectively. XGBoost achieved the highest AUROC. CONCLUSIONS: MLAs can predict future CDI in hospitalized patients using just 6 hours of data. In clinical practice, a machine-learning based tool may support prophylactic measures, earlier diagnosis, and more timely implementation of infection control measures.",
      "authors": "Panchavati Saarang; Zelin Nicole S; Garikipati Anurag; Pellegrini Emily; Iqbal Zohora; Barnes Gina; Hoffman Jana; Calvert Jacob; Mao Qingqing; Das Ritankar",
      "year": "2022",
      "journal": "American journal of infection control",
      "doi": "10.1016/j.ajic.2021.11.012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35067382/",
      "mesh_terms": "Clostridioides difficile; Clostridium Infections; Humans; Machine Learning; ROC Curve; Retrospective Studies",
      "keywords": "Algorithm; CDI; Clostridioides difficile; Electronic health record; Machine learning; Prediction; XGBoost",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34312570",
      "title": "A Unified Hierarchical XGBoost model for classifying priorities for COVID-19 vaccination campaign.",
      "abstract": "The current ML approaches do not fully focus to answer a still unresolved and topical challenge, namely the prediction of priorities of COVID-19 vaccine administration. Thus, our task includes some additional methodological challenges mainly related to avoiding unwanted bias while handling categorical and ordinal data with a highly imbalanced nature. Hence, the main contribution of this study is to propose a machine learning algorithm, namely Hierarchical Priority Classification eXtreme Gradient Boosting for priority classification for COVID-19 vaccine administration using the Italian Federation of General Practitioners dataset that contains Electronic Health Record data of 17k patients. We measured the effectiveness of the proposed methodology for classifying all the priority classes while demonstrating a significant improvement with respect to the state of the art. The proposed ML approach, which is integrated into a clinical decision support system, is currently supporting General Pracitioners in assigning COVID-19 vaccine administration priorities to their assistants.",
      "authors": "Romeo Luca; Frontoni Emanuele",
      "year": "2022",
      "journal": "Pattern recognition",
      "doi": "10.1016/j.patcog.2021.108197",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34312570/",
      "mesh_terms": "",
      "keywords": "COVID-19; Clinical decision support system; Machine learning; Model interpretability; Vaccination; XGBoost",
      "pub_types": "Journal Article",
      "pmcid": "PMC8295058"
    },
    {
      "pmid": "40913935",
      "title": "Machine learning for novel phenotyping in schizophrenia.",
      "abstract": "PURPOSE: Heterogeneity among people diagnosed with schizophrenia-spectrum disorders (schizophrenia) and high prevalence of co-occurring disorders makes identification of optimal treatments difficult. This study identified behavioral health phenotypes using machine learning with Medicaid claims of adults with schizophrenia. We compared the phenotypes' clinical outcomes and psychotropic medication prescription patterns for clinical validity. METHODS: Using national Medicaid claims from January 2010 - December 2012 we identified 249,006 adults ages 18-64, with \u2265 1 inpatient and/or\u00a0\u2265\u00a02 outpatient claims with principal or secondary diagnoses of schizophrenia (ICD9 295.xx) in 2010. Latent Dirichlet Allocation (LDA) incorporated their behavioral health co-occurring disorders in 2010 to identify behavioral health phenotypes, validated using 5-fold cross validation. Pairwise comparisons among each phenotype of psychotropic medication types, and likelihoods of any behavioral health inpatient admission or emergency department (ED) visit in 2011 were conducted. RESULTS: LDA with 5-fold cross validation identified 5 behavioral health phenotypes we labeled depression, substance use, mania-mixed mood, anxiety-paranoid, and conduct disorder-developmentally delayed; a sixth phenotype had no co-occurring disorders. Likelihoods of behavioral health inpatient admissions and ED visits were significantly different between the phenotypes. Psychotropic medications prescribed to the phenotypes were distinct. Post-hoc analyses using the same methods with 2017 Medicaid claims of 383,849 adults identified comparable phenotypes. CONCLUSIONS: This study demonstrated the feasibility of using machine learning with claims data to identify behavioral health phenotypes among individuals with schizophrenia. Future pharmacoepidemiologic investigations addressing confounding bias will compare effectiveness of treatments for each phenotype, informing efforts to identify personalized treatments for people with schizophrenia.",
      "authors": "Bareis Natalie; Wang Yuanjia; Olfson Mark; Gerhard Tobias; Dixon Lisa; Stroup T Scott",
      "year": "2025",
      "journal": "Schizophrenia research",
      "doi": "10.1016/j.schres.2025.08.011",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40913935/",
      "mesh_terms": "Humans; Schizophrenia; Machine Learning; Adult; Male; Female; Phenotype; Middle Aged; United States; Young Adult; Adolescent; Medicaid; Comorbidity; Psychotropic Drugs",
      "keywords": "Administrative data; Behavioral health co-occurring disorders; Epidemiology; Machine learning; Psychotropic medications; Schizophrenia",
      "pub_types": "Journal Article",
      "pmcid": "PMC12619572"
    },
    {
      "pmid": "33208538",
      "title": "Methods for correcting inference based on outcomes predicted by machine learning.",
      "abstract": "Many modern problems in medicine and public health leverage machine-learning methods to predict outcomes based on observable covariates. In a wide array of settings, predicted outcomes are used in subsequent statistical analysis, often without accounting for the distinction between observed and predicted outcomes. We call inference with predicted outcomes postprediction inference. In this paper, we develop methods for correcting statistical inference using outcomes predicted with arbitrarily complicated machine-learning models including random forests and deep neural nets. Rather than trying to derive the correction from first principles for each machine-learning algorithm, we observe that there is typically a low-dimensional and easily modeled representation of the relationship between the observed and predicted outcomes. We build an approach for postprediction inference that naturally fits into the standard machine-learning framework where the data are divided into training, testing, and validation sets. We train the prediction model in the training set, estimate the relationship between the observed and predicted outcomes in the testing set, and use that relationship to correct subsequent inference in the validation set. We show our postprediction inference (postpi) approach can correct bias and improve variance estimation and subsequent statistical inference with predicted outcomes. To show the broad range of applicability of our approach, we show postpi can improve inference in two distinct fields: modeling predicted phenotypes in repurposed gene expression data and modeling predicted causes of death in verbal autopsy data. Our method is available through an open-source R package: https://github.com/leekgroup/postpi.",
      "authors": "Wang Siruo; McCormick Tyler H; Leek Jeffrey T",
      "year": "2020",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "doi": "10.1073/pnas.2001238117",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33208538/",
      "mesh_terms": "Cause of Death; Computer Simulation; Humans; Machine Learning; Organ Specificity",
      "keywords": "interpretability; machine learning; postprediction inference; statistics",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC7720220"
    },
    {
      "pmid": "31220274",
      "title": "Applying machine learning to predict real-world individual treatment effects: insights from a virtual patient cohort.",
      "abstract": "OBJECTIVE: We aimed to investigate bias in applying machine learning to predict real-world individual treatment effects. MATERIALS AND METHODS: Using a virtual patient cohort, we simulated real-world healthcare data and applied random forest and gradient boosting classifiers to develop prediction models. Treatment effect was estimated as the difference between the predicted outcomes of a treatment and a control. We evaluated the impact of predictors (ie, treatment predictors [X1], confounders [X2], treatment effects modifiers [X3], and other outcome risk factors [X4]) with known effects on treatment and outcome using real-world data, and outcome imbalance on predicting individual outcome. Using counterfactuals, we evaluated percentage of patients with biased predicted individual treatment effects. RESULTS: The X4 had relatively more impact on model performance than X2 and X3 did. No effects were observed from X1. Moderate-to-severe outcome imbalance had a significantly negative impact on model performance, particularly among subgroups in which an outcome occurred. Bias in predicting individual treatment effects was significant and persisted even when the models had a 100% accuracy in predicting health outcome. DISCUSSION: Inadequate inclusion of the X2, X3, and X4 and moderate-to-severe outcome imbalance may affect model performance in predicting individual outcome and subsequently bias in predicting individual treatment effects. Machine learning models with all features and high performance for predicting individual outcome still yielded biased individual treatment effects. CONCLUSIONS: Direct application of machine learning might not adequately address bias in predicting individual treatment effects. Further method development is needed to advance machine learning to support individualized treatment selection.",
      "authors": "Fang Gang; Annis Izabela E; Elston-Lafata Jennifer; Cykert Samuel",
      "year": "2019",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocz036",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31220274/",
      "mesh_terms": "Cohort Studies; Computer Simulation; Humans; Machine Learning; Outcome and Process Assessment, Health Care; Precision Medicine; Prognosis; Treatment Outcome",
      "keywords": "comparative treatment effectiveness; machine learning; precision medicine; real-world evidence; virtual patient cohort",
      "pub_types": "Journal Article",
      "pmcid": "PMC7647181"
    },
    {
      "pmid": "38158050",
      "title": "Predicting adolescent suicidal behavior following inpatient discharge using structured and unstructured data.",
      "abstract": "BACKGROUND: The objective was to develop and assess performance of an algorithm predicting suicide-related ICD codes within three months of psychiatric discharge. METHODS: This prognostic study used a retrospective cohort of EHR data from 2789 youth (12 to 20\u00a0years old) hospitalized in a safety net institution in the Northeastern United States. The dataset combined structured data with unstructured data obtained through natural language processing of clinical notes. Machine learning approaches compared gradient boosting to random forest analyses. RESULTS: Area under the ROC and precision-recall curve were 0.88 and 0.17, respectively, for the final Gradient Boosting model. The cutoff point of the model-generated predicted probabilities of suicide that optimally classified the individual as high risk or not was 0.009. When applying the chosen cutoff (0.009) to the hold-out testing set, the model correctly identified 8 positive cases out of 10, and 418 negative cases out 548. The corresponding performance metrics showed 80\u00a0% sensitivity, 76\u00a0% specificity, 6\u00a0% PPV, 99\u00a0% NPV, F-1 score of 0.11, and an accuracy of 76\u00a0%. LIMITATIONS: The data in this study comes from a single health system, possibly introducing bias in the model's algorithm. Thus, the model may have underestimated the incidence of suicidal behavior in the study population. Further research should include multiple system EHRs. CONCLUSIONS: These performance metrics suggest a benefit to including both unstructured and structured data in design of predictive algorithms for suicidal behavior, which can be integrated into psychiatric services to help assess risk.",
      "authors": "Carson Nicholas J; Yang Xinyu; Mullin Brian; Stettenbauer Elizabeth; Waddington Marin; Zhang Alice; Williams Peyton; Rios Perez Gabriel E; Cook Benjamin L\u00ea",
      "year": "2024",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2023.12.059",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38158050/",
      "mesh_terms": "Adolescent; Child; Humans; Young Adult; Algorithms; Inpatients; Patient Discharge; Retrospective Studies; Suicidal Ideation",
      "keywords": "Adolescence; Electronic health records; Machine learning; Patient discharge; Risk; Suicide",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10923087"
    },
    {
      "pmid": "41214757",
      "title": "Predicting workplace absenteeism using machine learning: a pilot study in occupational health.",
      "abstract": "BACKGROUND: Workplace absenteeism represents a significant challenge for organizations and occupational health practitioners, with substantial implications for productivity, healthcare costs, and employee well-being. Traditional approaches to absenteeism management remain largely reactive, highlighting the need for predictive models that enable proactive interventions. OBJECTIVE: To develop and validate machine learning models for predicting workplace absenteeism patterns and identifying risk factors associated with prolonged absence in a pilot study framework, thereby demonstrating feasibility for evidence-based occupational health interventions. METHODS: This pilot study employed machine learning algorithms on a publicly available workplace absenteeism dataset from a Brazilian company (2007-2010) obtained from the UCI Machine Learning Repository. The dataset comprised 740 instances with 19 variables including demographic characteristics, clinical indicators (BMI, ICD-10 coded absence reasons), and occupational factors. Random Forest and Gradient Boosting algorithms were implemented for both classification of prolonged absences and regression of absence duration. Statistical outliers (>\u200930\u00a0h, 3.8% of cases) were excluded to focus on typical absence patterns. RESULTS: The developed models demonstrated feasibility for workplace absenteeism prediction within this pilot framework. The Random Forest classification model achieved 84% accuracy (AUC\u2009=\u20090.89) for distinguishing between typical and prolonged absences. For duration prediction of typical absences (\u2264\u200930\u00a0h), the Random Forest regression model yielded R\u00b2 = 0.13, RMSE\u2009=\u20093.93\u00a0h, and MAE\u2009=\u20092.37\u00a0h. Key predictors included absence reason (ICD-10 classification), body mass index, and workload metrics, with notable interactions between workload intensity and specific absence categories. CONCLUSIONS: This pilot study demonstrates the feasibility of machine learning approaches for occupational health management by enabling identification of employees at risk for prolonged absenteeism. While showing promise for supporting personalized health interventions and resource allocation, implementation requires external validation across multiple organizations and careful consideration of ethical implications regarding employee privacy and algorithmic fairness.",
      "authors": "Llamas Bl\u00e1zquez Pablo",
      "year": "2025",
      "journal": "Journal of occupational medicine and toxicology (London, England)",
      "doi": "10.1186/s12995-025-00482-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41214757/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Machine learning; Occupational health; Pilot study; Predictive modelling; Risk assessment; Workplace absenteeism",
      "pub_types": "Journal Article",
      "pmcid": "PMC12604190"
    },
    {
      "pmid": "39154983",
      "title": "Trajectory on postpartum depression of Chinese women and the risk prediction models: A machine-learning based three-wave follow-up research.",
      "abstract": "BACKGROUND: Our study delves into postpartum depression (PPD) extending observation up to six months postpartum, addressing the gap in long-term follow-ups and uncover critical intervention points. METHOD: Through a continuous three-wave cohort study involving 3174 of 10,730 invited postpartum women, we utilized machine learning to predict PPD risk, incorporating self-reported surveys and health records from October 2021 to Jan 2023. RESULTS: PPD prevalence slightly decreased from 30.9\u00a0% to 29.1\u00a0% over six months. The Random Forest model emerged as the most effective, identifying key predictors of PPD at different stages. The top three factors at first month were newborn's birth weight, maternal weight before delivery and before pregnancy. The EPDS scores of last time, newborn's birth weight and maternal weight before pregnancy and before delivery were main predictors for EPDS scores at third and sixth months postpartum. LIMITATION: The study faces limitations such as potential selection bias due to the convenience sampling method and the reliance on self-reported measures, which may introduce reporting bias. Furthermore, the high attrition rate could affect the representativeness of the sample and the generalizability of the findings. CONCLUSION: There is a slight decrease in PPD rates over six months, yet the prevalence remains high. This underscores the need for early and ongoing mental health support for new mothers. Our study highlights the efficacy of machine learning in enhancing PPD risk assessment and tailoring intervention strategies, paving the way for more personalized healthcare approaches in postpartum care.",
      "authors": "Wang Yu; Yan Ping; Wang Guan; Liu Yi; Xiang Jie; Song Yujia; Wei Lin; Chen Peng; Ren Jianhua",
      "year": "2024",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2024.08.074",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39154983/",
      "mesh_terms": "Humans; Depression, Postpartum; Female; Machine Learning; Adult; China; Follow-Up Studies; Pregnancy; Risk Factors; Prevalence; Cohort Studies; Young Adult; East Asian People",
      "keywords": "Machine-learning; Postpartum depression; Prediction models; Three-wave follow-up",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34268553",
      "title": "Demystifying Statistical Inference When Using Machine Learning in Causal Research.",
      "abstract": "In this issue, Naimi et al. (Am J Epidemiol. XXXX;XXX(XX):XXXX-XXXX) discuss a critical topic in public health and beyond: obtaining valid statistical inference when using machine learning in causal research. In doing so, the authors review recent prominent methodological work and recommend: (i) double robust estimators, such as targeted maximum likelihood estimation (TMLE); (ii) ensemble methods, such as Super Learner, to combine predictions from a diverse library of algorithms, and (iii) sample-splitting to reduce bias and improve inference. We largely agree with these recommendations. In this commentary, we highlight the critical importance of the Super Learner library. Specifically, in both simulation settings considered by the authors, we demonstrate that low bias and valid statistical inference can be achieved using TMLE without sample-splitting and with a Super Learner library that excludes tree-based methods but includes regression splines. Whether extremely data-adaptive algorithms and sample-splitting are needed depends on the specific problem and should be informed by simulations reflecting the specific application. More research is needed on practical recommendations for selecting among these options in common situations arising in epidemiology.",
      "authors": "Balzer Laura B; Westling Ted",
      "year": "2021",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwab200",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34268553/",
      "mesh_terms": "",
      "keywords": "Causal inference; Super Learner; TMLE; cross-fitting; cross-validation; double robust; machine learning; non-parametric",
      "pub_types": "Journal Article",
      "pmcid": "PMC10472326"
    },
    {
      "pmid": "29166301",
      "title": "Can We Train Machine Learning Methods to Outperform the High-dimensional Propensity Score Algorithm?",
      "abstract": "The use of retrospective health care claims datasets is frequently criticized for the lack of complete information on potential confounders. Utilizing patient's health status-related information from claims datasets as surrogates or proxies for mismeasured and unobserved confounders, the high-dimensional propensity score algorithm enables us to reduce bias. Using a previously published cohort study of postmyocardial infarction statin use (1998-2012), we compare the performance of the algorithm with a number of popular machine learning approaches for confounder selection in high-dimensional covariate spaces: random forest, least absolute shrinkage and selection operator, and elastic net. Our results suggest that, when the data analysis is done with epidemiologic principles in mind, machine learning methods perform as well as the high-dimensional propensity score algorithm. Using a plasmode framework that mimicked the empirical data, we also showed that a hybrid of machine learning and high-dimensional propensity score algorithms generally perform slightly better than both in terms of mean squared error, when a bias-based analysis is used.",
      "authors": "Karim Mohammad Ehsanul; Pang Menglan; Platt Robert W",
      "year": "2018",
      "journal": "Epidemiology (Cambridge, Mass.)",
      "doi": "10.1097/EDE.0000000000000787",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29166301/",
      "mesh_terms": "Algorithms; Data Accuracy; Datasets as Topic; Empirical Research; Machine Learning; Propensity Score; Retrospective Studies; United Kingdom",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37222862",
      "title": "Interpersonal Well-Being and Suicidal Outcomes in a Nationally Representative Study of Adolescents: A Translational Study.",
      "abstract": "Adolescent suicide continues to rise despite burgeoning research on interpersonal risk for suicide. This may reflect challenges in applying developmental psychopathology research into clinical settings. In response, the present study used a translational analytic plan to examine indices of social well-being most accurate and statistically fair for indexing adolescent suicide. Data from the National Comorbidity Survey Replication Adolescent Supplement were used. Adolescents aged 13-17 (N\u2009=\u20099,900) completed surveys on traumatic events, current relationships, and suicidal thoughts and attempts. Both frequentist (e.g., receiver operating characteristics) and Bayesian (e.g., Diagnostic Likelihood Ratios; DLRs) techniques provided insight into classification, calibration, and statistical fairness. Final algorithms were compared to a machine learning-informed algorithm. Overall, parental care and family cohesion best classified suicidal ideation, while these indices and school engagement best classified attempts. Multi-indicator algorithms suggested adolescents at high risk across these indices were approximately 3-times more likely to engage in ideation (DLR\u2009=\u20093.26) and 5-times more likely to engage in attempts (DLR\u2009=\u20094.53). Although equitable for attempts, models for ideation underperformed in non-White adolescents. Supplemental, machine learning-informed algorithms performed similarly, suggesting non-linear and interactive effects did not improve model performance. Future directions for interpersonal theories for suicide are discussed and clinical implications for suicide screening are demonstrated.",
      "authors": "Cohen Joseph R; Stutts Morgan",
      "year": "2023",
      "journal": "Research on child and adolescent psychopathology",
      "doi": "10.1007/s10802-023-01068-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37222862/",
      "mesh_terms": "Humans; Adolescent; Suicidal Ideation; Suicide, Attempted; Bayes Theorem; Suicide; Surveys and Questionnaires",
      "keywords": "Adolescence; Evidence-Based Medicine; Health disparities; Risk prediction; Suicide",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "5730496"
    },
    {
      "pmid": "39444417",
      "title": "Implementation of a Machine Learning Risk Prediction Model for Postpartum Depression in the Electronic Health Records.",
      "abstract": "This study describes the deployment process of an AI-driven clinical decision support (CDS) system to support postpartum depression (PPD) prevention, diagnosis and management. Central to this CDS is an L2-regularized logistic regression model trained on electronic health record (EHR) data at an academic medical center, and subsequently refined through a broader dataset from a consortium to ensure its generalizability and fairness. The deployment architecture leveraged Microsoft Azure to facilitate a scalable, secure, and efficient operational framework. We used Fast Healthcare Interoperability Resources (FHIR) for data extraction and ingestion between the two systems. Continuous Integration/Continuous Deployment pipelines automated the deployment and ongoing maintenance, ensuring the system's adaptability to evolving clinical data. Along the technical preparation, we focused on a seamless integration of the CDS within the clinical workflow, presenting risk assessment directly within the clinician schedule and providing options for subsequent actions. The developed CDS is expected to drive a PPD clinical pathway to enable efficient PPD risk management.",
      "authors": "Zhang Yiye; Joly Rochelle; Beecy Ashley N; Principe Samen; Satpathy Sujit; Gore Anatoly; Reilly Tom; Lang Mitchel; Sathi Nagi; Uy Carlos; Adams Matt; Israel Mark",
      "year": "2024",
      "journal": "AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39444417/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11497630"
    },
    {
      "pmid": "34319252",
      "title": "Ethical Development of Digital Phenotyping Tools for Mental Health Applications: Delphi Study.",
      "abstract": "BACKGROUND: Digital phenotyping (also known as personal sensing, intelligent sensing, or body computing) involves the collection of biometric and personal data in situ from digital devices, such as smartphones, wearables, or social media, to measure behavior or other health indicators. The collected data are analyzed to generate moment-by-moment quantification of a person's mental state and potentially predict future mental states. Digital phenotyping projects incorporate data from multiple sources, such as electronic health records, biometric scans, or genetic testing. As digital phenotyping tools can be used to study and predict behavior, they are of increasing interest for a range of consumer, government, and health care applications. In clinical care, digital phenotyping is expected to improve mental health diagnoses and treatment. At the same time, mental health applications of digital phenotyping present significant areas of ethical concern, particularly in terms of privacy and data protection, consent, bias, and accountability. OBJECTIVE: This study aims to develop consensus statements regarding key areas of ethical guidance for mental health applications of digital phenotyping in the United States. METHODS: We used a modified Delphi technique to identify the emerging ethical challenges posed by digital phenotyping for mental health applications and to formulate guidance for addressing these challenges. Experts in digital phenotyping, data science, mental health, law, and ethics participated as panelists in the study. The panel arrived at consensus recommendations through an iterative process involving interviews and surveys. The panelists focused primarily on clinical applications for digital phenotyping for mental health but also included recommendations regarding transparency and data protection to address potential areas of misuse of digital phenotyping data outside of the health care domain. RESULTS: The findings of this study showed strong agreement related to these ethical issues in the development of mental health applications of digital phenotyping: privacy, transparency, consent, accountability, and fairness. Consensus regarding the recommendation statements was strongest when the guidance was stated broadly enough to accommodate a range of potential applications. The privacy and data protection issues that the Delphi participants found particularly critical to address related to the perceived inadequacies of current regulations and frameworks for protecting sensitive personal information and the potential for sale and analysis of personal data outside of health systems. CONCLUSIONS: The Delphi study found agreement on a number of ethical issues to prioritize in the development of digital phenotyping for mental health applications. The Delphi consensus statements identified general recommendations and principles regarding the ethical application of digital phenotyping to mental health. As digital phenotyping for mental health is implemented in clinical care, there remains a need for empirical research and consultation with relevant stakeholders to further understand and address relevant ethical issues.",
      "authors": "Martinez-Martin Nicole; Greely Henry T; Cho Mildred K",
      "year": "2021",
      "journal": "JMIR mHealth and uHealth",
      "doi": "10.2196/27343",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34319252/",
      "mesh_terms": "Delphi Technique; Electronic Health Records; Humans; Mental Health; Privacy; Smartphone; United States",
      "keywords": "Delphi study; artificial intelligence; digital mental health; digital phenotyping; ethics; machine learning; mental health; mobile phone; neuroethics",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8367187"
    },
    {
      "pmid": "39845566",
      "title": "Discovering topics and trends in biosecurity law research: A machine learning approach.",
      "abstract": "This study employed machine learning techniques, specifically Latent Dirichlet Allocation (LDA), to analyze 559 articles on biosecurity legislation from 1996 to 2023. The LDA model identified nine key research topics, including Agricultural Management and Production, Biosafety and Environmental Impact, Biological Invasion and Regulation, Biosecurity Legislation and Prevention, Agriculture and Environmental Relations, Virus Infection and Governance, Health Risk Assessment and Detection, Disease Prevention and Biotechnology, and Policy Control and Research. The findings reveal significant trends: an increasing focus on Biosecurity Legislation and Prevention and a declining interest in Agricultural Management and Production. Geographically, Australia, Canada, and the United States lead in biosecurity research, exhibiting diverse research topics. Journal-level analysis highlights central topics such as Agricultural Management and Production, Biosecurity Legislation and Prevention, and Health Risk Assessment and Detection. This study's use of LDA reduces subjective bias, providing a more objective analysis of global biosecurity legislation literature. The research underscores the importance of expanding geographical scope, integrating advanced machine learning models, adopting interdisciplinary approaches, and assessing policy impacts to enhance biosecurity strategies globally.",
      "authors": "Liu Yang",
      "year": "2025",
      "journal": "One health (Amsterdam, Netherlands)",
      "doi": "10.1016/j.onehlt.2024.100964",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39845566/",
      "mesh_terms": "",
      "keywords": "Biosecurity legislation; Latent Dirichlet allocation (LDA); Topic distribution; Topic model",
      "pub_types": "Journal Article",
      "pmcid": "PMC11750572"
    },
    {
      "pmid": "38494885",
      "title": "In the face of ambiguity: intrinsic brain organization in development predicts one's bias toward positivity or negativity.",
      "abstract": "Exacerbated negativity bias, including in responses to ambiguity, represents a common phenotype of internalizing disorders. Individuals differ in their propensity toward positive or negative appraisals of ambiguity. This variability constitutes one's valence bias, a stable construct linked to mental health. Evidence suggests an initial negativity in response to ambiguity that updates via regulatory processes to support a more positive bias. Previous work implicates the amygdala and prefrontal cortex, and regions of the cingulo-opercular system, in this regulatory process. Nonetheless, the neurodevelopmental origins of valence bias remain unclear. The current study tests whether intrinsic brain organization predicts valence bias among 119 children and adolescents (6 to 17\u00a0years). Using whole-brain resting-state functional connectivity, a machine-learning model predicted valence bias (r\u2009=\u20090.20, P\u2009=\u20090.03), as did a model restricted to amygdala and cingulo-opercular system features (r\u2009=\u20090.19, P\u2009=\u20090.04). Disrupting connectivity revealed additional intra-system (e.g. fronto-parietal) and inter-system (e.g. amygdala to cingulo-opercular) connectivity important for prediction. The results highlight top-down control systems and bottom-up perceptual processes that influence valence bias in development. Thus, intrinsic brain organization informs the neurodevelopmental origins of valence bias, and directs future work aimed at explicating related internalizing symptomology.",
      "authors": "Harp Nicholas R; Nielsen Ashley N; Schultz Douglas H; Neta Maital",
      "year": "2024",
      "journal": "Cerebral cortex (New York, N.Y. : 1991)",
      "doi": "10.1093/cercor/bhae102",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38494885/",
      "mesh_terms": "Child; Adolescent; Humans; Brain; Prefrontal Cortex; Amygdala; Brain Mapping; Magnetic Resonance Imaging",
      "keywords": "ambiguity; individual differences; machine learning; resting-state functional connectivity; valence bias",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10945044"
    },
    {
      "pmid": "35469891",
      "title": "The Risk of Coding Racism into Pediatric Sepsis Care: The Necessity of Antiracism in Machine Learning.",
      "abstract": "Machine learning holds the possibility of improving racial health inequalities by compensating for human bias and structural racism. However, unanticipated racial biases may enter during model design, training, or implementation and perpetuate or worsen racial inequalities if ignored. Pre-existing racial health inequalities could be codified into medical care by machine learning without clinicians being aware. To illustrate the importance of a commitment to antiracism at all stages of machine learning, we examine machine learning in predicting severe sepsis in Black children, focusing on the impacts of structural racism that may be perpetuated by machine learning and difficult to discover. To move toward antiracist machine learning, we recommend partnering with ethicists and experts in model development, enrolling representative samples for training, including socioeconomic inputs with proximate causal associations to racial inequalities, reporting outcomes by race, and committing to equitable models that narrow inequality gaps or at least have equal benefit.",
      "authors": "Sveen William; Dewan Maya; Dexheimer Judith W",
      "year": "2022",
      "journal": "The Journal of pediatrics",
      "doi": "10.1016/j.jpeds.2022.04.024",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35469891/",
      "mesh_terms": "Child; Humans; Machine Learning; Racism; Sepsis",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32626900",
      "title": "Learning from local to global: An efficient distributed algorithm for modeling time-to-event data.",
      "abstract": "OBJECTIVE: We developed and evaluated a privacy-preserving One-shot Distributed Algorithm to fit a multicenter Cox proportional hazards model (ODAC) without sharing patient-level information across sites. MATERIALS AND METHODS: Using patient-level data from a single site combined with only aggregated information from other sites, we constructed a surrogate likelihood function, approximating the Cox partial likelihood function obtained using patient-level data from all sites. By maximizing the surrogate likelihood function, each site obtained a local estimate of the model parameter, and the ODAC estimator was constructed as a weighted average of all the local estimates. We evaluated the performance of ODAC with (1) a simulation study and (2) a real-world use case study using 4 datasets from the Observational Health Data Sciences and Informatics network. RESULTS: On the one hand, our simulation study showed that ODAC provided estimates nearly the same as the estimator obtained by analyzing, in a single dataset, the combined patient-level data from all sites (ie, the pooled estimator). The relative bias was <0.1% across all scenarios. The accuracy of ODAC remained high across different sample sizes and event rates. On the other hand, the meta-analysis estimator, which was obtained by the inverse variance weighted average of the site-specific estimates, had substantial bias when the event rate is <5%, with the relative bias reaching 20% when the event rate is 1%. In the Observational Health Data Sciences and Informatics network application, the ODAC estimates have a relative bias <5% for 15 out of 16 log hazard ratios, whereas the meta-analysis estimates had substantially higher bias than ODAC. CONCLUSIONS: ODAC is a privacy-preserving and noniterative method for implementing time-to-event analyses across multiple sites. It provides estimates on par with the pooled estimator and substantially outperforms the meta-analysis estimator when the event is uncommon, making it extremely suitable for studying rare events and diseases in a distributed manner.",
      "authors": "Duan Rui; Luo Chongliang; Schuemie Martijn J; Tong Jiayi; Liang C Jason; Chang Howard H; Boland Mary Regina; Bian Jiang; Xu Hua; Holmes John H; Forrest Christopher B; Morton Sally C; Berlin Jesse A; Moore Jason H; Mahoney Kevin B; Chen Yong",
      "year": "2020",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaa044",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32626900/",
      "mesh_terms": "Adult; Aged; Algorithms; Bias; Computer Simulation; Datasets as Topic; Electronic Health Records; Female; Humans; Likelihood Functions; Male; Middle Aged; Models, Statistical; Proportional Hazards Models; Sample Size; Time Factors",
      "keywords": "Cox proportional hazards model; data integration; distributed algorithm; electronic health record; meta-analysis",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7647322"
    },
    {
      "pmid": "37995113",
      "title": "A Conference (Missingness in Action) to Address Missingness in Data and AI in Health Care: Qualitative Thematic Analysis.",
      "abstract": "BACKGROUND: Missingness in health care data poses significant challenges in the development and implementation of artificial intelligence (AI) and machine learning solutions. Identifying and addressing these challenges is critical to ensuring the continued growth and accuracy of these models as well as their equitable and effective use in health care settings. OBJECTIVE: This study aims to explore the challenges, opportunities, and potential solutions related to missingness in health care data for AI applications through the conduct of a digital conference and thematic analysis of conference proceedings. METHODS: A digital conference was held in September 2022, attracting 861 registered participants, with 164 (19%) attending the live event. The conference featured presentations and panel discussions by experts in AI, machine learning, and health care. Transcripts of the event were analyzed using the stepwise framework of Braun and Clark to identify key themes related to missingness in health care data. RESULTS: Three principal themes-data quality and bias, human input in model development, and trust and privacy-emerged from the analysis. Topics included the accuracy of predictive models, lack of inclusion of underrepresented communities, partnership with physicians and other populations, challenges with sensitive health care data, and fostering trust with patients and the health care community. CONCLUSIONS: Addressing the challenges of data quality, human input, and trust is vital when devising and using machine learning algorithms in health care. Recommendations include expanding data collection efforts to reduce gaps and biases, involving medical professionals in the development and implementation of AI models, and developing clear ethical guidelines to safeguard patient privacy. Further research and ongoing discussions are needed to ensure these conclusions remain relevant as health care and AI continue to evolve.",
      "authors": "Rose Christian; Barber Rachel; Preiksaitis Carl; Kim Ireh; Mishra Nikesh; Kayser Kristen; Brown Italo; Gisondi Michael",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/49314",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37995113/",
      "mesh_terms": "Humans; Artificial Intelligence; Machine Learning; Algorithms; Data Accuracy; Data Collection",
      "keywords": "AI; artificial intelligence; data quality; digital conference; health care community; health care data; implementation; machine learning; predictive model; privacy; thematic analysis; trust",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10704317"
    },
    {
      "pmid": "31797639",
      "title": "Robust-ODAL: Learning from heterogeneous health systems without sharing patient-level data.",
      "abstract": "Electronic Health Records (EHR) contain extensive patient data on various health outcomes and risk predictors, providing an efficient and wide-reaching source for health research. Integrated EHR data can provide a larger sample size of the population to improve estimation and prediction accuracy. To overcome the obstacle of sharing patient-level data, distributed algorithms were developed to conduct statistical analyses across multiple clinical sites through sharing only aggregated information. However, the heterogeneity of data across sites is often ignored by existing distributed algorithms, which leads to substantial bias when studying the association between the outcomes and exposures. In this study, we propose a privacy-preserving and communication-efficient distributed algorithm which accounts for the heterogeneity caused by a small number of the clinical sites. We evaluated our algorithm through a systematic simulation study motivated by real-world scenarios and applied our algorithm to multiple claims datasets from the Observational Health Data Sciences and Informatics (OHDSI) network. The results showed that the proposed method performed better than the existing distributed algorithm ODAL and a meta-analysis method.",
      "authors": "Tong Jiayi; Duan Rui; Li Ruowang; Scheuemie Martijn J; Moore Jason H; Chen Yong",
      "year": "2020",
      "journal": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31797639/",
      "mesh_terms": "Algorithms; Computational Biology; Computer Simulation; Electronic Health Records; Humans; Information Dissemination; Machine Learning; Medical Informatics",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6905508"
    },
    {
      "pmid": "29135770",
      "title": "An Electronic Health Record-based Algorithm to Ascertain the Date of Second Breast Cancer Events.",
      "abstract": "OBJECTIVES: Studies of cancer recurrences and second primary tumors require information on outcome dates. Little is known about how well electronic health record-based algorithms can identify dates or how errors in dates can bias analyses. RESEARCH DESIGN: We assessed rule-based and model-fitting approaches to assign event dates using a previously published electronic health record-based algorithm for second breast cancer events (SBCE). We conducted a simulation study to assess bias due to date assignment errors in time-to-event analyses. SUBJECTS: From a cohort of 3152 early-stage breast cancer patients, 358 women accurately identified as having had an SBCE served as the basis for this analysis. MEASURES: Percent of predicted SBCE dates identified within \u00b160 days of the true date was the primary measure of accuracy. In the simulation study, bias in hazard ratios (HRs) was estimated by averaging the difference between HRs based on algorithm-assigned dates and the true HR across 1000 simulations each with simulated N=4000. RESULTS: The most accurate date algorithm had a median difference between the true and predicted dates of 0 days with 82% of predicted dates falling within 60 days of the true date. Bias resulted when algorithm sensitivity and specificity varied by exposure status, but was minimal when date assignment errors were of the magnitude observed for our date assignment method. CONCLUSIONS: SBCE date can be relatively accurately assigned based on a previous algorithm. While acceptable in many scenarios, algorithm-assigned dates are not appropriate to use when operating characteristics are likely to vary by the study exposure.",
      "authors": "Chubak Jessica; Onega Tracy; Zhu Weiwei; Buist Diana S M; Hubbard Rebecca A",
      "year": "2017",
      "journal": "Medical care",
      "doi": "10.1097/MLR.0000000000000352",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29135770/",
      "mesh_terms": "Adult; Aged; Algorithms; Breast Neoplasms; Cohort Studies; Electronic Health Records; Female; Humans; Middle Aged; Neoplasm Recurrence, Local; Risk Factors; Sensitivity and Specificity; United States",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC4592686"
    },
    {
      "pmid": "38754870",
      "title": "Validation of algorithms in studies based on routinely collected health data: general principles.",
      "abstract": "Clinicians, researchers, regulators, and other decision-makers increasingly rely on evidence from real-world data (RWD), including data routinely accumulating in health and administrative databases. RWD studies often rely on algorithms to operationalize variable definitions. An algorithm is a combination of codes or concepts used to identify persons with a specific health condition or characteristic. Establishing the validity of algorithms is a prerequisite for generating valid study findings that can ultimately inform evidence-based health care. In this paper, we aim to systematize terminology, methods, and practical considerations relevant to the conduct of validation studies of RWD-based algorithms. We discuss measures of algorithm accuracy, gold/reference standards, study size, prioritization of accuracy measures, algorithm portability, and implications for interpretation. Information bias is common in epidemiologic studies, underscoring the importance of transparency in decisions regarding choice and prioritizing measures of algorithm validity. The validity of an algorithm should be judged in the context of a data source, and one size does not fit all. Prioritizing validity measures within a given data source depends on the role of a given variable in the analysis (eligibility criterion, exposure, outcome, or covariate). Validation work should be part of routine maintenance of RWD sources. This article is part of a Special Collection on Pharmacoepidemiology.",
      "authors": "Ehrenstein Vera; Hellfritzsch Maja; Kahlert Johnny; Langan Sin\u00e9ad M; Urushihara Hisashi; Marinac-Dabic Danica; Lund Jennifer L; S\u00f8rensen Henrik Toft; Benchimol Eric I",
      "year": "2024",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwae071",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38754870/",
      "mesh_terms": "Algorithms; Humans; Reproducibility of Results; Validation Studies as Topic; Data Collection; Databases, Factual",
      "keywords": "algorithms; data quality; information bias; measurement error; misclassification; real-world data; routinely collected health data; validity",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39107854",
      "title": "Estimating and planning hospital costs of public hospitals in Brazil.",
      "abstract": "While the estimate of hospital costs concerns the past, its planning focuses on the future. However, in many low and middle-income countries, public hospitals do not have robust accounting health systems to evaluate and project their expenses. In Brazil, public hospitals are funded based on government estimates of available hospital infrastructure, historical expenditures and population needs. However, these pieces of information are not always readily available for all hospitals. To solve this challenge, we propose a flexible simulation-based optimisation algorithm that integrates this dual task: estimating and planning hospital costs. The method was applied to a network of 17 public hospitals in Brazil to produce the estimates. Setting the model parameters for population needs and future hospital infrastructure can be used as a cost-projection tool for divestment, maintenance, or investment. Results show that the method can aid health managers in hospitals' global budgeting and policymakers in improving fairness in hospitals' financing.",
      "authors": "Almeida Jo\u00e3o Fl\u00e1vio de Freitas; Concei\u00e7\u00e3o Samuel Vieira; Magalh\u00e3es Virg\u00ednia Silva; Alem\u00e3o M\u00e1rcia Mascarenhas",
      "year": "2024",
      "journal": "The International journal of health planning and management",
      "doi": "10.1002/hpm.3840",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39107854/",
      "mesh_terms": "Hospitals, Public; Brazil; Hospital Costs; Humans; Algorithms",
      "keywords": "hospital costs estimation; hospital global budgeting; simulation\u2010based optimisation",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "34615665",
      "title": "COVID-19 pandemic and artificial intelligence: challenges of ethical bias and trustworthy reliable reproducibility?",
      "abstract": "",
      "authors": "Kulikowski Casimir; Maojo Victor Manuel",
      "year": "2021",
      "journal": "BMJ health & care informatics",
      "doi": "10.1136/bmjhci-2021-100438",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34615665/",
      "mesh_terms": "Artificial Intelligence; COVID-19; Humans; Pandemics; Reproducibility of Results; SARS-CoV-2",
      "keywords": "COVID-19; artificial intelligence; machine learning; medical informatics; public health informatics",
      "pub_types": "Journal Article",
      "pmcid": "PMC8495685"
    },
    {
      "pmid": "40705491",
      "title": "Two-stage estimators for spatial confounding with point-referenced data.",
      "abstract": "Public health data are often spatially dependent, but standard spatial regression methods can suffer from bias and invalid inference when the independent variable is associated with spatially correlated residuals. This could occur if, for example, there is an unmeasured environmental contaminant associated with the independent and outcome variables in a spatial regression analysis. Geoadditive structural equation\u00a0modeling (gSEM), in which an estimated spatial trend is removed from both the explanatory and response variables before estimating the parameters of interest, has previously been proposed as a solution but there has been little investigation of gSEM's properties with point-referenced data. We link gSEM to results on double machine learning and semiparametric regression based on two-stage procedures. We propose using these semiparametric estimators for spatial regression using Gaussian processes with Mat\u00e8rn covariance to estimate the spatial trends and term this class of estimators double spatial regression (DSR). We derive regularity conditions for root-n asymptotic normality and consistency and closed-form variance estimation, and show that in simulations where standard spatial regression estimators are highly biased and have poor coverage, DSR can mitigate bias more effectively than competitors and obtain nominal coverage.",
      "authors": "Wiecha Nate; Hoppin Jane A; Reich Brian J",
      "year": "2025",
      "journal": "Biometrics",
      "doi": "10.1093/biomtc/ujaf093",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40705491/",
      "mesh_terms": "Computer Simulation; Humans; Models, Statistical; Spatial Regression; Confounding Factors, Epidemiologic; Bias; Machine Learning; Biometry; Data Interpretation, Statistical; Normal Distribution",
      "keywords": "Gaussian process; bias reduction; double machine learning; semiparametric regression",
      "pub_types": "Journal Article",
      "pmcid": "PMC12288666"
    },
    {
      "pmid": "38721435",
      "title": "Brain-age estimation with a low-cost EEG-headset: effectiveness and implications for large-scale screening and brain optimization.",
      "abstract": "Over time, pathological, genetic, environmental, and lifestyle factors can age the brain and diminish its functional capabilities. While these factors can lead to disorders that can be diagnosed and treated once they become symptomatic, often treatment is difficult or ineffective by the time significant overt symptoms appear. One approach to this problem is to develop a method for assessing general age-related brain health and function that can be implemented widely and inexpensively. To this end, we trained a machine-learning algorithm on resting-state EEG (RS-EEG) recordings obtained from healthy individuals as the core of a brain-age estimation technique that takes an individual's RS-EEG recorded with the low-cost, user-friendly EMOTIV EPOC X headset and returns that person's estimated brain age. We tested the current version of our machine-learning model against an independent test-set of healthy participants and obtained a correlation coefficient of 0.582 between the chronological and estimated brain ages (r = 0.963 after statistical bias-correction). The test-retest correlation was 0.750 (0.939 after bias-correction) over a period of 1 week. Given these strong results and the ease and low cost of implementation, this technique has the potential for widespread adoption in the clinic, workplace, and home as a method for assessing general brain health and function and for testing the impact of interventions over time.",
      "authors": "Kounios John; Fleck Jessica I; Zhang Fengqing; Oh Yongtaek",
      "year": "2024",
      "journal": "Frontiers in neuroergonomics",
      "doi": "10.3389/fnrgo.2024.1340732",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38721435/",
      "mesh_terms": "",
      "keywords": "EEG; brain health; brain-age estimation; machine learning; resting-state EEG",
      "pub_types": "Journal Article",
      "pmcid": "PMC11077564"
    },
    {
      "pmid": "31361300",
      "title": "Development of a global infectious disease activity database using natural language processing, machine learning, and human expertise.",
      "abstract": "OBJECTIVE: We assessed whether machine learning can be utilized to allow efficient extraction of infectious disease activity information from online media reports. MATERIALS AND METHODS: We curated a data set of labeled media reports (n\u2009=\u20098322) indicating which articles contain updates about disease activity. We trained a classifier on this data set. To validate our system, we used a held out test set and compared our articles to the World Health Organization Disease Outbreak News reports. RESULTS: Our classifier achieved a recall and precision of 88.8% and 86.1%, respectively. The overall surveillance system detected 94% of the outbreaks identified by the WHO covered by online media (89%) and did so 43.4 (IQR: 9.5-61) days earlier on average. DISCUSSION: We constructed a global real-time disease activity database surveilling 114 illnesses and syndromes. We must further assess our system for bias, representativeness, granularity, and accuracy. CONCLUSION: Machine learning, natural language processing, and human expertise can be used to efficiently identify disease activity from digital media reports.",
      "authors": "Feldman Joshua; Thomas-Bachli Andrea; Forsyth Jack; Patel Zaki Hasnain; Khan Kamran",
      "year": "2019",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocz112",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31361300/",
      "mesh_terms": "Communicable Diseases; Databases, Factual; Disease Outbreaks; Global Health; Humans; Information Storage and Retrieval; Machine Learning; Natural Language Processing; Population Surveillance; User-Computer Interface",
      "keywords": "communicable diseases; health information systems; internet; machine learning; public health surveillance",
      "pub_types": "Journal Article",
      "pmcid": "PMC7647217"
    },
    {
      "pmid": "35396245",
      "title": "Can medical algorithms be fair? Three ethical quandaries and one dilemma.",
      "abstract": "OBJECTIVE: To demonstrate what it takes to reconcile the idea of fairness in medical algorithms and machine learning (ML) with the broader discourse of fairness and health equality in health research. METHOD: The methodological approach used in this paper is theoretical and ethical analysis. RESULT: We show that the question of ensuring comprehensive ML fairness is interrelated to three quandaries and one dilemma. DISCUSSION: As fairness in ML depends on a nexus of inherent justice and fairness concerns embedded in health research, a comprehensive conceptualisation is called for to make the notion useful. CONCLUSION: This paper demonstrates that more analytical work is needed to conceptualise fairness in ML so it adequately reflects the complexity of justice and fairness concerns within the field of health research.",
      "authors": "B\u00e6r\u00f8e Kristine; Gundersen Torbj\u00f8rn; Henden Edmund; Rommetveit Kjetil",
      "year": "2022",
      "journal": "BMJ health & care informatics",
      "doi": "10.1136/bmjhci-2021-100445",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35396245/",
      "mesh_terms": "Algorithms; Humans; Machine Learning; Social Justice",
      "keywords": "artificial intelligence; delivery of health care; health equity; machine learning; public health",
      "pub_types": "Journal Article",
      "pmcid": "PMC8996015"
    },
    {
      "pmid": "38147277",
      "title": "Using Natural Language Processing to Identify Stigmatizing Language in Labor and Birth Clinical Notes.",
      "abstract": "INTRODUCTION: Stigma and bias related to race and other minoritized statuses may underlie disparities in pregnancy and birth outcomes. One emerging method to identify bias is the study of stigmatizing language in the electronic health record. The objective of our study was to develop automated natural language processing (NLP) methods to identify two types of stigmatizing language: marginalizing language and its complement, power/privilege language, accurately and automatically in labor and birth notes. METHODS: We analyzed notes for all birthing people\u2009>\u200920 weeks' gestation admitted for labor and birth at two hospitals during 2017. We then employed text preprocessing techniques, specifically using TF-IDF values as inputs, and tested machine learning classification algorithms to identify stigmatizing and power/privilege language in clinical notes. The algorithms assessed included Decision Trees, Random Forest, and Support Vector Machines. Additionally, we applied a feature importance evaluation method (InfoGain) to discern words that are highly correlated with these language categories. RESULTS: For marginalizing language, Decision Trees yielded the best classification with an F-score of 0.73. For power/privilege language, Support Vector Machines performed optimally, achieving an F-score of 0.91. These results demonstrate the effectiveness of the selected machine learning methods in classifying language categories in clinical notes. CONCLUSION: We identified well-performing machine learning methods to automatically detect stigmatizing language in clinical notes. To our knowledge, this is the first study to use NLP performance metrics to evaluate the performance of machine learning methods in discerning stigmatizing language. Future studies should delve deeper into refining and evaluating NLP methods, incorporating the latest algorithms rooted in deep learning.",
      "authors": "Barcelona Veronica; Scharp Danielle; Moen Hans; Davoudi Anahita; Idnay Betina R; Cato Kenrick; Topaz Maxim",
      "year": "2024",
      "journal": "Maternal and child health journal",
      "doi": "10.1007/s10995-023-03857-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38147277/",
      "mesh_terms": "Female; Humans; Natural Language Processing; Algorithms; Electronic Health Records; Machine Learning; Language",
      "keywords": "Bias; Electronic health records; Natural language processing",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40316929",
      "title": "Data-driven machine learning algorithm model for pneumonia prediction and determinant factor stratification among children aged 6-23 months in Ethiopia.",
      "abstract": "INTRODUCTION: Pneumonia is the leading cause of child morbidity and mortality and accounts for 5.6 million under-five child deaths. Pneumonia has a significant impact on the quality of life, the country's economy, and the survival of children. Therefore, this study aimed to develop data-driven predictive model using machine learning algorithms to predict pneumonia and stratify the determinant factors among children aged 6-23\u00a0months in Ethiopia. METHODS: A total of 2035 samples of children were used from the 2016 Ethiopian Demographic and Health Survey dataset. Jupyter Notebook from Anaconda Navigators was used for data management and analysis. Important libraries such as Pandas, Seaborn, and Numpy were imported from Python. The data was pre-processed into a training and testing dataset with a 4:1 ratio, and tenfold cross-validation was used to reduce bias and enhance the models' performance. Six machine learning algorithms were used for model building and comparison, and confusion matrix elements were used to evaluate the performance of each algorithm. Principal component analysis and heatmap function were used for correlation detection between features. Feature importance score was used to identify and stratify the most important predictors of pneumonia. RESULTS: From 2035 total samples, 16.6%, 20.1%, and 24.2% of children had short rapid breath, fever, and cough respectively. The overall magnitude of pneumonia among children aged 6-23\u00a0months was 31.3% based on the 2016 EDHS report. A random forest algorithm is the relatively best performance model to predict pneumonia and stratify its determinates with 91.3% accuracy. The health facility visits, child sex, initiation of breastfeeding, birth interval, birth weight, husbands' education, women's age, and region, are the top eight important predictors of pneumonia among children with important scores of more than 5% to 20% respectively. CONCLUSIONS: Random forest is the best model to predict pneumonia and stratify its determinant factors. The implications of this study are profound for advanced research methodology, tailored to promote effective health interventions such as lifestyle modification and behavioral intervention, based on individuals' unique features, specifically for stakeholders to take proactive childcare interventions. The study would serve as pioneering evidence for future research, and researchers are recommended to use deep learning algorithms to enhance prediction accuracy.",
      "authors": "Demsash Addisalem Workie; Abebe Rediet; Gezimu Wubishet; Kitil Gemeda Wakgari; Tizazu Michael Amera; Lambebo Abera; Bekele Firomsa; Alemu Solomon Seyife; Jarso Mohammedamin Hajure; Dube Geleta Nenko; Wedajo Lema Fikadu; Purohit Sanju; Kalayou Mulugeta Hayelom",
      "year": "2025",
      "journal": "BMC infectious diseases",
      "doi": "10.1186/s12879-025-10916-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40316929/",
      "mesh_terms": "Humans; Ethiopia; Infant; Pneumonia; Machine Learning; Female; Male; Algorithms; Risk Factors",
      "keywords": "Children; Data-driven; Machine learning; Pneumonia; Prediction Model",
      "pub_types": "Journal Article",
      "pmcid": "PMC12048943"
    },
    {
      "pmid": "41376360",
      "title": "Improved Outcomes in Mental Healthcare Using Artificial Intelligence.",
      "abstract": "Artificial intelligence (AI) presents opportunities and challenges in post-discharge psychiatric care. Leveraging structured data and machine learning, the Centre for Addiction and Mental Health aims to predict adverse outcomes, including readmissions, among patients recently discharged from psychiatric units. By identifying high-risk individuals, AI can guide referrals to resource-intensive outpatient clinics, enhancing continuity of care and improving outcomes. A governance framework addressing ethics, transparency and fairness underpins the development and implementation process. The study emphasizes using interpretable AI models over black-box systems to foster trust and clinical utility, aligning AI advancements with ethical mental health practices.",
      "authors": "Lustig Andrew; Hassan Masooma; Kim Ethan; D'Souza Keith; Tasca Adam; Tajirian Tania; Gratzer David",
      "year": "2025",
      "journal": "Healthcare quarterly (Toronto, Ont.)",
      "doi": "10.12927/hcq.2025.27734",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41376360/",
      "mesh_terms": "Humans; Artificial Intelligence; Mental Health Services; Mental Disorders; Patient Readmission",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "25488047",
      "title": "High-dimensional propensity score algorithm in comparative effectiveness research with time-varying interventions.",
      "abstract": "The high-dimensional propensity score (hdPS) algorithm was proposed for automation of confounding adjustment in problems involving large healthcare databases. It has been evaluated in comparative effectiveness research (CER) with point treatments to handle baseline confounding through matching or covariance adjustment on the hdPS. In observational studies with time-varying interventions, such hdPS approaches are often inadequate to handle time-dependent confounding and selection bias. Inverse probability weighting (IPW) estimation to fit marginal structural models can adequately handle these biases under the fundamental assumption of no unmeasured confounders. Upholding of this assumption relies on the selection of an adequate set of covariates for bias adjustment. We describe the application and performance of the hdPS algorithm to improve covariate selection in CER with time-varying interventions based on IPW estimation and explore stabilization of the resulting estimates using Super Learning. The evaluation is based on both the analysis of electronic health records data in a real-world CER study of adults with type 2 diabetes and a simulation study. This report (i) establishes the feasibility of IPW estimation with the hdPS algorithm based on large electronic health records databases, (ii) demonstrates little impact on inferences when supplementing the set of expert-selected covariates using the hdPS algorithm in a setting with extensive background knowledge, (iii) supports the application of the hdPS algorithm in discovery settings with little background knowledge or limited data availability, and (iv) motivates the application of Super Learning to stabilize effect estimates based on the hdPS algorithm.",
      "authors": "Neugebauer Romain; Schmittdiel Julie A; Zhu Zheng; Rassen Jeremy A; Seeger John D; Schneeweiss Sebastian",
      "year": "2015",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.6377",
      "url": "https://pubmed.ncbi.nlm.nih.gov/25488047/",
      "mesh_terms": "Adult; Algorithms; Biostatistics; Cohort Studies; Comparative Effectiveness Research; Computer Simulation; Confounding Factors, Epidemiologic; Databases, Factual; Diabetes Mellitus, Type 2; Electronic Health Records; Female; Humans; Male; Models, Statistical; Multicenter Studies as Topic; Observational Studies as Topic; Probability; Propensity Score; Retrospective Studies; Selection Bias",
      "keywords": "Super Learning; comparative effectiveness; diabetes; high-dimensional propensity score; inverse probability weighting; marginal structural model",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "38198776",
      "title": "Unlocking the potential of artificial intelligence in sports cardiology: does it have a role in evaluating athlete's heart?",
      "abstract": "The integration of artificial intelligence (AI) technologies is evolving in different fields of cardiology and in particular in sports cardiology. Artificial intelligence offers significant opportunities to enhance risk assessment, diagnosis, treatment planning, and monitoring of athletes. This article explores the application of AI in various aspects of sports cardiology, including imaging techniques, genetic testing, and wearable devices. The use of machine learning and deep neural networks enables improved analysis and interpretation of complex datasets. However, ethical and legal dilemmas must be addressed, including informed consent, algorithmic fairness, data privacy, and intellectual property issues. The integration of AI technologies should complement the expertise of physicians, allowing for a balanced approach that optimizes patient care and outcomes. Ongoing research and collaborations are vital to harness the full potential of AI in sports cardiology and advance our management of cardiovascular health in athletes.",
      "authors": "Palermi Stefano; Vecchiato Marco; Saglietto Andrea; Niederseer David; Oxborough David; Ortega-Martorell Sandra; Olier Ivan; Castelletti Silvia; Baggish Aaron; Maffessanti Francesco; Biffi Alessandro; D'Andrea Antonello; Zorzi Alessandro; Cavarretta Elena; D'Ascenzi Flavio",
      "year": "2024",
      "journal": "European journal of preventive cardiology",
      "doi": "10.1093/eurjpc/zwae008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38198776/",
      "mesh_terms": "Humans; Artificial Intelligence; Cardiomegaly, Exercise-Induced; Cardiology; Sports; Neural Networks, Computer",
      "keywords": "Artificial intelligence; Athlete\u2019s heart; Cardiovascular prevention; Deep learning; Machine learning; Sports cardiology",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33493961",
      "title": "A novel algorithm for minute ventilation estimation in remote health monitoring with magnetometer plethysmography.",
      "abstract": "The purpose of this study was to evaluate the accuracy of minute ventilation (V\u02d9E) estimation using a novel method based on a non-linear algorithm coupled with cycle-based features. The experiment protocol was well adapted for remote health monitoring applications by exploiting data streams from respiratory magnetometer plethysmography (RMP) during different physical activity (PA) types. Methods Thirteen subjects with an age distribution of 24.1\u00b13.4 years performed thirteen PA ranging from sedentary to moderate intensity (walking at 4 and 6\u00a0km/h, running at 9 and 12\u00a0km/h, biking at 90\u00a0W and 110\u00a0W). In total, 3359 temporal segments of 10s were acquired using the Nomics RMP device while the iWorx spirometer was used for reference V\u02d9E measurements. An artificial neural network (ANN) model based on respiration features was used to estimate V\u02d9E and compared to the multiple linear regression (MLR) model. We also compared the subject-specific approach with the subject-independent approach. Results The ANN model using subject-specific approach achieved better accuracy for the V\u02d9E estimation. The bias was between 0.20\u00b10.87 and 0.78\u00b13 l/min with the ANN model as compared to 0.73\u00b13.19 and 4.17\u00b12.61 l/min with the MLR model. Conclusion Our results demonstrated the pertinence of processing data streams from wearable RMP device to estimate the V\u02d9E with sufficient accuracy for various PA types. Due to its low-complexity and real-time algorithm design, the current approach can be easily integrated into most remote health monitoring applications coupled with wearable sensors.",
      "authors": "Houssein Aya; Ge Di; Gastinger Steven; Dumond Remy; Prioux Jacques",
      "year": "2021",
      "journal": "Computers in biology and medicine",
      "doi": "10.1016/j.compbiomed.2020.104189",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33493961/",
      "mesh_terms": "Adult; Algorithms; Humans; Neural Networks, Computer; Plethysmography; Respiration; Wearable Electronic Devices; Young Adult",
      "keywords": "Biosensor data streaming; Machine learning; Minute ventilation estimation; Respiratory magnetometer plethysmography",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37729813",
      "title": "A clinical classification framework for identifying persons with high social and medical needs: The COMPLEXedex-SDH.",
      "abstract": "BACKGROUND: First-generation algorithms resulted in high-cost features as a representation of need but unintentionally introduced systemic bias based on prior ability to access care. Improved precision health approaches are needed to reduce bias and improve health equity. PURPOSE: To integrate nursing expertise into a clinical definition of high-need cases and develop a clinical classification algorithm for implementing nursing interventions. METHODS: Two-phase retrospective, descriptive cohort study using 2019 data to build the algorithm (n\u00a0=\u00a019,20,848) and 2021 data to test it in adults \u226518 years old (n\u00a0=\u00a015,99,176). DISCUSSION: The COMPLEXedex-SDH algorithm identified the following populations: cross-cohort needs (10.9%); high-need persons (cross-cohort needs and other social determinants) (17.7%); suboptimal health\u00a0care utilization for persons with medical complexity (13.8%); high need persons with suboptimal health care utilization (6.2%). CONCLUSION: The COMPLEXedex-SDH enables the identification of high-need cases and value-based utilization into actionable cohorts to prioritize outreach calls to improve health equity and outcomes.",
      "authors": "Sullivan Suzanne S; Ledwin Kathryn M; Hewner Sharon",
      "year": "2023",
      "journal": "Nursing outlook",
      "doi": "10.1016/j.outlook.2023.102044",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37729813/",
      "mesh_terms": "Adult; Humans; Adolescent; Cohort Studies; Retrospective Studies; Social Determinants of Health; Delivery of Health Care; Health Equity",
      "keywords": "Care coordination; Provider\u2013provider communication; Social determinants of health; Social need",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10842584"
    },
    {
      "pmid": "35767600",
      "title": "Performance of a multisensor smart ring to evaluate sleep: in-lab and home-based evaluation of generalized and personalized algorithms.",
      "abstract": "STUDY OBJECTIVES: Wearable sleep technology has rapidly expanded across the consumer market due to advances in technology and increased interest in personalized sleep assessment to improve health and mental performance. We tested the performance of a novel device, the Happy Ring, alongside other commercial wearables (Actiwatch 2, Fitbit Charge 4, Whoop 3.0, Oura Ring V2), against in-lab polysomnography (PSG) and at-home electroencephalography (EEG)-derived sleep monitoring device, the Dreem 2 Headband. METHODS: Thirty-six healthy adults with no diagnosed sleep disorders and no recent use of medications or substances known to affect sleep patterns were assessed across 77 nights. Subjects participated in a single night of in-lab PSG and two nights of at-home data collection. The Happy Ring includes sensors for skin conductance, movement, heart rate, and skin temperature. The Happy Ring utilized two machine-learning derived scoring algorithms: a \"generalized\" algorithm that applied broadly to all users, and a \"personalized\" algorithm that adapted to individual subjects' data. Epoch-by-epoch analyses compared the wearable devices to in-lab PSG and to at-home EEG Headband. RESULTS: Compared to in-lab PSG, the \"generalized\" and \"personalized\" algorithms demonstrated good sensitivity (94% and 93%, respectively) and specificity (70% and 83%, respectively). The Happy Personalized model demonstrated a lower bias and more narrow limits of agreement across Bland-Altman measures. CONCLUSION: The Happy Ring performed well at home and in the lab, especially regarding sleep/wake detection. The personalized algorithm demonstrated improved detection accuracy over the generalized approach and other devices, suggesting that adaptable, dynamic algorithms can enhance sleep detection accuracy.",
      "authors": "Grandner Michael A; Bromberg Zohar; Hadley Aaron; Morrell Zoe; Graf Arnulf; Hutchison Stephen; Freckleton Dustin",
      "year": "2023",
      "journal": "Sleep",
      "doi": "10.1093/sleep/zsac152",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35767600/",
      "mesh_terms": "Adult; Humans; Actigraphy; Reproducibility of Results; Sleep; Polysomnography; Algorithms",
      "keywords": "actigraphy; polysomnography; sensors; sleep technology; validation; wearables",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33165392",
      "title": "The Ethics of Machine Learning in Medical Sciences: Where Do We Stand Today?",
      "abstract": "Advances in Machine Learning and availability of state-of-the-art computational resources, along with digitized healthcare data, have set the stage for extensive application of artificial intelligence in the realm of diagnosis, prognosis, clinical decision support, personalized treatment options, drug development, and the field of biomedicine. Here, we discuss the application of Machine Learning algorithms in patient healthcare and dermatological domains along with the ethical complexities that are involved. In scientific studies, ethical challenges were initially not addressed proportionally (as assessed by keyword counts in PubMed) and just more recently (since 2016) this has started to improve. Few pioneering countries have created regulatory guidelines around how to respect matters of (1) privacy, (2) fairness, (3) accountability, (4) transparency and (5) conflict of interest when developing novel medical Machine Learning applications. While there is a strong promise of emerging medical applications to ultimately benefit both the patients and the medical practitioners, it is important to raise awareness on the five key ethical issues and incorporate them into medical practice in the near future.",
      "authors": "Basu Treena; Engel-Wolf Sebastian; Menzer Olaf",
      "year": "2020",
      "journal": "Indian journal of dermatology",
      "doi": "10.4103/ijd.IJD_419_20",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33165392/",
      "mesh_terms": "",
      "keywords": "Best practices; electronic health records; ethics; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC7640783"
    },
    {
      "pmid": "39845684",
      "title": "Multimodal machine learning for analysing multifactorial causes of disease-The case of childhood overweight and obesity in Mexico.",
      "abstract": "BACKGROUND: Mexico has one of the highest global incidences of paediatric overweight and obesity. Public health interventions have shown only moderate success, possibly from relying on knowledge extracted using limited types of statistical data analysis methods. PURPOSE: To explore if multimodal machine learning can enhance identifying predictive features from obesogenic environments and investigating complex disease or social patterns, using the Mexican National Health and Nutrition Survey. METHODS: We grouped features into five data modalities corresponding to paediatric population exogenous factors, in two multimodal machine learning pipelines, against a unimodal early fusion baseline. The supervised pipeline employed four methods: Linear classifier with Elastic Net regularisation, k-Nearest Neighbour, Decision Tree, and Random Forest. The unsupervised pipeline used traditional methods with k-Means and hierarchical clustering, with the optimal number of clusters calculated to be k = 2. RESULTS: The decision tree classifier in the supervised early fusion approach produced the best quantitative results. The top five most important features for classifying child or adolescent health were measures of an adult in the household, selected at random: BMI, obesity diagnosis, being single, seeking care at private healthcare, and having paid TV in the home. Unsupervised learning approaches varied in the optimal number of clusters but agreed on the importance of home environment features when analysing inter-cluster patterns. Main findings from this study differed from previous studies using only traditional statistical methods on the same database. Notably, the BMI of a randomised adult within the household emerged as the most important feature, rather than maternal BMI, as reported in previous literature where unwanted cultural bias went undetected. CONCLUSION: Our general conclusion is that multimodal machine learning is a promising approach for comprehensively analysing obesogenic environments. The modalities allowed for a multimodal approach designed to critically analyse data signal strength and reveal sources of unwanted bias. In particular, it may aid in developing more effective public health policies to address the ongoing paediatric obesity epidemic in Mexico.",
      "authors": "Silva Sepulveda Rosario; Boman Magnus",
      "year": "2024",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2024.1369041",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39845684/",
      "mesh_terms": "Humans; Mexico; Pediatric Obesity; Machine Learning; Child; Female; Male; Adolescent; Nutrition Surveys; Overweight; Child, Preschool; Body Mass Index",
      "keywords": "Mexico; bias; multimodal machine learning; obesogenic environment; paediatric obesity; supervised machine learning; unsupervised machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11752892"
    },
    {
      "pmid": "33980048",
      "title": "Predicting optimal treatment regimens for patients with HR+/HER2-\u00a0breast cancer using machine learning based on electronic health records.",
      "abstract": "Aim: To predict optimal treatments maximizing overall survival (OS) and time to treatment discontinuation (TTD) for patients with metastatic breast cancer (MBC) using machine learning methods on electronic health records. Patients/methods: Adult females with HR+/HER2-\u00a0MBC on first- or second-line systemic therapy were eligible. Random survival forest (RSF) models were used to predict optimal regimen classes for individual patients and each line of therapy based on baseline characteristics. Results: RSF models suggested greater use of CDK4 & 6 inhibitor-based therapies may maximize OS and TTD. RSF-predicted optimal treatments demonstrated longer OS and TTD compared with nonoptimal treatments across line of therapy (hazard ratios\u00a0=\u00a00.44\u223c0.79). Conclusion: RSF may help inform optimal treatment choices and improve outcomes for patients with HR+/HER2-\u00a0MBC.",
      "authors": "Cui Zhanglin Lin; Kadziola Zbigniew; Lipkovich Ilya; Faries Douglas E; Sheffield Kristin M; Carter Gebra Cuyun",
      "year": "2021",
      "journal": "Journal of comparative effectiveness research",
      "doi": "10.2217/cer-2020-0230",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33980048/",
      "mesh_terms": "Adult; Antineoplastic Combined Chemotherapy Protocols; Breast Neoplasms; Electronic Health Records; Female; Humans; Machine Learning; Erb-b2 Receptor Tyrosine Kinases",
      "keywords": "bias control; breast cancer; comparative effectiveness research; electronic health record; machine learning; optimal treatment; random survival forest",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41077597",
      "title": "Prediction of Personalised Hypertension Using Machine Learning in Indonesian Population.",
      "abstract": "This study aims to enhance individual hypertension risk prediction in Indonesia\u00a0using machine learning (ML) models. The research investigates the predictive\u00a0accuracy of models with and without incorporating personal hypertension history,\u00a0seeking to understand how data limitations impact model performance in a low-resource setting.\u00a0Data from the SATUSEHAT IndonesiaKu (ASIK) system were preprocessed and filtered to create a dataset of 9.58 million adult health records. Two primary model variations were compared: Model A (incorporating patient history) and Model B (excluding patient history). We evaluated the model using five algorithms: XGBoost, LightGBM, CatBoost, Logistic Regression, and Random Forest. Model performance was assessed using the Area Under the Curve (AUC), sensitivity, and specificity metrics.\u00a0Model A achieved superior predictive accuracy (AUC\u2009=\u20090.85) compared to Model B (AUC\u2009=\u20090.78).\u00a0To mitigate potential bias, Model B was selected for further in-depth development. Evaluation of model B reveals that XGBoost and LightGBM algorithm achieved the highest performance (AUC 0.78) and LightGBM emerged as the best algorithm based on its performance. SHAP analysis was conducted and identified key predictors such as age, family history of hypertension, body weight, and waist circumference.\u00a0This study finds that while a patient's personal history of hypertension significantly enhances predictive accuracy, robust ML models can effectively predict hypertension risk using other accessible demographic, clinical, and lifestyle features. Model B offers a valuable and generalizable approach for broader risk screening, particularly where patient history may be unavailable or unreliable, while also providing insights into key modifiable and non-modifiable determinants of hypertension.",
      "authors": "Septian Edo; Khaefi Muhammad Rizal; Athoillah Achmad; Aisyah Dewi Nur; Hardhantyo Muhammad; Rahman Fauziah Mauly; Manikam Logan",
      "year": "2025",
      "journal": "Journal of medical systems",
      "doi": "10.1007/s10916-025-02253-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41077597/",
      "mesh_terms": "Humans; Indonesia; Machine Learning; Hypertension; Female; Male; Middle Aged; Adult; Algorithms; Risk Assessment; Risk Factors; Aged",
      "keywords": "Hypertension prediction; Machine learning; Non-communicable diseases (NCDs); Risk assessment",
      "pub_types": "Journal Article",
      "pmcid": "PMC12515743"
    },
    {
      "pmid": "38937337",
      "title": "Recognition of Patient Gender: A Machine Learning Preliminary Analysis Using Heart Sounds from Children and Adolescents.",
      "abstract": "Research has shown that X-rays and fundus images can classify gender, age group, and race, raising concerns about bias and fairness in medical AI applications. However, the potential for physiological sounds to classify sociodemographic traits has not been investigated. Exploring this gap is crucial for understanding the implications and ensuring fairness in the field of medical sound analysis. We aimed to develop classifiers to determine gender (men/women) based on heart sound recordings and using machine learning (ML). Data-driven ML analysis. We utilized the open-access CirCor DigiScope Phonocardiogram Dataset obtained from cardiac screening programs in Brazil. Volunteers\u2009<\u200921\u00a0years of age. Each participant completed a questionnaire and underwent a clinical examination, including electronic auscultation at four cardiac points: aortic (AV), mitral (MV), pulmonary (PV), and tricuspid (TV). We used Mel-frequency cepstral coefficients (MFCCs) to develop the ML classifiers. From each patient and from each auscultation sound recording, we extracted 10 MFCCs. In sensitivity analysis, we additionally extracted 20, 30, 40, and 50 MFCCs. The most effective gender classifier was developed using PV recordings (AUC ROC\u2009=\u200970.3%). The second best came from MV recordings (AUC ROC\u2009=\u200958.8%). AV and TV recordings produced classifiers with an AUC ROC of 56.4% and 56.1%, respectively. Using more MFCCs did not substantially improve the classifiers. It is possible to classify between males and females using phonocardiogram data. As health-related audio recordings become more prominent in ML applications, research is required to explore if these recordings contain signals that could distinguish sociodemographic features.",
      "authors": "Carrillo-Larco Rodrigo M",
      "year": "2025",
      "journal": "Pediatric cardiology",
      "doi": "10.1007/s00246-024-03561-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38937337/",
      "mesh_terms": "Humans; Female; Male; Machine Learning; Adolescent; Heart Sounds; Child; Phonocardiography; Sex Factors; Young Adult; Brazil",
      "keywords": "Artificial intelligence; Bias; Sound epidemiology",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40286381",
      "title": "Disparities in Artificial Intelligence-Based Tools Among Diverse Minority Populations: Biases, Barriers, and Solutions.",
      "abstract": "",
      "authors": "Ahluwalia Monica; Sehgal Sankalp; Lee Grace; Agu Emmanuel; Kpodonu Jacques",
      "year": "2025",
      "journal": "JACC. Advances",
      "doi": "10.1016/j.jacadv.2025.101742",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40286381/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; bias; cardiovascular disease; health care disparities; hypertrophic cardiomyopathy; machine learning",
      "pub_types": "Editorial",
      "pmcid": "PMC12103092"
    },
    {
      "pmid": "33751024",
      "title": "Thirteen Questions About Using Machine Learning in Causal Research (You Won't Believe the Answer to Number 10!).",
      "abstract": "Machine learning is gaining prominence in the health sciences, where much of its use has focused on data-driven prediction. However, machine learning can also be embedded within causal analyses, potentially reducing biases arising from model misspecification. Using a question-and-answer format, we provide an introduction and orientation for epidemiologists interested in using machine learning but concerned about potential bias or loss of rigor due to use of \"black box\" models. We conclude with sample software code that may lower the barrier to entry to using these techniques.",
      "authors": "Mooney Stephen J; Keil Alexander P; Westreich Daniel J",
      "year": "2021",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwab047",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33751024/",
      "mesh_terms": "Algorithms; Bias; Causality; Data Interpretation, Statistical; Epidemiologic Methods; Humans; Machine Learning",
      "keywords": "causal inference; double-robustness; epidemiologic methods; inverse probability weighting; machine learning; propensity score; targeted maximum likelihood estimation",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC8555423"
    },
    {
      "pmid": "41177628",
      "title": "Machine learning for ammonia volatilization prediction and slurry application management.",
      "abstract": "Anthropogenic ammonia emissions primarily originate from agriculture, especially field fertilization. These emissions represent nitrogen loss for farmers and contribute to air pollution, posing risks to human health and the environment. Estimating ammonia emissions is crucial for national inventories and policy-making. Various models exist for predicting emissions, including mechanistic, empirical, and semi-empirical approaches. While machine learning (ML) is widely used in environmental science, its application to ammonia emissions remains limited. In this study, we used 5939 ammonia emission data from 538 trials, extracted from the ALFAM2 database, to train three machine learning methods - random forest, gradient boosting, and lasso - for predicting cumulative ammonia emissions 72 h after manure application. These methods were compared to the semi-empirical ALFAM2 model using an independent test dataset. Random forest (RMSE = 4.51, r = 0.94, MAE = 3.28, Bias = 0.92) and gradient boosting (RMSE = 6.19, r = 0.89, MAE = 4.10, Bias = 0.51) showed the best performance, while the lasso log-linear model (RMSE = 7.30, r = 0.84, MAE = 5.57, Bias = -1.38) performed worst. Both random forest and gradient boosting outperformed the semi-empirical ALFAM2 model, which showed performance comparable to the lasso model. We then used these models and the ALFAM2 model to compare five slurry management techniques, varying in application method (trailing hoses, trailing shoes, and open slot) and post-application incorporation, across 128 scenarios with different manure types and weather conditions. Compared to broadcast application, alternative techniques reduced emissions by a median of -13.6 % to -61.7 %. This study highlights the promise of ML models in assessing ammonia emission reduction methods, while emphasizing the importance of evaluating model sensitivity to algorithm choice.",
      "authors": "Favrot Armand; G\u00e9nermont Sophie; D\u00e9cuq C\u00e9line; Makowski David",
      "year": "2026",
      "journal": "Journal of environmental sciences (China)",
      "doi": "10.1016/j.jes.2025.04.045",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41177628/",
      "mesh_terms": "Ammonia; Machine Learning; Air Pollutants; Environmental Monitoring; Volatilization; Manure; Air Pollution; Agriculture; Fertilizers",
      "keywords": "ALFAM2; Air pollution; Data-driven methods; Fertilization; Model prediction",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37986713",
      "title": "Effects of stopping criterion on the growth of trees in regression random forests.",
      "abstract": "Random forests are a powerful machine learning tool that capture complex relationships between independent variables and an outcome of interest. Trees built in a random forest are dependent on several hyperparameters, one of the more critical being the node size. The original algorithm of Breiman, controls for node size by limiting the size of the parent node, so that a node cannot be split if it has less than a specified number of observations. We propose that this hyperparameter should instead be defined as the minimum number of observations in each terminal node. The two existing random forest approaches are compared in the regression context based on estimated generalization error, bias-squared, and variance of resulting predictions in a number of simulated datasets. Additionally the two approaches are applied to type 2 diabetes data obtained from the National Health and Nutrition Examination Survey. We have developed a straightforward method for incorporating weights into the random forest analysis of survey data. Our results demonstrate that generalization error under the proposed approach is competitive to that attained from the original random forest approach when data have large random error variability. The R code created from this work is available and includes an illustration.",
      "authors": "Arsham Aryana; Rosenberg Philip; Little Mark",
      "year": "2023",
      "journal": "The New England Journal of Statistics in Data Science",
      "doi": "10.51387/22-nejsds5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37986713/",
      "mesh_terms": "",
      "keywords": "Generalization error; Node size; Regression random forest",
      "pub_types": "Journal Article",
      "pmcid": "PMC10659741"
    },
    {
      "pmid": "41032036",
      "title": "Machine learning based prediction of medication adherence in heart failure using large electronic health record cohort with linkages to pharmacy-fill and neighborhood-level data.",
      "abstract": "OBJECTIVE: While timely interventions can improve medication adherence, it is challenging to identify which patients are at risk of nonadherence at point-of-care. We aim to develop and validate flexible machine learning (ML) models to predict a continuous measure of adherence to guideline-directed medication therapies (GDMTs) for heart failure (HF). MATERIALS AND METHODS: We utilized a large electronic health record (EHR) cohort of 34,697 HF patients seen at NYU Langone Health with an active prescription for \u22651 GDMT between April 01, 2021 and October 31, 2022. The outcome was adherence to GDMT measured as proportion of days covered (PDC) at 6 months following a clinical encounter. Over 120 predictors included patient-, therapy-, healthcare-, and neighborhood-level factors guided by the World Health Organization's model of barriers to adherence. We compared performance of several ML models and their ensemble (superlearner) for predicting PDC with traditional regression model (OLS) using mean absolute error (MAE) averaged across 10-fold cross-validation, % increase in MAE relative to superlearner, and predictive-difference across deciles of predicted PDC. RESULTS: Superlearner, a flexible nonparametric prediction approach, demonstrated superior prediction performance. Superlearner and quantile random forest had the lowest MAE (mean [95% CI] = 18.9% [18.7%-19.1%] for both), followed by MAEs for quantile neural network (19.5% [19.3%-19.7%]) and kernel support vector regression (19.8% [19.6%-20.0%]). Gradient boosted trees and OLS were the 2 worst performing models with 17% and 14% higher MAEs, respectively, relative to superlearner. Superlearner demonstrated improved predictive difference. CONCLUSION: This development phase study suggests potential of linked EHR-pharmacy data and ML to identify HF patients who will benefit from medication adherence interventions. DISCUSSION: Fairness evaluation and external validation are needed prior to clinical integration.",
      "authors": "Adhikari Samrachana; Stokes Tyrel; Li Xiyue; Zhao Yunan; Fitchett Cassidy; Ladino Nathalia; Lawrence Steven; Qian Min; Cho Young S; Hamo Carine; Dodson John A; Chunara Rumi; Kronish Ian M; Mukhopadhyay Amrita; Blecker Saul B",
      "year": "2025",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf162",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41032036/",
      "mesh_terms": "Humans; Heart Failure; Machine Learning; Electronic Health Records; Male; Female; Aged; Middle Aged; Cohort Studies; Medication Adherence",
      "keywords": "heart failure; medication adherence; quantile machine learning; superlearner",
      "pub_types": "Journal Article",
      "pmcid": "PMC12646373"
    },
    {
      "pmid": "39430803",
      "title": "Artificial intelligence-generated feedback on social signals in patient-provider communication: technical performance, feedback usability, and impact.",
      "abstract": "OBJECTIVES: Implicit bias perpetuates health care inequities and manifests in patient-provider interactions, particularly nonverbal social cues like dominance. We investigated the use of artificial intelligence (AI) for automated communication assessment and feedback during primary care visits to raise clinician awareness of bias in patient interactions. MATERIALS AND METHODS: (1) Assessed the technical performance of our AI models by building a machine-learning pipeline that automatically detects social signals in patient-provider interactions from 145 primary care visits. (2) Engaged 24 clinicians to design usable AI-generated communication feedback for their workflow. (3) Evaluated the impact of our AI-based approach in a prospective cohort of 108 primary care visits. RESULTS: Findings demonstrate the feasibility of AI models to identify social signals, such as dominance, warmth, engagement, and interactivity, in nonverbal patient-provider communication. Although engaged clinicians preferred feedback delivered in personalized dashboards, they found nonverbal cues difficult to interpret, motivating social signals as an alternative feedback mechanism. Impact evaluation demonstrated fairness in all AI models with better generalizability of provider dominance, provider engagement, and patient warmth. Stronger clinician implicit race bias was associated with less provider dominance and warmth. Although clinicians expressed overall interest in our AI approach, they recommended improvements to enhance acceptability, feasibility, and implementation in telehealth and medical education contexts. DISCUSSION AND CONCLUSION: Findings demonstrate promise for AI-driven communication assessment and feedback systems focused on social signals. Future work should improve the performance of this approach, personalize models, and contextualize feedback, and investigate system implementation in educational workflows. This work exemplifies a systematic, multistage approach for evaluating AI tools designed to raise clinician awareness of implicit bias and promote patient-centered, equitable health care interactions.",
      "authors": "Bedmutha Manas Satish; Bascom Emily; Sladek Kimberly R; Tobar Kelly; Casanova-Perez Reggie; Andreiu Alexandra; Bhat Amrit; Mangal Sabrina; Wood Brian R; Sabin Janice; Pratt Wanda; Weibel Nadir; Hartzler Andrea L",
      "year": "2024",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooae106",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39430803/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; implicit.\u201d; interpersonal relations; nonverbal communication; primary health care/patient-centered care; social interaction; \u201cprejudice/bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC11488971"
    },
    {
      "pmid": "31617899",
      "title": "An augmented estimation procedure for EHR-based association studies accounting for differential misclassification.",
      "abstract": "OBJECTIVES: The ability to identify novel risk factors for health outcomes is a key strength of electronic health record (EHR)-based research. However, the validity of such studies is limited by error in EHR-derived phenotypes. The objective of this study was to develop a novel procedure for reducing bias in estimated associations between risk factors and phenotypes in EHR data. MATERIALS AND METHODS: The proposed method combines the strengths of a gold-standard phenotype obtained through manual chart review for a small validation set of patients and an automatically-derived phenotype that is available for all patients but is potentially error-prone (hereafter referred to as the algorithm-derived phenotype). An augmented estimator of associations is obtained by optimally combining these 2 phenotypes. We conducted simulation studies to evaluate the performance of the augmented estimator and conducted an analysis of risk factors for second breast cancer events using data on a cohort from Kaiser Permanente Washington. RESULTS: The proposed method was shown to reduce bias relative to an estimator using only the algorithm-derived phenotype and reduce variance compared to an estimator using only the validation data. DISCUSSION: Our simulation studies and real data application demonstrate that, compared to the estimator using validation data only, the augmented estimator has lower variance (ie, higher statistical efficiency). Compared to the estimator using error-prone EHR-derived phenotypes, the augmented estimator has smaller bias. CONCLUSIONS: The proposed estimator can effectively combine an error-prone phenotype with gold-standard data from a limited chart review in order to improve analyses of risk factors using EHR data.",
      "authors": "Tong Jiayi; Huang Jing; Chubak Jessica; Wang Xuan; Moore Jason H; Hubbard Rebecca A; Chen Yong",
      "year": "2020",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocz180",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31617899/",
      "mesh_terms": "Algorithms; Bias; Data Warehousing; Electronic Health Records; Humans",
      "keywords": "association study; bias reduction; differential misclassification; electronic health records; error in phenotype",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7025368"
    },
    {
      "pmid": "34080853",
      "title": "Elucidating an Atmospheric Brown Carbon Species-Toward Supplanting Chemical Intuition with Exhaustive Enumeration and Machine Learning.",
      "abstract": "Brown carbon (BrC) is involved in atmospheric light absorption and climate forcing and can cause adverse health effects. Understanding the formation mechanisms and molecular structure of BrC is of key importance in developing strategies to control its environment and health impact. Structure determination of BrC is challenging, due to the lack of experiments providing molecular fingerprints and the sheer number of molecular candidates with identical mass. Suggestions based on chemical intuition are prone to errors due to the inherent bias. We present an unbiased algorithm, using graph-based molecule generation and machine learning, which can identify all molecular structures of compounds involved in biomass burning and the composition of BrC. We apply this algorithm to C12H12O7, a light-absorbing \"test case\" molecule identified in chamber experiments on the aqueous photo-oxidation of syringol, a prevalent marker in wood smoke. Of the 260 million molecular graphs, the algorithm leaves only 36,518 (0.01%) as viable candidates matching the spectrum. Although no unique molecular structure is obtained from only a chemical formula and a UV/vis absorption spectrum, we discuss further reduction strategies and their efficacy. With additional data, the method can potentially more rapidly identify isomers extracted from lab and field aerosol particles without introducing human bias.",
      "authors": "Tapavicza Enrico; von Rudorff Guido Falk; De Haan David O; Contin Mario; George Christian; Riva Matthieu; von Lilienfeld O Anatole",
      "year": "2021",
      "journal": "Environmental science & technology",
      "doi": "10.1021/acs.est.1c00885",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34080853/",
      "mesh_terms": "Aerosols; Biomass; Carbon; Humans; Intuition; Machine Learning",
      "keywords": "biomass burning; chemical diversity; chemical space; light absorption; oligomers; structure determination",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "37398113",
      "title": "A Roadmap to Artificial Intelligence (AI): Methods for Designing and Building AI ready Data for Women's Health Studies.",
      "abstract": "OBJECTIVES: Evaluating methods for building data frameworks for application of AI in large scale datasets for women's health studies. METHODS: We created methods for transforming raw data to a data framework for applying machine learning (ML) and natural language processing (NLP) techniques for predicting falls and fractures. RESULTS: Prediction of falls was higher in women compared to men. Information extracted from radiology reports was converted to a matrix for applying machine learning. For fractures, by applying specialized algorithms, we extracted snippets from dual x-ray absorptiometry (DXA) scans for meaningful terms usable for predicting fracture risk. DISCUSSION: Life cycle of data from raw to analytic form includes data governance, cleaning, management, and analysis. For applying AI, data must be prepared optimally to reduce algorithmic bias. CONCLUSION: Algorithmic bias is harmful for research using AI methods. Building AI ready data frameworks that improve efficiency can be especially valuable for women's health.",
      "authors": "Kidwai-Khan Farah; Wang Rixin; Skanderson Melissa; Brandt Cynthia A; Fodeh Samah; Womack Julie A",
      "year": "2023",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2023.05.25.23290399",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37398113/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Preprint; Journal Article",
      "pmcid": "PMC10312839"
    },
    {
      "pmid": "37954527",
      "title": "Causal AI with Real World Data: Do Statins Protect from Alzheimer's Disease Onset?",
      "abstract": "Causal artificial intelligence aims at developing bias-robust models that can be used to intervene on, rather than just be predictive, of risks or outcomes. However, learning interventional models from observational data, including electronic health records (EHR), is challenging due to inherent bias, e.g., protopathic, confounding, collider. When estimating the effects of treatment interventions, classical approaches like propensity score matching are often used, but they pose limitations with large feature sets, nonlinear/nonparallel treatment group assignments, and collider bias. In this work, we used data from a large EHR consortium -OneFlorida- and evaluated causal statistical/machine learning methods for determining the effect of statin treatment on the risk of Alzheimer's disease, a debated clinical research question. We introduced a combination of directed acyclic graph (DAG) learning and comparison with expert's design, with calculation of the generalized adjustment criterion (GAC), to find an optimal set of covariates for estimation of treatment effects -ameliorating collider bias. The DAG/CAC approach was assessed together with traditional propensity score matching, inverse probability weighting, virtual-twin/counterfactual random forests, and deep counterfactual networks. We showed large heterogeneity in effect estimates upon different model configurations. Our results did not exclude a protective effect of statins, where the DAG/GAC point estimate aligned with the maximum credibility estimate, although the 95% credibility interval included a null effect, warranting further studies and replication.",
      "authors": "Prosperi Mattia; Salemi Marco; Ghosh Shantanu; Lyu Tianchen; Bian Jiang; Chen Zhaoyi; Zhao Jinying",
      "year": "2021",
      "journal": "ICMHI 2021 : 2021 5th International Conference on Medical and Health Informatics : May 14-16, 2021, Kyoto, Japan. International Conference on Medical and Health Informatics (5th : 2021 : Online)",
      "doi": "10.1145/3472813.3473206",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37954527/",
      "mesh_terms": "",
      "keywords": "Bayesian network; Causal artificial intelligence; biomedical informatics; directed acyclic graph; electronic medical records; generalized adjustment criterion; machine learning; treatment effect",
      "pub_types": "Journal Article",
      "pmcid": "PMC10636706"
    },
    {
      "pmid": "39317499",
      "title": "Prevention of adverse HIV treatment outcomes: machine learning to enable proactive support of people at risk of HIV care disengagement in Tanzania.",
      "abstract": "OBJECTIVES: This study aimed to develop a machine learning (ML) model to predict disengagement from HIV care, high viral load or death among people living with HIV (PLHIV) with the goal of enabling proactive support interventions in Tanzania. The algorithm addressed common challenges when applying ML to electronic medical record (EMR) data: (1) imbalanced outcome distribution; (2) heterogeneity across multisite EMR data and (3) evolving virological suppression thresholds. DESIGN: Observational study using a national EMR database. SETTING: Conducted in two regions in Tanzania, using data from the National HIV Care database. PARTICIPANTS: The study included over 6 million HIV care visit records from 295 961 PLHIV in two regions in Tanzania's National HIV Care database from January 2015 to May 2023. RESULTS: Our ML model effectively identified PLHIV at increased risk of adverse outcomes. Key predictors included past disengagement from care, antiretroviral therapy (ART) status (which tracks a patient's engagement with ART across visits), age and time on ART. The downsampling approach we implemented effectively managed imbalanced data to reduce prediction bias. Site-specific algorithms performed better compared with a universal approach, highlighting the importance of tailoring ML models to local contexts. A sensitivity analysis confirmed the model's robustness to changes in viral load suppression thresholds. CONCLUSIONS: ML models leveraging large-scale databases of patient data offer significant potential to identify PLHIV for interventions to enhance engagement in HIV care in resource-limited settings. Tailoring algorithms to local contexts and flexibility towards evolving clinical guidelines are essential for maximising their impact.",
      "authors": "Xie Zhongming; Hu Huiyu; Kadota Jillian L; Packel Laura J; Mlowe Matilda; Kwilasa Sylvester; Maokola Werner; Shabani Siraji; Sabasaba Amon; Njau Prosper F; Wang Jingshen; McCoy Sandra I",
      "year": "2024",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2024-088782",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39317499/",
      "mesh_terms": "Humans; HIV Infections; Tanzania; Machine Learning; Female; Adult; Male; Electronic Health Records; Middle Aged; Viral Load; Anti-HIV Agents; Young Adult; Algorithms; Adolescent; Treatment Outcome",
      "keywords": "HIV & AIDS; electronic health records; machine learning",
      "pub_types": "Journal Article; Observational Study; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11423721"
    },
    {
      "pmid": "39267699",
      "title": "Ethical trade-offs in AI for mental health.",
      "abstract": "It is expected that machine learning algorithms will enable better diagnosis, prognosis, and treatment in psychiatry. A central argument for deploying algorithmic methods in clinical decision-making in psychiatry is that they may enable not only faster and more accurate clinical judgments but also that they may provide a more objective foundation for clinical decisions. This article argues that the outputs of algorithms are never objective in the sense of being unaffected by human values and possibly biased choices. And it suggests that the best way to approach this is to ensure awareness of and transparency about the ethical trade-offs that must be made when developing an algorithm for mental health.",
      "authors": "Holm Sune",
      "year": "2024",
      "journal": "Frontiers in psychiatry",
      "doi": "10.3389/fpsyt.2024.1407562",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39267699/",
      "mesh_terms": "",
      "keywords": "AI; decision-making; diagnosis; explainability; fairness; mental health; psychiatry",
      "pub_types": "Journal Article",
      "pmcid": "PMC11390554"
    },
    {
      "pmid": "40466089",
      "title": "Integrating Nurse Preferences Into AI-Based Scheduling Systems: Qualitative Study.",
      "abstract": "BACKGROUND: Nurse scheduling is a complex challenge in health care, impacting both patient care quality and nurse well-being. Traditional scheduling methods often fail to consider individual preferences, leading to dissatisfaction, burnout, and high turnover. Inadequate scheduling practices, including restricted autonomy and lack of transparency, can further reduce nurse morale and negatively affect patient outcomes. Research suggests that participative scheduling approaches incorporating nurse preferences can improve job satisfaction. Artificial intelligence (AI) and mathematical optimization methods, such as mixed-integer programming (MIP), constraint programming (CP), genetic programming (GP), and reinforcement learning (RL), offer potential solutions to optimize scheduling and address these challenges. OBJECTIVE: This study aims to develop a framework for integrating nurses' preferences into AI-supported scheduling methods by gathering qualitative insights from nurses and supervisors and mapping these to mathematical and AI-based scheduling techniques. METHODS: Focus group interviews were conducted with 21 participants (nurses, supervisors, and temporary staff) from Swiss health care institutions to understand experiences and preferences related to staff scheduling. Qualitative data were analyzed using open and axial coding to extract key themes. These themes were then mapped to AI methodologies, including MIP, CP, GP, and RL, based on their suitability to address identified scheduling challenges. RESULTS: The study revealed key priorities in nurse scheduling. Fairness and participation were highlighted by 85% (18/21) of interview participants, emphasizing the need for transparent and inclusive scheduling. Flexibility and autonomy were preferred by 76% (16/21), favoring shift swaps and self-scheduling. AI expectations were mixed: 62% (13/21) saw potential for improved efficiency and fairness, while 38% (8/21) expressed concerns over reliability and loss of human oversight. Mapping to AI methods showed MIP as effective for fair shift allocation, CP for complex rule-based conditions, GP for handling unforeseen absences, and RL for dynamic schedule adaptation in hospital environments. A preliminary AI implementation of MIP in a training hospital unit (35 staff members) showed how to design a system from a mathematical perspective. CONCLUSIONS: AI-supported scheduling systems can significantly enhance fairness, transparency, and efficiency in nurse scheduling. However, concerns regarding AI reliability, adaptability to individual needs, and human oversight must be addressed. A hybrid approach integrating AI recommendations with human decision-making may be optimal. Future research should explore the broader implementation of AI-driven scheduling models and assess their impact on nurse satisfaction and patient outcomes over time.",
      "authors": "Renggli Fabienne Josefine; Gerlach Maisa; Bieri Jannic Stefan; Golz Christoph; Sariyar Murat",
      "year": "2025",
      "journal": "JMIR formative research",
      "doi": "10.2196/67747",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40466089/",
      "mesh_terms": "Humans; Qualitative Research; Artificial Intelligence; Personnel Staffing and Scheduling; Female; Male; Job Satisfaction; Adult; Focus Groups; Middle Aged; Attitude of Health Personnel; Nurses; Nursing Staff, Hospital",
      "keywords": "AI; AI-based scheduling; CP; LLM; MIP; ML; NLP; RL; artificial intelligence; burnout; comprehensive framework; constraint programming; dissatisfaction; feasibility; interview; large language model; machine learning; mixed-integer programming; natural language processing; nurse scheduling; reinforcement learning; well-being; work-life balance",
      "pub_types": "Journal Article",
      "pmcid": "PMC12157959"
    },
    {
      "pmid": "29500014",
      "title": "An ensemble boosting model for predicting transfer to the pediatric intensive care unit.",
      "abstract": "BACKGROUND: Early deterioration indicators have the potential to alert hospital care staff in advance of adverse events, such as patients requiring an increased level of care, or the need for rapid response teams to be called. Our work focuses on the problem of predicting the transfer of pediatric patients from the general ward of a hospital to the pediatric intensive care unit. OBJECTIVES: The development of a data-driven pediatric early deterioration indicator for use by clinicians with the purpose of predicting encounters where transfer from the general ward to the PICU is likely. METHODS: Using data collected over 5.5 years from the electronic health records of two medical facilities, we develop machine learning classifiers based on adaptive boosting and gradient tree boosting. We further combine these learned classifiers into an ensemble model and compare its performance to a modified pediatric early warning score (PEWS) baseline that relies on expert defined guidelines. To gauge model generalizability, we perform an inter-facility evaluation where we train our algorithm on data from one facility and perform evaluation on a hidden test dataset from a separate facility. RESULTS: We show that improvements are witnessed over the modified PEWS baseline in accuracy (0.77 vs. 0.69), sensitivity (0.80 vs. 0.68), specificity (0.74 vs. 0.70) and AUROC (0.85 vs. 0.73). CONCLUSIONS: Data-driven, machine learning algorithms can improve PICU transfer prediction accuracy compared to expertly defined systems, such as a modified PEWS, but care must be taken in the training of such approaches to avoid inadvertently introducing bias into the outcomes of these systems.",
      "authors": "Rubin Jonathan; Potes Cristhian; Xu-Wilson Minnan; Dong Junzi; Rahman Asif; Nguyen Hiep; Moromisato David",
      "year": "2018",
      "journal": "International journal of medical informatics",
      "doi": "10.1016/j.ijmedinf.2018.01.001",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29500014/",
      "mesh_terms": "Algorithms; Artificial Intelligence; Child; Child, Hospitalized; Female; Health Services Needs and Demand; Humans; Intensive Care Units, Pediatric; Machine Learning; Male; Models, Statistical; Patient Transfer; ROC Curve; Retrospective Studies; Severity of Illness Index",
      "keywords": "Early deterioration indicator; Early warning systems; Machine learning; Pediatrics",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40587839",
      "title": "Proposal for Using AI to Assess Clinical Data Integrity and Generate Metadata: Algorithm Development and Validation.",
      "abstract": "BACKGROUND: Evidence-based medicine combines scientific research, clinical expertise, and patient preferences to enhance the patient outcomes and improve health care quality. Clinical data are crucial in aligning medical decisions with evidence-based practices, whether derived from systematic research or real-world data sources. Quality assurance of clinical data, mainly through predictive quality algorithms and machine learning, is essential to mitigate risks such as misdiagnosis, inappropriate treatment, bias, and compromised patient safety. Furthermore, excellent quality of clinical data is a prerequisite for the replication of research results in order to gain insights from practice and real-world evidence. OBJECTIVE: This study aims to demonstrate the varying quality of medical data in primary clinical source systems at a maximum care university hospital and provide researchers with insights into data reliability through predictive quality algorithms using machine learning techniques. METHODS: A literature review was conducted to evaluate existing approaches to automated quality prediction. In addition, embedded in the process of integrating care data into a medical data integration center (MeDIC), metadata relevant to this clinical data was stored, considering factors such as data granularity and quality metrics. Completed patient cases with echocardiographic and laboratory findings as well as medication histories were selected from 2001 to 2023. Two authors manually reviewed the datasets and assigned a quality score for each entry, with 0 indicating unsatisfactory and 1 satisfactory quality. Since quality control was considered a binary problem, corresponding classifiers were used for the quality prediction. Logistic regression, k-nearest neighbors, a naive bayes classifier, a decision tree classifier, a random forest classifier, extreme gradient boosting (XGB), and support vector machines (SVM) were selected as machine learning algorithms. Based on preprocessing the dataset, training machine learning algorithms on echocardiographic, laboratory, and medication data, and assessing various prediction models, the most effective algorithms for quality classification were to be identified. The performance of the predictive quality algorithms was assessed based on accuracy, precision, recall, and scoring. RESULTS: There were 450 patient cases with complete information extracted from the MeDIC data pool. The laboratory and medication datasets had to be limited to 4000 data entries each to enable manual review; the echocardiographic datasets comprised 750 examinations. XGB demonstrated the highest performance for the echocardiographic dataset with an area under the receiver operating characteristic curve (AUC-ROC) of 84.6%. For laboratory data, SVM achieved an AUC-ROC score of 89.8%, demonstrating superior discrimination performance. Finally, regarding the medication dataset, SVM showed the most balanced performance, achieving an AUC-ROC of 65.1%, the highest of all tested models. CONCLUSIONS: This proposal presents a template for predicting data quality and incorporating the resulting quality information into the metadata of a data integration center, a concept not previously implemented. The model was deployed for data inspection using a hybrid approach that combines the trained model with conventional inspection methods.",
      "authors": "B\u00f6nisch Caroline; Schmidt Christian; Keszty\u00fcs Dorothea; Kestler Hans A; Keszty\u00fcs Tibor",
      "year": "2025",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/60204",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40587839/",
      "mesh_terms": "Humans; Algorithms; Metadata; Machine Learning; Artificial Intelligence; Reproducibility of Results; Data Accuracy",
      "keywords": "AI; accuracy; algorithm; artificial intelligence; clinical data; data integrity; data quality; development; interoperability; literature review; machine learning; metadata; model; quality; reliability; utilization; validation",
      "pub_types": "Journal Article",
      "pmcid": "PMC12234397"
    },
    {
      "pmid": "40739597",
      "title": "AI-Guided Decision Support in Acute Cardiac Care: From Chest Pain to STEMI.",
      "abstract": "Artificial intelligence (AI) is rapidly transforming the landscape of acute cardiac care, offering novel opportunities to enhance diagnostic accuracy, risk stratification, and clinical decision-making. This literature review explores the current and emerging applications of AI in managing acute cardiovascular conditions, including myocardial infarction, arrhythmias, and heart failure. Methods such as machine learning, deep learning, and natural language processing have demonstrated potential in analyzing electrocardiograms, imaging, electronic health records, and wearable data to support timely and individualized care. Despite encouraging results from retrospective studies and pilot implementations, several barriers hinder broader clinical integration. Key limitations include data quality issues, lack of model transparency, clinician skepticism, regulatory uncertainties, and concerns about equity and bias. The review emphasizes the need for prospective validation, interpretability, workflow integration, and interdisciplinary collaboration to ensure safe and effective deployment. Future directions include the development of multimodal and foundation models, AI-enabled point-of-care tools, and frameworks for bias mitigation and regulatory oversight. As AI technologies evolve, their sustainable and ethical implementation will be essential to achieving meaningful improvements in patient outcomes and health system efficiency.",
      "authors": "Tran Hadrian Hoang-Vu; Thu Audrey; Twayana Anu Radha; Fuertes Axel; Gonzalez Marco; Basta Marina; Mehta Krutagni Adwait; James Maggie; Frishman Wiliam H; Aronow Wilbert S",
      "year": "2025",
      "journal": "Cardiology in review",
      "doi": "10.1097/CRD.0000000000001016",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40739597/",
      "mesh_terms": "",
      "keywords": "acute cardiac care; algorithmic bias; artificial intelligence; cardiovascular diagnostics; clinical decision support; health equity; machine learning; precision medicine; real-time monitoring",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40514209",
      "title": "Applying Machine Learning Techniques to Predict Drug-Related Side Effect: A Policy Brief.",
      "abstract": "Drug safety is a critical aspect of public health, yet traditional detection methods may miss rare or long-term side effects. Recently, machine learning (ML) techniques have shown promise in predicting drug-related side effects earlier in the development pipeline. The objective of this policy brief was to propose evidence-based policy options for using ML techniques to predict drug-related side effects. This policy brief was developed upon a previously published scoping review of relevant studies. A secondary analysis synthesized key barriers and opportunities relevant to policy development. Key findings revealed some challenges in data standardization, interpretability, and regulatory alignment. Moreover, the results highlighted the potential of explainable ML and cross-sector collaboration to improve prediction accuracy and fairness. Five policy recommendations were proposed: (1) establishing standardized data collection and secure protocol sharing; (2) funding ML model development and rigorous validation; (3) integrating ML into drug development pipelines; (4) increasing public awareness through targeted education; and (5) implementing fairness regulations to address bias. These recommendations require joint efforts from governments, regulatory bodies, pharmaceutical firms, and academia to be implemented in practice. While ML offers transformative potential for drug safety, its real-world implementation faces ethical, regulatory, and technical hurdles. Policies must ensure model transparency, promote equity, and support infrastructure for ML adoption. Through interdisciplinary coordination and evidence-based policymaking, stakeholders can responsibly advance ML use in drug development to enhance patient outcomes.",
      "authors": "Toni Esmaeel; Ayatollahi Haleh",
      "year": "2025",
      "journal": "Inquiry : a journal of medical care organization, provision and financing",
      "doi": "10.1177/00469580251335805",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40514209/",
      "mesh_terms": "Machine Learning; Humans; Drug-Related Side Effects and Adverse Reactions; Policy Making; Health Policy",
      "keywords": "drug-related side effects and adverse reactions; health policy; machine learning; predictive models",
      "pub_types": "Journal Article",
      "pmcid": "PMC12166244"
    },
    {
      "pmid": "39834075",
      "title": "Advancing Ethical Considerations for Data Science in Injury and Violence Prevention.",
      "abstract": "Data science is an emerging field that provides new analytical methods. It incorporates novel data sources (eg, internet data) and methods (eg, machine learning) that offer valuable and timely insights into public health issues, including injury and violence prevention. The objective of this research was to describe ethical considerations for public health data scientists conducting injury and violence prevention-related data science projects to prevent unintended ethical, legal, and social consequences, such as loss of privacy or loss of public trust. We first reviewed foundational bioethics and public health ethics literature to identify key ethical concepts relevant to public health data science. After identifying these ethics concepts, we held a series of discussions to organize them under broad ethical domains. Within each domain, we examined relevant ethics concepts from our review of the primary literature. Lastly, we developed questions for each ethical domain to facilitate the early conceptualization stage of the ethical analysis of injury and violence prevention projects. We identified 4 ethical domains: privacy, responsible stewardship, justice as fairness, and inclusivity and engagement. We determined that each domain carries equal weight, with no consideration bearing more importance than the others. Examples of ethical considerations are clearly identifying project goals, determining whether people included in projects are at risk of reidentification through external sources or linkages, and evaluating and minimizing the potential for bias in data sources used. As data science methodologies are incorporated into public health research to work toward reducing the effect of injury and violence on individuals, families, and communities in the United States, we recommend that relevant ethical issues be identified, considered, and addressed.",
      "authors": "Idaikkadar Nimi; Bodin Eva; Cholli Preetam; Navon Livia; Ortmann Leonard; Banja John; Waller Lance A; Alic Alen; Yuan Keming; Law Royal",
      "year": "2025",
      "journal": "Public health reports (Washington, D.C. : 1974)",
      "doi": "10.1177/00333549241312055",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39834075/",
      "mesh_terms": "Humans; Violence; Public Health; Data Science; Wounds and Injuries; Privacy; Confidentiality",
      "keywords": "artificial intelligence; bioethics; data science; ethics; public health ethics",
      "pub_types": "Journal Article",
      "pmcid": "PMC11748135"
    },
    {
      "pmid": "41024767",
      "title": "Machine learning as an artificial intelligence application in management of chronic hepatitis B virus infection.",
      "abstract": "Let's review the role of gut microbiota in pathogenesis of chronic hepatitis B infection as addressed in by Zhu et al. Zhu et al used high-throughput technology to characterize the microbial ecosystems, which led to an explosion of various types of molecular profiling data, such as metagenomics, metatranscriptomics, and metabolomics. To analyze such data, machine learning (ML) algorithms have shown to be useful for identifying key molecular signatures, discovering potential patient stratifications, and, particularly, for generating models that can accurately predict phenotypes. Strong evidence suggests that such gut microbiome-based stratification could guide customized interventions to benefit human health. Supervised learning includes designing an algorithm to fix a pre-identified problem. To get an answer, ML software must access data that have been nominated. On the other hand, unsupervised learning does not address any pre-defined problems. Bias should be eliminated as much as possible. In unsupervised learning, an ML algorithm works to identify data patterns without any prior operator input. This can subsequently lead to elements being identified that could not be conceived by the operator. At the intersection between supervised and unsupervised learning is semi-supervised ML. Semi-supervised learning includes using a partially labeled data set. The ML algorithm utilizes unsupervised learning to label data (that has not yet been labelled) by drawing findings from the labeled data. Then, supervised techniques can be used to solve defined problems involving the labeled data. Reinforcement learning, which is similar to supervised learning in the meaning, is goal-oriented. Reinforcement learning does not need labeled data, instead, it is provided with a set of regulations on a problem. An algorithm will carry out operations to try to answer questions involving the problem. Based on obtained data of gut microbiota, various therapeutic modalities can be applied: Prebiotics, probiotics, postbiotics, engineered bacteria, bacteriophage, and novel microbe-materials therapeutic system and fecal transplantation. In conclusion, ML is an artificial intelligence application that helps in providing new perspectives on tailored therapy. Furthermore, assessing the impact of gut microbiota modification is a critical step in advanced liver disease management. These new artificial intelligence techniques although promising, still require further analysis and validation in future studies.",
      "authors": "Ezzat Wafaa Mohamed",
      "year": "2025",
      "journal": "World journal of gastroenterology",
      "doi": "10.3748/wjg.v31.i35.109776",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41024767/",
      "mesh_terms": "Humans; Hepatitis B, Chronic; Machine Learning; Gastrointestinal Microbiome; Hepatitis B virus; Algorithms; Artificial Intelligence; Antiviral Agents; Supervised Machine Learning",
      "keywords": "Artificial intelligence; Gut microbiota; Hepatitis B virus; Infection; Machine learning",
      "pub_types": "Letter",
      "pmcid": "PMC12476635"
    },
    {
      "pmid": "30864308",
      "title": "ODAL: A one-shot distributed algorithm to perform logistic regressions on electronic health records data from multiple clinical sites.",
      "abstract": "Electronic Health Records (EHR) contain extensive information on various health outcomes and risk factors, and therefore have been broadly used in healthcare research. Integrating EHR data from multiple clinical sites can accelerate knowledge discovery and risk prediction by providing a larger sample size in a more general population which potentially reduces clinical bias and improves estimation and prediction accuracy. To overcome the barrier of patient-level data sharing, distributed algorithms are developed to conduct statistical analyses across multiple sites through sharing only aggregated information. The current distributed algorithm often requires iterative information evaluation and transferring across sites, which can potentially lead to a high communication cost in practical settings. In this study, we propose a privacy-preserving and communication-efficient distributed algorithm for logistic regression without requiring iterative communications across sites. Our simulation study showed our algorithm reached comparative accuracy comparing to the oracle estimator where data are pooled together. We applied our algorithm to an EHR data from the University of Pennsylvania health system to evaluate the risks of fetal loss due to various medication exposures.",
      "authors": "Duan Rui; Boland Mary Regina; Moore Jason H; Chen Yong",
      "year": "2019",
      "journal": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30864308/",
      "mesh_terms": "Algorithms; Computational Biology; Computer Communication Networks; Computer Simulation; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Female; Fetal Death; Humans; Infant, Newborn; Information Dissemination; International Classification of Diseases; Likelihood Functions; Logistic Models; Medical Informatics; Pregnancy",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6417819"
    },
    {
      "pmid": "38746851",
      "title": "Implementation and prospective performance evaluation of an intraoperative duration prediction model using high throughput real-time data.",
      "abstract": "BACKGROUND: Accurate real-time prediction of intraoperative duration can contribute to improved perioperative outcomes. We implemented a data pipeline for extraction of real-time data from nascent anaesthesia records and silently deployed a predictive machine learning (ML) algorithm. METHODS: Clinical variables were retrieved from the electronic health record via a third-party clinical decision support platform and contemporaneously ingested into a previously developed ML model. The model was trained using 3 months data, and performance was subsequently evaluated over 10 months using continuous ranked probability score. RESULTS: The ML model made 6 173 435 predictions on 62 142 procedures. Mean continuous ranked probability score for the ML model was 27.19 (standard error 0.016) min compared with 51.66 (standard error 0.029) min for the bias-corrected scheduled duration. Linear regression did not demonstrate performance drift over the testing period. CONCLUSIONS: We implemented and silently deployed a real-time ML algorithm for predicting surgery duration. Prospective evaluation showed that model performance was preserved over a 10-month testing period.",
      "authors": "Jiao York; Kannampallil Thomas",
      "year": "2024",
      "journal": "BJA open",
      "doi": "10.1016/j.bjao.2024.100285",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38746851/",
      "mesh_terms": "",
      "keywords": "machine learning; perioperative medicine; statistical models; surgical duration",
      "pub_types": "Journal Article",
      "pmcid": "PMC11091514"
    },
    {
      "pmid": "38699316",
      "title": "Precision Phenotyping for Curating Research Cohorts of Patients with Post-Acute Sequelae of COVID-19 (PASC) as a Diagnosis of Exclusion.",
      "abstract": "Scalable identification of patients with the post-acute sequelae of COVID-19 (PASC) is challenging due to a lack of reproducible precision phenotyping algorithms and the suboptimal accuracy, demographic biases, and underestimation of the PASC diagnosis code (ICD-10 U09.9). In a retrospective case-control study, we developed a precision phenotyping algorithm for identifying research cohorts of PASC patients, defined as a diagnosis of exclusion. We used longitudinal electronic health records (EHR) data from over 295 thousand patients from 14 hospitals and 20 community health centers in Massachusetts. The algorithm employs an attention mechanism to exclude sequelae that prior conditions can explain. We performed independent chart reviews to tune and validate our precision phenotyping algorithm. Our PASC phenotyping algorithm improves precision and prevalence estimation and reduces bias in identifying Long COVID patients compared to the U09.9 diagnosis code. Our algorithm identified a PASC research cohort of over 24 thousand patients (compared to about 6 thousand when using the U09.9 diagnosis code), with a 79.9 percent precision (compared to 77.8 percent from the U09.9 diagnosis code). Our estimated prevalence of PASC was 22.8 percent, which is close to the national estimates for the region. We also provide an in-depth analysis outlining the clinical attributes, encompassing identified lingering effects by organ, comorbidity profiles, and temporal differences in the risk of PASC. The PASC phenotyping method presented in this study boasts superior precision, accurately gauges the prevalence of PASC without underestimating it, and exhibits less bias in pinpointing Long COVID patients. The PASC cohort derived from our algorithm will serve as a springboard for delving into Long COVID's genetic, metabolomic, and clinical intricacies, surmounting the constraints of recent PASC cohort studies, which were hampered by their limited size and available outcome data.",
      "authors": "Azhir Alaleh; H\u00fcgel Jonas; Tian Jiazi; Cheng Jingya; Bassett Ingrid V; Bell Douglas S; Bernstam Elmer V; Farhat Maha R; Henderson Darren W; Lau Emily S; Morris Michele; Semenov Yevgeniy R; Triant Virginia A; Visweswaran Shyam; Strasser Zachary H; Klann Jeffrey G; Murphy Shawn N; Estiri Hossein",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.04.13.24305771",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38699316/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Preprint; Journal Article",
      "pmcid": "PMC11065031"
    },
    {
      "pmid": "41302288",
      "title": "Incompleteness of Electronic Health Records: An Impending Process Problem Within Healthcare.",
      "abstract": "BACKGROUND: The digitization of health records was expected to improve data quality and accessibility, yet incompleteness remains a widespread challenge that undermines clinical care, interoperability, and downstream analytics. PROBLEM: Evidence shows that missing and under-recorded elements in electronic health records (EHRs) are largely driven by process gaps across patients, providers, technology, and policy-not solely by technical limitations. OBJECTIVE: This perspective integrates conceptual foundations of incompleteness, synthesizes cross-country evidence, and examines process-level drivers and consequences, with an emphasis on how missingness propagates bias in AI and machine learning systems. Contribution: We present a unifying taxonomy, highlight complementary approaches (e.g., Record Strength Score, distributional testing, and workflow studies), and we propose a pragmatic agenda for mitigation through technical, organizational, governance, and patient-centered levers. CONCLUSIONS: While EHR incompleteness cannot be fully eliminated, it can be systematically mitigated through standards, workflow redesign, patient engagement, and governance-essential steps toward building safe, equitable, and effective learning health systems.",
      "authors": "Gurupur Varadraj; Hooshmand Sahar; Prabhu Deepa Fernandes; Trader Elizabeth; Salvi Sanket",
      "year": "2025",
      "journal": "Healthcare (Basel, Switzerland)",
      "doi": "10.3390/healthcare13222900",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41302288/",
      "mesh_terms": "",
      "keywords": "bias; clinical documentation; data quality; electronic health records; global health; incompleteness; interoperability; machine learning; missing data; process improvement",
      "pub_types": "Journal Article",
      "pmcid": "PMC12652376"
    },
    {
      "pmid": "41393045",
      "title": "Ethical challenges in scene understanding for public health AI.",
      "abstract": "INTRODUCTION: Integrating AI into public health introduces complex ethical challenges, especially in scene understanding, where automated decisions affect socially sensitive contexts. In contexts requiring heightened sensitivity, including disease surveillance, patient monitoring, and behavioral analysis, the interpretability, fairness, and accountability of AI systems are crucial parameters. Conventional approaches to ethical modeling in AI often impose normative concerns as external constraints, resulting in post-hoc evaluations that fail to address ethical tensions in real time. These deficiencies are especially problematic in public health applications, where decision making must safeguard privacy, foster social trust, and accommodate diverse moral frameworks. METHODS: To address these limitations, this study introduces a methodological framework that integrates ethical reasoning into the learning architecture itself. The proposed model, VirtuNet, incorporates deontic constraints and stakeholder preferences within its computational pathways, embedding ethical admissibility into both representation and decision processes. Moreover, a dynamic conflict-resolution mechanism, reflective equilibriumstrategy, is developed to adapt policy behavior in response to evolving ethical considerations, facilitating principled moral deliberation under uncertainty. This dual-structured approach, combining embedded normative templates with adaptive strategic mechanisms, ensures that AI behaviors align with public health values such as transparency, accountability, and privacy preservation. RESULTS AND DISCUSSION: Experimental evaluations reveal that the framework achieves superior ethical alignment, reduced norm violations, and improved adaptability compared to traditional constraint-based systems. By bridging formal ethics, machine learning, and public interest imperatives, this work establishes a foundation for deploying ethically resilient AI in public health scenarios demanding trust, legality, and respect for human dignity.",
      "authors": "Qi Yin; Zhao Zihan",
      "year": "2025",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2025.1685813",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41393045/",
      "mesh_terms": "Humans; Public Health; Artificial Intelligence; Decision Making; Privacy",
      "keywords": "deontic constraints and stakeholder preferences; ethical reasoning; public health AI; reflective equilibrium strategy; scene understanding",
      "pub_types": "Journal Article",
      "pmcid": "PMC12698608"
    },
    {
      "pmid": "39232225",
      "title": "Why I'm committed to breaking the bias in large language models.",
      "abstract": "",
      "authors": "Rajaratnam Vaikunthan",
      "year": "2024",
      "journal": "Nature",
      "doi": "10.1038/d41586-024-02839-y",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39232225/",
      "mesh_terms": "",
      "keywords": "Ethics; Health care; Machine learning; Research management",
      "pub_types": "News",
      "pmcid": ""
    },
    {
      "pmid": "40920354",
      "title": "Artificial intelligence in nutrition science: Balancing innovation and ethical responsibility.",
      "abstract": "Artificial intelligence (AI) is increasingly applied in nutrition science to support clinical decision-making, prevent diet-related diseases such as obesity and type 2 diabetes, and improve nutrition care in both preventive and therapeutic settings. By analyzing diverse datasets, AI systems can support highly individualized nutritional guidance. We focus on machine learning applications and image recognition tools for dietary assessment and meal planning, highlighting their potential to enhance patient engagement and adherence through mobile apps and real-time feedback. Despite these advantages, challenges persist. AI-driven recommendations depend heavily on data quality and algorithm transparency, and biases may arise from unbalanced datasets that underrepresent certain populations or dietary patterns. These challenges can be mitigated through validated data sources, explainable AI systems, and mandatory professional oversight. We emphasize an approach that integrates AI responsibly within nutritional practice. It underscores the importance of ethical standards, interdisciplinary collaboration, and equitable access to ensure safe and effective implementation.",
      "authors": "Capocasa Marco; Venier Davide",
      "year": "2025",
      "journal": "Nutrition and health",
      "doi": "10.1177/02601060251375834",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40920354/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; algorithmic bias; digital health tools; ethical considerations; personalized nutrition",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34248317",
      "title": "Considerations for the Ethical Implementation of Psychological Assessment Through Social Media via Machine Learning.",
      "abstract": "The ubiquity of social media usage has led to exciting new technologies such as machine learning. Machine learning is poised to change many fields of health, including psychology. The wealth of information provided by each social media user in combination with machine learning technologies may pave the way for automated psychological assessment and diagnosis. Assessment of individuals' social media profiles using machine learning technologies for diagnosis and screening confers many benefits (i.e., time and cost efficiency, reduced recall bias, information about an individual's emotions and functioning spanning months or years, etc.); however the implementation of these technologies will pose unique challenges to the professional ethics of psychology. Namely, psychologists must understand the impact of these assessment technologies on privacy and confidentiality, informed consent, recordkeeping, bases for assessments, and diversity and justice. This paper offers a brief review of the current applications of machine learning technologies in psychology and public health, provides an overview of potential implementations in clinical settings, and introduces ethical considerations for professional psychologists. This paper presents considerations which may aid in the extension of the current Ethical Principles of Psychologists and Code of Conduct to address these important technological advancements in the field of clinical psychology.",
      "authors": "Fleming Megan N",
      "year": "2021",
      "journal": "Ethics & behavior",
      "doi": "10.1080/10508422.2020.1817026",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34248317/",
      "mesh_terms": "",
      "keywords": "Ethical Principles of Psychologists; automated assessment; machine learning in psychology; psychology; social media",
      "pub_types": "Journal Article",
      "pmcid": "PMC8261642"
    },
    {
      "pmid": "36997714",
      "title": "AI 'fairness' research held back by lack of diversity.",
      "abstract": "",
      "authors": "Wong Carissa",
      "year": "2023",
      "journal": "Nature",
      "doi": "10.1038/d41586-023-00935-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36997714/",
      "mesh_terms": "",
      "keywords": "Health care; Machine learning; Scientific community",
      "pub_types": "News",
      "pmcid": ""
    },
    {
      "pmid": "21257983",
      "title": "Impact of pesticide exposure misclassification on estimates of relative risks in the Agricultural Health Study.",
      "abstract": "BACKGROUND: The Agricultural Health Study (AHS) is a prospective study of licensed pesticide applicators and their spouses in Iowa and North Carolina. We evaluate the impact of occupational pesticide exposure misclassification on relative risks using data from the cohort and the AHS Pesticide Exposure Study (AHS/PES). METHODS: We assessed the impact of exposure misclassification on relative risks using the range of correlation coefficients observed between measured post-application urinary levels of 2,4-dichlorophenoxyacetic acid (2,4-D) and a chlorpyrifos metabolite and exposure estimates based on an algorithm from 83 AHS pesticide applications. RESULTS: Correlations between urinary levels of 2,4-D and a chlorpyrifos metabolite and algorithm estimated intensity scores were about 0.4 for 2,4-D (n=64), 0.8 for liquid chlorpyrifos (n=4) and 0.6 for granular chlorpyrifos (n=12). Correlations of urinary levels with kilograms of active ingredient used, duration of application, or number of acres treated were lower and ranged from -0.36 to 0.19. These findings indicate that a priori expert-derived algorithm scores were more closely related to measured urinary levels than individual exposure determinants evaluated here. Estimates of potential bias in relative risks based on the correlations from the AHS/PES indicate that non-differential misclassification of exposure using the algorithm would bias estimates towards the null, but less than that from individual exposure determinants. CONCLUSIONS: Although correlations between algorithm scores and urinary levels were quite good (ie, correlations between 0.4 and 0.8), exposure misclassification would still bias relative risk estimates in the AHS towards the null and diminish study power.",
      "authors": "Blair Aaron; Thomas Kent; Coble Joseph; Sandler Dale P; Hines Cynthia J; Lynch Charles F; Knott Charles; Purdue Mark P; Zahm Shelia Hoar; Alavanja Michael C R; Dosemeci Mustafa; Kamel Freya; Hoppin Jane A; Freeman Laura Beane; Lubin Jay H",
      "year": "2011",
      "journal": "Occupational and environmental medicine",
      "doi": "10.1136/oem.2010.059469",
      "url": "https://pubmed.ncbi.nlm.nih.gov/21257983/",
      "mesh_terms": "2,4-Dichlorophenoxyacetic Acid; Agriculture; Algorithms; Biomarkers; Environmental Monitoring; Humans; Occupational Exposure; Pesticides; Prospective Studies; Pyridones; Risk Assessment",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Intramural; Research Support, U.S. Gov't, Non-P.H.S.; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC3566632"
    },
    {
      "pmid": "40972228",
      "title": "Health Tech for the People (HT4P): A transdisciplinary research initiative focused on artificial intelligence tech ethics and design for health justice.",
      "abstract": "BACKGROUND: Technologies animated by artificial intelligence (AI) and machine learning proliferate in nursing's work and health care. Rapidly evolving AI technologies demand ethics and research infrastructure responsive to this dynamic landscape. PURPOSE: We founded Health Tech for the People (HT4P) to develop a critical technology ethics for more accountable, human-centered design of AI technologies. METHODS: Our HT4P framework, grounded in data feminism and design justice principles, guided projects across two priority areas: reproductive health and aging technologies. DISCUSSION: Outcomes of HT4P's first year included an ethics fellowship, five transdisciplinary symposia/workshops, community partnerships and a community-directed technology ethics seminar, and multiple projects-in-progress. CONCLUSION: Nurses have an opportunity to cultivate a radical imagination for more just and careful\u00a0tech futures. This requires us to develop ethics of technology that puts values in practice by redistributing power, acknowledging the invisible and undervalued labor and resources, and repairing long-standing injustices.",
      "authors": "Walker Rachel Rae; Dillard-Wright Jess; Karkar Ravi; Chung Joohyun; Molony Jason; Gatrall Cory Ellen",
      "year": "2025",
      "journal": "Nursing outlook",
      "doi": "10.1016/j.outlook.2025.102546",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40972228/",
      "mesh_terms": "Humans; Artificial Intelligence; Social Justice; Interdisciplinary Research; Female",
      "keywords": "Algorithmic bias; Artificial intelligence; Data feminism; Design justice; Machine learning; Tech ethics",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "26113170",
      "title": "Development and application of an automated algorithm to identify a window of consecutive days of accelerometer wear for large-scale studies.",
      "abstract": "BACKGROUND: Some accelerometer studies ask participants to document in a daily log when the device was worn. These logs are used to inform the window of consecutive days to extract from the accelerometer for analysis. Logs can be missing or inaccurate, which can introduce bias in the data. To mitigate this bias, we developed a simple computer algorithm that used data within the accelerometer to identify the window of consecutive wear days. To evaluate the algorithm's performance, we compared how well it agreed to the window of days identified by visual inspection and participant logs. FINDINGS: Participants were older women (mean age 79 years) in a cohort study that aimed to examine the relationship of objective physical activity on cardiovascular health. The study protocol requested that participants wear an accelerometer 24 h per day over nine calendar days (to capture seven consecutive wear days) and to complete daily logs. A stratified sample with (n = 75) and without (n = 100) participant logs were selected. The Objective Physical Activity and Cardiovascular Health (OPACH) algorithm was applied to the accelerometer data to identify a window of up to seven consecutive wear days. Participant logs documented dates the device was first put on, worn, and removed. Using pre-established guidelines, two independent raters visually reviewed the accelerometer data and characterized the dates representing up to seven consecutive days of 24-h wear. Average agreement level between the two raters was 90%. The percent agreement was compared between the three methods. The OPACH algorithm and visual inspection had 83% agreement in identifying a window with the same total number of days, if one or more shifts in calendar dates were allowed. For visual inspection vs. logs and algorithm vs. logs, this agreement was 81 and 74%, respectively. CONCLUSION: The OPACH algorithm can be efficiently and readily applied in large-scale accelerometer studies for the identification of a window of consecutive days of accelerometer wear. This algorithm was comparable to visual inspection and participant logs and might provide a quicker and more cost-effective alternative to selecting which data to extract from the accelerometer for analysis. TRIAL REGISTRATION: clinicaltrials.gov identifier: NCT00000611.",
      "authors": "Rillamas-Sun Eileen; Buchner David M; Di Chongzhi; Evenson Kelly R; LaCroix Andrea Z",
      "year": "2015",
      "journal": "BMC research notes",
      "doi": "10.1186/s13104-015-1229-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26113170/",
      "mesh_terms": "Accelerometry; Aged; Aged, 80 and over; Algorithms; Body Mass Index; Female; Humans; Monitoring, Ambulatory; Motor Activity; Myocardial Contraction; Self Report; Time Factors; Ventricular Function",
      "keywords": "",
      "pub_types": "Clinical Trial; Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC4482153"
    },
    {
      "pmid": "39520983",
      "title": "Precision phenotyping for curating research cohorts of patients with unexplained post-acute sequelae of COVID-19.",
      "abstract": "BACKGROUND: Scalable identification of patients with post-acute sequelae of COVID-19 (PASC) is challenging due to a lack of reproducible precision phenotyping algorithms, which has led to suboptimal accuracy, demographic biases, and underestimation of the PASC. METHODS: In a retrospective case-control study, we developed a precision phenotyping algorithm for identifying cohorts of patients with PASC. We used longitudinal electronic health records data from over 295,000 patients from 14 hospitals and 20 community health centers in Massachusetts. The algorithm employs an attention mechanism to simultaneously exclude sequelae that prior conditions can explain and include infection-associated chronic conditions. We performed independent chart reviews to tune and validate the algorithm. FINDINGS: The PASC phenotyping algorithm improves precision and prevalence estimation and reduces bias in identifying PASC cohorts compared to the ICD-10-CM code U09.9. The algorithm identified a cohort of over 24,000 patients with 79.9% precision. Our estimated prevalence of PASC was 22.8%, which is close to the national estimates for the region. We also provide in-depth analyses, encompassing identified lingering effects by organ, comorbidity profiles, and temporal differences in the risk of PASC. CONCLUSIONS: PASC precision phenotyping boasts superior precision and prevalence estimation while exhibiting less bias in identifying patients with PASC. The cohort derived from this algorithm will serve as a springboard for delving into the genetic, metabolomic, and clinical intricacies of PASC, surmounting the constraints of prior PASC cohort studies. FUNDING: This research was funded by the US National Institute of Allergy and Infectious Diseases (NIAID).",
      "authors": "Azhir Alaleh; H\u00fcgel Jonas; Tian Jiazi; Cheng Jingya; Bassett Ingrid V; Bell Douglas S; Bernstam Elmer V; Farhat Maha R; Henderson Darren W; Lau Emily S; Morris Michele; Semenov Yevgeniy R; Triant Virginia A; Visweswaran Shyam; Strasser Zachary H; Klann Jeffrey G; Murphy Shawn N; Estiri Hossein",
      "year": "2025",
      "journal": "Med (New York, N.Y.)",
      "doi": "10.1016/j.medj.2024.10.009",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39520983/",
      "mesh_terms": "Humans; COVID-19; Retrospective Studies; Case-Control Studies; Algorithms; Phenotype; Male; Female; Massachusetts; Middle Aged; Post-Acute COVID-19 Syndrome; SARS-CoV-2; Aged; Adult; Electronic Health Records; Prevalence",
      "keywords": "COVID-19; PASC; SARS-COV-2; Translation to population health; attention mechanism; long Covid; machine learning; phenotyping; post-acute sequalae",
      "pub_types": "Journal Article",
      "pmcid": "PMC11911085"
    },
    {
      "pmid": "40235516",
      "title": "NLP-enriched social determinants of health improve prediction of suicide death among the Veterans.",
      "abstract": "Predictions of suicide death of patients discharged from psychiatric hospitals (PDPH) can guide intervention efforts including intensive post-discharge case management programs, designed to reduce suicide risk among high-risk patients. This study aims to determine if additions of social and behavioral determinants of health (SBDH) as predictors could improve the prediction of suicide death of PDPH. We analyzed a cohort of 197,581 US Veterans discharged from 129 VHA psychiatric hospitals across the US between January 1, 2017, and July 1, 2019 with a total of 414,043 discharges. Predictive variables included administrative data and SBDH, the latter derived from unstructured clinical notes via a natural language processing (NLP) system and ICD codes, observed within a 365-day window prior to discharge. We evaluated the impact of SBDH on the predictive performance of two advanced models: an ensemble of traditional machine learning models and a transformer-based deep learning foundation model for electronic health records (TransformEHR). We measured sensitivity, positive predictive value (PPV), and area under the receiver operating characteristic curve (AUROC) overall and by gender. Calibration analysis was also conducted to measure model reliability. TransformEHR with SBDH achieved AUROC of 64.04. Specifically, ICD-based SBDH improved AUROC by 3.1% (95% CI, 1.6% - 4.5%) for the ensemble model and by 2.9% (95% CI, 0.5% - 5.4%) for TransformEHR, compared to models without SBDH. NLP-extracted SBDH further improved the AUROC: 1.7% (95% CI, 0.1%- 3.3%) for ensemble model and 1.8% (95% CI, 0.6%- 2.9%) for TransformEHR. TransformEHR achieved 0.2%, 0.4%, 0.8%, 1.6% PPV per 100 PDPH 7, 30, 90, 180 respectively. Moreover, TransformEHR showed superior calibration and fairness compared to ensemble model, with SBDH further improving fairness across both predictive models. In conclusion, both ICD-based SBDH and NLP-extracted SBDH improved the performance, calibration, and model fairness of prediction of suicide death for Veterans after their psychiatric discharge.",
      "authors": "Yang Zhichao; Mitra Avijit; Hu Wen; Berlowitz Dan; Yu Hong",
      "year": "2025",
      "journal": "Research square",
      "doi": "10.21203/rs.3.rs-5067562/v1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40235516/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC11998781"
    },
    {
      "pmid": "40153546",
      "title": "Accuracy of Smartphone-Mediated Snore Detection in a Simulated Real-World Setting: Algorithm Development and Validation.",
      "abstract": "BACKGROUND: High-quality sleep is essential for both physical and mental well-being. Insufficient or poor-quality sleep is linked to numerous health issues, including cardiometabolic diseases, mental health disorders, and increased mortality. Snoring-a prevalent condition-can disrupt sleep and is associated with disease states, including coronary artery disease and obstructive sleep apnea. OBJECTIVE: The SleepWatch smartphone app (Bodymatter, Inc) aims to monitor and improve sleep quality and has snore detection capabilities that were built through a machine-learning process trained on over 60,000 acoustic events. This study evaluated the accuracy of the SleepWatch snore detection algorithm in a simulated real-world setting. METHODS: The snore detection algorithm was tested by using 36 simulated snoring audio files derived from 18 participants. Each file simulated a snoring index between 30 and 600 snores per hour. Additionally, 9 files with nonsnoring sounds were tested to evaluate the algorithm's capacity to avoid false positives. Sensitivity, specificity, and accuracy were calculated for each test, and results were compared by using Bland-Altman plots and Spearman correlation to assess the statistical association between detected and actual snores. RESULTS: The SleepWatch algorithm showed an average sensitivity of 86.3% (SD 16.6%), an average specificity of 99.5% (SD 10.8%), and an average accuracy of 95.2% (SD 5.6%) across the snoring tests. The positive predictive value and negative predictive value were 98.9% (SD 2.6%) and 93.8% (SD 14.4%) respectively. The algorithm performed exceptionally well in avoiding false positives, with a specificity of 97.1% (SD 3.5%) for nonsnoring files. Inclusive of all snoring and nonsnore tests, the aggregated accuracy for all trials in this bench study was 95.6% (SD 5.3%). The Bland-Altman analysis indicated a mean bias of -29.8 (SD 41.7) snores per hour, and the Spearman correlation analysis revealed a strong positive correlation (rs=0.974; P<.001) between detected and actual snore rates. CONCLUSIONS: The SleepWatch snore detection algorithm demonstrates high accuracy and compares favorably with other snore detection apps. Aside from its broader use in sleep monitoring, SleepWatch demonstrates potential as a tool for identifying individuals at risk for sleep-disordered breathing, including obstructive sleep apnea, on the basis of the snoring index.",
      "authors": "Brown Jeffrey; Mitchell Zachary; Jiang Yu Albert; Archdeacon Ryan",
      "year": "2025",
      "journal": "JMIR formative research",
      "doi": "10.2196/67861",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40153546/",
      "mesh_terms": "Humans; Snoring; Smartphone; Algorithms; Female; Male; Adult; Mobile Applications; Sensitivity and Specificity; Middle Aged; Reproducibility of Results",
      "keywords": "Bodymatter; SleepWatch; machine learning; mobile device; mobile health; neural net; sleep apnea; sleep monitoring; sleep tracking; smartphone; smartphone application; snore detection; snore tracking",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC11970566"
    },
    {
      "pmid": "40520252",
      "title": "Synthetic data in medicine: Legal and ethical considerations for patient profiling.",
      "abstract": "Synthetic data is increasingly used in healthcare to facilitate privacy-preserving research, algorithm training, and patient profiling. By mimicking the statistical properties of real data without exposing identifiable information, synthetic data promises to resolve tensions between innovation and data protection. However, its legal and ethical implications remain insufficiently examined, particularly within the European Union (EU) regulatory landscape. This paper contributes to the emerging field of synthetic data governance by proposing a differentiated legal-ethical framework tailored to EU law. This paper follows a three-part taxonomy of synthetic data (fully synthetic, partially synthetic, and hybrid synthetic data) based on generation methods and identifiability risk. This taxonomy is situated within the broader context of the General Data Protection Regulation, the Artificial Intelligence Act, and the Medical Devices Regulation, clarifying when and how synthetic data may fall under EU regulatory scope. Focusing on patient profiling as a high-risk use case, the paper shows that while fully synthetic data may not constitute personal data, its downstream application in clinical or decision-making systems can still raise fairness, bias, and accountability concerns. The ethical analysis of profiling practices utilizing synthetic data is conducted through the lens of the four foundational biomedical principles: autonomy, beneficence, non-maleficence, and justice. The paper calls for sector-specific standards, generation quality benchmarks, and governance mechanisms aligning technical innovation with legal compliance and ethical integrity in digital health.",
      "authors": "Nisevic Maja; Milojevic Dusko; Spajic Daniela",
      "year": "2025",
      "journal": "Computational and structural biotechnology journal",
      "doi": "10.1016/j.csbj.2025.05.026",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40520252/",
      "mesh_terms": "",
      "keywords": "AI Act; Biomedical ethics; GDPR; Innovation and medicine; MDR; Patient profiling; Synthetic data",
      "pub_types": "Journal Article",
      "pmcid": "PMC12166703"
    },
    {
      "pmid": "35966822",
      "title": "Economic resilience in times of public health shock: The case of the US states.",
      "abstract": "Does adopting social distancing policies amid a health crisis, e.g., COVID-19, hurt economies? Using a machine learning approach at the intermediate stage, we applied a generalized synthetic control method to answer this question. We utilize state policy response differences. Cross-validation, a machine learning approach, is used to produce the \"counterfactual\" for adopting states-how they \"would have behaved\" without lockdown orders. We categorize states with social distancing as the treatment group and those without as the control. We employ the state time-period for fixed effects, adjusting for selection bias and endogeneity. We find significant and intuitively explicable impacts on some states, such as West Virginia, but none at the aggregate level, suggesting that social distancing may not affect the entire economy. Our work implies a resilience index utilizing the magnitude and significance of the social distancing measures to rank the states' resilience. These findings help governments and businesses better prepare for shocks.",
      "authors": "Osman Syed Muhammad Ishraque; Islam Faridul; Sakib Nazmus",
      "year": "2022",
      "journal": "Research in economics = Ricerche economiche",
      "doi": "10.1016/j.rie.2022.08.004",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35966822/",
      "mesh_terms": "",
      "keywords": "COVID-19; Economic resilience; Generalized synthetic control; Machine Learning and Causal Inference",
      "pub_types": "Journal Article",
      "pmcid": "PMC9364661"
    },
    {
      "pmid": "40261883",
      "title": "Improving clinical decision support through interpretable machine learning and error handling in electronic health records.",
      "abstract": "OBJECTIVE: To develop an electronic medical record (EMR) data processing tool that confers clinical context to machine learning (ML) algorithms for error handling, bias mitigation, and interpretability. MATERIALS AND METHODS: We present Trust-MAPS, an algorithm that translates clinical domain knowledge into high-dimensional, mixed-integer programming models that capture physiological and biological constraints on clinical measurements. EMR data are projected onto this constrained space, effectively bringing outliers to fall within a physiologically feasible range. We then compute the distance of each data point from the constrained space modeling healthy physiology to quantify deviation from the norm. These distances, termed \"trust-scores,\" are integrated into the feature space for downstream ML applications. We demonstrate the utility of Trust-MAPS by training a binary classifier for early sepsis prediction on data from the 2019 PhysioNet Computing in Cardiology Challenge, using the XGBoost algorithm and applying SMOTE for overcoming class-imbalance. RESULTS: The Trust-MAPS framework shows desirable behavior in handling potential errors and boosting predictive performance. We achieve an area under the receiver operating characteristic curve of 0.91 (95% CI, 0.89-0.92) for predicting sepsis 6 hours before onset-a marked 15% improvement over a baseline model trained without Trust-MAPS. DISCUSSIONS: Downstream classification performance improves after Trust-MAPS preprocessing, highlighting the bias reducing capabilities of the error-handling projections. Trust-scores emerge as clinically meaningful features that not only boost predictive performance for clinical decision support tasks but also lend interpretability to ML models. CONCLUSION: This work is the first to translate clinical domain knowledge into mathematical constraints, model cross-vital dependencies, and identify aberrations in high-dimensional medical data. Our method allows for error handling in EMR and confers interpretability and superior predictive power to models trained for clinical decision support.",
      "authors": "Arora Mehak; Mortagy Hassan; Dwarshuis Nathan; Wang Jeffrey; Yang Philip; Holder Andre L; Gupta Swati; Kamaleswaran Rishikesan",
      "year": "2026",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf058",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40261883/",
      "mesh_terms": "Electronic Health Records; Machine Learning; Humans; Decision Support Systems, Clinical; Algorithms; Sepsis",
      "keywords": "clinical data preprocessing; clinical decision support; context-aware algorithms; interpretable machine learning; outlier detection",
      "pub_types": "Journal Article",
      "pmcid": "PMC12758464"
    },
    {
      "pmid": "39962099",
      "title": "Stress management with HRV following AI, semantic ontology, genetic algorithm and tree explainer.",
      "abstract": "Heart Rate Variability (HRV) serves as a vital marker of stress levels, with lower HRV indicating higher stress. It measures the variation in the time between heartbeats and offers insights into health. Artificial intelligence (AI) research aims to use HRV data for accurate stress level classification, aiding early detection and well-being approaches. This study's objective is to create a semantic model of HRV features in a knowledge graph and develop an accurate, reliable, explainable, and ethical AI model for predictive HRV analysis. The SWELL-KW dataset, containing labeled HRV data for stress conditions, is examined. Various techniques like feature selection and dimensionality reduction are explored to improve classification accuracy while minimizing bias. Different machine learning (ML) algorithms, including traditional and ensemble methods, are employed for analyzing both imbalanced and balanced HRV datasets. To address imbalances, various data formats and oversampling techniques such as SMOTE and ADASYN are experimented with. Additionally, a Tree-Explainer, specifically SHAP, is used to interpret and explain the models' classifications. The combination of genetic algorithm-based feature selection and classification using a Random Forest Classifier yields effective results for both imbalanced and balanced datasets, especially in analyzing non-linear HRV features. These optimized features play a crucial role in developing a stress management system within a Semantic framework. Introducing domain ontology enhances data representation and knowledge acquisition. The consistency and reliability of the Ontology model are assessed using Hermit reasoners, with reasoning time as a performance measure. HRV serves as a significant indicator of stress, offering insights into its correlation with mental well-being. While HRV is non-invasive, its interpretation must integrate other stress assessments for a holistic understanding of an individual's stress response. Monitoring HRV can help evaluate stress management strategies and interventions, aiding individuals in maintaining well-being.",
      "authors": "Chatterjee Ayan; Riegler Michael A; Ganesh K; Halvorsen P\u00e5l",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-87510-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39962099/",
      "mesh_terms": "Humans; Heart Rate; Algorithms; Stress, Psychological; Artificial Intelligence; Semantics; Machine Learning; Male; Female; Genetic Algorithms",
      "keywords": "Data balancing; Ethical AI; Genetic algorithm; HRV; Random forest; SHAP; Semantic ontology; Stress",
      "pub_types": "Journal Article",
      "pmcid": "PMC11833117"
    },
    {
      "pmid": "41292499",
      "title": "Quantifying diagnostic signal decay in dementia: a national study of Medicare hospitalization data.",
      "abstract": "INTRODUCTION: Artificial intelligence (AI) models in healthcare require accurate diagnostic data. In dementia, diagnostic ambiguity and inconsistent coding may distort data quality. METHODS: This cohort study analyzed 2016 to 2018 Medicare Part A hospitalization claims across 3000+ U.S. counties. Seventeen International Classification of Diseases, 10th Revision dementia codes were grouped into five categories. Temporal patterns were modeled using the transitive sequential pattern mining (tSPM+) algorithm; matrix similarity and multivariable regression assessed geographic and demographic variation. RESULTS: Non-specific codes were most common. Alzheimer's and vascular dementia codes showed high regional variability. Frequent transitions from specific to non-specific codes indicated diagnostic signal decay. Counties with more rural, Medicaid-eligible, and Black or Hispanic patients had lower alignment with national patterns. DISCUSSION: Dementia documentation varies widely and systematically across the United States. Much of this reflects inconsistent diagnostic practices, not true disease differences. Signal decay introduces bias into claims-based research and AI. Linking claims to validated cohorts may improve data quality and model fairness. HIGHLIGHTS: Non-specific dementia codes dominate Medicare hospitalization data. Temporal analysis shows diagnostic signal decay over time. Geographic variation is linked to rurality and racial demographics. Signal decay poses bias risks for AI and claims-based research. Model explains 38% of variation in diagnostic pattern similarity.",
      "authors": "Spoto Federica; Tian Jiazi; H\u00fcgel Jonas; Ortega Daniel T; Ritchie Christine S; Blacker Deborah; Dominici Francesca; Patel Chirag J; Mork Daniel; Estiri Hossein",
      "year": "2025",
      "journal": "Alzheimer's & dementia : the journal of the Alzheimer's Association",
      "doi": "10.1002/alz.70945",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41292499/",
      "mesh_terms": "Humans; United States; Medicare; Dementia; Hospitalization; Cohort Studies; Male; Female; Aged; International Classification of Diseases; Artificial Intelligence",
      "keywords": "Alzheimer's disease; dementia; diagnosis coding; health disparities; health services administration; longitudinal data analysis; medical informatics; nervous system diseases; population characteristics; quality of health care; regression analysis; statistics",
      "pub_types": "Journal Article",
      "pmcid": "PMC12648117"
    },
    {
      "pmid": "39968539",
      "title": "Co-Designing an Electronic Health Record Derived Digital Dashboard to Support Fair-AI Applications in Mental Health.",
      "abstract": "Guided by interviews with end-users and in collaboration with lived-experience advisors, the Fairness Dashboard is being co-designed to promote the standardized and responsible utilization of sociodemographic data in statistical and machine learning models. This initiative aims to mitigate the potential for harm and to advance the equitable and compassionate interpretation of knowledge derived from Artificial Intelligence.",
      "authors": "Szkudlarek Patrycja; Kassam Iman; Kloiber Stefan; Maslej Marta; Hill Sean; Sikstrom Laura",
      "year": "2025",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI250005",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39968539/",
      "mesh_terms": "Electronic Health Records; Artificial Intelligence; Humans; User-Computer Interface; Mental Health",
      "keywords": "Artificial Intelligence; Health equity; digital dashboard; mental health; patient engagement",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40440641",
      "title": "Estimating the Risk of Lower Extremity Complications in Adults Newly Diagnosed With Diabetic Polyneuropathy: Retrospective Cohort Study.",
      "abstract": "BACKGROUND: Diabetes-related lower extremity complications, such as foot ulceration and amputation, are on the rise, currently affecting nearly 131 million people worldwide. Methods for early detection of individuals at high risk remain elusive. While data-driven diabetic polyneuropathy algorithms exist, high-performing, clinically useful tools to assess risk are needed to improve clinical care. OBJECTIVE: This study aimed to develop an electronic medical record-based machine learning algorithm that would predict lower extremity complications. METHODS: We conducted a retrospective longitudinal cohort study to predict the risk of lower extremity complications within 24 months of an initial diagnosis of diabetic polyneuropathy. From an initial cohort of 468,162 individuals with at least 1 diagnosis of diabetic polyneuropathy at one of 2 multispecialty health care systems (based in northern California and Colorado) between April 2012 and December 2016, we created an analytic cohort of 48,209 adults with continuous enrollment, who were newly diagnosed with no evidence of end-of-life care. The outcome was any lower extremity complication, including foot ulceration, osteomyelitis, gangrene, or lower extremity amputation. We randomly split the data into training (38,569/48209; 80%) and testing (9,640/48209; 20%) datasets. In the training dataset, we used super Learner (SL), an ensemble learning method that employs cross-validation and combines multiple candidate risk predictors, into a single risk predictor. We evaluated the performance of the SL risk predictor in the testing dataset using the receiver operating characteristic curve and a calibration plot. RESULTS: Of the 48,209 individuals in the cohort, 2327 developed a lower extremity complication during follow-up. The SL risk estimator exhibited good discrimination (AUC=0.845, 95% CI 0.826-0.863) and calibration. A modified version of our SL algorithm, simplified to facilitate real-world adoption, had only slightly reduced discrimination (AUC=0.817, 95%CI 0.797-0.837). The modified version slightly outperformed the na\u00efve logistic regression model (AUC=0.804, 95% CI 0.783-0.825) in terms of precision gained relative to the frequency of alerts and number of patients that needed to be evaluated. CONCLUSIONS: We have built a machine learning-based risk estimator with the potential to improve clinical detection of diabetic patients at high risk for lower extremity complications at the time of an initial diabetic polyneuropathy diagnosis. The algorithm exhibited good discriminant validity and calibration using only data from the electronic medical record. Additional research will be needed to identify optimal contexts and strategies for maximizing algorithmic fairness in both interpretation and deployment.",
      "authors": "Adams Alyce S; Lee Catherine; Escobar Gabriel; Bayliss Elizabeth A; Callaghan Brian; Horberg Michael; Schmittdiel Julie A; Trinacty Connie; Gilliam Lisa K; Kim Eileen; Hejazi Nima S; Ma Lin; Neugebauer Romain",
      "year": "2025",
      "journal": "JMIR diabetes",
      "doi": "10.2196/60141",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40440641/",
      "mesh_terms": "",
      "keywords": "AI; California; Colorado; USA; artificial intelligence; diabetes; diabetic; diabetic polyneuropathy; foot ulcer; logistic regression model; lower extremity; lower extremity complication; machine learning; neuropathy; regression model; risk prediction",
      "pub_types": "Journal Article",
      "pmcid": "PMC12140504"
    },
    {
      "pmid": "39830177",
      "title": "STI/HIV risk prediction model development-A novel use of public data to forecast STIs/HIV risk for men who have sex with men.",
      "abstract": "A novel automatic framework is proposed for global sexually transmissible infections (STIs) and HIV risk prediction. Four machine learning methods, namely, Gradient Boosting Machine (GBM), Random Forest (RF), XG Boost, and Ensemble learning GBM-RF-XG Boost are applied and evaluated on the Demographic and Health Surveys Program (DHSP), with thirteen features ultimately selected as the most predictive features. Classification and generalization experiments are conducted to test the accuracy, F1-score, precision, and area under the curve (AUC) performance of these four algorithms. Two imbalanced data solutions are also applied to reduce bias for classification performance improvement. The experimental results of these models demonstrate that the Random Forest algorithm yields the best results on HIV prediction, whereby the highest accuracy, and AUC are 0.99 and 0.99, respectively. The performance of the STI prediction achieves the best when the Synthetic Minority Oversampling Technique (SMOTE) is applied (Accuracy\u202f=\u202f0.99, AUC\u202f=\u202f0.99), which outperforms the state-of-the-art baselines. Two possible factors that may affect the classification and generalization performance are further analyzed. This automatic classification model helps to improve convenience and reduce the cost of HIV testing.",
      "authors": "Ji Xiaopeng; Tang Zhaohui; Osborne Sonya R; Van Nguyen Thi Phuoc; Mullens Amy B; Dean Judith A; Li Yan",
      "year": "2024",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2024.1511689",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39830177/",
      "mesh_terms": "Sexually Transmitted Diseases; HIV Infections; Sexual and Gender Minorities; Machine Learning; Adult; Humans; Male; Risk Assessment; Risk Factors; Forecasting",
      "keywords": "artificial intelligence; human immunodeficiency virus; machine learning; risk prediction; sexually transmissible infections",
      "pub_types": "Journal Article",
      "pmcid": "PMC11739126"
    },
    {
      "pmid": "39864407",
      "title": "Communication-efficient federated learning of temporal effects on opioid use disorder with data from distributed research networks.",
      "abstract": "OBJECTIVE: To develop a distributed algorithm to fit multi-center Cox regression models with time-varying coefficients to facilitate privacy-preserving data integration across multiple health systems. MATERIALS AND METHODS: The Cox model with time-varying coefficients relaxes the proportional hazards assumption of the usual Cox model and is particularly useful to model time-to-event outcomes. We proposed a One-shot Distributed Algorithm to fit multi-center Cox regression models with Time varying coefficients (ODACT). This algorithm constructed a surrogate likelihood function to approximate the Cox partial likelihood function, using patient-level data from a lead site and aggregated data from other sites. The performance of ODACT was demonstrated by simulation and a real-world study of opioid use disorder (OUD) using decentralized data from a large clinical research network across 5 sites with 69\u00a0163 subjects. RESULTS: The ODACT method precisely estimated the time-varying effects over time. In the simulation study, ODACT always achieved estimation close to that of the pooled analysis, while the meta-estimator showed considerable amount of bias. In the OUD study, the bias of the estimated hazard ratios by ODACT are smaller than those of the meta-estimator for all 7 risk factors at almost all of the time points from 0 to 2.5 years. The greatest bias of the meta-estimator was for the effects of age\u2009\u226565 years, and smoking. CONCLUSION: ODACT is a privacy-preserving and communication-efficient method for analyzing multi-center time-to-event data which allows the covariates' effects to be time-varying. ODACT provides estimates close to the pooled estimator and substantially outperforms the meta-analysis estimator. DISCUSSION: The proposed ODACT is a privacy-preserving distributed algorithm for fitting Cox models with time-varying coefficients. The limitations of ODACT include that privacy-preserving via aggregate data does rely on relatively large number of data at each individual site, and rigorous quantification of the risk of privacy leaks requires further investigation.",
      "authors": "Liang C Jason; Luo Chongliang; Kranzler Henry R; Bian Jiang; Chen Yong",
      "year": "2025",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocae313",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39864407/",
      "mesh_terms": "Humans; Opioid-Related Disorders; Proportional Hazards Models; Algorithms; Likelihood Functions; Time Factors; Computer Simulation; Federated Learning",
      "keywords": "Cox regression; distributed algorithm; electronic health records; privacy; survival; time-varying effects",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC12005629"
    },
    {
      "pmid": "40582296",
      "title": "Psychometric properties of an Iranian instrument for assessing adherence to ethical principles in the use of artificial intelligence among healthcare providers.",
      "abstract": "INTRODUCTION: Artificial Intelligence (AI) technologies, especially machine learning and deep learning, are increasingly utilized to improve diagnostic accuracy and treatment selection in healthcare. The aim of this study was to conduct psychometric properties of an instrument for assessing adherence to ethical principles in the use of AI among healthcare providers. METHODS: This study was a methodological cross-sectional research study conducted in Iran in 2024. It consisted of three major steps: the construction of items, the assessment of validity utilizing face, content, and construct validity, and the evaluation of reliability through Cronbach's alpha and the interclass correlation coefficient (ICC). RESULTS: The exploratory factor analysis yielded six major components: Accountability, Absence of bias, Irreplaceability of human, Accuracy, transparency, accessibility, fairness, and utility of outcomes, Privacy, fairness and utility in services, and Transparency of input of data and information. The final version of the study instrument consisted of 14 items and was established as a valid and reliable tool for assessing adherence to ethical principles in the use of artificial intelligence among healthcare providers, with a Cronbach's alpha value and ICC of 0.79. CONCLUSION: Our study provided a novel instrument that can be utilized in various areas to ensure adherence to ethical standards in the use of AI among healthcare service providers. Further research is necessary to offer a more comprehensive and detailed understanding of the context.",
      "authors": "Khosravi Mohsen; Herandi Yasaman; Tabatabaei Far Sedighe Sadat; Vasokolaei Ghasem Rajabi; Nejad Fatemeh Yousefi; Bouzarjomehri Hossein; Izadi Reyhane; Zare Zahra; Abdollahzade Marzie; Rahmani Hojjat; Ahmadi Marzaleh Milad",
      "year": "2025",
      "journal": "International journal of medical informatics",
      "doi": "10.1016/j.ijmedinf.2025.106019",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40582296/",
      "mesh_terms": "Iran; Humans; Psychometrics; Artificial Intelligence; Health Personnel; Cross-Sectional Studies; Reproducibility of Results; Male; Female; Surveys and Questionnaires; Adult; Guideline Adherence",
      "keywords": "Artificial intelligence; Bioethics; Delivery of health care; Digital health; Ethics",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41290059",
      "title": "Validation of a Claims-Based Algorithm for Specialist Palliative Care Delivery in Metastatic Cancer.",
      "abstract": "CONTEXT: The lack of valid methods to identify specialist palliative care (PC) delivery in population-level data impedes comprehensive understanding of its use. OBJECTIVE: To develop and validate a claims-based algorithm to identify receipt of specialist PC in Medicare beneficiaries with metastatic cancer. METHODS: We developed a claims-based algorithm to identify specialist PC, using a physician billing claim from a known PC clinician as the gold standard, retaining candidate variables with a positive predictive value (PPV) >60%. We evaluated algorithm performance and conducted simulation to measure bias resulting from algorithm use when examining the association between specialist PC and outcomes. RESULTS: We identified 1,384,750 claims from 68,121 patients. The prevalence of specialist PC was 3.8% on the claim-level and 26.8% on the patient-level. The provider specialty code for \"hospice and palliative care\" (PPV 80.4%) and the diagnosis code Z51.5 for \"encounter for palliative care\" (PPV 67.5%) were included, where claims were counted as specialist PC if they had either variable. PPV and sensitivity of the algorithm were 68.0% and 83.0% respectively on a claim-level, and 78.4% and 88.3% respectively on a patient-level. Percent bias differed by outcome (hospice 4.2%, hospice enrollment \u22653 days 5.3%, intensive care unit use in the last 30 days of life -1.7%, chemotherapy use in the last 14 days of life -1.3%). CONCLUSIONS: A simple algorithm can identify receipt of specialist PC care in Medicare claims for patients with metastatic cancer with reasonable accuracy. Algorithm use results in potentially acceptable amounts of bias, depending on study aims.",
      "authors": "Hua May; Yang Zhixin; Guo Ling; Cassel J Brian; Morrison R Sean; Li Guohua",
      "year": "2026",
      "journal": "Journal of pain and symptom management",
      "doi": "10.1016/j.jpainsymman.2025.11.016",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41290059/",
      "mesh_terms": "Humans; Palliative Care; Algorithms; Neoplasms; United States; Medicare; Male; Female; Aged; Neoplasm Metastasis; Aged, 80 and over; Insurance Claim Review; Specialization; Reproducibility of Results",
      "keywords": "Palliative care; algorithms; delivery of health care; hospices; neoplasms; predictive value of tests",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC12668232"
    },
    {
      "pmid": "40785165",
      "title": "Hidden patterns and overlooked pitfalls in AI-generated dermatology images: Beyond surface diversity.",
      "abstract": "",
      "authors": "Yeh Chao-Bin; Chen Shiuan-Chih",
      "year": "2025",
      "journal": "Journal of the European Academy of Dermatology and Venereology : JEADV",
      "doi": "10.1111/jdv.70002",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40785165/",
      "mesh_terms": "",
      "keywords": "algorithmic bias; artificial intelligence; dermatology; health equity; machine learning; skin pigmentation",
      "pub_types": "Letter",
      "pmcid": ""
    },
    {
      "pmid": "40831608",
      "title": "An artificial intelligence-based platform for personalized predictions of Metacognitive Training effectiveness.",
      "abstract": "This study introduces a machine learning (ML)-based platform aimed at predicting the effectiveness of Metacognitive Training (MCT). The platform is meant to function as an experimental prototype in the scope of a clinical research project for a decision support system to assist clinicians in tailoring treatment plans for patients with psychosis. It integrates eight ML models to evaluate MCT effectiveness under a wide range of mental health questionnaires to assess a broad spectrum of psychological symptoms. By incorporating diverse measures, the platform aims to capture a comprehensive understanding of patient profiles, enabling more precise and tailored predictions for treatment personalization. Furthermore, the transparency requirements for artificial intelligence (AI) systems, as outlined in the AI Act regulation of the European Union, are addressed through the implementation of explainable AI models, using post-hoc explanations based on SHAP analysis for each predictive model. Ethical concerns related to ensuring gender-neutral behavior in the system are tackled by conducting a disparate impact analysis, which evaluates biases present in the models enhancing the system's accountability and alignment with ethical and regulatory standards.",
      "authors": "K\u00f6nig Caroline; Copado Pedro; Vellido Alfredo; Nebot \u00c0ngela; Angulo Cecilio; Lamarca Maria; Acu\u00f1a Vanessa; Berna Fabrice; Moritz Steffen; Gaw\u0119da \u0141ukasz; Ochoa Susana",
      "year": "2025",
      "journal": "Computational and structural biotechnology journal",
      "doi": "10.1016/j.csbj.2025.07.051",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40831608/",
      "mesh_terms": "",
      "keywords": "Explainable artificial intelligence; Fairness; Feature selection; Mental health; Metacognitive Training; Personalized medicine",
      "pub_types": "Journal Article",
      "pmcid": "PMC12358636"
    },
    {
      "pmid": "41061508",
      "title": "Evaluation of three chemical transport models for extreme PM10 events in Morocco and improvement of forecasts using hybrid CTM-Random Forest models.",
      "abstract": "Particulate matter (PM10), originating from natural sources such as dust storms and human activities, significantly impacts public health and the environment. Accurate forecasting of PM10 concentrations is therefore crucial. This study aims to predict PM10 levels during extreme pollution episodes in Morocco using chemical transport models (CTMs) and to enhance these predictions with machine learning (ML) models. Three CTMs, namely CHIMERE, SILAM, and CAMS were validated during a high PM10 pollution episode that occurred between 2020 and 2021 in five Moroccan cities. Subsequently, two hybrid models combining SILAM and CHIMERE with the Random Forest (RF) algorithm were developed to improve the predictions. The performance of these hybrid models was assessed by comparing observed in situ data with predictions using statistical measures. The results demonstrate that CHIMERE and SILAM accurately forecast peak pollution levels, with strong correlations across all cities. CHIMERE, in particular, showed excellent accuracy in simulating concentration trends. In contrast, the CAMS model performed poorly due to its low spatial resolution. On the other hand, the hybrid models of SILAM-RF and CHIMERE-RF greatly improved the bias and error reductions, giving a better fit for the observed data. CHIMERE-RF performed well, offering more precise and reliable forecasts for extreme pollution events. These findings are essential for air quality monitoring during severe PM10 episodes, aiding in implementing preventive measures to minimize health risks related to PM10.",
      "authors": "Chelhaoui Youssef; El Ass Khalid; Khomsi Kenza; El Moussaoui Tawfik; Chelhaoui Khaoula",
      "year": "2025",
      "journal": "The Science of the total environment",
      "doi": "10.1016/j.scitotenv.2025.180668",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41061508/",
      "mesh_terms": "",
      "keywords": "Chemical transport models (CTMs); Extreme pollution events; Forecasting; Hybrid models; Machine learning (ML); Particulate matter (PM10)",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40755962",
      "title": "Enhancing early gestational diabetes mellitus prediction with imputation-based machine learning framework: A comparative study on real-world clinical records.",
      "abstract": "OBJECTIVE: Gestational diabetes mellitus (GDM) is one of the most common pregnancy complications. Electronic health records (EHRs) promise GDM risk prediction, but missing data poses a challenge to developing reliable and generalizable risk prediction models. This study aims to address the problem of missing EHR data in GDM prediction before 12 weeks gestation. METHODS: A total of 5066 women with singleton pregnancies, aged 18 to 50, were included in this retrospective study. This study evaluated 6 imputation methods, combined with 4 classification machine learning models. The evaluation encompassed downstream predictive performance, robustness to variable missingness, ability to restore original data distribution, and influence on feature selection based on 10-fold cross-validation. RESULTS: Our findings revealed a significant improvement in model performance with imputation. When using the top 30 features, logistic regression (LR) with multivariate imputation by chained equations using classification and regression trees (mice) achieved the highest area under the receiver operating characteristic curve of 0.6899, compared to 0.6336 for the LR model without imputation. Mice also led to the best average performance across prediction models and yielded the most accurate restoration of the original data distribution. LR models trained on data imputed by mice remained the most robust across varying levels of missingness. The classification algorithm primarily accounted for differences in predictive performance. In addition, we identified 18 key features for early GDM prediction in the Chinese population. CONCLUSION: This study demonstrates the critical role of imputation in improving the performance and fairness of GDM prediction models. The findings provide practical guidance for integrating imputation into clinical machine learning pipelines.",
      "authors": "Ma Leyao; Yang Lin; Wang Yaxin; Hao Jie; Li Yini; Ma Liangkun; Wang Ziyang; Li Ye; Zhang Suhan; Hu Mingyue; Li Jiao; Sun Yin",
      "year": "2025",
      "journal": "Digital health",
      "doi": "10.1177/20552076251352436",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40755962/",
      "mesh_terms": "",
      "keywords": "Gestational diabetes mellitus; electronic health records; imputation; machine learning; missing data; risk prediction",
      "pub_types": "Journal Article",
      "pmcid": "PMC12317186"
    },
    {
      "pmid": "23515213",
      "title": "Development of a framework for cohort simulation in cost-effectiveness analyses using a multistep ordinary differential equation solver algorithm in R.",
      "abstract": "INTRODUCTION: Dynamic processes in cost-effectiveness analysis (CEA) are typically described using cohort simulations, which can be implemented as Markov models, or alternatively using systems of ordinary differential equations (ODEs). In the field of CEA, simple and potentially inaccurate single-step algorithms are commonly used for solving ODEs, which can potentially induce bias, especially if an incorrect step size is used. The aims of this project were 1) to implement and demonstrate the use of a modern and well-established hybrid linear multistep ODE solver algorithm (LSODA) in the context of CEA using the statistical scripting language R and 2) to quantify bias in outcome for a case example CEA as generated by a commonly used single-step ODE solver algorithm. METHODS: A previously published CEA comparing the adjuvant breast cancer therapies anastrozole and tamoxifen was used as a case example to implement the computational framework. A commonly used single-step algorithm was compared with the proposed multistep algorithm to quantify bias in the single-step method. RESULTS: A framework implementing the multistep ODE solver LSODA was successfully developed. When a single-step ODE solver with step size of 1 year was used, incremental life-years gained was underestimated by 0.016 years (5.6% relative error, RE) and \u00a3158 (6.8% RE) compared with the multistep method. CONCLUSION: The framework was found suitable for the conduct of CEAs. We demonstrated how the use of single-step algorithms with insufficiently small step sizes causes unnecessary bias in outcomes measures of CEAs. Scripting languages such as R can further improve transparency, reproducibility, and overall integrity in the field of health economics.",
      "authors": "Frederix Gerardus W J; van Hasselt Johan G C; Severens Johan L; H\u00f6vels Anke M; Huitema Alwin D R; Raaijmakers Jan A M; Schellens Jan H M",
      "year": "2013",
      "journal": "Medical decision making : an international journal of the Society for Medical Decision Making",
      "doi": "10.1177/0272989X13476763",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23515213/",
      "mesh_terms": "Algorithms; Cohort Studies; Cost-Benefit Analysis",
      "keywords": "Markov model; R; cohort simulation; cost-effectiveness analysis; tamoxifen",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41534082",
      "title": "Developing a Suicide Risk Prediction Algorithm Using Electronic Health Record Data in Mental Health Care: Real-World Case Study.",
      "abstract": "BACKGROUND: Artificial intelligence (AI) offers potential solutions to address the challenges faced by a strained mental health care system, such as increasing demand for care, staff shortages, and pressured accessibility. While developing AI-based tools for clinical practice is technically feasible and has the potential to produce real-world impact, only a few are actually implemented into clinical practice. Implementation starts at the algorithm development phase, as this phase bridges theoretical innovation and practical application. The design and the way the AI tool is developed may either facilitate or hinder later implementation and use. OBJECTIVE: This study aims to examine the development process of a suicide risk prediction algorithm using real-world electronic health record (EHR) data through a qualitative case study approach for clinical use in mental health care. It explores which challenges the development team encountered in creating the algorithm and how they addressed these challenges. This study identifies key considerations for the integration of technical and clinical perspectives in algorithms, facilitating the evolution of mental health organizations toward data-driven practice. The studied algorithm remains exploratory and has not yet been implemented in clinical practice. METHODS: An exploratory, multimethod qualitative case study was conducted, using a hybrid approach with both inductive and deductive analysis. Data were collected through desk research, reflective team meetings, and iterative feedback sessions with the development team. Thematic analysis was used to identify development challenges and the team's responses. Based on these findings, key considerations for future algorithm development were derived. RESULTS: Key challenges included defining, operationalizing, and measuring suicide incidents within EHRs due to issues such as missing data, underreporting, and differences between data sources. Predicting factors were identified by consulting clinical experts; however, psychosocial variables had to be constructed as they could not directly be extracted from EHR data. Risk of bias occurred when traditional suicide prevention questionnaires, unequally distributed across patients, were used as input. Analyzing unstructured data by natural language processing was challenging due to data noise, but ultimately enabled successful sentiment analysis, which provided dynamic, clinically relevant information for the algorithm. A complex model enhanced predictive accuracy but posed challenges regarding understandability, which was highly valued by clinicians. CONCLUSIONS: To advance mental health care as a data-driven field, several critical considerations must be addressed: ensuring robust data governance and quality, fostering cultural shifts in data documentation practices, establishing mechanisms for continuous monitoring of AI tool usage, mitigating risks of bias, balancing predictive performance with explainability, and maintaining a clinician \"in-the-loop\" approach. Future research should prioritize sociotechnical aspects related to the development, implementation, and daily use of AI in mental health care practice.",
      "authors": "Hummel Linda; Lorenz-Artz Karin C A G; Bierbooms Joyce J P A; Bongers Inge M B",
      "year": "2026",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/74240",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41534082/",
      "mesh_terms": "Electronic Health Records; Humans; Algorithms; Risk Assessment; Qualitative Research; Mental Health Services; Artificial Intelligence; Suicide; Suicide Prevention; Prediction Algorithms",
      "keywords": "artificial intelligence; electronic health records; implementation science; mental mealth services; prediction algorithms; suicide prevention",
      "pub_types": "Journal Article",
      "pmcid": "PMC12803502"
    },
    {
      "pmid": "20651865",
      "title": "The New Zealand Advanced Choice of Employment (ACE) Scheme: analysis after 7 years of District Health Board cooperation in a competitive employment context.",
      "abstract": "AIM: The Advanced Choice of Employment Scheme (ACE) coordinates the appointment of postgraduate year 1 doctors in New Zealand (NZ). ACE is a voluntary collaborative operation by all 21 of NZ's District Health Boards (DHBs). This audit evaluates the performance of ACE over its first 7 years of operation. METHODS: The proportion of applicants successfully matched and the correlation between their preferred and matched DHBs was evaluated. Qualitative performance was assessed through survey of NZ trainee interns (TIs). RESULTS: Nearly all (99-100%) NZ TIs using ACE have been successfully matched each year. Most (96-99%) of the successful applicants have been matched to one of their top-four preferred DHBs, and a mean of 81% to their most-preferred choice. Qualitative satisfaction with ACE was high (90% good). Applicant concerns included the usability of the online application portal and uncertainty about the fairness of the ACE algorithm. CONCLUSION: The ACE scheme has been highly successful for allocating PGY1 positions over 7 years and achieves generally high applicant satisfaction. DHBs have successfully cooperated despite their competing interest in recruiting top applicants. This study supports the contention that increased collaboration between DHBs may improve efficiency within the NZ health sector.",
      "authors": "Adams Brandon M; O'Grady Gregory; Pole J Richard",
      "year": "2010",
      "journal": "The New Zealand medical journal",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/20651865/",
      "mesh_terms": "Employment; Follow-Up Studies; Humans; Internship and Residency; New Zealand; Personnel Selection; Physicians; Retrospective Studies; Time Factors",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34978638",
      "title": "What is morally at stake when using algorithms to make medical diagnoses? Expanding the discussion beyond risks and harms.",
      "abstract": "In this paper, we examine the qualitative moral impact of machine learning-based clinical decision support systems in the process of medical diagnosis. To date, discussions about machine learning in this context have focused on problems that can be measured and assessed quantitatively, such as by estimating the extent of potential harm or calculating incurred risks. We maintain that such discussions neglect the qualitative moral impact of these technologies. Drawing on the philosophical approaches of technomoral change and technological mediation theory, which explore the interplay between technologies and morality, we present an analysis of concerns related to the adoption of machine learning-aided medical diagnosis. We analyze anticipated moral issues that machine learning systems pose for different stakeholders, such as bias and opacity in the way that models are trained to produce diagnoses, changes to how health\u00a0care providers, patients, and developers understand their roles and professions, and challenges to existing forms of medical legislation. Albeit preliminary in nature, the insights offered by the technomoral change and the technological mediation approaches expand and enrich the current discussion about machine learning in diagnostic practices, bringing distinct and currently underexplored areas of concern to the forefront. These insights can contribute to a more encompassing and better informed decision-making process when adapting machine learning techniques to medical diagnosis, while acknowledging the interests of multiple stakeholders and the active role that technologies play in generating, perpetuating, and modifying ethical concerns in health care.",
      "authors": "de Boer Bas; Kudina Olya",
      "year": "2021",
      "journal": "Theoretical medicine and bioethics",
      "doi": "10.1007/s11017-021-09553-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34978638/",
      "mesh_terms": "Algorithms; Delivery of Health Care; Humans; Machine Learning; Morals",
      "keywords": "Algorithms; Ethics; Machine learning; Medical diagnosis; Technological mediation; Technomoral change",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8907081"
    },
    {
      "pmid": "34424534",
      "title": "Longitudinal Data Discontinuity in Electronic Health Records and Consequences for Medication Effectiveness Studies.",
      "abstract": "Electronic health record (EHR) discontinuity (i.e., receiving care outside of the study EHR system), can lead to information bias in EHR-based real-world evidence (RWE) studies. An algorithm has been previously developed to identify patients with high EHR-continuity. We sought to assess whether applying this algorithm to patient selection for inclusion can reduce bias caused by data-discontinuity in four RWE examples. Among Medicare beneficiaries aged >=65\u00a0years from 2007 to 2014, we established 4 cohorts assessing drug effects on short-term or long-term outcomes, respectively. We linked claims data with two US EHR systems and calculated %bias of the multivariable-adjusted effect estimates based on only EHR vs. linked EHR-claims data because the linked data capture medical information recorded outside of the study EHR. Our study cohort included 77,288 patients in system 1 and 60,309 in system 2. We found the subcohort in the lowest quartile of EHR-continuity captured 72-81% of the short-term and only 21-31% of the long-term outcome events, leading to %bias of 6-99% for the short-term and 62-112% for the long-term outcome examples. This trend appeared to be more pronounced in the example using a nonuser comparison rather than an active comparison. We did not find significant treatment effect heterogeneity by EHR-continuity for most subgroups across empirical examples. In EHR-based RWE studies, investigators may consider excluding patients with low algorithm-predicted EHR-continuity as the EHR data capture relatively few of their actual outcomes, and treatment effect estimates in these patients may be unreliable.",
      "authors": "Joshua Lin Kueiyu; Jin Yinzhu; Gagne Joshua; Glynn Robert J; Murphy Shawn N; Tong Angela; Schneeweiss Sebastian",
      "year": "2022",
      "journal": "Clinical pharmacology and therapeutics",
      "doi": "10.1002/cpt.2400",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34424534/",
      "mesh_terms": "Administrative Claims, Healthcare; Aged; Aged, 80 and over; Algorithms; Bias; Cohort Studies; Continuity of Patient Care; Electronic Health Records; Female; Humans; Longitudinal Studies; Male; Medicare; Middle Aged; Treatment Outcome; United States",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC8678205"
    },
    {
      "pmid": "26634383",
      "title": "Comparing high-dimensional confounder control methods for rapid cohort studies from electronic health records.",
      "abstract": "AIMS: Electronic health records (EHR), containing rich clinical histories of large patient populations, can provide evidence for clinical decisions when evidence from trials and literature is absent. To enable such observational studies from EHR in real time, particularly in emergencies, rapid confounder control methods that can handle numerous variables and adjust for biases are imperative. This study compares the performance of 18 automatic confounder control methods. METHODS: Methods include propensity scores, direct adjustment by machine learning, similarity matching and resampling in two simulated and one real-world EHR datasets. RESULTS & CONCLUSIONS: Direct adjustment by lasso regression and ensemble models involving multiple resamples have performance comparable to expert-based propensity scores and thus, may help provide real-time EHR-based evidence for timely clinical decisions.",
      "authors": "Low Yen Sia; Gallego Blanca; Shah Nigam Haresh",
      "year": "2016",
      "journal": "Journal of comparative effectiveness research",
      "doi": "10.2217/cer.15.53",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26634383/",
      "mesh_terms": "Algorithms; Cohort Studies; Confounding Factors, Epidemiologic; Electronic Health Records; Humans; Machine Learning; Propensity Score",
      "keywords": "bias; clinical decision support; cohort studies; confounding; electronic health records; machine learning; propensity scores",
      "pub_types": "Comparative Study; Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC4933592"
    },
    {
      "pmid": "41062565",
      "title": "The influence of higher education based on machine learning on subjective well-being.",
      "abstract": "As higher education becomes increasingly prevalent and accessible in China, a growing number of residents are afforded the option to pursue advanced studies. Can higher education genuinely enhance residents' subjective well-being? The response to this enquiry necessitates additional investigation. This study selected 5 wave data of Chinese General Social Survey (CGSS), a total of 53,874 samples. Machine learning methodologies, including XGBoost and GBDT, were utilised for the inaugural correlation investigation between higher education and subjective well-being in China. Feature importance sorting elucidated the nonlinear correlations and interaction effects, such as the threshold effect of social fairness cognition on happiness, that typical regression models struggle to capture. (1) The average subjective well-being of the higher education group (4.005309) was significantly higher than that of the non-higher education group (3.835478), and the education level had a significant positive predictive role on subjective well-being (p\u2009=\u20090.000\u2009<\u20090.05); (2) Machine learning uncovers substantial correlations between higher education and subjective well-being ([Formula: see text]=0.008, p\u2009<\u20090.01), with social justice cognition (feature weight=0.32) and self-rated health (0.28) identified as primary mediators. (3) The proportion of women in the highest level of well-being ([4.0,5.0)] was slightly higher than that of men. Higher education can markedly enhance the subjective well-being of individuals. Furthermore, it improves residents' subjective well-being via social justice perception, self-assessed health, social class identity, job satisfaction, and socio-economic status. This establishes a scientific foundation for the government and all societal sectors to augment investment in education, enhance the distribution of educational resources, and foster the comprehensive development of individuals.",
      "authors": "Qin Ting; Fu Rui; Yao Pengjian; Wei Pingqiang",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-19116-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41062565/",
      "mesh_terms": "Humans; Machine Learning; Female; Male; Adult; China; Middle Aged; Educational Status; Surveys and Questionnaires; Young Adult; Happiness; Social Justice; Personal Satisfaction",
      "keywords": "Higher education; Machine learning; Social justice cognition; Socio-economic status; Subjective well-being",
      "pub_types": "Journal Article",
      "pmcid": "PMC12508042"
    },
    {
      "pmid": "37642995",
      "title": "Sharing Data With Shared Benefits: Artificial Intelligence Perspective.",
      "abstract": "Artificial intelligence (AI) and data sharing go hand in hand. In order to develop powerful AI models for medical and health applications, data need to be collected and brought together over multiple centers. However, due to various reasons, including data privacy, not all data can be made publicly available or shared with other parties. Federated and swarm learning can help in these scenarios. However, in the private sector, such as between companies, the incentive is limited, as the resulting AI models would be available for all partners irrespective of their individual contribution, including the amount of data provided by each party. Here, we explore a potential solution to this challenge as a viewpoint, aiming to establish a fairer approach that encourages companies to engage in collaborative data analysis and AI modeling. Within the proposed approach, each individual participant could gain a model commensurate with their respective data contribution, ultimately leading to better diagnostic tools for all participants in a fair manner.",
      "authors": "Tajabadi Mohammad; Grabenhenrich Linus; Ribeiro Ad\u00e8le; Leyer Michael; Heider Dominik",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/47540",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37642995/",
      "mesh_terms": "Artificial Intelligence; Data Analysis; Information Dissemination",
      "keywords": "applications; artificial intelligence; artificial intelligence model; data analysis; data sharing; development; diagnostic tool; fairness; federated learning; machine learning; medical data; tool",
      "pub_types": "Journal Article",
      "pmcid": "PMC10498316"
    },
    {
      "pmid": "39670276",
      "title": "Multicenter Evaluation of Machine-Learning Continuous Pulse Rate Algorithm on Wrist-Worn Device.",
      "abstract": "INTRODUCTION: Though wrist-worn photoplethysmography (PPG) sensors play an important role in long-term and continuous heart rhythm monitoring, signals measured at the wrist are contaminated by more intense motion artifacts compared to other body locations. Machine learning (ML)-based algorithms can improve long-term pulse rate (PR) tracking but are associated with more stringent regulatory requirements when intended for clinical use. This study aimed to evaluate the accuracy of a digital health technology using wrist-worn PPG sensors and an ML-based algorithm to measure PR continuously. METHODS: Volunteers were enrolled in three independent clinical trials and concurrently monitored with the investigational device and FDA-cleared electrocardiography (ECG) devices during supervised protocols representative of real-life activities. The primary acceptance threshold was an accuracy root-mean-square (ARMS) \u22643 beats per minute (bpm) or 5 bpm under no-motion and motion conditions, respectively. Bias, mean absolute error (MAE), mean absolute percentage error (MAPE), limits of agreement (LoA), and Pearson and Lin's concordance correlation coefficients (\u2374 and CCC) were also computed. Subgroup and outlier analyses were conducted to examine the effect of site, skin tone, age, sex, body mass index (BMI), and health status on PR accuracy. RESULTS: Collectively, 16,915 paired observations between the device and the reference ECG were analyzed from 157 subjects (male: 49.04%, age mean: 43 years, age range: 19-83 years, BMI mean: 26.4, BMI range: 17.5-52, Fitzpatrick class V-IV: 22.9%, cardiovascular condition: 24%). The PR output attained an accuracy of 1.67 bpm under no-motion (n = 5,621 min) and 4.39 bpm under motion (n = 11,294 min), satisfying the acceptance thresholds. Bias and LoA (lower, upper LoA) were -0.09 (-3.36, 3.17) bpm under no-motion and 0.51 (-8.05, 9.06) bpm under motion. MAE was 0.6 bpm in no-motion and 1.77 bpm in motion, and MAPE was 0.86% in no-motion and 2.05% in motion, with \u2374 and CCC >0.98 in both conditions. ARMS values met the clinical acceptance threshold in all relevant subgroups at each clinical site separately, excluding male subjects under motion conditions (ARMS = 5.41 bpm), with more frequent and larger outliers due to stronger forearm contractions. However, these mostly occurred in isolation and, therefore would not impact the clinical utility or usability of the device for its intended use of retrospective review and trend analysis (\u2374 and CCC >0.97 and MAPE = 2.61%). CONCLUSION: The analytical validation conducted in this study demonstrated clinical-grade accuracy and generalizability of ML-based continuous PR estimations across a full range of physical motions, health conditions, and demographic variables known to confound PPG signals, paving the way for device usage by populations most likely to benefit from continuous PR monitoring.",
      "authors": "Chen Weixuan; Cordero Rafael; Lever Taylor Jessie; Pangallo Domenico R; Picard Rosalind W; Cruz Marisa; Regalia Giulia",
      "year": "2024",
      "journal": "Digital biomarkers",
      "doi": "10.1159/000542615",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39670276/",
      "mesh_terms": "",
      "keywords": "Digital health technologies; Machine learning; Mobile technology; Motion artifacts; Pulse rate; Wearable sensors",
      "pub_types": "Journal Article",
      "pmcid": "PMC11637493"
    },
    {
      "pmid": "41315506",
      "title": "Predicting suicide death among veterans after psychiatric hospitalization using transformer based models with social determinants and NLP.",
      "abstract": "Predictions of suicide death of patients discharged from psychiatric hospitals (PDPH) can guide intervention efforts including intensive post-discharge case management programs, designed to reduce suicide risk among high-risk patients. This study aims to determine if additions of social and behavioral determinants of health (SBDH) as predictors could improve the prediction of suicide death of PDPH. We analyzed a cohort of 197,581 US Veterans discharged from 129 VHA psychiatric hospitals across the US between January 1, 2017, and July 1, 2019 with a total of 414,043 discharges. Predictive variables included administrative data and SBDH, the latter derived from unstructured clinical notes via a natural language processing (NLP) system and ICD codes, observed within a 365-day window prior to discharge. We evaluated the impact of SBDH on the predictive performance of two advanced models: an ensemble of traditional machine learning models and a transformer-based deep learning foundation model for electronic health records (TransformEHR). We measured sensitivity, positive predictive value (PPV), and area under the receiver operating characteristic curve (AUROC) overall and by gender. Calibration analysis was also conducted to measure model reliability. TransformEHR with SBDH achieved AUROC of 64.0 Specifically, ICD-based SBDH improved AUROC by 3.1% (95% CI, 1.6% - 4.5%) for the ensemble model and by 2.9% (95% CI, 0.5% - 5.4%) for TransformEHR, compared to models without SBDH. NLP-extracted SBDH further improved the AUROC: 1.7% (95% CI, 0.1%- 3.3%) for ensemble model and 1.8% (95% CI, 0.6%- 2.9%) for TransformEHR. TransformEHR achieved 0.2%, 0.4%, 0.8%, 1.6% PPV per 100 PDPH 7, 30, 90, 180 respectively. Moreover, TransformEHR showed superior calibration and fairness compared to ensemble model, with SBDH further improving fairness across both predictive models. In conclusion, both ICD-based SBDH and NLP-extracted SBDH improved the performance, calibration, and model fairness of prediction of suicide death for Veterans after their psychiatric discharge.",
      "authors": "Yang Zhichao; Mitra Avijit; Hu Wen; Berlowitz Dan; Yu Hong",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-27435-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41315506/",
      "mesh_terms": "Humans; Veterans; Male; Female; Natural Language Processing; Suicide; Middle Aged; United States; Electronic Health Records; Hospitals, Psychiatric; Social Determinants of Health; Adult; Hospitalization; Patient Discharge; Aged; ROC Curve; Machine Learning; Risk Factors",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12698767"
    },
    {
      "pmid": "34455125",
      "title": "Training and evaluating machine learning algorithms for ocean microplastics classification through vibrational spectroscopy.",
      "abstract": "Microplastics are contaminants of emerging concern - not only environmental, but also to human health. Characterizing them is of fundamental importance to evaluate their potential impacts and target specific actions aiming to reduce potential harming effects. This study extends the exploration of machine learning classification algorithms applied to FTIR spectra of microplastics collected at sea. A comparison of successful classification models was made in order to evaluate prediction performance for 13 classes of polymers. A rigorous methodology was applied using a pipeline scheme to avoid bias in the training and selection phases. The application of an oversampling technique also contributed by compensating unbalanceness in the dataset. The log-loss was used as the minimization function target and to assess performance. In our analysis, Support Vector Machine Classifier provides a good relationship between simplicity and performance, for a fast and useful automatic characterization of microplastics.",
      "authors": "Back Henrique de Medeiros; Vargas Junior Edson Cilos; Alarcon Orestes Estevam; Pottmaier Daphiny",
      "year": "2022",
      "journal": "Chemosphere",
      "doi": "10.1016/j.chemosphere.2021.131903",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34455125/",
      "mesh_terms": "Algorithms; Environmental Monitoring; Humans; Machine Learning; Microplastics; Oceans and Seas; Plastics; Spectroscopy, Fourier Transform Infrared; Support Vector Machine",
      "keywords": "Chemical identification; FTIR; Machine learning; Marine pollution; Microplastics; Vibrational spectroscopy",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40682318",
      "title": "Beyond Adverse Childhood Experiences: What Should be Considered for Trauma-Focused Adolescent Mental Health Risk Assessments?",
      "abstract": "To align with emerging policies for adolescents, feasible, accurate, and equitable trauma-focused assessment protocols need to be developed. To date, most research on this topic has focused on whether traditional adverse childhood experiences (i.e., maltreatment, impaired caregiving) can adequately index mental health risk. Yet, there are noted clinical and statistical drawbacks to this approach. Instead, examining threat and reward biases, two subtypes of cognitive biases stemming from interpersonal trauma exposure, may provide a reasonable alternative to adversity screening. Thus, the aim of this study was to examine the accuracy and fairness of self-reported, trauma-informed cognitive vulnerabilities for classifying concurrent and prospective adolescent mental health risk relative to more commonly assessed childhood adversities. In a diverse adolescent sample (N\u2009=\u2009584; MAge\u2009=\u200914.43; 48.9% female; 35% African American; 38.5% White; 40% Hispanic) youth completed measures for adversity exposure (family, dating, and community violence), threat biases (posttraumatic cognitions, hostility), and reward biases (anticipatory, consummatory) during an initial assessment, as well as symptoms of posttraumatic stress (PTS), depression, and violent behavior at baseline and 1\u2009year later. Indices of statistical discrimination, calibration, and statistical fairness were examined using an evidence-based medicine analytic approach, which was subsequently compared to a machine learning approach. Overall, posttraumatic cognitions emerged as an accurate and statistically fair predictor of prospective PTS (area under the curve [AUC]95% CI\u2009=\u2009[0.63, 0.78]; diagnostic likelihood ratio [DLR]95% CI\u2009=\u2009[1.32, 3.52]), and to a lesser extent depression (AUC95% CI\u2009=\u2009[0.56, 0.70]; DLR95% CI\u2009=\u2009[1.25, 2.98]), and both models were well calibrated (i.e., p-value >05 for Spiegelhalter's Z test). Meanwhile, community violence (CV) exposure best classified the risk for prospective violent behavior (AUC95% CI\u2009=\u2009[0.62, 0.73]; DLR95% CI\u2009=\u2009[2.68, 5.49]), especially in males, and was well calibrated. The machine learning algorithms added limited incremental validity to our predictions. Our study suggests that focusing on posttraumatic cognitions and less invasive adversity items (i.e., CV exposure) may lead to trauma screening and assessment protocols that are accurate, equitable, and feasible to implement within applied settings serving diverse youth.",
      "authors": "Cohen Joseph R; Choi Jae Wan; Stutts Morgan; Temple Jeff R",
      "year": "2025",
      "journal": "Journal of interpersonal violence",
      "doi": "10.1177/08862605251350127",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40682318/",
      "mesh_terms": "",
      "keywords": "adolescence; evidence-based medicine; posttraumatic stress; screening; trauma; violence",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "19567795",
      "title": "A globally optimal k-anonymity method for the de-identification of health data.",
      "abstract": "BACKGROUND: Explicit patient consent requirements in privacy laws can have a negative impact on health research, leading to selection bias and reduced recruitment. Often legislative requirements to obtain consent are waived if the information collected or disclosed is de-identified. OBJECTIVE: The authors developed and empirically evaluated a new globally optimal de-identification algorithm that satisfies the k-anonymity criterion and that is suitable for health datasets. DESIGN: Authors compared OLA (Optimal Lattice Anonymization) empirically to three existing k-anonymity algorithms, Datafly, Samarati, and Incognito, on six public, hospital, and registry datasets for different values of k and suppression limits. Measurement Three information loss metrics were used for the comparison: precision, discernability metric, and non-uniform entropy. Each algorithm's performance speed was also evaluated. RESULTS: The Datafly and Samarati algorithms had higher information loss than OLA and Incognito; OLA was consistently faster than Incognito in finding the globally optimal de-identification solution. CONCLUSIONS: For the de-identification of health datasets, OLA is an improvement on existing k-anonymity algorithms in terms of information loss and performance.",
      "authors": "El Emam Khaled; Dankar Fida Kamal; Issa Romeo; Jonker Elizabeth; Amyot Daniel; Cogo Elise; Corriveau Jean-Pierre; Walker Mark; Chowdhury Sadrul; Vaillancourt Regis; Roffey Tyson; Bottomley Jim",
      "year": "2009",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1197/jamia.M3144",
      "url": "https://pubmed.ncbi.nlm.nih.gov/19567795/",
      "mesh_terms": "Adolescent; Adult; Algorithms; Confidentiality; Female; Humans; Information Storage and Retrieval; Male; Medical Records Systems, Computerized",
      "keywords": "",
      "pub_types": "Comparative Study; Evaluation Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC2744718"
    },
    {
      "pmid": "37304721",
      "title": "Machine learning enhances prediction of plants as potential sources of antimalarials.",
      "abstract": "Plants are a rich source of bioactive compounds and a number of plant-derived antiplasmodial compounds have been developed into pharmaceutical drugs for the prevention and treatment of malaria, a major public health challenge. However, identifying plants with antiplasmodial potential can be time-consuming and costly. One approach for selecting plants to investigate is based on ethnobotanical knowledge which, though having provided some major successes, is restricted to a relatively small group of plant species. Machine learning, incorporating ethnobotanical and plant trait data, provides a promising approach to improve the identification of antiplasmodial plants and accelerate the search for new plant-derived antiplasmodial compounds. In this paper we present a novel dataset on antiplasmodial activity for three flowering plant families - Apocynaceae, Loganiaceae and Rubiaceae (together comprising c. 21,100 species) - and demonstrate the ability of machine learning algorithms to predict the antiplasmodial potential of plant species. We evaluate the predictive capability of a variety of algorithms - Support Vector Machines, Logistic Regression, Gradient Boosted Trees and Bayesian Neural Networks - and compare these to two ethnobotanical selection approaches - based on usage as an antimalarial and general usage as a medicine. We evaluate the approaches using the given data and when the given samples are reweighted to correct for sampling biases. In both evaluation settings each of the machine learning models have a higher precision than the ethnobotanical approaches. In the bias-corrected scenario, the Support Vector classifier performs best - attaining a mean precision of 0.67 compared to the best performing ethnobotanical approach with a mean precision of 0.46. We also use the bias correction method and the Support Vector classifier to estimate the potential of plants to provide novel antiplasmodial compounds. We estimate that 7677 species in Apocynaceae, Loganiaceae and Rubiaceae warrant further investigation and that at least 1300 active antiplasmodial species are highly unlikely to be investigated by conventional approaches. While traditional and Indigenous knowledge remains vital to our understanding of people-plant relationships and an invaluable source of information, these results indicate a vast and relatively untapped source in the search for new plant-derived antiplasmodial compounds.",
      "authors": "Richard-Bollans Adam; Aitken Conal; Antonelli Alexandre; Bitencourt C\u00e1ssia; Goyder David; Lucas Eve; Ondo Ian; P\u00e9rez-Escobar Oscar A; Pironon Samuel; Richardson James E; Russell David; Silvestro Daniele; Wright Colin W; Howes Melanie-Jayne R",
      "year": "2023",
      "journal": "Frontiers in plant science",
      "doi": "10.3389/fpls.2023.1173328",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37304721/",
      "mesh_terms": "",
      "keywords": "antiplasmodial activity; botany; ethnobotany; ethnopharmacology; machine learning; malaria; sampling bias; traditional and indigenous knowledge",
      "pub_types": "Journal Article",
      "pmcid": "PMC10248027"
    },
    {
      "pmid": "11469231",
      "title": "Estimating log models: to transform or not to transform?",
      "abstract": "Health economists often use log models to deal with skewed outcomes, such as health utilization or health expenditures. The literature provides a number of alternative estimation approaches for log models, including ordinary least-squares on ln(y) and generalized linear models. This study examines how well the alternative estimators behave econometrically in terms of bias and precision when the data are skewed or have other common data problems (heteroscedasticity, heavy tails, etc.). No single alternative is best under all conditions examined. The paper provides a straightforward algorithm for choosing among the alternative estimators. Even if the estimators considered are consistent, there can be major losses in precision from selecting a less appropriate estimator.",
      "authors": "Manning W G; Mullahy J",
      "year": "2001",
      "journal": "Journal of health economics",
      "doi": "10.1016/s0167-6296(01)00086-8",
      "url": "https://pubmed.ncbi.nlm.nih.gov/11469231/",
      "mesh_terms": "Delivery of Health Care, Integrated; Health Expenditures; Health Services Research; Humans; Logistic Models; Models, Econometric; United States",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "39323613",
      "title": "Machine learning in cancer-associated thrombosis: hype or hope in untangling the clot.",
      "abstract": "The goal of machine learning (ML) is to create informative signals and useful tasks by leveraging large datasets to derive computational algorithms. ML has the potential to revolutionize the healthcare industry by boosting productivity, enhancing safe and effective patient care, and lightening the load on clinicians. In addition to gaining mechanistic insights into cancer-associated thrombosis (CAT), ML can be used to improve patient outcomes, streamline healthcare delivery, and spur innovation. Our review paper delves into the present and potential applications of this cutting-edge technology, encompassing three areas: i) computer vision-assisted diagnosis of thromboembolism from radiology data; ii) case detection from electronic health records using natural language processing; iii) algorithms for CAT prediction and risk stratification. The availability of large, well-annotated, high-quality datasets, overfitting, limited generalizability, the risk of propagating inherent bias, and a lack of transparency among patients and clinicians are among the challenges that must be overcome in order to effectively develop ML in the health sector. To guarantee that this powerful instrument can be utilized to maximize innovation in CAT, clinicians can collaborate with stakeholders such as computer scientists, regulatory bodies, and patient groups.",
      "authors": "Patell Rushad; Zwicker Jeffrey I; Singh Rohan; Mantha Simon",
      "year": "2024",
      "journal": "Bleeding, thrombosis and vascular biology",
      "doi": "10.4081/btvb.2024.123",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39323613/",
      "mesh_terms": "",
      "keywords": "cancer-associated thrombosis; machine learning; natural language processing; venous thromboembolism",
      "pub_types": "Journal Article",
      "pmcid": "PMC11423546"
    },
    {
      "pmid": "40721829",
      "title": "Semantic classification of Indonesian consumer health questions.",
      "abstract": "PURPOSE: Online consumer health forums serve as a way for the public to connect with medical professionals. While these medical forums offer a valuable service, online Question Answering (QA) forums can struggle to deliver timely answers due to the limited number of available healthcare professionals. One way to solve this problem is by developing an automatic QA system that can provide patients with quicker answers. One key component of such a system could be a module for classifying the semantic type of a question. This would allow the system to understand the patient's intent and route them towards the relevant information. METHODS: This paper proposes a novel two-step approach to address the challenge of semantic type classification in Indonesian consumer health questions. We acknowledge the scarcity of Indonesian health domain data, a hurdle for machine learning models. To address this gap, we first introduce a novel corpus of annotated Indonesian consumer health questions. Second, we utilize this newly created corpus to build and evaluate a data-driven predictive model for classifying question semantic types. To enhance the trustworthiness and interpretability of the model's predictions, we employ an explainable model framework, LIME. This framework facilitates a deeper understanding of the role played by word-based features in the model's decision-making process. Additionally, it empowers us to conduct a comprehensive bias analysis, allowing for the detection of \"semantic bias\", where words with no inherent association with a specific semantic type disproportionately influence the model's predictions. RESULTS: The annotation process revealed moderate agreement between expert annotators. In addition, not all words with high LIME probability could be considered true characteristics of a question type. This suggests a potential bias in the data used and the machine learning models themselves. Notably, XGBoost, Na\u00efve Bayes, and MLP models exhibited a tendency to predict questions containing the words \"kanker\" (cancer) and \"depresi\" (depression) as belonging to the DIAGNOSIS category. In terms of prediction performance, Perceptron and XGBoost emerged as the top-performing models, achieving the highest weighted average F1 scores across all input scenarios and weighting factors. Na\u00efve Bayes performed best after balancing the data with Borderline SMOTE, indicating its promise for handling imbalanced datasets. CONCLUSION: We constructed a corpus of query semantics in the domain of Indonesian consumer health, containing 964 questions annotated with their corresponding semantic types. This corpus served as the foundation for building a predictive model. We further investigated the impact of disease-biased words on model performance. These words exhibited high LIME scores, yet lacked association with a specific semantic type. We trained models using datasets with and without these biased words and found no significant difference in model performance between the two scenarios, suggesting that the models might possess an ability to mitigate the influence of such bias during the learning process.",
      "authors": "Hanami Raniah Nur; Mahendra Rahmad; Wicaksono Alfan Farizki",
      "year": "2025",
      "journal": "Journal of biomedical semantics",
      "doi": "10.1186/s13326-025-00334-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40721829/",
      "mesh_terms": "Indonesia; Semantics; Consumer Health Information; Humans; Machine Learning",
      "keywords": "Consumer health question-answering system; Consumer health questions; Semantic annotation scheme; Semantic type classification; Text mining",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC12302743"
    },
    {
      "pmid": "37050425",
      "title": "Machine Learning-Assisted Improved Anomaly Detection for Structural Health Monitoring.",
      "abstract": "The importance of civil engineering infrastructure in modern societies has increased lately due to the growth of the global economy. It forges global supply chains facilitating enormous economic activity. The bridges usually form critical links in complex supply chain networks. Structural health monitoring (SHM) of these infrastructures is essential to reduce life-cycle costs, and determine their remaining life using advanced sensing techniques and data fusion methods. However, the data obtained from the SHM systems describing the health condition of the infrastructure systems may contain anomalies (i.e., distortion, drift, bias, outlier, noise etc.). An automated framework is required to accurately classify these anomalies and evaluate the current condition of these systems in a timely and cost-effective manner. In this paper, a recursive and interpretable decision tree framework is proposed to perform multiclass classification of acceleration data collected from a real-life bridge. The decision nodes of the decision tree are random forest classifiers that are invoked recursively after synthetically augmenting the training data before successive iterations until suitable classification performance is obtained. This machine-learning-based classification model evolved from a simplistic decision tree where statistical features are used to perform classification. The feature vectors defined for training the random forest classifiers are calculated using similar statistical features that are easy to interpret, enhancing the interpretability of the classifier models. The proposed framework could classify non-anomalous (i.e., normal) time-series of the test dataset with 98% accuracy.",
      "authors": "Samudra Shreyas; Barbosh Mohamed; Sadhu Ayan",
      "year": "2023",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s23073365",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37050425/",
      "mesh_terms": "",
      "keywords": "anomaly detection; decision tree; machine learning; random forest; structural health monitoring; vibration data",
      "pub_types": "Journal Article",
      "pmcid": "PMC10098874"
    },
    {
      "pmid": "27935320",
      "title": "Missing laboratory results data in electronic health databases: implications for monitoring diabetes risk.",
      "abstract": "AIM: Laboratory test (lab) results may be useful to detect incident diabetes in electronic health record and claims-based studies. RESEARCH DESIGN & METHODS: Using the Mini-Sentinel distributed database, we assessed the value of lab results added to diagnosis codes and dispensing claims to identify incident diabetes. RESULTS: Inclusion of lab results increased the number of diabetes outcomes identified by 21%. In settings where capture of lab results was relatively complete, the absence of lab results was associated with implausibly low rates of the outcome. CONCLUSION: Lab results can increase sensitivity of algorithms for detecting diabetes, and missing lab results are associated with much lower rates of diabetes ascertainment regardless of algorithm. Patterns of missing lab results may identify ascertainment bias.",
      "authors": "Flory James H; Roy Jason; Gagne Joshua J; Haynes Kevin; Herrinton Lisa; Lu Christine; Patorno Elisabetta; Shoaibi Azadeh; Raebel Marsha A",
      "year": "2017",
      "journal": "Journal of comparative effectiveness research",
      "doi": "10.2217/cer-2016-0033",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27935320/",
      "mesh_terms": "Clinical Laboratory Techniques; Databases, Factual; Diabetes Mellitus; Electronic Health Records; Humans; Risk",
      "keywords": "ascertainment bias; cohort studies; endocrinology; metabolism",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32939352",
      "title": "How to apply dynamic panel bootstrap-corrected fixed-effects (xtbcfe) and heterogeneous dynamics (panelhetero).",
      "abstract": "The characteristics of panel data namely, inter alia, missing values, cross-sectional dependence, serial correlation, small time period bias, omitted variable bias, country-specific fixed-effects, time effects, heterogeneous effects and convergence often lead to misspecification, and spurious regression, thus, affecting the consistency and robustness of the model. In this regard, a more sophisticated panel estimation technique that accounts for the attributes and challenges is worthwhile. The novel panel bootstrap-corrected fixed-effects estimator (xtbcfe) and heterogeneous dynamics (panelhetero) recommended in this study meets almost all the requirements for robust and consistent panel estimation with an interface for user modifications. We further demonstrate how to use empirical CDF, moments and kernel density estimation to investigate heterogeneous effects. Due to the complexities in the application of xtbcfe and panelhetero algorithm, we provide a step-by-step procedure and guidelines for the estimation approach. We apply the xtbcfe and panelhetero algorithm for global estimation of mortality, disability-adjusted life years and welfare cost from exposure to ambient air pollution. Importantly, the xtbcfe algorithm can be applied to any panel data-based studies in social science, environmental science, environmental economics, health economics, energy economics, and among others.\u2022Procedures useful for data imputation and transforming negative variables for time series, cross-sectional and panel data are presented.\u2022Contrary to traditional models, we show how a novel approach can be modified and used to examine the degree of heterogeneous effects across cross-sectional units of panel data.\u2022We demonstrate how the dynamic panel bootstrap-corrected fixed-effects estimator is useful in estimating higher-order panel data models and accounting for challenges such as omitted-variable bias, convergence, cross-section dependence and heterogeneous effects.\u2022We apply the imputation technique, panelhetero, and xtbcfe algorithms to examine the nexus between ambient air pollution and health outcomes.",
      "authors": "Sarkodie Samuel Asumadu; Owusu Phebe Asantewaa",
      "year": "2020",
      "journal": "MethodsX",
      "doi": "10.1016/j.mex.2020.101045",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32939352/",
      "mesh_terms": "",
      "keywords": "Bias correction; Bootstrap-corrected fixed-effects estimator; Dynamic panel modeling; Heterogeneous dynamics; Missing data imputation; Monte Carlo simulation; Treatment of Negative values; Within estimator; panelhetero; xtbcfe",
      "pub_types": "Journal Article",
      "pmcid": "PMC7479353"
    },
    {
      "pmid": "39854338",
      "title": "Low-cost and scalable machine learning model for identifying children and adolescents with poor oral health using survey data: An empirical study in Portugal.",
      "abstract": "This empirical study assessed the potential of developing a machine-learning model to identify children and adolescents with poor oral health using only self-reported survey data. Such a model could enable scalable and cost-effective screening and targeted interventions, optimizing limited resources to improve oral health outcomes. To train and test the model, we used data from 2,133 students attending schools in a Portuguese municipality. Poor oral health (the dependent variable) was defined as having a Decayed, Missing, and Filled Teeth index for deciduous teeth (dmft) or permanent teeth (DMFT) above expert-defined thresholds (dmft/DMFT \u2265 3 or 4). The survey provided information about the students' oral health habits, knowledge, beliefs, and food and physical activity habits, which served as independent variables. Logistic regression models with variables selected through low-variance filtering and recursive feature elimination outperformed various others trained with complex machine learning algorithms based on precision@k metric, outperforming also random selection and expert rule-based models in identifying students with poor oral health. The proposed models are inherently explainable, broadly applicable, which given the context, could compensate their lower performance (Area Under the Curve = 0.64-0.70) compared to similar approaches and models. This study is one of the few in oral health care that includes bias auditing of classification models. The audit surfaced potential biases related to demographic factors such as age and social assistance status. Addressing these biases without significantly compromising model performance remains a challenge. The results confirm the feasibility of survey-based machine learning models for identifying individuals with poor oral health, but further validation of this approach and pilot testing in field trials are necessary.",
      "authors": "Lavado Susana; Costa Eduardo; Sturm Niclas F; Tafferner Johannes S; Rodrigues Oct\u00e1vio; Pita Barros Pedro; Zejnilovic Leid",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0312075",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39854338/",
      "mesh_terms": "Humans; Oral Health; Machine Learning; Adolescent; Child; Male; Female; Portugal; Dental Caries; Surveys and Questionnaires",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11759376"
    },
    {
      "pmid": "32099479",
      "title": "External Validation of an Algorithm to Identify Patients with High Data-Completeness in Electronic Health Records for Comparative Effectiveness Research.",
      "abstract": "OBJECTIVE: Electronic health records (EHR) data-discontinuity, i.e. receiving care outside of a particular EHR system, may cause misclassification of study variables. We aimed to validate an algorithm to identify patients with high EHR data-continuity to reduce such bias. MATERIALS AND METHODS: We analyzed data from two EHR systems linked with Medicare claims data from 2007 through 2014, one in Massachusetts (MA, n=80,588) and the other in North Carolina (NC, n=33,207). We quantified EHR data-continuity by Mean Proportion of Encounters Captured (MPEC) by the EHR system when compared to complete recording in claims data. The prediction model for MPEC was developed in MA and validated in NC. Stratified by predicted EHR data-continuity, we quantified misclassification of 40 key variables by Mean Standardized Differences (MSD) between the proportions of these variables based on EHR alone vs the linked claims-EHR data. RESULTS: The mean MPEC was 27% in the MA and 26% in the NC system. The predicted and observed EHR data-continuity was highly correlated (Spearman correlation=0.78 and 0.73, respectively). The misclassification (MSD) of 40 variables in patients of the predicted EHR data-continuity cohort was significantly smaller (44%, 95% CI: 40-48%) than that in the remaining population. DISCUSSION: The comorbidity profiles were similar in patients with high vs low EHR data-continuity. Therefore, restricting an analysis to patients with high EHR data-continuity may reduce information bias while preserving the representativeness of the study cohort. CONCLUSION: We have successfully validated an algorithm that can identify a high EHR data-continuity cohort representative of the source population.",
      "authors": "Lin Kueiyu Joshua; Rosenthal Gary E; Murphy Shawn N; Mandl Kenneth D; Jin Yinzhu; Glynn Robert J; Schneeweiss Sebastian",
      "year": "2020",
      "journal": "Clinical epidemiology",
      "doi": "10.2147/CLEP.S232540",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32099479/",
      "mesh_terms": "",
      "keywords": "comparative effectiveness research; continuity; data linkage; electronic medical records; external validation; information bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC7007793"
    },
    {
      "pmid": "33322776",
      "title": "Derivation of Respiratory Metrics in Health and Asthma.",
      "abstract": "UNLABELLED: The ability to continuously monitor breathing metrics may have indications for general health as well as respiratory conditions such as asthma. However, few studies have focused on breathing due to a lack of available wearable technologies. To examine the performance of two machine learning algorithms in extracting breathing metrics from a finger-based pulse oximeter, which is amenable to long-term monitoring. METHODS: Pulse oximetry data were collected from 11 healthy and 11 with asthma subjects who breathed at a range of controlled respiratory rates. U-shaped network (U-Net) and Long Short-Term Memory (LSTM) algorithms were applied to the data, and results compared against breathing metrics derived from respiratory inductance plethysmography measured simultaneously as a reference. RESULTS: The LSTM vs. U-Net model provided breathing metrics which were strongly correlated with those from the reference signal (all p < 0.001, except for inspiratory: expiratory ratio). The following absolute mean bias (95% confidence interval) values were observed (in seconds): inspiration time 0.01(-2.31, 2.34) vs. -0.02(-2.19, 2.16), expiration time -0.19(-2.35, 1.98) vs. -0.24(-2.36, 1.89), and inter-breath intervals -0.19(-2.73, 2.35) vs. -0.25(2.76, 2.26). The inspiratory:expiratory ratios were -0.14(-1.43, 1.16) vs. -0.14(-1.42, 1.13). Respiratory rate (breaths per minute) values were 0.22(-2.51, 2.96) vs. 0.29(-2.54, 3.11). While percentage bias was low, the 95% limits of agreement was high (~35% for respiratory rate). CONCLUSION: Both machine learning models show strong correlation and good comparability with reference, with low bias though wide variability for deriving breathing metrics in asthma and health cohorts. Future efforts should focus on improvement of performance of these models, e.g., by increasing the size of the training dataset at the lower breathing rates.",
      "authors": "Prinable Joseph; Jones Peter; Boland David; McEwan Alistair; Thamrin Cindy",
      "year": "2020",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s20247134",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33322776/",
      "mesh_terms": "Humans; Male; Asthma; Oximetry; Respiration; Respiratory Rate",
      "keywords": "LSTM; U-Net; asthma; machine learning; respiratory monitoring",
      "pub_types": "Letter",
      "pmcid": "PMC7764376"
    },
    {
      "pmid": "38726910",
      "title": "Prediction of 24-Hour Urinary Sodium Excretion Using Machine-Learning Algorithms.",
      "abstract": "BACKGROUND: Accurate quantification of sodium intake based on self-reported dietary assessments has been a persistent challenge. We aimed to apply machine-learning (ML) algorithms to predict 24-hour urinary sodium excretion from self-reported questionnaire information. METHODS AND RESULTS: We analyzed 3454 participants from the NHS (Nurses' Health Study), NHS-II (Nurses' Health Study II), and HPFS (Health Professionals Follow-Up Study), with repeated measures of 24-hour urinary sodium excretion over 1\u2009year. We used an ensemble approach to predict averaged 24-hour urinary sodium excretion using 36 characteristics. The TOHP-I (Trial of Hypertension Prevention I) was used for the external validation. The final ML algorithms were applied to 167\u2009920 nonhypertensive adults with 30-year follow-up to estimate confounder-adjusted hazard ratio (HR) of incident hypertension for predicted sodium. Averaged 24-hour urinary sodium excretion was better predicted and calibrated with ML compared with the food frequency questionnaire (Spearman correlation coefficient, 0.51 [95% CI, 0.49-0.54] with ML; 0.19 [95% CI, 0.16-0.23] with the food frequency questionnaire; 0.46 [95% CI, 0.42-0.50] in the TOHP-I). However, the prediction heavily depended on body size, and the prediction of energy-adjusted 24-hour sodium excretion was modestly better using ML. ML-predicted sodium was modestly more strongly associated than food frequency questionnaire-based sodium in the NHS-II (HR comparing Q5 versus Q1, 1.48 [95% CI, 1.40-1.56] with ML; 1.04 [95% CI, 0.99-1.08] with the food frequency questionnaire), but no material differences were observed in the NHS or HPFS. CONCLUSIONS: The present ML algorithm improved prediction of participants' absolute 24-hour urinary sodium excretion. The present algorithms may be a generalizable approach for predicting absolute sodium intake but do not substantially reduce the bias stemming from measurement error in disease associations.",
      "authors": "Hamaya Rikuta; Wang Molin; Juraschek Stephen P; Mukamal Kenneth J; Manson JoAnn E; Tobias Deirdre K; Sun Qi; Curhan Gary C; Willett Walter C; Rimm Eric B; Cook Nancy R",
      "year": "2024",
      "journal": "Journal of the American Heart Association",
      "doi": "10.1161/JAHA.123.034310",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38726910/",
      "mesh_terms": "Humans; Female; Male; Machine Learning; Middle Aged; Adult; Hypertension; Sodium; Aged; Sodium, Dietary; Algorithms; Predictive Value of Tests; Self Report; Time Factors; Reproducibility of Results; United States; Urinalysis",
      "keywords": "dietary sodium; food frequency questionnaire; hypertension; machine learning; measurement error",
      "pub_types": "Journal Article",
      "pmcid": "PMC11179835"
    },
    {
      "pmid": "31521873",
      "title": "Symptomatology differences of major depression in psychiatric versus general hospitals: A machine learning approach.",
      "abstract": "BACKGROUND: Symptomatology differences of major depressive disorder (MDD) in psychiatric and general hospitals in China leads to possible misdiagnosis. Looking at the symptomatology of first-visit patients with MDD in different mental health services, and identifying predictors of health-seeking behavior using machine learning may help to improve diagnostic accuracy. METHODS: 1500 patients first diagnosed with MDD were recruited from 16 psychiatric hospitals and 16 general hospitals across China. Socio-demographic characteristics, causal attribution, symptoms of depression within and outside Diagnostic and Statistical Manual of Mental Disorders (DSM) framework were collected using a self-made questionnaire. A predictive model of 62 variables was established using Random forest, symptom frequencies of patients in general hospitals and psychiatric hospitals were compared. RESULTS: The machine learning approach revealed that symptoms were strong predictors of health-seeking behavior among patients with MDD. General hospitals patients had higher frequencies of suicidal ideation (\u03c72=15.230, p<0.001), psychosis (\u03c72=14.264, p<0.001), weight change (all p<0.001), hypersomnia (\u03c72=25.940, p<0.001), and a tendency of denying emotional/cognitive symptoms compared with psychiatric hospitals patients. LIMITATIONS: Stigma and preference bias were not measured. Severity of current depressive episodes was not assessed. Data of previous episode(s) was not presented. CONCLUSIONS: Symptom evaluation targeting specific patient population in different hospitals is crucial for diagnostic accuracy. Suicide prevention reliant on collaboration between general hospitals and psychiatric hospitals is required in the future construction of Chinese mental health system.",
      "authors": "Cui Lvchun; Wang Chenglei; Wu Zhiguo; Peng Daihui; Huang Jingjing; Zhang Chen; Huang Jia; Hong Wu; Wang Yong; Chen Jun; Liu Tiebang; Rong Han; Yang Haichen; Fang Yiru",
      "year": "2020",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2019.09.030",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31521873/",
      "mesh_terms": "Adult; China; Major Depressive Disorder; Diagnostic Errors; Diagnostic and Statistical Manual of Mental Disorders; Female; Hospitals, General; Hospitals, Psychiatric; Humans; Machine Learning; Male; Middle Aged; Suicidal Ideation; Surveys and Questionnaires; Symptom Assessment; Young Adult",
      "keywords": "Chinese; Health behavior; Machine learning; Major depressive disorder; Symptoms",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "39778397",
      "title": "An emotionally intelligent haptic system - An efficient solution for anxiety detection and mitigation.",
      "abstract": "BACKGROUND: Anxiety is a psycho-physiological condition associated with an individual's mental state. Long-term anxiety persistence can lead to anxiety disorder, which is the underlying cause of many mental health problems. As such, it is critical to precisely identify anxiety by automated, effective, and user-bias-free ways. OBJECTIVE: The objective of this study is to develop an innovative emotionally intelligent Haptic system for anxiety detection, which can be used to track and manage people's anxiety. METHOD: The suggested approach incorporates a haptic feedback mechanism that is based on EEG data and is analysed by machine learning algorithms. This allows users to effectively control their emotional well-being by receiving timely feedback and assessments of their anxiety levels. First, the authors use publicly accessible data to present an experimental study for the categorization of human anxiety. RESULTS: The ensemble model used for the classification produces results with a 97 % accuracy rate, 0.98 recall, 0.99 precision, and a 0.99 F1 score. Furthermore, self-curated data is subjected to an advanced spike analysis algorithm that identifies signal spikes and then quantifies the level of anxiety. CONCLUSION: The results obtained demonstrate that haptic stimuli are produced smoothly, offering a comprehensive and innovative method of managing anxiety.",
      "authors": "Mishra Swapneel; Seth Saumya; Jain Shrishti; Pant Vasudev; Parikh Jolly; Chugh Nupur; Puri Yugnanda",
      "year": "2025",
      "journal": "Computer methods and programs in biomedicine",
      "doi": "10.1016/j.cmpb.2025.108590",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39778397/",
      "mesh_terms": "Humans; Anxiety; Emotions; Algorithms; Machine Learning; Electroencephalography; Female; Male; Adult",
      "keywords": "Anxiousness detection; Bio AMP EXG sensor; Bone conductor; EEG brainwave dataset; Haptic system",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40837693",
      "title": "Nationwide Machine Learning-Ensemble PM2.5 Mapping Prediction and Forecasting Models in South Korea with High Spatiotemporal Resolution and Health Risk Estimation-Based Evaluations.",
      "abstract": "Several studies developed machine learning-based PM2.5 prediction models; however, nationwide models addressing both mapping prediction and forecasting were limited. Further, although the prediction accuracy is different from PM2.5-related health risk estimation, previous studies solely examined the prediction accuracy. This study suggests a method to assess the statistical properties of PM2.5-health risk estimation, which also can be used as a model selection. We used three machine learning algorithms and an ensemble method to construct PM2.5 mapping prediction (1 km2) and two-day forecasting models majorly using satellite-driven data in South Korea (2015-2022). We performed a simulation study to examine the statistical properties of short-term PM2.5 risk estimation using prediction models. Our ensemble spatial prediction model showed better performance than single algorithms (0.956 test R 2). The range of the R 2 values was 0.78-0.98 across the monitoring sites. The average % bias was from 1.403%-1.787% when our mapping models for PM2.5-mortality risk estimation, compared to the estimates from monitored PM2.5. The best R 2 of our forecasting models was 0.904. This study developed machine learning models for spatial PM2.5 predictions and forecasting in Korea. This study also suggested a method to address risk estimation and model selection concurrently when multiple prediction models were used.",
      "authors": "Ahn Seoyeong; Kim Ayoung; Chung Yeonseung; Kang Cinoo; Kim Sooyoung; Kwon Dohoon; Park Jiwoo; Oh Jieun; Park Jinah; Moon Jeongmin; Song Insung; Min Jieun; Lee Hyung Joo; Kim Ho; Lee Whanhee",
      "year": "2025",
      "journal": "Environment & health (Washington, D.C.)",
      "doi": "10.1021/envhealth.4c00201",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40837693/",
      "mesh_terms": "",
      "keywords": "Fine particulate matter (PM2.5); Forecasting models; Mapping prediction models; PM2.5-related Health risk estimation; and Machine learning algorithms",
      "pub_types": "Journal Article",
      "pmcid": "PMC12362205"
    },
    {
      "pmid": "40046729",
      "title": "Do we need flexible machine-learning algorithms to assess the effect of long-term exposure to fine particulate matter on mortality?: An example from a Canadian national cohort.",
      "abstract": "BACKGROUND: Evidence suggests the existence of nonlinearity in the relationship between long-term fine particulate matter (PM2.5) and mortality, and the methods to flexibly incorporate nonlinearity can be improved. To heuristically evaluate the necessity of incorporating machine-learning algorithms, we compared the benefit of reducing long-term PM2.5 on mortality estimated from three analytical methods with varying flexibility and complexity. METHODS: Using a cohort of the Canadian Community Health Survey respondents (followed from 2005 until 2014), we obtained consented respondents' baseline characteristics, time-varying annual average PM2.5 in the previous 3 years, yearly income and neighborhood characteristics, and vital status. We estimated the 10-year cumulative mortality rate under both a natural-course exposure and a hypothetical dynamic intervention, which would set the respondent's exposure to 8.8 \u03bcg/m3 (current Canadian annual PM2.5 standard) if higher. We compared estimates of three analytical methods and mean squared errors under a range of hypothetical true values. RESULTS: Among 62,365 participants, the 10-year cumulative mortality rate differences per 1000 participants were -0.23 (95% confidence intervals: -0.46, 0.00), -0.83 (-1.24, -0.43), and -0.67 (-1.27, -0.06) for parametric g-computation, targeted minimum loss-based estimator using parametric models, and targeted minimum loss-based estimator with SuperLearner and six candidate algorithms of high flexibility, respectively. Changing the hyperparameters did not meaningful change estimates or algorithm weights. CONCLUSIONS: All three methods of reducing long-term exposure to PM2.5 yielded tangible public health benefits in Canada where PM2.5 levels are among the lowest worldwide. However, the advantage of employing machine-learning algorithms with a doubly robust estimator remains minimal, especially considering the variance-bias tradeoff.",
      "authors": "Chen Chen; Kaufman Jay S; Rana Juwel; Benmarhnia Tarik; Chen Hong",
      "year": "2025",
      "journal": "Environmental epidemiology (Philadelphia, Pa.)",
      "doi": "10.1097/EE9.0000000000000375",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40046729/",
      "mesh_terms": "",
      "keywords": "Air pollution; Causal inference; Doubly robust estimation; Environmental epidemiology; Long-term exposure; Machine learning; Mortality; SuperLearner",
      "pub_types": "Journal Article",
      "pmcid": "PMC11882297"
    },
    {
      "pmid": "31858938",
      "title": "The Ethics of Medical AI and the Physician-Patient Relationship.",
      "abstract": "This article considers recent ethical topics relating to medical AI. After a general discussion of recent medical AI innovations, and a more analytic look at related ethical issues such as data privacy, physician dependency on poorly understood AI helpware, bias in data used to create algorithms post-GDPR, and changes to the patient-physician relationship, the article examines the issue of so-called robot doctors. Whereas the so-called democratization of healthcare due to health wearables and increased access to medical information might suggest a positive shift in the patient-physician relationship, the physician's 'need to care' might be irreplaceable, and robot healthcare workers ('robot carers') might be seen as contributing to dehumanized healthcare practices.",
      "authors": "Dalton-Brown Sally",
      "year": "2020",
      "journal": "Cambridge quarterly of healthcare ethics : CQ : the international journal of healthcare ethics committees",
      "doi": "10.1017/S0963180119000847",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31858938/",
      "mesh_terms": "Artificial Intelligence; Confidentiality; Ethics, Medical; European Union; Humans; Informed Consent; Physician-Patient Relations; Physicians; Robotics",
      "keywords": "GDPR; Medical AI; algorithm bias; care robots",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "27687561",
      "title": "Estimating oxygen uptake and energy expenditure during treadmill walking by neural network analysis of easy-to-obtain inputs.",
      "abstract": "The study of oxygen uptake (V\u0307o2) dynamics during walking exercise transitions adds valuable information regarding fitness. However, direct V\u0307o2 measurements are not practical for general population under realistic settings. Devices to measure V\u0307o2 are associated with elevated cost, uncomfortable use of a mask, need of trained technicians, and impossibility of long-term data collection. The objective of this study was to predict the V\u0307o2 dynamics from heart rate and inputs from the treadmill ergometer by a novel artificial neural network approach. To accomplish this, 10 healthy young participants performed one incremental and three moderate constant work rate treadmill walking exercises. The speed and grade used for the moderate-intensity protocol was related to 80% of the V\u0307o2 response at the gas exchange threshold estimated during the incremental exercise. The measured V\u0307o2 was used to train an artificial neural network to create an algorithm able to predict the V\u0307o2 based on easy-to-obtain inputs. The dynamics of the V\u0307o2 response during exercise transition were evaluated by exponential modeling. Within each participant, the predicted V\u0307o2 was strongly correlated to the measured V\u0307o2 ( = 0.97 \u00b1 0.0) and presented a low bias (~0.2%), enabling the characterization of the V\u0307o2 dynamics during treadmill walking exercise. The proposed algorithm could be incorporated into smart devices and fitness equipment, making them suitable for tracking changes in aerobic fitness and physical health beyond the infrequent monitoring of patients during clinical interventions and rehabilitation programs.",
      "authors": "Beltrame Thomas; Amelard Robert; Villar Rodrigo; Shafiee Mohammad J; Wong Alexander; Hughson Richard L",
      "year": "2016",
      "journal": "Journal of applied physiology (Bethesda, Md. : 1985)",
      "doi": "10.1152/japplphysiol.00600.2016",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27687561/",
      "mesh_terms": "Adult; Energy Metabolism; Exercise; Exercise Test; Female; Heart Rate; Humans; Male; Neural Networks, Computer; Oxygen; Oxygen Consumption; Physical Exertion; Walking; Young Adult",
      "keywords": "aerobic fitness; machine learning; oxygen uptake kinetics",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36141522",
      "title": "Emergency Relief Chain for Natural Disaster Response Based on Government-Enterprise Coordination.",
      "abstract": "Public health and effective risk response cannot be promoted without a coordinated emergency process during a natural disaster. One primary problem with the emergency relief chain is the homogeneous layout of rescue organizations and reserves. There is a need for government-enterprise coordination to enhance the systemic resilience and demand orientation. Therefore, a bi-level multi-phase emergency plan model involving procurement, prepositioning and allocation is proposed. The tradeoff of efficiency, economy and fairness is offered through the multi-objective cellular genetic algorithm (MOCGA). The flood emergency in Hunan Province, China is used as a case study. The impact of multi-objective and coordination mechanisms on the relief chain is discussed. The results show that there is a significant boundary condition for the coordinated location strategy of emergency facilities and that further government coordination over the transition phase can generate optimal relief benefits. Demand orientation is addressed by the proposed model and MOCGA, with the realization of the process coordination in multiple reserves, optimal layout, and transition allocation. The emergency relief chain based on government-enterprise coordination that adapts to the evolution of disasters can provide positive actions for integrated precaution and health security.",
      "authors": "Wang Feiyue; Xie Ziling; Pei Zhongwei; Liu Dingli",
      "year": "2022",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph191811255",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36141522/",
      "mesh_terms": "Disaster Planning; Disasters; Emergency Medical Services; Floods; Government",
      "keywords": "emergency relief chain; government-enterprise; process coordination; transition allocation",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9517505"
    },
    {
      "pmid": "34608222",
      "title": "An efficient and accurate distributed learning algorithm for modeling multi-site zero-inflated count outcomes.",
      "abstract": "Clinical research networks (CRNs), made up of multiple healthcare systems each with patient data from several care sites, are beneficial for studying rare outcomes and increasing generalizability of results. While CRNs encourage sharing aggregate data across healthcare systems, individual systems within CRNs often cannot share patient-level data due to privacy regulations, prohibiting multi-site regression which requires an analyst to access all individual patient data pooled together. Meta-analysis is commonly used to model data stored at multiple institutions within a CRN but can result in biased estimation, most notably in rare-event contexts. We present a communication-efficient, privacy-preserving algorithm for modeling multi-site zero-inflated count outcomes within a CRN. Our method, a one-shot distributed algorithm for performing hurdle regression (ODAH), models zero-inflated count data stored in multiple sites without sharing patient-level data across sites, resulting in estimates closely approximating those that would be obtained in a pooled patient-level data analysis. We evaluate our method through extensive simulations and two real-world data applications using electronic health records: examining risk factors associated with pediatric avoidable hospitalization and modeling serious adverse event frequency associated with a colorectal cancer therapy. In simulations, ODAH produced bias less than 0.1% across all settings explored while meta-analysis estimates exhibited bias up to 12.7%, with meta-analysis performing worst in settings with high zero-inflation or low event rates. Across both applied analyses, ODAH estimates had less than 10% bias for 18 of 20 coefficients estimated, while meta-analysis estimates exhibited substantially higher bias. Relative to existing methods for distributed data analysis, ODAH offers a highly accurate, computationally efficient method for modeling multi-site zero-inflated count data.",
      "authors": "Edmondson Mackenzie J; Luo Chongliang; Duan Rui; Maltenfort Mitchell; Chen Zhaoyi; Locke Kenneth; Shults Justine; Bian Jiang; Ryan Patrick B; Forrest Christopher B; Chen Yong",
      "year": "2021",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-021-99078-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34608222/",
      "mesh_terms": "Algorithms; Big Data; Data Mining; Delivery of Health Care; Electronic Health Records; Humans; Models, Statistical",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8490431"
    },
    {
      "pmid": "31212933",
      "title": "Machine Learning-Based Integration of High-Resolution Wildfire Smoke Simulations and Observations for Regional Health Impact Assessment.",
      "abstract": "Large wildfires are an increasing threat to the western U.S. In the 2017 fire season, extensive wildfires occurred across the Pacific Northwest (PNW). To evaluate public health impacts of wildfire smoke, we integrated numerical simulations and observations for regional fire events during August-September of 2017. A one-way coupled Weather Research and Forecasting and Community Multiscale Air Quality modeling system was used to simulate fire smoke transport and dispersion. To reduce modeling bias in fine particulate matter (PM2.5) and to optimize smoke exposure estimates, we integrated modeling results with the high-resolution Multi-Angle Implementation of Atmospheric Correction satellite aerosol optical depth and the U.S. Environmental Protection Agency AirNow ground-level monitoring PM2.5 concentrations. Three machine learning-based data fusion algorithms were applied: An ordinary multi-linear regression method, a generalized boosting method, and a random forest (RF) method. 10-Fold cross-validation found improved surface PM2.5 estimation after data integration and bias correction, especially with the RF method. Lastly, to assess transient health effects of fire smoke, we applied the optimized high-resolution PM2.5 exposure estimate in a short-term exposure-response function. Total estimated regional mortality attributable to PM2.5 exposure during the smoke episode was 183 (95% confidence interval: 0, 432), with 85% of the PM2.5 pollution and 95% of the consequent multiple-cause mortality contributed by fire emissions. This application demonstrates both the profound health impacts of fire smoke over the PNW and the need for a high-performance fire smoke forecasting and reanalysis system to reduce public health risks of smoke hazards in fire-prone regions.",
      "authors": "Zou Yufei; O'Neill Susan M; Larkin Narasimhan K; Alvarado Ernesto C; Solomon Robert; Mass Clifford; Liu Yang; Odman M Talat; Shen Huizhong",
      "year": "2019",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph16122137",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31212933/",
      "mesh_terms": "Air Pollutants; Air Pollution; Algorithms; Environmental Monitoring; Health Impact Assessment; Humans; Machine Learning; Northwestern United States; Smoke; Wildfires",
      "keywords": "PM2.5 air pollution; fire smoke modeling; health impact assessment; machine learning-based data fusion",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC6617359"
    },
    {
      "pmid": "36405957",
      "title": "Imbalanced data preprocessing techniques for machine learning: a systematic mapping study.",
      "abstract": "Machine Learning (ML) algorithms have been increasingly replacing people in several application domains-in which the majority suffer from data imbalance. In order to solve this problem, published studies implement data preprocessing techniques, cost-sensitive and ensemble learning. These solutions reduce the naturally occurring bias towards the majority sample through ML. This study uses a systematic mapping methodology to assess 9927 papers related to sampling techniques for ML in imbalanced data applications from 7 digital libraries. A filtering process selected 35 representative papers from various domains, such as health, finance, and engineering. As a result of a thorough quantitative analysis of these papers, this study proposes two taxonomies-illustrating sampling techniques and ML models. The results indicate that oversampling and classical ML are the most common preprocessing techniques and models, respectively. However, solutions with neural networks and ensemble ML models have the best performance-with potentially better results through hybrid sampling techniques. Finally, none of the 35 works apply simulation-based synthetic oversampling, indicating a path for future preprocessing solutions.",
      "authors": "Werner de Vargas Vitor; Schneider Aranda Jorge Arthur; Dos Santos Costa Ricardo; da Silva Pereira Paulo Ricardo; Vict\u00f3ria Barbosa Jorge Luis",
      "year": "2023",
      "journal": "Knowledge and information systems",
      "doi": "10.1007/s10115-022-01772-8",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36405957/",
      "mesh_terms": "",
      "keywords": "Imbalanced data; Machine learning; Preprocessing techniques; Sampling; Systematic mapping study",
      "pub_types": "Journal Article",
      "pmcid": "PMC9645765"
    },
    {
      "pmid": "11776735",
      "title": "Acceptance of rules generated by machine learning among medical experts.",
      "abstract": "OBJECTIVES: The aim was to evaluate the potential for monotonicity constraints to bias machine learning systems to learn rules that were both accurate and meaningful. METHODS: Two data sets, taken from problems as diverse as screening for dementia and assessing the risk of mental retardation, were collected and a rule learning system, with and without monotonicity constraints, was run on each. The rules were shown to experts, who were asked how willing they would be to use such rules in practice. The accuracy of the rules was also evaluated. RESULTS: Rules learned with monotonicity constraints were at least as accurate as rules learned without such constraints. Experts were, on average, more willing to use the rules learned with the monotonicity constraints. CONCLUSIONS: The analysis of medical databases has the potential of improving patient outcomes and/or lowering the cost of health care delivery. Various techniques, from statistics, pattern recognition, machine learning, and neural networks, have been proposed to \"mine\" this data by uncovering patterns that may be used to guide decision making. This study suggests cognitive factors make learned models coherent and, therefore, credible to experts. One factor that influences the acceptance of learned models is consistency with existing medical knowledge.",
      "authors": "Pazzani M J; Mani S; Shankle W R",
      "year": "2001",
      "journal": "Methods of information in medicine",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/11776735/",
      "mesh_terms": "Alzheimer Disease; Artificial Intelligence; Data Collection; Databases as Topic; Decision Support Systems, Clinical; Diagnosis, Computer-Assisted; Humans; Intellectual Disability; Mental Status Schedule",
      "keywords": "",
      "pub_types": "Evaluation Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40853158",
      "title": "Big Data in Neurosurgery: A Guideline on Data Structures, Machine Learning Models, and Ethical Considerations.",
      "abstract": "Artificial intelligence (AI) is reshaping neurosurgery, offering unprecedented opportunities to enhance diagnostics, personalize treatment, and predict outcomes. At the heart of this transformation is the ability to effectively harness big data (BD) within the electronic medical record. Understanding these data structures is essential for making sense of the vast volumes of information generated in modern neurosurgical practice. Equally important are the machine learning (ML) models driving these advancements. From supervised learning and convolutional neural networks to generative AI, these tools are already making a mark in areas such as brain tumor segmentation and spine surgery outcome predictions. Their versatility highlights the potential of ML to complement clinical expertise and streamline decision-making in neurosurgery. However, adopting BD and ML also brings ethical challenges that cannot be ignored. Bias in algorithms threatens to reinforce health disparities, whereas concerns about data privacy demand vigilance in handling sensitive patient information. In addition, the question of liability looms large as ML increasingly influences clinical decisions. The aim of the study was to provide a roadmap for neurosurgeons navigating the evolving intersection of BD, ML, and ethical responsibility in the AI era.",
      "authors": "Singh Rohin; Kassis George; Sbaih Omar; Li Herman; Shahrestani Shane; Lawton Michael T; Gottfried Oren; Bydon Mohamad; Stone Jonathan J",
      "year": "2025",
      "journal": "Operative neurosurgery (Hagerstown, Md.)",
      "doi": "10.1227/ons.0000000000001751",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40853158/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Big data; Epic; Ethics; Machine learning",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "17099826",
      "title": "[Name-based identification of cases of Turkish origin in the childhood cancer registry in Mainz].",
      "abstract": "Until now few analyses of routine data relating to the health of migrants have been conducted in Germany. A major obstacle is that most data sources do not provide reliable information on the origin of migrants. While some sources contain the nationality of persons registered, this information does not allow one to identify migrants who have taken up German citizenship, i.e., a substantial part of second-generation migrants. In this paper we demonstrate how a computer-aided, name-based algorithm can be used to identify persons of Turkish origin in the German Childhood Cancer Registry in Mainz, Germany. The performance of the algorithm, as assessed against the gold standard of assessing names manually, was very good (sensitivity and specificity > or = 0.975). In total, we identified 1774 of the 37,259 cases in the registry as being of Turkish origin. The name algorithm proved to be a useful tool to identify Turkish migrants in routine data sources, thus avoiding potential bias due to changes in citizenship. This approach aims at improving migrant-sensitive health reporting and research in Germany. In future, additional information on migrant status should be obtained already during primary data collection so that health data for all migrant groups can be provided.",
      "authors": "Spallek J; Kaatsch P; Spix C; Ulusoy N; Zeeb H; Razum O",
      "year": "2006",
      "journal": "Gesundheitswesen (Bundesverband der Arzte des Offentlichen Gesundheitsdienstes (Germany))",
      "doi": "10.1055/s-2006-927166",
      "url": "https://pubmed.ncbi.nlm.nih.gov/17099826/",
      "mesh_terms": "Algorithms; Artificial Intelligence; Child; Emigration and Immigration; Germany; Humans; Names; Natural Language Processing; Neoplasms; Registries; Turkey",
      "keywords": "",
      "pub_types": "English Abstract; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39914461",
      "title": "Statistical Inference for Association Studies in the Presence of Binary Outcome Misclassification.",
      "abstract": "In biomedical and public health association studies, binary outcome variables may be subject to misclassification, resulting in substantial bias in effect estimates. The feasibility of addressing binary outcome misclassification in regression models is often hindered by model identifiability issues. In this paper, we characterize the identifiability problems in this class of models as a specific case of \"label-switching\" and leverage a pattern in the resulting parameter estimates to solve the permutation invariance of the complete data log-likelihood. Our proposed algorithm in binary outcome misclassification models does not require gold standard labels and relies only on the assumption that the sum of the sensitivity and specificity exceeds 1. A label-switching correction is applied within estimation methods to recover unbiased effect estimates and to estimate misclassification rates. Open-source software is provided to implement the proposed methods. We give a detailed simulation study for our proposed methodology and apply these methods to data from the 2020 Medical Expenditure Panel Survey (MEPS).",
      "authors": "Hochstedler Webb Kimberly A; Wells Martin T",
      "year": "2025",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.10316",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39914461/",
      "mesh_terms": "Humans; Bias; Computer Simulation; Models, Statistical; Algorithms; Likelihood Functions; Data Interpretation, Statistical; Regression Analysis; Software",
      "keywords": "EM algorithm; MCMC; association studies; bias correction; identification; label\u2010switching",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40109456",
      "title": "[Legal Risk Assessment and Prevention in Artificial Intelligence-Assisted Health Care].",
      "abstract": "With the wide application of new technologies such as large language models and generative artificial intelligence (AI) in the health care sector, artificial intelligence-assisted health care is confronted with new forms of legal risks. The algorithmic bias and data security issues in AI-assisted health care have given rise to risks of infringement on general personality rights and specific personality rights. The handling of health care data and the distribution of profits from health care data have spawned disputes over data property rights. Moreover, there will also be risks of uncertainties in the attribution of liability for medical harms once AI technology becomes deeply embedded in health care. Based on the emerging changes in the legal risks associated with AI-assisted health care, it is necessary to establish a corresponding algorithm review mechanism to eliminate algorithm biases, improve the data management system through a whole-life cycle approach to ensure data security, define hierarchical data property rights and establish authorization rules to resolve property rights disputes, and reasonably assign tort liability for medical harms based on specific faults.",
      "authors": "Yang Jinming; Wang Na; Hu Yexun; Zhang Wei",
      "year": "2025",
      "journal": "Sichuan da xue xue bao. Yi xue ban = Journal of Sichuan University. Medical science edition",
      "doi": "10.12182/20250160301",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40109456/",
      "mesh_terms": "Artificial Intelligence; Humans; Risk Assessment; Computer Security; Delivery of Health Care; Algorithms; Liability, Legal",
      "keywords": "Artificial intelligence; Intelligent medical treatment; Legal risk",
      "pub_types": "English Abstract; Journal Article",
      "pmcid": "PMC11914023"
    },
    {
      "pmid": "39287997",
      "title": "Leveraging predictive analytics to target payer-led medication adherence interventions.",
      "abstract": "This article examines how predictive analytics can enhance payer initiatives to improve medication adherence. Despite its known impact on health outcomes and costs, medication nonadherence remains a widespread and persistent challenge in health care. Although payers are increasingly involved in addressing nonadherence, traditional approaches typically lead to suboptimal results due to their reactive nature and generic intervention. With improved access to data and more sophisticated machine learning tools, there is a growing opportunity for payers to use predictive analytics to stratify and target members at high risk, predict potential primary and secondary nonadherence, and preemptively intervene with tailored solutions. The potential benefit of this approach includes prevention, not only resolution, of nonadherence and leads to improved health outcomes, reduced health care costs, and increased member satisfaction. The article also discusses potential caveats to consider, such as data sharing, bias mitigation, and regulatory compliance, when implementing predictive analytics in this context.",
      "authors": "Sharma Pankhuri",
      "year": "2024",
      "journal": "The American journal of managed care",
      "doi": "10.37765/ajmc.2024.89610",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39287997/",
      "mesh_terms": "Humans; United States; Drug Monitoring",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "31427903",
      "title": "Machine Learning Model for Imbalanced Cholera Dataset in Tanzania.",
      "abstract": "Cholera epidemic remains a public threat throughout history, affecting vulnerable population living with unreliable water and substandard sanitary conditions. Various studies have observed that the occurrence of cholera has strong linkage with environmental factors such as climate change and geographical location. Climate change has been strongly linked to the seasonal occurrence and widespread of cholera through the creation of weather patterns that favor the disease's transmission, infection, and the growth of Vibrio cholerae, which cause the disease. Over the past decades, there have been great achievements in developing epidemic models for the proper prediction of cholera. However, the integration of weather variables and use of machine learning techniques have not been explicitly deployed in modeling cholera epidemics in Tanzania due to the challenges that come with its datasets such as imbalanced data and missing information. This paper explores the use of machine learning techniques to model cholera epidemics with linkage to seasonal weather changes while overcoming the data imbalance problem. Adaptive Synthetic Sampling Approach (ADASYN) and Principal Component Analysis (PCA) were used to the restore sampling balance and dimensional of the dataset. In addition, sensitivity, specificity, and balanced-accuracy metrics were used to evaluate the performance of the seven models. Based on the results of the Wilcoxon sign-rank test and features of the models, XGBoost classifier was selected to be the best model for the study. Overall results improved our understanding of the significant roles of machine learning strategies in health-care data. However, the study could not be treated as a time series problem due to the data collection bias. The study recommends a review of health-care systems in order to facilitate quality data collection and deployment of machine learning techniques.",
      "authors": "Leo Judith; Luhanga Edith; Michael Kisangiri",
      "year": "2019",
      "journal": "TheScientificWorldJournal",
      "doi": "10.1155/2019/9397578",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31427903/",
      "mesh_terms": "Cholera; Databases as Topic; Humans; Machine Learning; Rain; Seasons; Tanzania; World Health Organization",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC6683776"
    },
    {
      "pmid": "35332406",
      "title": "Assessment of neonatal respiratory rate variability.",
      "abstract": "Accurate measurement of respiratory rate (RR) in neonates is challenging due to high neonatal RR variability (RRV). There is growing evidence that RRV measurement could inform and guide neonatal care. We sought to quantify neonatal RRV during a clinical study in which we compared multiparameter continuous physiological monitoring (MCPM) devices. Measurements of capnography-recorded exhaled carbon dioxide across 60-s epochs were collected from neonates admitted to the neonatal unit at Aga Khan University-Nairobi hospital. Breaths were manually counted from capnograms and using an automated signal detection algorithm which also calculated mean and median RR for each epoch. Outcome measures were between- and within-neonate RRV, between- and within-epoch RRV, and 95% limits of agreement, bias, and root-mean-square deviation. Twenty-seven neonates were included, with 130 epochs analysed. Mean manual breath count (MBC) was 48 breaths per minute. Median RRV ranged from 11.5% (interquartile range (IQR) 6.8-18.9%) to 28.1% (IQR 23.5-36.7%). Bias and limits of agreement for MBC vs algorithm-derived breath count, MBC vs algorithm-derived median breath rate, MBC vs algorithm-derived mean breath rate were\u2009-\u20090.5 (-\u20092.7, 1.66),\u2009-\u20093.16 (-\u200912.12, 5.8), and\u2009-\u20093.99 (-\u200911.3, 3.32), respectively. The marked RRV highlights the challenge of performing accurate RR measurements in neonates. More research is required to optimize the use of RRV to improve care. When evaluating MCPM devices, accuracy thresholds should be less stringent in newborns due to increased RRV. Lastly, median RR, which discounts the impact of extreme outliers, may be more reflective of the underlying physiological control of breathing.",
      "authors": "Coleman Jesse; Ginsburg Amy Sarah; Macharia William M; Ochieng Roseline; Chomba Dorothy; Zhou Guohai; Dunsmuir Dustin; Karlen Walter; Ansermino J Mark",
      "year": "2022",
      "journal": "Journal of clinical monitoring and computing",
      "doi": "10.1007/s10877-022-00840-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35332406/",
      "mesh_terms": "Infant, Newborn; Humans; Respiratory Rate; Kenya; Capnography; Monitoring, Physiologic; Respiration",
      "keywords": "Child health; Critical care; Delivery of health care; Diagnosis; Patient care",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9637627"
    },
    {
      "pmid": "39529038",
      "title": "Evaluation of photoplethysmography-based monitoring of pulse rate, interbeat-intervals, and oxygen saturation during high-intensity interval training.",
      "abstract": "BACKGROUND: Heart disease patients necessitate precise monitoring to ensure the safety and efficacy of their physical activities when managing conditions such as hypertension or heart failure. This study, therefore, aimed to evaluate the accuracy of photoplethysmography (PPG)-based monitoring of pulse rate (PR), interbeat-intervals (IB-I) and oxygen saturation (SpO2) during high-intensity interval training (HIIT). METHODS: Between January and March 2024, healthy volunteers were subjected to a cycling HIIT workout with bike resistance increments to evaluate performance within different heart rate ranges. To determine the accuracy of PPG-based measurements for PR, IB-I, and SpO2 using the CardioWatch 287-2 (Corsano Health, the Netherlands), measurements throughout these ranges were compared to paired reference values from the Covidien Nellcor pulse oximeter (PM10N) and Vivalink's wearable ECG patch monitor. Subgroups were defined for Fitzpatrick skin type and gender. RESULTS: In total, 35 healthy individuals participated, resulting in 7183 paired measurements for PR, 22,713 for IB-I, and 41,817 for SpO2. The PR algorithm showed an average root mean square (Arms) of 2.51 beats per minute (bpm), bias at 0.05\u00a0bpm, and limits of agreement (LoA) from -4.87 to 4.97\u00a0bpm. The IB-I algorithm achieved an Arms of 23.00\u00a0ms, a bias of 1.00\u00a0ms, and LoA from -43.82 to 46.21\u00a0ms. Finally, the SpO2 algorithm showed an Arms of 1.28%, a bias of 0.13%, and LoA from -2.37% to 2.62%. The results were consistent across different demographic subgroups. CONCLUSIONS: This study demonstrates that the PPG-based CardioWatch 287-2 can accurately monitor PR, IB-I, and SpO2 during HIIT. However, further research is recommended to evaluate the algorithm's performance in heart disease patients during demanding exercise.",
      "authors": "Vijgeboom Tara; Muller Marjolein; Ebrahimkheil Kambiz; van Eijck Casper; Ronner Eelko",
      "year": "2024",
      "journal": "Biomedical engineering online",
      "doi": "10.1186/s12938-024-01309-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39529038/",
      "mesh_terms": "Humans; Photoplethysmography; Heart Rate; Male; Female; Oxygen Saturation; Adult; High-Intensity Interval Training; Monitoring, Physiologic; Young Adult; Signal Processing, Computer-Assisted; Oximetry; Healthy Volunteers",
      "keywords": "Continuous monitoring; High-intensity interval training; Interbeat intervals; Oxygen saturation; Photoplethysmography; Pulse rate",
      "pub_types": "Journal Article; Evaluation Study",
      "pmcid": "PMC11552347"
    },
    {
      "pmid": "39270211",
      "title": "Early Diagnosis of Hereditary Angioedema in Japan Based on a US Medical Dataset: Algorithm Development and Validation.",
      "abstract": "BACKGROUND: Hereditary angioedema (HAE), a rare genetic disease, induces acute attacks of swelling in various regions of the body. Its prevalence is estimated to be 1 in 50,000 people, with no reported bias among different ethnic groups. However, considering the estimated prevalence, the number of patients in Japan diagnosed with HAE remains approximately 1 in 250,000, which means that only 20% of potential HAE cases are identified. OBJECTIVE: This study aimed to develop an artificial intelligence (AI) model that can detect patients with suspected HAE using medical history data (medical claims, prescriptions, and electronic medical records [EMRs]) in the United States. We also aimed to validate the detection performance of the model for HAE cases using the Japanese dataset. METHODS: The HAE patient and control groups were identified using the US claims and EMR datasets. We analyzed the characteristics of the diagnostic history of patients with HAE and developed an AI model to predict the probability of HAE based on a generalized linear model and bootstrap method. The model was then applied to the EMR data of the Kyoto University Hospital to verify its applicability to the Japanese dataset. RESULTS: Precision and sensitivity were measured to validate the model performance. Using the comprehensive US dataset, the precision score was 2% in the initial model development step. Our model can screen out suspected patients, where 1 in 50 of these patients have HAE. In addition, in the validation step with Japanese EMR data, the precision score was 23.6%, which exceeded our expectations. We achieved a sensitivity score of 61.5% for the US dataset and 37.6% for the validation exercise using data from a single Japanese hospital. Overall, our model could predict patients with typical HAE symptoms. CONCLUSIONS: This study indicates that our AI model can detect HAE in patients with typical symptoms and is effective in Japanese data. However, further prospective clinical studies are required to investigate whether this model can be used to diagnose HAE.",
      "authors": "Yamashita Kouhei; Nomoto Yuji; Hirose Tomoya; Yutani Akira; Okada Akira; Watanabe Nayu; Suzuki Ken; Senzaki Munenori; Kuroda Tomohiro",
      "year": "2024",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/59858",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39270211/",
      "mesh_terms": "",
      "keywords": "AI; EHR; EHRs; EMR; EMRs; Electronic health record; HAE; ML; PHR; RWD; algorithm; algorithms; angioedema; artificial intelligence; big data; early detection; early warning; edema; electronic health records; electronic medical record; electronic medical records; health record; health records; machine learning; patient record; personal health record; practical model; practical models; prediction; predictive analytics; predictive model; predictive models; predictive system; rare diseases; real world data; screening",
      "pub_types": "Journal Article",
      "pmcid": "PMC11437219"
    },
    {
      "pmid": "39761454",
      "title": "Current Use And Evaluation Of Artificial Intelligence And Predictive Models In US Hospitals.",
      "abstract": "Effective evaluation and governance of predictive models used in health care, particularly those driven by artificial intelligence (AI) and machine learning, are needed to ensure that models are fair, appropriate, valid, effective, and safe, or FAVES. We analyzed data from the 2023 American Hospital Association Annual Survey Information Technology Supplement to identify how AI and predictive models are used and evaluated for accuracy and bias in hospitals. Hospitals use AI and predictive models to predict health trajectories or risks for inpatients, identify high-risk outpatients to inform follow-up care, monitor health, recommend treatments, simplify or automate billing procedures, and facilitate scheduling. We found that 65\u00a0percent of US hospitals used predictive models, and 79\u00a0percent of those used models from their electronic health record developer. Sixty-one percent of hospitals that used models evaluated them for accuracy using data from their health system (local evaluation), but only 44\u00a0percent reported local evaluation for bias. Hospitals that developed their own predictive models, had high operating margins, and were health system members were more likely to report local evaluation. Policy and programs that provide technical support, tools to assess FAVES principles, and educational resources would help ensure that all hospitals can use predictive models safely and prevent a new organizational digital divide in AI.",
      "authors": "Nong Paige; Adler-Milstein Julia; Apathy Nate C; Holmgren A Jay; Everson Jordan",
      "year": "2025",
      "journal": "Health affairs (Project Hope)",
      "doi": "10.1377/hlthaff.2024.00842",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39761454/",
      "mesh_terms": "Artificial Intelligence; United States; Humans; Hospitals; Machine Learning; Electronic Health Records; Forecasting",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39763535",
      "title": "A Natural Language Processing Pipeline based on the Columbia-Suicide Severity Rating Scale.",
      "abstract": "IMPORTANCE: Diagnostic codes in the Electronic Health Record (EHR) are known to be limited in reporting patient suicidality, and especially in differentiating the levels of suicide severity. OBJECTIVE: The authors developed and validated a portable natural language processing (NLP) algorithm for detection of suicidal ideation (SI) and suicide-related behavior and attempts (SB/SA) in EHR data. The algorithm was then deployed, and SI and SB/SA ascertainment was compared to that of International Statistical Classification of Diseases (ICD-9 and 10) diagnostic codes. DESIGN: A group of experts designed the pipeline to detect and distinguish suicide severity based on the Columbia-Suicide Severity Rating Scale (C-SSRS). Notes were manually annotated to create the \"Gold Standard\" with which the algorithm output was evaluated for accuracy. SETTING: The algorithm was developed at two academic medical centers, Weill Cornell Medicine (WCM), the Mount Sinai Health System (MSHS), and tested at these two, plus a third, the University of Utah Healthcare Center (UUHSC). PARTICIPANTS: Notes were from participants with psychiatric encounters at the three institutions. MAIN OUTCOMES: The two main outcomes were the accuracy scores of the NLP pipeline and comparison of ascertainment rates to ICD codes. RESULTS: F1 accuracy scores ranged from 0.86-0.97 at the three sites. The NLP rate of detection of SB/SA was almost 30 times higher, and SI was almost 10 times higher, when compared with that of diagnostic codes. NLP detected almost all cases detected by diagnostic codes. No bias in performance was found for race/ethnicity and performance was comparable in psychiatric and non-psychiatric EHRs. CONCLUSIONS AND RELEVANCE: EHRs from cohorts with psychiatric diagnoses or encounters at WCM, MSHS, and UUHSC had SI and SB/SA extracted using an NLP algorithm based on parameters defined by the C-SSRS. Validity was determined by comparing the algorithm output to manual annotations of clinical notes by domain experts. NLP-detection of SI and SB/SA was compared with that of ICD codes across a range of demographic groups. Algorithm performance was also examined for bias in minoritized groups and in non-psychiatric notes. KEY POINTS: Question: Can we automate the extraction of data available in clinical notes to accurately detect and distinguish patients with suicidal ideation (SI) and suicidal behavior (SB)?Findings: Our Natural Language Processing (NLP) approach was able to identify and distinguish SI and SB at three different hospital systems with benchmarked accuracy scores (above 0.85). The rate of detecting SI and SB using the algorithm was 10-30 times that of diagnostic codes found in the Electronic Health Record.Meaning: Our algorithm renders the use of International Classification of Disease (ICD) diagnostic codes for SI and SB ascertainment obsolete.",
      "authors": "Lepow Lauren A; Adekkanattu Prakash; Cusick Marika; Coon Hilary; Fennessy Brian; O'Connell Shane; Pierce Charlotte; Rabbany Jessica; Sharma Mohit; Olfson Mark; Bakian Amanda; Xiao Yunyu; Mullins Niamh; Nadkarni Girish N; Charney Alexander W; Pathak Jyotishman; Mann J John",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.12.19.24319352",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39763535/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC11702744"
    },
    {
      "pmid": "41385787",
      "title": "Lumbar Acceleration Gait Estimation: \"Step-by-Step\" Algorithm Updates and Improvements.",
      "abstract": "BACKGROUND: Digital health technologies, such as accelerometry, offer low participant burden and provide quantitative metrics with ease of deployment, making them increasingly popular for gait monitoring. Remote gait monitoring delivers quantifiable, continuous health measures over extended periods, surpassing the limited insights from single clinic or laboratory visits and offering a more comprehensive health perspective. Numerous gait algorithm implementations, inspired by prior research, aim to standardize these metrics across devices. The SciKit Digital Health (SKDH) package exemplifies this as a device-agnostic framework. OBJECTIVE: This study introduces a series of literature-informed enhancements to the SKDH gait algorithm, improving its performance against reference standards and reducing the need for manual parameter adjustments across diverse populations. METHODS: A block-wise refinement process was undertaken, examining each algorithmic component for potential enhancements and evaluating their cumulative impact on the complete gait algorithm and the metrics generated. RESULTS: Using data from healthy adult and pediatric participants, the novel gait event estimation method reduced the mean absolute error by more than 50% compared with its predecessor. Following the updates, the intraclass correlation values for final gait metric concordance with the in-laboratory reference improved markedly, from 0.50-0.74 to 0.81-0.90. Additionally, the systematic bias observed in the previous version's gait speed estimation was rectified, narrowing the difference from the reference from 0.065-0.230 to 0.00-0.03 m/s. CONCLUSIONS: The findings from this study provide robust evidence supporting the validity of the enhancements made to the gait algorithm. They demonstrate that a single lumbar accelerometer can capture gait characteristics with high accuracy and reliability across various speeds and age groups.",
      "authors": "Adamowicz Lukas; Lin Wenyi; Karahanoglu F Isik; Cai Xuemei; Santamaria Mar; Demanuele Charmaine; Di Junrui",
      "year": "2025",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/72831",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41385787/",
      "mesh_terms": "Humans; Algorithms; Gait; Adult; Accelerometry; Child; Male; Female; Gait Analysis; Young Adult; Lumbosacral Region; Acceleration",
      "keywords": "IMU; accelerometer; gait; walking; walking speed",
      "pub_types": "Journal Article",
      "pmcid": "PMC12743242"
    },
    {
      "pmid": "10117988",
      "title": "The validation of interviews for estimating morbidity.",
      "abstract": "Health interview surveys have been widely used to measure morbidity in developing countries, particularly for infectious diseases. Structured questionnaires using algorithms which derive sign/symptom-based diagnoses seem to be the most reliable but there have been few studies to validate them. The purpose of validation is to evaluate the sensitivity and specificity of brief algorithms (combinations of signs/symptoms) which can then be used for the rapid assessment of community health problems. Validation requires a comparison with an external standard such as physician or serological diagnoses. There are several potential pitfalls in assessing validity, such as selection bias, differences in populations and the pattern of diseases in study populations compared to the community. Validation studies conducted in the community may overcome bias caused by case selection. Health centre derived estimates can be adjusted and applied to the community with caution. Further study is needed to validate algorithms for important diseases in different cultural settings. Community-based studies need to be conducted, and the utility of derived algorithms for tracking disease frequency explored further.",
      "authors": "Kalter H",
      "year": "1992",
      "journal": "Health policy and planning",
      "doi": "10.1093/heapol/7.1.30",
      "url": "https://pubmed.ncbi.nlm.nih.gov/10117988/",
      "mesh_terms": "Algorithms; Bayes Theorem; Communicable Diseases; Data Collection; Developing Countries; Diagnosis; Health Services Needs and Demand; Health Surveys; Humans; Interviews as Topic; Morbidity; Reproducibility of Results; Selection Bias",
      "keywords": "Child Health; Communication; Critique; Data Collection; Developing Countries; Diseases; Estimation Technics; Health; Indirect Estimation Technics; Interviews; Language; Measurement; Morbidity; Prevalence; Questionnaire Design; Research Methodology; Sampling Studies; Signs And Symptoms; Studies; Survey Methodology; Surveys; Validity--determinants",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38714097",
      "title": "Incremental Healthcare Costs of Diabetes Mellitus in a Middle-Income Country Using Administrative Healthcare Data.",
      "abstract": "OBJECTIVES: To estimate the incremental medical cost of diabetes mellitus using information from administrative databases in Colombia. METHODS: We carried out a retrospective cohort study with administrative health databases from Colombian population affiliated in the contributory health insurance scheme. We used an operative definition to select the cohort with diabetes. Incremental cost and cost ratio of diabetes were estimated using an inverse probability weighting of treatment approach to find the causal effect of having the disease. Weights were calculated by a propensity score method using a Random Forest model. The flexibility of this machine learning algorithm allows to have a better specification and bias reduction. Additionally, we reported incremental costs and cost ratios with confidence intervals using bootstrapping and analyzed costs by age groups and complications associated with diabetes. RESULTS: The estimated prevalence of diabetes was 2834 per 100 000 cases, in 2018. The group with diabetes was comprised 634 015 people and the control group 1 524 808. The calculated annual direct medical cost was $860, for which the incremental cost was $493 and the cost ratio 2.34. The incremental annual cost for some type of complication ranges from $1239 to $2043, renal complication being the most expensive. Incremental cost by age groups ranges from $347 to $878, being higher in younger people. CONCLUSIONS: Although the cost of diabetes in Colombia ranges among the global averages and is similar to other Latin-American countries, a greater incremental cost was found in patients with renal, circulatory, and neurologic complications.",
      "authors": "Castro-Villarreal Santiago; Miksi Sara; Beltr\u00e1n-Ostos Adriana; Valencia Carlos F",
      "year": "2024",
      "journal": "Value in health regional issues",
      "doi": "10.1016/j.vhri.2024.100992",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38714097/",
      "mesh_terms": "Humans; Colombia; Retrospective Studies; Diabetes Mellitus; Male; Middle Aged; Health Care Costs; Female; Adult; Aged; Prevalence; Adolescent; Databases, Factual",
      "keywords": "administrative databases; diabetes; incremental cost; inverse probability weighting estimation; medical cost estimation",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36816027",
      "title": "Ethical layering in AI-driven polygenic risk scores-New complexities, new challenges.",
      "abstract": "Researchers aim to develop polygenic risk scores as a tool to prevent and more effectively treat serious diseases, disorders and conditions such as breast cancer, type 2 diabetes mellitus and coronary heart disease. Recently, machine learning techniques, in particular deep neural networks, have been increasingly developed to create polygenic risk scores using electronic health records as well as genomic and other health data. While the use of artificial intelligence for polygenic risk scores may enable greater accuracy, performance and prediction, it also presents a range of increasingly complex ethical challenges. The ethical and social issues of many polygenic risk score applications in medicine have been widely discussed. However, in the literature and in practice, the ethical implications of their confluence with the use of artificial intelligence have not yet been sufficiently considered. Based on a comprehensive review of the existing literature, we argue that this stands in need of urgent consideration for research and subsequent translation into the clinical setting. Considering the many ethical layers involved, we will first give a brief overview of the development of artificial intelligence-driven polygenic risk scores, associated ethical and social implications, challenges in artificial intelligence ethics, and finally, explore potential complexities of polygenic risk scores driven by artificial intelligence. We point out emerging complexity regarding fairness, challenges in building trust, explaining and understanding artificial intelligence and polygenic risk scores as well as regulatory uncertainties and further challenges. We strongly advocate taking a proactive approach to embedding ethics in research and implementation processes for polygenic risk scores driven by artificial intelligence.",
      "authors": "Fritzsche Marie-Christine; Aky\u00fcz Kaya; Cano Abad\u00eda M\u00f3nica; McLennan Stuart; Marttinen Pekka; Mayrhofer Michaela Th; Buyx Alena M",
      "year": "2023",
      "journal": "Frontiers in genetics",
      "doi": "10.3389/fgene.2023.1098439",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36816027/",
      "mesh_terms": "",
      "keywords": "artificial intelligence\u2013AI; deep neural network (DNN); ethical; genomics; machine learning (ML); polygenic risk score; predictive medicine; stratification",
      "pub_types": "Journal Article",
      "pmcid": "PMC9933509"
    },
    {
      "pmid": "31293245",
      "title": "Artificial Intelligence and the Implementation Challenge.",
      "abstract": "BACKGROUND: Applications of artificial intelligence (AI) in health care have garnered much attention in recent years, but the implementation issues posed by AI have not been substantially addressed. OBJECTIVE: In this paper, we have focused on machine learning (ML) as a form of AI and have provided a framework for thinking about use cases of ML in health care. We have structured our discussion of challenges in the implementation of ML in comparison with other technologies using the framework of Nonadoption, Abandonment, and Challenges to the Scale-Up, Spread, and Sustainability of Health and Care Technologies (NASSS). METHODS: After providing an overview of AI technology, we describe use cases of ML as falling into the categories of decision support and automation. We suggest these use cases apply to clinical, operational, and epidemiological tasks and that the primary function of ML in health care in the near term will be decision support. We then outline unique implementation issues posed by ML initiatives in the categories addressed by the NASSS framework, specifically including meaningful decision support, explainability, privacy, consent, algorithmic bias, security, scalability, the role of corporations, and the changing nature of health care work. RESULTS: Ultimately, we suggest that the future of ML in health care remains positive but uncertain, as support from patients, the public, and a wide range of health care stakeholders is necessary to enable its meaningful implementation. CONCLUSIONS: If the implementation science community is to facilitate the adoption of ML in ways that stand to generate widespread benefits, the issues raised in this paper will require substantial attention in the coming years.",
      "authors": "Shaw James; Rudzicz Frank; Jamieson Trevor; Goldfarb Avi",
      "year": "2019",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/13659",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31293245/",
      "mesh_terms": "Artificial Intelligence; Humans; Machine Learning; Telemedicine",
      "keywords": "artificial intelligence; ethics; implementation science; machine learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6652121"
    },
    {
      "pmid": "40367064",
      "title": "From manual clinical criteria to machine learning algorithms: Comparing outcome endpoints derived from diverse electronic health record data modalities.",
      "abstract": "BACKGROUND: Progression free survival (PFS) is a critical clinical outcome endpoint during cancer management and treatment evaluation. Yet, PFS is often missing from publicly available datasets due to the current subjective, expert, and time-intensive nature of generating PFS metrics. Given emerging research in multi-modal machine learning (ML), we explored the benefits and challenges associated with mining different electronic health record (EHR) data modalities and automating extraction of PFS metrics via ML algorithms. METHODS: We analyzed EHR data from 92 pathology-proven GBM patients, obtaining 233 corticosteroid prescriptions, 2080 radiology reports, and 743 brain MRI scans. Three methods were developed to derive clinical PFS: 1) frequency analysis of corticosteroid prescriptions, 2) natural language processing (NLP) of reports, and 3) computer vision (CV) volumetric analysis of imaging. Outputs from these methods were compared to manually annotated clinical guideline PFS metrics. RESULTS: Employing data-driven methods, standalone progression rates were 63% (prescription), 78% (NLP), and 54% (CV), compared to the 99% progression rate from manually applied clinical guidelines using integrated data sources. The prescription method identified progression an average of 5.2 months later than the clinical standard, while the CV and NLP algorithms identified progression earlier by 2.6 and 6.9 months, respectively. While lesion growth is a clinical guideline progression indicator, only half of patients exhibited increasing contrast-enhancing tumor volumes during scan-based CV analysis. CONCLUSION: Our results indicate that data-driven algorithms can extract tumor progression outcomes from existing EHR data. However, ML methods are subject to varying availability bias, supporting contextual information, and pre-processing resource burdens that influence the extracted PFS endpoint distributions. Our scan-based CV results also suggest that the automation of clinical criteria may not align with human intuition. Our findings indicate a need for improved data source integration, validation, and revisiting of clinical criteria in parallel to multi-modal ML algorithm development.",
      "authors": "Chappidi Shreya; Belue Mason J; Harmon Stephanie A; Jagasia Sarisha; Zhuge Ying; Tasci Erdal; Turkbey Baris; Singh Jatinder; Camphausen Kevin; Krauze Andra V",
      "year": "2025",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000755",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40367064/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12077705"
    },
    {
      "pmid": "24693862",
      "title": "Identifying diabetics in Medicare claims and survey data: implications for health services research.",
      "abstract": "BACKGROUND: Diabetes health services research often utilizes secondary data sources, including survey self-report and Medicare claims, to identify and study the diabetic population, but disagreement exists between these two data sources. We assessed agreement between the Chronic Condition Warehouse diabetes algorithm for Medicare claims and self-report measures of diabetes. Differences in healthcare utilization outcomes under each diabetes definition were also explored. METHODS: Claims data from the Medicare Beneficiary Annual Summary File were linked to survey and blood data collected from the 2006 Health and Retirement Study. A Hemoglobin A1c reading, collected on 2,028 respondents, was used to reconcile discrepancies between the self-report and Medicare claims measures of diabetes. T-tests were used to assess differences in healthcare utilization outcomes for each diabetes measure. RESULTS: The Chronic Condition Warehouse (CCW) algorithm yielded a higher rate of diabetes than respondent self-reports (27.3 vs. 21.2, p\u2009<\u20090.05). A1c levels of discordant claims-based diabetics suggest that these patients are not diabetic, however, they have high rates of healthcare spending and utilization similar to diabetics. CONCLUSIONS: Concordance between A1c and self-reports was higher than for A1c and the CCW algorithm. Accuracy of self-reports was superior to the CCW algorithm. False positives in the claims data have similar utilization profiles to diabetics, suggesting minimal bias in some types of claims-based analyses, though researchers should consider sensitivity analysis across definitions for health services research.",
      "authors": "Sakshaug Joseph W; Weir David R; Nicholas Lauren H",
      "year": "2014",
      "journal": "BMC health services research",
      "doi": "10.1186/1472-6963-14-150",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24693862/",
      "mesh_terms": "Aged; Aged, 80 and over; Algorithms; Diabetes Mellitus; Female; Glycated Hemoglobin; Health Services Research; Humans; Insurance Claim Review; Male; Medicare; Prevalence; United States",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC3975984"
    },
    {
      "pmid": "18002861",
      "title": "An orientation measuring system suitable for routine uses made by the fusion of a 3D gyroscope and a magnetic tracker.",
      "abstract": "Many studies have shown the efficacy of orientation and three-dimensional joint angle measurement for patient evaluation or rehabilitation purposes. But currently, the use of these systems for routine practice is questionable. The commercially available devices are generally too expensive and complicated-to-use. This study proposed the fusion between two affordable types of orientation measuring systems, which used separately couldn't satisfy the health professionals' needs. One was a portable magnetic tracker limited in accuracy, sampling frequency and possibly distorted. The other was triplets of gyroscopes limited by their bias, which generates orientation drift after integration. The fusion algorithm presented here relay on two cascaded complementary Kalman filters to estimate the bias of the gyroscopes and to provide accurate and high frequency orientation even during distortion periods. This system was assessed during treadmill walking and reported good performances.",
      "authors": "Favre Julien; Chardonnens Julien; Aminian Kamiar",
      "year": "2007",
      "journal": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference",
      "doi": "10.1109/IEMBS.2007.4353195",
      "url": "https://pubmed.ncbi.nlm.nih.gov/18002861/",
      "mesh_terms": "Algorithms; Computer Simulation; Humans; Magnetics; Models, Biological; Range of Motion, Articular",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32058264",
      "title": "The application of artificial intelligence (AI) techniques to identify frailty within a residential aged care administrative data set.",
      "abstract": "INTRODUCTION: Research has shown that frailty, a geriatric syndrome associated with an increased risk of negative outcomes for older people, is highly prevalent among residents of residential aged care facilities (also called long term care facilities or nursing homes). However, progress on effective identification of frailty within residential care remains at an early stage, necessitating the development of new methods for accurate and efficient screening. OBJECTIVES: We aimed to determine the effectiveness of artificial intelligence (AI) algorithms in accurately identifying frailty among residents aged 75 years and over in comparison with a calculated electronic Frailty Index (eFI) based on a routinely-collected residential aged care administrative data set drawn from 10 residential care facilities located in Queensland, Australia. A secondary objective included the identification of best-performing candidate algorithms. METHODS: We designed a frailty prediction system based on the eFI identification of frailty, allocating 84.5 % and 15.5 % of the data to training and test data sets respectively. We compared the performance of 18 specific scenarios to predict frailty against eFI based on unique combinations of three ML algorithms (support vector machines [SVM], decision trees [DT] and K-nearest neighbours [KNN]) and six cases (6, 10, 11, 14, 39 and 70 input variables). We calculated accuracy, percentage positive and negative agreement, sensitivity, specificity, Cohen's kappa and Prevalence- and Bias- Adjusted Kappa (PABAK), table frequencies and positive and negative predictive values. RESULTS: Of 592 eligible resident records, 500 were allocated to the training set and 92 to the test set. Three scenarios (10, 11 and 70 input variables), all based on SVM algorithm, returned overall accuracy above 75 %. CONCLUSIONS: There is some potential for AI techniques to contribute towards better frailty identification within residential care. However, potential benefits will need to be weighed against administrative burden, data quality concerns and presence of potential bias.",
      "authors": "Ambagtsheer R C; Shafiabady N; Dent E; Seiboth C; Beilby J",
      "year": "2020",
      "journal": "International journal of medical informatics",
      "doi": "10.1016/j.ijmedinf.2020.104094",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32058264/",
      "mesh_terms": "Aged; Aged, 80 and over; Artificial Intelligence; Assisted Living Facilities; Australia; Cross-Sectional Studies; Delivery of Health Care; Female; Frailty; Geriatric Assessment; Homes for the Aged; Humans; Male; Mass Screening; Nursing Homes; Queensland; Retrospective Studies",
      "keywords": "Artificial intelligence; Frailty; Health records; Machine learning; Personal; Residential facilities",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40548850",
      "title": "Electrocardiogram-Based Artificial Intelligence for Detection of Low Ejection Fraction: A Contemporary Review.",
      "abstract": "Artificial intelligence (AI) is transforming the role of electrocardiography (ECG) in cardiovascular care, enabling early disease detection, improved risk stratification, and optimized therapeutic decision-making. This review explores recent advances in AI-enhanced ECG (AI-ECG) applications, with a focus on both technical innovations and clinical integration. Key developments include deep learning models capable of detecting structural heart disease, arrhythmias, and even systemic conditions from ECG data. Emphasis is placed on the need for model explainability, fairness, and generalizability through diverse training datasets and interpretable algorithms. Multimodal learning, federated approaches, and temporal modeling are highlighted as emerging strategies to enhance model robustness and clinical relevance. Integration into electronic health records, prospective validation studies, and regulatory considerations are discussed as essential steps toward real-world adoption. Additionally, AI-driven remote monitoring through wearable devices offers scalable solutions for early intervention, though challenges around accuracy, alarm fatigue, and cost-effectiveness remain. Finally, global collaboration and policy frameworks are necessary to ensure equitable, ethical, and sustainable deployment of AI-ECG technologies. Collectively, this work underscores the transformative potential of AI-ECG while outlining critical directions for its safe and effective implementation in clinical practice.",
      "authors": "Tran Hadrian Hoang-Vu; Thu Audrey; Fuertes Axel; Twayana Anu Radha; Mahadevaiah Ashwini; Mehta Krutagni Adwait; James Maggie; Basta Marina; Weissman Simcha; Frishman Wiliam H; Aronow Wilbert S",
      "year": "2025",
      "journal": "Cardiology in review",
      "doi": "10.1097/CRD.0000000000000975",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40548850/",
      "mesh_terms": "",
      "keywords": "AI-ECG; artificial intelligence; cardiovascular diagnostics; electrocardiography; machine learning",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34330583",
      "title": "Volunteering as an Equalizer: A Quasi-Experimental Study Using Propensity Score Analysis.",
      "abstract": "INTRODUCTION: Formal volunteering in later life is beneficial for both physical and psychological well-being. However, research points to potential selection bias because older adults with key advantages, such as wealth, are more likely to volunteer and reap its benefits. Accordingly, this study addresses this selection bias by considering the characteristics of volunteers and nonvolunteers using the inverse probability of treatment weighting. It also examines whether volunteering has differential impacts between the highest and lowest wealth quintiles using inverse probability of treatment weighting. METHODS: Data were analyzed from the 2004-2016 waves of the Health and Retirement Study (N=90,881). The weights, created using a machine learning method, were incorporated in the analysis to estimate the treatment effects along with relevant covariates. Analyses were conducted in 2020. RESULTS: Volunteering enhanced self-reported health and reduced depressive symptoms in the full sample. Furthermore, those in the lowest wealth quintile experienced significantly better self-reported health from volunteering than their wealthy counterparts. Volunteering was associated with fewer depressive symptoms regardless of wealth status. CONCLUSIONS: The study enhances the understanding of formal volunteering and health while suggesting that volunteers with low wealth may benefit more from volunteering in terms of their health. Hindrances to volunteering among the least wealthy, such as financial distress, discrimination, or lack of organizational support, may attenuate the benefits of voluntary activity.",
      "authors": "Kim Seoyoun; Halvorsen Cal J",
      "year": "2021",
      "journal": "American journal of preventive medicine",
      "doi": "10.1016/j.amepre.2021.05.004",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34330583/",
      "mesh_terms": "Aged; Humans; Propensity Score; Retirement; Selection Bias; Volunteers",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32632685",
      "title": "Environmental air pollution clustering using enhanced ensemble clustering methodology.",
      "abstract": "Air pollution these days could cause severe effects on human health. As human health is crumbled with serious respiratory or other lung diseases, it is prominent to study air pollution. One of the ways to address this issue is by applying clustering techniques. The two main important problems that are faced in the clustering algorithm are, firstly, the exact shape of the cluster and the number of clusters that input data can produce. Secondly, choosing an appropriate algorithm for a particular problem is not clearly known. Finally, multiple replications of the same algorithm lead to alternative solutions due to the fact such as random initialization of cluster heads. Ensembling algorithms can handle these problems and overcome bias and variance in the traditional clustering process. An adequate study has not been carried out in the ensembling approach mainly for clustering. In this paper, we use an enhanced ensemble clustering method to cluster the pollution data levels. This study helps to take preventive measures that are needed to control further contamination, reduce the alarming levels, and analyze the results to find healthy and unhealthy regions in a given area. This ensemble technique also explains about uncertain objects that are found in clustering. The distinct advantage of this algorithm is that there is no requirement of prior information about the data. This experiment shows that the implemented ensemble consensus clustering has demonstrated improved performance when compared with basic clustering algorithms.",
      "authors": "Vandhana Soundararaj; Anuradha Jagadeesan",
      "year": "2021",
      "journal": "Environmental science and pollution research international",
      "doi": "10.1007/s11356-020-09962-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32632685/",
      "mesh_terms": "Air Pollution; Algorithms; Cluster Analysis; Environmental Pollution; Humans",
      "keywords": "Air pollution; Cluster certainty; Consensus functions; Ensemble clustering; Ensemble members; Similarity matrix",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40357530",
      "title": "Advancing the Use of Longitudinal Electronic Health Records: Tutorial for Uncovering Real-World Evidence in Chronic Disease Outcomes.",
      "abstract": "Managing chronic diseases requires ongoing monitoring of disease activity and therapeutic responses to optimize treatment plans. With the growing availability of disease-modifying therapies, it is crucial to investigate comparative effectiveness and long-term outcomes beyond those available from randomized clinical trials. We introduce a comprehensive pipeline for generating reproducible and generalizable real-world evidence on disease outcomes by leveraging electronic health record data. The pipeline first generates scalable disease outcomes by linking electronic health record data with registry data containing a small sample of labeled outcomes. It then applies causal analysis using these scalable outcomes to evaluate therapies for chronic diseases. The implementation of the pipeline is illustrated in a case study based on multiple sclerosis. Our approach addresses challenges in real-world evidence generation for disease activity of chronic conditions, specifically the lack of direct observations on key outcomes and biases arising from imperfect or incomplete data. We present advanced machine learning techniques such as semisupervised and ensemble methods to impute missing outcome data, further incorporating steps for calibrated causal analyses and bias correction.",
      "authors": "Huang Feiqing; Hou Jue; Zhou Ningxuan; Greco Kimberly; Lin Chenyu; Sweet Sara Morini; Wen Jun; Shen Lechen; Gonzalez Nicolas; Zhang Sinian; Liao Katherine P; Cai Tianrun; Xia Zongqi; Bourgeois Florence T; Cai Tianxi",
      "year": "2025",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/71873",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40357530/",
      "mesh_terms": "Electronic Health Records; Humans; Chronic Disease; Multiple Sclerosis; Machine Learning; Longitudinal Studies",
      "keywords": "calibration; causal inference; chronic disease outcomes; data imputation; electronic health records; longitudinal disease activity; machine learning; real-world evidence",
      "pub_types": "Journal Article",
      "pmcid": "PMC12107207"
    },
    {
      "pmid": "36430005",
      "title": "PREVIDE: A Qualitative Study to Develop a Decision-Making Framework (PREVention decIDE) for Noncommunicable Disease Prevention in Healthcare Organisations.",
      "abstract": "Noncommunicable diseases (NCDs), including obesity, remain a significant global public health challenge. Prevention and public health innovation are needed to effectively address NCDs; however, understanding of how healthcare organisations make prevention decisions is immature. This study aimed to (1) explore how healthcare organisations make decisions for NCD prevention in Queensland, Australia (2) develop a contemporary decision-making framework to guide NCD prevention in healthcare organisations. Cross-sectional and qualitative design, comprising individual semi-structured interviews. Participants (n = 14) were recruited from two organisations: the state public health care system (CareQ) and health promotion/disease prevention agency (PrevQ). Participants held executive, director/manager or project/clinical lead roles. Data were analysed in two phases (1) automated content analysis using machine learning (Leximancer v4.5) (2) researcher-led interpretation of the text analytics. Final themes were consolidated into a proposed decision-making framework (PREVIDE, PREvention decIDE) for NCD prevention in healthcare organisations. Decision-making was driven by four themes: Data, Evidence, Ethics and Health, i.e., data, its quality and the story it tells; traditional and non-traditional sources of evidence; ethical grounding in fairness and equity; and long-term value generated across multiple determinants of health. The strength of evidence was directly proportional to confidence in the ethics of a decision. PREVIDE can be adapted by public health practitioners and policymakers to guide real-world policy, practice and investment decisions for obesity prevention and with further validation, other NCDs and priority settings (e.g., healthcare).",
      "authors": "Canfell Oliver J; Davidson Kamila; Sullivan Clair; Eakin Elizabeth E; Burton-Jones Andrew",
      "year": "2022",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph192215285",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36430005/",
      "mesh_terms": "Humans; Noncommunicable Diseases; Cross-Sectional Studies; Delivery of Health Care; Qualitative Research; Obesity",
      "keywords": "decision-making; health policy; noncommunicable diseases; obesity; precision public health; preventive medicine; public health; public health informatics",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9690592"
    },
    {
      "pmid": "7863724",
      "title": "An algorithm to estimate age in women during their childbearing years.",
      "abstract": "Estimating age in women living in rural areas of Papua New Guinea can be inaccurate and subject to observer bias. Parity is often used, but this means that survey results cannot be used to examine the effect of childbearing on nutrition. We describe a method for estimating age in women independent of their parity developed during studies of women's health in the Wosera Subdistrict of Papua New Guinea. The tool, appropriately modified, may be useful to others conducting surveys requiring an estimate of maternal age.",
      "authors": "Baea M; Garner P; Lai D",
      "year": "1994",
      "journal": "Papua and New Guinea medical journal",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/7863724/",
      "mesh_terms": "Adolescent; Adult; Algorithms; Female; Humans; Maternal Age; Middle Aged; Parity; Women's Health",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "21969088",
      "title": "Understanding appraisal processes underlying the thentest: a mixed methods investigation.",
      "abstract": "AIMS: Mixed methods investigated the cognitive processes reflected in retrospective pretest (thentest) discrepancy scores [i.e., recalibration response shift (RS)]. METHODS: People with human immunodeficiency virus/acquired immune disease syndrome (HIV/AIDS) (n\u00a0=\u00a0521) were interviewed at baseline and 6\u00a0months using the Quality of Life (QOL) Appraisal Profile, the Rand-36, General Health thentest, and recall items. Open-ended appraisal questions were coded, and factor analyses reduced the data. Ipsative (based on the then-minus-pretest) and normative (based on regression residuals) discrepancy scores were compared. Hypothesis testing related to recall bias and relationships among appraisal parameters and ipsative discrepancies, after covariate adjustment. RESULTS: Coded frame of reference themes were distinct from experience sampling, standards of comparison, and combinatory algorithm. There was convergence between the ipsative and normative discrepancy scores (r\u00a0=\u00a00.30), but the former were associated with more appraisal changes and goal-related appraisals than the latter. Thentest effect sizes (ES) were larger than standard change scores, even controlling for recall bias. Multivariate models including appraisal parameters explained 9% more variance over the standard (unadjusted for RS) model. CONCLUSIONS: Ipsative and normative discrepancy scores measure distinct constructs, represent different configurations of appraisal change, and are not invalidated or explained by recall bias. The thentest does not imply recalibration alone but rather a host of health- and self-care-related concerns.",
      "authors": "Schwartz Carolyn E; Rapkin Bruce D",
      "year": "2012",
      "journal": "Quality of life research : an international journal of quality of life aspects of treatment, care and rehabilitation",
      "doi": "10.1007/s11136-011-0023-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/21969088/",
      "mesh_terms": "Algorithms; Factor Analysis, Statistical; Female; HIV Infections; Health Services Research; Humans; Interviews as Topic; Male; Mental Recall; Middle Aged; Psychometrics; Quality of Life; Reproducibility of Results; Research Design; Sickness Impact Profile",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "40825473",
      "title": "Developmental Foundations of a Pediatric Mental Health Risk Calculator for Young Children.",
      "abstract": "OBJECTIVE: To advance the clinical utility of an emerging risk calculator for identifying when to worry and when to act when young children show signs of mental health concerns in pediatric care, we\u00a01) replicate an early childhood mental health risk algorithm (DECIDE); 2) determine the preliminary predictive utility of additional child and parenting assets, advancing a strengths-based framework to reduce the likelihood of biased identification. METHODS: Data were from 2 independent studies: the national Future of Families and Child Wellbeing Study (FFCWS; N\u00a0=\u00a02763) and the regional Mental Health, Earlier Synthetic Cohort study (MHESC; N\u00a0=\u00a0323). Predictors were assessed in toddlerhood/early preschool age. Internalizing/externalizing problems were measured in older preschoolers, serving as outcomes. Epidemiologic risk prediction methods were applied to\u00a01) replicate the DECIDE risk algorithm domains comprised of demographics, child irritability, and adverse childhood experiences; 2) examine the added predictive utility of child and parenting assets. Predictive utility was based on area under the curve (AUC) and/or the integrated discrimination improvement (IDI). RESULTS: The DECIDE algorithm was replicated in FFCWS and MHESC (AUC\u00a0=\u00a00.70 for both studies; IDI\u00a0=\u00a00.07 in FFCWS and 0.06 in MHESC). IDIs indicated predictive utility for child assets beyond the existing DECIDE algorithm in both studies, and for parenting assets in FFCWS. CONCLUSIONS: Robust validation of predictive algorithms is critical for assessing generalizability. Reducing bias in early mental health risk algorithms via a strengths-based approach is key to equitable decision-making. This work lays the foundation for implementation of early mental health decision tools in routine care of young children.",
      "authors": "MacNeill Leigha A; Zhang Yudong; Giase Gina M; Wiggins Jillian Lee; Norton Elizabeth S; Smith Justin D; Davis Matthew M; Raven Julia G; Poleon Roshaye B; Yu Qiongru; Smyser Christopher D; Rogers Cynthia E; Luby Joan L; Allen Norrina B; Wakschlag Lauren S",
      "year": "2026",
      "journal": "Academic pediatrics",
      "doi": "10.1016/j.acap.2025.103128",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40825473/",
      "mesh_terms": "Humans; Child, Preschool; Male; Female; Risk Assessment; Algorithms; Mental Health; Parenting; Mental Disorders; Infant; Adverse Childhood Experiences; Cohort Studies",
      "keywords": "clinical decision-making; developmentally-informed; early childhood mental health; risk calculator",
      "pub_types": "Journal Article",
      "pmcid": "PMC12677145"
    },
    {
      "pmid": "34337602",
      "title": "A Survey of Challenges and Opportunities in Sensing and Analytics for Risk Factors of Cardiovascular Disorders.",
      "abstract": "Cardiovascular disorders cause nearly one in three deaths in the United States. Short- and long-term care for these disorders is often determined in short-term settings. However, these decisions are made with minimal longitudinal and long-term data. To overcome this bias towards data from acute care settings, improved longitudinal monitoring for cardiovascular patients is needed. Longitudinal monitoring provides a more comprehensive picture of patient health, allowing for informed decision making. This work surveys sensing and machine learning in the field of remote health monitoring for cardiovascular disorders. We highlight three needs in the design of new smart health technologies: (1) need for sensing technologies that track longitudinal trends of the cardiovascular disorder despite infrequent, noisy, or missing data measurements; (2) need for new analytic techniques designed in a longitudinal, continual fashion to aid in the development of new risk prediction techniques and in tracking disease progression; and (3) need for personalized and interpretable machine learning techniques, allowing for advancements in clinical decision making. We highlight these needs based upon the current state of the art in smart health technologies and analytics. We then discuss opportunities in addressing these needs for development of smart health technologies for the field of cardiovascular disorders and care.",
      "authors": "Hurley Nathan C; Spatz Erica S; Krumholz Harlan M; Jafari Roozbeh; Mortazavi Bobak J",
      "year": "2021",
      "journal": "ACM transactions on computing for healthcare",
      "doi": "10.1145/3417958",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34337602/",
      "mesh_terms": "",
      "keywords": "Cardiovascular disease; cardiovascular risk factors; longitudinal monitoring; patient analytics; sensors; smart health",
      "pub_types": "Journal Article",
      "pmcid": "PMC8320445"
    },
    {
      "pmid": "40247042",
      "title": "Predicting coronary heart disease with advanced machine learning classifiers for improved cardiovascular risk assessment.",
      "abstract": "Worldwide, coronary heart disease (CHD) is a leading cause of mortality, and its early prediction remains a critical challenge in clinical data analysis. Machine learning (ML) offers valuable diagnostic support by leveraging healthcare data to enhance decision-making and prediction accuracy. Although numerous studies have applied ML classifiers for heart disease prediction, their contributions often lack clarity in addressing key challenges. In this paper, we present a comprehensive ML framework that systematically tackles these issues. First, we employ mutual information (MI) for effective feature selection to isolate the most informative predictors. Second, we address the significant class imbalance in the dataset using the Synthetic Minority Oversampling Technique (SMOTE), which substantially improves model training. Third, we propose a novel hybrid model that integrates particle swarm optimization (PSO) with an artificial neural network (ANN) to optimize feature weighting and bias training. Additionally, we conduct a comparative analysis with traditional classifiers, including Logistic Regression and Random Forest, using the National Health and Nutritional Examination Survey dataset. Our results demonstrate that while conventional classifiers achieve an accuracy of 95.8%, the proposed PSO-ANN model attains an enhanced accuracy of up to 97% in predicting CHD. This work clearly defines its contributions by improving feature selection, handling data imbalance, and introducing an innovative hybrid model for superior prediction performance.",
      "authors": "Rehman Moiz Ur; Naseem Shahid; Butt Ateeq Ur Rehman; Mahmood Tariq; Khan Amjad Rehman; Khan Inayat; Khan Jawad; Jung Younhyun",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-96437-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40247042/",
      "mesh_terms": "Humans; Machine Learning; Risk Assessment; Coronary Disease; Neural Networks, Computer; Male; Female; Middle Aged; Aged",
      "keywords": "Artificial Neural Network; Coronary Heart Disease; Health Informatics; Health Issues; Machine Learning; Medical Images; Mutual Information; Particle Swarm Optimization",
      "pub_types": "Journal Article",
      "pmcid": "PMC12006408"
    },
    {
      "pmid": "40378128",
      "title": "Robust performances of a nocturnal long-term ECG algorithm for the evaluation of sleep apnea syndrome: A pilot study.",
      "abstract": "Obstructive sleep apnea-hypopnea syndrome (OSAHS) is one of the most common sleep disorders affecting nearly one billion of the global adult population, making it a major public health issue. Even if in-lab polysomnography (PSG) remains the gold standard to diagnose OSAHS, there is a growing interest to develop new solutions with more convenient at home devices enhanced with AI-based algorithms for the detection of sleep apnea. This retrospective study aimed to assess the performances of a new method based on nocturnal long-term electrocardiogram signal to detect apneas and hypopneas, in patients who performed attended in-lab PSG. After assessing the quality of the ECG signal, the new method automatically detected apneas and hypopneas using dedicated machine learning algorithm. The agreement between the new ECG-based detection method and the standard interpretation of PSG by a sleep clinician was determined in a blind manner. Eighty-five exams were included into the study with a mean bias between the proposed method and the scorer of 3.5 apneas-hypopneas/hour (/h) (95% CI -48.1 to 55.1). At a threshold of 15/h, sensibility and specificity were 93.3% and 66.7% respectively, and positive and negative predictive values were 87.5% and 80%, respectively. The proposed method using nocturnal long-term electrocardiogram signals showed very high performances to detect apneas and hypopneas. Its implementation in a simple ECG-based device would offer a promising opportunity for preliminary evaluation of patients suspected or at-risk of OSAHS.",
      "authors": "Guyot Pauline; Eveilleau Morgane; Bastogne Thierry; Ayav Carole; Carpentier Nicolas; Chenuel Bruno",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0318622",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40378128/",
      "mesh_terms": "Humans; Pilot Projects; Electrocardiography; Algorithms; Female; Male; Middle Aged; Polysomnography; Retrospective Studies; Adult; Sleep Apnea Syndromes; Sleep Apnea, Obstructive; Aged",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12083785"
    },
    {
      "pmid": "36191488",
      "title": "Biomarkers of maternal lead exposure during pregnancy using micro-spatial child deciduous dentine measurements.",
      "abstract": "BACKGROUND: Lead is a toxic chemical of public health concern, however limited biomarkers are able to reconstruct prior lead exposures in early-life when biospecimens are not collected and stored. Although child tooth dentine measurements accurately assess past child perinatal lead exposure, it has not been established if they reflect maternal exposure in pregnancy. AIM: To assess the prenatal relationship between child tooth dentine and maternal blood lead measurements and to estimate maternal lead exposure during the 2nd and 3rd trimesters of pregnancy from weekly child dentine profiles. METHODS: We measured early-life lead exposure in child tooth dentine and maternal blood from 419 child-mother dyads enrolled in the Programming Research in Obesity, Growth, Environment and Social Stress (PROGRESS) cohort. We employed the Super-Learner algorithm to determine the relationship of dentine lead data with maternal blood lead concentrations and to predict maternal lead from child dentine lead data in blinded analyses. We validated and quantified the bias of our results internally. RESULTS: Mothers had moderate blood lead levels (trimesters: 2nd\u00a0=\u00a029.45 ug/L, 3rd\u00a0=\u00a031.78 ug/L). Trimester-averaged and weekly child dentine lead measurements were highly correlated with maternal blood levels in the corresponding trimesters. The predicted trimester-specific maternal lead levels were significantly correlated with actual measured blood values (trimesters: 2nd\u00a0=\u00a00.83; 3rd\u00a0=\u00a00.88). Biomarkers of maternal lead exposure discriminated women highly exposed to lead (>mean) with 85\u00a0% and 96\u00a0% specificity in the 2nd and 3rd trimesters, respectively, with 80\u00a0% sensitivity. DISCUSSION: Weekly child dentine lead levels can serve as biomarkers of past child and maternal lead exposures during pregnancy.",
      "authors": "Gerbi Lucia; Austin Christine; Pedretti Nicolo Foppa; McRae Nia; Amarasiriwardena Chitra J; Mercado-Garc\u00eda Adriana; Torres-Olascoaga Libni A; Tellez-Rojo Martha M; Wright Robert O; Arora Manish; Elena Colicino",
      "year": "2022",
      "journal": "Environment international",
      "doi": "10.1016/j.envint.2022.107529",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36191488/",
      "mesh_terms": "Biomarkers; Cohort Studies; Dentin; Female; Humans; Lead; Maternal Exposure; Pregnancy",
      "keywords": "Blood lead levels; Machine learning; Pregnancy; Prenatal lead exposure; Super-Learner algorithm; Tooth dentine lead levels",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9576006"
    },
    {
      "pmid": "39576977",
      "title": "Exploring the Use of a Length AI Algorithm to Estimate Children's Length from Smartphone Images in a Real-World Setting: Algorithm Development and Usability Study.",
      "abstract": "BACKGROUND: Length measurement in young children younger than 18 months is important for monitoring growth and development. Accurate length measurement requires proper equipment, standardized methods, and trained personnel. In addition, length measurement requires young children's cooperation, making it particularly challenging during infancy and toddlerhood. OBJECTIVE: This study aimed to develop a length artificial intelligence (LAI) algorithm to aid users in determining recumbent length conveniently from smartphone images and explore its performance and suitability for personal and clinical use. METHODS: This proof-of-concept study in healthy children (aged 0-18 months) was performed at KK Women's and Children's Hospital, Singapore, from November 2021 to March 2022. Smartphone images were taken by parents and investigators. Standardized length-board measurements were taken by trained investigators. Performance was evaluated by comparing the tool's image-based length estimations with length-board measurements (bias [mean error, mean difference between measured and predicted length]; absolute error [magnitude of error]). Prediction performance was evaluated on an individual-image basis and participant-averaged basis. User experience was collected through questionnaires. RESULTS: A total of 215 participants (median age 4.4, IQR 1.9-9.7 months) were included. The tool produced a length prediction for 99.4% (2211/2224) of photos analyzed. The mean absolute error was 2.47 cm for individual image predictions and 1.77 cm for participant-averaged predictions. Investigators and parents reported no difficulties in capturing the required photos for most participants (182/215, 84.7% participants and 144/200, 72% participants, respectively). CONCLUSIONS: The LAI algorithm is an accessible and novel way of estimating children's length from smartphone images without the need for specialized equipment or trained personnel. The LAI algorithm's current performance and ease of use suggest its potential for use by parents or caregivers with an accuracy approaching what is typically achieved in general clinics or community health settings. The results show that the algorithm is acceptable for use in a personal setting, serving as a proof of concept for use in clinical settings. TRIAL REGISTRATION: ClinicalTrials.gov NCT05079776; https://clinicaltrials.gov/ct2/show/NCT05079776.",
      "authors": "Chua Mei Chien; Hadimaja Matthew; Wong Jill; Mukherjee Sankha Subhra; Foussat Agathe; Chan Daniel; Nandal Umesh; Yap Fabian",
      "year": "2024",
      "journal": "JMIR pediatrics and parenting",
      "doi": "10.2196/59564",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39576977/",
      "mesh_terms": "",
      "keywords": "AI; algorithm; artificial intelligence; children; computer vision; height; imaging; infant; length; length estimation; mHealth; measure; mobile health; mobile phone; neonatal; newborn; pediatric; smartphone; smartphone images",
      "pub_types": "Journal Article",
      "pmcid": "PMC11624450"
    },
    {
      "pmid": "35114899",
      "title": "Accuracy of an estimated core temperature algorithm for agricultural workers.",
      "abstract": "There is a substantial burden of occupational health effects from heat exposure. We sought to assess the accuracy of estimated core body temperature (CBTest) derived from an algorithm that uses sequential heart rate and initializing CBT,1 compared with gastrointestinal temperature measured using more invasive ingestible sensors (CBTgi), among outdoor agricultural workers. We analyzed CBTest and CBTgi data from Washington State, USA, pear and apple harvesters collected across one work shift in 2015 (13,413 observations, 35 participants) using Bland Altman methods. The mean (standard deviation, range) CBTgi was 37.7 (0.4, 36.5-39.4)\u00b0C. Overall CBT bias (limits of agreement) was -0.14 (\u00b10.76)\u00b0C. Biases ranged from -0.006 to -0.75\u2009\u00b0C. The algorithm, which does not require the use of ingestible sensors, may be a practical tool in research among groups of workers for evaluating the effectiveness of interventions to prevent adverse occupational heat health effects.",
      "authors": "Egbert Jared; Krenz Jennifer; Sampson Paul D; Jung Jihoon; Calkins Miriam; Zhang Kai; Palm\u00e1ndez Pablo; Faestel Paul; Spector June T",
      "year": "2022",
      "journal": "Archives of environmental & occupational health",
      "doi": "10.1080/19338244.2022.2033672",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35114899/",
      "mesh_terms": "Algorithms; Body Temperature; Farmers; Heat Stress Disorders; Hot Temperature; Humans; Occupational Exposure; Temperature",
      "keywords": "Agricultural workers; core body temperature; gastrointestinal temperature; heat stress; heat-related illness; physiological strain index",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC9346099"
    },
    {
      "pmid": "41426766",
      "title": "Apples-to-Apples: Age-Sex Standardisation of Public Chest X-ray Datasets.",
      "abstract": "Background Public chest radiograph datasets are widely used for model development and benchmarking, but differences in patient demographics can inflate apparent between-dataset differences in disease label prevalence. Objective To quantify the proportion of NIH ChestX-ray14 versus CheXpert prevalence differences that is explained by age and sex alone. Methods A cross-sectional analysis of\u00a0NIH ChestX-ray14 (n=112,120 studies) and CheXpert (n=223,413) databases was performed. Sex was harmonised to Male/Female and age was categorised as 0-17, 18-39, 40-59, 60-79, and \u226580 years. Five shared labels were assessed: consolidation, atelectasis, pleural effusion, edema, and cardiomegaly. For CheXpert, label uncertainty (-1) was treated as negative in the primary analysis. For each label, we calculated crude prevalence with Wilson 95% confidence intervals and compared datasets using a two-proportion z-test. We then performed direct standardisation by reweighting CheXpert age-sex strata to the NIH age-sex distribution and reported the reduction in the crude prevalence gap attributable to age-sex adjustment. Results Crude prevalence was higher in CheXpert than NIH for all labels (all p<0.001). After age-sex standardisation, CheXpert prevalence decreased for every label, indicating that demographics account for a substantial share of between-dataset differences. For consolidation, the crude gap of 1.96 percentage points (6.12% vs 4.16%) decreased to a standardised gap of 1.47 percentage points (CheXpert standardised 5.63% vs NIH 4.16%), representing approximately a 25% reduction. For atelectasis, the gap declined from 4.85 to 2.84 percentage points (41% reduction approx.). For pleural effusion, the gap declined from 28.10 to 19.03 percentage points (32% reduction approx.). For edema, the gap declined from 21.70 to 14.78 percentage points (32% reduction approx.). For cardiomegaly, the gap declined from 9.45 to 6.55 percentage points (31% reduction approx.). Across labels, age-sex standardisation explained approximately 25% to 40% of the crude prevalence differences. Conclusion A simple age-sex standardisation step explains a large proportion of apparent label prevalence differences between NIH ChestX-ray14 and CheXpert. Routine reporting of standardised prevalence alongside crude estimates and demographic composition can improve fairness and interpretability in cross-dataset benchmarking and reduce the risk of attributing demographic composition effects to labelling or model performance.",
      "authors": "Badawy Amr; Elhariry Maiar; Chirrimar Amrit; Chohan Ashrit",
      "year": "2025",
      "journal": "Cureus",
      "doi": "10.7759/cureus.97260",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41426766/",
      "mesh_terms": "",
      "keywords": "ai and machine learning; artifical intelligence; big data analytics; big data analytics and machine learning; dataset bias; health informatics big data; radiology; radiology research",
      "pub_types": "Journal Article",
      "pmcid": "PMC12716848"
    },
    {
      "pmid": "36009575",
      "title": "Machine Learning Data Analysis Highlights the Role of Parasutterella and Alloprevotella in Autism Spectrum Disorders.",
      "abstract": "In recent years, the involvement of the gut microbiota in disease and health has been investigated by sequencing the 16S gene from fecal samples. Dysbiotic gut microbiota was also observed in Autism Spectrum Disorder (ASD), a neurodevelopmental disorder characterized by gastrointestinal symptoms. However, despite the relevant number of studies, it is still difficult to identify a typical dysbiotic profile in ASD patients. The discrepancies among these studies are due to technical factors (i.e., experimental procedures) and external parameters (i.e., dietary habits). In this paper, we collected 959 samples from eight available projects (540 ASD and 419 Healthy Controls, HC) and reduced the observed bias among studies. Then, we applied a Machine Learning (ML) approach to create a predictor able to discriminate between ASD and HC. We tested and optimized three algorithms: Random Forest, Support Vector Machine and Gradient Boosting Machine. All three algorithms confirmed the importance of five different genera, including Parasutterella and Alloprevotella. Furthermore, our results show that ML algorithms could identify common taxonomic features by comparing datasets obtained from countries characterized by latent confounding variables.",
      "authors": "Pietrucci Daniele; Teofani Adelaide; Milanesi Marco; Fosso Bruno; Putignani Lorenza; Messina Francesco; Pesole Graziano; Desideri Alessandro; Chillemi Giovanni",
      "year": "2022",
      "journal": "Biomedicines",
      "doi": "10.3390/biomedicines10082028",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36009575/",
      "mesh_terms": "",
      "keywords": "Alloprevorella; Parasutterella; autism spectrum disorder; dysbiosis; gut microbiota; machine learning data analysis; targeted metagenomics",
      "pub_types": "Journal Article",
      "pmcid": "PMC9405825"
    },
    {
      "pmid": "27729095",
      "title": "Developing a Rapid Algorithm to Enable Rapid Characterization of Alginate Microcapsules.",
      "abstract": "The islets of Langerhans are endocrine tissue clusters that secrete hormones that regulate the body's glucose, carbohydrate, and fat metabolism, the most important of which is insulin, a hormone secreted by \u03b2-cells within the islets. In certain instances, a person's own immune system attacks and destroys them, leading to the development of type 1 diabetes (T1D), a life-long condition that needs daily insulin administration to maintain health and prolong survival. Islet transplantation is a surgical procedure that has demonstrated the ability to normalize blood sugar levels for up to a few years, but the need for chronic immunosuppression relegates it to a last resort that is often only used sparingly and in seriously ill patients. Islet microencapsulation is a biomedical innovation designed to protect islets from the immune system by coating them with a biocompatible polymer, and this new technology has demonstrated various degrees of success in small- and large-animal studies. This success is significantly impacted by microcapsule morphology and encapsulation efficiency. Since hundreds of thousands of microcapsules are generated during the process, characterization of encapsulated islets without the help of some degree of automation would be difficult, time-consuming, and error prone due to inherent observer bias. We have developed an image analysis algorithm that can analyze hundreds of microencapsulated islets and characterize their size, shape, circularity, and distortion with minimal observer bias. This algorithm can be easily adapted to similar nano- or microencapsulation technologies to implement stricter quality control and improve biomaterial device design and success.",
      "authors": "Chan Ka Hei; Krishnan Rahul; Alexander Michael; Lakey Jonathan R T",
      "year": "2017",
      "journal": "Cell transplantation",
      "doi": "10.3727/096368916X693446",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27729095/",
      "mesh_terms": "Alginates; Algorithms; Animals; Capsules; Diabetes Mellitus, Type 1; Glucuronic Acid; Hexuronic Acids; Humans; Islets of Langerhans Transplantation",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC5657713"
    },
    {
      "pmid": "15680747",
      "title": "A simple imputation algorithm reduced missing data in SF-12 health surveys.",
      "abstract": "OBJECTIVE: The SF-12 Health Survey is a 12-item questionnaire that yields two summary scores (physical and mental health). Neither score can be computed when an item is missing. We explored imputation methods for missing scores for this instrument. STUDY DESIGN AND SETTING: Using data from a population-based survey, we tested several ways of imputing simulated missing data. RESULTS: Among 1250 participants, 118 (9.6%) had at last one missing SF-12 item. Missing data were more common among women, older respondents, non-Swiss nationals, and health service users. Among the 1132 respondents with complete data, replacement of any item with the mean population item weight yielded good results: the mean correlation between imputed and true score was 0.979 for both the physical and mental score. Results remained satisfactory when up to three of the six key items for each score (items that contribute predominantly to a given score), and any number of non-key items, were replaced by the mean. Application of this imputation algorithm to the original survey reduced the proportion of missing scores to <1%. Respondents with incomplete surveys, hence imputed scores, had lower scores than respondents with complete data (physical score: 44.9 vs. 49.8, p < 0.001, mental score: 44.4 vs. 46.3, p=0.064). CONCLUSIONS: A simple imputation algorithm can substantially reduce the proportion of missing scores for the SF-12 health survey, and consequently reduce non-response bias.",
      "authors": "Perneger Thomas V; Burnand Bernard",
      "year": "2005",
      "journal": "Journal of clinical epidemiology",
      "doi": "10.1016/j.jclinepi.2004.06.005",
      "url": "https://pubmed.ncbi.nlm.nih.gov/15680747/",
      "mesh_terms": "Algorithms; Data Interpretation, Statistical; Health Surveys; Humans; Selection Bias; Surveys and Questionnaires",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33138668",
      "title": "A simple, rapid, interpretable, actionable and implementable digital PCR based mortality index.",
      "abstract": "Mortality assessments are conducted for both civil and commercial purposes. Recent advances in epigenetics have resulted in DNA methylation tools to assess risk and aid in this task. However, widely available array-based algorithms are not readily translatable into clinical tools and do not provide a good foundation for clinical recommendations. Further, recent work shows evidence of heritability and possible racial bias in these indices. Using a publicly available array data set, the Framingham Heart Study (FHS), we develop and test a five-locus mortality-risk algorithm using only previously validated methylation biomarkers that have been shown to be free of racial bias, and that provide specific assessments of smoking, alcohol consumption, diabetes and heart disease. We show that a model using age, sex and methylation measurements at these five loci outperforms the 513 probe Levine index and approximates the predictive power of the 1030 probe GrimAge index. We then show each of the five loci in our algorithm can be assessed using a more powerful, reference-free digital PCR approach, further demonstrating that it is readily clinically translatable. Finally, we show the loci do not reflect ethnically specific variation. We conclude that this algorithm is a simple, yet powerful tool for assessing mortality risk. We further suggest that the output from this or similarly derived algorithms using either array or digital PCR can be used to provide powerful feedback to patients, guide recommendations for additional medical assessments, and help monitor the effect of public health prevention interventions.",
      "authors": "Philibert Robert; Long Jeffrey D; Mills James A; Beach S R H; Gibbons Frederick X; Gerrard Meg; Simons Ron; Pinho Paulo B; Ingle Douglas; Dawes Kelsey; Dogan Timur; Dogan Meeshanthini",
      "year": "2021",
      "journal": "Epigenetics",
      "doi": "10.1080/15592294.2020.1841874",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33138668/",
      "mesh_terms": "Alcohol Drinking; DNA Methylation; Epigenesis, Genetic; Epigenomics; Humans; Polymerase Chain Reaction",
      "keywords": "DNA methylation; alcohol; coronary artery disease; diabetes; mortality; smoking",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC8510561"
    },
    {
      "pmid": "39802674",
      "title": "Uncertainty estimation in diagnosis generation from large language models: next-word probability is not pre-test probability.",
      "abstract": "OBJECTIVE: To evaluate large language models (LLMs) for pre-test diagnostic probability estimation and compare their uncertainty estimation performance with a traditional machine learning classifier. MATERIALS AND METHODS: We assessed 2 instruction-tuned LLMs, Mistral-7B-Instruct and Llama3-70B-chat-hf, on predicting binary outcomes for Sepsis, Arrhythmia, and Congestive Heart Failure (CHF) using electronic health record (EHR) data from 660 patients. Three uncertainty estimation methods-Verbalized Confidence, Token Logits, and LLM Embedding+XGB-were compared against an\u00a0eXtreme Gradient Boosting (XGB) classifier trained on raw EHR data. Performance metrics included AUROC and Pearson correlation between predicted probabilities. RESULTS: The XGB classifier outperformed the LLM-based methods across all tasks. LLM Embedding+XGB showed the closest performance to the XGB baseline, while Verbalized Confidence and Token Logits underperformed. DISCUSSION: These findings, consistent across multiple models and demographic groups, highlight the limitations of current LLMs in providing reliable pre-test probability estimations and underscore the need for improved calibration and bias mitigation strategies. Future work should explore hybrid approaches that integrate LLMs with numerical reasoning modules and calibrated embeddings to enhance diagnostic accuracy and ensure fairer predictions across diverse populations. CONCLUSIONS: LLMs demonstrate potential but currently fall short in estimating diagnostic probabilities compared to traditional machine learning classifiers trained on structured EHR data. Further improvements are needed for reliable clinical use.",
      "authors": "Gao Yanjun; Myers Skatje; Chen Shan; Dligach Dmitriy; Miller Timothy; Bitterman Danielle S; Chen Guanhua; Mayampurath Anoop; Churpek Matthew M; Afshar Majid",
      "year": "2025",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooae154",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39802674/",
      "mesh_terms": "",
      "keywords": "diagnostic uncertainty; electronic health records; large language models; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11723528"
    },
    {
      "pmid": "30862730",
      "title": "Optimizing schools' start time and bus routes.",
      "abstract": "Maintaining a fleet of buses to transport students to school is a major expense for school districts. To reduce costs by reusing buses between schools, many districts spread start times across the morning. However, assigning each school a time involves estimating the impact on transportation costs and reconciling additional competing objectives. Facing this intricate optimization problem, school districts must resort to ad hoc approaches, which can be expensive, inequitable, and even detrimental to student health. For example, there is medical evidence that early high school starts are impacting the development of an entire generation of students and constitute a major public health crisis. We present an optimization model for the school time selection problem (STSP), which relies on a school bus routing algorithm that we call biobjective routing decomposition (BiRD). BiRD leverages a natural decomposition of the routing problem, computing and combining subproblem solutions via mixed integer optimization. It significantly outperforms state-of-the-art routing methods, and its implementation in Boston has led to $5 million in yearly savings, maintaining service quality for students despite a 50-bus fleet reduction. Using BiRD, we construct a tractable proxy to transportation costs, allowing the formulation of the STSP as a multiobjective generalized quadratic assignment problem. Local search methods provide high-quality solutions, allowing school districts to explore tradeoffs between competing priorities and choose times that best fulfill community needs. In December 2017, the development of this method led the Boston School Committee to unanimously approve the first school start time reform in 30 years.",
      "authors": "Bertsimas Dimitris; Delarue Arthur; Martin Sebastien",
      "year": "2019",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "doi": "10.1073/pnas.1811462116",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30862730/",
      "mesh_terms": "",
      "keywords": "education; fairness; optimization; public policy; transportation",
      "pub_types": "Journal Article",
      "pmcid": "PMC6442556"
    },
    {
      "pmid": "41468526",
      "title": "Aligning a Household-Level Service Array Through a Jurisdiction-Wide Child Maltreatment Prevention Effort: Protocol for a Geospatial and Counterfactual Modeling Study.",
      "abstract": "BACKGROUND: Child maltreatment is associated with multiple negative outcomes at the individual and societal levels. Children experiencing maltreatment are at greater risk of a host of negative outcomes (eg, psychological disorders, substance use, violent delinquency, suicidality, and adverse educational outcomes). OBJECTIVE: This study aims to prevent and ameliorate child maltreatment by using a combination of geospatial smoothing via a risk terrain modeling (RTM) framework and counterfactual modeling to identify risky areas and determine the optimal (re)allocation of services to maximally improve maltreatment outcomes. METHODS: A 3-stage process is proposed that can iteratively be applied within a collaborating jurisdiction to enable responsive and sustained achievement of identified child welfare outcomes. This process makes use of 2 analytic approaches: geospatial smoothing via an RTM framework and counterfactual modeling. RTM is a spatial analytic approach that uses spatial machine learning methods to estimate the risk of maltreatment based on previous cases of maltreatment and risk factors of the built environment provided by the participating jurisdiction. Using previously validated cases of maltreatment as our target variable (eg, substantiated claims of abuse and neglect) and violent crime data and built environment data as our primary predictor variables, we estimate a series of machine learning models to geospatially smooth the historically identified places at increased risk of child maltreatment. Areas identified as higher risk receive extensive services associated with preventing or limiting child maltreatment, such as prenatal or postnatal care, subsidized daycare, and parental counseling. We make use of counterfactual explanation modeling to optimally align service allocation to maximally improve maltreatment outcomes for future service allocations within a collaborating jurisdiction. The technique leverages a statistical model associating household-level information with maltreatment outcomes to explore combinations of services that would be predicted to achieve optimal and practical recommendations for future service allocation efforts. Constraints can be introduced to this logic, such as service availability and cost. Algorithmic fairness is also a potential consideration during aggregation, with possibilities for both measuring and balancing metrics such as \"recourse fairness.\" RESULTS: As of September 2025, a participating jurisdiction is being recruited. CONCLUSIONS: This protocol sets forth a novel approach for the allocation of supportive services for families at risk of child maltreatment through geospatial smoothing via an RTM framework and the maximization of service impact through a counterfactual explanation model. Child maltreatment is an unfortunate and ubiquitous issue in the United States. This proposal builds on jurisdiction-wide public health strategies to allocate services in a data-informed fashion and further align future iterations of the allocation strategy using outcomes-based counterfactual modeling at the household level. The flexibility of the proposed methodology enables its application regardless of the collaborating jurisdiction's preferences and constraints.",
      "authors": "Green Jamaal; Glass Brian; Purdy Jordan; Daley Dyann",
      "year": "2025",
      "journal": "JMIR research protocols",
      "doi": "10.2196/71997",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41468526/",
      "mesh_terms": "Humans; Child Abuse; Child; Risk Factors; Spatial Analysis; Female; Family Characteristics",
      "keywords": "child maltreatment; counterfactual modeling; geospatial modeling; human services; public service provision",
      "pub_types": "Journal Article",
      "pmcid": "PMC12752913"
    },
    {
      "pmid": "10492381",
      "title": "Decision analysis in nuclear medicine.",
      "abstract": "This review focuses primarily on the methodology involved in properly reviewing the literature for performing a meta-analysis and on methods for performing a formal decision analysis using decision trees. Issues related to performing a detailed metaanalysis with consideration of particular issues, including publication bias, verification bias and patient spectrum, are addressed. The importance of collecting conventional measures of test performance (e.g., sensitivity and specificity) and of changes in patient management to model the cost-effectiveness of a management algorithm is detailed. With greater utilization of the techniques discussed in this review, nuclear medicine researchers should be well prepared to compete for the limited resources available in the current health care environment. Furthermore, nuclear medicine physicians will be better prepared to best serve their patients by using only those studies with a proven role in improving patient management.",
      "authors": "Gambhir S S",
      "year": "1999",
      "journal": "Journal of nuclear medicine : official publication, Society of Nuclear Medicine",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/10492381/",
      "mesh_terms": "Cost-Benefit Analysis; Decision Support Techniques; Decision Trees; Humans; Life Expectancy; Meta-Analysis as Topic; Nuclear Medicine; Quality of Life",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37198237",
      "title": "Development and validation of a prediction equation for body fat percentage from measured BMI: a supervised machine learning approach.",
      "abstract": "Body mass index is a widely used but poor predictor of adiposity in populations with excessive fat-free mass. Rigorous predictive models validated specifically in a nationally representative sample of the US population and that could be used for calibration purposes are needed. The objective of this study was to develop and validate prediction equations of body fat percentage obtained from Dual Energy X-ray Absorptiometry using body mass index (BMI) and socio-demographics. We used the\u00a0National Health and Nutrition Examination Survey (NHANES)\u00a0data from 5931 and 2340 adults aged 20 to 69 in 1999-2002 and 2003-2006, respectively. A supervised machine learning using ordinary least squares and a validation set approach were used to develop and select best models based on R2 and root mean square error. We compared our findings with other published models and utilized our best models to assess the amount of bias in the association between predicted body fat and elevated low-density lipoprotein (LDL). Three models included BMI, BMI2, age, gender, education, income, and interaction terms and produced R-squared values of 0.87 and yielded the smallest standard errors of estimation. The amount of bias in the association between predicted BF% and elevated LDL from our best model was -0.005. Our models provided strong predictive abilities and low bias compared to most published models. Its strengths rely on its simplicity and its ease of use in low-resource settings.",
      "authors": "Xu Shiming; Nianogo Roch A; Jaga Seema; Arah Onyebuchi A",
      "year": "2023",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-023-33914-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37198237/",
      "mesh_terms": "Body Mass Index; Nutrition Surveys; Body Composition; Predictive Value of Tests; Reproducibility of Results; Sex Factors; Adipose Tissue; Absorptiometry, Photon",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10192430"
    },
    {
      "pmid": "41009246",
      "title": "Predicting Adverse Childhood Experiences from Family Environment Factors: A Machine Learning Approach.",
      "abstract": "Adverse childhood experiences (ACEs) are associated with profound long-term health and developmental consequences. However, current identification strategies are largely reactive, often missing opportunities for early intervention. Therefore, the potential of machine learning to proactively identify children at risk of ACE exposure needs to be explored. Using nationally representative data from 63,239 children in the 2018-2020 National Survey of Children's Health (NSCH) after listwise deletion, we trained and validated multiple machine learning models to predict ACE exposure categorized as none, one, or two or more ACEs. Model performance was assessed using accuracy, precision, recall, F1 scores, and area under the curve (AUC) metrics with 5-fold cross-validation. The Random Forest model achieved the highest predictive accuracy (82%) and demonstrated strong performance across ACE categories. Key predictive features included child sex (female), food insufficiency, school absenteeism, quality of parent-child communication, and experiences of bullying. The model yielded high performance in identifying children with no ACEs (F1 = 0.89) and moderate performance for those with multiple ACEs (F1 = 0.64). However, performance for the single ACE category was notably lower (F1 = 0.55), indicating challenges in predicting this intermediate group. These findings suggest that family environment factors can be leveraged to predict ACE exposure with clinically meaningful accuracy, offering a foundation for proactive screening protocols. However, implementation must carefully address systematic selection bias, clinical utility limitations, and ethical considerations regarding predictive modeling of vulnerable children.",
      "authors": "Tawiah Nii Adjetey; Appiah Emmanuel A; White Felisha",
      "year": "2025",
      "journal": "Behavioral sciences (Basel, Switzerland)",
      "doi": "10.3390/bs15091216",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41009246/",
      "mesh_terms": "",
      "keywords": "adverse childhood experiences; data analysis; family environment; machine learning; predictive modeling",
      "pub_types": "Journal Article",
      "pmcid": "PMC12466657"
    },
    {
      "pmid": "11757053",
      "title": "Radiation dose estimation for epidemiologic studies of flight attendants.",
      "abstract": "BACKGROUND: NIOSH is conducting health studies of female flight attendants. Exposures of interest include cosmic radiation and circadian rhythm disruption, however, the data needed to estimate cumulative radiation dose are not found in work histories. METHODS: We developed an algorithm to generate from work histories the required input data for Federal Aviation Administration radiation estimation software and evaluated whether effects of cumulative radiation dose could be distinguished analytically from effects of circadian rhythm disruption. RESULTS: The algorithm has relatively low bias (< 6%) for longer flights, which contribute most to cumulative radiation dose. In one NIOSH study, 44 crew incurred an estimated average annual occupational dose of 1.5-1.7 mSv. Selection of a study population flying predominantly North-South flights can provide the necessary distinction between radiation and time zone crossing exposures. CONCLUSIONS: Methods developed will be useful for exposure assessment in cabin crew studies with relatively short study periods, (e.g., reproductive health studies) for which limited flight history details are generally available.",
      "authors": "Grajewski Barbara; Waters Martha A; Whelan Elizabeth A; Bloom Thomas F",
      "year": "2002",
      "journal": "American journal of industrial medicine",
      "doi": "10.1002/ajim.10018",
      "url": "https://pubmed.ncbi.nlm.nih.gov/11757053/",
      "mesh_terms": "Aerospace Medicine; Aircraft; Algorithms; Altitude; Circadian Rhythm; Cosmic Radiation; Epidemiologic Research Design; Female; Humans; Occupational Exposure; Radiation Dosage; Travel",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "12706850",
      "title": "An algorithm for neurite outgrowth reconstruction.",
      "abstract": "We present a numerical method which provides the ability to analyze digitized microscope images of retinal explants and quantify neurite outgrowth. Few parameters are required as input and limited user interaction is necessary to process an entire experiment of images. This eliminates fatigue related errors and user-related bias common to manual analysis. The method does not rely on stained images and handles images of variable quality. The algorithm is used to determine time and dose dependent, in vitro, neurotoxic effects of 1 GeV per nucleon iron particles in retinal explants. No neurotoxic effects are detected until 72 h after exposure; at 72 h, significant reductions of neurite outgrowth occurred at doses higher than 10 cGy.",
      "authors": "Weaver Christina M; Pinezich John D; Lindquist W Brent; Vazquez Marcelo E",
      "year": "2003",
      "journal": "Journal of neuroscience methods",
      "doi": "10.1016/s0165-0270(03)00017-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/12706850/",
      "mesh_terms": "Algorithms; Animals; Cell Differentiation; Cells, Cultured; Chick Embryo; Dose-Response Relationship, Drug; Image Processing, Computer-Assisted; Neurites",
      "keywords": "NASA Discipline Radiation Health; NASA Program Biomedical Research and Countermeasures; Non-NASA Center",
      "pub_types": "Comparative Study; Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "34078469",
      "title": "How do you feel during the COVID-19 pandemic? A survey using psychological and linguistic self-report measures, and machine learning to investigate mental health, subjective experience, personality, and behaviour during the COVID-19 pandemic among university students.",
      "abstract": "BACKGROUND: The WHO has raised concerns about the psychological consequences of the current COVID-19 pandemic, negatively affecting health across societies, cultures and age-groups. METHODS: This online survey study investigated mental health, subjective experience, and behaviour (health, learning/teaching) among university students studying in Egypt or Germany shortly after the first pandemic lockdown in May 2020. Psychological assessment included stable personality traits, self-concept and state-like psychological variables related to (a) mental health (depression, anxiety), (b) pandemic threat perception (feelings during the pandemic, perceived difficulties in describing, identifying, expressing emotions), (c) health (e.g., worries about health, bodily symptoms) and behaviour including perceived difficulties in learning. Assessment methods comprised self-report questions, standardized psychological scales, psychological questionnaires, and linguistic self-report measures. Data analysis comprised descriptive analysis of mental health, linguistic analysis of self-concept, personality and feelings, as well as correlational analysis and machine learning. N\u2009=\u2009220 (107 women, 112 men, 1 = other) studying in Egypt or Germany provided answers to all psychological questionnaires and survey items. RESULTS: Mean state and trait anxiety scores were significantly above the cut off scores that distinguish between high versus low anxious subjects. Depressive symptoms were reported by 51.82% of the student sample, the mean score was significantly above the screening cut off score for risk of depression. Worries about health (mental and physical health) and perceived difficulties in identifying feelings, and difficulties in learning behaviour relative to before the pandemic were also significant. No negative self-concept was found in the linguistic descriptions of the participants, whereas linguistic descriptions of feelings during the pandemic revealed a negativity bias in emotion perception. Machine learning (exploratory) predicted personality from the self-report data suggesting relations between personality and subjective experience that were not captured by descriptive or correlative data analytics alone. CONCLUSION: Despite small sample sizes, this multimethod survey provides important insight into mental health of university students studying in Egypt or Germany and how they perceived the first COVID-19 pandemic lockdown in May 2020. The results should be continued with larger samples to help develop psychological interventions that support university students across countries and cultures to stay psychologically resilient during the pandemic.",
      "authors": "Herbert Cornelia; El Bolock Alia; Abdennadher Slim",
      "year": "2021",
      "journal": "BMC psychology",
      "doi": "10.1186/s40359-021-00574-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34078469/",
      "mesh_terms": "Anxiety; COVID-19; Communicable Disease Control; Diagnostic Self Evaluation; Egypt; Emotions; Female; Germany; Humans; Linguistics; Machine Learning; Male; Mental Health; Pandemics; SARS-CoV-2; Self Report; Students; Surveys and Questionnaires; Universities",
      "keywords": "Anxiety; COVID-19; Character computing; Corona virus; Depression; Emotion perception; Linguistic analysis; Machine learning; Mental health; Pandemic; Personality; Self-concept",
      "pub_types": "Journal Article",
      "pmcid": "PMC8170461"
    },
    {
      "pmid": "40795063",
      "title": "Enhancing end-stage renal disease outcome prediction: a multisourced data-driven approach.",
      "abstract": "OBJECTIVES: To improve prediction of chronic kidney disease (CKD) progression to end-stage renal disease (ESRD) using machine learning (ML) and deep learning (DL) models applied to integrated clinical and claims data with varying observation windows, supported by explainable artificial intelligence (AI) to enhance interpretability and reduce bias. MATERIALS AND METHODS: We utilized data from 10\u00a0326 CKD patients, combining clinical and claims information from 2009 to 2018. After preprocessing, cohort identification, and feature engineering, we evaluated multiple statistical, ML and DL models using 5 distinct observation windows. Feature importance and SHapley Additive exPlanations (SHAP) analysis were employed to understand key predictors. Models were tested for robustness, clinical relevance, misclassification patterns, and bias. RESULTS: Integrated data models outperformed single data source models, with long short-term memory achieving the highest area under the receiver operating characteristic curve (AUROC) (0.93) and F1 score (0.65). A 24-month observation window optimally balanced early detection and prediction accuracy. The 2021 estimated glomerular filtration rate (eGFR)\u00a0equation improved prediction accuracy and reduced racial bias, particularly for African American patients. DISCUSSION: Improved prediction accuracy, interpretability, and bias mitigation strategies have the potential to enhance CKD management, support targeted interventions, and reduce health-care disparities. CONCLUSION: This study presents a robust framework for predicting ESRD outcomes, improving clinical decision-making through integrated multisourced data and advanced analytics. Future research will expand data integration and extend this framework to other chronic diseases.",
      "authors": "Li Yubo; Padman Rema",
      "year": "2026",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf118",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40795063/",
      "mesh_terms": "Humans; Kidney Failure, Chronic; Machine Learning; Disease Progression; Male; Female; Deep Learning; Middle Aged; Renal Insufficiency, Chronic; Aged; ROC Curve",
      "keywords": "chronic kidney disease; clinical and claims data integration; end-stage renal disease; machine learning; predictive modeling",
      "pub_types": "Journal Article",
      "pmcid": "PMC12758457"
    },
    {
      "pmid": "22517404",
      "title": "Automated quantification of white matter disease extent at 3 T: comparison with volumetric readings.",
      "abstract": "PURPOSE: To develop and validate an algorithm to automatically quantify white matter hyperintensity (WMH) volume. MATERIALS AND METHODS: Images acquired as part of the Dallas Heart Study, a multiethnic, population-based study of cardiovascular health, were used to develop and validate the algorithm. 3D magnetization prepared rapid acquisition gradient echo (MP-RAGE) and 2D fluid-attenuated inversion recovery (FLAIR) images were acquired from 2082 participants. Images from 161 participants (7.7% of the cohort) were used to set an intensity threshold to maximize the agreement between the algorithm and a qualitative rating made by a radiologist. The resulting algorithm was run on the entire cohort and outlier analyses were used to refine the WMH volume measurement. The refined, automatic WMH burden estimate was then compared to manual quantitative measurements of WMH volume in 28 participants distributed across the range of volumes seen in the entire cohort. RESULTS: The algorithm showed good agreement with the volumetric readings of a trained analyst: the Spearman's Rank Order Correlation coefficient was r = 0.87. Linear regression analysis showed a good correlation WMHml[automated] = 1.02 \u00d7 WMHml[manual] - 0.48. Bland-Altman analysis showed a bias of 0.34 mL and a standard deviation of 2.8 mL over a range of 0.13 to 41 mL. CONCLUSION: We have developed an algorithm that automatically estimates the volume of WMH burden using an MP-RAGE and a FLAIR image. This provides a tool for evaluating the WMH burden of large populations to investigate the relationship between WMH burden and other health factors.",
      "authors": "Hulsey Keith M; Gupta Mohit; King Kevin S; Peshock Ronald M; Whittemore Anthony R; McColl Roderick W",
      "year": "2012",
      "journal": "Journal of magnetic resonance imaging : JMRI",
      "doi": "10.1002/jmri.23659",
      "url": "https://pubmed.ncbi.nlm.nih.gov/22517404/",
      "mesh_terms": "Algorithms; Brain; Demyelinating Diseases; Diffusion Tensor Imaging; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Nerve Fibers, Myelinated; Observer Variation; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38081690",
      "title": "Machine learning approach to determine the decision rules in ergonomic assessment of working posture in sewing machine operators.",
      "abstract": "INTRODUCTION: There are some inherent problems with the use of observation methods in the ergonomic assessment of working posture, namely the stability and precision of the measurements. This study aims to use a machine learning (ML) approach to avoid the subjectivity bias of observational methods in ergonomic assessments and further identify risk patterns for work-related musculoskeletal disorders (WMSDs) among sewing machine operators. METHODS: We proposed a decision tree analysis scheme for ergonomic assessment in working postures (DTAS-EAWP). First, DTAS-EAWP used computer vision-based technology to detect the body movement angles from the on-site working videos to generate a dataset of risk scores through the criteria of Rapid Entire Body Assessment (REBA) for sewing machine operators. Second, data mining techniques (WEKA) using the C4.5 algorithm were used to construct a representative decision tree (RDT) with paths of various risk levels, and attribute importance analysis was performed to determine the critical body segments for WMSDs. RESULTS: DTAS-EAWP was able to recognize 11,211 samples of continuous working postures in sewing machine operation and calculate the corresponding final REBA scores. A total of 13 decision rules were constructed in the RDT, with over 95% prediction accuracy and 83% path coverage, to depict the possible risk tendency in the working postures. Through RDT and attribute importance analysis, it was identified that the lower arm and the upper arms exhibited as critical segments that significantly increased the risk levels for WMSDs. CONCLUSIONS: This study demonstrates that ML approach with computer vision-based estimation and DT analysis are feasible for comprehensively exploring the decision rules in ergonomic assessment of working postures for risk prediction of WMSDs in sewing machine operators. PRACTICAL APPLICATIONS: This DTAS-EAWP can be applied in manufacturing industries to automatically analyze working postures and identify risk patterns of WMSDs, leading to the development of effectively preventive interventions.",
      "authors": "Su Jun-Ming; Chang Jer-Hao; Indrayani Ni Luh Dwi; Wang Chi-Jane",
      "year": "2023",
      "journal": "Journal of safety research",
      "doi": "10.1016/j.jsr.2023.08.008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38081690/",
      "mesh_terms": "Humans; Ergonomics; Musculoskeletal Diseases; Occupational Diseases; Posture; Risk Factors",
      "keywords": "Emergent technologies; Ergonomics; Musculoskeletal disorders; Occupational health; Risk assessment",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37084908",
      "title": "Digital mapping of the soil available water capacity: tool for the resilience of agricultural systems to climate change.",
      "abstract": "Soil available water capacity (AWC) is a key function for human survival and well-being. However, its direct measurement is laborious and spatial interpretation is complex. Digital soil mapping (DSM) techniques emerge as an alternative to spatial modeling of soil properties. DSM techniques commonly apply machine learning (ML) models, with a high level of complexity. In this context, we aimed to perform a digital mapping of soil AWC and interpret the results of the Random Forest (RF) algorithm and, in a case study, to show that digital AWC maps can support agricultural planning in response to the local effects of climate change. To do so, we divided this research into two approaches: In the first approach, we showed a DSM using 1857 sample points in a southeastern region of Brazil with laboratory-determined soil attributes, together with a pedotransfer function (PTF), remote sensing and DSM techniques. In the second approach, the constructed AWC digital soil map and weather station data were used to calculate climatological soil water balances for the periods between 1917-1946 and 1991-2020. The result showed the selection of covariates using Shapley values as a criterion contributed to the parsimony of the model, obtaining goodness-of-fit metrics of R2 0.72, RMSE 16.72\u00a0mm\u00a0m-1, CCC 0.83, and Bias of 0.53 over the validation set. The highest contributing covariates for soil AWC prediction were the Landsat multitemporal images with bare soil pixels, mean diurnal, and annual temperature range. Under the current climate conditions, soil available water content (AW) increased during the dry period (April to August). May had the highest increase in AW (\u223c17\u00a0mm\u00a0m-1) and decrease in September (\u223c14\u00a0mm\u00a0m-1). The used methodology provides support for AWC modeling at 30\u00a0m resolution, as well as insight into the adaptation of crop growth periods to the effects of climate change.",
      "authors": "G\u00f3mez Andr\u00e9s M R; de Jong van Lier Quirijn; Silvero N\u00e9lida E Q; Inforsato Leonardo; de Melo Marina Luciana Abreu; Rodr\u00edguez-Albarrac\u00edn Heidy S; Rosin N\u00edcolas Augusto; Rosas Jorge Tadeu Fim; Rizzo Rodnei; Dematt\u00ea Jose A M",
      "year": "2023",
      "journal": "The Science of the total environment",
      "doi": "10.1016/j.scitotenv.2023.163572",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37084908/",
      "mesh_terms": "",
      "keywords": "Climate change; Ecosystem services; Machine learning; Remote sensing; Shapley value; Soil functions; Soil health; Soil quality",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37632234",
      "title": "A broadly applicable approach to enrich electronic-health-record cohorts by identifying patients with complete data: a multisite evaluation.",
      "abstract": "OBJECTIVE: Patients who receive most care within a single healthcare system (colloquially called a \"loyalty cohort\" since they typically return to the same providers) have mostly complete data within that organization's electronic health record (EHR). Loyalty cohorts have low data missingness, which can unintentionally bias research results. Using proxies of routine care and healthcare utilization metrics, we compute a per-patient score that identifies a loyalty cohort. MATERIALS AND METHODS: We implemented a computable program for the widely adopted i2b2 platform that identifies loyalty cohorts in EHRs based on a machine-learning model, which was previously validated using linked claims data. We developed a novel validation approach, which tests, using only EHR data, whether patients returned to the same healthcare system after the training period. We evaluated these tools at 3 institutions using data from 2017 to 2019. RESULTS: Loyalty cohort calculations to identify patients who returned during a 1-year follow-up yielded a mean area under the receiver operating characteristic curve of 0.77 using the original model and 0.80 after calibrating the model at individual sites. Factors such as multiple medications or visits contributed significantly at all sites. Screening tests' contributions (eg, colonoscopy) varied across sites, likely due to coding and population differences. DISCUSSION: This open-source implementation of a \"loyalty score\" algorithm had good predictive power. Enriching research cohorts by utilizing these low-missingness patients is a way to obtain the data completeness necessary for accurate causal analysis. CONCLUSION: i2b2 sites can use this approach to select cohorts with mostly complete EHR data.",
      "authors": "Klann Jeffrey G; Henderson Darren W; Morris Michele; Estiri Hossein; Weber Griffin M; Visweswaran Shyam; Murphy Shawn N",
      "year": "2023",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocad166",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37632234/",
      "mesh_terms": "Humans; Electronic Health Records; Algorithms; Machine Learning; Delivery of Health Care; Electronics",
      "keywords": "clinical data warehousing; clinical research informatics; data completeness; electronic health records; i2b2; loyalty cohort",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10654861"
    },
    {
      "pmid": "35860322",
      "title": "A process to deduplicate individuals for regional chronic disease prevalence estimates using a distributed data network of electronic health records.",
      "abstract": "INTRODUCTION: Learning health systems can help estimate chronic disease prevalence through distributed data networks (DDNs). Concerns remain about bias introduced to DDN prevalence estimates when individuals seeking care across systems are counted multiple times. This paper describes a process to deduplicate individuals for DDN prevalence estimates. METHODS: We operationalized a two-step deduplication process, leveraging health information exchange (HIE)-assigned network identifiers, within the Colorado Health Observation Regional Data Service (CHORDS) DDN. We generated prevalence estimates for type 1 and type 2 diabetes among pediatric patients (0-17\u2009years) with at least one 2017 encounter in one of two geographically-proximate DDN partners. We assessed the extent of cross-system duplication and its effect on prevalence estimates. RESULTS: We identified 218\u2009437 unique pediatric patients seen across systems during 2017, including 7628 (3.5%) seen in both. We found no measurable difference in prevalence after deduplication. The number of cases we identified differed slightly by data reconciliation strategy. Concordance of linked patients' demographic attributes varied by attribute. CONCLUSIONS: We implemented an HIE-dependent, extensible process that deduplicates individuals for less biased prevalence estimates in a DDN. Our null pilot findings have limited generalizability. Overlap was small and likely insufficient to influence prevalence estimates. Other factors, including the number and size of partners, the matching algorithm, and the electronic phenotype may influence the degree of deduplication bias. Additional use cases may help improve understanding of duplication bias and reveal other principles and insights. This study informed how DDNs could support learning health systems' response to public health challenges and improve regional health.",
      "authors": "Scott Kenneth A; Davies Sara Deakyne; Zucker Rachel; Ong Toan; Kraus Emily McCormick; Kahn Michael G; Bondy Jessica; Daley Matt F; Horle Kate; Bacon Emily; Schilling Lisa; Crume Tessa; Hasnain-Wynia Romana; Foldy Seth; Budney Gregory; Davidson Arthur J",
      "year": "2022",
      "journal": "Learning health systems",
      "doi": "10.1002/lrh2.10297",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35860322/",
      "mesh_terms": "",
      "keywords": "electronic health records; medical record linkage; network; public health informatics; public health surveillance",
      "pub_types": "Journal Article",
      "pmcid": "PMC9284932"
    },
    {
      "pmid": "38395165",
      "title": "Satellite-based aerosol optical depth estimates over the continental U.S. during the 2020 wildfire season: Roles of smoke and land cover.",
      "abstract": "Wildfires produce smoke that can affect an area >1000 times the burn extent, with far-reaching human health, ecologic, and economic impacts. Accurately estimating aerosol load within smoke plumes is therefore crucial for understanding and mitigating these impacts. We evaluated the effectiveness of the latest Collection 6.1 MODIS Multi-Angle Implementation of Atmospheric Correction (MAIAC) algorithm in estimating aerosol optical depth (AOD) across the U.S. during the historic 2020 wildfire season. We compared satellite-based MAIAC AOD to ground-based AERONET AOD measurements during no-, light-, medium-, and heavy-smoke conditions identified using the Hazard Mapping System Fire and Smoke Product. This smoke product consists of maximum extent smoke polygons digitized by analysts using visible band imagery and classified according to smoke density. We also examined the strength of the correlations between satellite- and ground-based AOD for major land cover types under various smoke density levels. MAIAC performed well in estimating AOD during smoke-affected conditions. Correlations between MAIAC and AERONET AOD were strong for medium- (r\u00a0=\u00a00.91) and heavy-smoke (r\u00a0=\u00a00.90) density, and MAIAC estimates of AOD showed little bias relative to ground-based AERONET measurements (normalized mean bias\u00a0=\u00a03\u00a0% for medium, 5\u00a0% for heavy smoke). During two high AOD, heavy smoke episodes, MAIAC underestimated ground-based AERONET AOD under mixed aerosol (i.e., smoke and dust; median bias\u00a0=\u00a0-0.08) and overestimated AOD under smoke-dominated (median bias\u00a0=\u00a00.02) aerosol. MAIAC most overestimated ground-based AERONET AOD over barren land (mean NMB\u00a0=\u00a048\u00a0%). Our findings indicate that MODIS MAIAC can provide robust estimates of AOD as smoke density increases in coming years. Increased frequency of mixed aerosol and expansion of developed land could affect the performance of the MAIAC algorithm in the future, however, with implications for evaluating wildfire-associated health and welfare effects and air quality standards.",
      "authors": "Daniels Jacob; Liang Lu; Benedict Katherine B; Brahney Janice; Rangel Roman; Weathers Kathleen C; Ponette-Gonz\u00e1lez Alexandra G",
      "year": "2024",
      "journal": "The Science of the total environment",
      "doi": "10.1016/j.scitotenv.2024.171122",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38395165/",
      "mesh_terms": "",
      "keywords": "AERONET; Air quality; Dust; MODIS; Particulate matter; Wildland-urban interface; \u00c5ngstr\u00f6m exponent",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40628455",
      "title": "Enhancing AI Readiness in Pediatric Surgery: Impact of a Targeted Workshop on Knowledge and Competencies.",
      "abstract": "Despite an awareness of the transformative potential of artificial intelligence (AI) in health care, its development in pediatric surgery seems slow. One major reason may be a lack of formal AI training. This study assesses the basic AI knowledge and the effectiveness of AI workshops (AI-WS).Four AI-WS were held at the International Academy of Pediatric Surgery 2024. Topics included AI principles, real-time algorithm training, and potential AI applications in pediatric surgery. Self-developed surveys consisting of eight pre-WS and nine post-WS questions were conducted, focusing on participants' AI competencies, usage, educational needs, barriers, and future perspectives.Out of 57 pediatric surgeons, 53 completed both surveys. None had formal AI training. Although 90% were familiar with AI in diagnostic imaging, most had only basic knowledge of AI technology. After the workshop, participants reported a significant increase in the general understanding of AI/machine learning (ML) (p\u2009<\u20090.001). 96% stated that they were better informed about AI/ML applications for clinical practice; 83% expressed interest in further AI training; 91% believed that AI will be more integrated into clinical practice; and over 80% anticipated that AI will improve patient outcomes.The AI-WS effectively enhanced pediatric surgeons' AI knowledge and their readiness to adopt AI technologies. Even though our study is limited by the relatively low sample size and a potential selection bias, our results still highlight the importance of targeted education in preparing health care professionals for AI integration. The long-term sustainability of knowledge gains, however, has to be examined in further studies.",
      "authors": "Till Holger; Elsayed Hesham; Singer Georg; Oberm\u00fcller Beate; Till Tristan; Gnatzy Richard; Tschauner Sebastian",
      "year": "2025",
      "journal": "European journal of pediatric surgery : official journal of Austrian Association of Pediatric Surgery ... [et al] = Zeitschrift fur Kinderchirurgie",
      "doi": "10.1055/a-2650-6603",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40628455/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41349584",
      "title": "Enhancing Maternal Health Surveillance in the United States Through Natural Language Processing.",
      "abstract": "Maternal health outcomes are essential indicators of overall health care quality and societal well-being. However, in the United States, the maternal health surveillance is often inaccurate, restricting the clinical utility of the data gathered. The limits imposed by these inaccuracies restrict timely policy responses and hinder effective innovations, despite the increasing availability of electronic health records. This paper explores the potential use of natural language processing in improving maternal health surveillance. By combining rule-based linguistic processing with machine learning, natural language processing can transform narrative text into structured, analyzable data, allowing it to be used for predictive purposes, as well as the development of real-time public health surveillance systems. \u00b7 Maternal health surveillance is often inaccurate, restricting the clinical utility of the data.. \u00b7 Natural language processing can extract key insights from unstructured clinical notes.. \u00b7 Artificial intelligence-driven surveillance in obstetrics may improve data accuracy and timeliness.. \u00b7 Ethical use of natural language processing needs to ensure privacy, bias control, and validation..",
      "authors": "Horgan Rebecca; Kawakita Tetsuya; Saade George",
      "year": "2025",
      "journal": "American journal of perinatology",
      "doi": "10.1055/a-2764-2341",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41349584/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37516036",
      "title": "Assessment of machine learning algorithms in national data to classify the risk of self-harm among young adults in hospital: A retrospective study.",
      "abstract": "BACKGROUND: Self-harm is one of the most common presentations at accident and emergency departments in the UK and is a strong predictor of suicide risk. The UK Government has prioritised identifying risk factors and developing preventative strategies for self-harm. Machine learning offers a potential method to identify complex patterns with predictive value for the risk of self-harm. METHODS: National data in the UK Mental Health Services Data Set were isolated for patients aged 18-30\u00a0years who started a mental health hospital admission between Aug 1, 2020 and Aug 1, 2021, and had been discharged by Jan 1, 2022. Data were obtained on age group, gender, ethnicity, employment status, marital status, accommodation status and source of admission to hospital and used to construct seven machine learning models that were used individually and as an ensemble to predict hospital stays that would be associated with a risk of self-harm. OUTCOMES: The training dataset included 23 808 items (including 1081 episodes of self-harm) and the testing dataset 5951 items (including 270 episodes of self-harm). The best performing algorithms were the random forest model (AUC-ROC 0.70, 95%CI:0.66-0.74) and the ensemble model (AUC-ROC 0.77 95%CI:0.75-0.79). INTERPRETATION: Machine learning algorithms could predict hospital stays with a high risk of self-harm based on readily available data that are routinely collected by health providers and recorded in the Mental Health Services Data Set. The findings should be validated externally with other real-world, prospective data. FUNDING: This study was supported by the Midlands and Lancashire Commissioning Support Unit.",
      "authors": "Arora Anmol; Bojko Louis; Kumar Santosh; Lillington Joseph; Panesar Sukhmeet; Petrungaro Bruno",
      "year": "2023",
      "journal": "International journal of medical informatics",
      "doi": "10.1016/j.ijmedinf.2023.105164",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37516036/",
      "mesh_terms": "Humans; Young Adult; Retrospective Studies; Prospective Studies; Self-Injurious Behavior; Machine Learning; Hospitals; Algorithms; Risk Assessment",
      "keywords": "Algorithmic bias; Artificial intelligence; Deep learning; Generalisability; Neural networks; Psychiatry; Risk stratification; Statistical models",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "35995107",
      "title": "PheValuator 2.0: Methodological improvements for the PheValuator approach to semi-automated phenotype algorithm evaluation.",
      "abstract": "PURPOSE: Phenotype algorithms are central to performing analyses using observational data. These algorithms translate the clinical idea of a health condition into an executable set of rules allowing for queries of data elements from a database. PheValuator, a software package in the Observational Health Data Sciences and Informatics (OHDSI) tool stack, provides a method to assess the performance characteristics of these algorithms, namely, sensitivity, specificity, and positive and negative predictive value. It uses machine learning to develop predictive models for determining a probabilistic gold standard of subjects for assessment of cases and non-cases of health conditions. PheValuator was developed to complement or even replace the traditional approach of algorithm validation, i.e., by expert assessment of subject records through chart review. Results in our first PheValuator paper suggest a systematic underestimation of the PPV compared to previous results using chart review. In this paper we evaluate modifications made to the method designed to improve its performance. METHODS: The major changes to PheValuator included allowing all diagnostic conditions, clinical observations, drug prescriptions, and laboratory measurements to be included as predictors within the modeling process whereas in the prior version there were significant restrictions on the included predictors. We also have allowed for the inclusion of the temporal relationships of the predictors in the model. To evaluate the performance of the new method, we compared the results from the new and original methods against results found from the literature using traditional validation of algorithms for 19 phenotypes. We performed these tests using data from five commercial databases. RESULTS: In the assessment aggregating all phenotype algorithms, the median difference between the PheValuator estimate and the gold standard estimate for PPV was reduced from -21 (IQR -34, -3) in Version 1.0 to 4 (IQR -3, 15) using Version 2.0. We found a median difference in specificity of 3 (IQR 1, 4.25) for Version 1.0 and 3 (IQR 1, 4) for Version 2.0. The median difference between the two versions of PheValuator and the gold standard for estimates of sensitivity was reduced from -39 (-51, -20) to -16 (-34, -6). CONCLUSION: PheValuator 2.0 produces estimates for the performance characteristics for phenotype algorithms that are significantly closer to estimates from traditional validation through chart review compared to version 1.0. With this tool in researcher's toolkits, methods, such as quantitative bias analysis, may now be used to improve the reliability and reproducibility of research studies using observational data.",
      "authors": "Swerdel Joel N; Schuemie Martijn; Murray Gayle; Ryan Patrick B",
      "year": "2022",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2022.104177",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35995107/",
      "mesh_terms": "Reproducibility of Results; Algorithms; Databases, Factual; Machine Learning; Phenotype",
      "keywords": "Phenotype algorithms; Positive predictive value; Sensitivity; Specificity",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40956256",
      "title": "American Association of Clinical Endocrinology Consensus Statement: Algorithm for the Evaluation and Treatment of Adults with Obesity/Adiposity-Based Chronic Disease - 2025 Update.",
      "abstract": "OBJECTIVE: This 2025 consensus statement provides evidence-based visual guidance in graphic algorithms and a summary of evidence to assist health care professionals and adults with obesity and adiposity-based chronic disease (ABCD) in shared decision making to improve care and achieve health goals. METHODS: AACE selected a task force of medical experts to update the 2016 AACE algorithm for the medical care of patients with obesity and align this algorithm update with related AACE clinical guidance. Details on surgical and procedural therapies for obesity treatment as well as the care of pediatric-aged patients are beyond the scope of this algorithm. RESULTS: The algorithm includes 11 sections: (1) principles of person-centered and complication-centric management of obesity/ABCD, (2) care model for people with obesity/ABCD: screening and diagnosis, (3) diagnosis: anthropometric component, (4) diagnosis: clinical component, (5) individualized treatment plan, therapeutic goals, and follow-up, (6) response to therapy and weight-loss targets for people with ABCD, (7) behavioral/lifestyle therapy for people with obesity/ABCD, (8) hierarchies of preferred medications for complication-centric care of people with ABCD, (9) lower-cost pharmacologic step therapy for ABCD, (10) medications for obesity: individualization of therapy, and (11) medications for obesity approved by the U.S. Food and Drug Administration. CONCLUSIONS: This 2025 algorithm for the medical care of adults with obesity underscores that ABCD is a complex, chronic disease that necessitates long-term treatment and care. Emphasis is placed on optimizing health rather than just weight reduction and achieving clinical goals other than a singular focus on body mass index (ie, complication-centric care). Choice of interventions and intensity of treatment should be individualized, taking disease severity or stage into account. Equality of care and reducing weight bias and stigma through a biopsychosocial chronic care model are critical and included throughout this clinical guidance statement.",
      "authors": "Nadolsky Karl; Garvey W Timothy; Agarwal Monica; Bonnecaze Alex; Burguera Bartolome; Chaplin Michelle DeGeeter; Griebeler Marcio L; Harris Samantha R; Schellinger Jeffrey N; Simonetti Juliana; Srinath Reshmi; Yumuk Volkan",
      "year": "2025",
      "journal": "Endocrine practice : official journal of the American College of Endocrinology and the American Association of Clinical Endocrinologists",
      "doi": "10.1016/j.eprac.2025.07.017",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40956256/",
      "mesh_terms": "Humans; Algorithms; Obesity; Chronic Disease; Adult; Adiposity; Endocrinology; Societies, Medical; United States",
      "keywords": "ABCD; adiposity-based chronic disease; complication-centric; complications; obesity; obesity algorithm; obesity management; obesity medications",
      "pub_types": "Journal Article; Consensus Statement",
      "pmcid": ""
    },
    {
      "pmid": "37003169",
      "title": "An efficient landmark model for prediction of suicide attempts in multiple clinical settings.",
      "abstract": "Growing evidence has shown that applying machine learning models to large clinical data sources may exceed clinician performance in suicide risk stratification. However, many existing prediction models either suffer from \"temporal bias\" (a bias that stems from using case-control sampling) or require training on all available patient visit data. Here, we adopt a \"landmark model\" framework that aligns with clinical practice for prediction of suicide-related behaviors (SRBs) using a large electronic health record database. Using the landmark approach, we developed models for SRB prediction (regularized Cox regression and random survival forest) that establish a time-point (e.g., clinical visit) from which predictions are made over user-specified prediction windows using historical information up to that point. We applied this approach to cohorts from three clinical settings: general outpatient, psychiatric emergency department, and psychiatric inpatients, for varying prediction windows and lengths of historical data. Models achieved high discriminative performance (area under the Receiver Operating Characteristic curve 0.74-0.93 for the Cox model) across different prediction windows and settings, even with relatively short periods of historical data. In short, we developed accurate, dynamic SRB risk prediction models with the landmark approach that reduce bias and enhance the reliability and portability of suicide risk prediction models.",
      "authors": "Sheu Yi-Han; Sun Jiehuan; Lee Hyunjoon; Castro Victor M; Barak-Corren Yuval; Song Eugene; Madsen Emily M; Gordon William J; Kohane Isaac S; Churchill Susanne E; Reis Ben Y; Cai Tianxi; Smoller Jordan W",
      "year": "2023",
      "journal": "Psychiatry research",
      "doi": "10.1016/j.psychres.2023.115175",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37003169/",
      "mesh_terms": "Humans; Suicide, Attempted; Reproducibility of Results; Emergency Service, Hospital; ROC Curve",
      "keywords": "Electronic health record; Landmark model; Prediction; Suicide attempt",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10267893"
    },
    {
      "pmid": "38711170",
      "title": "Uncovering and Expressing our Purpose.",
      "abstract": "Generative artificial intelligence (AI) is currently a source of angst, because of its ability to give us content that sounds uncannily like a real person, and because of concern that people will not stop at using it as a tool to generate and synthesize ideas, but instead will cede control over our words, and then our thoughts. This editorial details each article in Creative Nursing Vol. 30 Issue 2, highlighting the ways in which social media, different kinds of AI, and other tools for connectivity can be used for good: finding our purpose, uniting people over long distances, expediting knowledge implementation, managing large volumes of literature, advancing health equity, and enriching nursing education.",
      "authors": "Lewis-Hunstiger Marty",
      "year": "2024",
      "journal": "Creative nursing",
      "doi": "10.1177/10784535241250195",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38711170/",
      "mesh_terms": "Humans; Artificial Intelligence; Social Media",
      "keywords": "Generative AI; WhatsApp; algorithm bias; implementation science; in garbage out; singularity",
      "pub_types": "Editorial",
      "pmcid": ""
    },
    {
      "pmid": "41370279",
      "title": "Development of machine learning models for prediction of current and future dementia.",
      "abstract": "Dementia is among the most distressing and burdensome health challenges in aging populations. Treatment efficacy is limited; however, early diagnosis can delay or prevent disease progression. Previous machine learning-based prediction models have limitations (e.g., they are based on clinical parameters or are not generalizable). Thus, in this study, prediction models were developed for current and future dementia solely based on demographic, socioeconomic, and health-related features. Demographic, socioeconomic, and health-related variables collected from the Korean Longitudinal Study of Ageing (KLoSA) were used to develop machine learning-based prediction models for current and future dementia with various algorithms. Two sampling strategies were used for feature selection, one based on domain knowledge and the other based on statistical testing. Hyperparameter tuning was performed using grid search with cross-validation on the training set, and model evaluation was conducted on a separate test set. In the initial no-follow-up dataset, 92 of 6,898 participants exhibited dementia. Among 6,207 participants without dementia initially, 69 developed dementia within 2 years. Linear support vector machine (SVM) and radial bias function SVM exhibited the best sensitivity for current and future dementia (79.4% and 77.7%, respectively). The SHAP (SHapley Additive exPlanations) approach improved the transparency of the model by highlighting the top ten features most strongly associated with increased dementia risk. We achieved reasonably accurate prediction results for dementia using only non-clinical features.",
      "authors": "Jeong Wonseok; Chung Wankyo",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0330213",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41370279/",
      "mesh_terms": "Humans; Dementia; Male; Aged; Female; Machine Learning; Longitudinal Studies; Aged, 80 and over; Support Vector Machine; Republic of Korea; Middle Aged; Algorithms",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12694792"
    },
    {
      "pmid": "41332851",
      "title": "Causal modeling of chronic kidney disease in a participatory framework for informing the inclusion of social drivers in health algorithms.",
      "abstract": "Incomplete or incorrect causal theories are a key source of bias in machine learning (ML) algorithms. Community-engaged methodologies provide an avenue for mitigating this bias through incorporating causal insights from community stakeholders into ML development. In health applications, community-engaged approaches can enable the study of social drivers of health (SDOH), which are known to shape health inequities. However, it remains challenging for SDOH to inform ML algorithms, partially because SDOH variables are known to be interrelated, yet it is difficult to elucidate the causal relationships between them. Community based system dynamics is a community-engaged methodology that can be used to co-create formal causal graphs, called causal loop diagrams, with patients. Here, we used community based system dynamics to create a causal graph representing the impacts of SDOH on the progression of chronic kidney disease, a chronic condition with SDOH-driven health disparities. We conducted focus groups with 42 participants and a day-long model building workshop with 11 participants, resulting in a final graph comprising 16 variables, 42 causal links, and 5 subsystems of semantically related SDOH variables. This final graph, representing the causal relationships between social variables relevant to chronic kidney disease, can inform the development of clinical ML algorithms and other technological interventions.",
      "authors": "Foryciarz Agata; Srivathsa Neha; Sedan Oshra; Goldman Rosas Lisa; Rose Sherri",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.11.19.25340498",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41332851/",
      "mesh_terms": "",
      "keywords": "causal loop diagram; chronic kidney disease; community based systems dynamics; community engaged research; group model building; health inequities; participatory AI; social drivers of health",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12668084"
    },
    {
      "pmid": "34304401",
      "title": "Development and validation of an algorithm using health administrative data to define patient attachment to primary care providers.",
      "abstract": "PURPOSE: The authors developed and validated an algorithm using health administrative data to identify patients who are attached or uncertainly attached to a primary care provider (PCP) using patient responses to a survey conducted in Ontario, Canada. DESIGN/METHODOLOGY/APPROACH: The authors conducted a validation study using as a reference standard respondents to a community-based survey who indicated they did or did not have a PCP. The authors developed and tested health administrative algorithms against this reference standard. The authors calculated the sensitivity, specificity positive predictive value (PPV) and negative predictive value (NPV) on the final patient attachment algorithm. The authors then applied the attachment algorithm to the 2017 Ontario population. FINDINGS: The patient attachment algorithm had an excellent sensitivity (90.5%) and PPV (96.8%), though modest specificity (46.1%) and a low NPV (21.3%). This means that the algorithm assigned survey respondents as being attached to a PCP and when in fact they said they had a PCP, yet a significant proportion of those found to be uncertainly attached had indicated they did have a PCP. In 2017, most people in Ontario, Canada (85.4%) were attached to a PCP but 14.6% were uncertainly attached. RESEARCH LIMITATIONS/IMPLICATIONS: Administrative data for nurse practitioner's encounters and other interprofessional care providers are not currently available. The authors also cannot separately identify primary care visits conducted in walk in clinics using our health administrative data. Finally, the definition of hospital-based healthcare use did not include outpatient specialty care. PRACTICAL IMPLICATIONS: Uncertain attachment to a primary health care provider is a recurrent problem that results in inequitable access in health services delivery. Providing annual reports on uncertainly attached patients can help evaluate primary care system changes developed to improve access. This algorithm can be used by health care planners and policy makers to examine the geographic variability and time trends of the uncertainly attached population to inform the development of programs to improve primary care access. SOCIAL IMPLICATIONS: As primary care is an essential component of a person's medical home, identifying regions or high need populations that have higher levels of uncertainly attached patients will help target programs to support their primary care access and needs. Furthermore, this approach will be useful in future research to determine the health impacts of uncertain attachment to primary care, especially in view of a growing body of the literature highlighting the importance of primary care continuity. ORIGINALITY/VALUE: This patient attachment algorithm is the first to use existing health administrative data validated with responses from a patient survey. Using patient surveys alone to assess attachment levels is expensive and time consuming to complete. They can also be subject to poor response rates and recall bias. Utilizing existing health administrative data provides more accurate, timely estimates of patient attachment for everyone in the population.",
      "authors": "Jaakkimainen Liisa; Bayoumi Imaan; Glazier Richard H; Premji Kamila; Kiran Tara; Khan Shahriar; Frymire Eliot; Green Michael E",
      "year": "2021",
      "journal": "Journal of health organization and management",
      "doi": "10.1108/JHOM-05-2020-0171",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34304401/",
      "mesh_terms": "Algorithms; Delivery of Health Care; Health Personnel; Humans; Ontario; Primary Health Care",
      "keywords": "Big data; Health services research; Methodology; Primary care",
      "pub_types": "Journal Article",
      "pmcid": "PMC8956282"
    },
    {
      "pmid": "25565889",
      "title": "Validation of the danish national diabetes register.",
      "abstract": "The Danish National Diabetes Register (NDR) was established in 2006 and builds on data from Danish health registers. We validated the content of NDR, using full information from the Danish National Patient Register and data from the literature. Our study indicates that the completeness in NDR is \u226595% concerning ascertainment from data sources specific for diabetes, ie, prescriptions with antidiabetic drugs and diagnoses of diabetes in the National Patient Register. Since the NDR algorithm ignores diabetes-related hospital contacts terminated before 1990, the establishment of the date of inclusion is systematically delayed for \u226510% of the registrants in general and for \u226530% of the inclusions before 1997 in particular. This bias is enhanced for ascertainment by chiropody services and by frequent measurements of blood glucose because the date of reimbursement of services, rather than the date of encounter, has been taken as the date of inclusion in NDR. We also find that some 20% of the registrations in NDR may represent false positive inclusions of persons with frequent measurements of blood glucose without having diabetes. We conclude that NDR is a novel initiative to support research in the epidemiological and public health aspects of diabetes in Denmark, but we also present a list of recommended changes for improving validity, by reducing the impact of current sources of bias and misclassifications.",
      "authors": "Green Anders; Sorts\u00f8 Camilla; Jensen Peter Bj\u00f8dstrup; Emneus Martha",
      "year": "2015",
      "journal": "Clinical epidemiology",
      "doi": "10.2147/CLEP.S72768",
      "url": "https://pubmed.ncbi.nlm.nih.gov/25565889/",
      "mesh_terms": "",
      "keywords": "ascertainment; diabetes mellitus; epidemiology; validity",
      "pub_types": "Journal Article",
      "pmcid": "PMC4274151"
    },
    {
      "pmid": "41272799",
      "title": "FLASH: innovative integrated enzymatic-fluorescent labeling for automated muscle fiber typing, metabolic and morphometric analysis.",
      "abstract": "BACKGROUND: Skeletal muscle is a dynamic tissue capable of structural and metabolic remodeling in response to physiological and pathological stimuli. These adaptations are central to understanding the mechanisms underlying conditions such as genetic myopathies, cancer, aging, and recovery from injury. Muscle fiber characterization-assessing fiber type, size, and metabolic profile-is essential for such studies. However, conventional histological methods often rely on serial tissue sections and multiple staining protocols, which are time-consuming, require significant biological material, and introduce methodological bias. METHODS: We developed FLASH (Fluorescence-based Labeling for Assessing Skeletal muscle Histology), a novel methodology combining enzymatic (SDH or GPDH) and quadruple fluorescent labeling (Laminin, MYH4, MYH2, MYH7) on a single muscle section. The resulting images were analyzed using a custom macro in Fiji/ImageJ, integrating the Cellpose segmentation algorithm. This automated pipeline detects individual muscle fibers, quantifies their cross-sectional area (CSA), identifies fiber types based on myosin isoform expression, and measures enzymatic staining intensity. Batch analysis was implemented to process entire image folders automatically. Validation was performed by comparing automated fiber detection with expert manual segmentation using correlation analysis and Bland-Altman plots. RESULTS: The FLASH method allowed simultaneous assessment of both contractile and metabolic properties within individual fibers on the same section, removing the need for serial cuts. The automated image analysis achieved high accuracy in fiber detection (r\u2009>\u20090.95 compared to manual annotation) and produced consistent CSA and fiber-type quantification, even under suboptimal staining conditions. The macro enabled significant time savings by automating the complete analysis workflow, including ROI generation and Excel data export for each image. CONCLUSIONS: FLASH provides an efficient and robust tool for high-throughput skeletal muscle histology. By combining enzymatic and fluorescent co-labeling with machine learning-based image analysis, this method improves reproductibility, reduces experimental complexity, and minimizes user bias. FLASH is particularly well-suited for large-scale or longitudinal studies investigating muscle adaptation in health and disease.",
      "authors": "Di Gallo Maxime; Guilbert Thomas; Pereira Doriane; Cepella Zo\u00e9; Braud-Mussi Rapha\u00ebl; Jauliac Edgar; Macaux Gaspard; Britto Florian Alexis; Launay Thierry",
      "year": "2025",
      "journal": "Skeletal muscle",
      "doi": "10.1186/s13395-025-00401-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41272799/",
      "mesh_terms": "Muscle Fibers, Skeletal; Animals; Myosin Heavy Chains; Staining and Labeling; Mice; Fluorescent Dyes; Image Processing, Computer-Assisted",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12639953"
    },
    {
      "pmid": "32656489",
      "title": "The impact of measurement error in modeled ambient particles exposures on health effect estimates in multilevel analysis: A simulation study.",
      "abstract": "UNLABELLED: Various spatiotemporal models have been proposed for predicting ambient particulate exposure for inclusion in epidemiological analyses. We investigated the effect of measurement error in the prediction of particulate matter with diameter <10 \u00b5m (PM10) and <2.5 \u00b5m (PM2.5) concentrations on the estimation of health effects. METHODS: We sampled 1,000 small administrative areas in London, United Kingdom, and simulated the \"true\" underlying daily exposure surfaces for PM10 and PM2.5 for 2009-2013 incorporating temporal variation and spatial covariance informed by the extensive London monitoring network. We added measurement error assessed by comparing measurements at fixed sites and predictions from spatiotemporal land-use regression (LUR) models; dispersion models; models using satellite data and applying machine learning algorithms; and combinations of these methods through generalized additive models. Two health outcomes were simulated to assess whether the bias varies with the effect size. We applied multilevel Poisson regression to simultaneously model the effect of long- and short-term pollutant exposure. For each scenario, we ran 1,000 simulations to assess measurement error impact on health effect estimation. RESULTS: For long-term exposure to particles, we observed bias toward the null, except for traffic PM2.5 for which only LUR underestimated the effect. For short-term exposure, results were variable between exposure models and bias ranged from -11% (underestimate) to 20% (overestimate) for PM10 and of -20% to 17% for PM2.5. Integration of models performed best in almost all cases. CONCLUSIONS: No single exposure model performed optimally across scenarios. In most cases, measurement error resulted in attenuation of the effect estimate.",
      "authors": "Samoli Evangelia; Butland Barbara K; Rodopoulou Sophia; Atkinson Richard W; Barratt Benjamin; Beevers Sean D; Beddows Andrew; Dimakopoulou Konstantina; Schwartz Joel D; Yazdi Mahdieh Danesh; Katsouyanni Klea",
      "year": "2020",
      "journal": "Environmental epidemiology (Philadelphia, Pa.)",
      "doi": "10.1097/EE9.0000000000000094",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32656489/",
      "mesh_terms": "",
      "keywords": "Health effects; Measurement error; Modeled air pollution; Particulate matter",
      "pub_types": "Journal Article",
      "pmcid": "PMC7319186"
    },
    {
      "pmid": "40610644",
      "title": "Personalized game-based digital intervention for relieving depression and anxiety symptoms: a pilot RCT.",
      "abstract": "This study assessed the preliminary effectiveness of a game-based digital therapeutics (DTx) intervention for depression and anxiety using a randomized controlled trial (RCT) design to examine the role of reinforcement learning (RL) personalization. This RCT included 223 individuals with depressive symptoms, aged 18-50, divided into three groups: an RL Algorithm group (personalized treatment), an active control group (fixed treatment), and a no-intervention control group. The intervention combined cognitive bias modification and cognitive behavioral therapy, with outcomes measured by the Patient Health Questionnaire-9 and the Generalized Anxiety Disorder-7. Results showed significantly higher treatment response and recovery rates in the RL Algorithm group compared to the no-intervention group. The game-based DTx intervention, enhanced by RL personalization, effectively reduced depression and anxiety symptoms, supporting its potential for mental health treatment. The study was registered at clinicaltrials.gov (NCT06301555).",
      "authors": "Shao Xiaojun; Liu Lu; Zhu Xiaotong; Tian Chunsheng; Li Dai; Zhang Liqun; Liu Xiang; Liu Yanru; Zhu Gang; Li Lingjiang",
      "year": "2025",
      "journal": "Npj mental health research",
      "doi": "10.1038/s44184-025-00141-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40610644/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12229681"
    },
    {
      "pmid": "30625513",
      "title": "Total polyphenol quantitation using integrated NIR and MIR spectroscopy: A case study of Chinese dates (Ziziphus jujuba).",
      "abstract": "INTRODUCTION: Polyphenols are the foremost measure of phytochemicals in Chinese dates due to their many potential health benefits such as averting cancers, reducing the risk of coronary artery disease, diuretic activity, myocardial stimulant, coronary dilator and muscle relaxant. OBJECTIVE: To quantitate the polyphenols in Chinese dates using a data fusion approach with near-infrared (NIR) and mid-infrared (MIR) spectroscopy. MATERIAL AND METHODS: A total of 80 Chinese dates samples were used for data acquisition from both NIR and MIR spectroscopy. The efficient spectral intervals were extracted by the synergy interval partial least square (Si-PLS) algorithm as input variables for NIR-MIR fusion model. A genetic algorithm (GA) was used to construct the model based on NIR-MIR fusion. The performance of the developed models was evaluated using correlation coefficients of calibration (R2 ) and prediction (r2 ), root mean square error of prediction (RMSEP), bias and residual prediction deviation (RPD). RESULTS: The data fusion model based on the GA was superior compared to NIR and MIR build model. The optimal GA-fusion model yielded R2 \u00a0=\u00a00.9621, r2 \u00a0=\u00a00.9451, RPD\u00a0=\u00a02.44, calibration set bias\u00a0=\u00a00.004 and prediction set bias\u00a0=\u00a00.061, computing only 15 variables. CONCLUSION: These findings reveal that integration of NIR and MIR is possible for the prediction of total polyphenol content in Chinese dates.",
      "authors": "Arslan Muhammad; Xiaobo Zou; Tahir Haroon Elrasheid; Zareef Muhammad; Xuetao Hu; Rakha Allah",
      "year": "2019",
      "journal": "Phytochemical analysis : PCA",
      "doi": "10.1002/pca.2818",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30625513/",
      "mesh_terms": "Algorithms; Calibration; Colorimetry; Fruit; Polyphenols; Spectrophotometry, Infrared; Spectroscopy, Near-Infrared; Ziziphus",
      "keywords": "genetic algorithms; polyphenols; principal component analysis; spectral interval selection; spectroscopy techniques",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35791751",
      "title": "Constrained groupwise additive index models.",
      "abstract": "In environmental epidemiology, there is wide interest in creating and using comprehensive indices that can summarize information from different environmental exposures while retaining strong predictive power on a target health outcome. In this context, the present article proposes a model called the constrained groupwise additive index model (CGAIM) to create easy-to-interpret indices predictive of a response variable, from a potentially large list of variables. The CGAIM considers groups of predictors that naturally belong together to yield meaningful indices. It also allows the addition of linear constraints on both the index weights and the form of their relationship with the response variable to represent prior assumptions or operational requirements. We propose an efficient algorithm to estimate the CGAIM, along with index selection and inference procedures. A simulation study shows that the proposed algorithm has good estimation performances, with low bias and variance and is applicable in complex situations with many correlated predictors. It also demonstrates important sensitivity and specificity in index selection, but non-negligible coverage error on constructed confidence intervals. The CGAIM is then illustrated in the construction of heat indices in a health warning system context. We believe the CGAIM could become useful in a wide variety of situations, such as warning systems establishment, and multipollutant or exposome studies.",
      "authors": "Masselot Pierre; Chebana Fateh; Campagna C\u00e9line; Lavigne \u00c9ric; Ouarda Taha B M J; Gosselin Pierre",
      "year": "2023",
      "journal": "Biostatistics (Oxford, England)",
      "doi": "10.1093/biostatistics/kxac023",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35791751/",
      "mesh_terms": "Humans; Environmental Exposure; Computer Simulation; Algorithms; Bias",
      "keywords": "Additive index models; Dimension reduction; Index; Linear constraints; Quadratic programming",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10583725"
    },
    {
      "pmid": "31799938",
      "title": "Counting Bites With Bits: Expert Workshop Addressing Calorie and Macronutrient Intake Monitoring.",
      "abstract": "BACKGROUND: Conventional diet assessment approaches such as the 24-hour self-reported recall are burdensome, suffer from recall bias, and are inaccurate in estimating energy intake. Wearable sensor technology, coupled with advanced algorithms, is increasingly showing promise in its ability to capture behaviors that provide useful information for estimating calorie and macronutrient intake. OBJECTIVE: This paper aimed to summarize current technological approaches to monitoring energy intake on the basis of expert opinion from a workshop panel and to make recommendations to advance technology and algorithms to improve estimation of energy expenditure. METHODS: A 1-day invitational workshop sponsored by the National Science Foundation was held at Northwestern University. A total of 30 participants, including population health researchers, engineers, and intervention developers, from 6 universities and the National Institutes of Health participated in a panel discussing the state of evidence with regard to monitoring calorie intake and eating behaviors. RESULTS: Calorie monitoring using technological approaches can be characterized into 3 domains: (1) image-based sensing (eg, wearable and smartphone-based cameras combined with machine learning algorithms); (2) eating action unit (EAU) sensors (eg, to measure feeding gesture and chewing rate); and (3) biochemical measures (eg, serum and plasma metabolite concentrations). We discussed how each domain functions, provided examples of promising solutions, and highlighted potential challenges and opportunities in each domain. Image-based sensor research requires improved ground truth (context and known information about the foods), accurate food image segmentation and recognition algorithms, and reliable methods of estimating portion size. EAU-based domain research is limited by the understanding of when their systems (device and inference algorithm) succeed and fail, need for privacy-protecting methods of capturing ground truth, and uncertainty in food categorization. Although an exciting novel technology, the challenges of biochemical sensing range from a lack of adaptability to environmental effects (eg, temperature change) and mechanical impact, instability of wearable sensor performance over time, and single-use design. CONCLUSIONS: Conventional approaches to calorie monitoring rely predominantly on self-reports. These approaches can gain contextual information from image-based and EAU-based domains that can map automatically captured food images to a food database and detect proxies that correlate with food volume and caloric intake. Although the continued development of advanced machine learning techniques will advance the accuracy of such wearables, biochemical sensing provides an electrochemical analysis of sweat using soft bioelectronics on human skin, enabling noninvasive measures of chemical compounds that provide insight into the digestive and endocrine systems. Future computing-based researchers should focus on reducing the burden of wearable sensors, aligning data across multiple devices, automating methods of data annotation, increasing rigor in studying system acceptability, increasing battery lifetime, and rigorously testing validity of the measure. Such research requires moving promising technological solutions from the controlled laboratory setting to the field.",
      "authors": "Alshurafa Nabil; Lin Annie Wen; Zhu Fengqing; Ghaffari Roozbeh; Hester Josiah; Delp Edward; Rogers John; Spring Bonnie",
      "year": "2019",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/14904",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31799938/",
      "mesh_terms": "Algorithms; Education; Energy Intake; Feeding Behavior; Humans; Smartphone; Telemedicine; United States; Wearable Electronic Devices",
      "keywords": "computer vision systems; computing methodologies; diet; eHealth; eating; energy intake; feeding behavior; mHealth; nutritional status; obesity; wearable technology",
      "pub_types": "Consensus Statement; Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC6920913"
    },
    {
      "pmid": "30627211",
      "title": "The Design and Implementation of Cardiotocography Signals Classification Algorithm Based on Neural Network.",
      "abstract": "Mobile medical care is a hot issue in current medical research. Due to the inconvenience of going to hospital for fetal heart monitoring and the limited medical resources, real-time monitoring of fetal health on portable devices has become an urgent need for pregnant women, which helps to protect the health of the fetus in a more comprehensive manner and reduce the workload of doctors. For the feature acquisition of the fetal heart rate (FHR) signal, the traditional feature-based classification methods need to manually read the morphological features from the FHR curve, which is time-consuming and costly and has a certain degree of calibration bias. This paper proposes a classification method of the FHR signal based on neural networks, which can avoid manual feature acquisition and reduce the error caused by human factors. The algorithm will directly learn from the FHR data and truly realize the real-time diagnosis of FHR data. The convolution neural network classification method named \"MKNet\" and recurrent neural network named \"MKRNN\" are designed. The main contents of this paper include the preprocessing of the FHR signal, the training of the classification model, and the experiment evaluation. Finally, MKNet is proved to be the best algorithm for real-time FHR signal classification.",
      "authors": "Tang Haijing; Wang Taoyi; Li Mengke; Yang Xu",
      "year": "2018",
      "journal": "Computational and mathematical methods in medicine",
      "doi": "10.1155/2018/8568617",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30627211/",
      "mesh_terms": "Algorithms; Calibration; Cardiotocography; Female; Heart Rate, Fetal; Humans; Neural Networks, Computer; Pregnancy; Signal Processing, Computer-Assisted; Support Vector Machine",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC6305052"
    },
    {
      "pmid": "39176819",
      "title": "Balancing Acts: Tackling Data Imbalance in Machine Learning for Predicting Myocardial Infarction in Type 2 Diabetes.",
      "abstract": "Type 2 Diabetes (T2D) is a prevalent lifelong health condition. It is predicted that over 500 million adults will be diagnosed with T2D by 2040. T2D can develop at any age, and if it progresses, it may cause serious comorbidities. One of the most critical T2D-related comorbidities is Myocardial Infarction (MI), known as heart attack. MI is a life-threatening medical emergency, and it is important to predict it and intervene in a timely manner. The use of Machine Learning (ML) for clinical prediction is gaining pace, but the class imbalance in predictive models is a key challenge for establishing a trustworthy deployment of the technology. This may lead to bias and overfitting in the ML models, and it may cause misleading interpretations of the ML outputs. In our study, we showed how systematic use of Class Imbalance Handling (CIH) techniques may improve the performance of the ML models. We used the Connected Bradford dataset, consisting of over one million real-world health records. Three commonly used CIH techniques, Oversampling, Undersampling, and Class Weighting (CW) have been used for Naive Bayes (NB), Neural Network (NN), Random Forest (RF), Support Vector Machine (SVM), and Ensemble models. We report that CW overperforms among the other techniques with the highest Accuracy and F1 values of 0.9948 and 0.9556, respectively. Applying the most appropriate CIH techniques for the ML models using real-world healthcare data provides promising results for helping to reduce the risk of MI in patients with T2D.",
      "authors": "Ozturk Berk; Lawton Tom; Smith Stephen; Habli Ibrahim",
      "year": "2024",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI240491",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39176819/",
      "mesh_terms": "Diabetes Mellitus, Type 2; Humans; Myocardial Infarction; Machine Learning; Bayes Theorem; Support Vector Machine",
      "keywords": "Type 2 diabetes; class imbalance; dataset; heart attack; machine learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "39251179",
      "title": "Examining the importance of neighborhood natural, and built environment factors in predicting older adults' mental well-being: An XGBoost-SHAP approach.",
      "abstract": "BACKGROUND: Previous studies have shown that urban neighborhood environmental factors significantly influence the health outcomes of urban older adults. However, most cross-sectional studies exploring the health effects of these factors have failed to quantify the relative importance of each factor. METHODS: We use XGBoost machine learning techniques and SHAPley Additive Interpretation (SHAP) to rank the importance of urban neighborhood environmental factors in shaping the mental health of urban older adults. To address self-selection bias in housing choice, we distinguish older adults living in private housing from those living in public as residents in private housing have more freedom to choose where to live. RESULTS: The results show that both natural and built environmental factors in urban neighborhoods are important predictors of mental well-being scores. Five natural environmental factors (blue space, perceived greenery quantity, NDVI, street view greenness, aesthetic quality) and three built environmental factors (physical activity facilities quality, physical activity facilities quantity, neighborhood disorder) had considerable predictive power for mental well-being scores in two groups. Among them, blue space, perceived greenery quantity and street view greenness quantity became less important after controlling for self-selection bias, possibly because of the unequal distribution of quantity and quality, and the performance of neighborhood disorder, aesthetic quality and physical activity facilities quality was more sensitive in public housing. CONCLUSIONS: These results highlight the nuanced and differential effects of neighborhood environmental exposures on mental well-being outcomes, depending on housing preferences. The results of this study can provide support for decision makers in urban planning, landscape design and environmental management in order to improve the mental well-being status of urban older adults.",
      "authors": "Liu Kaijun; Liao Changni",
      "year": "2024",
      "journal": "Environmental research",
      "doi": "10.1016/j.envres.2024.119929",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39251179/",
      "mesh_terms": "Humans; Mental Health; Aged; Built Environment; Female; Male; Residence Characteristics; Neighborhood Characteristics; Aged, 80 and over; Machine Learning; Urban Population; Middle Aged; Cross-Sectional Studies",
      "keywords": "Housing self-selection; Machine learning; Mental well-being; Neighborhood environment; Older adults",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36387928",
      "title": "Advancing an Algorithm for the Identification of Patients with High Data-Continuity in Electronic Health Records.",
      "abstract": "BACKGROUND: Identifying high data-continuity patients in an electronic health record (EHR) system may facilitate selecting cohorts with a lower degree of variable misclassification and promote study validity. We updated a previously developed algorithm for identifying patients with high EHR data-completeness by adding demographic and health utilization factors to improve adaptability to networks serving patients of diverse backgrounds. We also expanded the algorithm to accommodate data in the ICD-10 era. METHODS: We used Medicare claims linked with EHR data to identify individuals aged \u226565 years. EHR-continuity was defined as the proportion of encounters captured in EHR data relative to claims. We compared the model with additional demographic factors and their interaction terms with other predictors with the original algorithm and assessed the performance by area under the ROC curve (AUC) and net reclassification index (NRI). RESULTS: The study cohort consisted of 264,099 subjects. The updated prediction model had an AUC of 0.93 in the validation set. Compared to the previous model, the new model had an NRI of 37.4% (p<0.001) for EHR-continuity classification. Interaction terms between demographic variables and other predictors did not improve the performance. Patients within the top 20% of predicted EHR-continuity had four times less misclassification of key variables compared to the remaining population. CONCLUSION: Adding demographic and healthcare utilization variables significantly improved the model performance. Patients with high predicted EHR-continuity had less misclassification of study variables compared to the remaining population in both ICD-9 and 10 eras.",
      "authors": "Merola David; Schneeweiss Sebastian; Jin Yinzhu; Lii Joyce; Lin Kueiyu Joshua",
      "year": "2022",
      "journal": "Clinical epidemiology",
      "doi": "10.2147/CLEP.S370031",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36387928/",
      "mesh_terms": "",
      "keywords": "comparative effectiveness research; data continuity; electronic medical records; information bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC9653024"
    },
    {
      "pmid": "35312210",
      "title": "Mind the gap: Performance metric evaluation in brain-age prediction.",
      "abstract": "Estimating age based on neuroimaging-derived data has become a popular approach to developing markers for brain integrity and health. While a variety of machine-learning algorithms can provide accurate predictions of age based on brain characteristics, there is significant variation in model accuracy reported across studies. We predicted age in two population-based datasets, and assessed the effects of age range, sample size and age-bias correction on the model performance metrics Pearson's correlation coefficient (r), the coefficient of determination (R2 ), Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). The results showed that these metrics vary considerably depending on cohort age range; r and R2 values are lower when measured in samples with a narrower age range. RMSE and MAE are also lower in samples with a narrower age range due to smaller errors/brain age delta values when predictions are closer to the mean age of the group. Across subsets with different age ranges, performance metrics improve with increasing sample size. Performance metrics further vary depending on prediction variance as well as mean age difference between training and test sets, and age-bias corrected metrics indicate high accuracy-also for models showing poor initial performance. In conclusion, performance metrics used for evaluating age prediction models depend on cohort and study-specific data characteristics, and cannot be directly compared across different studies. Since age-bias corrected metrics generally indicate high accuracy, even for poorly performing models, inspection of uncorrected model results provides important information about underlying model attributes such as prediction variance.",
      "authors": "de Lange Ann-Marie G; Anat\u00fcrk Melis; Rokicki Jaroslav; Han Laura K M; Franke Katja; Alnaes Dag; Ebmeier Klaus P; Draganski Bogdan; Kaufmann Tobias; Westlye Lars T; Hahn Tim; Cole James H",
      "year": "2022",
      "journal": "Human brain mapping",
      "doi": "10.1002/hbm.25837",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35312210/",
      "mesh_terms": "Algorithms; Brain; Cohort Studies; Humans; Machine Learning",
      "keywords": "brain-age prediction; machine learning; neuroimaging; statistics",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9188975"
    },
    {
      "pmid": "40829285",
      "title": "Machine learning pipeline with custom grid search for colorectal Raman spectroscopy data.",
      "abstract": "Colorectal cancer remains a major health burden, and its early detection is crucial for effective treatment. This study investigates the use of a handheld Raman spectrometer in combination with machine learning to classify colorectal tissue samples collected during colonoscopy. A dataset of 330 spectra from 155 participants was preprocessed using a standardized pipeline, and multiple classification models were trained to distinguish between healthy and pathological tissue. Due to the strong class imbalance and limited data size, a custom grid search approach was implemented to optimize both model hyperparameters and preprocessing parameters. Unlike standard GridSearchCV, our method prioritized balanced accuracy on the test set to reduce bias toward the dominant class. Among the tested classifiers, the Decision Tree (DT) and Support Vector Classifier (SVC) achieved the highest balanced accuracy (71.77% for DT and 70.77% for SVC), outperforming models trained using traditional methods. These results demonstrate the potential of Raman spectroscopy as a rapid, non-destructive screening tool and highlight the importance of tailored model selection strategies in biomedical applications. While this study is based on a limited dataset, it serves as a promising step toward more robust classification models and supports the feasibility of this approach for future clinical validation.",
      "authors": "Janstov\u00e1 Daniela; Tome\u0161 Jakub; Vali\u0161 Jan; Synytsya Alla; Kov\u00e1\u010dov\u00e1 Zuzana; Petrt\u00fdl Jarom\u00edr; Setni\u010dka Vladim\u00edr; Mare\u0161 Jan",
      "year": "2026",
      "journal": "Spectrochimica acta. Part A, Molecular and biomolecular spectroscopy",
      "doi": "10.1016/j.saa.2025.126749",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40829285/",
      "mesh_terms": "Spectrum Analysis, Raman; Humans; Machine Learning; Colorectal Neoplasms; Support Vector Machine; Male; Female; Middle Aged; Decision Trees",
      "keywords": "Balanced accuracy; Colorectal cancer; Machine learning; Preprocessing pipeline; Raman spectroscopy; Spectral classification",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39787925",
      "title": "Quantifying the contributions of factors to bioaccessible Cd and Pb in soil using machine learning.",
      "abstract": "The bioaccessibility of cadmium (Cd) and lead (Pb) in the gastrointestinal tract is crucial for health risk assessments of contaminated soils. However, variability in In vitro analytical conditions and soil properties introduces bias and uncertainty in predictions. This study employed three in vitro methods to measure Cd and Pb bioaccessibility during the gastric and gastrointestinal phases, using soil samples incubated for one year. Twelve machine learning models were tested, with Random Forest chosen for its superior performance, achieving R\u00b2 values between 0.74 and 0.82 in the test set. Key experimental conditions, including Cl\u207b concentration and extraction pH, were identified among the top five factors influencing bioaccessibility. Despite identical incubation conditions, bioaccessible Cd and Pb varied significantly, sometimes by several orders of magnitude, across soil types. Soil properties such as fine particle percentage (<1 \u03bcm) and pH were crucial, while MnO\u2082 content had a greater effect on Pb due to its geochemical behavior. Incorporating aging time into the model improved predictions, explaining 3.6-7.5\u202f% of the variation, with the potential for a greater influence over longer contact times. This study emphasizes the importance of experimental conditions and soil-specific factors in accurately predicting heavy metal bioaccessibility in contaminated soils.",
      "authors": "Mao Lingchen; Kang Kai; Kong Hui; Zhu Ensheng; Zhang Zheng; Li Ying; Tao Hong",
      "year": "2025",
      "journal": "Journal of hazardous materials",
      "doi": "10.1016/j.jhazmat.2025.137102",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39787925/",
      "mesh_terms": "Lead; Soil Pollutants; Cadmium; Machine Learning; Soil; Hydrogen-Ion Concentration; Biological Availability",
      "keywords": "Aging time; In vitro simulation; Machine Learning; Random Forest; Soil properties",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39697049",
      "title": "A psychologically interpretable artificial intelligence framework for the screening of loneliness, depression, and anxiety.",
      "abstract": "Negative emotions such as loneliness, depression, and anxiety (LDA) are prevalent and pose significant challenges to emotional well-being. Traditional methods of assessing LDA, reliant on questionnaires, often face limitations because of participants' inability or potential bias. This study introduces emoLDAnet, an artificial intelligence (AI)-driven psychological framework that leverages video-recorded conversations to detect negative emotions through the analysis of facial expressions and physiological signals. We recruited 50 participants to undergo questionnaires and interviews, with their responses recorded on video. The emoLDAnet employs a combination of deep learning (e.g., VGG11) and machine learning (e.g., decision trees [DTs]) to identify emotional states. The emoLDAnet incorporates the OCC-PAD-LDA psychological transformation model, enhancing the interpretability of AI decisions by translating facial expressions into psychologically meaningful data. Results indicate that emoLDAnet achieves high detection rates for loneliness, depression, and anxiety, with F1-scores exceeding 80% and Kendall's correlation coefficients above 0.5, demonstrating strong agreement with traditional scales. The study underscores the importance of the OCC-PAD-LDA model in improving screening accuracy and the significant impact of machine learning classifiers on the framework's performance. The emoLDAnet has the potential to support large-scale emotional well-being early screening and contribute to the advancement of mental health care.",
      "authors": "Liu Feng; Wang Peiwan; Hu Jingyi; Shen Siyuan; Wang Hanyang; Shi Chen; Peng Yujia; Zhou Aimin",
      "year": "2025",
      "journal": "Applied psychology. Health and well-being",
      "doi": "10.1111/aphw.12639",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39697049/",
      "mesh_terms": "Humans; Loneliness; Depression; Adult; Female; Male; Artificial Intelligence; Anxiety; Facial Expression; Middle Aged; Young Adult; Machine Learning; Deep Learning; Aged",
      "keywords": "anxiety; depression; emotional well\u2010being; loneliness; machine learning; psychological AI identification framework",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "39741942",
      "title": "Policy brief: Improving national vaccination decision-making through data.",
      "abstract": "Life course immunisation looks at the broad value of vaccination across multiple generations, calling for more data power, collaboration, and multi-disciplinary work. Rapid strides in artificial intelligence, such as machine learning and natural language processing, can enhance data analysis, conceptual modelling, and real-time surveillance. The GRADE process is a valuable tool in informing public health decisions. It must be enhanced by real-world data which can span and capture immediate needs in diverse populations and vaccination administration scenarios. Analysis of data from multiple study designs is required to understand the nuances of health behaviors and interventions, address gaps, and mitigate the risk of bias or confounding presented by any single data collection methodology. Secure and responsible health data sharing across European countries can contribute to a deeper understanding of vaccines.",
      "authors": "Evans Sandra; Schmitt Joe; Kalra Dipak; Sokol Tomislav; Holt Daphne",
      "year": "2024",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2024.1407841",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39741942/",
      "mesh_terms": "Humans; Decision Making; Vaccination; Health Policy; Europe; Public Health",
      "keywords": "AI technologies; National Immunisation Programs; National Immunisation Technical Advisory Groups; big data analysis; life course immunisation; vaccine policy; vaccine-preventable diseases",
      "pub_types": "Journal Article",
      "pmcid": "PMC11685149"
    },
    {
      "pmid": "40039422",
      "title": "mSTEP: An Automated Algorithm for Blood Pressure Measurement from Korotkoff Sounds.",
      "abstract": "Accurate blood pressure measurement is crucial for effective health monitoring, with oscillometric and auscultation methods being commonly employed. However, oscillometric measurements are population-dependent, and manual auscultation relies heavily on operator skill. This study introduces the modulated Short-Time Energy and finding the peaks (mSTEP) algorithm, designed to automate the tracking of systolic blood pressure (SBP) and diastolic blood pressure (DBP) from auscultatory signals, aiming to provide accurate BP measurements. The mSTEP algorithm was rigorously evaluated on a dataset comprising 350 recordings with manually annotated SBP and DBP for ground truth value. Implementation of the algorithm yielded successful identification of both SBP and DBP, with errors of -1.5 \u00b1 6.6 mmHg and 3.8 \u00b1 7.6 mmHg, respectively, with insignificant bias (p<0.0001). The agreement between mSTEP algorithm results and the reference measurement was strong and statistically significant, exhibiting correlation coefficients (r) of 0.94 (p<0.0001) for SBP and 0.79 (p<0.0001) for DBP. Bland-Altman plots further supported strong agreement, with confidence intervals of -14.5 mmHg to 11.4 mmHg for SBP and - 11.1 mmHg to 18.6 mmHg for DBP. According to the performance assessment, the algorithm received an 'A' grade in the BHS grading system and successfully met the accuracy requirements prescribed by AAMI/ANSI and ISO. The proposed algorithm potentially leads to the development of automated devices for accurate blood pressure measurements without depending on population or individual-level calibration coefficients.",
      "authors": "Krishna Arjun R; V Raj Kiran; Nabeel P M; Joseph Jayaraj",
      "year": "2024",
      "journal": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference",
      "doi": "10.1109/EMBC53108.2024.10781900",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40039422/",
      "mesh_terms": "Algorithms; Humans; Blood Pressure Determination; Blood Pressure; Auscultation; Signal Processing, Computer-Assisted; Male; Female",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38218231",
      "title": "Artificial Intelligence and Machine Learning May Resolve Health Care Information Overload.",
      "abstract": "Biomedical information doubles almost every 2 months, and this very rate is expected to double by 2025. The result is information overload for clinicians and researchers. Today, artificial intelligence (AI) and machine learning (ML) research contribute to the deluge of information. In addition, AI large language models, although capable of automating scientific writing, are flawed. They hallucinate (make things up), are trained primarily on non-peer-reviewed content, raise ethical and legal issues, and lack human empathy. Still, when it comes to AI including ML, we are optimistic. The technology is improving rapidly. In the future, AI will help us manage unwieldy information by processing data, determining diagnoses, recommending treatments, and predicting outcomes. In research, AI and ML similarly promise efficient data analysis and literature review and will create new content in response to our instructions. Human touch will be required, and we will disclose use of AI proactively, including rationale for its use, our data input, our level of confidence in the output, and the patients or populations to whom the output may be applied. In addition, we will ensure data quality is high and bias is minimized. Most of all, we will provide essential reasoning, clinical and research guidance, and diligent oversight. Humans will remain accountable.",
      "authors": "Siegel Mark G; Rossi Michael J; Lubowitz James H",
      "year": "2024",
      "journal": "Arthroscopy : the journal of arthroscopic & related surgery : official publication of the Arthroscopy Association of North America and the International Arthroscopy Association",
      "doi": "10.1016/j.arthro.2024.01.007",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38218231/",
      "mesh_terms": "Humans; Artificial Intelligence; Machine Learning; Review Literature as Topic",
      "keywords": "",
      "pub_types": "Editorial",
      "pmcid": ""
    },
    {
      "pmid": "36844967",
      "title": "Understanding Covid-19 Mobility Through Human Capital: A Unified Causal Framework.",
      "abstract": "This paper seeks to identify the causal impact of educational human capital on social distancing behavior at workplace in Turkey using district-level data for the period of April 2020 - February 2021. We adopt a unified causal framework, predicated on domain knowledge, theory-justified constraints anda data-driven causal structure discovery using causal graphs. We answer our causal query by employing machine learning prediction algorithms; instrumental variables in the presence of latent confounding and Heckman's model in the presence of selection bias. Results show that educated regions are able to distance-work and educational human capital is a key factor in reducing workplace mobility, possibly through its impact on employment. This pattern leads to higher workplace mobility for less educated regions and translates into higher Covid-19 infection rates. The future of the pandemic lies in less educated segments of developing countries and calls for public health action to decrease its unequal and pervasive impact.",
      "authors": "Bilgel F\u0131rat; Karahasan Burhan Can",
      "year": "2023",
      "journal": "Computational economics",
      "doi": "10.1007/s10614-023-10359-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36844967/",
      "mesh_terms": "",
      "keywords": "Causal structure discovery; Do-calculus; Instrumental variables; Machine learning; Sample selection; Workplace mobility",
      "pub_types": "Journal Article",
      "pmcid": "PMC9942069"
    },
    {
      "pmid": "32035304",
      "title": "Missing data imputation via the expectation-maximization algorithm can improve principal component analysis aimed at deriving biomarker profiles and dietary patterns.",
      "abstract": "Principal component analysis (PCA) is a popular statistical tool. However, despite numerous advantages, the good practice of imputing missing data before PCA is not common. In the present work, we evaluated the hypothesis that the expectation-maximization (EM) algorithm for missing data imputation is a reliable and advantageous procedure when using PCA to derive biomarker profiles and dietary patterns. To this aim, we used numerical simulations aimed to mimic real data commonly observed in nutritional research. Finally, we showed the advantages and pitfalls of the EM algorithm for missing data imputation applied to plasma fatty acid concentrations and nutrient intakes from real data sets deriving from the US National Health and Nutrition Examination Survey. PCA applied to simulated data having missing values resulted in biased eigenvalues with respect to the original data set without missing values. The bias between the eigenvalues from the original set of data and from the data set with missing values increased with number of missing values and appeared as independent with respect to the correlation structure among variables. On the other hand, when data were imputed, the mean of the eigenvalues over the 10 missing imputation runs overlapped with the ones derived from the PCA applied to the original data set. These results were confirmed when real data sets from the National Health and Nutrition Examination Survey were analyzed. We accept the hypothesis that the EM algorithm for missing data imputation applied before PCA aimed to derive biochemical profiles and dietary patterns is an effective technique especially for relatively small sample sizes.",
      "authors": "Malan Linda; Smuts Cornelius M; Baumgartner Jeannine; Ricci Cristian",
      "year": "2020",
      "journal": "Nutrition research (New York, N.Y.)",
      "doi": "10.1016/j.nutres.2020.01.001",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32035304/",
      "mesh_terms": "Algorithms; Biomarkers; Data Collection; Diet; Fatty Acids; Humans; Nutrients; Nutrition Surveys; Principal Component Analysis; United States",
      "keywords": "Biochemical profiles; Dietary patterns; EM algorithm; Missing data imputation; Principal component analysis",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35878784",
      "title": "An algorithm to predict data completeness in oncology electronic medical records for comparative effectiveness research.",
      "abstract": "INTRODUCTION: Electronic health record (EHR) discontinuity (missing out-of-network encounters) can lead to information bias. We sought to construct an algorithm that identifies high EHR-continuity among oncology patients. METHODS: Using a linked Medicare-EHR database and regression, we sought to 1) measure how often Medicare claims for outpatient encounters were substantiated by visits recorded in the EHR, and 2) predict continuity ratio, defined as the yearly proportion of outpatient encounters reported to Medicare that were captured by EHR data. The prediction model...s performance was evaluated with the coefficient of determination and Spearman...s correlation. We quantified variable misclassification by decile of continuity ratio using standardized difference and sensitivity. RESULTS: A total of 79,678 subjects met all eligibility criteria. Predicted and observed continuity was highly correlated (\u03c3Spearman=0.86). On average across all variables measured, MSD was reduced by a factor of 1/7th and sensitivity was improved 35-fold comparing subjects in the highest vs. lowest decile of CR. CONCLUSION: In the oncology population, restricting EHR-based study cohorts to subjects with high continuity may reduce misclassification without greatly impacting representativeness. Further work is needed to elucidate the best manner of implementing continuity prediction rules in cohort studies.",
      "authors": "Merola David; Schneeweiss Sebastian; Schrag Deborah; Lii Joyce; Lin Kueiyu Joshua",
      "year": "2022",
      "journal": "Annals of epidemiology",
      "doi": "10.1016/j.annepidem.2022.07.007",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35878784/",
      "mesh_terms": "Aged; Humans; United States; Electronic Health Records; Comparative Effectiveness Research; Medicare; Algorithms; Medical Oncology; Neoplasms",
      "keywords": "Comparative effectiveness research; Continuity; Electronic medical records; Information bias",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9741728"
    },
    {
      "pmid": "34662699",
      "title": "Automatic quantification of white matter hyperintensities on T2-weighted fluid attenuated inversion recovery magnetic resonance imaging.",
      "abstract": "White matter hyperintensities (WMH) are areas of increased signal visualized on T2-weighted fluid attenuated inversion recovery (FLAIR) brain magnetic resonance imaging (MRI) sequences. They are typically attributed to small vessel cerebrovascular disease in the context of aging. Among older adults, WMH are associated with risk of cognitive decline and dementia, stroke, and various other health outcomes. There has been increasing interest in incorporating quantitative WMH measurement as outcomes in clinical trials, observational research, and clinical settings. Here, we present a novel, fully automated, unsupervised detection algorithm for WMH segmentation and quantification. The algorithm uses a robust preprocessing pipeline, including brain extraction and a sample-specific mask that incorporates spatial information for automatic false positive reduction, and a half Gaussian mixture model (HGMM). The method was evaluated in 24 participants with varying degrees of WMH (4.9-78.6\u00a0cm3) from a community-based study of aging and dementia with dice coefficient, sensitivity, specificity, correlation, and bias relative to the ground truth manual segmentation approach performed by two expert raters. Results were compared with those derived from commonly used available WMH segmentation packages, including SPM lesion probability algorithm (LPA), SPM lesion growing algorithm (LGA), and Brain Intensity AbNormality Classification Algorithm (BIANCA). The HGMM algorithm derived WMH values that had a dice score of 0.87, sensitivity of 0.89, and specificity of 0.99 compared to ground truth. White matter hyperintensity volumes derived with HGMM were strongly correlated with ground truth values (r\u00a0=\u00a00.97, p\u00a0=\u00a03.9e-16), with no observable bias (-1.1 [-2.6, 0.44], p-value\u00a0=\u00a00.16). Our novel algorithm uniquely uses a robust preprocessing pipeline and a half-Gaussian mixture model to segment WMH with high agreement with ground truth for large scale studies of brain aging.",
      "authors": "Igwe Kay C; Lao Patrick J; Vorburger Robert S; Banerjee Arit; Rivera Andres; Chesebro Anthony; Laing Krystal; Manly Jennifer J; Brickman Adam M",
      "year": "2022",
      "journal": "Magnetic resonance imaging",
      "doi": "10.1016/j.mri.2021.10.007",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34662699/",
      "mesh_terms": "Aged; Brain; Humans; Leukoaraiosis; Magnetic Resonance Imaging; Stroke; White Matter",
      "keywords": "Automated segmentation; Half Gaussian mixture model; Mixture model; Small vessel cerebrovascular disease; White matter hyperintensity",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC8818099"
    },
    {
      "pmid": "38536234",
      "title": "Target Product Profile for a Machine Learning-Automated Retinal Imaging Analysis Software for Use in English Diabetic Eye Screening: Protocol for a Mixed Methods Study.",
      "abstract": "BACKGROUND: Diabetic eye screening (DES) represents a significant opportunity for the application of machine learning (ML) technologies, which may improve clinical and service outcomes. However, successful integration of ML into DES requires careful product development, evaluation, and implementation. Target product profiles (TPPs) summarize the requirements necessary for successful implementation so these can guide product development and evaluation. OBJECTIVE: This study aims to produce a TPP for an ML-automated retinal imaging analysis software (ML-ARIAS) system for use in DES in England. METHODS: This work will consist of 3 phases. Phase 1 will establish the characteristics to be addressed in the TPP. A list of candidate characteristics will be generated from the following sources: an overview of systematic reviews of diagnostic test TPPs; a systematic review of digital health TPPs; and the National Institute for Health and Care Excellence's Evidence Standards Framework for Digital Health Technologies. The list of characteristics will be refined and validated by a study advisory group (SAG) made up of representatives from key stakeholders in DES. This includes people with diabetes; health care professionals; health care managers and leaders; and regulators and policy makers. In phase 2, specifications for these characteristics will be drafted following a series of semistructured interviews with participants from these stakeholder groups. Data collected from these interviews will be analyzed using the shortlist of characteristics as a framework, after which specifications will be drafted to create a draft TPP. Following approval by the SAG, in phase 3, the draft will enter an internet-based Delphi consensus study with participants sought from the groups previously identified, as well as ML-ARIAS developers, to ensure feasibility. Participants will be invited to score characteristic and specification pairs on a scale from \"definitely exclude\" to \"definitely include,\" and suggest edits. The document will be iterated between rounds based on participants' feedback. Feedback on the draft document will be sought from a group of ML-ARIAS developers before its final contents are agreed upon in an in-person consensus meeting. At this meeting, representatives from the stakeholder groups previously identified (minus ML-ARIAS developers, to avoid bias) will be presented with the Delphi results and feedback of the user group and asked to agree on the final contents by vote. RESULTS: Phase 1 was completed in November 2023. Phase 2 is underway and expected to finish in March 2024. Phase 3 is expected to be complete in July 2024. CONCLUSIONS: The multistakeholder development of a TPP for an ML-ARIAS for use in DES in England will help developers produce tools that serve the needs of patients, health care providers, and their staff. The TPP development process will also provide methods and a template to produce similar documents in other disease areas. INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): DERR1-10.2196/50568.",
      "authors": "Macdonald Trystan; Dinnes Jacqueline; Maniatopoulos Gregory; Taylor-Phillips Sian; Shinkins Bethany; Hogg Jeffry; Dunbar John Kevin; Solebo Ameenat Lola; Sutton Hannah; Attwood John; Pogose Michael; Given-Wilson Rosalind; Greaves Felix; Macrae Carl; Pearson Russell; Bamford Daniel; Tufail Adnan; Liu Xiaoxuan; Denniston Alastair K",
      "year": "2024",
      "journal": "JMIR research protocols",
      "doi": "10.2196/50568",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38536234/",
      "mesh_terms": "",
      "keywords": "DM; England; artificial intelligence; design; developers; diabetes mellitus; diabetic; diabetic eye screening; diabetic retinopathy; eye screening; imaging analysis software; implementation; machine learning; retinal imaging; study protocol; target product profile",
      "pub_types": "Journal Article",
      "pmcid": "PMC11007610"
    },
    {
      "pmid": "41492323",
      "title": "mModPoEs: Multimodal posture estimation and feedback-driven correction of load-bearing human movements using wearable sensors and computer vision.",
      "abstract": "OBJECTIVE: Improper spinal posture during activities of daily living such as seated posture, upright stance, and ambulation, particularly under load-bearing conditions, has been recognized as a major contributor to musculoskeletal disorders, including chronic back pain and disc degeneration. This study presents a multimodal posture estimation and feedback framework that integrates wearable-sensor data and computer-vision analysis to support spinal health. METHODS: The system integrates data from Inertial Measurement Units (IMUs) and flex sensors to quantify postural angles which acts as sensor data, while concurrently extracting key visual features from multi-view (frontal and lateral) video recordings and photographs using the MediaPipe framework. A control group was formed under the guidance of physiotherapist and the data was collected at Tagore College of Physiotherapy located in Chennai, India. This control group comprises of 40 subjects, selected without gender bias, aged between 19 and 22 years. The analysis on multimodal data incorporated specifically, logistic regression (LR), decision tree (DT), random forest (RF), KNN and SVM. RESULTS: Among all evaluated models, the RF algorithm, showed effective performance and balance in all activities of both male and female subjects. The dataset used was a composite collection of both genders, resulting in accuracy rates of 75\u00a0%, 95\u00a0% and 63\u00a0% for sitting, standing, and walking, respectively. CONCLUSION: The findings highlight that integrating wearable and visual modalities enhances posture classification accuracy. While the findings are preliminary, they establish a methodological foundation for future development of multimodal, feedback-based posture assessment systems.",
      "authors": "Gokul Thilaak P; Malathi G; Thiagarajan D",
      "year": "2026",
      "journal": "Journal of orthopaedics",
      "doi": "10.1016/j.jor.2025.12.024",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41492323/",
      "mesh_terms": "",
      "keywords": "Computer vision; Flex sensors; Inertial measurement unit (IMU); Machine learning; MediaPipe; Posture correction; Posture estimation",
      "pub_types": "Journal Article",
      "pmcid": "PMC12765337"
    },
    {
      "pmid": "37440303",
      "title": "Implementing a Machine Learning Screening Tool for Malnutrition: Insights From Qualitative Research Applicable to Other Machine Learning-Based Clinical Decision Support Systems.",
      "abstract": "BACKGROUND: Machine learning (ML)-based clinical decision support systems (CDSS) are popular in clinical practice settings but are often criticized for being limited in usability, interpretability, and effectiveness. Evaluating the implementation of ML-based CDSS is critical to ensure CDSS is acceptable and useful to clinicians and helps them deliver high-quality health care. Malnutrition is a common and underdiagnosed condition among hospital patients, which can have serious adverse impacts. Early identification and treatment of malnutrition are important. OBJECTIVE: This study aims to evaluate the implementation of an ML tool, Malnutrition Universal Screening Tool (MUST)-Plus, that predicts hospital patients at high risk for malnutrition and identify best implementation practices applicable to this and other ML-based CDSS. METHODS: We conducted a qualitative postimplementation evaluation using in-depth interviews with registered dietitians (RDs) who use MUST-Plus output in their everyday work. After coding the data, we mapped emergent themes onto select domains of the nonadoption, abandonment, scale-up, spread, and sustainability (NASSS) framework. RESULTS: We interviewed 17 of the 24 RDs approached (71%), representing 37% of those who use MUST-Plus output. Several themes emerged: (1) enhancements to the tool were made to improve accuracy and usability; (2) MUST-Plus helped identify patients that would not otherwise be seen; perceived usefulness was highest in the original site; (3) perceived accuracy varied by respondent and site; (4) RDs valued autonomy in prioritizing patients; (5) depth of tool understanding varied by hospital and level; (6) MUST-Plus was integrated into workflows and electronic health records; and (7) RDs expressed a desire to eventually have 1 automated screener. CONCLUSIONS: Our findings suggest that continuous involvement of stakeholders at new sites given staff turnover is vital to ensure buy-in. Qualitative research can help identify the potential bias of ML tools and should be widely used to ensure health equity. Ongoing collaboration among CDSS developers, data scientists, and clinical providers may help refine CDSS for optimal use and improve the acceptability of CDSS in the clinical context.",
      "authors": "Besculides Melanie; Mazumdar Madhu; Phlegar Sydney; Freeman Robert; Wilson Sara; Joshi Himanshu; Kia Arash; Gorbenko Ksenia",
      "year": "2023",
      "journal": "JMIR formative research",
      "doi": "10.2196/42262",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37440303/",
      "mesh_terms": "",
      "keywords": "AI; CDSS; acceptability; clinical; data; decision-making; effectiveness; evaluation; machine learning; malnutrition; nutrition; screening; tool; treatment; usability",
      "pub_types": "Journal Article",
      "pmcid": "PMC10375393"
    },
    {
      "pmid": "40433911",
      "title": "Pesticide Residue Detection Using Grating Spectroscope and GWO-CNN-BiLSTM Method.",
      "abstract": "Pesticide residues represent a globally significant issue due to their high toxicity and broad dissemination. Thiamethoxam (TMX), commonly applied during the cultivation of vegetables like spinach, has its principal metabolite, clothianidin, which can accumulate in crops, posing significant long-term dietary risks. To accurately detect TMX residues in spinach, this study developed a portable detection device integrating a grating spectrometer (GS) with a smartphone and introduced image processing techniques alongside deep learning detection methods. This method employs a ResNet50 model enhanced by Squeeze-and-Excitation Networks (SE) attention mechanism to extract key features, which are subsequently input into a hybrid model combining a convolutional neural network (CNN) and a bidirectional long short-term memory (BiLSTM) network, optimized using the gray wolf optimization (GWO) algorithm. The results demonstrate that the method achieves a root mean square error (RMSE) of approximately 0.220, a mean absolute error (MAE) of about 0.060, a mean bias error (MBE) of about 0.002, and a coefficient of determination (R2) of approximately 0.960. The R2 increased by 0.049 compared to pre-optimization values and by 0.060 relative to the top traditional machine learning models, thereby enhancing the precision of detection. This technology promises to be a vital tool in the field of pesticide residue detection, offering robust support for ensuring food safety and public health.",
      "authors": "Zhao Yanshen; Fu Huayu; Zhou Hongcai; Zhu Hongfei; Zhao Yifan; Wang Cong; Zhang Runzhe; Han Zhongzhi",
      "year": "2025",
      "journal": "Journal of food science",
      "doi": "10.1111/1750-3841.70282",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40433911/",
      "mesh_terms": "Pesticide Residues; Food Contamination; Neural Networks, Computer; Thiamethoxam; Spinacia oleracea; Neonicotinoids; Spectrum Analysis; Algorithms; Smartphone; Guanidines; Thiazoles",
      "keywords": "attention mechanism; deep learning; grating spectrometer; pesticide residues",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37427675",
      "title": "The implication of oversampling on the effectiveness of force signals in the fault detection of endodontic instruments during RCT.",
      "abstract": "This work provides an innovative endodontic instrument fault detection methodology during root canal treatment (RCT). Sometimes, an endodontic instrument is prone to fracture from the tip, for causes uncertain the dentist's control. A comprehensive assessment and decision support system for an endodontist may avoid several breakages. This research proposes a machine learning and artificial intelligence-based approach that can help to diagnose instrument health. During the RCT, force signals are recorded using a dynamometer. From the acquired signals, statistical features are extracted. Because there are fewer instances of the minority class (i.e. faulty/moderate class), oversampling of datasets is required to avoid bias and overfitting. Therefore, the synthetic minority oversampling technique (SMOTE) is employed to increase the minority class. Further, evaluating the performance using the machine learning techniques, namely Gaussian Na\u00efve Bayes (GNB), quadratic support vector machine (QSVM), fine k-nearest neighbor (FKNN), and ensemble bagged tree (EBT). The EBT model provides excellent performance relative to the GNB, QSVM, and FKNN. Machine learning (ML) algorithms can accurately detect endodontic instruments' faults by monitoring the force signals. The EBT and FKNN classifier is trained exceptionally well with an area under curve values of 1.0 and 0.99 and prediction accuracy of 98.95 and 97.56%, respectively. ML can potentially enhance clinical outcomes, boost learning, decrease process malfunctions, increase treatment efficacy, and enhance instrument performance, contributing to superior RCT processes. This work uses ML methodologies for fault detection of endodontic instruments, providing practitioners with an adequate decision support system.",
      "authors": "Thakur Vinod Singh; Kankar Pavan Kumar; Parey Anand; Jain Arpit; Jain Prashant Kumar",
      "year": "2023",
      "journal": "Proceedings of the Institution of Mechanical Engineers. Part H, Journal of engineering in medicine",
      "doi": "10.1177/09544119231186074",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37427675/",
      "mesh_terms": "Algorithms; Artificial Intelligence; Machine Learning; Treatment Outcome; Root Canal Therapy; Equipment Failure Analysis",
      "keywords": "Root canal treatment; endodontics; fault detection; machine learning; synthetic minority oversampling technique",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33750311",
      "title": "Waist circumference prediction for epidemiological research using gradient boosted trees.",
      "abstract": "BACKGROUND: Waist circumference is becoming recognized as a useful predictor of health risks in clinical research. However, clinical datasets tend to lack this measurement and self-reported values tend to be inaccurate. Predicting waist circumference from standard physical features could be a viable method for generating this information when it is missing or mitigating the impact of inaccurate self-reports. This study determined the degree to which the XGBoost advanced machine learning algorithm could build models that predict waist circumference from height, weight, calculated Body Mass Index, age, race/ethnicity and sex, whether they perform better than current models based on linear regression, and the relative importance of each feature in this prediction. METHODS: We trained tree-based models (via XGBoost gradient boosting) and linear models (via regression) to predict waist circumference from height, weight, Body Mass Index, age, race/ethnicity and sex (n\u2009=\u200960,740 participants). We created 10 iterations of each model, each using 90% of the dataset for training and the remaining 10% for testing performance (this group was different for each iteration). We calculated model performance and feature importance as an average across 10 iterations. We then externally validated the ensembled version of the top model. RESULTS: The XGBoost model predicted waist circumference with a mean bias \u00b1 standard deviation of 0.0\u2009\u00b1\u20090.04\u2009cm and a root mean squared error of 4.7\u2009\u00b1\u20090.05\u2009cm, with performance varying slightly by sex and race/ethnicity. The XGBoost model showed varying degrees of improvement over linear regression models. The top 3 predictors were Body Mass Index, weight and race (Asian). External validation found that on average this model overestimated waist circumference by 4.65\u2009cm in the United Kingdom population (mainly due to overprediction in females) and underestimated waist circumference by 1.7\u2009cm in the Chinese population. The respective root mean squared errors were 7.7\u2009cm and 7.1\u2009cm. CONCLUSIONS: XGBoost-based models accurately predict waist circumference from standard physical features. Waist circumference prediction using this approach would be valuable for epidemiological research and beyond.",
      "authors": "Zhou Weihong; Eckler Spencer; Barszczyk Andrew; Waese-Perlman Alex; Wang Yingjie; Gu Xiaoping; Feng Zhong-Ping; Peng Yuzhu; Lee Kang",
      "year": "2021",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/s12874-021-01242-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33750311/",
      "mesh_terms": "Bias; Body Mass Index; Female; Humans; Self Report; United Kingdom; Waist Circumference",
      "keywords": "Gradient boosted trees; Machine learning; Multilayer perceptron; Waist circumference",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7944598"
    },
    {
      "pmid": "37131277",
      "title": "Building Machine Learning Models to Correct Self-Reported Anthropometric Measures.",
      "abstract": "Monitoring population obesity risk primarily depends on self-reported anthropometric data prone to recall error and bias. This study developed machine learning (ML) models to correct self-reported height and weight and estimate obesity prevalence in US adults. Individual-level data from 50 274 adults were retrieved from the National Health and Nutrition Examination Survey (NHANES) 1999-2020 waves. Large, statistically significant differences between self-reported and objectively measured anthropometric data were present. Using their self-reported counterparts, we applied 9 ML models to predict objectively measured height, weight, and body mass index. Model performances were assessed using root-mean-square error. Adopting the best performing models reduced the discrepancy between self-reported and objectively measured sample average height by 22.08%, weight by 2.02%, body mass index by 11.14%, and obesity prevalence by 99.52%. The difference between predicted (36.05%) and objectively measured obesity prevalence (36.03%) was statistically nonsignificant. The models may be used to reliably estimate obesity prevalence in US adults using data from population health surveys.",
      "authors": "An Ruopeng; Ji Mengmeng",
      "year": "2023",
      "journal": "Journal of public health management and practice : JPHMP",
      "doi": "10.1097/PHH.0000000000001769",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37131277/",
      "mesh_terms": "Adult; Humans; Body Weight; Nutrition Surveys; Self Report; Body Height; Obesity; Body Mass Index; Prevalence",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35214310",
      "title": "Intelligent Clinical Decision Support.",
      "abstract": "Early recognition of pathologic cardiorespiratory stress and forecasting cardiorespiratory decompensation in the critically ill is difficult even in highly monitored patients in the Intensive Care Unit (ICU). Instability can be intuitively defined as the overt manifestation of the failure of the host to adequately respond to cardiorespiratory stress. The enormous volume of patient data available in ICU environments, both of high-frequency numeric and waveform data accessible from bedside monitors, plus Electronic Health Record (EHR) data, presents a platform ripe for Artificial Intelligence (AI) approaches for the detection and forecasting of instability, and data-driven intelligent clinical decision support (CDS). Building unbiased, reliable, and usable AI-based systems across health care sites is rapidly becoming a high priority, specifically as these systems relate to diagnostics, forecasting, and bedside clinical decision support. The ICU environment is particularly well-positioned to demonstrate the value of AI in saving lives. The goal is to create AI models embedded in a real-time CDS for forecasting and mitigation of critical instability in ICU patients of sufficient readiness to be deployed at the bedside. Such a system must leverage multi-source patient data, machine learning, systems engineering, and human action expertise, the latter being key to successful CDS implementation in the clinical workflow and evaluation of bias. We present one approach to create an operationally relevant AI-based forecasting CDS system.",
      "authors": "Pinsky Michael R; Dubrawski Artur; Clermont Gilles",
      "year": "2022",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s22041408",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35214310/",
      "mesh_terms": "Artificial Intelligence; Critical Care; Decision Support Systems, Clinical; Humans; Intensive Care Units; Machine Learning",
      "keywords": "database; hemodynamic monitoring; machine learning; predictive analytics",
      "pub_types": "Journal Article",
      "pmcid": "PMC8963066"
    },
    {
      "pmid": "34970633",
      "title": "Evaluation of the ASSIGN open-source deterministic address-matching algorithm for allocating unique property reference numbers to general practitioner-recorded patient addresses.",
      "abstract": "INTRODUCTION: Linking places to people is a core element of the UK government's geospatial strategy. Matching patient addresses in electronic health records to their Unique Property Reference Numbers (UPRNs) enables spatial linkage for research, innovation and public benefit. Available algorithms are not transparent or evaluated for use with addresses recorded by health care providers. OBJECTIVES: To describe and quality assure the open-source deterministic ASSIGN address-matching algorithm applied to general practitioner-recorded patient addresses. METHODS: Best practice standards were used to report the ASSIGN algorithm match rate, sensitivity and positive predictive value using gold-standard datasets from London and Wales. We applied the ASSIGN algorithm to the recorded addresses of a sample of 1,757,018 patients registered with all general practices in north east London. We examined bias in match results for the study population using multivariable analyses to estimate the likelihood of an address-matched UPRN by demographic, registration, and organisational variables. RESULTS: We found a 99.5% and 99.6% match rate with high sensitivity (0.999,0.998) and positive predictive value (0.996,0.998) for the Welsh and London gold standard datasets respectively, and a 98.6% match rate for the study population.The 1.4% of the study population without a UPRN match were more likely to have changed registered address in the last 12 months (match rate: 95.4%), be from a Chinese ethnic background (95.5%), or registered with a general practice using the SystmOne clinical record system (94.4%). Conversely, people registered for more than 6.5 years with their general practitioner were more likely to have a match (99.4%) than those with shorter registration durations. CONCLUSIONS: ASSIGN is a highly accurate open-source address-matching algorithm with a high match rate and minimal biases when evaluated against a large sample of general practice-recorded patient addresses. ASSIGN has potential to be used in other address-based datasets including those with information relevant to the wider determinants of health.",
      "authors": "Harper Gill; Stables David; Simon Paul; Ahmed Zaheer; Smith Kelvin; Robson John; Dezateux Carol",
      "year": "2021",
      "journal": "International journal of population data science",
      "doi": "10.23889/ijpds.v6i1.1674",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34970633/",
      "mesh_terms": "Algorithms; Electronic Health Records; General Practitioners; Humans; Medical Record Linkage; Probability",
      "keywords": "address-matching; addresses; data linkage; electronic health record; place-based health; population health; quality assurance",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8678979"
    },
    {
      "pmid": "38235322",
      "title": "Comparing broad and narrow phenotype algorithms: differences in performance characteristics and immortal time incurred.",
      "abstract": "Introduction: When developing phenotype algorithms for observational research, there is usually a trade-off between definitions that are sensitive or specific. The objective of this study was to estimate the performance characteristics of phenotype algorithms designed for increasing specificity and to estimate the immortal time associated with each algorithm. Materials and methods: We examined algorithms for 11 chronic health conditions. The analyses were from data from five databases. For each health condition, we created five algorithms to examine performance (sensitivity and positive predictive value (PPV)) differences: one broad algorithm using a single code for the health condition and four narrow algorithms where a second diagnosis code was required 1-30\u00a0days, 1-90\u00a0days, 1-365\u00a0days, or 1- all days in a subject's continuous observation period after the first code. We also examined the proportion of immortal time relative to time-at-risk (TAR) for four outcomes. The TAR's were: 0-30\u00a0days after the first condition occurrence (the index date), 0-90\u00a0days post-index, 0-365\u00a0days post-index, and 0-1,095\u00a0days post-index. Performance of algorithms for chronic health conditions was estimated using PheValuator (V2.1.4) from the OHDSI toolstack. Immortal time was calculated as the time from the index date until the first of the following: 1) the outcome; 2) the end of the outcome TAR; 3) the occurrence of the second code for the chronic health condition. Results: In the first analysis, the narrow phenotype algorithms, i.e., those requiring a second condition code, produced higher estimates for PPV and lower estimates for sensitivity compared to the single code algorithm. In all conditions, increasing the time to the required second code increased the sensitivity of the algorithm. In the second analysis, the amount of immortal time increased as the window used to identify the second diagnosis code increased. The proportion of TAR that was immortal was highest in the 30\u00a0days TAR analyses compared to the 1,095\u00a0days TAR analyses. Conclusion: Attempting to increase the specificity of a health condition algorithm by adding a second code is a potentially valid approach to increase specificity, albeit at the cost of incurring immortal time.",
      "authors": "Swerdel Joel N; Conover Mitchell M",
      "year": "2023",
      "journal": "Journal of pharmacy & pharmaceutical sciences : a publication of the Canadian Society for Pharmaceutical Sciences, Societe canadienne des sciences pharmaceutiques",
      "doi": "10.3389/jpps.2023.12095",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38235322/",
      "mesh_terms": "Humans; Predictive Value of Tests; Algorithms; Phenotype; Databases, Factual; Upper Extremity Deformities, Congenital",
      "keywords": "bias; immortal time; observational data; phenotype algorithms; validation",
      "pub_types": "Journal Article",
      "pmcid": "PMC10791821"
    },
    {
      "pmid": "40643081",
      "title": "Transformative potential of artificial intelligence in US CDC HIV interventions: balancing innovation with health privacy.",
      "abstract": "Artificial intelligence (AI) holds significant potential to transform HIV prevention and treatment through the application of advanced technologies such as machine learning (ML), deep learning (DL), and generative AI (Gen AI). These technologies can enhance the monitoring, management, and analysis of vast and complex HIV-related datasets, enabling more timely predictions of potential risks and improving HIV care strategies. AI is poised to streamline HIV prevention interventions by increasing workforce efficiency, supporting expanded accessibility and sustainability of preexposure prophylaxis (PrEP) care in nontraditional settings, and supporting clinical decision-making. Additionally, when utilized within HIV care systems, AI can help close gaps in diagnosis, treatment, and continuous care engagement. However, to optimize AI's potential in HIV prevention, careful implementation is crucial. Challenges such as reducing bias, ensuring ethical standards (including health privacy standards) are maintained, and mitigating risks like AI hallucinations must be addressed. Thoughtful integration, community consultation, and continuous evaluation will be critical to ensuring that AI plays a beneficial role in HIV prevention and drives innovations that lead to more equitable health outcomes. This editorial review explores AI's transformative potential, focusing on the US CDC's key public health strategies for HIV prevention. When aligning with public health strategies - particularly in countries supported by initiatives like President's Emergency Plan for AIDS Relief (PEPFAR) - AI can contribute significantly to global efforts to end the HIV epidemic. It offers a vision for AI's future application in HIV prevention, emphasizing the need for a holistic and syndemic approach to improving HIV prevention worldwide.",
      "authors": "Kamitani Emiko; Koenig Linda J; Sullivan Patrick",
      "year": "2025",
      "journal": "AIDS (London, England)",
      "doi": "10.1097/QAD.0000000000004220",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40643081/",
      "mesh_terms": "Humans; Artificial Intelligence; Centers for Disease Control and Prevention, U.S.; HIV Infections; Pre-Exposure Prophylaxis; United States",
      "keywords": "HIV; artificial intelligence; deep learning; machine learning; public health",
      "pub_types": "Editorial",
      "pmcid": "PMC12409397"
    },
    {
      "pmid": "40423079",
      "title": "Comparative Evaluation of Automatic Detection and Classification of Daily Living Activities Using Batch Learning and Stream Learning Algorithms.",
      "abstract": "Background/Objectives: Activities of Daily Living (ADLs) are crucial for assessing an individual's autonomy, encompassing tasks such as eating, dressing, and moving around, among others. Predicting these activities is part of health monitoring, elderly care, and intelligent systems, improving quality of life, and facilitating early dependency detection, all of which are relevant components of personalized health and social care. However, the automatic classification of ADLs from sensor data remains challenging due to high variability in human behavior, sensor noise, and discrepancies in data acquisition protocols. These challenges limit the accuracy and applicability of existing solutions. This study details the modeling and evaluation of real-time ADL classification models based on batch learning (BL) and stream learning (SL) algorithms. Methods: The methodology followed is the Cross-Industry Standard Process for Data Mining (CRISP-DM). The models were trained with a comprehensive dataset integrating 23 ADL-centric datasets using accelerometers and gyroscopes data. The data were preprocessed by applying normalization and sampling rate unification techniques, and finally, relevant sensor locations on the body were selected. Results: After cleaning and debugging, a final dataset was generated, containing 238,990 samples, 56 activities, and 52 columns. The study compared models trained with BL and SL algorithms, evaluating their performance under various classification scenarios using accuracy, area under the curve (AUC), and F1-score metrics. Finally, a mobile application was developed to classify ADLs in real time (feeding data from a dataset). Conclusions: The outcome of this study can be used in various data science projects related to ADL and Human activity recognition (HAR), and due to the integration of diverse data sources, it is potentially useful to address bias and improve generalizability in Machine Learning models. The principal advantage of online learning algorithms is dynamically adapting to data changes, representing a significant advance in personal autonomy and health care monitoring.",
      "authors": "Mu\u00f1oz Paula Sof\u00eda; Orozco Ana Sof\u00eda; Pab\u00f3n Jaime; G\u00f3mez Daniel; Salazar-Cabrera Ricardo; Cer\u00f3n Jes\u00fas D; L\u00f3pez Diego M; Blobel Bernd",
      "year": "2025",
      "journal": "Journal of personalized medicine",
      "doi": "10.3390/jpm15050208",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40423079/",
      "mesh_terms": "",
      "keywords": "ADL; HAR; activities of daily living; algorithm comparison; batch learning; human activity recognition; stream learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC12113474"
    },
    {
      "pmid": "35248628",
      "title": "A data-augmentation approach to deriving long-term surface SO2 across Northern China: Implications for interpretable machine learning.",
      "abstract": "Until recently, Northern China was one of the most SO2 polluted regions in the world. The lack of long-term and spatially resolved surface SO2 data hinders retrospective evaluation of relevant environmental policies and human health effects. This study aims to derive the spatiotemporal distribution of surface SO2 across Northern China during 2005-2019. As \"concept drift\" causes substantial estimation bias in back-extrapolation, we propose a new approach named the robust back-extrapolation via data augmentation approach (RBE-DA) to model the long-term surface SO2. The results show that the population-weighted regional SO2 ([SO2]pw) increased from 2005 to 2007 and decreased steadily afterwards. The [SO2]pw decreased by 80.4% from 74.2 \u00b1 28.4 \u03bcg/m3 in 2007 to 14.6 \u00b1 4.8 \u03bcg/m3 in 2019. The predicted spatial distributions for each year show that the SO2 pollution was severe (more than 20 \u03bcg/m3) in most areas of Northern China until 2017. By using model interpretation methods, we visually reveal the mechanism of estimation bias in the back-extrapolation. Specifically, the training data is severely imbalanced with respect to the satellite-retrieved SO2 column densities (i.e., it is short on high-value samples), so the benchmark model is unable to extrapolate the effects of this important predictor. This study provides long-term surface SO2 data for post hoc evaluation and human exposure assessment in Northern China, while demonstrating that the interpretable machine learning approach is critical for model diagnostics and refinement. Leveraging satellite retrievals, the RBE-DA approach can be applied worldwide to back-extrapolate various measures of air quality.",
      "authors": "Zhang Shifu; Mi Tan; Wu Qinhuizi; Luo Yuzhou; Grieneisen Michael L; Shi Guangming; Yang Fumo; Zhan Yu",
      "year": "2022",
      "journal": "The Science of the total environment",
      "doi": "10.1016/j.scitotenv.2022.154278",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35248628/",
      "mesh_terms": "Air Pollutants; Air Pollution; China; Environmental Monitoring; Humans; Machine Learning; Particulate Matter; Retrospective Studies",
      "keywords": "Back-extrapolation; Data augmentation; Imbalanced data; Machine learning; Northern China; SO(2) pollution",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36554017",
      "title": "Economics of Artificial Intelligence in Healthcare: Diagnosis vs. Treatment.",
      "abstract": "Motivation: The price of medical treatment continues to rise due to (i) an increasing population; (ii) an aging human growth; (iii) disease prevalence; (iv) a rise in the frequency of patients that utilize health care services; and (v) increase in the price. Objective: Artificial Intelligence (AI) is already well-known for its superiority in various healthcare applications, including the segmentation of lesions in images, speech recognition, smartphone personal assistants, navigation, ride-sharing apps, and many more. Our study is based on two hypotheses: (i) AI offers more economic solutions compared to conventional methods; (ii) AI treatment offers stronger economics compared to AI diagnosis. This novel study aims to evaluate AI technology in the context of healthcare costs, namely in the areas of diagnosis and treatment, and then compare it to the traditional or non-AI-based approaches. Methodology: PRISMA was used to select the best 200 studies for AI in healthcare with a primary focus on cost reduction, especially towards diagnosis and treatment. We defined the diagnosis and treatment architectures, investigated their characteristics, and categorized the roles that AI plays in the diagnostic and therapeutic paradigms. We experimented with various combinations of different assumptions by integrating AI and then comparing it against conventional costs. Lastly, we dwell on three powerful future concepts of AI, namely, pruning, bias, explainability, and regulatory approvals of AI systems. Conclusions: The model shows tremendous cost savings using AI tools in diagnosis and treatment. The economics of AI can be improved by incorporating pruning, reduction in AI bias, explainability, and regulatory approvals.",
      "authors": "Khanna Narendra N; Maindarkar Mahesh A; Viswanathan Vijay; Fernandes Jose Fernandes E; Paul Sudip; Bhagawati Mrinalini; Ahluwalia Puneet; Ruzsa Zoltan; Sharma Aditya; Kolluri Raghu; Singh Inder M; Laird John R; Fatemi Mostafa; Alizad Azra; Saba Luca; Agarwal Vikas; Sharma Aman; Teji Jagjit S; Al-Maini Mustafa; Rathore Vijay; Naidu Subbaram; Liblik Kiera; Johri Amer M; Turk Monika; Mohanty Lopamudra; Sobel David W; Miner Martin; Viskovic Klaudija; Tsoulfas George; Protogerou Athanasios D; Kitas George D; Fouda Mostafa M; Chaturvedi Seemant; Kalra Mannudeep K; Suri Jasjit S",
      "year": "2022",
      "journal": "Healthcare (Basel, Switzerland)",
      "doi": "10.3390/healthcare10122493",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36554017/",
      "mesh_terms": "",
      "keywords": "AI bias; AI explainability; AI pruning; artificial intelligence; cost-effectiveness; deep learning; diagnosis; health economics; machine learning; recommendations; treatment",
      "pub_types": "Journal Article",
      "pmcid": "PMC9777836"
    },
    {
      "pmid": "40421178",
      "title": "Hybrid deep learning for IoT-based health monitoring with physiological event extraction.",
      "abstract": "OBJECTIVE: Integrating IoT technologies into the healthcare system has significantly raised the prospects for patient monitoring and disease prediction. However, the present-day models have failed to effectively encompass spatial-temporal data samples. METHODS: This paper presents a novel hybrid machine-learning model by amalgamating Convolutional Neural Networks (CNNs) with Long Short-Term Memory models (LSTMs) to boost prediction accuracy. Whereas the CNNs extract spatial features from medical images, the LSTMs model the temporal patterns of wearable sensor data. Such a configuration increases the prediction accuracy by 10% more than that achieved by the individual models. For better feature extraction, the proposed method implements Physiological Event Extraction (PEE), which is aimed at identifying important physiological events such as heart rate variability and respiratory changes from raw sensor data samples. RESULTS: This method helps render the features interpretable, providing another 15% improvement in prediction performance. Anomaly detection employed ensemble techniques that combined the Isolation Forest and One-Class SVM, reducing false positives by 20%, thus outperforming conventional approaches. It further enhanced the True Positive Rate (TPR) by 25% through using an online learning algorithm with Incremental Gradient Descent with Momentums. Robust statistical methods based on M-estimator theory had been integrated for the treatment of outliers and missing data, which helped in reducing bias in estimation by 30% and increasing the False Positive Rate (FPR) by 12%. CONCLUSION: All these enhancements constitute a major step towards improving the IoT healthcare data processing chain, thereby providing a trusted and accurate system for real-time health monitoring and anomaly detection. In this regard, the research also paves the way for designing next-gen IoT healthcare analytics and their actual clinical applications.",
      "authors": "Vallabhuni Sivanagaraju; Debasis Kumar",
      "year": "2025",
      "journal": "Digital health",
      "doi": "10.1177/20552076251337848",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40421178/",
      "mesh_terms": "",
      "keywords": "Hybrid ML models; IoT healthcare; anomaly detection; continuous learning; physiological event extraction",
      "pub_types": "Journal Article",
      "pmcid": "PMC12104608"
    },
    {
      "pmid": "24591703",
      "title": "Policymaking to preserve privacy in disclosure of public health data: a suggested framework.",
      "abstract": "Health organisations in Turkey gather a vast amount of valuable individual data that can be used for public health purposes. The organisations use rigid methods to remove some useful details from the data while publishing the rest of the data in a highly aggregated form, mostly because of privacy concerns and lack of standardised policies. This action leads to information loss and bias affecting public health research. Hence, organisations need dynamic policies and well-defined procedures rather than a specific algorithm to protect the privacy of individual data. To address this need, we developed a framework for the systematic application of anonymity methods while reducing and objectively reporting the information loss without leaking confidentiality. This framework acts as a roadmap for policymaking by providing high-level pseudo-policies with semitechnical guidelines in addition to some sample scenarios suitable for policymakers, public health programme managers and legislators.",
      "authors": "Mizani Mehrdad A; Baykal Nazife",
      "year": "2015",
      "journal": "Journal of medical ethics",
      "doi": "10.1136/medethics-2012-100731",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24591703/",
      "mesh_terms": "Confidentiality; Disclosure; Humans; Policy Making; Privacy; Public Health; Public Policy; Turkey",
      "keywords": "Confidentiality/Privacy; Information Technology; Policy Guidelines/Inst. Review Boards/Review Cttes.; Public Health Ethics",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33407780",
      "title": "Reporting guidelines for clinical trials of artificial intelligence interventions: the SPIRIT-AI and CONSORT-AI guidelines.",
      "abstract": "BACKGROUND: The application of artificial intelligence (AI) in healthcare is an area of immense interest. The high profile of 'AI in health' means that there are unusually strong drivers to accelerate the introduction and implementation of innovative AI interventions, which may not be supported by the available evidence, and for which the usual systems of appraisal may not yet be sufficient. MAIN TEXT: We are beginning to see the emergence of randomised clinical trials evaluating AI interventions in real-world settings. It is imperative that these studies are conducted and reported to the highest standards to enable effective evaluation because they will potentially be a key part of the evidence that is used when deciding whether an AI intervention is sufficiently safe and effective to be approved and commissioned. Minimum reporting guidelines for clinical trial protocols and reports have been instrumental in improving the quality of clinical trials and promoting completeness and transparency of reporting for the evaluation of new health interventions. The current guidelines-SPIRIT and CONSORT-are suited to traditional health interventions but research has revealed that they do not adequately address potential sources of bias specific to AI systems. Examples of elements that require specific reporting include algorithm version and the procedure for acquiring input data. In response, the SPIRIT-AI and CONSORT-AI guidelines were developed by a multidisciplinary group of international experts using a consensus building methodological process. The extensions include a number of new items that should be reported in addition to the core items. Each item, where possible, was informed by challenges identified in existing studies of AI systems in health settings. CONCLUSION: The SPIRIT-AI and CONSORT-AI guidelines provide the first international standards for clinical trials of AI systems. The guidelines are designed to ensure complete and transparent reporting of clinical trial protocols and reports involving AI interventions and have the potential to improve the quality of these clinical trials through improvements in their design and delivery. Their use will help to efficiently identify the safest and most effective AI interventions and commission them with confidence for the benefit of patients and the public.",
      "authors": "Ibrahim Hussein; Liu Xiaoxuan; Rivera Samantha Cruz; Moher David; Chan An-Wen; Sydes Matthew R; Calvert Melanie J; Denniston Alastair K",
      "year": "2021",
      "journal": "Trials",
      "doi": "10.1186/s13063-020-04951-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33407780/",
      "mesh_terms": "Artificial Intelligence; Consensus; Humans; Research Design; Research Report",
      "keywords": "Artificial intelligence; Checklist; Clinical trials; Guidelines; Machine learning; Randomised controlled trials; Research design; Research report",
      "pub_types": "Letter",
      "pmcid": "PMC7788716"
    },
    {
      "pmid": "23849160",
      "title": "Super learning to hedge against incorrect inference from arbitrary parametric assumptions in marginal structural modeling.",
      "abstract": "OBJECTIVE: Clinical trials are unlikely to ever be launched for many comparative effectiveness research (CER) questions. Inferences from hypothetical randomized trials may however be emulated with marginal structural modeling (MSM) using observational data, but success in adjusting for time-dependent confounding and selection bias typically relies on parametric modeling assumptions. If these assumptions are violated, inferences from MSM may be inaccurate. In this article, we motivate the application of a data-adaptive estimation approach called super learning (SL) to avoid reliance on arbitrary parametric assumptions in CER. STUDY DESIGN AND SETTING: Using the electronic health records data from adults with new-onset type 2 diabetes, we implemented MSM with inverse probability weighting (IPW) estimation to evaluate the effect of three oral antidiabetic therapies on the worsening of glomerular filtration rate. RESULTS: Inferences from IPW estimation were noticeably sensitive to the parametric assumptions about the associations between both the exposure and censoring processes and the main suspected source of confounding, that is, time-dependent measurements of hemoglobin A1c. SL was successfully implemented to harness flexible confounding and selection bias adjustment from existing machine learning algorithms. CONCLUSION: Erroneous IPW inference about clinical effectiveness because of arbitrary and incorrect modeling decisions may be avoided with SL.",
      "authors": "Neugebauer Romain; Fireman Bruce; Roy Jason A; Raebel Marsha A; Nichols Gregory A; O'Connor Patrick J",
      "year": "2013",
      "journal": "Journal of clinical epidemiology",
      "doi": "10.1016/j.jclinepi.2013.01.016",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23849160/",
      "mesh_terms": "Adult; Aged; Cohort Studies; Comparative Effectiveness Research; Confounding Factors, Epidemiologic; Data Interpretation, Statistical; Diabetes Mellitus, Type 2; Disease Progression; Drug Therapy, Combination; Electronic Health Records; Glomerular Filtration Rate; Humans; Hypoglycemic Agents; Metformin; Middle Aged; Models, Statistical; Randomized Controlled Trials as Topic; Selection Bias; Sulfonylurea Compounds; Survival Analysis; Time Factors; Treatment Outcome; Young Adult",
      "keywords": "Comparative effectiveness research; Inverse probability weighting; Marginal structural model; Selection bias; Super learning; Time-dependent confounding",
      "pub_types": "Journal Article",
      "pmcid": "PMC3713501"
    },
    {
      "pmid": "32685710",
      "title": "Propensity score stratification using bootstrap aggregating classification trees analysis.",
      "abstract": "INTRODUCTION: Observational research in the field of health often does not conduct randomized controlled trials on research subjects. A non-random selection process on research subjects can result in a biased treatment effect due to an imbalance between the treatment and control groups. METHODS: The problem of bias effects can be dealt with by reducing the bias in the confounding variable using the propensity score method. Estimation of propensity score can use machine learning method with a classification tree analysis approach. The resulting single classification tree model is still unstable if there is a slight change in learning data. Therefore, the ensemble method is applied which is bootstrap aggregating the classification tree as a tool to improve the stability and predictive power of the classification tree. RESULTS: This study aims to determine the effect of giving treatment antiretroviral therapy and counseling to opportunistic infections in HIV AIDS patients. The result of propensity score stratification analysis using bootstrap aggregating classification trees analysis is able to reduce the bias by 89.54%, using 5 strata and having a balanced covariate in each stratum. CONCLUSION: Testing the effect of treatment shows that there is a significant effect of giving antiretroviral therapy and counseling to opportunistic infections in HIV AIDS patients.",
      "authors": "Otok Bambang Widjanarko; Musa Marsuddin; Purhadi; Yasmirullah Septia Devi Prihastuti",
      "year": "2020",
      "journal": "Heliyon",
      "doi": "10.1016/j.heliyon.2020.e04288",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32685710/",
      "mesh_terms": "",
      "keywords": "Bootstrap aggregating; Classification trees analysis; Mathematics; Opportunistic infection; Propensity score stratification; Statistics",
      "pub_types": "Journal Article",
      "pmcid": "PMC7355728"
    },
    {
      "pmid": "36377370",
      "title": "Guidelines to Establish an Equitable Mobile Health Ecosystem.",
      "abstract": "Mobile health (mHealth)-that is, use of mobile devices, such as mobile phones, monitoring devices, personal digital assistants, and other wireless devices, in medical care-is a promising approach to the provision of support services. mHealth may aid in facilitating monitoring of mental health conditions, offering peer support, providing psychoeducation (i.e., information about mental health conditions), and delivering evidence-based practices. However, some groups may fail to benefit from mHealth despite a high need for mental health services, including people from racially and ethnically disadvantaged groups, rural residents, individuals who are socioeconomically disadvantaged, and people with disabilities. A well-designed mHealth ecosystem that considers multiple elements of design, development, and implementation can afford disadvantaged populations the opportunity to address inequities and facilitate access to and uptake of mHealth. This article proposes inclusion of the following principles and standards in the development of an mHealth ecosystem of equity: use a human-centered design, reduce bias in machine-learning analytical techniques, promote inclusivity via mHealth design features, facilitate informed decision making in technology selection, embrace adaptive technology, promote digital literacy through mHealth by teaching patients how to use the technology, and facilitate access to mHealth to improve health outcomes.",
      "authors": "Fortuna Karen L; Kadakia Arya; Cosco Theodore D; Rotondi Armando; Nicholson Joanne; Mois George; Myers Amanda L; Hamilton Jennifer; Brewer LaPrincess C; Collins-Pisano Caroline; Barr Paul; Hudson Matthew F; Joseph Kalisa; Mullaly Christa; Booth Mark; Lebby Stephanie; Walker Robert",
      "year": "2023",
      "journal": "Psychiatric services (Washington, D.C.)",
      "doi": "10.1176/appi.ps.202200011",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36377370/",
      "mesh_terms": "Humans; Ecosystem; Telemedicine; Cell Phone; Computers, Handheld; Mobile Applications",
      "keywords": "Inequities; Mobile health; Quality improvement; Racial-ethnic disparities; mHealth",
      "pub_types": "Journal Article",
      "pmcid": "PMC11398716"
    },
    {
      "pmid": "37451495",
      "title": "Generating synthetic clinical data that capture class imbalanced distributions with generative adversarial networks: Example using antiretroviral therapy for HIV.",
      "abstract": "OBJECTIVE: Clinical data's confidential nature often limits the development of machine learning models in healthcare. Generative adversarial networks (GANs) can synthesise realistic datasets, but suffer from mode collapse, resulting in low diversity and bias towards majority demographics and common clinical practices. This work proposes an extension to the classic GAN framework that includes a variational autoencoder (VAE) and an external memory mechanism to overcome these limitations and generate synthetic data accurately describing imbalanced class distributions commonly found in clinical variables. METHODS: The proposed method generated a synthetic dataset related to antiretroviral therapy for human immunodeficiency virus (ART for HIV). We evaluated it based on five metrics: (1) accurately representing imbalanced class distribution; (2) the realism of the individual variables; (3) the realism among variables; (4) patient disclosure risk; and (5) the utility of the generated dataset for developing downstream machine learning models. RESULTS: The proposed method overcomes the issue of mode collapse and generates a synthetic dataset that accurately describes imbalanced class distributions commonly found in clinical variables. The generated data has a patient disclosure risk of 0.095%, lower than the 9% threshold stated by Health Canada and the European Medicines Agency, making it suitable for distribution to the research community with high security. The generated data also has high utility, indicating the potential of the proposed method to enable the development of downstream machine learning algorithms for healthcare applications using synthetic data. CONCLUSION: Our proposed extension to the classic GAN framework, which includes a VAE and an external memory mechanism, represents a promising approach towards generating synthetic data that accurately describe imbalanced class distributions commonly found in clinical variables. This method overcomes the limitations of GANs and creates more realistic datasets with higher patient cohort diversity, facilitating the development of downstream machine learning algorithms for healthcare applications.",
      "authors": "Kuo Nicholas I-Hsien; Garcia Federico; S\u00f6nnerborg Anders; B\u00f6hm Michael; Kaiser Rolf; Zazzi Maurizio; Polizzotto Mark; Jorm Louisa; Barbieri Sebastiano",
      "year": "2023",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2023.104436",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37451495/",
      "mesh_terms": "Humans; HIV; Algorithms; Benchmarking; Disclosure; HIV Infections",
      "keywords": "Generative adversarial networks; Human immunodeficiency virus; Machine learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "36705960",
      "title": "Assessing Barriers to Implementation of Machine Learning and Artificial Intelligence-Based Tools in Critical Care: Web-Based Survey Study.",
      "abstract": "BACKGROUND: Although there is considerable interest in machine learning (ML) and artificial intelligence (AI) in critical care, the implementation of effective algorithms into practice has been limited. OBJECTIVE: We sought to understand physician perspectives of a novel intubation prediction tool. Further, we sought to understand health care provider and nonprovider perspectives on the use of ML in health care. We aim to use the data gathered to elucidate implementation barriers and determinants of this intubation prediction tool, as well as ML/AI-based algorithms in critical care and health care in general. METHODS: We developed 2 anonymous surveys in Qualtrics, 1 single-center survey distributed to 99 critical care physicians via email, and 1 social media survey distributed via Facebook and Twitter with branching logic to tailor questions for providers and nonproviders. The surveys included a mixture of categorical, Likert scale, and free-text items. Likert scale means with SD were reported from 1 to 5. We used student t tests to examine the differences between groups. In addition, Likert scale responses were converted into 3 categories, and percentage values were reported in order to demonstrate the distribution of responses. Qualitative free-text responses were reviewed by a member of the study team to determine validity, and content analysis was performed to determine common themes in responses. RESULTS: Out of 99 critical care physicians, 47 (48%) completed the single-center survey. Perceived knowledge of ML was low with a mean Likert score of 2.4 out of 5 (SD 0.96), with 7.5% of respondents rating their knowledge as a 4 or 5. The willingness to use the ML-based algorithm was 3.32 out of 5 (SD 0.95), with 75% of respondents answering 3 out of 5. The social media survey had 770 total responses with 605 (79%) providers and 165 (21%) nonproviders. We found no difference in providers' perceived knowledge based on level of experience in either survey. We found that nonproviders had significantly less perceived knowledge of ML (mean 3.04 out of 5, SD 1.53 vs mean 3.43, SD 0.941; P<.001) and comfort with ML (mean 3.28 out of 5, SD 1.02 vs mean 3.53, SD 0.935; P=.004) than providers. Free-text responses revealed multiple shared concerns, including accuracy/reliability, data bias, patient safety, and privacy/security risks. CONCLUSIONS: These data suggest that providers and nonproviders have positive perceptions of ML-based tools, and that a tool to predict the need for intubation would be of interest to critical care providers. There were many shared concerns about ML/AI in health care elucidated by the surveys. These results provide a baseline evaluation of implementation barriers and determinants of ML/AI-based tools that will be important in their optimal implementation and adoption in the critical care setting and health care in general.",
      "authors": "Mlodzinski Eric; Wardi Gabriel; Viglione Clare; Nemati Shamim; Crotty Alexander Laura; Malhotra Atul",
      "year": "2023",
      "journal": "JMIR perioperative medicine",
      "doi": "10.2196/41056",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36705960/",
      "mesh_terms": "",
      "keywords": "Qualtrics; adoption; artificial intelligence; attitude; barrier; critical care; implementation; intubation; machine learning; perception; perspective; predict; questionnaire; respiratory insufficiency; survey; surveys and questionnaires; trust",
      "pub_types": "Journal Article",
      "pmcid": "PMC10013679"
    },
    {
      "pmid": "37966891",
      "title": "Open-Source, Step-Counting Algorithm for Smartphone Data Collected in Clinical and Nonclinical Settings: Algorithm Development and Validation Study.",
      "abstract": "BACKGROUND: Step counts are increasingly used in public health and clinical research to assess well-being, lifestyle, and health status. However, estimating step counts using commercial activity trackers has several limitations, including a lack of reproducibility, generalizability, and scalability. Smartphones are a potentially promising alternative, but their step-counting algorithms require robust validation that accounts for temporal sensor body location, individual gait characteristics, and heterogeneous health states. OBJECTIVE: Our goal was to evaluate an open-source, step-counting method for smartphones under various measurement conditions against step counts estimated from data collected simultaneously from different body locations (\"cross-body\" validation), manually ascertained ground truth (\"visually assessed\" validation), and step counts from a commercial activity tracker (Fitbit Charge 2) in patients with advanced cancer (\"commercial wearable\" validation). METHODS: We used 8 independent data sets collected in controlled, semicontrolled, and free-living environments with different devices (primarily Android smartphones and wearable accelerometers) carried at typical body locations. A total of 5 data sets (n=103) were used for cross-body validation, 2 data sets (n=107) for visually assessed validation, and 1 data set (n=45) was used for commercial wearable validation. In each scenario, step counts were estimated using a previously published step-counting method for smartphones that uses raw subsecond-level accelerometer data. We calculated the mean bias and limits of agreement (LoA) between step count estimates and validation criteria using Bland-Altman analysis. RESULTS: In the cross-body validation data sets, participants performed 751.7 (SD 581.2) steps, and the mean bias was -7.2 (LoA -47.6, 33.3) steps, or -0.5%. In the visually assessed validation data sets, the ground truth step count was 367.4 (SD 359.4) steps, while the mean bias was -0.4 (LoA -75.2, 74.3) steps, or 0.1%. In the commercial wearable validation data set, Fitbit devices indicated mean step counts of 1931.2 (SD 2338.4), while the calculated bias was equal to -67.1 (LoA -603.8, 469.7) steps, or a difference of 3.4%. CONCLUSIONS: This study demonstrates that our open-source, step-counting method for smartphone data provides reliable step counts across sensor locations, measurement scenarios, and populations, including healthy adults and patients with cancer.",
      "authors": "Straczkiewicz Marcin; Keating Nancy L; Thompson Embree; Matulonis Ursula A; Campos Susana M; Wright Alexi A; Onnela Jukka-Pekka",
      "year": "2023",
      "journal": "JMIR cancer",
      "doi": "10.2196/47646",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37966891/",
      "mesh_terms": "",
      "keywords": "accelerometer; cancer; open-source; smartphone; step count; validation; wearable",
      "pub_types": "Journal Article",
      "pmcid": "PMC10687676"
    },
    {
      "pmid": "38413045",
      "title": "Contrasting Objective and Perceived Risk: Predicting COVID-19 Health Behaviors in a Nationally Representative U.S. Sample.",
      "abstract": "BACKGROUND: Individuals confronting health threats may display an optimistic bias such that judgments of their risk for illness or death are unrealistically positive given their objective circumstances. PURPOSE: We explored optimistic bias for health risks using k-means clustering in the context of COVID-19. We identified risk profiles using subjective and objective indicators of severity and susceptibility risk for COVID-19. METHODS: Between 3/18/2020-4/18/2020, a national probability sample of 6,514 U.S. residents reported both their subjective risk perceptions (e.g., perceived likelihood of illness or death) and objective risk indices (e.g., age, weight, pre-existing conditions) of COVID-19-related susceptibility and severity, alongside other pandemic-related experiences. Six months later, a subsample (N = 5,661) completed a follow-up survey with questions about their frequency of engagement in recommended health protective behaviors (social distancing, mask wearing, risk behaviors, vaccination intentions). RESULTS: The k-means clustering procedure identified five risk profiles in the Wave 1 sample; two of these demonstrated aspects of optimistic bias, representing almost 44% of the sample. In OLS regression models predicting health protective behavior adoption at Wave 2, clusters representing individuals with high perceived severity risk were most likely to report engagement in social distancing, but many individuals who were objectively at high risk for illness and death did not report engaging in self-protective behaviors. CONCLUSIONS: Objective risk of disease severity only inconsistently predicted health protective behavior. Risk profiles may help identify groups that need more targeted interventions to increase their support for public health policy and health enhancing recommendations more broadly.",
      "authors": "Thompson Rebecca R; Jones Nickolas M; Garfin Dana Rose; Holman E Alison; Silver Roxane Cohen",
      "year": "2024",
      "journal": "Annals of behavioral medicine : a publication of the Society of Behavioral Medicine",
      "doi": "10.1093/abm/kaad055",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38413045/",
      "mesh_terms": "Humans; COVID-19; Health Behavior; Pandemics; Surveys and Questionnaires",
      "keywords": "COVID-19; Optimistic bias; Risk perceptions; k-means clustering",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38859799",
      "title": "Pharmaceutical innovativeness index: methodological approach for assessing the value of medicines - a case study of oncology drugs.",
      "abstract": "BACKGROUND: We propose a framework to assess the value of pharmaceutical innovations, with explicit clinical and methodological parameters, based on the therapeutic value and health needs. RESEARCH DESIGN AND METHODS: The study was based on the adaptation of health technology assessment methods documented in the literature, which was applied to a sample of oncological drugs. Difficulties and issues during the application of those tools were identified and addressed to develop a new framework with new and revised domains and clear classification criterion for each domain. Scores were assigned to each level and domain according to their relevance to generate the final score of innovativeness. RESULTS: The Pharmaceutical Innovation Index (PII) includes four domains, two related to clinical and social dimensions - Therapeutic Need and Added Therapeutic Value - and other two about methodological features - Study Design and Quality (risk of bias). The scores combined after assigned to each domain results Index of the Innovativeness of the medicines represents the degree of pharmaceutical innovation. CONCLUSION: This work proposes a transparent methodology with well-defined criteria and script; the algorithm developed with authors' weightings and criteria may be switched to best adjust to other applications, perspective or clinical indications, while keeping the transparency and objectiveness.",
      "authors": "Gargano Ludmila P; Alvares-Teodoro Juliana; de A Acurcio Francisco; Guerra Augusto A",
      "year": "2024",
      "journal": "Expert review of pharmacoeconomics & outcomes research",
      "doi": "10.1080/14737167.2024.2365985",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38859799/",
      "mesh_terms": "Humans; Technology Assessment, Biomedical; Antineoplastic Agents; Research Design; Algorithms; Neoplasms; Health Services Needs and Demand; Bias",
      "keywords": "Health technology assessment; added therapeutic value; innovativeness; pharmaceutical innovation; pharmaceuticals; value-based innovation",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34744829",
      "title": "Machine Learning Prediction of Treatment Outcome in Late-Life Depression.",
      "abstract": "Background: Recent evidence suggests that integration of multi-modal data improves performance in machine learning prediction of depression treatment outcomes. Here, we compared the predictive performance of three machine learning classifiers using differing combinations of sociodemographic characteristics, baseline clinical self-reports, cognitive tests, and structural magnetic resonance imaging (MRI) features to predict treatment outcomes in late-life depression (LLD). Methods: Data were combined from two clinical trials conducted with depressed adults aged 60 and older, including response to escitalopram (N = 32, NCT01902004) and Tai Chi (N = 35, NCT02460666). Remission was defined as a score of 6 or less on the 24-item Hamilton Rating Scale for Depression (HAMD) at the end of 24 weeks of treatment. Features subsets were constructed from baseline sociodemographic and clinical features, gray matter volumes (GMVs), or both. Three classification algorithms were compared: (1) Support Vector Machine-Radial Bias Function (SVMRBF), (2) Random Forest (RF), and (3) Logistic Regression (LR). A repeated 5-fold cross-validation approach with a wrapper-based feature selection method was used for model fitting. Model performance metrics included Area under the ROC Curve (AUC) and Matthews correlation coefficient (MCC). Cross-validated performance significance was tested by permutation analysis. Classifiers were compared by Cochran's Q and post-hoc pairwise comparisons using McNemar's Chi-Square test with Bonferroni correction. Results: For the RF and SVMRBF algorithms, the combined feature set outperformed the clinical and GMV feature sets with a final cross-validated AUC of 0.83 \u00b1 0.11 and 0.80 \u00b1 0.11, respectively. Both classifiers passed permutation analysis. The LR algorithm performed best using GMV features alone (AUC 0.79 \u00b1 0.14) but failed to pass permutation analysis using any feature set. Performance of the three classifiers differed significantly for all three features sets. Important predictive features of treatment response included anterior and posterior cingulate volumes, depression characteristics, and self-reported health-related quality scores. Conclusion: This preliminary exploration into the use of ML and multi-modal data to identify predictors of general treatment response in LLD indicates that integration of clinical and structural MRI features significantly increases predictive capability. Identified features are among those previously implicated in geriatric depression, encouraging future work in this arena.",
      "authors": "Grzenda Adrienne; Speier William; Siddarth Prabha; Pant Anurag; Krause-Sorio Beatrix; Narr Katherine; Lavretsky Helen",
      "year": "2021",
      "journal": "Frontiers in psychiatry",
      "doi": "10.3389/fpsyt.2021.738494",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34744829/",
      "mesh_terms": "",
      "keywords": "computational modeling; late-life depression (LLD); machine learning; pharmacology; prediction model",
      "pub_types": "Journal Article",
      "pmcid": "PMC8563624"
    },
    {
      "pmid": "35586088",
      "title": "Using Convolutional Neural Networks for the Assessment Research of Mental Health.",
      "abstract": "Existing mental health assessment methods mainly rely on experts' experience, which has subjective bias, so convolutional neural networks are applied to mental health assessment to achieve the fusion of face, voice, and gait. Among them, the OpenPose algorithm is used to extract facial and posture features; openSMILE is used to extract voice features; and attention mechanism is introduced to reasonably allocate the weight values of different modal features. As can be seen, the effective identification and evaluation of 10 indicators such as mental health somatization, depression, and anxiety are realized. Simulation results show that the proposed method can accurately assess mental health. Here, the overall recognition accuracy can reach 77.20%, and the F1 value can reach 0.77. Compared with the recognition methods based on face single-mode fusion, face\u2009+\u2009voice dual-mode fusion, and face\u2009+\u2009voice\u2009+\u2009gait multimodal fusion, the recognition accuracy and F1 value of proposed method are improved to varying degrees, and the recognition effect is better, which has certain practical application value.",
      "authors": "Liu Yanbing",
      "year": "2022",
      "journal": "Computational intelligence and neuroscience",
      "doi": "10.1155/2022/1636855",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35586088/",
      "mesh_terms": "Algorithms; Face; Gait; Mental Health; Neural Networks, Computer",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9110170"
    },
    {
      "pmid": "33778840",
      "title": "Data-Driven Model Building for Life-Course Epidemiology.",
      "abstract": "Life-course epidemiology is useful for describing and analyzing complex etiological mechanisms for disease development, but existing statistical methods are essentially confirmatory, because they rely on a priori model specification. This limits the scope of causal inquiries that can be made, because these methods are suited mostly to examine well-known hypotheses that do not question our established view of health, which could lead to confirmation bias. We propose an exploratory alternative. Instead of specifying a life-course model prior to data analysis, our method infers the life-course model directly from the data. Our proposed method extends the well-known Peter-Clark (PC) algorithm (named after its authors) for causal discovery, and it facilitates including temporal information for inferring a model from observational data. The extended algorithm is called temporal PC. The obtained life-course model can afterward be perused for interesting causal hypotheses. Our method complements classical confirmatory methods and guides researchers in expanding their models in new directions. We showcase the method using a data set encompassing almost 3,000 Danish men followed from birth until age 65 years. Using this data set, we inferred life-course models for the role of socioeconomic and health-related factors on development of depression.",
      "authors": "Petersen Anne H; Osler Merete; Ekstr\u00f8m Claus T",
      "year": "2021",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwab087",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33778840/",
      "mesh_terms": "Adolescent; Adult; Aged; Algorithms; Causality; Child; Child, Preschool; Denmark; Depression; Epidemiologic Methods; Humans; Infant; Infant, Newborn; Male; Middle Aged; Models, Statistical; Socioeconomic Factors; Young Adult",
      "keywords": "causal discovery; life-course epidemiology; observational data; structure learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "38317869",
      "title": "Prediction Models for Glaucoma in a Multicenter Electronic Health Records Consortium: The Sight Outcomes Research Collaborative.",
      "abstract": "PURPOSE: Advances in artificial intelligence have enabled the development of predictive models for glaucoma. However, most work is single-center and uncertainty exists regarding the generalizability of such models. The purpose of this study was to build and evaluate machine learning (ML) approaches to predict glaucoma progression requiring surgery using data from a large multicenter consortium of electronic health records (EHR). DESIGN: Cohort study. PARTICIPANTS: Thirty-six thousand five hundred forty-eight patients with glaucoma, as identified by International Classification of Diseases (ICD) codes from 6 academic eye centers participating in the Sight OUtcomes Research Collaborative (SOURCE). METHODS: We developed ML models to predict whether patients with glaucoma would progress to glaucoma surgery in the coming year (identified by Current Procedural Terminology codes) using the following modeling approaches: (1) penalized logistic regression (lasso, ridge, and elastic net); (2) tree-based models (random forest, gradient boosted machines, and XGBoost), and (3) deep learning models. Model input features included demographics, diagnosis codes, medications, and clinical information (intraocular pressure, visual acuity, refractive status, and central corneal thickness) available from structured EHR data. One site was reserved as an \"external site\" test set (N\u00a0=\u00a01550); of the patients from the remaining sites, 10% each were randomly selected to be in development and test sets, with the remaining 27\u2009999 reserved for model training. MAIN OUTCOME MEASURES: Evaluation metrics included area under the receiver operating characteristic curve (AUROC) on the test set and the external site. RESULTS: Six thousand nineteen (16.5%) of 36\u2009548 patients underwent glaucoma surgery. Overall, the AUROC ranged from 0.735 to 0.771 on the random test set and from 0.706 to 0.754 on the external test site, with the XGBoost and random forest model performing best, respectively. There was greatest performance decrease from the random test set to the external test site for the penalized regression models. CONCLUSIONS: Machine learning models developed using structured EHR data can reasonably predict whether glaucoma patients will need surgery, with reasonable generalizability to an external site. Additional research is needed to investigate the impact of protected class characteristics such as race or gender on model performance and fairness. FINANCIAL DISCLOSURES: Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.",
      "authors": "Wang Sophia Y; Ravindranath Rohith; Stein Joshua D",
      "year": "2024",
      "journal": "Ophthalmology science",
      "doi": "10.1016/j.xops.2023.100445",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38317869/",
      "mesh_terms": "",
      "keywords": "Deep learning; Glaucoma; Machine learning; Multicenter study",
      "pub_types": "Journal Article",
      "pmcid": "PMC10838906"
    },
    {
      "pmid": "30383423",
      "title": "Bias From Potentially Mischievous Responders on Large-Scale Estimates of Lesbian, Gay, Bisexual, or Questioning (LGBQ)-Heterosexual Youth Health Disparities.",
      "abstract": "OBJECTIVES: To determine how sensitive estimates of lesbian, gay, bisexual, or questioning (LGBQ)-heterosexual youth health disparities are to the presence of potentially mischievous responders. METHODS: We used US data from the 2015 Youth Risk Behavior Survey, pooled across jurisdictions that included a question about sexual identity for a total sample of 148\u2009960 students. We used boosted regressions (a machine-learning technique) to identify unusual patterns of responses to 7 screener items presumably unrelated to LGBQ identification, which generated an index of suspected mischievousness. We estimated LGBQ-heterosexual youth disparities on 20 health outcomes; then we removed 1% of suspected mischievous responders at a time and re-estimated disparities to assess the robustness of original estimates. RESULTS: Accounting for suspected mischievousness reduced estimates of the average LGBQ-heterosexual youth health disparity by up to 46% for boys and 23% for girls; however, screening did not affect all outcomes equally. Drug- and alcohol-related disparities were most affected, particularly among boys, but bullying and suicidal ideation were unaffected. CONCLUSIONS: Including screener items in public health data sets and performing rigorous sensitivity analyses can support the validity of youth health estimates.",
      "authors": "Cimpian Joseph R; Timmer Jennifer D; Birkett Michelle A; Marro Rachel L; Turner Blair C; Phillips Gregory L",
      "year": "2018",
      "journal": "American journal of public health",
      "doi": "10.2105/AJPH.2018.304407",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30383423/",
      "mesh_terms": "Adolescent; Adult; Bisexuality; Child; Data Interpretation, Statistical; Female; Homosexuality; Humans; Male; Risk-Taking; Surveys and Questionnaires; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC6215371"
    },
    {
      "pmid": "40578211",
      "title": "The role of AI in transforming psychiatric-mental health care: Enhancing the role of psychiatric-mental health nurse practitioners.",
      "abstract": "The integration of artificial intelligence (AI) into psychiatric-mental health care presents transformative opportunities for psychiatric-mental health nurse practitioners (PMHNPs). AI enhances diagnostic accuracy, personalizes treatment plans, and improves patient outcomes by analyzing large datasets and identifying patterns beyond traditional methods. This paper explores AI's role in psychiatric care, focusing on its potential to enhance diagnostics, telepsychiatry, and personalized psychopharmacology. AI tools also enable real-time monitoring of patient symptoms through wearable devices and mobile applications, allowing for timely interventions. However, the integration of AI requires shifts in PMHNP education, emphasizing data literacy, machine learning, and ethical decision-making. While AI offers significant benefits, challenges such as data privacy, algorithmic bias, and maintaining the therapeutic relationship must be addressed. As AI becomes increasingly integrated into mental health care, PMHNPs will play a crucial role in ensuring its ethical and effective use in patient-centered care.",
      "authors": "Garcia Gryan",
      "year": "2025",
      "journal": "Nursing outlook",
      "doi": "10.1016/j.outlook.2025.102461",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40578211/",
      "mesh_terms": "Humans; Artificial Intelligence; Nurse Practitioners; Psychiatric Nursing; Mental Health Services; Mental Disorders; Nurse's Role; Female; Male; Adult; Telemedicine; Middle Aged",
      "keywords": "Artificial intelligence; Ethical considerations in AI; Personalized treatment; Psychiatric-mental health nurse practitioners; Telepsychiatry",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39100498",
      "title": "MoodCapture: Depression Detection Using In-the-Wild Smartphone Images.",
      "abstract": "MoodCapture presents a novel approach that assesses depression based on images automatically captured from the front-facing camera of smartphones as people go about their daily lives. We collect over 125,000 photos in the wild from N=177 participants diagnosed with major depressive disorder for 90 days. Images are captured naturalistically while participants respond to the PHQ-8 depression survey question: \"I have felt down, depressed, or hopeless\". Our analysis explores important image attributes, such as angle, dominant colors, location, objects, and lighting. We show that a random forest trained with face landmarks can classify samples as depressed or non-depressed and predict raw PHQ-8 scores effectively. Our post-hoc analysis provides several insights through an ablation study, feature importance analysis, and bias assessment. Importantly, we evaluate user concerns about using MoodCapture to detect depression based on sharing photos, providing critical insights into privacy concerns that inform the future design of in-the-wild image-based mental health assessment tools.",
      "authors": "Nepal Subigya; Pillai Arvind; Wang Weichen; Griffin Tess; Collins Amanda C; Heinz Michael; Lekkas Damien; Mirjafari Shayan; Nemesure Matthew; Price George; Jacobson Nicholas C; Campbell Andrew T",
      "year": "2024",
      "journal": "Proceedings of the SIGCHI conference on human factors in computing systems. CHI Conference",
      "doi": "10.1145/3613904.3642680",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39100498/",
      "mesh_terms": "",
      "keywords": "Depression; Face; Facial Expressions; In-the-wild; Machine Learning; Mental Health; Mood; PHQ; Passive Sensing; Smartphones",
      "pub_types": "Journal Article",
      "pmcid": "PMC11296678"
    },
    {
      "pmid": "34867518",
      "title": "Do Words Matter? Detecting Social Isolation and Loneliness in Older Adults Using Natural Language Processing.",
      "abstract": "Introduction: Social isolation and loneliness (SI/L) are growing problems with serious health implications for older adults, especially in light of the COVID-19 pandemic. We examined transcripts from semi-structured interviews with 97 older adults (mean age 83 years) to identify linguistic features of SI/L. Methods: Natural Language Processing (NLP) methods were used to identify relevant interview segments (responses to specific questions), extract the type and number of social contacts and linguistic features such as sentiment, parts-of-speech, and syntactic complexity. We examined: (1) associations of NLP-derived assessments of social relationships and linguistic features with validated self-report assessments of social support and loneliness; and (2) important linguistic features for detecting individuals with higher level of SI/L by using machine learning (ML) models. Results: NLP-derived assessments of social relationships were associated with self-reported assessments of social support and loneliness, though these associations were stronger in women than in men. Usage of first-person plural pronouns was negatively associated with loneliness in women and positively associated with emotional support in men. ML analysis using leave-one-out methodology showed good performance (F1 = 0.73, AUC = 0.75, specificity = 0.76, and sensitivity = 0.69) of the binary classification models in detecting individuals with higher level of SI/L. Comparable performance were also observed when classifying social and emotional support measures. Using ML models, we identified several linguistic features (including use of first-person plural pronouns, sentiment, sentence complexity, and sentence similarity) that most strongly predicted scores on scales for loneliness and social support. Discussion: Linguistic data can provide unique insights into SI/L among older adults beyond scale-based assessments, though there are consistent gender differences. Future research studies that incorporate diverse linguistic features as well as other behavioral data-streams may be better able to capture the complexity of social functioning in older adults and identification of target subpopulations for future interventions. Given the novelty, use of NLP should include prospective consideration of bias, fairness, accountability, and related ethical and social implications.",
      "authors": "Badal Varsha D; Nebeker Camille; Shinkawa Kaoru; Yamada Yasunori; Rentscher Kelly E; Kim Ho-Cheol; Lee Ellen E",
      "year": "2021",
      "journal": "Frontiers in psychiatry",
      "doi": "10.3389/fpsyt.2021.728732",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34867518/",
      "mesh_terms": "",
      "keywords": "NLP; Social support; artificial intelligence; gender; linguistic features; loneliness; social connectedness",
      "pub_types": "Journal Article",
      "pmcid": "PMC8635064"
    },
    {
      "pmid": "38111126",
      "title": "An evolutionary algorithm for the direct optimization of covariate balance between nonrandomized populations.",
      "abstract": "Matching reduces confounding bias in comparing the outcomes of nonrandomized patient populations by removing systematic differences between them. Under very basic assumptions, propensity score (PS) matching can be shown to eliminate bias entirely in estimating the average treatment effect on the treated. In practice, misspecification of the PS model leads to deviations from theory and matching quality is ultimately judged by the observed post-matching balance in baseline covariates. Since covariate balance is the ultimate arbiter of successful matching, we argue for an approach to matching in which the success criterion is explicitly specified and describe an evolutionary algorithm to directly optimize an arbitrary metric of covariate balance. We demonstrate the performance of the proposed method using a simulated dataset of 275,000 patients and 10 matching covariates. We further apply the method to match 250 patients from a recently completed clinical trial to a pool of more than 160,000 patients identified from electronic health records on 101 covariates. In all cases, we find that the proposed method outperforms PS matching as measured by the specified balance criterion. We additionally find that the evolutionary approach can perform comparably to another popular direct optimization technique based on linear integer programming, while having the additional advantage of supporting arbitrary balance metrics. We demonstrate how the chosen balance metric impacts the statistical properties of the resulting matched populations, emphasizing the potential impact of using nonlinear balance functions in constructing an external control arm. We release our implementation of the considered algorithms in Python.",
      "authors": "Privitera Stephen; Sedghamiz Hooman; Hartenstein Alexander; Vaitsiakhovich Tatsiana; Kleinjung Frank",
      "year": "2024",
      "journal": "Pharmaceutical statistics",
      "doi": "10.1002/pst.2352",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38111126/",
      "mesh_terms": "Humans; Algorithms; Propensity Score; Computer Simulation; Bias; Clinical Trials as Topic; Electronic Health Records; Models, Statistical",
      "keywords": "balance diagnostics; external control arm; population matching; propensity score; real\u2010world evidence",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "28239834",
      "title": "Order-constrained linear optimization.",
      "abstract": "Despite the fact that data and theories in the social, behavioural, and health sciences are often represented on an ordinal scale, there has been relatively little emphasis on modelling ordinal properties. The most common analytic framework used in psychological science is the general linear model, whose variants include ANOVA, MANOVA, and ordinary linear regression. While these methods are designed to provide the best fit to the metric properties of the data, they are not designed to maximally model ordinal properties. In this paper, we develop an order-constrained linear least-squares (OCLO) optimization algorithm that maximizes the linear least-squares fit to the data conditional on maximizing the ordinal fit based on Kendall's \u03c4. The algorithm builds on the maximum rank correlation estimator (Han, 1987, Journal of Econometrics, 35, 303) and the general monotone model (Dougherty & Thomas, 2012, Psychological Review, 119, 321). Analyses of simulated data indicate that when modelling data that adhere to the assumptions of ordinary least squares, OCLO shows minimal bias, little increase in variance, and almost no loss in out-of-sample predictive accuracy. In contrast, under conditions in which data include a small number of extreme scores (fat-tailed distributions), OCLO shows less bias and variance, and substantially better out-of-sample predictive accuracy, even when the outliers are removed. We show that the advantages of OCLO over ordinary least squares in predicting new observations hold across a variety of scenarios in which researchers must decide to retain or eliminate extreme scores when fitting data.",
      "authors": "Tidwell Joe W; Dougherty Michael R; Chrabaszcz Jeffrey S; Thomas Rick P",
      "year": "2017",
      "journal": "The British journal of mathematical and statistical psychology",
      "doi": "10.1111/bmsp.12090",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28239834/",
      "mesh_terms": "Algorithms; Computer Simulation; Data Interpretation, Statistical; Humans; Least-Squares Analysis; Linear Models; Models, Psychological; Models, Statistical; Psychology",
      "keywords": "general monotone model; maximum rank correlation estimator; regression; semi-parametric",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "23604043",
      "title": "Validation of Medicaid Claims-based Diagnosis of Myocardial Infarction Using an HIV Clinical Cohort.",
      "abstract": "BACKGROUND: In nonexperimental comparative effectiveness research using health care databases, outcome measurements must be validated to evaluate and potentially adjust for misclassification bias. We aimed to validate claims-based myocardial infarction (MI) algorithms in a Medicaid population using an HIV clinical cohort as the gold standard. METHODS: Medicaid administrative data were obtained for the years 2002-2008 and linked to the UNC CFAR HIV Clinical Cohort based on social security number, first name, and last name and MI were adjudicated. Sensitivity, specificity, positive predictive value, and negative predictive value were calculated. RESULTS: There were 1063 individuals included in the study. Over a median observed time of 2.5 years, 17 had an MI. Specificity ranged from 0.979 to 0.993 with the highest specificity obtained using the ICD-9 code 410.xx in the primary or secondary position and a length of stay >3 days. Sensitivity of MI ascertainment varied from 0.588 to 0.824 depending on algorithm. CONCLUSIONS: Specificities of varying claims-based MI ascertainment criteria are high but small changes impact positive predictive value in a cohort with low incidence. Sensitivities vary based on ascertainment criteria. Type of algorithm used should be prioritized based on study question and maximization of specific validation parameters that will minimize bias while also considering precision.",
      "authors": "Brouwer Emily S; Napravnik Sonia; Eron Joseph J; Simpson Ross J; Brookhart M Alan; Stalzer Brant; Vinikoor Michael; Floris-Moore Michelle; St\u00fcrmer Til",
      "year": "2015",
      "journal": "Medical care",
      "doi": "10.1097/MLR.0b013e318287d6fd",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23604043/",
      "mesh_terms": "Adult; Algorithms; Databases, Factual; Female; HIV Infections; Humans; Insurance Claim Review; International Classification of Diseases; Length of Stay; Male; Medicaid; Middle Aged; Myocardial Infarction; Racial Groups; Reproducibility of Results; United States",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC4022708"
    },
    {
      "pmid": "26968948",
      "title": "Outbreak definition by change point analysis: a tool for public health decision?",
      "abstract": "BACKGROUND: Most studies of epidemic detection focus on their start and rarely on the whole signal or the end of the epidemic. In some cases, it may be necessary to retrospectively identify outbreak signals from surveillance data. Our study aims at evaluating the ability of change point analysis (CPA) methods to locate the whole disease outbreak signal. We will compare our approach with the results coming from experts' signal inspections, considered as the gold standard method. METHODS: We simulated 840 time series, each of which includes an epidemic-free baseline (7 options) and a type of epidemic (4 options). We tested the ability of 4 CPA methods (Max-likelihood, Kruskall-Wallis, Kernel, Bayesian) methods and expert inspection to identify the simulated outbreaks. We evaluated the performances using metrics including delay, accuracy, bias, sensitivity, specificity and Bayesian probability of correct classification (PCC). RESULTS: A minimum of 15\u00a0h was required for experts for analyzing the 840 curves and a maximum of 25\u00a0min for a CPA algorithm. The Kernel algorithm was the most effective overall in terms of accuracy, bias and global decision (PCC\u2009=\u20090.904), compared to PCC of 0.848 for human expert review. CONCLUSIONS: For the aim of retrospectively identifying the start and end of a disease outbreak, in the absence of human resources available to do this work, we recommend using the Kernel change point model. And in case of experts' availability, we also suggest to supplement the Human expertise with a CPA, especially when the signal noise difference is below 0.",
      "authors": "Texier Ga\u00ebtan; Farouh Magnim; Pellegrin Liliane; Jackson Michael L; Meynard Jean-Baptiste; Deparis Xavier; Chaudet Herv\u00e9",
      "year": "2016",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-016-0271-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26968948/",
      "mesh_terms": "Computer Simulation; Decision Support Techniques; Disease Outbreaks; Epidemiological Monitoring; Humans; Models, Statistical; Public Health",
      "keywords": "Change point analysis; Disease surveillance; Evaluation; Expert; Outbreak identification",
      "pub_types": "Journal Article",
      "pmcid": "PMC4788889"
    },
    {
      "pmid": "40144984",
      "title": "Perspective improvement of regional air pollution burden of disease estimation by machine intelligence.",
      "abstract": "As air pollution events increasingly threaten public health under climate change, more precise estimations of air pollutant exposure and the burden of diseases (BD) are urgently needed. However, current BD assessments from various sources of air pollutant concentrations and exposure risks, and the derived uncertainty still needs systematic assessment. Owing to growing health and air quality data availability, machine learning (ML) may provide a promising solution. This study proposed an ML-measurement-model fusion (MMF) framework that can quantify the air pollutant biases from the Chemical Transport Modeling (CTM) inputs, and further analyze the BD biases concerning various sources of air pollutant estimations and exposure risks. In our study region, the proposed ML-MMF framework successfully improves CTM-modeled PM2.5 (from R2\u202f=\u202f0.41 to R2\u202f=\u202f0.86) and O3 (from R2\u202f=\u202f0.48 to R2\u202f=\u202f0.82). The bias quantification results showed that premature deaths in the study region are mainly biased by boundary conditions (Improvement Ratio, IR\u202f=\u202f99%) and meteorology (91%), compared with emission and land-use data. The results of further analysis showed using observations only (PM2.5: 17%; O3: 56%) or the uncorrected CTM estimations (PM2.5: -18%; O3: 171%) contributed more BD biases compared with employing averaged risks without considering urbanization levels (PM2.5: -5%; O3: -4%). In conclusion, employing observations only, uncorrected CTM estimations, and homogeneous risks may contribute to non-negligible BD biases and affect regional air quality and risk management. To cope with increasing needs of finer-scale air quality management under climate change, our developed ML-MMF framework can provide a quantitative reference to improve CTM performance and priority to improve input data quality and CTM mechanisms.",
      "authors": "Kuo Cheng-Pin; Fu Joshua S; Liu Yang",
      "year": "2025",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2025.1436838",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40144984/",
      "mesh_terms": "Air Pollution; Humans; Air Pollutants; Machine Learning; Environmental Exposure; Particulate Matter; Climate Change; Environmental Monitoring; Cost of Illness",
      "keywords": "PM2.5; bias correction; disease burden; machine learning; ozone",
      "pub_types": "Journal Article",
      "pmcid": "PMC11937109"
    },
    {
      "pmid": "38838307",
      "title": "Chinese Oncologists' Perspectives on Integrating AI into Clinical Practice: Cross-Sectional Survey Study.",
      "abstract": "BACKGROUND: The rapid development of artificial intelligence (AI) has brought significant interest to its potential applications in oncology. Although AI-powered tools are already being implemented in some Chinese hospitals, their integration into clinical practice raises several concerns for Chinese oncologists. OBJECTIVE: This study aims to explore the concerns of Chinese oncologists regarding the integration of AI into clinical practice and to identify the factors influencing these concerns. METHODS: A total of 228 Chinese oncologists participated in a cross-sectional web-based survey from April to June in 2023 in mainland China. The survey gauged their worries about AI with multiple-choice questions. The survey evaluated their views on the statements of \"The impact of AI on the doctor-patient relationship\" and \"AI will replace doctors.\" The data were analyzed using descriptive statistics, and variate analyses were used to find correlations between the oncologists' backgrounds and their concerns. RESULTS: The study revealed that the most prominent concerns were the potential for AI to mislead diagnosis and treatment (163/228, 71.5%); an overreliance on AI (162/228, 71%); data and algorithm bias (123/228, 54%); issues with data security and patient privacy (123/228, 54%); and a lag in the adaptation of laws, regulations, and policies in keeping up with AI's development (115/228, 50.4%). Oncologists with a bachelor's degree expressed heightened concerns related to data and algorithm bias (34/49, 69%; P=.03) and the lagging nature of legal, regulatory, and policy issues (32/49, 65%; P=.046). Regarding AI's impact on doctor-patient relationships, 53.1% (121/228) saw a positive impact, whereas 35.5% (81/228) found it difficult to judge, 9.2% (21/228) feared increased disputes, and 2.2% (5/228) believed that there is no impact. Although sex differences were not significant (P=.08), perceptions varied-male oncologists tended to be more positive than female oncologists (74/135, 54.8% vs 47/93, 50%). Oncologists with a bachelor's degree (26/49, 53%; P=.03) and experienced clinicians (\u226521 years; 28/56, 50%; P=.054). found it the hardest to judge. Those with IT experience were significantly more positive (25/35, 71%) than those without (96/193, 49.7%; P=.02). Opinions regarding the possibility of AI replacing doctors were diverse, with 23.2% (53/228) strongly disagreeing, 14% (32/228) disagreeing, 29.8% (68/228) being neutral, 16.2% (37/228) agreeing, and 16.7% (38/228) strongly agreeing. There were no significant correlations with demographic and professional factors (all P>.05). CONCLUSIONS: Addressing oncologists' concerns about AI requires collaborative efforts from policy makers, developers, health care professionals, and legal experts. Emphasizing transparency, human-centered design, bias mitigation, and education about AI's potential and limitations is crucial. Through close collaboration and a multidisciplinary strategy, AI can be effectively integrated into oncology, balancing benefits with ethical considerations and enhancing patient care.",
      "authors": "Li Ming; Xiong XiaoMin; Xu Bo; Dickson Conan",
      "year": "2024",
      "journal": "JMIR formative research",
      "doi": "10.2196/53918",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38838307/",
      "mesh_terms": "",
      "keywords": "AI; artificial intelligence; clinical practice; concern; machine learning; oncologist",
      "pub_types": "Journal Article",
      "pmcid": "PMC11187515"
    },
    {
      "pmid": "32960411",
      "title": "Surrogates and Artificial Intelligence: Why AI Trumps Family.",
      "abstract": "The increasing accuracy of algorithms to predict values and preferences raises the possibility that artificial intelligence technology will be able to serve as a surrogate decision-maker for incapacitated patients. Following Camillo Lamanna and Lauren Byrne, we call this technology the autonomy algorithm (AA). Such an algorithm would mine medical research, health records, and social media data to predict patient treatment preferences. The possibility of developing the AA raises the ethical question of whether the AA or a relative ought to serve as surrogate decision-maker in cases where the patient has not issued a medical power of attorney. We argue that in such cases, and against the standard practice of vesting familial surrogates with decision making authority, the AA should have sole decision-making authority. This is because the AA will likely be better at predicting what treatment option the patient would have chosen. It would also be better at avoiding bias and, therefore, choosing in a more patient-centered manner. Furthermore, we argue that these considerations override any moral weight of the patient's special relationship with their relatives.",
      "authors": "Hubbard Ryan; Greenblum Jake",
      "year": "2020",
      "journal": "Science and engineering ethics",
      "doi": "10.1007/s11948-020-00266-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32960411/",
      "mesh_terms": "Artificial Intelligence; Decision Making; Humans; Morals; Patient Preference",
      "keywords": "Artificial intelligence (AI); Biomedical; Decision-making; Ethics; Surrogate",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34256541",
      "title": "Anti-doping and other sport integrity challenges during the COVID-19 pandemic.",
      "abstract": "The coronavirus disease (COVID-19) pandemic has had an unprecedent impact on the world of sport and society at large. Many of the challenges with respect to integrity previously facing competitive sport have been accentuated further during the pandemic. Threats to the integrity of sporting competition include traditional doping, issues of technological fairness, and integration of transgender and intersex athletes in elite sport. The enforced lull in competitive sport provides an unprecedented opportunity for stakeholders in sport to focus on unresolved integrity issues and develop and implement long-lasting solutions. There needs to be a concerted effort to focus on the many technological innovations accelerated by and perfected during COVID-19 that have enabled us to work from home, such as teaching students on-line, applications for medical advice, prescriptions and referrals, and treating patients in hospitals/care homes via video links and use these developments and innovations to enhance sport integrity and anti-doping procedures. Positive sports integrity actions will require a considered application of all such technology, as well as the inclusion of \"omics\" technology, big data, bioinformatics and machine learning/artificial intelligence approaches to modernize sport. Applications include protecting the health of athletes, considered non-discriminative integration of athletes into elite sport, intelligent remote testing to improve the frequency of anti-doping tests, detection windows, and the potential combination with omics technology to improve the tests' sensitivity and specificity in order to protect clean athletes and deter doping practices.",
      "authors": "Lima Giscard; Muniz-Pardos Borja; Kolliari-Turner Alexander; Hamilton Blair; Guppy Fergus M; Grivas Gerasimos; Bosch Andrew; Borrione Paolo; DI Gianfrancesco Alessia; Fossati Chiara; Pigozzi Fabio; Pitsiladis Yannis",
      "year": "2021",
      "journal": "The Journal of sports medicine and physical fitness",
      "doi": "10.23736/S0022-4707.21.12777-X",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34256541/",
      "mesh_terms": "Artificial Intelligence; Athletes; COVID-19; Doping in Sports; Humans; Pandemics; SARS-CoV-2",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34799627",
      "title": "A weighted patient network-based framework for predicting chronic diseases using graph neural networks.",
      "abstract": "Chronic disease prediction is a critical task in healthcare. Existing studies fulfil this requirement by employing machine learning techniques based on patient features, but they suffer from high dimensional data problems and a high level of bias. We propose a framework for predicting chronic disease based on Graph Neural Networks (GNNs) to address these issues. We begin by projecting a patient-disease bipartite graph to create a weighted patient network (WPN) that extracts the latent relationship among patients. We then use GNN-based techniques to build prediction models. These models use features extracted from WPN to create robust patient representations for chronic disease prediction. We compare the output of GNN-based models to machine learning methods by using cardiovascular disease and chronic pulmonary disease. The results show that our framework enhances the accuracy of chronic disease prediction. The model with attention mechanisms achieves an accuracy of 93.49% for cardiovascular disease prediction and 89.15% for chronic pulmonary disease prediction. Furthermore, the visualisation of the last hidden layers of GNN-based models shows the pattern for the two cohorts, demonstrating the discriminative strength of the framework. The proposed framework can help stakeholders improve health management systems for patients at risk of developing chronic diseases and conditions.",
      "authors": "Lu Haohui; Uddin Shahadat",
      "year": "2021",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-021-01964-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34799627/",
      "mesh_terms": "Algorithms; Cardiovascular Diseases; Chronic Disease; Data Interpretation, Statistical; Databases, Factual; Female; Humans; Machine Learning; Male; Neural Networks, Computer; Programming Languages; Pulmonary Disease, Chronic Obstructive; Reproducibility of Results; Risk; Software; Translational Research, Biomedical",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC8604920"
    },
    {
      "pmid": "31931980",
      "title": "Predicting opioid misuse at the population level is different from identifying opioid misuse in individual patients.",
      "abstract": "Tumin and Bhalla mentioned challenges associated with the use of population-based survey and machine learning (ML) results on adolescent opioid misuse to clinical settings. In a clinical setting, medical providers do know patient's identity. So, it is not surprising that drug misuse is rarely identified through patient's self-report especially if it involves illicit drug. Even though self-report is susceptible to bias, it is a valid and affordable tool to gather data on illicit drug use at the population level. Use of audio computer-assisted self-interviewing (ACASI) and computer-assisted personal interviewing (CAPI) in NSDUH provides the respondent with a highly private and confidential mode for responding to questions, which helps increase the level of honest reporting of illicit drug use and other sensitive behaviors. As acknowledged in the paper, opioid misuse should not be inferred at the individual level from our ML models. Such interpretations may lead to ecological fallacy. Predicting opioid misuse at the population level is different from identifying opioid misuse in individual patients. Nonetheless, we believe that coordinated multisectoral collaborations that leverage the expertise and resources of both public health and clinical sectors would offer a promising model for addressing the opioid crisis.",
      "authors": "Seo Dong-Chul; Han Dae-Hee; Lee Shieun",
      "year": "2020",
      "journal": "Preventive medicine",
      "doi": "10.1016/j.ypmed.2019.105969",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31931980/",
      "mesh_terms": "Adolescent; Analgesics, Opioid; Drug Users; Humans; Machine Learning; Prescription Drug Misuse; Self Report",
      "keywords": "Adolescents; Machine learning; Opioid misuse",
      "pub_types": "Letter; Comment",
      "pmcid": ""
    },
    {
      "pmid": "32526532",
      "title": "Population-level surveillance of congenital heart defects among adolescents and adults in Colorado: Implications of record linkage.",
      "abstract": "BACKGROUND: The objective was to describe the design of a population-level electronic health record (EHR) and insurance claims-based surveillance system of adolescents and adults with congenital heart defects (CHDs) in Colorado and to evaluate the bias introduced by duplicate cases across data sources. METHODS: The Colorado CHD Surveillance System ascertained individuals aged 11-64\u202fyears with a CHD based on International Classification of Diseases, Ninth Revision, Clinical Modification diagnostic coding between 2011 and 2013 from a diverse network of health care systems and an All Payer Claims Database (APCD). A probability-based identity reconciliation algorithm identified duplicate cases. Logistic regression was conducted to investigate bias introduced by duplicate cases on the relationship between CHD severity (severe compared to moderate/mild) and adverse outcomes including all-cause mortality, inpatient hospitalization, and major adverse cardiac events (myocardial infarction, congestive heart failure, or cerebrovascular event). Sensitivity analyses were conducted to investigate bias introduced by the sole use or exclusion of APCD data. RESULTS: A total of 12,293 unique cases were identified, of which 3,476 had a within or between data source duplicate. Duplicate cases were more likely to be in the youngest age group and have private health insurance, a severe heart defect, a CHD comorbidity, and higher health care utilization. We found that failure to resolve duplicate cases between data sources would inflate the relationship between CHD severity and both morbidity and mortality outcomes by ~15%. Sensitivity analyses indicate that scenarios in which APCD was excluded from case finding or relied upon as the sole source of case finding would also result in an overestimation of the relationship between a CHD severity and major adverse outcomes. DISCUSSION: Aggregated EHR- and claims-based surveillance systems of adolescents and adults with CHD that fail to account for duplicate records will introduce considerable bias into research findings. CONCLUSION: Population-level surveillance systems for rare chronic conditions, such as congenital heart disease, based on aggregation of EHR and claims data require sophisticated identity reconciliation methods to prevent bias introduced by duplicate cases.",
      "authors": "Crume Tessa L; Duca Lindsey M; Ong Toan; Kraus Emily; Scott Ken; Khanna Amber; Kao David; Rausch Christopher M; McKenzie Lisa; Daley Matthew F; Coleman Suzanne; Kahn Michael G; Costa Everett; Davidson Arthur J",
      "year": "2020",
      "journal": "American heart journal",
      "doi": "10.1016/j.ahj.2020.04.008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32526532/",
      "mesh_terms": "Adolescent; Adult; Bias; Child; Colorado; Electronic Health Records; Female; Heart Defects, Congenital; Humans; Information Storage and Retrieval; Insurance Claim Reporting; Male; Medical Record Linkage; Middle Aged; Population Surveillance; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "40346110",
      "title": "Mitigating class imbalance in churn prediction with ensemble methods and SMOTE.",
      "abstract": "This study examines how imbalanced datasets affect the accuracy of machine learning models, especially in predictive analytics applications such as churn prediction. When datasets are skewed towards the majority class, it can lead to biased model performance, reducing overall effectiveness. To analyze this impact, the research utilizes a churn dataset to evaluate how data imbalance influences model accuracy. The study utilized nine individual classifiers along with six homogeneous ensemble models to evaluate the effects of imbalanced data on model performance. Single classifier models struggle to identify underlying patterns in imbalanced data, while ensembles improve predictive performance by focusing on the minority class. However, when trained on unbalanced data, their accuracy remains subpar. The top six classifiers were selected for further investigation based on their performance on the imbalanced data. A SMOTE sampling technique was employed to create a balanced dataset, ensuring that all classes were adequately represented. The generated model's performance improved from 61 to 79%, indicating the removal of bias in the target data. The results showed that Adaboost, an optimal classifier, demonstrated superior performance with an F1-Score of 87.6% in identifying potential churn and assessing customer account health. The findings emphasize the importance of balanced datasets for accurate ML model predictions.",
      "authors": "Suguna R; Suriya Prakash J; Aditya Pai H; Mahesh T R; Vinoth Kumar Venkatesan; Yimer Temesgen Engida",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-01031-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40346110/",
      "mesh_terms": "",
      "keywords": "Churn prediction; Ensemble models; Imbalanced data; Machine learning; Predictive analytics; Sampling techniques; Single classifier",
      "pub_types": "Journal Article",
      "pmcid": "PMC12064797"
    },
    {
      "pmid": "33281668",
      "title": "Toward Learning Machines at a Mother and Baby Unit.",
      "abstract": "Agnostic analyses of unique video material from a Mother and Baby Unit were carried out to investigate the usefulness of such analyses to the unit. The goal was to improve outcomes: the health of mothers and their babies. The method was to implement a learning machine that becomes more useful over time and over task. A feasible set-up is here described, with the purpose of producing intelligible and useful results to healthcare professionals at the unit by means of a vision processing pipeline, grouped together with multi-modal capabilities of handling annotations and audio. Algorithmic bias turned out to be an obstacle that could only partly be handled by modern pipelines for automated feature analysis. The professional use of complex quantitative scoring for various mental health-related assessments further complicated the automation of laborious tasks. Activities during the MBU stay had previously been shown to decrease psychiatric symptoms across diagnostic groups. The implementation and first set of experiments on a learning machine for the unit produced the first steps toward explaining why this is so, in turn enabling decision support to staff about what to do more and what to do less of.",
      "authors": "Boman Magnus; Downs Johnny; Karali Abubakrelsedik; Pawlby Susan",
      "year": "2020",
      "journal": "Frontiers in psychology",
      "doi": "10.3389/fpsyg.2020.567310",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33281668/",
      "mesh_terms": "",
      "keywords": "learning machine; machine learning; maternal unresponsiveness; mental health; mind-mindedness; multi-modal learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC7691596"
    },
    {
      "pmid": "34635760",
      "title": "Imputation of missing values for electronic health record laboratory data.",
      "abstract": "Laboratory data from Electronic Health Records (EHR) are often used in prediction models where estimation bias and model performance from missingness can be mitigated using imputation methods. We demonstrate the utility of imputation in two real-world EHR-derived cohorts of ischemic stroke from Geisinger and of heart failure from Sutter Health to: (1) characterize the patterns of missingness in laboratory variables; (2) simulate two missing mechanisms, arbitrary and monotone; (3) compare cross-sectional and multi-level multivariate missing imputation algorithms applied to laboratory data; (4) assess whether incorporation of latent information, derived from comorbidity data, can improve the performance of the algorithms. The latter was based on a case study of hemoglobin A1c under a univariate missing imputation framework. Overall, the pattern of missingness in EHR laboratory variables was not at random and was highly associated with patients' comorbidity data; and the multi-level imputation algorithm showed smaller imputation error than the cross-sectional method.",
      "authors": "Li Jiang; Yan Xiaowei S; Chaudhary Durgesh; Avula Venkatesh; Mudiganti Satish; Husby Hannah; Shahjouei Shima; Afshar Ardavan; Stewart Walter F; Yeasin Mohammed; Zand Ramin; Abedi Vida",
      "year": "2021",
      "journal": "NPJ digital medicine",
      "doi": "10.1038/s41746-021-00518-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34635760/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC8505441"
    },
    {
      "pmid": "36803893",
      "title": "Make it or break it: On-time vaccination intent at the time of Covid-19.",
      "abstract": "On-time effective vaccination is critical to curbing a pandemic, but this is often hampered by citizens' hesitancy to get quickly vaccinated. This research concentrates on the hypothesis that, besides traditional factors in the literature, vaccination success would hinge on two dimensions: a) addressing a broader set of risk perception factors than health-related issues only, and b) securing sufficient social and institutional trust at the time of vaccination campaign launch. We test this hypothesis regarding Covid-19 vaccination preferences in six European countries and at the early stage of the pandemic by April 2020. We find that addressing the two roadblock dimensions could further boost Covid-19 vaccination coverage by 22%. The study also offers three extra innovations. The first is that the traditional segmentation logic between vaccine \"acceptors\", \"hesitants\" and \"refusers\" is further justified by the fact that segments have different attitudes: refusers care less about health issues than they are worried about family tensions and finance (dimension 1 of our hypothesis). In contrast, hesitants are the battlefield for more transparency by media and government actions (dimension 2 of our hypothesis). The second added value is that we extend our hypothesis testing with a supervised non-parametric machine learning technique (Random Forests). Again, consistent with our hypothesis, this method picks up higher-order interaction between risk and trust variables that strongly predict on-time vaccination intent. We finally explicitly adjust survey responses to account for possible reporting bias. Among others, vaccine-reluctant citizens may under-report their limited will to get vaccinated.",
      "authors": "Bughin Jacques; Cincera Michele; Peters Kelly; Reykowska Dorota; \u017byszkiewicz Marcin; Ohme Rafal",
      "year": "2023",
      "journal": "Vaccine",
      "doi": "10.1016/j.vaccine.2023.02.014",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36803893/",
      "mesh_terms": "Humans; COVID-19; COVID-19 Vaccines; Vaccination; Intention; Emotions",
      "keywords": "Covid-19; Machine Learning; Random-forest; Social trust; Vaccine strategy",
      "pub_types": "Journal Article",
      "pmcid": "PMC9905100"
    },
    {
      "pmid": "32090211",
      "title": "Learning Personalized Treatment Rules from Electronic Health Records Using Topic Modeling Feature Extraction.",
      "abstract": "To address substantial heterogeneity in patient response to treatment of chronic disorders and achieve the promise of precision medicine, individualized treatment rules (ITRs) are estimated to tailor treatments according to patient-specific characteristics. Randomized controlled trials (RCTs) provide gold standard data for learning ITRs not subject to confounding bias. However, RCTs are often conducted under stringent inclusion/exclusion criteria, and participants in RCTs may not reflect the general patient population. Thus, ITRs learned from RCTs lack generalizability to the broader real world patient population. Real world databases such as electronic health records (EHRs) provide new resources as complements to RCTs to facilitate evidence-based research for personalized medicine. However, to ensure the validity of ITRs learned from EHRs, a number of challenges including confounding bias and selection bias must be addressed. In this work, we propose a matching-based machine learning method to estimate optimal individualized treatment rules from EHRs using interpretable features extracted from EHR documentation of medications and ICD diagnoses codes. We use a latent Dirichlet allocation (LDA) model to extract latent topics and weights as features for learning ITRs. Our method achieves confounding reduction in observational studies through matching treated and untreated individuals and improves treatment optimization by augmenting feature space with clinically meaningful LDA-based features. We apply the method to EHR data collected at New York Presbyterian Hospital clinical data warehouse in studying optimal second-line treatment for type 2 diabetes (T2D) patients. We use cross validation to show that ITRs outperforms uniform treatment strategies (i.e., assigning same treatment to all individuals), and including topic modeling features leads to more reduction of post-treatment complications.",
      "authors": "Wu Peng; Xu Tianchen; Wang Yuanjia",
      "year": "2019",
      "journal": "Proceedings of the ... International Conference on Data Science and Advanced Analytics. IEEE International Conference on Data Science and Advanced Analytics",
      "doi": "10.1109/dsaa.2019.00054",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32090211/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC7035126"
    },
    {
      "pmid": "33108374",
      "title": "Assessing concerns for the economic consequence of the COVID-19 response and mental health problems associated with economic vulnerability and negative economic shock in Italy, Spain, and the United Kingdom.",
      "abstract": "Many different countries have been under lockdown or extreme social distancing measures to control the spread of COVID-19. The potentially far-reaching side effects of these measures have not yet been fully understood. In this study we analyse the results of a multi-country survey conducted in Italy (N = 3,504), Spain (N = 3,524) and the United Kingdom (N = 3,523), with two separate analyses. In the first analysis, we examine the elicitation of citizens' concerns over the downplaying of the economic consequences of the lockdown during the COVID-19 pandemic. We control for Social Desirability Bias through a list experiment included in the survey. In the second analysis, we examine the data from the same survey to predict the level of stress, anxiety and depression associated with being economically vulnerable and having been affected by a negative economic shock. To accomplish this, we have used a prediction algorithm based on machine learning techniques. To quantify the size of this affected population, we compare its magnitude with the number of people affected by COVID-19 using measures of susceptibility, vulnerability and behavioural change collected in the same questionnaire. We find that the concern for the economy and for \"the way out\" of the lockdown is diffuse and there is evidence of minor underreporting. Additionally, we estimate that around 42.8% of the populations in the three countries are at high risk of stress, anxiety, and depression, based on their level of economic vulnerability and their exposure to a negative economic shock.",
      "authors": "Codagnone Cristiano; Bogliacino Francesco; G\u00f3mez Camilo; Charris Rafael; Montealegre Felipe; Liva Giovanni; Lupi\u00e1\u00f1ez-Villanueva Francisco; Folkvord Frans; Veltri Giuseppe A",
      "year": "2020",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0240876",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33108374/",
      "mesh_terms": "Adolescent; Adult; Aged; Anxiety; Betacoronavirus; COVID-19; Communicable Disease Control; Coronavirus Infections; Depression; Economic Recession; Female; Humans; Italy; Male; Mental Disorders; Middle Aged; Pandemics; Pneumonia, Viral; Principal Component Analysis; Quarantine; SARS-CoV-2; Spain; Stress, Psychological; Surveys and Questionnaires; United Kingdom; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7591048"
    },
    {
      "pmid": "40023505",
      "title": "Using Machine Learning to Identify Social Determinants of Health that Impact Discharge Disposition for Hospitalized Patients.",
      "abstract": "OBJECTIVE: To identify self-reported social determinants of health (SDOH) among hospitalized patients that predict discharge to a skilled nursing facility (SNF). DESIGN: A retrospective cohort analysis of 134,807 hospitalized patients from electronic medical records. SETTING AND PARTICIPANTS: All patients admitted to hospitals within a large multistate tertiary health system. METHODS: The primary outcome was hospital disposition (home discharge vs SNF). The cohort was split into derivation and validation sets (75/25). We adopted 2 regularized regression-based statistical approaches, namely, the stacked elastic net (SENET) and bootstrap imputation-stability selection (BISS), to implement variable selection with incomplete data. After variable selection, logistic regression with the selected variables was conducted to create the final predictive model. The prediction accuracy and model fairness were evaluated on the test dataset using the area under the curve (AUC), equal AUC, and calibration. RESULTS: In the sample, 8.72% of patients were discharged to an SNF. The final models included between 11 and 15 variables. Significant SDOH variables included alcohol consumption, dental check, employment status, financial resources, nutrition, physical activities, social connection, and transportation needs. The final models also included 1 clinical (Charlson Comorbidity Index) and 2 demographic (marital status and education level) characteristics. The final models were confirmed across methods and datasets, predicted well in the validation cohort (AUC around 0.77), and were well calibrated. CONCLUSIONS AND IMPLICATIONS: Multiple SDOH characteristics predict SNF disposition, especially the lack of a life partner or spouse, are potentially mitigable (nutrition, physical activities, and transportation needs), and offer actionable targets to increase home discharge rates. The collection and integration of SDOH data may optimize the appropriateness and efficiency discharge planning.",
      "authors": "Ren He; Wang Chun; Weiss David J; Bowles Kathryn; Xu Gongjun; Keeney Tamra; Cheville Andrea L",
      "year": "2025",
      "journal": "Journal of the American Medical Directors Association",
      "doi": "10.1016/j.jamda.2025.105524",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40023505/",
      "mesh_terms": "Humans; Patient Discharge; Male; Female; Social Determinants of Health; Machine Learning; Retrospective Studies; Aged; Middle Aged; Skilled Nursing Facilities; Aged, 80 and over; Hospitalization",
      "keywords": "Social determinants of health; discharge prediction; home discharge; hospital outcomes; post-acute care; skilled nursing facility",
      "pub_types": "Journal Article",
      "pmcid": "PMC12086869"
    },
    {
      "pmid": "41078689",
      "title": "Real-World Evidence: Methodologies for Integrating Real-World Data into Clinical Research Frameworks.",
      "abstract": "Real-world evidence (RWE), derived from real-world data (RWD), is transforming clinical research by complementing traditional randomized controlled trials. With diverse data sources such as electronic health records, patient registries, and wearable devices, RWE offers insights that reflect everyday clinical practice. Despite challenges like unstructured data, bias, and privacy concerns, advances in artificial intelligence, machine learning, and data standardization enable meaningful analysis. Regulatory frameworks, including India's Digital Personal Data Protection Act, reinforce ethical use of patient data. By refining methodologies and fostering collaboration, RWE provides valuable evidence for regulatory decisions, personalized medicine, and enhanced patient care outcomes.",
      "authors": "Kale Sachin; Vatkar Arvind; Gehilot Ojasv; Shyam Ashok",
      "year": "2025",
      "journal": "Journal of orthopaedic case reports",
      "doi": "10.13107/jocr.2025.v15.i10.6138",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41078689/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Clinical research; Personalized medicine; Real-world data; Real-world evidence",
      "pub_types": "Editorial",
      "pmcid": "PMC12514902"
    },
    {
      "pmid": "28293864",
      "title": "Using Probabilistic Record Linkage of Structured and Unstructured Data to Identify Duplicate Cases in Spontaneous Adverse Event Reporting Systems.",
      "abstract": "INTRODUCTION: Duplicate case reports in spontaneous adverse event reporting systems pose a challenge for medical reviewers to efficiently perform individual and aggregate safety analyses. Duplicate cases can bias data mining by generating spurious signals of disproportional reporting of product-adverse event pairs. OBJECTIVE: We have developed a probabilistic record linkage algorithm for identifying duplicate cases in the US Vaccine Adverse Event Reporting System (VAERS) and the US Food and Drug Administration Adverse Event Reporting System (FAERS). METHODS: In addition to using structured field data, the algorithm incorporates the non-structured narrative text of adverse event reports by examining clinical and temporal information extracted by the Event-based Text-mining of Health Electronic Records system, a natural language processing tool. The final component of the algorithm is a novel duplicate confidence value that is calculated by a rule-based empirical approach that looks for similarities in a number of criteria between two case reports. RESULTS: For VAERS, the algorithm identified 77% of known duplicate pairs with a precision (or positive predictive value) of 95%. For FAERS, it identified 13% of known duplicate pairs with a precision of 100%. The textual information did not improve the algorithm's automated classification for VAERS or FAERS. The empirical duplicate confidence value increased performance on both VAERS and FAERS, mainly by reducing the occurrence of false-positives. CONCLUSIONS: The algorithm was shown to be effective at identifying pre-linked duplicate VAERS reports. The narrative text was not shown to be a key component in the automated detection evaluation; however, it is essential for supporting the semi-automated approach that is likely to be deployed at the Food and Drug Administration, where medical reviewers will perform some manual review of the most highly ranked reports identified by the algorithm.",
      "authors": "Kreimeyer Kory; Menschik David; Winiecki Scott; Paul Wendy; Barash Faith; Woo Emily Jane; Alimchandani Meghna; Arya Deepa; Zinderman Craig; Forshee Richard; Botsis Taxiarchis",
      "year": "2017",
      "journal": "Drug safety",
      "doi": "10.1007/s40264-017-0523-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28293864/",
      "mesh_terms": "Adverse Drug Reaction Reporting Systems; Data Interpretation, Statistical; Data Mining; Databases, Factual; Humans; United States",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40930127",
      "title": "The Role of Generative Artificial Intelligence and Large Language Models in Atrial Fibrillation: Clinical Research and Decision Support.",
      "abstract": "Atrial fibrillation (AF) is a prevalent and complex cardiac arrhythmia requiring multifaceted management strategies. This review explores the integration of large language models (LLMs) and machine learning into AF care, with a focus on clinical utility, privacy preservation, and ethical deployment. Federated and transfer learning methods have enabled high-performance predictive modeling across distributed datasets without compromising data security. LLMs enhance decision-making by synthesizing structured and unstructured data within electronic health records, supporting anticoagulation decisions, risk stratification, and treatment optimization. Additionally, these tools reduce clinician burden through automated documentation and improve patient engagement via personalized communication, chatbots, and remote monitoring platforms. Despite promising outcomes, challenges such as algorithmic bias, hallucinations, outdated knowledge, and limited explainability persist. Regulatory frameworks remain underdeveloped for continuously learning models, necessitating stronger oversight. Future directions emphasize the creation of cardiology-specific LLMs, multimodal data integration, and inclusive co-development with stakeholders. Overall, artificial intelligence-enabled tools show significant potential to improve precision, efficiency, and equity in AF care, provided their deployment remains ethically grounded and clinically validated.",
      "authors": "Tran Hadrian Hoang-Vu; Thu Audrey; Twayana Anu Radha; Fuertes Axel; Gonzalez Marco; Basta Marina; James Maggie; Frishman William H; Aronow Wilbert S",
      "year": "2025",
      "journal": "Cardiology in review",
      "doi": "10.1097/CRD.0000000000001042",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40930127/",
      "mesh_terms": "",
      "keywords": "algorithmic bias; artificial intelligence; atrial fibrillation; cardiovascular informatics; clinical decision support; explainability; federated learning; large language models; patient engagement; remote monitoring",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "31830096",
      "title": "Pediatric trainees systematically under-report duty hour violations compared to electronic health record defined shifts.",
      "abstract": "Duty hour monitoring is required in accredited training programs, however trainee self-reporting is onerous and vulnerable to bias. The objectives of this study were to use an automated, validated algorithm to measure duty hour violations of pediatric trainees over a full academic year and compare to self-reported violations. Duty hour violations calculated from electronic health record (EHR) logs varied significantly by trainee role and rotation. Block-by-block differences show 36.8% (222/603) of resident-blocks with more EHR-defined violations (EDV) compared to self-reported violations (SRV), demonstrating systematic under-reporting of duty hour violations. Automated duty hour tracking could provide real-time, objective assessment of the trainee work environment, allowing program directors and accrediting organizations to design and test interventions focused on improving educational quality.",
      "authors": "Dziorny Adam C; Orenstein Evan W; Lindell Robert B; Hames Nicole A; Washington Nicole; Desai Bimal",
      "year": "2019",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0226493",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31830096/",
      "mesh_terms": "Electronic Health Records; Guideline Adherence; Humans; Internship and Residency; Pediatrics; Personnel Staffing and Scheduling; Quality Improvement; Self Report; Surveys and Questionnaires; Training Support; Work Schedule Tolerance",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC6907762"
    },
    {
      "pmid": "39565746",
      "title": "Comparing the performance of screening surveys versus predictive models in identifying patients in need of health-related social need services in the emergency department.",
      "abstract": "BACKGROUND: Health-related social needs (HRSNs), such as housing instability, food insecurity, and financial strain, are increasingly prevalent among patients. Healthcare organizations must first correctly identify patients with HRSNs to refer them to appropriate services or offer resources to address their HRSNs. Yet, current identification methods are suboptimal, inconsistently applied, and cost prohibitive. Machine learning (ML) predictive modeling applied to existing data sources may be a solution to systematically and effectively identify patients with HRSNs. The performance of ML predictive models using data from electronic health records (EHRs) and other sources has not been compared to other methods of identifying patients needing HRSN services. METHODS: A screening questionnaire that included housing instability, food insecurity, transportation barriers, legal issues, and financial strain was administered to adult ED patients at a large safety-net hospital in the mid-Western United States (n = 1,101). We identified those patients likely in need of HRSN-related services within the next 30 days using positive indications from referrals, encounters, scheduling data, orders, or clinical notes. We built an XGBoost classification algorithm using responses from the screening questionnaire to predict HRSN needs (screening questionnaire model). Additionally, we extracted features from the past 12 months of existing EHR, administrative, and health information exchange data for the survey respondents. We built ML predictive models with these EHR data using XGBoost (ML EHR model). Out of concerns of potential bias, we built both the screening question model and the ML EHR model with and without demographic features. Models were assessed on the validation set using sensitivity, specificity, and Area Under the Curve (AUC) values. Models were compared using the Delong test. RESULTS: Almost half (41%) of the patients had a positive indicator for a likely HRSN service need within the next 30 days, as identified through referrals, encounters, scheduling data, orders, or clinical notes. The screening question model had suboptimal performance, with an AUC = 0.580 (95%CI = 0.546, 0.611). Including gender and age resulted in higher performance in the screening question model (AUC = 0.640; 95%CI = 0.609, 0.672). The ML EHR models had higher performance. Without including age and gender, the ML EHR model had an AUC = 0.765 (95%CI = 0.737, 0.792). Adding age and gender did not improve the model (AUC = 0.722; 95%CI = 0.744, 0.800). The screening questionnaire models indicated bias with the highest performance for White non-Hispanic patients. The performance of the ML EHR-based model also differed by race and ethnicity. CONCLUSION: ML predictive models leveraging several robust EHR data sources outperformed models using screening questions only. Nevertheless, all models indicated biases. Additional work is needed to design predictive models for effectively identifying all patients with HRSNs.",
      "authors": "Mazurenko Olena; Hirsh Adam T; Harle Christopher A; Shen Joanna; McNamee Cassidy; Vest Joshua R",
      "year": "2024",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0312193",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39565746/",
      "mesh_terms": "Humans; Emergency Service, Hospital; Female; Male; Middle Aged; Surveys and Questionnaires; Adult; Machine Learning; Electronic Health Records; Health Services Needs and Demand; Aged; Mass Screening",
      "keywords": "",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": "PMC11578524"
    },
    {
      "pmid": "36085794",
      "title": "Walking and running cadence estimation using a single trunk-fixed accelerometer for daily physical activities assessment.",
      "abstract": "Accurate assessment of the type, duration, and intensity of physical activity (PA) in daily life is considered very important because of the close relationship between PA level, health, and well-being. Therefore, the assessment of PA using lightweight wearable sensors has gained interest in recent years. In particular, the use of activity monitors could help to measure the health-related effects of specific PA interventions. Our study, named as Run4Vit, focuses on evaluating the acute and longterm effects of an eight-week running intervention on PA behaviour and vitality. To achieve this goal, we developed an algorithm to detect running and estimate instantaneous cadence using a single trunk-fixed accelerometer. Cadence was computed using time and frequency domain approaches. Validation was performed over a wide range of locomotion speeds using an open-source gait database. Across all subjects, the cadence estimation algorithms achieved a mean bias and precision of - 0.01 \u00b1 0.69 steps/min for the temporal method and 0.02 \u00b1 1.33 steps/min for the frequency method. The running detection algorithm demonstrated very good performance, with an accuracy of 98% and a precision superior to 99%. These algorithms could be used to extract metrics related to the multiple dimensions of PA, and provide reliable outcome measures for the Run4Vit longitudinal running intervention program. Clinical Relevance- This work aims at validating a multi-dimensional physical activity (PA) classification algorithm for assessing the acute and long-term effects of eight weeks running intervention on PA behaviours and vitality.",
      "authors": "Prigent G; Barthelet E; Aminian K; Paraschiv-Ionescu A",
      "year": "2022",
      "journal": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference",
      "doi": "10.1109/EMBC48229.2022.9871713",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36085794/",
      "mesh_terms": "Accelerometry; Exercise; Fitness Trackers; Gait; Humans; Walking",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "24283337",
      "title": "Influence of parameter values and variances and algorithm architecture in ConsExpo model on modeled exposures.",
      "abstract": "This study evaluated the influence of parameter values and variances and model architecture on modeled exposures, and identified important data gaps that influence lack-of-knowledge-related uncertainty, using Consexpo 4.1 as an illustrative case study. Understanding the influential determinants in exposure estimates enables more informed and appropriate use of this model and the resulting exposure estimates. In exploring the influence of parameter placement in an algorithm and of the values and variances chosen to characterize the parameters within ConsExpo, \"sensitive\" and \"important\" parameters were identified: product amount, weight fraction, exposure duration, exposure time, and ventilation rate were deemed \"important,\" or \"always sensitive.\" With this awareness, exposure assessors can strategically focus on acquiring the most robust estimates for these parameters. ConsExpo relies predominantly on three algorithms to assess the default scenarios: inhalation vapors evaporation equation using the Langmuir mass transfer, the dermal instant application with diffusion through the skin, and the oral ingestion by direct uptake algorithm. These algorithms, which do not necessarily render health conservative estimates, account for 87, 89 and 59% of the inhalation, dermal and oral default scenario assessments,respectively, according them greater influence relative to the less frequently used algorithms. Default data provided in ConsExpo may be useful to initiate assessments, but are insufficient for determining exposure acceptability or setting policy, as parameters defined by highly uncertain values produce biased estimates that may not be health conservative. Furthermore, this lack-of-knowledge uncertainty makes the magnitude of this bias uncertain. Significant data gaps persist for product amount, exposure time, and exposure duration. These \"important\" parameters exert influence in requiring broad values and variances to account for their uncertainty. Prioritizing them for research will not only help fill a large and influential knowledge gap, but also lead to more accurate assessments and thus refine the studies informing policy decisions.",
      "authors": "Arnold Susan F; Ramachandran Gurumurthy",
      "year": "2014",
      "journal": "Journal of occupational and environmental hygiene",
      "doi": "10.1080/15459624.2013.816430",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24283337/",
      "mesh_terms": "Air Pollution, Indoor; Algorithms; Computer Simulation; Eating; Household Products; Humans; Inhalation Exposure; Models, Theoretical; Skin Absorption; Uncertainty",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38400459",
      "title": "Mobile Data Gathering and Preliminary Analysis for the Functional Reach Test.",
      "abstract": "The functional reach test (FRT) is a clinical tool used to evaluate dynamic balance and fall risk in older adults and those with certain neurological diseases. It provides crucial information for developing rehabilitation programs to improve balance and reduce fall risk. This paper aims to describe a new tool to gather and analyze the data from inertial sensors to allow automation and increased reliability in the future by removing practitioner bias and facilitating the FRT procedure. A new tool for gathering and analyzing data from inertial sensors has been developed to remove practitioner bias and streamline the FRT procedure. The study involved 54 senior citizens using smartphones with sensors to execute FRT. The methods included using a mobile app to gather data, using sensor-fusion algorithms like the Madgwick algorithm to estimate orientation, and attempting to estimate location by twice integrating accelerometer data. However, accurate position estimation was difficult, highlighting the need for more research and development. The study highlights the benefits and drawbacks of automated balance assessment testing with mobile device sensors, highlighting the potential of technology to enhance conventional health evaluations.",
      "authors": "Francisco Lu\u00eds; Duarte Jo\u00e3o; Albuquerque Carlos; Albuquerque Daniel; Pires Ivan Miguel; Coelho Paulo Jorge",
      "year": "2024",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s24041301",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38400459/",
      "mesh_terms": "Humans; Aged; Reproducibility of Results; Algorithms; Smartphone; Mobile Applications; Nervous System Diseases",
      "keywords": "functional reach test; inertial sensors; monitoring apps; smart wearables",
      "pub_types": "Journal Article",
      "pmcid": "PMC10892343"
    },
    {
      "pmid": "38890798",
      "title": "Health consumers' ethical concerns towards artificial intelligence in Australian emergency departments.",
      "abstract": "OBJECTIVES: To investigate health consumers' ethical concerns towards the use of artificial intelligence (AI) in EDs. METHODS: Qualitative semi-structured interviews with health consumers, recruited via health consumer networks and community groups, interviews conducted between January and August 2022. RESULTS: We interviewed 28 health consumers about their perceptions towards the ethical use of AI in EDs. The results discussed in this paper highlight the challenges and barriers for the effective and ethical implementation of AI from the perspective of Australian health consumers. Most health consumers are more likely to support AI health tools in EDs if they continue to be involved in the decision-making process. There is considerably more approval of AI tools that support clinical decision-making, as opposed to replacing it. There is mixed sentiment about the acceptability of AI tools influencing clinical decision-making and judgement. Health consumers are mostly supportive of the use of their data to train and develop AI tools but are concerned with who has access. Addressing bias and discrimination in AI is an important consideration for some health consumers. Robust regulation and governance are critical for health consumers to trust and accept the use of AI. CONCLUSION: Health consumers view AI as an emerging technology that they want to see comprehensively regulated to ensure it functions safely and securely with EDs. Without considerations made for the ethical design, implementation and use of AI technologies, health consumer trust and acceptance in the use of these tools will be limited.",
      "authors": "Freeman Sam; Stewart Jonathon; Kaard Rebecca; Ouliel Eden; Goudie Adrian; Dwivedi Girish; Akhlaghi Hamed",
      "year": "2024",
      "journal": "Emergency medicine Australasia : EMA",
      "doi": "10.1111/1742-6723.14449",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38890798/",
      "mesh_terms": "Humans; Artificial Intelligence; Emergency Service, Hospital; Australia; Qualitative Research; Male; Female; Adult; Middle Aged; Interviews as Topic; Aged",
      "keywords": "artificial intelligence; emergency medicine; ethics; health consumers; machine learning; qualitative research",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33407254",
      "title": "\"AI's gonna have an impact on everything in society, so it has to have an impact on public health\": a fundamental qualitative descriptive study of the implications of artificial intelligence for public health.",
      "abstract": "BACKGROUND: Our objective was to determine the impacts of artificial intelligence (AI) on public health practice. METHODS: We used a fundamental qualitative descriptive study design, enrolling 15 experts in public health and AI from June 2018 until July 2019 who worked in North America and Asia. We conducted in-depth semi-structured interviews, iteratively coded the resulting transcripts, and analyzed the results thematically. RESULTS: We developed 137 codes, from which nine themes emerged. The themes included opportunities such as leveraging big data and improving interventions; barriers to adoption such as confusion regarding AI's applicability, limited capacity, and poor data quality; and risks such as propagation of bias, exacerbation of inequity, hype, and poor regulation. CONCLUSIONS: Experts are cautiously optimistic about AI's impacts on public health practice, particularly for improving disease surveillance. However, they perceived substantial barriers, such as a lack of available expertise, and risks, including inadequate regulation. Therefore, investment and research into AI for public health practice would likely be beneficial. However, increased access to high-quality data, research and education regarding the limitations of AI, and development of rigorous regulation are necessary to realize these benefits.",
      "authors": "Morgenstern Jason D; Rosella Laura C; Daley Mark J; Goel Vivek; Sch\u00fcnemann Holger J; Piggott Thomas",
      "year": "2021",
      "journal": "BMC public health",
      "doi": "10.1186/s12889-020-10030-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33407254/",
      "mesh_terms": "Artificial Intelligence; Asia; Big Data; Humans; North America; Public Health",
      "keywords": "Big data; Community medicine; Epidemiology; Machine learning; Population health; Preventive medicine; Qualitative",
      "pub_types": "Journal Article",
      "pmcid": "PMC7787411"
    },
    {
      "pmid": "41246939",
      "title": "Marginal structural models for quantifying the causal effects of exposure to ambient air pollution on progression of CT emphysema in the MESA Lung and MESA Air Studies.",
      "abstract": "Associations between exposure to ambient air pollution and progression of emphysema have been identified in longitudinal observational studies. However, previous work has not used statistical causal inference methods tailored to address bias from time-varying confounding. The objective of this study is to propose an analytical approach for estimating longitudinal health effects of air pollution while accounting for time-varying confounding using marginal structural models and to re-analyze data on air pollution and emphysema progression from the Multi-Ethnic Study of Atherosclerosis (MESA) using this analytical approach. We estimate weights for continuous exposure levels using two techniques: quantile binning of the exposure and a semiparametric model for the requisite conditional densities. The latter approach incorporates flexible machine learning methods. We find evidence for the harmful effects of ambient ozone pollution during study follow-up on the progression of emphysema, consistent with previously reported results. We find no evidence of effects of NOx during study follow-up. This investigation demonstrates that analyses based on marginal structural models are feasible in studies of the health effects of air pollution and may address possible sources of bias that traditional regression-based methods fail to address. Further investigation is warranted to understand differences between our findings and previously published results.",
      "authors": "Malinsky Daniel; Wang Meng; Heise Rachel; Pistenmaa Carrie L; Hoffman Eric A; Sheppard Lianne; Szpiro Adam A; Laine Andrew; Angelini Elsa; Smith Benjamin M; Kaufman Joel D; Barr R Graham",
      "year": "2025",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwaf252",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41246939/",
      "mesh_terms": "",
      "keywords": "Air Pollution; Causal Inference; Emphysema",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32084102",
      "title": "Application of Behavioral Risk Factor Surveillance System Sampling Weights to Transgender Health Measurement.",
      "abstract": "BACKGROUND: Obtaining representative data from the transgender population is fundamental to improving their health and well-being and advancing transgender health research. The addition of the Behavioral Risk Factor Surveillance System (BRFSS) gender identity measure is a promising step toward better understanding transgender health. However, methodological concerns have emerged regarding the validity of data collected from transgender participants and its effect on the accuracy of population parameters derived from those data. OBJECTIVES: The aim of the study was to provide rationale substantiating concerns with the formulation and application of the 2015 BRFSS sampling weights and address the methodological challenges that arise when using this surveillance data to study transgender population health. METHODS: We examined the 2015 BRFSS methodology and used the BRFSS data to present a comparison of poor health status using two methodological approaches (a matched-subject design and the full BRFSS sample with sampling weights applied) to compare their effects on parameter estimates. RESULTS: Measurement error engendered by BRFSS data collection procedures introduced sex/gender identity discordance and contributed to problematic sampling weights. The sex-specific \"raking\" algorithm used by BRFSS to calculate the sampling weights was contingent on the classification accuracy of transgender by participants. Because of the sex/gender identity discordance of 74% of the transgender women and 66% of transgender men, sampling weights may not be able to adequately remove bias. The application of sampling weights has the potential to result in inaccurate parameter estimates when evaluating factors that may influence transgender health. DISCUSSION: Generalizations made from the weighted analysis may obscure the need for healthcare policy and clinical interventions aimed to promote health and prevent illness for transgender adults. Methods of public health surveillance and population surveys should be reviewed to help reduce systematic bias and increase the validity of data collected from transgender people.",
      "authors": "Cicero Ethan C; Reisner Sari L; Merwin Elizabeth I; Humphreys Janice C; Silva Susan G",
      "year": "2020",
      "journal": "Nursing research",
      "doi": "10.1097/NNR.0000000000000428",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32084102/",
      "mesh_terms": "Adult; Behavioral Risk Factor Surveillance System; Bias; Female; Health Status; Humans; Male; Middle Aged; Public Health Surveillance; Transgender Persons",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7329606"
    },
    {
      "pmid": "41243596",
      "title": "Adaptive modelling approach for predicting causes of death: insights from verbal autopsy data in Tanzania.",
      "abstract": "BACKGROUND: The World Health Organization (WHO) has approved the use of a verbal autopsy (VA), a survey-based approach to generate out-of-hospital causes of death (CoDs). Through this study, an adaptive Bayesian networks machine learning model was developed and tested. The model is scalable and adaptable for predicting new causes as the dataset expands. METHODS: The 2016 WHO questionnaire was used to collect data from Iringa, Tanzania, and data augmentation was performed using the Synthetic Minority Oversampling Technique for nominal features to increase the dataset size and reduce bias in the CoD classification. The model development was guided by a CoD decision flow that integrates essential factors and steps for accurate CoD prediction. To our knowledge, no previous study has provided this operational guide for VA cause of death prediction. RESULTS: The model was evaluated using accuracy, sensitivity, specificity and F1 score metrics and compared with Support Vector Machine and Na\u00efve Bayesian models. Results indicated an average accuracy of 97%, specificity of 97%, sensitivity of 94% and F1 score of 94%, which are superior compared with Na\u00efve Bayesian and Support Vector Machine models. CONCLUSIONS: The reported performance of the developed model demonstrates the potential for this model to enhance VA-based CoD data by integrating a machine learning approach with physician expertise. The results highlight the effectiveness of combining Bayesian networks with physician Symptom Cause Information as a valuable tool in advancing the performance of CoD predictions.",
      "authors": "Tunga Mahadia; Chambua James; Lungo Juma",
      "year": "2026",
      "journal": "International health",
      "doi": "10.1093/inthealth/ihaf123",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41243596/",
      "mesh_terms": "Humans; Tanzania; Bayes Theorem; Cause of Death; Autopsy; Male; Machine Learning; Female; Surveys and Questionnaires; Adult; Support Vector Machine; World Health Organization; Sensitivity and Specificity; Middle Aged; Young Adult",
      "keywords": "Bayesian model; VA machine learning model; VA model; WHO VA questionnaire; cause of death prediction; verbal autopsy",
      "pub_types": "Journal Article",
      "pmcid": "PMC12766446"
    },
    {
      "pmid": "26180664",
      "title": "Validity Assessment of Referral Decisions at a VA Health Care System Polytrauma System of Care.",
      "abstract": "There has been intensive interest to ensure equitable and appropriate access to the specialized rehabilitative services of the VA Polytrauma System of Care (PSC) for patients sustaining polytrauma and traumatic brain injuries (TBI).\u00a0A retrospective cohort study with prospective data acquisition was conducted to assess validity and objectivity of the acceptance decision algorithm to the VA Palo Alto Health Care System (VAPAHCS) PSC.\u00a0Our hypotheses are\u00a0(1) VAPAHCS PSC referral decisions were appropriate and without bias and (2) the identified needs of redirected referrals were addressed.\u00a0This analysis included 1,025 referrals (906 patients); 813 patients (89.7%) were accepted, and 93 (10.3%) were redirected. Redirected cases were older, were more often active duty service members, and were not from the West Coast.\u00a0There were more females redirected due to concomitant spinal cord injury. These are rationale differences.\u00a0In redirected patients, the most commonly identified rehabilitation needs were psychological support, mobility/physical therapy, and communication/speech services; >75% of patients had these services offered elsewhere outside of the PSC resources.\u00a0While balancing financial stewardship and meeting our mission to provide outstanding rehabilitative care to veterans and service members, we demonstrated that acceptance decisions were valid and without bias, and redirected patients received appropriate alternate resources.",
      "authors": "Chung Joyce; Aguila Fatima; Harris Odette",
      "year": "2015",
      "journal": "Cureus",
      "doi": "10.7759/cureus.240",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26180664/",
      "mesh_terms": "",
      "keywords": "admissions; decision-making; military; polytrauma; referrals; rehabilitation; rehabilitation needs; resources; traumatic brain injury; veterans",
      "pub_types": "Journal Article",
      "pmcid": "PMC4494525"
    },
    {
      "pmid": "40862617",
      "title": "Comparing Comorbidities of Older Adults With Opiate Use Disorder by Race and Ethnicity.",
      "abstract": "Older adult Blacks have more opioid related deaths and medical problems than their White and Latino peers. The purpose of this study was to identify the differences of co-occurring medical conditions in older patients with opiate use disorder by race and ethnicity. It is a follow-up retrospective study that utilized a computer algorithm employed by a network of 43 Federally Qualified Health Centers in New York State to collect health record data on persons aged 55 and older with an opiate use disorder diagnosis from March 2020 to August 2020. The results are that older adult Blacks had higher incidences of heart or circulatory disorders, anemia, HIV/AIDS, and immunodeficiency than Whites or Latinos, but a lower incidence of a pain disorder diagnosis. While multiple factors account for these differences (e.g., cultural factors and social determinants of health) and provider bias should also be considered.",
      "authors": "Baumann Steven L; Samuels William Ellery",
      "year": "2025",
      "journal": "Journal of addictions nursing",
      "doi": "10.1097/JAN.0000000000000633",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40862617/",
      "mesh_terms": "Aged; Female; Humans; Male; Middle Aged; Black or African American; Comorbidity; Ethnicity; Hispanic or Latino; New York; Opioid-Related Disorders; Racial Groups; Retrospective Studies; White",
      "keywords": "Comorbidities; Older Adults; Opiate Use Disorders; Race and Ethnicity",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": ""
    },
    {
      "pmid": "41099009",
      "title": "Predicting Cycloplegic Spherical Equivalent Refraction Among Children and Adolescents Using Non-cycloplegic Data and Machine Learning - China, 2020-2024.",
      "abstract": "INTRODUCTION: Cycloplegic refraction is the gold standard for assessing refractive error in children. However, logistical constraints hinder its implementation in large-scale surveys. METHODS: Data obtained from a nationwide ocular health survey conducted in ten provincial-level administrative divisions in China were analyzed (2020-2024). Participants aged 5-18 years underwent standardized non-cycloplegic and cycloplegic autorefraction, axial length (AL), corneal radius (CR), and AL/CR measurements. Random forest and XGBoost models were trained to predict the cycloplegic spherical equivalent (SE) using non-cycloplegic SE, uncorrected visual acuity (UCVA), and biometric parameters. Performance was evaluated using R2, root mean square error (RMSE), and Bland-Altman analysis. RESULTS: Both models exhibited strong predictive performance. In the test set, random forest achieved R2=0.88 and RMSE=0.55 diopter (D), whereas XGBoost achieved R2=0.89 and RMSE=0.54 D. Non-cycloplegic SE, AL/CR ratio, AL, and UCVA were consistently the top predictors. The predicted SE exhibited strong agreement with the cycloplegic SE, with minimal residual bias. CONCLUSION: Machine learning models incorporating noncycloplegic SE and ocular biometrics accurately estimate cycloplegic SE in children and adolescents, providing a practical alternative for large-scale refractive-error surveillance when cycloplegia is impractical.",
      "authors": "Liu Keke; Qin Ran; Luo Huijuan; Kuang Huining; E Ranbo; Zhang Chenyu; Sun Bingjie; Guo Xin",
      "year": "2025",
      "journal": "China CDC weekly",
      "doi": "10.46234/ccdcw2025.217",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41099009/",
      "mesh_terms": "",
      "keywords": "Cycloplegic refraction; machine learning; non-cycloplegic prediction; spherical equivalent",
      "pub_types": "Journal Article",
      "pmcid": "PMC12518965"
    },
    {
      "pmid": "38875060",
      "title": "A new method for identification of traditional Chinese medicine constitution based on tongue features with machine learning.",
      "abstract": "BACKGROUND: The theory of Chinese medicine (TCM) constitution contributes to the optimisation of individualised healthcare programmes. However, at present, TCM constitution identification mainly relies on inefficient questionnaires with subjective bias. Efficient and accurate TCM constitution identification can play an important role in individualised medicine and healthcare. OBJECTIVE: Building an efficient model for identifying traditional Chinese medicine constitutions using objective tongue features and machine learning techniques. METHODS: The DS01-A device was applied to collect tongue images and extract features. We trained and evaluated five machine learning models: Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), LightGBM (LGBM), and CatBoost (CB). Among these, we selected the model with the best performance as the base classifier for constructing our heterogeneous ensemble learning model. Using various performance metrics, including classification accuracy, precision, recall, F1 score, and area under curve (AUC), to comprehensively evaluate model performance. RESULTS: A total of 1149 tongue images were obtained and 45 features were extracted, forming dataset 1. RF, LGBM, and CB were selected as the base learners for the RLC-Stacking. On dataset 1, RLC-Stacking1 achieved an accuracy of 0.8122, outperforming individual classifiers. After feature selection, the classification accuracy of RLC-Stacking2 improved to 0.8287, an improvement of 0.00165 compared to RLC-Stacking1. RLC-Stacking2 achieved an accuracy exceeding 0.85 for identifying each TCM constitution type, indicating excellent identification performance. CONCLUSION: The study provides a reliable method for the accurate and rapid identification of TCM constitutions and can assist clinicians in tailoring individualized medical treatments based on personal constitution types and guide daily health care. The information extracted from tongue images serves as an effective marker for objective TCM constitution identification.",
      "authors": "Zhao Mei; Zhou Hengyu; Wang Jing; Liu Yongyue; Zhang Xiaoqing",
      "year": "2024",
      "journal": "Technology and health care : official journal of the European Society for Engineering and Medicine",
      "doi": "10.3233/THC-240128",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38875060/",
      "mesh_terms": "Humans; Tongue; Medicine, Chinese Traditional; Machine Learning; Support Vector Machine; Adult; Male; Female",
      "keywords": "Traditional Chinese Medicine Constitution; constitution identification; ensemble learning; machine learning; tongue features",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32973578",
      "title": "A Four-Step Method for the Development of an ADHD-VR Digital Game Diagnostic Tool Prototype for Children Using a DL Model.",
      "abstract": "Attention-deficit/hyperactivity disorder (ADHD) is a common neurodevelopmental disorder among children resulting in disturbances in their daily functioning. Virtual reality (VR) and machine learning technologies, such as deep learning (DL) application, are promising diagnostic tools for ADHD in the near future because VR provides stimuli to replace real stimuli and recreate experiences with high realism. It also creates a playful virtual environment and reduces stress in children. The DL model is a subset of machine learning that can transform input and output data into diagnostic values using convolutional neural network systems. By using a sensitive and specific ADHD-VR diagnostic tool prototype for children with DL model, ADHD can be diagnosed more easily and accurately, especially in places with few mental health resources or where tele-consultation is possible. To date, several virtual reality-continuous performance test (VR-CPT) diagnostic tools have been developed for ADHD; however, they do not include a machine learning or deep learning application. A diagnostic tool development study needs a trustworthy and applicable study design and conduct to ensure the completeness and transparency of the report of the accuracy of the diagnostic tool. The proposed four-step method is a mixed-method research design that combines qualitative and quantitative approaches to reduce bias and collect essential information to ensure the trustworthiness and relevance of the study findings. Therefore, this study aimed to present a brief review of a ADHD-VR digital game diagnostic tool prototype with a DL model for children and the proposed four-step method for its development.",
      "authors": "Wiguna Tjhin; Wigantara Ngurah Agung; Ismail Raden Irawati; Kaligis Fransiska; Minayati Kusuma; Bahana Raymond; Dirgantoro Bayu",
      "year": "2020",
      "journal": "Frontiers in psychiatry",
      "doi": "10.3389/fpsyt.2020.00829",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32973578/",
      "mesh_terms": "",
      "keywords": "Indonesia; attention-deficit/hyperactivity disorder; diagnostic tool; digital game; machine learning; neuropsychological test; virtual reality",
      "pub_types": "Journal Article",
      "pmcid": "PMC7461963"
    },
    {
      "pmid": "36366063",
      "title": "Digital Single-Image Smartphone Assessment of Total Body Fat and Abdominal Fat Using Machine Learning.",
      "abstract": "Background: Obesity is chronic health problem. Screening for the obesity phenotype is limited by the availability of practical methods. Methods: We determined the reproducibility and accuracy of an automated machine-learning method using smartphone camera-enabled capture and analysis of single, two-dimensional (2D) standing lateral digital images to estimate fat mass (FM) compared to dual X-ray absorptiometry (DXA) in females and males. We also report the first model to predict abdominal FM using 2D digital images. Results: Gender-specific 2D estimates of FM were significantly correlated (p < 0.001) with DXA FM values and not different (p > 0.05). Reproducibility of FM estimates was very high (R2 = 0.99) with high concordance (R2 = 0.99) and low absolute pure error (0.114 to 0.116 kg) and percent error (1.3 and 3%). Bland\u2212Altman plots revealed no proportional bias with limits of agreement of 4.9 to \u22124.3 kg and 3.9 to \u22124.9 kg for females and males, respectively. A novel 2D model to estimate abdominal (lumbar 2\u22125) FM produced high correlations (R2 = 0.99) and concordance (R2 = 0.99) compared to DXA abdominal FM values. Conclusions: A smartphone camera trained with machine learning and automated processing of 2D lateral standing digital images is an objective and valid method to estimate FM and, with proof of concept, to determine abdominal FM. It can facilitate practical identification of the obesity phenotype in adults.",
      "authors": "Farina Gian Luca; Orlandi Carmine; Lukaski Henry; Nescolarde Lexa",
      "year": "2022",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s22218365",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36366063/",
      "mesh_terms": "Male; Female; Humans; Body Composition; Electric Impedance; Body Mass Index; Smartphone; Reproducibility of Results; Absorptiometry, Photon; Obesity; Adipose Tissue; Abdominal Fat; Machine Learning",
      "keywords": "abdominal fat mass; fat mass; machine learning; smartphone camera; two-dimensional digital imaging",
      "pub_types": "Journal Article",
      "pmcid": "PMC9657201"
    },
    {
      "pmid": "40528447",
      "title": "Harnessing predictive analytics to support high-risk learners in a one-year certification program in emergency medicine (CPEM) in Pakistan.",
      "abstract": "INTRODUCTION: Predictive analytics and Machine Learning (PAML) are gaining traction in health professions education (HPE). Their utilization includes, but is not limited to, guiding student enrollment, identifying at-risk learners, enhancing educational decisions, and allocating proper resources through data-driven insights. This study explored the use of PAML to identify at-risk learners in a one-year Certification Program in Emergency Medicine (CPEM) at the Indus Hospital and Health Network (IHHN), Pakistan with the aim of providing targeted educational support for improved outcome. METHODOLOGY: By leveraging data from prior CPEM cohorts (2018-2022, n\u2009=\u200991), regression tree and linear regression machine learning models were compared to predict the final examination performance of the CPEM 2023 learner cohort (n\u2009=\u200926). The models were prospectively applied to identify at-risk learners (n\u2009=\u200914/26). Extra learning support (ELS) was offered as an inclusive measure to everyone, not just the ones flagged by the models and was accepted by ten learners. Data were analyzed for model accuracy and the impact of the educational intervention. RESULTS: Both models showed high accuracy (regression tree: Area Under the Receiver Operating Characteristic (ROC) Curve (AUC)= 0.89; linear regression: AUC= 0.88), though the regression tree model demonstrated slightly better sensitivity and specificity. The models altogether predicted unsatisfactory performance for 14 learners scheduled to sit for the 2023 final examination. Following targeted intervention, eight learners showed improvement in their final scores. Regression tree model was comparatively better in making predictions; however, both models had their limitation. CONCLUSION: The study demonstrated the feasibility and utility of using PAML to identify at-risk learners and tailor support strategies for enhancing educational outcome in low-resource settings. This additional support can augment expert judgement and ensure equitable educational practices. However, model limitations and ethical concerns, such as algorithmic bias, overfitting, and data imbalance, must be actively addressed in high-stakes assessments.[Box: see text].",
      "authors": "Ali Saima; Saleem Syed Ghazanfar; Arumuganathan Priya; Mukhtar Sama; Khatri Adeel; Rybarczyk Megan",
      "year": "2026",
      "journal": "Medical teacher",
      "doi": "10.1080/0142159X.2025.2519645",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40528447/",
      "mesh_terms": "Humans; Emergency Medicine; Pakistan; Certification; Machine Learning; Educational Measurement; Female; Male",
      "keywords": "Pakistan; Predictive analytics; emergency medicine education; health professions education; machine learning; targeted intervention",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "22538238",
      "title": "Automated region of interest analysis of dynamic Ca\u00b2+ signals in image sequences.",
      "abstract": "Ca(2+) signals are commonly measured using fluorescent Ca(2+) indicators and microscopy techniques, but manual analysis of Ca(2+) measurements is time consuming and subject to bias. Automated region of interest (ROI) detection algorithms have been employed for identification of Ca(2+) signals in one-dimensional line scan images, but currently there is no process to integrate acquisition and analysis of ROIs within two-dimensional time lapse image sequences. Therefore we devised a novel algorithm for rapid ROI identification and measurement based on the analysis of best-fit ellipses assigned to signals within noise-filtered image sequences. This algorithm was implemented as a plugin for ImageJ software (National Institutes of Health, Bethesda, MD). We evaluated the ability of our algorithm to detect synthetic Gaussian signal pulses embedded in background noise. The algorithm placed ROIs very near to the center of a range of signal pulses, resulting in mean signal amplitude measurements of 99.06 \u00b1 4.11% of true amplitude values. As a practical application, we evaluated both agonist-induced Ca(2+) responses in cultured endothelial cell monolayers, and subtle basal endothelial Ca(2+) dynamics in opened artery preparations. Our algorithm enabled comprehensive measurement of individual and localized cellular responses within cultured cell monolayers. It also accurately identified characteristic Ca(2+) transients, or Ca(2+) pulsars, within the endothelium of intact mouse mesenteric arteries and revealed the distribution of this basal Ca(2+) signal modality to be non-Gaussian with respect to amplitude, duration, and spatial spread. We propose that large-scale statistical evaluations made possible by our algorithm will lead to a more efficient and complete characterization of physiologic Ca(2+)-dependent signaling.",
      "authors": "Francis Michael; Qian Xun; Charbel Chim\u00e8ne; Ledoux Jonathan; Parker J C; Taylor Mark S",
      "year": "2012",
      "journal": "American journal of physiology. Cell physiology",
      "doi": "10.1152/ajpcell.00016.2012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/22538238/",
      "mesh_terms": "Algorithms; Animals; Calcium Signaling; Cells, Cultured; Endothelium, Vascular; Image Processing, Computer-Assisted; Mesenteric Arteries; Mice; Software",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC3423022"
    },
    {
      "pmid": "33749612",
      "title": "Predicting Emotional States Using Behavioral Markers Derived From Passively Sensed Data: Data-Driven Machine Learning Approach.",
      "abstract": "BACKGROUND: Mental health disorders affect multiple aspects of patients' lives, including mood, cognition, and behavior. eHealth and mobile health (mHealth) technologies enable rich sets of information to be collected noninvasively, representing a promising opportunity to construct behavioral markers of mental health. Combining such data with self-reported information about psychological symptoms may provide a more comprehensive and contextualized view of a patient's mental state than questionnaire data alone. However, mobile sensed data are usually noisy and incomplete, with significant amounts of missing observations. Therefore, recognizing the clinical potential of mHealth tools depends critically on developing methods to cope with such data issues. OBJECTIVE: This study aims to present a machine learning-based approach for emotional state prediction that uses passively collected data from mobile phones and wearable devices and self-reported emotions. The proposed methods must cope with high-dimensional and heterogeneous time-series data with a large percentage of missing observations. METHODS: Passively sensed behavior and self-reported emotional state data from a cohort of 943 individuals (outpatients recruited from community clinics) were available for analysis. All patients had at least 30 days' worth of naturally occurring behavior observations, including information about physical activity, geolocation, sleep, and smartphone app use. These regularly sampled but frequently missing and heterogeneous time series were analyzed with the following probabilistic latent variable models for data averaging and feature extraction: mixture model (MM) and hidden Markov model (HMM). The extracted features were then combined with a classifier to predict emotional state. A variety of classical machine learning methods and recurrent neural networks were compared. Finally, a personalized Bayesian model was proposed to improve performance by considering the individual differences in the data and applying a different classifier bias term for each patient. RESULTS: Probabilistic generative models proved to be good preprocessing and feature extractor tools for data with large percentages of missing observations. Models that took into account the posterior probabilities of the MM and HMM latent states outperformed those that did not by more than 20%, suggesting that the underlying behavioral patterns identified were meaningful for individuals' overall emotional state. The best performing generalized models achieved a 0.81 area under the curve of the receiver operating characteristic and 0.71 area under the precision-recall curve when predicting self-reported emotional valence from behavior in held-out test data. Moreover, the proposed personalized models demonstrated that accounting for individual differences through a simple hierarchical model can substantially improve emotional state prediction performance without relying on previous days' data. CONCLUSIONS: These findings demonstrate the feasibility of designing machine learning models for predicting emotional states from mobile sensing data capable of dealing with heterogeneous data with large numbers of missing observations. Such models may represent valuable tools for clinicians to monitor patients' mood states.",
      "authors": "S\u00fckei Emese; Norbury Agnes; Perez-Rodriguez M Mercedes; Olmos Pablo M; Art\u00e9s Antonio",
      "year": "2021",
      "journal": "JMIR mHealth and uHealth",
      "doi": "10.2196/24465",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33749612/",
      "mesh_terms": "Bayes Theorem; Emotions; Exercise; Humans; Machine Learning; Mental Health",
      "keywords": "Bayesian analysis; affect; digital phenotype; machine learning; mental health; mobile health; mobile phone; personalized models; probabilistic models",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8088855"
    },
    {
      "pmid": "41410806",
      "title": "Identifying Patients at High Risk for Colorectal Carcinoma Using the Electronic Health Record.",
      "abstract": "BACKGROUND: Colorectal cancer (CRC) is the fourth most common and second deadliest cancer in the US. Screening is effective at reducing CRC incidence and mortality, but rates of screening remain suboptimal. There are no sensitive machine learning models for accurately identifying individuals at risk for colorectal cancer or precancerous polyps. OBJECTIVES: The aim of our study was to develop and validate a novel machine learning model that uses multimodal Electronic Health Record (EHR) data, including the most recent complete blood count (CBC), basic metabolic panel (BMP), ICD codes, and medications, to estimate a patient's likelihood of having CRC or an advanced precancerous lesion. METHODS: We developed ColAI, an L1-regularized logistic regression model trained on 1-year trailing EHR data, to predict CRC or advanced adenoma at screening colonoscopy. Labs are treated as continuous variables, while ICD codes and medications are represented as binary indicators of presence. ColAI was trained using 87,825 screening colonoscopies and validated using 21,957 independent colonoscopies between August 1, 2020, and March 31, 2024, from the NYU Langone Health system. RESULTS: ColAI achieved an AUROC of 0.93 for CRC and 0.98 for CRC or advanced adenoma. Performance remained consistent across different hospitals and time periods within NYU Langone, demonstrating strong generalizability. Performance also remained consistent between first and follow-up colonoscopies, decreasing concern for selection bias. CONCLUSIONS: ColAI accurately identifies patients at elevated risk for CRC using only routine EHR data. It has the potential to enhance targeted outreach to high-risk, unscreened individuals and improve early cancer detection at the population level.",
      "authors": "Ahuja Yuri; Meng Xucong; Shaukat Aasma",
      "year": "2025",
      "journal": "Digestive diseases and sciences",
      "doi": "10.1007/s10620-025-09615-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41410806/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Colonoscopy; Colorectal carcinoma; Medical informatics",
      "pub_types": "Journal Article",
      "pmcid": "8045951"
    },
    {
      "pmid": "36718234",
      "title": "Rationing scarce healthcare capacity: A study of the ventilator allocation guidelines during the COVID-19 pandemic.",
      "abstract": "In the United States, even though national guidelines for allocating scarce healthcare resources are lacking, 26 states have specific ventilator allocation guidelines to be invoked in case of a shortage. While several states developed their guidelines in response to the recent COVID-19 pandemic, New York State developed these guidelines in 2015 as \"pandemic influenza is a foreseeable threat, one that we cannot ignore.\" The primary objective of this study is to assess the existing procedures and priority rules in place for allocating/rationing scarce ventilator capacity and propose alternative (and improved) priority schemes. We first build machine learning models using inpatient records of COVID-19 patients admitted to New York-Presbyterian/Columbia University Irving Medical Center and an affiliated community health center to predict survival probabilities as well as ventilator length-of-use. Then, we use the resulting point estimators and their uncertainties as inputs for a multiclass priority queueing model with abandonments to assess three priority schemes: (i) SOFA-P (Sequential Organ Failure Assessment based prioritization), which most closely mimics the existing practice by prioritizing patients with sufficiently low SOFA scores; (ii) ISP (incremental survival probability), which assigns priority based on patient-level survival predictions; and (iii) ISP-LU (incremental survival probability per length-of-use), which takes into account survival predictions and resource use duration. Our findings highlight that our proposed priority scheme, ISP-LU, achieves a demonstrable improvement over the other two alternatives. Specifically, the expected number of survivals increases and death risk while waiting for ventilator use decreases. We also show that ISP-LU is a robust priority scheme whose implementation yields a Pareto-improvement over both SOFA-P and ISP in terms of maximizing saved lives after mechanical ventilation while limiting racial disparity in access to the priority\u00a0queue.",
      "authors": "Anderson David R; Aydinliyim Tolga; Bjarnad\u00f3ttir Margr\u00e9t V; \u00c7il Eren B; Anderson Michaela R",
      "year": "2023",
      "journal": "Production and operations management",
      "doi": "10.1111/poms.13934",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36718234/",
      "mesh_terms": "",
      "keywords": "COVID\u201019; fairness; machine learning; multiclass queueing with abandonments; priority scheduling; resource allocation; scarce ventilator capacity",
      "pub_types": "Journal Article",
      "pmcid": "PMC9877846"
    },
    {
      "pmid": "36088867",
      "title": "Machine learning models to prognose 30-Day Mortality in Postoperative Disseminated Cancer Patients.",
      "abstract": "Patients with disseminated cancer at higher risk for postoperative mortality see improved outcomes with altered clinical management. Being able to risk stratify patients immediately after their index surgery to flag high risk patients for healthcare providers is vital. The combination of physician uncertainty and a demonstrated optimism bias often lead to an overestimation of patient life expectancy which can precent proper end of life counseling and lead to inadequate postoperative follow up. In this cohort study of 167,474 postoperative patients with multiple types of disseminated cancer, patients at high risk of 30-day postoperative mortality were accurately identified using our machine learning models based solely on clinical features and preoperative lab values. Extreme Gradient Boosting, Random Forest, and Logistic Regression machine learning models were developed on the cohort. Among 167,474 disseminated cancer patients, 50,669 (30.3%) died within 30 days of their index surgery; After preprocessing, 28 features were included in the model development. The cohort was randomly divided into 133,979 patients (80%) for training the models and 33,495 patients (20%) for testing. The extreme gradient boosting model had an AUC of 0.93 (95% CI: 0.926-0.931), the random forest model had an AUC of 0.93 (95% CI: 0.930-0.934), and the logistic regression model had an AUC of 0.90 (95% CI: 0.900-0.906 the index operation. Ultimately, Machine learning models were able to accurately predict short-term postoperative mortality among a heterogenous population of disseminated cancer patients using commonly accessible medical features. These models can be included in electronic health systems to guide clinical judgements that affect direct patient care, particularly in low-resource settings.",
      "authors": "Ganguli Reetam; Franklin Jordan; Yu Xiaotian; Lin Alice; Lad Rishik; Heffernan Daithi S",
      "year": "2022",
      "journal": "Surgical oncology",
      "doi": "10.1016/j.suronc.2022.101810",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36088867/",
      "mesh_terms": "Cohort Studies; Humans; Logistic Models; Machine Learning; Neoplasms; Prognosis",
      "keywords": "Artificial intelligence; Machine learning; Mortality; Oncology; Postoperative",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "24047600",
      "title": "A comparison of machine learning methods for classification using simulation with multiple real data examples from mental health studies.",
      "abstract": "BACKGROUND: Recent literature on the comparison of machine learning methods has raised questions about the neutrality, unbiasedness and utility of many comparative studies. Reporting of results on favourable datasets and sampling error in the estimated performance measures based on single samples are thought to be the major sources of bias in such comparisons. Better performance in one or a few instances does not necessarily imply so on an average or on a population level and simulation studies may be a better alternative for objectively comparing the performances of machine learning algorithms. METHODS: We compare the classification performance of a number of important and widely used machine learning algorithms, namely the Random Forests (RF), Support Vector Machines (SVM), Linear Discriminant Analysis (LDA) and k-Nearest Neighbour (kNN). Using massively parallel processing on high-performance supercomputers, we compare the generalisation errors at various combinations of levels of several factors: number of features, training sample size, biological variation, experimental variation, effect size, replication and correlation between features. RESULTS: For smaller number of correlated features, number of features not exceeding approximately half the sample size, LDA was found to be the method of choice in terms of average generalisation errors as well as stability (precision) of error estimates. SVM (with RBF kernel) outperforms LDA as well as RF and kNN by a clear margin as the feature set gets larger provided the sample size is not too small (at least 20). The performance of kNN also improves as the number of features grows and outplays that of LDA and RF unless the data variability is too high and/or effect sizes are too small. RF was found to outperform only kNN in some instances where the data are more variable and have smaller effect sizes, in which cases it also provide more stable error estimates than kNN and LDA. Applications to a number of real datasets supported the findings from the simulation study.",
      "authors": "Khondoker Mizanur; Dobson Richard; Skirrow Caroline; Simmons Andrew; Stahl Daniel",
      "year": "2016",
      "journal": "Statistical methods in medical research",
      "doi": "10.1177/0962280213502437",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24047600/",
      "mesh_terms": "Behavioral Research; Colorectal Neoplasms; Discriminant Analysis; Half-Life; Humans; Machine Learning; Mental Health; Sample Size; Support Vector Machine",
      "keywords": "cross-validation; electroencephalogram (EEG); generalisation error; machine learning; magnetic resonance imaging (MRI); microarrays; truncated distribution",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": "PMC5081132"
    },
    {
      "pmid": "23910956",
      "title": "Using balance statistics to determine the optimal number of controls in matching studies.",
      "abstract": "When a randomized controlled trial is not feasible, investigators typically turn to matching techniques as an alternative approach to evaluate the effectiveness of health care interventions. Matching studies are designed to minimize imbalances on measured pre-intervention characteristics, thereby reducing bias in estimates of treatment effects. Generally, a matching ratio up to 4:1 (control to treatment) elicits the lowest bias. However, when matching techniques are used in prospective studies, investigators try to maximize the number of controls matched to each treated individual to increase the likelihood that a sufficient sample size will remain after attrition. In this paper, we describe a systematic approach to managing the trade-off between minimizing bias and maximizing matched sample size. Our approach includes the following three steps: (1) run the desired matching algorithm, starting with 1:1 (one control to one treated individual) matching and iterating until the maximum desired number of potential controls per treated subject is reached; (2) for each iteration, test for covariate balance; and (3) generate numeric summaries and graphical plots of the balance statistics across all iterations in order to determine the optimal solution. We demonstrate the implementation of this approach with data from a medical home pilot programme and with a simulation study of populations of 100,000 in which 1000 individuals receive the intervention. We advocate undertaking this methodical approach in matching studies to ensure that the optimal matching solution is identified. Doing so will raise the overall quality of the literature and increase the likelihood of identifying effective interventions.",
      "authors": "Linden Ariel; Samuels Steven J",
      "year": "2013",
      "journal": "Journal of evaluation in clinical practice",
      "doi": "10.1111/jep.12072",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23910956/",
      "mesh_terms": "Bias; Clinical Trials as Topic; Data Interpretation, Statistical; Humans; Outcome Assessment, Health Care; Research Design; Sample Size; Treatment Outcome",
      "keywords": "balance; bias; matching; observational studies; propensity score",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38854991",
      "title": "2023 Beijing Health Data Science Summit.",
      "abstract": "The 5th annual Beijing Health Data Science Summit, organized by the National Institute of Health Data Science at Peking University, recently concluded with resounding success. This year, the summit aimed to foster collaboration among researchers, practitioners, and stakeholders in the field of health data science to advance the use of data for better health outcomes. One significant highlight of this year's summit was the introduction of the Abstract Competition, organized by Health Data Science, a Science Partner Journal, which focused on the use of cutting-edge data science methodologies, particularly the application of artificial intelligence in the healthcare scenarios. The competition provided a platform for researchers to showcase their groundbreaking work and innovations. In total, the summit received 61 abstract submissions. Following a rigorous evaluation process by the Abstract Review Committee, eight exceptional abstracts were selected to compete in the final round and give presentations in the Abstract Competition. The winners of the Abstract Competition are as follows:\u2022First Prize: \"Interpretable Machine Learning for Predicting Outcomes of Childhood Kawasaki Disease: Electronic Health Record Analysis\" presented by researchers from the Chinese Academy of Medical Sciences, Peking Union Medical College, and Chongqing Medical University (presenter Yifan Duan).\u2022Second Prize: \"Survival Disparities among Mobility Patterns of Patients with Cancer: A Population-Based Study\" presented by a team from Peking University (presenter Fengyu Wen).\u2022Third Prize: \"Deep Learning-Based Real-Time Predictive Model for the Development of Acute Stroke\" presented by researchers from Beijing Tiantan Hospital (presenter Lan Lan). We extend our heartfelt gratitude to the esteemed panel of judges whose expertise and dedication ensured the fairness and quality of the competition. The judging panel included Jiebo Luo from the University of Rochester (chair), Shenda Hong from Peking University, Xiaozhong Liu from Worcester Polytechnic Institute, Liu Yang from Hong Kong Baptist University, Ma Jianzhu from Tsinghua University, Ting Ma from Harbin Institute of Technology, and Jian Tang from Mila-Quebec Artificial Intelligence Institute. We wish to convey our deep appreciation to Zixuan He and Haoyang Hong for their invaluable assistance in the meticulous planning and execution of the event. As the 2023 Beijing Health Data Science Summit comes to a close, we look forward to welcoming all participants to join us in 2024. Together, we will continue to advance the frontiers of health data science and work toward a healthier future for all.",
      "authors": "",
      "year": "2024",
      "journal": "Health data science",
      "doi": "10.34133/hds.0112",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38854991/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11157085"
    },
    {
      "pmid": "35294539",
      "title": "Assessment of Machine Learning-Based Medical Directives to Expedite Care in Pediatric Emergency Medicine.",
      "abstract": "IMPORTANCE: Increased wait times and long lengths of stay in emergency departments (EDs) are associated with poor patient outcomes. Systems to improve ED efficiency would be useful. Specifically, minimizing the time to diagnosis by developing novel workflows that expedite test ordering can help accelerate clinical decision-making. OBJECTIVE: To explore the use of machine learning-based medical directives (MLMDs) to automate diagnostic testing at triage for patients with common pediatric ED diagnoses. DESIGN, SETTING, AND PARTICIPANTS: Machine learning models trained on retrospective electronic health record data were evaluated in a decision analytical model study conducted at the ED of the Hospital for Sick Children Toronto, Canada. Data were collected on all patients aged 0 to 18 years presenting to the ED from July 1, 2018, to June 30, 2019 (77\u202f219 total patient visits). EXPOSURE: Machine learning models were trained to predict the need for urinary dipstick testing, electrocardiogram, abdominal ultrasonography, testicular ultrasonography, bilirubin level testing, and forearm radiographs. MAIN OUTCOMES AND MEASURES: Models were evaluated using area under the receiver operator curve, true-positive rate, false-positive rate, and positive predictive values. Model decision thresholds were determined to limit the total number of false-positive results and achieve high positive predictive values. The time difference between patient triage completion and test ordering was assessed for each use of MLMD. Error rates were analyzed to assess model bias. In addition, model explainability was determined using Shapley Additive Explanations values. RESULTS: There was a total of 42 238 boys (54.7%) included in model development; mean (SD) age of the children was 5.4 (4.8) years. Models obtained high area under the receiver operator curve (0.89-0.99) and positive predictive values (0.77-0.94) across each of the use cases. The proposed implementation of MLMDs would streamline care for 22.3% of all patient visits and make test results available earlier by 165 minutes (weighted mean) per affected patient. Model explainability for each MLMD demonstrated clinically relevant features having the most influence on model predictions. Models also performed with minimal to no sex bias. CONCLUSIONS AND RELEVANCE: The findings of this study suggest the potential for clinical automation using MLMDs. When integrated into clinical workflows, MLMDs may have the potential to autonomously order common ED tests early in a patient's visit with explainability provided to patients and clinicians.",
      "authors": "Singh Devin; Nagaraj Sujay; Mashouri Pouria; Drysdale Erik; Fischer Jason; Goldenberg Anna; Brudno Michael",
      "year": "2022",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2022.2599",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35294539/",
      "mesh_terms": "Adolescent; Child; Child, Preschool; Emergency Service, Hospital; Humans; Infant; Infant, Newborn; Machine Learning; Male; Pediatric Emergency Medicine; Retrospective Studies; Triage",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8928004"
    },
    {
      "pmid": "32216034",
      "title": "Diabetic eye screening with variable screening intervals based on individual risk factors is safe and effective in ophthalmic practice.",
      "abstract": "PURPOSE: To test in a 'real world' diabetic eye-screening programme, a computer-based personal risk evaluation for progression to sight-threatening diabetic retinopathy. Screening intervals were individualized, and clinical outcomes, safety and cost-effectiveness documented. METHODS: The RETINARISK algorithm was used in an ophthalmology clinic in Norway. The diabetes cohort was divided on voluntary basis into two groups: one with variable screening intervals based on their personal risk profile and the other group with conventional fixed interval diabetic eye screening. Compliance, clinical outcomes, safety and health economics were evaluated. A total of 843 diabetic patients participated in the program 2014-2019. A total of 63 had type 1 and 780 type 2 diabetes. A total of 671 patients had no diabetic retinopathy at baseline and 171 had retinopathy. RESULTS: A total of 444 (53%) diabetic patients were included in the personal risk profile program and 399 in the fixed interval group. The RETINARISK algorithm calculated 563 screening intervals for the variable interval group, which was 23\u00a0\u00b1\u00a016\u00a0months (mean\u00a0\u00b1\u00a0SD), compared to 14\u00a0\u00b1\u00a05\u00a0months for the group with fixed screening intervals. Due to selection bias, the two groups could not be directly compared. We did not experience any delay in detecting diabetic retinal changes when using the personal risk profile program. CONCLUSION: The RETINARISK algorithm was safe and effective in a diabetic screening program in an ophthalmology clinic over 5\u00a0years. The use of the program reduces the mean frequency of screening visits and liberates valuable time in ophthalmic practice to be used on high-risk diabetic patients or other patient groups.",
      "authors": "Estil Svein; Steinarsson AEgir \u00de\u00f3r; Einarsson Stefan; Aspelund Thor; Stef\u00e1nsson Einar",
      "year": "2020",
      "journal": "Acta ophthalmologica",
      "doi": "10.1111/aos.14425",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32216034/",
      "mesh_terms": "Aged; Algorithms; Diabetes Mellitus, Type 2; Diabetic Retinopathy; Female; Follow-Up Studies; Humans; Incidence; Male; Mass Screening; Middle Aged; Norway; Patient Compliance; Retrospective Studies; Risk Factors; Time Factors",
      "keywords": "blindness; diabetic retinopathy; health care; health economics; information technology; risk; risk factors; risk profile; screening",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "28263996",
      "title": "Reproducibility, reliability and validity of population-based administrative health data for the assessment of cancer non-related comorbidities.",
      "abstract": "BACKGROUND: Patients with comorbidities do not receive optimal treatment for their cancer, leading to lower cancer survival. Information on individual comorbidities is not straightforward to derive from population-based administrative health datasets. We described the development of a reproducible algorithm to extract the individual Charlson index comorbidities from such data. We illustrated the algorithm with 1,789 laryngeal cancer patients diagnosed in England in 2013. We aimed to clearly set out and advocate the time-related assumptions specified in the algorithm by providing empirical evidence for them. METHODS: Comorbidities were assessed from hospital records in the ten years preceding cancer diagnosis and internal reliability of the hospital records was checked. Data were right-truncated 6 or 12 months prior to cancer diagnosis to avoid inclusion of potentially cancer-related comorbidities. We tested for collider bias using Cox regression. RESULTS: Our administrative data showed weak to moderate internal reliability to identify comorbidities (ICC ranging between 0.1 and 0.6) but a notably high external validity (86.3%). We showed a reverse protective effect of non-cancer related Chronic Obstructive Pulmonary Disease (COPD) when the effect is split into cancer and non-cancer related COPD (Age-adjusted HR: 0.95, 95% CI:0.7-1.28 for non-cancer related comorbidities). Furthermore, we showed that a window of 6 years before diagnosis is an optimal period for the assessment of comorbidities. CONCLUSION: To formulate a robust approach for assessing common comorbidities, it is important that assumptions made are explicitly stated and empirically proven. We provide a transparent and consistent approach useful to researchers looking to assess comorbidities for cancer patients using administrative health data.",
      "authors": "Maringe Camille; Fowler Helen; Rachet Bernard; Luque-Fernandez Miguel Angel",
      "year": "2017",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0172814",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28263996/",
      "mesh_terms": "Algorithms; Comorbidity; England; Female; Humans; Longitudinal Studies; Male; Neoplasms; Population Surveillance; Proportional Hazards Models; Reproducibility of Results; Retrospective Studies",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC5338773"
    },
    {
      "pmid": "41026707",
      "title": "DiabetesXpertNet: An innovative attention-based CNN for accurate type 2 diabetes prediction.",
      "abstract": "Type 2 diabetes mellitus remains a critical global health challenge, with rising incidence rates placing immense pressure on healthcare systems worldwide. This chronic metabolic disorder affects diverse populations, including the elderly and children, leading to severe complications. Early and accurate prediction is essential to mitigate these consequences, yet traditional models often struggle with challenges such as imbalanced datasets, high-dimensional data, missing values, and outliers, resulting in limited predictive performance and interpretability. This study introduces DiabetesXpertNet, an innovative deep learning framework designed to enhance the prediction of Type 2 diabetes mellitus. Unlike existing convolutional neural network models optimized for image data, which focus on generalized attention mechanisms, DiabetesXpertNet is specifically tailored for tabular medical data. It incorporates a convolutional neural network architecture with dynamic channel attention modules to prioritize clinically significant features, such as glucose and insulin levels, and a context-aware feature enhancer to capture complex sequential relationships within structured datasets. The model employs advanced preprocessing techniques, including mean imputation for missing values, median replacement for outliers, and feature selection through mutual information and LASSO regression, to improve dataset quality and computational efficiency. Additionally, a logistic regression-based class weighting strategy addresses class imbalance, enhancing model fairness. Evaluated on the PID dataset and Frankfurt Hospital, Germany Diabetes datasets, DiabetesXpertNet achieves an accuracy of 89.98%, AUC of 91.95%, precision of 89.08%, recall of 88.11%, and F1-score of 88.01%, outperforming existing machine learning and deep learning models. Compared to traditional machine learning approaches, it demonstrates significant improvements in precision (+5.1%), recall (+4.8%), F1-score (+5.1%), accuracy (+6.0%), and AUC (+4.5%). Against other convolutional neural network models, it shows meaningful gains in precision (+2.2%), recall (+1.1%), F1-score (+1.2%), accuracy (+1.9%), and AUC (+0.6%). These results underscore the robustness and interpretability of DiabetesXpertNet, making it a promising tool for early Type 2 diabetes diagnosis in clinical settings.",
      "authors": "Farnoosh Rahman; Abnoosian Karlo; Isewid Rasha Abbas; Javaheri Danial",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0330454",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41026707/",
      "mesh_terms": "Diabetes Mellitus, Type 2; Humans; Neural Networks, Computer; Deep Learning; Blood Glucose; Male; Female",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12483257"
    },
    {
      "pmid": "33188540",
      "title": "Shared decision-making and maternity care in the deep learning age: Acknowledging and overcoming inherited defeaters.",
      "abstract": "In recent years there has been an explosion of interest in Artificial Intelligence (AI) both in health care and academic philosophy. This has been due mainly to the rise of effective machine learning and deep learning algorithms, together with increases in data collection and processing power, which have made rapid progress in many areas. However, use of this technology has brought with it philosophical issues and practical problems, in particular, epistemic and ethical. In this paper the authors, with backgrounds in philosophy, maternity care practice and clinical research, draw upon and extend a recent framework for shared decision-making (SDM) that identified a duty of care to the client's knowledge as a necessary condition for SDM. This duty entails the responsibility to acknowledge and overcome epistemic defeaters. This framework is applied to the use of AI in maternity care, in particular, the use of machine learning and deep learning technology to attempt to enhance electronic fetal monitoring (EFM). In doing so, various sub-kinds of epistemic defeater, namely, transparent, opaque, underdetermined, and inherited defeaters are taxonomized and discussed. The authors argue that, although effective current or future AI-enhanced EFM may impose an epistemic obligation on the part of clinicians to rely on such systems' predictions or diagnoses as input to SDM, such obligations may be overridden by inherited defeaters, caused by a form of algorithmic bias. The existence of inherited defeaters implies that the duty of care to the client's knowledge extends to any situation in which a clinician (or anyone else) is involved in producing training data for a system that will be used in SDM. Any future AI must be capable of assessing women individually, taking into account a wide range of factors including women's preferences, to provide a holistic range of evidence for clinical decision-making.",
      "authors": "Begley Keith; Begley Cecily; Smith Valerie",
      "year": "2021",
      "journal": "Journal of evaluation in clinical practice",
      "doi": "10.1111/jep.13515",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33188540/",
      "mesh_terms": "Artificial Intelligence; Decision Making; Decision Making, Shared; Deep Learning; Female; Humans; Maternal Health Services; Pregnancy",
      "keywords": "algorithmic bias; artificial intelligence; duty of care; electronic fetal monitoring; epistemic defeaters; shared decision-making",
      "pub_types": "Journal Article",
      "pmcid": "PMC9292822"
    },
    {
      "pmid": "36716983",
      "title": "A method for comparing multiple imputation techniques: A case study on the U.S. national COVID cohort collaborative.",
      "abstract": "Healthcare datasets obtained from Electronic Health Records have proven to be extremely useful for assessing associations between patients' predictors and outcomes of interest. However, these datasets often suffer from missing values in a high proportion of cases, whose removal may introduce severe bias. Several multiple imputation algorithms have been proposed to attempt to recover the missing information under an assumed missingness mechanism. Each algorithm presents strengths and weaknesses, and there is currently no consensus on which multiple imputation algorithm works best in a given scenario. Furthermore, the selection of each algorithm's parameters and data-related modeling choices are also both crucial and challenging. In this paper we propose a novel framework to numerically evaluate strategies for handling missing data in the context of statistical analysis, with a particular focus on multiple imputation techniques. We demonstrate the feasibility of our approach on a large cohort of type-2 diabetes patients provided by the National COVID Cohort Collaborative (N3C) Enclave, where we explored the influence of various patient characteristics on outcomes related to COVID-19. Our analysis included classic multiple imputation techniques as well as simple complete-case Inverse Probability Weighted models. Extensive experiments show that our approach can effectively highlight the most promising and performant missing-data handling strategy for our case study. Moreover, our methodology allowed a better understanding of the behavior of the different models and of how it changed as we modified their parameters. Our method is general and can be applied to different research fields and on datasets containing heterogeneous types.",
      "authors": "Casiraghi Elena; Wong Rachel; Hall Margaret; Coleman Ben; Notaro Marco; Evans Michael D; Tronieri Jena S; Blau Hannah; Laraway Bryan; Callahan Tiffany J; Chan Lauren E; Bramante Carolyn T; Buse John B; Moffitt Richard A; St\u00fcrmer Til; Johnson Steven G; Raymond Shao Yu; Reese Justin; Robinson Peter N; Paccanaro Alberto; Valentini Giorgio; Huling Jared D; Wilkins Kenneth J",
      "year": "2023",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2023.104295",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36716983/",
      "mesh_terms": "Humans; COVID-19; Algorithms; Research Design; Bias; Probability",
      "keywords": "COVID-19 severity assessment; Clinical informatics; Diabetic patients; Evaluation framework; Multiple Imputation",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10683778"
    },
    {
      "pmid": "27115650",
      "title": "Big Data, Evolution, and Metagenomes: Predicting Disease from Gut Microbiota Codon Usage Profiles.",
      "abstract": "Metagenomics projects use next-generation sequencing to unravel genetic potential in microbial communities from a wealth of environmental niches, including those associated with human body and relevant to human health. In order to understand large datasets collected in metagenomics surveys and interpret them in context of how a community metabolism as a whole adapts and interacts with the environment, it is necessary to extend beyond the conventional approaches of decomposing metagenomes into microbial species' constituents and performing analysis on separate components. By applying concepts of translational optimization through codon usage adaptation on entire metagenomic datasets, we demonstrate that a bias in codon usage present throughout the entire microbial community can be used as a powerful analytical tool to predict for community lifestyle-specific metabolism. Here we demonstrate this approach combined with machine learning, to classify human gut microbiome samples according to the pathological condition diagnosed in the human host.",
      "authors": "Fabijani\u0107 Maja; Vlahovi\u010dek Kristian",
      "year": "2016",
      "journal": "Methods in molecular biology (Clifton, N.J.)",
      "doi": "10.1007/978-1-4939-3572-7_26",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27115650/",
      "mesh_terms": "Codon; Data Mining; Evolution, Molecular; Gastrointestinal Microbiome; High-Throughput Nucleotide Sequencing; Humans; Liver Cirrhosis; Machine Learning; Metagenomics; Phylogeny",
      "keywords": "Cirrhosis; Enrichment analysis; Human metagenome; Random forests; Translational optimization; Variable selection",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "39108274",
      "title": "Identifying children's environmental health risks, needs, misconceptions, and opportunities for research translation using social media.",
      "abstract": "As part of the Advancing Science, Practice, Programming, and Policy in Research Translation for Children's Environmental Health (ASP3IRE) center, machine learning, geographic information systems (GIS), and natural language processing to analyze more than 650 million posts related to children's environmental health are being used. Using preliminary analyses as examples, this commentary discusses the potential opportunities, benefits, challenges, and limitations of children's health social media analytics. Social media contains large volumes of contextually rich data that describe children's health risks and needs, characteristics of homes and childcare locations important to environmental exposures, and parent and childcare provider perceptions, awareness of, and misconceptions about children's environmental health. Twenty five million unique conversations mentioning children, with likes, views, and replies from more than 33 million X (formerly Twitter) users were identified. Many of these posts can be linked to traditional environmental and health data. However, social media analytics have several challenges and limitations. Challenges include a need for interdisciplinary collaborations, selectivity and sensitivity of analytical methods, the dynamic, evolving communication methods and platform preferences of social media users, and operational policies. Limitations include data availability, generalizability, and self-report bias. Social media analytics has significant potential to contribute to children's environmental health research and translation.",
      "authors": "Larkin Andrew; MacDonald Megan; Jackson Dixie; Kile Molly L; Hystad Perry",
      "year": "2024",
      "journal": "Exploration of digital health technologies",
      "doi": "10.37349/edht.2024.00011",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39108274/",
      "mesh_terms": "",
      "keywords": "Social media; children; environment; health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11302476"
    },
    {
      "pmid": "40839247",
      "title": "Translating the EORTC CAT core and the QLQ-C30 to the EQ-5D-5L in patients with metastatic breast cancer: A comparison of direct and indirect mapping algorithms.",
      "abstract": "BACKGROUND: To enable the use of different non-preference-based patient-reported outcome measures to derive utility values for health economic evaluations in oncological trials, this study developed direct and indirect mapping algorithms for estimating the EQ-5D-5L utility index via the German value set from the EORTC CAT Core and the QLQ-C30 in metastatic breast cancer patients. METHODS: We included 1,839 observations from 878 patients with metastatic breast cancer from the PRO B study. We compared direct mapping algorithms, including adjusted limited dependent variable mixture models (ALDVMM), Tobit regression, ordinal least squares regression, and adjusted beta regression, while indirect mapping employed a generalized ordered logit model. Visualization was used to assess model performance across the entire distribution, while quantitative evaluation was performed using mean absolute error (MAE), root mean squared error (RMSE), and mean prediction bias. RESULTS: Among the direct algorithms, adjusted beta regression demonstrated the best performance. It had the lowest MAE of 0.07-0.08 and RMSE of 0.11-0.13, a mean prediction bias of -0.004, close to zero. The indirect mapping model also performed well, with a mean prediction bias of 0.04 and MAE of 0.07, showing performance comparable to the preferred direct mapping algorithm for both the EORTC CAT Core and the QLQ-C30. CONCLUSIONS: This study developed and validated robust direct and indirect algorithms for estimating the EQ-5D-5L utility index from the EORTC CAT Core and the QLQ-C30 based on the German tariff. In particular, using this indirect mapping algorithm, the EORTC CAT Core and QLQ-C30 can be translated into quality-adjusted life-years, facilitating health economic evaluations across different country tariffs. TRIAL REGISTRATION: DRKS (German Clinical Trials Register) DRKS00024015. Registered on 15 February 2021, https//drks.de/search/de/trial/DRKS00024015.",
      "authors": "Gebert Pimrapat; Hage Anna Maria; Fischer Felix; Klapproth Christoph Paul; Grittner Ulrike; Karsten Maria Margarete",
      "year": "2025",
      "journal": "The European journal of health economics : HEPAC : health economics in prevention and care",
      "doi": "10.1007/s10198-025-01824-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40839247/",
      "mesh_terms": "",
      "keywords": "Advanced breast cancer; EORTC CAT core; EORTC QLQ-C30; EQ-5D-5L; Mapping; Patient-reported outcome",
      "pub_types": "Journal Article",
      "pmcid": "4234877"
    },
    {
      "pmid": "41468580",
      "title": "Evaluation of Few-Shot AI-Generated Feedback on Case Reports in Physical Therapy Education: Mixed Methods Study.",
      "abstract": "BACKGROUND: While artificial intelligence (AI)-generated feedback offers significant potential to overcome constraints on faculty time and resources associated with providing personalized feedback, its perceived usefulness can be undermined by algorithm aversion. In-context learning, particularly the few-shot approach, has emerged as a promising paradigm for enhancing AI performance. However, there is limited research investigating its usefulness, especially in health profession education. OBJECTIVE: This study aimed to compare the quality of AI-generated formative feedback from 2 settings, feedback generated in a zero-shot setting (hereafter, \"zero-shot feedback\") and feedback generated in a few-shot setting (hereafter, \"few-shot feedback\"), using a mixed methods approach in Japanese physical therapy education. Additionally, we examined the effect of algorithm aversion on these 2 feedback types. METHODS: A mixed methods study was conducted with 35 fourth-year physical therapy students (mean age 21.4, SD 0.7 years). Zero-shot feedback was created using Gemini 2.5 Pro with default settings, whereas few-shot feedback was generated by providing the same model with 9 teacher-created examples. The participants compared the quality of both feedback types using 3 methods: a direct preference question, the Feedback Perceptions Questionnaire (FPQ), and focus group interviews. Quantitative comparisons of FPQ scores were performed using the Wilcoxon signed rank test. To investigate algorithm aversion, the study examined how student perceptions changed before and after disclosure of the feedback's identity. RESULTS: Most students (26/35, 74%) preferred few-shot feedback over zero-shot feedback in terms of overall usefulness, although no significant difference was found between the 2 feedback types for the total FPQ score (P=.22). On the specific FPQ scales, few-shot feedback scored significantly higher than zero-shot feedback on fairness across all 3 items: \"satisfied\" (P=.02; r=0.407), \"fair\" (P=.04; r=0.341), and \"justified\" (P=.02; r=0.392). It also scored significantly higher on 1 item of the usefulness scale (\"useful\"; P=.02; r=0.401) and 1 item of the willingness scale (\"invest a lot of effort\"; P=.02; r=0.394). In contrast, zero-shot feedback scored significantly higher on the affect scale across 2 items: \"successful\" (P=.03; r=0.365) and \"angry\" (P=.008; r=0.443). Regarding algorithm aversion, evaluations for zero-shot feedback became more negative for 83% (15/18) of the items after identity disclosure, whereas positive perceptions of few-shot feedback were maintained or increased. Qualitative analysis revealed that students valued zero-shot feedback for its encouraging tone, whereas few-shot feedback was appreciated for its contextual understanding and concrete guidance for improvement. CONCLUSIONS: Japanese physical therapy students perceived few-shot feedback more favorably than zero-shot feedback on case reports. This few-shot AI model shows potential to resist algorithm aversion and serves as an effective educational tool to support autonomous writing, facilitate reflection on clinical reasoning, and cultivate advanced thinking skills.",
      "authors": "Sudo Hisaya; Noborimoto Yoko; Takahashi Jun",
      "year": "2025",
      "journal": "JMIR medical education",
      "doi": "10.2196/85614",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41468580/",
      "mesh_terms": "Humans; Male; Female; Artificial Intelligence; Japan; Surveys and Questionnaires; Young Adult; Formative Feedback; Physical Therapy Specialty; Focus Groups; Feedback; Algorithms",
      "keywords": "AI; Gemini; algorithm aversion; artificial intelligence; few-shot setting; formative feedback; generative AI; generative artificial intelligence; health profession education; in-context learning; large language models; physical therapy education",
      "pub_types": "Journal Article",
      "pmcid": "PMC12811036"
    },
    {
      "pmid": "35935648",
      "title": "Real-World and Regulatory Perspectives of Artificial Intelligence in Cardiovascular Imaging.",
      "abstract": "Recent progress in digital health data recording, advances in computing power, and methodological approaches that extract information from data as artificial intelligence are expected to have a disruptive impact on technology in medicine. One of the potential benefits is the ability to extract new and essential insights from the vast amount of data generated during health care delivery every day. Cardiovascular imaging is boosted by new intelligent automatic methods to manage, process, segment, and analyze petabytes of image data exceeding historical manual capacities. Algorithms that learn from data raise new challenges for regulatory bodies. Partially autonomous behavior and adaptive modifications and a lack of transparency in deriving evidence from complex data pose considerable problems. Controlling new technologies requires new controlling techniques and ongoing regulatory research. All stakeholders must participate in the quest to find a fair balance between innovation and regulation. The regulatory approach to artificial intelligence must be risk-based and resilient. A focus on unknown emerging risks demands continuous surveillance and clinical evaluation during the total product life cycle. Since learning algorithms are data-driven, high-quality data is fundamental for good machine learning practice. Mining, processing, validation, governance, and data control must account for bias, error, inappropriate use, drifts, and shifts, particularly in real-world data. Regulators worldwide are tackling twenty-first century challenges raised by \"learning\" medical devices. Ethical concerns and regulatory approaches are presented. The paper concludes with a discussion on the future of responsible artificial intelligence.",
      "authors": "Wellnhofer Ernst",
      "year": "2022",
      "journal": "Frontiers in cardiovascular medicine",
      "doi": "10.3389/fcvm.2022.890809",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35935648/",
      "mesh_terms": "",
      "keywords": "innovation; machine learning (ML); regulation; safety and risk; software as a medical device (SaMD); total product life cycle (TPLC)",
      "pub_types": "Journal Article",
      "pmcid": "PMC9354141"
    },
    {
      "pmid": "34837000",
      "title": "Combining machine learning and conventional statistical approaches for risk factor discovery in a large cohort study.",
      "abstract": "We present a simple and efficient hypothesis-free machine learning pipeline for risk factor discovery that accounts for non-linearity and interaction in large biomedical databases with minimal variable pre-processing. In this study, mortality models were built using gradient boosting decision trees (GBDT) and important predictors were identified using a Shapley values-based feature attribution method, SHAP values. Cox models controlled for false discovery rate were used for confounder adjustment, interpretability, and further validation. The pipeline was tested using information from 502,506 UK Biobank participants, aged 37-73\u00a0years at recruitment and followed over seven years for mortality registrations. From the 11,639 predictors included in GBDT, 193 potential risk factors had SHAP values\u2009\u2265\u20090.05, passed the correlation test, and were selected for further modelling. Of the total variable importance summed up, 60% was directly health related, and baseline characteristics, sociodemographics, and lifestyle factors each contributed about 10%. Cox models adjusted for baseline characteristics, showed evidence for an association with mortality for 166 out of the 193 predictors. These included mostly well-known risk factors (e.g., age, sex, ethnicity, education, material deprivation, smoking, physical activity, self-rated health, BMI, and many disease outcomes). For 19 predictors we saw evidence for an association in the unadjusted but not adjusted analyses, suggesting bias by confounding. Our GBDT-SHAP pipeline was able to identify relevant predictors 'hidden' within thousands of variables, providing an efficient and pragmatic solution for the first stage of hypothesis free risk factor identification.",
      "authors": "Madakkatel Iqbal; Zhou Ang; McDonnell Mark D; Hypp\u00f6nen Elina",
      "year": "2021",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-021-02476-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34837000/",
      "mesh_terms": "Aged; Cognition Disorders; Cohort Studies; Databases, Factual; Female; Humans; Life Style; Machine Learning; Male; Middle Aged; Mortality; Risk Factors; Smoking; United Kingdom",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8626442"
    },
    {
      "pmid": "39617415",
      "title": "Sensitivity Analysis for Effects of Multiple Exposures in the Presence of Unmeasured Confounding: Non-Gaussian and Time-to-Event Outcomes.",
      "abstract": "In epidemiological studies, evaluating the health impacts stemming from multiple exposures is one of the important goals. To analyze the effects of multiple exposures on discrete or time-to-event health outcomes, researchers often employ generalized linear models, Cox proportional hazards models, and machine learning methods. However, observational studies are prone to unmeasured confounding factors, which can introduce the potential for substantial bias in the multiple exposure effects. To address this issue, we propose a novel outcome model-based sensitivity analysis method for non-Gaussian and time-to-event outcomes with multiple exposures. All the proposed sensitivity analysis problems are formulated as linear programming problems with quadratic and linear constraints, which can be solved efficiently. Analytic solutions are provided for some optimization problems, and a numerical study is performed to examine how the proposed sensitivity analysis behaves in finite samples. We illustrate the proposed method using two real data examples.",
      "authors": "Lee Seungjae; Jeong Boram; Lee Donghwan; Lee Woojoo",
      "year": "2024",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.10293",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39617415/",
      "mesh_terms": "Humans; Confounding Factors, Epidemiologic; Proportional Hazards Models; Models, Statistical; Linear Models; Computer Simulation; Bias; Normal Distribution",
      "keywords": "multiple exposures; non\u2010Gaussian outcomes; sensitivity analysis; time\u2010to\u2010event outcomes; unmeasured confounding\u00a0",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40588165",
      "title": "Deep learning with ensemble-based hybrid AI model for bipolar and unipolar depression detection using demographic and behavioral based on time-series data.",
      "abstract": "BACKGROUND: Depression, including Bipolar and Unipolar types, is a widespread mental health issue. Conventional diagnostic methods rely on subjective assessments, leading to possible underreporting and bias. Machine learning (ML) and deep learning (DL) offer automated approaches to detect depression using behavioral and demographic data. METHODS: This study proposes a hybrid AI framework combining structured demographic features with synthetic actigraph time-series data. Demographic data is modeled using an XGBoost ensemble, while temporal data is analyzed through a deep convolutional neural network (CNN). The training pipeline includes stratified k-fold cross-validation, hyperparameter tuning, and statistical testing. Model explainability is enhanced using SHAP (XGBoost) and Grad-CAM (CNN). RESULTS: The hybrid model demonstrated strong classification performance across metrics like accuracy, sensitivity, and specificity. Integrating temporal and static features improved prediction of Bipolar and Unipolar Depression. Interpretability tools revealed key features and time patterns influencing predictions. CONCLUSIONS: This work introduces a robust and interpretable framework for depression classification using synthetic multimodal data. While not clinically validated, the model serves as a methodological foundation for future research with real-world datasets.",
      "authors": "Kanchapogu Naga Raju; Nandan Mohanty Sachi",
      "year": "2025",
      "journal": "Dialogues in clinical neuroscience",
      "doi": "10.1080/19585969.2025.2524337",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40588165/",
      "mesh_terms": "Humans; Deep Learning; Bipolar Disorder; Depressive Disorder; Male; Female; Adult; Middle Aged; Neural Networks, Computer",
      "keywords": "Depression prediction; actigraph time-series analysis; bipolar disorder; hybrid deep learning model; machine learning; unipolar depression",
      "pub_types": "Journal Article",
      "pmcid": "PMC12210415"
    },
    {
      "pmid": "30169498",
      "title": "Machine learning models in electronic health records can outperform conventional survival models for predicting patient mortality in coronary artery disease.",
      "abstract": "Prognostic modelling is important in clinical practice and epidemiology for patient management and research. Electronic health records (EHR) provide large quantities of data for such models, but conventional epidemiological approaches require significant researcher time to implement. Expert selection of variables, fine-tuning of variable transformations and interactions, and imputing missing values are time-consuming and could bias subsequent analysis, particularly given that missingness in EHR is both high, and may carry meaning. Using a cohort of 80,000 patients from the CALIBER programme, we compared traditional modelling and machine-learning approaches in EHR. First, we used Cox models and random survival forests with and without imputation on 27 expert-selected, preprocessed variables to predict all-cause mortality. We then used Cox models, random forests and elastic net regression on an extended dataset with 586 variables to build prognostic models and identify novel prognostic factors without prior expert input. We observed that data-driven models used on an extended dataset can outperform conventional models for prognosis, without data preprocessing or imputing missing values. An elastic net Cox regression based with 586 unimputed variables with continuous values discretised achieved a C-index of 0.801 (bootstrapped 95% CI 0.799 to 0.802), compared to 0.793 (0.791 to 0.794) for a traditional Cox model comprising 27 expert-selected variables with imputation for missing values. We also found that data-driven models allow identification of novel prognostic variables; that the absence of values for particular variables carries meaning, and can have significant implications for prognosis; and that variables often have a nonlinear association with mortality, which discretised Cox models and random forests can elucidate. This demonstrates that machine-learning approaches applied to raw EHR data can be used to build models for use in research and clinical practice, and identify novel predictive variables and their effects to inform future research.",
      "authors": "Steele Andrew J; Denaxas Spiros C; Shah Anoop D; Hemingway Harry; Luscombe Nicholas M",
      "year": "2018",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0202344",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30169498/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Cohort Studies; Coronary Artery Disease; Data Interpretation, Statistical; Diagnosis, Computer-Assisted; Electronic Health Records; Female; Humans; Machine Learning; Male; Middle Aged; Models, Biological; Prognosis; Survival Analysis",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6118376"
    },
    {
      "pmid": "39711752",
      "title": "Feasibility of using an artificially intelligent chatbot to increase access to information and sexual and reproductive health services.",
      "abstract": "BACKGROUND: Following the US Supreme Court decision overturning Roe v. Wade, there is evidence of limitations in access to safe abortion care. Artificially intelligent (AI)-enabled conversational chatbots are becoming an appealing option to support access to care, but generative AI systems can misinform and hallucinate and risk reinforcing problematic bias and stigma related to sexual and reproductive healthcare. METHOD: A single arm pilot study describing the development of an AI chatbot focused on sexual and reproductive health and its deployment in a clinic setting and community-based organization over a nine-month period. RESULTS: We adjusted chatbot content based on feedback from the medical director and clients of organizations where the system was deployed given updated medical guidelines and preferred language related to gender-affirming care. We deployed the system in two organizations and tracked use over nine months. In that time, there were 1749 queries from 425 unique users. One-tenth of users of the clinic based chatbot went on to schedule an appointment for care. CONCLUSIONS: Ongoing challenges in accessing sexual and reproductive health suggest having diverse mechanisms to facilitate access to accurate and updated medical information is warranted. Using an AI chatbot is feasible to accomplish this goal and shows promise in increasing opportunities to access care.",
      "authors": "Bull Sheana; Hood Shakari; Mumby Sara; Hendrickson Anna; Silvasstar Joshva; Salyers Adam",
      "year": "2024",
      "journal": "Digital health",
      "doi": "10.1177/20552076241308994",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39711752/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; access to care; chatbots; health communication; machine learning; natural language processing; sexual health communication",
      "pub_types": "Journal Article",
      "pmcid": "PMC11660256"
    },
    {
      "pmid": "41407112",
      "title": "Leveraging low-cost app-based step count data to assess depression and anxiety in university students: A cross-sectional mobile health study.",
      "abstract": "BACKGROUND: The prevalence of depression and anxiety among college students worldwide is on the rise, significantly impacting their health and quality of life. Traditional mental health screening scales have some limitations, including subjectivity and recall bias. Therefore, developing rapid, low-cost objective detection technologies is needed. METHODS: We designed a low-cost, app-based data collection system to collect step count data and self-reported depression and anxiety questionnaires. This cross-sectional study included 578 participants with 28\u00a0days of step count data. Beyond basic statistical step metrics, we extracted frequency domain and non-linear features to capture lifestyle periodicity and regularity, and we novelly introduced a weekday-weekend activity fluctuation feature to quantify behavioral variability. We examined the associations between these features and depression/anxiety severity, and further evaluated machine learning models for depression/anxiety status classification. RESULTS: Several step count features showed significant associations with higher depression scores, including lower overall steps, reduced lifestyle regularity, and greater weekday-weekend fluctuations. Anxiety severity was also associated with lower regularity in step counts. In binary classification, the depression model achieved acceptable performance (AUC\u00a0=\u00a00.802, 95\u00a0% CI: 0.766-0.838; accuracy\u00a0=\u00a071.1\u00a0%, 95\u00a0% CI: 69.8\u00a0%-75.5\u00a0%). LIMITATIONS: The cross-sectional study cannot explain causal relationships. Additionally, unmeasured confounding factors may influence the observed associations. CONCLUSIONS: This study demonstrates that step count-derived features are significantly associated with depression and anxiety severity, highlighting the potential of passive sensing data as a scalable, low-cost screening approach for mental health assessment.",
      "authors": "Huang Jiali; Zhang Yuezhou; Zhou Dongsheng; Li Xingxing; Li Hui; Lian Bin; Cai Weiming; Cao Liyu; Liu Juan; Xu Fenfen; Wang Lang; Fu Zhengke; Han Zhili; Qin Shengjie; Wei Chaoran; Fei Zihan; Zhao Xianghong",
      "year": "2026",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2025.120880",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41407112/",
      "mesh_terms": "Humans; Cross-Sectional Studies; Male; Female; Mobile Applications; Students; Universities; Depression; Young Adult; Anxiety; Adult; Surveys and Questionnaires; Adolescent; Telemedicine",
      "keywords": "Anxiety; Depression; Machine learning; Mobile health; Physical activity; Step count",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39966793",
      "title": "How good is your synthetic data? SynthRO, a dashboard to evaluate and benchmark synthetic tabular data.",
      "abstract": "BACKGROUND: The exponential growth in patient data collection by healthcare providers, governments, and private industries is yielding large and diverse datasets that offer new insights into critical medical questions. Leveraging extensive computational resources, Machine Learning and Artificial Intelligence are increasingly utilized to address health-related issues, such as predicting outcomes from Electronic Health Records and detecting patterns in multi-omics data. Despite the proliferation of medical devices based on Artificial Intelligence, data accessibility for research is limited due to privacy concerns. Efforts to de-identify data have met challenges in maintaining effectiveness, particularly with large datasets. As an alternative, synthetic data, that replicate main statistical properties of real patient data, are proposed. However, the lack of standardized evaluation metrics complicates the selection of appropriate synthetic data generation methods. Effective evaluation of synthetic data must consider resemblance, utility and privacy, tailored to specific applications. Despite available metrics, benchmarking efforts remain limited, necessitating further research in this area. RESULTS: We present SynthRO (Synthetic data Rank and Order), a user-friendly tool for benchmarking health synthetic tabular data across various contexts. SynthRO offers accessible quality evaluation metrics and automated benchmarking, helping users determine the most suitable synthetic data models for specific use cases by prioritizing metrics and providing consistent quantitative scores. Our dashboard is divided into three main sections: (1) Loading Data section, where users can locally upload real and synthetic datasets; (2) Evaluation section, in which several quality assessments are performed by computing different metrics and measures; (3) Benchmarking section, where users can globally compare synthetic datasets based on quality evaluation. CONCLUSIONS: Synthetic data mitigate concerns about privacy and data accessibility, yet lacks standardized evaluation metrics. SynthRO provides an accessible dashboard helping users select suitable synthetic data models, and it also supports various use cases in healthcare, enhancing prognostic scores and enabling federated learning. SynthRO's accessible GUI and modular structure facilitate effective data evaluation, promoting reliability and fairness. Future developments will include temporal data evaluation, further broadening its applicability.",
      "authors": "Santangelo Gabriele; Nicora Giovanna; Bellazzi Riccardo; Dagliati Arianna",
      "year": "2025",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-024-02731-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39966793/",
      "mesh_terms": "Benchmarking; Humans; Electronic Health Records; Artificial Intelligence; Datasets as Topic",
      "keywords": "Benchmarking Tools; Electronic Health Records (EHRs); Synthetic Tabular Data evaluation; Synthetic data; Utility and privacy evaluation",
      "pub_types": "Journal Article",
      "pmcid": "PMC11837667"
    },
    {
      "pmid": "37650647",
      "title": "Development and Validation of a Claims-Based Model to Predict Categories of Obesity.",
      "abstract": "We developed and validated a claims-based algorithm that classifies patients into obesity categories. Using Medicare (2007-2017) and Medicaid (2000-2014) claims data linked to 2 electronic health record (EHR) systems in Boston, Massachusetts, we identified a cohort of patients with an EHR-based body mass index (BMI) measurement (calculated as weight (kg)/height (m)2). We used regularized regression to select from 137 variables and built generalized linear models to classify patients with BMIs of \u226525, \u226530, and \u226540. We developed the prediction model using EHR system 1 (training set) and validated it in EHR system 2 (validation set). The cohort contained 123,432 patients in the Medicare population and 40,736 patients in the Medicaid population. The model comprised 97 variables in the Medicare set and 95 in the Medicaid set, including BMI-related diagnosis codes, cardiovascular and antidiabetic drugs, and obesity-related comorbidities. The areas under the receiver-operating-characteristic curve in the validation set were 0.72, 0.75, and 0.83 (Medicare) and 0.66, 0.66, and 0.70 (Medicaid) for BMIs of \u226525, \u226530, and \u226540, respectively. The positive predictive values were 81.5%, 80.6%, and 64.7% (Medicare) and 81.6%, 77.5%, and 62.5% (Medicaid), for BMIs of \u226525, \u226530, and \u226540, respectively. The proposed model can identify obesity categories in claims databases when BMI measurements are missing and can be used for confounding adjustment, defining subgroups, or probabilistic bias analysis.",
      "authors": "Suissa Karine; Wyss Richard; Lu Zhigang; Bessette Lily G; York Cassandra; Tsacogianis Theodore N; Lin Kueiyu Joshua",
      "year": "2024",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwad178",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37650647/",
      "mesh_terms": "Aged; Humans; United States; Medicare; Obesity; Body Mass Index; Comorbidity; Hypoglycemic Agents; Electronic Health Records",
      "keywords": "body mass index; machine learning; missing data; obesity; pharmacoepidemiology; prediction modeling",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11484604"
    },
    {
      "pmid": "41157332",
      "title": "Assessing Obstructive Sleep Apnea Severity During Wakefulness via Tracheal Breathing Sound Analysis.",
      "abstract": "Obstructive sleep apnea (OSA) is a commonly underdiagnosed condition that not only increases the risk of accidents but also significantly contributes to a wide range of health complications, including heightened perioperative morbidity and mortality risks during surgeries under general anesthesia. Polysomnography (PSG), which is the diagnostic gold standard, is costly, requires skilled technicians, is time-consuming, and is not always accessible. This study presents a fast, objective, and non-invasive method for detecting OSA severity by analyzing tracheal breathing sounds (TBS) recorded during wakefulness in supine position. Features were extracted from six binary (1-vs-1) severity comparisons-Non-OSA, Mild, Moderate, and Severe-and combined with anthropometric characteristics for classification. The data of 199 subjects (74 Non-OSA, 35 Mild, 50 Moderate, and 40 Severe) were analyzed, the data of 169 and 30 was used for training and blind testing, respectively, and the training dataset was shuffled 10 times to avoid any bias during training. Multiple machine learning models were evaluated, and the best-performing model for each was saved. Across six experimental models comparing OSA severity levels, the most balanced performance was achieved by the Base Model of Non-OSA vs. Severe-OSA using the support vector machine algorithm, with 88.2% accuracy, 83.3% sensitivity, and 90.9% specificity. While Random Forests in the Base Model of Non-OSA vs. Mild-OSA achieved 100% sensitivity, its accuracy was lower (81.2%). The results confirm the reliability and robustness of the proposed approach, providing a basis for OSA severity screening in under 10 min during wakefulness.",
      "authors": "Alqudah Ali Mohammad; Moussavi Zahra",
      "year": "2025",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s25206280",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41157332/",
      "mesh_terms": "Humans; Sleep Apnea, Obstructive; Wakefulness; Male; Respiratory Sounds; Middle Aged; Female; Polysomnography; Adult; Trachea; Support Vector Machine; Algorithms; Severity of Illness Index; Machine Learning",
      "keywords": "OSA severity prediction; obstructive sleep apnea; tracheal breathing sounds; wakefulness screening",
      "pub_types": "Journal Article",
      "pmcid": "PMC12567693"
    },
    {
      "pmid": "40956157",
      "title": "Novel and optimized mouse behavior enabled by fully autonomous HABITS: Home-cage assisted behavioral innovation and testing system.",
      "abstract": "Mice are among the most prevalent animal models used in neuroscience, benefiting from the extensive physiological, imaging, and genetic tools available to study their brain. However, the development of novel and optimized behavioral paradigms for mice has been laborious and inconsistent, impeding the investigation of complex cognitions. Here, we present a home-cage assisted mouse behavioral innovation and testing system (HABITS), enabling free-moving mice to learn challenging cognitive behaviors in their home-cage without any human involvement. Supported by the general programming framework, we have not only replicated established paradigms in current neuroscience research but also developed novel paradigms previously unexplored in mice, resulting in more than 300 mice demonstrated in various cognition functions. Most significantly, HABITS incorporates a machine-teaching algorithm, which comprehensively optimized the presentation of stimuli and modalities for trials, leading to more efficient training and higher-quality behavioral outcomes. To our knowledge, this is the first instance where mouse behavior has been systematically optimized by an algorithmic approach. Altogether, our results open a new avenue for mouse behavioral innovation and optimization, which directly facilitates investigation of neural circuits for novel cognitions with mice.",
      "authors": "Yu Bowen; Li Penghai; Xu Haoze; Wang Yueming; Xu Kedi; Hao Yaoyao",
      "year": "2025",
      "journal": "eLife",
      "doi": "10.7554/eLife.104833",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40956157/",
      "mesh_terms": "Animals; Mice; Behavior, Animal; Cognition; Male; Habits; Mice, Inbred C57BL; Algorithms",
      "keywords": "autonomous training; behavioral innovation; behavioral optimization; machine teaching; mouse; mouse cognition; neuroscience",
      "pub_types": "Journal Article",
      "pmcid": "PMC12440354"
    },
    {
      "pmid": "38977198",
      "title": "Characterizing the consistency of motion of spermatozoa through nanoscale motion tracing.",
      "abstract": "OBJECTIVE: To demonstrate nanoscale motion tracing of spermatozoa and present analysis of the motion traces to characterize the consistency of motion of spermatozoa as a complement to progressive motility analysis. DESIGN: Anonymized sperm samples were videographed under a quantitative phase microscope, followed by generating and analyzing superresolution motion traces of individual spermatozoa. SETTING: Not applicable. PATIENT(S): Centrifuged human sperm samples. INTERVENTION(S): Not applicable. MAIN OUTCOME MEASURE(S): Precision of motion trace of individual sperms, presence of a helical pattern in the motion trace, mean and standard deviations of helical periods and radii of sperm motion traces, speed of progression. RESULT(S): Spatially sensitive quantitative phase imaging with a superresolution computational technique MUltiple SIgnal Classification ALgorithm allowed achieving motion precision of 340 nm using \u00d710, 0.25 numerical aperture lens whereas the diffraction-limited resolution at this setting was 1,320 nm. The motion traces thus derived facilitated new kinematic features of sperm, namely the statistics of helix period and radii per sperm. Through the analysis, 47 sperms with a speed >25 \u03bcm/s were randomly selected from the same healthy donor semen sample, it is seen that the kinematic features did not correlate with the speed of the sperms. In addition, it is noted that spermatozoa may experience changes in the periodicity and radius of the helical path over time. Further, some very fast sperms (e.g., >70 \u03bcm/s) may demonstrate irregular motion and need further investigation. Presented computational analysis can be used directly for sperm samples from both fertility patients with normal and abnormal sperm cell conditions. We note that MUltiple SIgnal Classification ALgorithm is an image analysis technique that may vaguely fall under the machine learning category, but the conventional metrics for reporting found in Enhancing the QUAlity and Transparency Of health Research network do not apply. Alternative suitable metrics are reported, and bias is avoided through random selection of regions for analysis. Detailed methods are included for reproducibility. CONCLUSION(S): Kinematic features derived from nanoscale motion traces of spermatozoa contain information complementary to the speed of the sperms, allowing further distinction among the progressively motile sperms. Some highly progressive spermatozoa may have irregular motion patterns, and whether irregularity of motion indicates poor quality regarding artificial insemination needs further investigation. The presented technique can be generalized for sperm analysis for a variety of fertility conditions.",
      "authors": "Bhatt Sunil; Butola Ankit; Acu\u00f1a Sebastian; Hansen Daniel Henry; Tinguely Jean-Claude; Nystad Mona; Mehta Dalip Singh; Agarwal Krishna",
      "year": "2024",
      "journal": "F&S science",
      "doi": "10.1016/j.xfss.2024.07.002",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38977198/",
      "mesh_terms": "Male; Humans; Sperm Motility; Spermatozoa; Algorithms; Biomechanical Phenomena; Semen Analysis; Image Processing, Computer-Assisted",
      "keywords": "Assisted reproduction; beyond progressive motility; computer-assisted sperm analysis; sperm cells; sperm selection",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "18488068",
      "title": "Creating diagnostic scores using data-adaptive regression: An application to prediction of 30-day mortality among stroke victims in a rural hospital in India.",
      "abstract": "Developing diagnostic scores for prediction of clinical outcomes uses medical knowledge regarding which variables are most important and empirical/statistical learning to find the functional form of these covariates that provides the most accurate prediction (eg, highest specificity and sensitivity). Given the variables chosen by the clinician as most relevant or available due to limited resources, the job is a purely statistical one: which model, among competitors, provides the most accurate prediction of clinical outcomes, where accuracy is relative to some loss function. An optimal algorithm for choosing a model follows: (1) provides a flexible, sequence of models, which can 'twist and bend' to fit the data and (2) use of a validation procedure that optimally balances bias/variance by choosing models of the right size (complexity). We propose a solution to creating diagnostic scores that, given the available variables, will appropriately trade-off model complexity with variability of estimation; the algorithm uses a combination of machine learning, logistic regression (POLYCLASS) and cross-validation. For example, we apply the procedure to data collected from stroke victims in a rural clinic in India, where the outcome of interest is death within 30 days. A quick and accurate diagnosis of stroke is important for immediate resuscitation. Equally important is giving patients and their families an indication of the prognosis. Accurate predictions of clinical outcomes made soon after the onset of stroke can also help choose appropriate supporting treatment decisions. Severity scores have been created in developed nations (for instance, Guy's Prognostic Score, Canadian Neurological Score, and the National Institute of Health Stroke Scale). However, we propose a method for developing scores appropriate to local settings in possibly very different medical circumstances. Specifically, we used a freely available and easy to use exploratory regression technique (POLYCLASS) to predict 30-day mortality following stroke in a rural Indian population and compared the accuracy of the technique with these existing stroke scales, resulting in more accurate prediction than the existing scores (POLYCLASS sensitivity and specificity of 90% and 76%, respectively). This method can easily be extrapolated to different clinical settings and for different disease outcomes. In addition, the software and algorithms used are open-source (free) and we provide the code in the appendix.",
      "authors": "Birkner Merrill D; Kalantri Sp; Solao Vaishali; Badam Priya; Joshi Rajnish; Goel Ashish; Pai Madhukar; Hubbard Alan E",
      "year": "2007",
      "journal": "Therapeutics and clinical risk management",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/18488068/",
      "mesh_terms": "",
      "keywords": "accuracy; mortality; prediction; prognostic model; stroke",
      "pub_types": "Journal Article",
      "pmcid": "PMC2386350"
    },
    {
      "pmid": "41232266",
      "title": "Mind the (widening) gap: why public health must engage with AI now.",
      "abstract": "OBJECTIVES: This commentary aims to highlight the opportunities and challenges that Artificial Intelligence (AI) presents for public health. STUDY DESIGN: Narrative commentary and conceptual analysis. METHODS: The commentary draws on material developed for a forthcoming book by the European Observatory on Health Systems and Policies. Sources were selected to highlight both the potential and the limitations of AI integration at population levels, with a focus on equity, governance, and implementation. The analysis is informed by established public health principles: prevention, systems thinking, and the social determinants of health. RESULTS: AI applications in public health go beyond process automation and operational efficiency. By integrating and processing diverse, multi-modal data sources, its implementation presents opportunities to understand the wider determinants of health at a more nuanced level and identify populations at risk with greater precision. Additionally, AI has the potential to help understand and support behaviour change in sophisticated ways, enhance disease surveillance and modelling, and enable more targeted and responsive public communication and engagement strategies. However, there are several barriers to realise AI's potential in public health, including system fragmentation, data access limitations, resource constraints, implementation challenges, workforce readiness gaps, and technological limitations such as bias and generative AI \"hallucinations\". CONCLUSION: Without deliberate engagement, AI risks reinforcing existing inequities. Practical steps for action include embedding AI training in public health education, building multidisciplinary teams, investing in data infrastructure, and ensuring participatory approaches. AI will continue to shape public health systems, whether or not public health professionals engage. We argue that the public health community is both uniquely positioned and ethically obligated to engage proactively with AI.",
      "authors": "Del Rey Puech Paula; Payne Rebecca; Saund Jasjot; McKee Martin",
      "year": "2026",
      "journal": "Public health",
      "doi": "10.1016/j.puhe.2025.106047",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41232266/",
      "mesh_terms": "Humans; Artificial Intelligence; Public Health; Social Determinants of Health",
      "keywords": "Artificial Intelligence; Equity; Machine Learning; Public Health",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41501115",
      "title": "Machine learning assessment of retinal blood flow links metabolic dysfunction and accelerated microvascular aging.",
      "abstract": "Microvascular aging impairs tissue perfusion and contributes to age-related organ dysfunction; however, direct approaches to assess microvascular aging remain limited. Here, we developed machine learning models to estimate chronological age from retinal blood flow data acquired by laser speckle flowgraphy (LSFG) in 1,008 adults undergoing health checkups. Using 18 predefined parameters and 3,253 automatically extracted time-series features, the best model for all participants achieved a mean absolute percentage error (MAPE) of 10.3% between predicted and chronological age. In addition, sex-specific models for women and men outperformed the model for all participants (MAPE 8.6% in women and 9.3% in men), allowing us to explore sex differences in microvascular aging patterns. Based on bias-corrected residuals, we defined a novel biomarker, the relative microvascular aging index (rmVAI). Higher rmVAI was significantly associated with elevated blood pressure, diabetes, metabolic syndrome, and metabolic dysfunction-associated fatty liver disease (MAFLD). Individuals classified as \"model-predicted older\" (rmVAI\u2009>\u200910%) had higher fatty liver index values (mean 38.2 vs 26.7) and an approximately twofold higher prevalence of hepatic steatosis (26% vs 12%) than those classified as \"model-predicted younger\" (rmVAI\u2009< -\u200910%). Our LSFG-based machine learning framework provides a scalable and non-invasive tool for quantifying microvascular aging from retinal blood flow and suggests that MAFLD is a potent systemic contributor to accelerated microvascular aging, supporting a putative \"liver-microvascular axis\" that warrants further investigation for early risk stratification in clinical practice.",
      "authors": "Magi Shigeyuki; Maruyama Takahiro; Takagi Seiji; Naito Atsuhiko T; Hori Yuichi",
      "year": "2026",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-32776-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41501115/",
      "mesh_terms": "Humans; Machine Learning; Female; Male; Middle Aged; Retinal Vessels; Adult; Aged; Aging; Microvessels; Microcirculation; Regional Blood Flow; Retina",
      "keywords": "Laser speckle flowgraphy; Machine learning; Metabolic dysfunction\u2013associated fatty liver disease; Metabolic syndrome; Microvascular aging; Retinal blood flow",
      "pub_types": "Journal Article",
      "pmcid": "PMC12827333"
    },
    {
      "pmid": "41348847",
      "title": "Comparison of multivariable methods for determining cutpoints of biomarkers in the context of survival time analyses: A simulation study with practical applications to survival data.",
      "abstract": "INTRODUCTION: Survival time models are commonly employed in medicine and health sciences when analysing data. In these time-to-event analyses, it is often necessary to dichotomise variables that are metrically measured. One example could be to assign patients to different risk groups based on an occurring event. Besides univariable methods, multivariable approaches also exist for establishing cutpoints. Up to now, these multivariable approaches have hardly been investigated. METHODS: Using a Monte Carlo simulation study, we analysed eight multivariable methods from the literature to establish a cutpoint of a biomarker in the context of a semiparametric Cox regression model. The methods are the following: maximising the chi-square statistic, maximising the chi-square statistic with a split-sample approach, maximising the c-index using either the AddFor- or Genetic algorithm, maximising the concordance probability estimator (CPE) with the AddFor- or Genetic algorithm, and minimising the Akaike information criterion (AIC). We compared these methods with each other and in addition with the univariable log-rank minimum p-value approach. The simulation parameters analysed included the cutpoint's distance from the biomarker's median, sample size, total censoring, censoring before the end of the follow-up time (drop-outs), and the survival time distribution. Bias and empirical standard error were used as the primary performance measures. Furthermore, each method is illustrated using two practical data examples. RESULTS: All analysed methods are biased towards the biomarker's median. Multivariable methods that estimate the cutpoint by using the lowest AIC or the maximum of the chi-square statistic have the lowest bias and empirical standard error in most simulation scenarios. The difference in bias between the methods based on maximising the c-index or maximising the CPE is minimal. Regardless of the distribution used (Weibull, Gompertz, or exponential), the respective bias shows similar dependencies on the simulation parameters. CONCLUSIONS: Multivariable methods to estimate a biomarker's cutpoint in survival time analyses using the Cox regression model may represent a good alternative to univariable methods. Our simulation has shown that methods maximising the chi-square statistic or minimising the AIC, respectively, perform better than the univariable method using the minimum p-value approach and outperform multivariable methods based on the c-index or CPE.",
      "authors": "Porthun Jan; Wienke Andreas",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0338425",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41348847/",
      "mesh_terms": "Humans; Biomarkers; Monte Carlo Method; Computer Simulation; Survival Analysis; Proportional Hazards Models; Multivariate Analysis; Algorithms",
      "keywords": "",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": "PMC12680250"
    },
    {
      "pmid": "38317167",
      "title": "Comparison of Sysmex XN-V body fluid mode and deep-learning-based quantification with manual techniques for total nucleated cell count and differential count for equine bronchoalveolar lavage samples.",
      "abstract": "BACKGROUND: Bronchoalveolar lavage (BAL) is a diagnostic method for the assessment of the lower respiratory airway health status in horses. Differential cell count and sometimes also total nucleated cell count (TNCC) are routinely measured by time-consuming manual methods, while faster automated methods exist. The aims of this study were to compare: 1) the Sysmex XN-V body fluid (BF) mode with the manual techniques for TNCC and two-part differential into mononuclear and polymorphonuclear cells; 2) the Olympus VS200 slide scanner and software generated deep-learning-based algorithm with manual techniques for four-part differential cell count into alveolar macrophages, lymphocytes, neutrophils, and mast cells. The methods were compared in 69 clinical BAL samples. RESULTS: Incorrect gating by the Sysmex BF mode was observed on many scattergrams, therefore all samples were reanalyzed with manually set gates. For the TNCC, a proportional and systematic bias with a correlation of r\u2009=\u20090.79 was seen when comparing the Sysmex BF mode with manual methods. For the two-part differential count, a mild constant and proportional bias and a very small mean difference with moderate limits of agreement with a correlation of r\u2009=\u20090.84 and 0.83 were seen when comparing the Sysmex BF mode with manual methods. The Sysmex BF mode classified significantly more samples as abnormal based on the TNCC and the two-part differential compared to the manual method. When comparing the Olympus VS200 deep-learning-based algorithm with manual methods for the four-part differential cell count, a very small bias in the regression analysis and a very small mean difference in the difference plot, as well as a correlation of r\u2009=\u20090.85 to 0.92 were observed for all four cell categories. The Olympus VS200 deep-learning-based algorithm also showed better precision than manual methods for the four-part differential cell count, especially with an increasing number of analyzed cells. CONCLUSIONS: The Sysmex XN-V BF mode can be used for TNCC and two-part differential count measurements after reanalyzing the samples with manually set gates. The Olympus VS200 deep-learning-based algorithm correlates well with the manual methods, while showing better precision and can be used for a four-part differential cell count.",
      "authors": "Lapsina Sandra; Riond Barbara; Hofmann-Lehmann Regina; Stirn Martina",
      "year": "2024",
      "journal": "BMC veterinary research",
      "doi": "10.1186/s12917-024-03884-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38317167/",
      "mesh_terms": "Animals; Horses; Deep Learning; Body Fluids; Cell Count; Lymphocytes; Algorithms; Leukocyte Count; Reproducibility of Results",
      "keywords": "Artificial intelligence; Body fluid mode; Bronchoalveolar lavage; Deep-learning; Differential count; Equine; Regating; Sysmex; Total nucleated cell count",
      "pub_types": "Journal Article",
      "pmcid": "PMC10840287"
    },
    {
      "pmid": "40527301",
      "title": "Using Machine Learning to Predict Medication Therapy Problems among Patients with Chronic Kidney Disease.",
      "abstract": "INTRODUCTION: Patients with chronic kidney disease (CKD) are at risk of medication therapy problems (MTPs) due to high comorbidity and medication burden. Using data from the Kidney Coordinated HeAlth Management Partnership (Kidney CHAMP) trial, we used machine learning to build a predictive model to identify MTP high-risk patients with CKD in the primary care setting. METHODS: We used baseline data from patients enrolled in the intervention arm of the Kidney CHAMP trial, completed May 2019-July 2022, which tested a population health management strategy, including medication management, for improving CKD care. The dataset was divided into 80% training and 20% testing subsets. The area under the ROC curve (AUROC) was used to assess classification accuracy in distinguishing between patients with and without MTP. Eight candidate models were considered, and the top three performing models (random forest, support vector machines, and gradient boosting), based on cross-validated AUROC on training data, underwent further refinement. The model with the highest AUROC in the testing set, while considering the bias/variance trade-off, was selected as the best-performing model. SHapley Additive exPlanations was then leveraged using the best-performing model to evaluate the impact of each predictor to the final risk score. RESULTS: Among 730 patients who received medication review at baseline, 566 (77.5%) had at least 1 MTP. Key demographics were mean age 74 years, 55% female, 92% white, 64% with diabetes, and the mean number of medications 5.8 at baseline. The random forest model had the best performance on the testing set with AUROC 0.72, sensitivity 0.80, and specificity 0.64. The five most influential variables, ranked in descending order of importance for predicting individuals with MTP, were diabetes status (yes/no), hemoglobin A1C (HbA1C), urine albumin-to-creatinine ratio (UACR), systolic blood pressure, and age. CONCLUSION: In outpatient primary care, a machine learning-based MTP risk calculator that uses routinely available clinical data can identify patients with moderate-high-risk CKD who are at high risk for developing MTPs.",
      "authors": "Alghwiri Alaa A; Weltman Melanie R; Lavenburg Linda-Marie U; Han Zhuoheng; Nolin Thomas D; Chen Yi-Fan; Yabes Jonathan G; Jhamb Manisha",
      "year": "2026",
      "journal": "American journal of nephrology",
      "doi": "10.1159/000546540",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40527301/",
      "mesh_terms": "Humans; Renal Insufficiency, Chronic; Female; Machine Learning; Male; Aged; Middle Aged; Primary Health Care; ROC Curve; Risk Assessment",
      "keywords": "Machine learning; Medication therapy problems",
      "pub_types": "Journal Article",
      "pmcid": "PMC12218150"
    },
    {
      "pmid": "35967967",
      "title": "Linking multi-media modeling with machine learning to assess and predict lake Chlorophyll a concentrations.",
      "abstract": "Eutrophication and excessive algal growth pose a threat on aquatic organisms and the health of the public, environment, and the economy. Understanding what drives excessive algal growth can inform mitigation measures and aid in advance planning to minimize impacts. We demonstrate how simulated data from weather, hydrological, and agroecosystem numerical prediction models can be combined with machine learning (ML) to assess and predict Chlorophyll a (Chl a) concentrations, a proxy for lake eutrophication and algal biomass. The study area is Lake Erie for a 16-year period, 2002-2017. A total of 20 environmental variables from linked and coupled physical models are used as input features to train the ML model with Chl a observations from 16 measuring stations. Included are meteorological variables from the Weather Research and Forecasting (WRF) model, hydrological variables from the Variable Infiltration Capacity (VIC) model, and agricultural management practice variables from the Environmental Policy Integrated Climate (EPIC) agroecosystem model. The consolidation of these variables is conducive to a successful prediction of Chl a. Aside from the synergistic effects that weather, hydrology, and fertilizers have on eutrophication and excessive algal growth, we found that the application of different forms of both P and N fertilizers are highly ranked for the prediction of Chl a concentration. The developed ML model successfully predicts Chl a with a coefficient of determination of 0.81, bias of -0.12 \u03bcg/l and RMSE of 4.97 \u03bcg/l. The developed ML-based modeling approach can be used for impact assessment of agriculture practices in a changing climate that affect Chl a concentrations in Lake Erie.",
      "authors": "Chang Christina Feng; Garcia Valerie; Tang Chunling; Vlahos Penny; Wanik David; Yan Jun; Bash Jesse O; Astitha Marina",
      "year": "2021",
      "journal": "Journal of Great Lakes research",
      "doi": "10.1016/j.jglr.2021.09.011",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35967967/",
      "mesh_terms": "",
      "keywords": "Fertilizers; Lake eutrophication; Machine learning; Numerical prediction models",
      "pub_types": "Journal Article",
      "pmcid": "PMC9364922"
    },
    {
      "pmid": "40815998",
      "title": "Machine learning-driven analysis of temporal pupil dynamics for interpretable ADHD diagnosis.",
      "abstract": "Attention-deficit/hyperactivity disorder (ADHD) is a prevalent neurodevelopmental disorder characterized by inattention and hyperactivity. Current diagnostic methods rely on bias-prone subjective assessments, such as clinical interviews and behavior rating scales. Objective biomarkers remain elusive hindering standardized ADHD diagnosis. Pupillometry, measuring pupil responses linked to cognition and attention, offers a promising, objective alternative. However, prior work often overlooks clinically relevant features and lacks interpretability, limiting clinical adoption. We introduce an interpretable machine-learning framework leveraging temporal pupil dynamics to classify ADHD and control groups. The primary novelty of our work lies in identifying and statistically validating task-aligned features-specifically, novel dynamic pupil dilation and constriction rates extracted in block-wise temporal segments-which capture subtle attentional fluctuations overlooked by prior models. We analyzed published pupillometry data from 49 participants (21 controls, 28 ADHD, 17 assessed on and off medication) during a visuospatial working memory task. Candidate features were identified through statistical analyses using mixed analysis of variance. Classification models were trained to prioritize interpretability by utilizing statistically significant, literature-supported features. Model transparency was enhanced with heatmaps and feature-importance charts. The models demonstrated strong classification performance: using pupil features alone yielded 84.4% accuracy (area under the receiver operating characteristic (AUROC) 88.6%). Including task performance improved accuracy to 86.7% (AUROC 91.5%). Final integration of reaction time metrics achieved 88.9% accuracy (AUROC 90.8%), with 97.8% sensitivity and 82.2% specificity. By leveraging interpretable, dynamic pupil metrics, our approach advances objective, reproducible ADHD diagnosis and supports clinical deployment.",
      "authors": "Sharma Swati; Chakrabarty Mrinmoy; Ray Sonia Baloni; Shukla Jainendra",
      "year": "2025",
      "journal": "Computers in biology and medicine",
      "doi": "10.1016/j.compbiomed.2025.110878",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40815998/",
      "mesh_terms": "Humans; Attention Deficit Disorder with Hyperactivity; Pupil; Machine Learning; Male; Female; Child; Adolescent",
      "keywords": "Attention-deficit/hyperactivity disorder; Deep learning; Machine learning; Mental health; Neurodevelopment; Pupillometry",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "27131074",
      "title": "Validation of objective records and misreporting of personal radio use in a cohort of British Police forces (the Airwave Health Monitoring Study).",
      "abstract": "BACKGROUND: Terrestrial Trunked Radio (TETRA) is a digital communication system progressively adopted by Police Forces in Great Britain since 2001. In 2000, the UK Independent Expert Group on Mobile Phones suggested that exposure to TETRA-like signal modulation might have adverse effects on health. The Airwave Health Monitoring Study was established to investigate possible long-term effects of TETRA use on health. This requires estimation of TETRA use among Police Force employees participating in the study. METHODS: We investigated TETRA usage among 42,112 Police officers and staff. An algorithm was created to link each personal radio user to his/her objective radio usage records for the 26,035 participants with available data. We linked 16,577 personal radio users to their objective radio usage records and compared self-reported usage with data from the TETRA operator for those individuals. RESULTS: For weekly usage, the correlation between self-reported and operator-derived personal radio usage was r=0.69 for number and r=0.59 for the duration of calls. Compared with objective data, participants under-reported the number of calls and over-reported the duration of calls by a factor of around 4 and 1.6 respectively. Correlations were lower and bias higher when looking at daily usage. CONCLUSION: Where both objective and self-reported information were available, our study showed substantial misreporting in self-reported TETRA usage. Successful linkage of large numbers of TETRA users to objective data on their personal radios will allow objective assessment of TETRA radio usage for these participants and development of algorithms to correct bias in self-reported data for the remainder.",
      "authors": "Vergnaud Anne-Claire; Aresu Maria; McRobie Dennis; Singh Deepa; Spear Jeanette; Heard Andy; Elliott Paul",
      "year": "2016",
      "journal": "Environmental research",
      "doi": "10.1016/j.envres.2016.04.018",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27131074/",
      "mesh_terms": "Adult; Algorithms; Bias; Female; Humans; Male; Middle Aged; Occupational Exposure; Police; Radio; Radio Waves; Reproducibility of Results; Self Report; United Kingdom",
      "keywords": "Electromagnetic field; Occupational cohort; Radio frequency; TETRA",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40908883",
      "title": "Deconvoluting and Interpreting Nontargeted Chemical Data: A Data-Driven Forensic Workflow for Identifying the Most Prominent Chemical Sources in Receiving Waters.",
      "abstract": "Chemical forensics aims to identify major contamination sources, but existing workflows often rely on predefined targets and known sources, introducing bias. Here, we present a data-driven workflow that reduces this bias by applying an unsupervised machine learning technique. We applied both nonmetric multidimensional scaling (NMDS) and non-negative matrix factorization (NMF) on the same nontargeted chemical data set to compare their different interpretations of environmental sources. Weekly nontargeted data was collected from the Fall Creek Monitoring Station (Ithaca, NY), where daily samples were previously analyzed using source-defined models. NMF was first used to decompose the full nontargeted chemical data set into a small set of chemical factors representing distinct composition profiles. Each factor was then interpreted through (1) Spearman correlations with watershed characteristics (e.g., temperature, flow) and (2) suspect screening of high-weighted nontargeted features. In addition to confirming known anthropogenic inputs, our analysis revealed potential novel sources associated with snowmelt, groundwater seepage, and seasonal hydrological dynamics. We also detected an annual shift in the chemical composition, highlighting the evolving influence of these sources. This workflow enables watershed managers to move beyond predefined sources, detect both known and emerging chemical contributors, and apply adaptive, evidence-based strategies to protect water quality under changing conditions.",
      "authors": "Shi Cheng; Carpenter Corey M G; Helbling Damian E; Jones Gerrad D",
      "year": "2025",
      "journal": "Environmental science & technology",
      "doi": "10.1021/acs.est.5c07541",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40908883/",
      "mesh_terms": "Environmental Monitoring; Water Pollutants, Chemical; Groundwater; Machine Learning; Workflow",
      "keywords": "chemical forensics; non-negative matrix factorization; nontargeted analysis; unsupervised learning; watershed health",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39899627",
      "title": "Step-by-step causal analysis of EHRs to ground decision-making.",
      "abstract": "Causal inference enables machine learning methods to estimate treatment effects of medical interventions from electronic health records (EHRs). The prevalence of such observational data and the difficulty for randomized controlled trials (RCT) to cover all population/treatment relationships make these methods increasingly attractive for studying causal effects. However, researchers should be wary of many pitfalls. We propose and illustrate a framework for causal inference estimating the effect of albumin on mortality in sepsis using an Intensive Care database (MIMIC-IV) and comparing various sensitivity analyses to results from RCTs as gold-standard. The first step is study design, using the target trial concept and the PICOT framework: Population (patients with sepsis), Intervention (combination of crystalloids and albumin for fluid resuscitation), Control (crystalloids only), Outcome (28-day mortality), Time (intervention start within 24h of admission). We show that too large treatment-initiation times induce immortal time bias. The second step is selection of the confounding variables based on expert knowledge. Increasingly adding confounders enables to recover the RCT results from observational data. As the third step, we assess the influence of multiple models with varying assumptions, showing that a doubly robust estimator (AIPW) with random forests proved to be the most reliable estimator. Results show that these steps are all important for valid causal estimates. A valid causal model can then be used to individualize decision making: subgroup analyses showed that treatment efficacy of albumin was better for patients >60 years old, males, and patients with septic shock. Without causal thinking, machine learning is not enough for optimal clinical decision on an individual patient level. Our step-by-step analytic framework helps avoiding many pitfalls of applying machine learning to EHR data, building models that avoid shortcuts and extract the best decision-making evidence.",
      "authors": "Doutreligne Matthieu; Struja Tristan; Abecassis Judith; Morgand Claire; Celi Leo Anthony; Varoquaux Ga\u00ebl",
      "year": "2025",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000721",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39899627/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11790099"
    },
    {
      "pmid": "40101659",
      "title": "Enhancing pyrrolizidine alkaloid separation and detection: LC-MS/MS method development and integration of ion mobility spectrometry into the LC-HRMS workflow.",
      "abstract": "Pyrrolizidine alkaloids (PAs) are plant toxins occurring in different foodstuffs, including teas, herbal infusions and species. Additionally, PAs may be transferred to honey and pollen when honeybees come into contact with contaminated plants. Due to their adverse effect, PAs occurrence in food must be controlled to ensure public health. Nevertheless, the presence of numeours PA epimers complicates their chromatographic separation and detection. In this regard, a method using liquid chromatography coupled with tandem mass spectrosmetry (LC-MS/MS) has been developed allowing the separation of 31 out of the 35 regulated PAs, which was sucessfully validated in different food matrices such as herbal infusions, spices and honey. Afterwards, travelling wave ion mobility spectrometry hyphenated with quadrupole time-of-flight mass spectrometry (TWIMS-QTOF) was evaluated to improve the analytical performance of PAs determination. Thus, collision cross section (CCS) values of PAs have been therefore obtained for the first time. The CCS library for PAs was also compared with predicted values by machine learning and with those meassured in real food matrices (bias <2 %). In addition, an in-house library was used in the suspect screening of PAs to complement the targeted analysis of the studied samples, all of which tested positive for several PAs.",
      "authors": "Carbonell-Rozas Laura; Dreolin Nicola; Foddy Henry; Dall'Asta Chiara",
      "year": "2025",
      "journal": "Journal of chromatography. A",
      "doi": "10.1016/j.chroma.2025.465863",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40101659/",
      "mesh_terms": "Pyrrolizidine Alkaloids; Tandem Mass Spectrometry; Chromatography, Liquid; Ion Mobility Spectrometry; Limit of Detection; Reproducibility of Results; Food Contamination; Linear Models; Honey; Food Analysis; Liquid Chromatography-Mass Spectrometry",
      "keywords": "CCS; Herbal infusions; Honey; Ion mobility mass spectrometry; Pyrrolizidine alkaloids; Spices",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "28268385",
      "title": "Beat-to-beat heart rate detection by smartphone's accelerometers: validation with ECG.",
      "abstract": "UNLABELLED: Mobile phones offer the possibility to monitor and track health parameters. Our aim was to test the feasibility and accuracy of measuring beat-to-beat heart rate using smartphone accelerometers by recording the vibrations generated by the heart during its function and transmitted to the chest wall, i.e. the so-called seismocardiographic signal (SCG). METHODS: 9 healthy male volunteers were studied in supine (SUP) and in standing (ST) posture. A smartphone (iPhone6, Apple) was positioned on the thorax (POS1) to acquire SCG signal. While supine, a second smartphone was positioned on the navel (POS2). The SCG signal was recorded for 3 minutes during spontaneous respiration, synchronous with 3-leads ECG. Using a fully automated algorithm based on amplitude thresholding after rectification, the characteristic peak of the SCG signal (IVC) was detected and used to compute beat-to-beat heart duration, to be compared with the corresponding RR intervals extracted from the ECG. RESULTS: A 100% feasibility of the approach resulted for POS1 in SUP, while 89% in POS2, and 78% for POS1 in ST. In supine, for each smartphones' position, the automated algorithm correctly identified the cardiac beats with >98% accuracy. Linear correlation (r2) with RR was very high (>0.98) in each posture and position, with no bias and narrow limits of agreement. CONCLUSIONS: The obtained results proved the feasibility of the proposed approach and the robustness of the applied algorithm in measuring the beat-to-beat heart rate from smartphone-derived SCG, with high accuracy compared to conventional ECG-derived measure.",
      "authors": "Landreani F; Martin-Yebra A; Casellato C; Frigo C; Pavan E; Migeotte P-F; Caiani E G",
      "year": "2016",
      "journal": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference",
      "doi": "10.1109/EMBC.2016.7590755",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28268385/",
      "mesh_terms": "Accelerometry; Algorithms; Electrocardiography; Heart; Heart Rate; Humans; Male; Smartphone",
      "keywords": "",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": ""
    },
    {
      "pmid": "40944990",
      "title": "The sound of emergency: The role of vocal cues in healthcare.",
      "abstract": "A considerable body of research has explored how first impressions from voices influence social decisions, demonstrating the significance of perceived emotional and social traits alongside acoustic parameters across various contexts, including elections, legal decisions, and economic or mating-related choices. In a novel ecological context, specifically healthcare emergency dispatch, where trained nurses respond to critical health situations, we investigated whether caller voice characteristics (e.g., acoustic parameters, gender, emotional valence and arousal, social trait attributions) is related to healthcare professionals' prioritization decisions beyond available clinical information. We selected cases when the call-taker deviated from an algorithm, changing the proposed priority, to understand which factors may bias their decision. We dissociated acoustic-phonetic features from semantic content by manipulating stimuli across different experimental samples, comprised of Italian and American participants. Judgments of emotional traits (valence and arousal) and social traits (perceived trustworthiness, dominance, familiarity, and attractiveness) were collected from all participants while listening brief excerpts (mean audio length of 3\u00a0s) from original call recordings. Critically, we found that social attributions of dominance and attractiveness, arousal and valence ratings, as well as control variables such as voice gender, pitch, harmonic-to-noise ratio (HNR), and COVID-19 related pathologies, were significantly associated with instances where call-takers made wrong decisions by either overestimating or underestimating care priority.",
      "authors": "Bagnis Arianna; Todorov Alexander; Caffo Ernesto; De Palma Alessandra; Franchini Francesco; Melucci Pierfrancesco; Mattarozzi Katia",
      "year": "2025",
      "journal": "Social science & medicine (1982)",
      "doi": "10.1016/j.socscimed.2025.118558",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40944990/",
      "mesh_terms": "Humans; Female; Male; Adult; Cues; Italy; COVID-19; Voice; Emotions; Middle Aged; Decision Making",
      "keywords": "Emergency; First impression; Healthcare; Implicit bias; Voice",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "22268227",
      "title": "Regression calibration when foods (measured with error) are the variables of interest: markedly non-Gaussian data with many zeroes.",
      "abstract": "Regression calibration has been described as a means of correcting effects of measurement error for normally distributed dietary variables. When foods are the items of interest, true distributions of intake are often positively skewed, may contain many zeroes, and are usually not described by well-known statistical distributions. The authors considered the validity of regression calibration assumptions where data are non-Gaussian. Such data (including many zeroes) were simulated, and use of the regression calibration algorithm was evaluated. An example used data from Adventist Health Study 2 (2002-2008). In this special situation, a linear calibration model does (as usual) at least approximately correct the parameter that captures the exposure-disease association in the \"disease\" model. Poor fit in the calibration model does not produce biased calibrated estimates when the \"disease\" model is linear, and it produces little bias in a nonlinear \"disease\" model if the model is approximately linear. Poor fit will adversely affect statistical power, but more complex linear calibration models can help here. The authors conclude that non-Gaussian data with many zeroes do not invalidate regression calibration. Irrespective of fit, linear regression calibration in this situation at least approximately corrects bias. More complex linear calibration equations that improve fit may increase power over that of uncalibrated regressions.",
      "authors": "Fraser Gary E; Stram Daniel O",
      "year": "2012",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwr316",
      "url": "https://pubmed.ncbi.nlm.nih.gov/22268227/",
      "mesh_terms": "Algorithms; Bias; Calibration; Data Interpretation, Statistical; Diet Surveys; Food; Humans; Linear Models; Models, Statistical; Normal Distribution; Regression Analysis; Statistical Distributions",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC3271814"
    },
    {
      "pmid": "39468743",
      "title": "Derivation of outcome-dependent dietary patterns for low-income women obtained from survey data using a supervised weighted overfitted latent class analysis.",
      "abstract": "Poor diet quality is a key modifiable risk factor for hypertension and disproportionately impacts low-income women. Analyzing diet-driven hypertensive outcomes in this demographic is challenging due to the complexity of dietary data and selection bias when the data come from surveys, a main data source for understanding diet-disease relationships in understudied populations. Supervised Bayesian model-based clustering methods summarize dietary data into latent patterns that holistically capture relationships among foods and a known health outcome but do not sufficiently account for complex survey design. This leads to biased estimation and inference and lack of generalizability of the patterns. To address this, we propose a supervised weighted overfitted latent class analysis (SWOLCA) based on a Bayesian pseudo-likelihood approach that integrates sampling weights into an exposure-outcome model for discrete data. Our model adjusts for stratification, clustering, and informative sampling, and handles modifying effects via interaction terms within a Markov chain Monte Carlo Gibbs sampling algorithm. Simulation studies confirm that the SWOLCA model exhibits good performance in terms of bias, precision, and coverage. Using data from the National Health and Nutrition Examination Survey (2015-2018), we demonstrate the utility of our model by characterizing dietary patterns associated with hypertensive outcomes among low-income women in the United States.",
      "authors": "Wu Stephanie M; Williams Matthew R; Savitsky Terrance D; Stephenson Briana J K",
      "year": "2024",
      "journal": "Biometrics",
      "doi": "10.1093/biomtc/ujae122",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39468743/",
      "mesh_terms": "Humans; Female; Poverty; Bayes Theorem; Latent Class Analysis; Diet; Nutrition Surveys; Monte Carlo Method; Hypertension; Markov Chains; Computer Simulation; Algorithms",
      "keywords": "Bayesian clustering; NHANES; dietary pattern analysis; latent class analysis; survey design",
      "pub_types": "Journal Article",
      "pmcid": "PMC11518851"
    },
    {
      "pmid": "33104747",
      "title": "Computer vision supported pedestrian tracking: A demonstration on trail bridges in rural Rwanda.",
      "abstract": "Trail bridges can improve access to critical services such as health care, schools, and markets. In order to evaluate the impact of trail bridges in rural Rwanda, it is helpful to objectively know how and when they are being used. In this study, we deployed motion-activated digital cameras across several trail bridges installed by the non-profit Bridges to Prosperity. We conducted and validated manual counting of bridge use to establish a ground truth. We adapted an open source computer vision algorithm to identify and count bridge use reflected in the digital images. We found a reliable correlation with less than 3% error bias of bridge crossings per hour between manual counting and those sites at which the cameras logged short video clips. We applied this algorithm across 186 total days of observation at four sites in fall 2019, and observed a total of 33,800 daily bridge crossings ranging from about 20 to over 1,100 individual uses per day, with no apparent correlation between daily or total weekly rainfall and bridge use, potentially indicating that transportation behaviors, after a bridge is installed, are no longer impacted by rainfall conditions. Higher bridge use was observed in the late afternoons, on market and church days, and roughly equal use of the bridge crossings in each direction. These trends are consistent with the design-intent of these bridges.",
      "authors": "Thomas Evan; Gerster Sally; Mugabo Lambert; Jean Huguens; Oates Tim",
      "year": "2020",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0241379",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33104747/",
      "mesh_terms": "Algorithms; Costs and Cost Analysis; Humans; Image Processing, Computer-Assisted; Movement; Pedestrians; Rural Population; Rwanda",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7588060"
    },
    {
      "pmid": "35405939",
      "title": "Association between Serum Triglycerides and Prostate Specific Antigen (PSA) among U.S. Males: National Health and Nutrition Examination Survey (NHANES), 2003-2010.",
      "abstract": "(1) Background: Increasing evidence indicates that lipid metabolism may influence the concentration of prostate-specific antigen (PSA). However, the association between triglycerides and PSA remains unclear and complicated. Hence, we evaluated the correlation between triglycerides and PSA based on the U.S. National Health and Nutrition Examination Survey (NHANES) database. (2) Methods: A total of 2910 participants out of 41,156 participants fit into our study after conducting the screening from the 2003 to 2010 NHANES survey. Serum triglycerides were the independent variable of our study, and PSA was the dependent variable; (3) Results: In our study, the average age of chosen participants was 59.7 years (\u00b112.7). After adjusting for covariates, the result indicated that for each additional unit of serum triglyceride (mg/dL), the PSA concentrations were reduced by 0.0043 ng/mL (-0.0082, -0.0005) with a statistical difference. Furthermore, we used machine learning of the XGBoost model to determine the relative importance of selected variables as well as constructed a smooth curve based on the fully adjusted model to investigate the possible linear relationship between the triglyceride and PSA concentrations. (4) Conclusions: The serum triglyceride is independently and negatively correlated with PSA among American males, which may make it hard to detect asymptomatic prostate cancer and diagnose at an advance stage with higher triglycerides due to detection bias.",
      "authors": "Wei Chengcheng; Tian Liang; Jia Bo; Wang Miao; Xiong Ming; Hu Bo; Deng Changqi; Hou Yaxin; Hou Teng; Yang Xiong; Chen Zhaohui",
      "year": "2022",
      "journal": "Nutrients",
      "doi": "10.3390/nu14071325",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35405939/",
      "mesh_terms": "Humans; Male; Mass Screening; Middle Aged; Nutrition Surveys; Prostate-Specific Antigen; Prostatic Neoplasms; Triglycerides; United States",
      "keywords": "National Health and Nutrition Examination Survey (NHANES); machine learning; prostate cancer; prostate-specific antigen; triglycerides",
      "pub_types": "Journal Article",
      "pmcid": "PMC9002993"
    },
    {
      "pmid": "32735229",
      "title": "Derivation of Breathing Metrics From a Photoplethysmogram at Rest: Machine Learning Methodology.",
      "abstract": "BACKGROUND: There has been a recent increased interest in monitoring health using wearable sensor technologies; however, few have focused on breathing. The ability to monitor breathing metrics may have indications both for general health as well as respiratory conditions such as asthma, where long-term monitoring of lung function has shown promising utility. OBJECTIVE: In this paper, we explore a long short-term memory (LSTM) architecture and predict measures of interbreath intervals, respiratory rate, and the inspiration-expiration ratio from a photoplethysmogram signal. This serves as a proof-of-concept study of the applicability of a machine learning architecture to the derivation of respiratory metrics. METHODS: A pulse oximeter was mounted to the left index finger of 9 healthy subjects who breathed at controlled respiratory rates. A respiratory band was used to collect a reference signal as a comparison. RESULTS: Over a 40-second window, the LSTM model predicted a respiratory waveform through which breathing metrics could be derived with a bias value and 95% CI. Metrics included inspiration time (-0.16 seconds, -1.64 to 1.31 seconds), expiration time (0.09 seconds, -1.35 to 1.53 seconds), respiratory rate (0.12 breaths per minute, -2.13 to 2.37 breaths per minute), interbreath intervals (-0.07 seconds, -1.75 to 1.61 seconds), and the inspiration-expiration ratio (0.09, -0.66 to 0.84). CONCLUSIONS: A trained LSTM model shows acceptable accuracy for deriving breathing metrics and could be useful for long-term breathing monitoring in health. Its utility in respiratory disease (eg, asthma) warrants further investigation.",
      "authors": "Prinable Joseph; Jones Peter; Boland David; Thamrin Cindy; McEwan Alistair",
      "year": "2020",
      "journal": "JMIR mHealth and uHealth",
      "doi": "10.2196/13737",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32735229/",
      "mesh_terms": "Humans; Machine Learning; Photoplethysmography; Respiration; Respiratory Rate",
      "keywords": "LSTM; asthma monitoring; photoplethysmogram; respiration",
      "pub_types": "Journal Article",
      "pmcid": "PMC7428909"
    },
    {
      "pmid": "21851978",
      "title": "Diagnostic testing, treatment, cost of care, and survival among registered and non-registered patients with myelodysplastic syndromes.",
      "abstract": "Considering current reliance on cancer registry data, we sought to assess the potential for bias in myelodysplastic syndrome (MDS) registration using SEER-Medicare data 2001-2005. Using a validated claims-based algorithm, we identified and compared registered and non-registered MDS patients, and found that median cumulative survival was 18 and 28 months, 74% and 64% used erythropoiesis-stimulating agents (ESAs), and average 6-month health care cost was $24,249 and $21,750, respectively. While most non-registered MDS patients showed resource utilization and survival characteristics consistent with lower-risk MDS, a subset was registered as acute myeloid leukemia (7.6%) and accounted for early mortality.",
      "authors": "Craig Benjamin M; Rollison Dana E; List Alan F; Cogle Christopher R",
      "year": "2011",
      "journal": "Leukemia research",
      "doi": "10.1016/j.leukres.2011.07.028",
      "url": "https://pubmed.ncbi.nlm.nih.gov/21851978/",
      "mesh_terms": "Aged; Aged, 80 and over; Diagnostic Tests, Routine; Female; Health Care Costs; Hematinics; Humans; Leukemia, Myeloid, Acute; Male; Medicare; Myelodysplastic Syndromes; Retrospective Studies; SEER Program; Survival Rate; United States",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC3191243"
    },
    {
      "pmid": "7734604",
      "title": "When you can't ask their names: linking anonymous respondents with the Hogben number.",
      "abstract": "This article describes a method of linking anonymous subjects with a respondent-generated code using an algorithm based on personal details to produce unique identifiers. It was used to increase confidentiality and statistical power in a year-long work-place health promotion evaluation. Subjects were employees of a large retail chain; 80 per cent were female, and the majority educated to high school level. Of the 385 possible, 81 per cent matched; 67 per cent of the codes were matched on all elements and another 14 per cent were accepted as 'fuzzy' matches. Linking respondents increased the statistical power of the study from an unacceptable 0.4 to an acceptable 0.8. Other research on linking records is briefly discussed, including sample bias and probabilistic matching. This technique is useful when anonymity is likely to raise response rates, but the ideal code could be further sought.",
      "authors": "Honig F",
      "year": "1995",
      "journal": "Australian journal of public health",
      "doi": "10.1111/j.1753-6405.1995.tb00305.x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/7734604/",
      "mesh_terms": "Adult; Bias; Confidentiality; Coronary Disease; Data Collection; Data Interpretation, Statistical; Electronic Data Processing; Female; Fuzzy Logic; Health Promotion; Health Surveys; Humans; Middle Aged; Probability",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36795690",
      "title": "Using a data-driven approach for the development and evaluation of phenotype algorithms for systemic lupus erythematosus.",
      "abstract": "BACKGROUND: Systemic lupus erythematosus (SLE) is a chronic autoimmune disease of unknown origin. The objective of this research was to develop phenotype algorithms for SLE suitable for use in epidemiological studies using empirical evidence from observational databases. METHODS: We used a process for empirically determining and evaluating phenotype algorithms for health conditions to be analyzed in observational research. The process started with a literature search to discover prior algorithms used for SLE. We then used a set of Observational Health Data Sciences and Informatics (OHDSI) open-source tools to refine and validate the algorithms. These included tools to discover codes for SLE that may have been missed in prior studies and to determine possible low specificity and index date misclassification in algorithms for correction. RESULTS: We developed four algorithms using our process: two algorithms for prevalent SLE and two for incident SLE. The algorithms for both incident and prevalent cases are comprised of a more specific version and a more sensitive version. Each of the algorithms corrects for possible index date misclassification. After validation, we found the highest positive predictive value estimate for the prevalent, specific algorithm (89%). The highest sensitivity estimate was found for the sensitive, prevalent algorithm (77%). CONCLUSION: We developed phenotype algorithms for SLE using a data-driven approach. The four final algorithms may be used directly in observational studies. The validation of these algorithms provides researchers an added measure of confidence that the algorithms are selecting subjects correctly and allows for the application of quantitative bias analysis.",
      "authors": "Swerdel Joel N; Ramcharran Darmendra; Hardin Jill",
      "year": "2023",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0281929",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36795690/",
      "mesh_terms": "Humans; Lupus Erythematosus, Systemic; Predictive Value of Tests; Algorithms; Databases, Factual",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9934349"
    },
    {
      "pmid": "40075925",
      "title": "Body Temperature Detection of Group-Housed Pigs Based on the Pairing of Left and Right Ear Roots in Thermal Images.",
      "abstract": "Body temperature is a critical indicator of pig health. This study proposes a non-contact method for detecting body temperature in group-housed pigs by extracting temperature data from thermal images of ear roots. Thermal images in the drinking trough area were captured using a thermal camera, with real-time data transmitted to a monitoring room via optical fibers. The YOLO v11m-OBB model was utilized to detect the ear root areas with oriented bounding boxes, while a novel algorithm, the two-stage left and right ear root pairing algorithm (YOLO TEPA-OBB), paired the ear roots of individual pigs using center distance clustering and angular relationships in a polar coordinate system. The maximum temperature of the ear roots was extracted to represent the body temperature. Experimental results based on 749 ear roots show that the YOLO TEPA-OBB achieves 98.7% precision, 98.4% recall, and 98.7% mean average precision (mAP) in detecting ear roots, with an ear root pairing accuracy of 98.1%. The Pearson correlation coefficient (r) between predicted and reference temperatures is 0.989, with a mean bias of 0.014 \u00b0C and a standard deviation of 0.103 \u00b0C. This research facilitates real-time body temperature monitoring and precise health management for group-housed pigs.",
      "authors": "Xiang Rong; Zhang Yi; Lin Hongjian; Fu Yingchun; Rao Xiuqin; Pan Jinming; Pan Chenghao",
      "year": "2025",
      "journal": "Animals : an open access journal from MDPI",
      "doi": "10.3390/ani15050642",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40075925/",
      "mesh_terms": "",
      "keywords": "YOLO; body temperature; ear root; group-housed pigs; thermal images",
      "pub_types": "Journal Article",
      "pmcid": "PMC11898202"
    },
    {
      "pmid": "39775396",
      "title": "Utilising causal inference methods to estimate effects and strategise interventions in observational health data.",
      "abstract": "Randomised controlled trials (RCTs) are the gold standard for evaluating health interventions but often face ethical and practical challenges. When RCTs are not feasible, large observational data sets emerge as a pivotal resource, though these data sets may be subject to bias and unmeasured confounding. Traditional statistical (or non-causal) learning methods, while useful, face limitations in fully uncovering causal effects, i.e., determining if an intervention truly has a direct impact on the outcome. This gap is bridged by the latest advancements in causal inference methods, building upon machine learning-based approaches to investigate not only population-level effects but also the heterogeneous effects of interventions across population subgroups. We demonstrate a causality approach that utilises causal trees and forests, enhanced by weighting mechanisms to adjust for confounding covariates. This method does more than just predict the overall effect of an intervention on the whole population; it also gives a clear picture of how it works differently in various subgroups. Finally, this method excels in strategising and optimising interventions, by suggesting precise and explainable approaches to targeting the intervention, to maximise overall population health outcomes. These capabilities are crucial for health researchers, offering new insights into existing data and assisting in the decision-making process for future interventions. Using observational data from the 2017-18 Australian National Health Survey, our study demonstrates the power of causal trees in estimating the impact of exercise on BMI levels, understanding how this impact varies across subgroups, and assessing the effectiveness of various intervention targeting strategies for enhanced health benefits.",
      "authors": "Duong Bao; Senadeera Manisha; Nguyen Toan; Nichols Melanie; Backholer Kathryn; Allender Steven; Nguyen Thin",
      "year": "2024",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0314761",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39775396/",
      "mesh_terms": "Humans; Causality; Female; Male; Middle Aged; Machine Learning; Observational Studies as Topic; Adult; Australia; Aged; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11684594"
    },
    {
      "pmid": "28823185",
      "title": "Conducting EQ-5D Valuation Studies in Resource-Constrained Countries: The Potential Use of Shrinkage Estimators to Reduce Sample Size.",
      "abstract": "BACKGROUND: Resource-constrained countries have difficulty conducting large EQ-5D valuation studies, which limits their ability to conduct cost-utility analyses using a value set specific to their own population. When estimates of similar but related parameters are available, shrinkage estimators reduce uncertainty and yield estimators with smaller mean square error (MSE). We hypothesized that health utilities based on shrinkage estimators can reduce MSE and mean absolute error (MAE) when compared to country-specific health utilities. METHODS: We conducted a simulation study (1,000 iterations) based on the observed means and standard deviations (or standard errors) of the EQ-5D-3L valuation studies from 14 counties. In each iteration, the simulated data were fitted with the model based on the country-specific functional form of the scoring algorithm to create country-specific health utilities (\"na\u00efve\" estimators). Shrinkage estimators were calculated based on the empirical Bayes estimation methods. The performance of shrinkage estimators was compared with those of the na\u00efve estimators over a range of different sample sizes based on MSE, MAE, mean bias, standard errors and the width of confidence intervals. RESULTS: The MSE of the shrinkage estimators was smaller than the MSE of the na\u00efve estimators on average, as theoretically predicted. Importantly, the MAE of the shrinkage estimators was also smaller than the MAE of the na\u00efve estimators on average. In addition, the reduction in MSE with the use of shrinkage estimators did not substantially increase bias. The degree of reduction in uncertainty by shrinkage estimators is most apparent in valuation studies with small sample size. CONCLUSION: Health utilities derived from shrinkage estimation allow valuation studies with small sample size to \"borrow strength\" from other valuation studies to reduce uncertainty.",
      "authors": "Chan Kelvin K W; Xie Feng; Willan Andrew R; Pullenayegum Eleanor M",
      "year": "2018",
      "journal": "Medical decision making : an international journal of the Society for Medical Decision Making",
      "doi": "10.1177/0272989X17725748",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28823185/",
      "mesh_terms": "Bayes Theorem; Computer Simulation; Cost-Benefit Analysis; Data Interpretation, Statistical; Humans; Quality of Life; Research Design; Sample Size; Surveys and Questionnaires",
      "keywords": "EQ-5D-3L; health utilities; shrinkage estimation; valuation studies",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "31077817",
      "title": "A cross-lingual approach to automatic ICD-10 coding of death certificates by exploring machine translation.",
      "abstract": "Automatic ICD-10 coding is an unresolved challenge in terms of Machine Learning tasks. Despite hospitals generating an enormous amount of clinical documents, data is considerably sparse, associated with a very skewed and unbalanced code distribution, what entails reduced interoperability. In addition, in some languages the availability of coded documents is very limited. This paper proposes a cross-lingual approach based on Machine Translation methods to code death certificates with ICD-10 using supervised learning. The aim of this approach is to increase the availability of coded documents by combining collections of different languages, which may also contribute to reduce their possible bias in the ICD distribution, i.e. to avoid the promotion of a subset of codes due to service or environmental factors. A significant improvement in system performance is achieved for those labels with few occurrences.",
      "authors": "Almagro Mario; Mart\u00ednez Raquel; Montalvo Soto; Fresno V\u00edctor",
      "year": "2019",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2019.103207",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31077817/",
      "mesh_terms": "Automation; Electronic Health Records; Humans; International Classification of Diseases; Machine Learning; Translating",
      "keywords": "Cross-lingual approach; Electronic health records; ICD-10 coding; Machine translation; Text mining",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "38573370",
      "title": "Algor-ethics: charting the ethical path for AI in critical care.",
      "abstract": "The integration of Clinical Decision Support Systems (CDSS) based on artificial intelligence (AI) in healthcare is groundbreaking evolution with enormous potential, but its development and ethical implementation, presents unique challenges, particularly in critical care, where physicians often deal with life-threating conditions requiring rapid actions and patients unable to participate in the decisional process. Moreover, development of AI-based CDSS is complex and should address different sources of bias, including data acquisition, health disparities, domain shifts during clinical use, and cognitive biases in decision-making. In this scenario algor-ethics is mandatory and emphasizes the integration of 'Human-in-the-Loop' and 'Algorithmic Stewardship' principles, and the benefits of advanced data engineering. The establishment of Clinical AI Departments (CAID) is necessary to lead AI innovation in healthcare, ensuring ethical integrity and human-centered development in this rapidly evolving field.",
      "authors": "Montomoli Jonathan; Bitondo Maria Maddalena; Cascella Marco; Rezoagli Emanuele; Romeo Luca; Bellini Valentina; Semeraro Federico; Gamberini Emiliano; Frontoni Emanuele; Agnoletti Vanni; Altini Mattia; Benanti Paolo; Bignami Elena Giovanna",
      "year": "2024",
      "journal": "Journal of clinical monitoring and computing",
      "doi": "10.1007/s10877-024-01157-y",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38573370/",
      "mesh_terms": "Humans; Artificial Intelligence; Critical Care; Decision Support Systems, Clinical; Algorithms; Clinical Decision-Making",
      "keywords": "Algorethics; Artificial intelligence; Data engineering; Ethics; Machine learning",
      "pub_types": "Letter",
      "pmcid": "PMC11297831"
    },
    {
      "pmid": "31437925",
      "title": "Knowledge Learning Symbiosis for Developing Risk Prediction Models from Regional EHR Repositories.",
      "abstract": "Secondary use of regional EHR data suffers several problems, including data selection bias and limited data size caused by data incompleteness. Here, we propose knowledge learning symbiosis (KLS) as a framework to incorporate domain knowledge to address the problems and make better secondary use of EHR data. Under the framework, we introduce three main categories of methods: knowledge injection to input features, objective functions, and output labels, where knowledge-enhanced neural network (KENN) was first introduced to inject knowledge into objective functions. A case study was conducted to build a cardiovascular disease risk prediction model on the type 2 diabetes patient cohort using regional EHR repositories. By incorporating a well-established knowledge risk model as domain knowledge under our KLS framework, we increased risk prediction performance both on small and biased data, where KENN showed the best performance among all methods.",
      "authors": "Mei Jing; Xia Eryu",
      "year": "2019",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI190223",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31437925/",
      "mesh_terms": "Diabetes Mellitus, Type 2; Electronic Health Records; Humans; Machine Learning; Neural Networks, Computer",
      "keywords": "Electronic Health Records; Machine Learning; Risk Assessment",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36424983",
      "title": "Satellites for long-term monitoring of inland U.S. lakes: The MERIS time series and application for chlorophyll-a.",
      "abstract": "Lakes and other surface fresh waterbodies provide drinking water, recreational and economic opportunities, food, and other critical support for humans, aquatic life, and ecosystem health. Lakes are also productive ecosystems that provide habitats and influence global cycles. Chlorophyll concentration provides a common metric of water quality, and is frequently used as a proxy for lake trophic state. Here, we document the generation and distribution of the complete MEdium Resolution Imaging Spectrometer (MERIS; Appendix A provides a complete list of abbreviations) radiometric time series for over 2300 satellite resolvable inland bodies of water across the contiguous United States (CONUS) and more than 5,000 in Alaska. This contribution greatly increases the ease of use of satellite remote sensing data for inland water quality monitoring, as well as highlights new horizons in inland water remote sensing algorithm development. We evaluate the performance of satellite remote sensing Cyanobacteria Index (CI)-based chlorophyll algorithms, the retrievals for which provide surrogate estimates of phytoplankton concentrations in cyanobacteria dominated lakes. Our analysis quantifies the algorithms' abilities to assess lake trophic state across the CONUS. As a case study, we apply a bootstrapping approach to derive a new CI-to-chlorophyll relationship, ChlBS, which performs relatively well with a multiplicative bias of 1.11 (11%) and mean absolute error of 1.60 (60%). While the primary contribution of this work is the distribution of the MERIS radiometric timeseries, we provide this case study as a roadmap for future stakeholders' algorithm development activities, as well as a tool to assess the strengths and weaknesses of applying a single algorithm across CONUS.",
      "authors": "Seegers Bridget N; Werdell P Jeremy; Vandermeulen Ryan A; Salls Wilson; Stumpf Richard P; Schaeffer Blake A; Owens Tommy J; Bailey Sean W; Scott Joel P; Loftin Keith A",
      "year": "2021",
      "journal": "Remote sensing of environment",
      "doi": "10.1016/j.rse.2021.112685",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36424983/",
      "mesh_terms": "",
      "keywords": "Algorithm validation; Chlorophylla; Inland waters; MERIS timeseries; Remote sensing; Water quality",
      "pub_types": "Journal Article",
      "pmcid": "PMC9680834"
    },
    {
      "pmid": "41066663",
      "title": "Estimating Variance of Log Standardized Incidence Ratios Assessing Health Care Providers' Performance: Comparative Analysis Using Bayesian, Bootstrap, and Delta Method Approaches.",
      "abstract": "BACKGROUND: In health care providers' performance assessment, standardized incidence ratios are essential tools used to assess whether observed event rates deviate from expected values. Accurate estimation of variance in these ratios is crucial as it affects decision-making regarding providers' performance. There is little data on how the choice of these variance estimation methods affects decision-making. OBJECTIVE: In this study, we compared 3 methods (the delta method, bootstrapping method, and Bayesian approach) to estimate the variance of the logarithm of the standardized incidence ratio. METHODS: Using patient-level data from the Australia and New Zealand Dialysis and Transplant Registry for 2012-2023, we used a random effects model to predict treatment at home 1 year after starting treatment. We compared the 3 approaches (with more than 5000 iterations for bootstrapping and Markov chain Monte Carlo sampling) using bias, variance, and mean squared error (MSE) as performance measures. Using the 3 methods, funnel plots were used to compare the hospitals' performance in treating Indigenous and non-Indigenous patients close to home, as a service-level measure of equity. RESULTS: The bias values across all methods were similar, with the Bayesian method narrowly having the lowest bias (0.01922), followed by the delta method (0.01927) and bootstrap method (0.02567). In addition, the Bayesian method exhibited the lowest variance (0.00005), indicating more stable and less dispersed estimates. The delta method had a higher variance (0.00016), while the bootstrap method had the highest variance (0.00027), meaning it introduced more uncertainty. Finally, the Bayesian method had the lowest MSE (0.00042), indicating better overall accuracy, while the bootstrap method had the highest MSE (0.00094), showing it was the least reliable method. CONCLUSIONS: We demonstrated that these methods can be used to measure equity for patient-centered outcomes, both within and between service providers simultaneously. The choice of variance estimation method is critical and heavily affects the interpretation of the performance of health service providers. We favor the Bayesian Markov chain Monte Carlo method as it was found to be a better approach.",
      "authors": "Woldeyohannes Solomon; Jones Yomei; Lawton Paul",
      "year": "2025",
      "journal": "JMIRx med",
      "doi": "10.2196/77415",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41066663/",
      "mesh_terms": "",
      "keywords": "SIR; equity; health care provider; machine learning; performance; standardized incidence ratio",
      "pub_types": "Journal Article",
      "pmcid": "PMC12605305"
    },
    {
      "pmid": "39839956",
      "title": "Enhance health evidence quality in classification tasks: A triangulation approach utilizing case-based reasoning and process features.",
      "abstract": "OBJECTIVE: Machine learning (ML) has enabled healthcare discoveries by facilitating efficient modeling, such as for cancer screening. Unlike clinical trials, real-world data used in ML are often gathered for multiple purposes, leading to bias and missing information for a specific classification task. This challenge is especially pronounced in healthcare because of stringent ethical considerations and resource constraints.This study proposed an integrated approach to enhance the quality of health evidence from a classification task for predicting Medicare's Diagnosis-Related Groups of ischemic heart disease (IHD) patients. METHODS: Eligible participants were identified from the Medical Information Mart for Intensive Care IV (MIMIC IV), a publicly available hospital database. Six ML models were selected for model triangulation. Sequential triangulation was employed via Local Process Mining (LPM) and Qualitative Comparative Analysis (QCA). RESULTS: A total of 1545 IHD hospitalizations from 916 patients were identified from the MIMIC IV. Eight health process features were identified through LPM aligned with clinical knowledge. The correlation coefficients for process features, ranging from 0.24 to 0.42, are higher than those for non-process features ranged from 0.02 to 0.36. A total of 56 unique combinations were identified from the QCA, with 28 configurations having raw coverage lower than 1.0%. The overall model performance (i.e. weighted F1 and area under the curve scores) increased after adopting this integrated approach. The proportion of cases misclassified by any of the six models decreased by 47% after incorporating process features (from 5.29% to 2.91%) and further decreased to 0.0% after applying the QCA solutions. CONCLUSION: The integrated approach demonstrates its ability to enhance quality of a classification task through its clinical relevance, improved model performance, and reduced case-level error rates. However, more scalable QCA methods are needed for larger datasets. Developing health process feature engineering for broader applications can be a future direction.",
      "authors": "Guo Ruihua; Smith Ross; Chen Qifan; Ritchie Angus; Poon Simon",
      "year": "2025",
      "journal": "Digital health",
      "doi": "10.1177/20552076251314097",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39839956/",
      "mesh_terms": "",
      "keywords": "Process mining; classification; electronic health records; evidence-based assessment; machine learning; triangulation",
      "pub_types": "Journal Article",
      "pmcid": "PMC11748077"
    },
    {
      "pmid": "39455462",
      "title": "Analyzing and forecasting air pollution concentration in the capital and Southern Thailand using a lag-dependent Gaussian process model.",
      "abstract": "The air pollution problem has now amassed worldwide attention due to its multifaceted harm to human health. Exploring the concentration of air pollution and improving forecast have important consideration worldwide. In this research, we analyze the air pollution concentration of Southern Thailand and compare it with the central region. Also, we proposed a methodology based on the lag-dependent Gaussian process (LDGP), a Bayesian non-parametric machine learning model, with a stable optimization approach, which is a cluster-based multi-starter technique based on the Nelder-Mead optimizer. This model also provides the confidence band for forecasted values. We also used autoregressive deep neural network (AR-DNN), autoregressive random forest (AR-RF), gradient boosting (GB), and K-nearest neighbors (KNN) models. A comparison of the proposed methodology was performed on the daily air pollution data collected from the southern provinces and also from the capital of Thailand from 1 January 2018 to 31 December 2022. We used well-established performance evaluation measures to compare the performance of the models. To evaluate the bias due to overfit, we performed a tenfold cross-validation for all the pollutants in each region and compared the models to choose the best one. Moreover, we explored the concentration of air pollution in these regions. Results of descriptive analysis revealed that Bangkok had a much higher concentration of air pollution as compared to the southern region. However, the southern region had higher exposure to PM air pollutants as per WHO recommendations and also had higher exposure to O3 and CO levels. The proposed LDGP model outperformed the other machine learning models for forecasting all air pollutants. Hence, it is recommended to be used by experts for further research and studies with different kernel functions. This research is also expected to contribute to local government planning and prevention and worldwide use of the same methodology for the sustainability of public health.",
      "authors": "Khurram Haris; Lim Apiradee",
      "year": "2024",
      "journal": "Environmental monitoring and assessment",
      "doi": "10.1007/s10661-024-13275-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39455462/",
      "mesh_terms": "Thailand; Air Pollution; Environmental Monitoring; Air Pollutants; Forecasting; Normal Distribution; Bayes Theorem; Particulate Matter",
      "keywords": "Air pollution; Forecast; Gaussian process; Machine learning; Particulate matter",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37854935",
      "title": "Optimizing Dynamic Antibiotic Treatment Strategies against Invasive Methicillin-Resistant Staphylococcus Aureus Infections using Causal Survival Forests and G-Formula on Statewide Electronic Health Record Data.",
      "abstract": "Developing models for individualized, time-varying treatment optimization from observational data with large variable spaces, e.g., electronic health records (EHR), is problematic because of inherent, complex bias that can change over time. Traditional methods such as the g-formula are robust, but must identify critical subsets of variables due to combinatorial issues. Machine learning approaches such as causal survival forests have fewer constraints and can provide fine-tuned, individualized counterfactual predictions. In this study, we aimed to optimize time-varying antibiotic treatment -identifying treatment heterogeneity and conditional treatment effects- against invasive methicillin-resistant Staphylococcus Aureus (MRSA) infections, using statewide EHR data collected in Florida, USA. While many previous studies focused on measuring the effects of the first empiric treatment (i.e., usually vancomycin), our study focuses on dynamic sequential treatment changes, comparing possible vancomycin switches with other antibiotics at clinically relevant time points, e.g., after obtaining a bacterial culture and susceptibility testing. Our study population included adult individuals admitted to the hospital with invasive MRSA. We collected demographic, clinical, medication, and laboratory information from the EHR for these patients. Then, we followed three sequential antibiotic choices (i.e., their empiric treatment, subsequent directed treatment, and final sustaining treatment), evaluating 30-day mortality as the outcome. We applied both causal survival forests and g-formula using different clinical intervention policies. We found that switching from vancomycin to another antibiotic improved survival probability, yet there was a benefit from initiating vancomycin compared to not using it at any time point. These findings show consistency with the empiric choice of vancomycin before confirmation of MRSA and shed light on how to manage switches on course. In conclusion, this application of causal machine learning on EHR demonstrates utility in modeling dynamic, heterogeneous treatment effects that cannot be evaluated precisely using randomized clinical trials.",
      "authors": "Jun Inyoung; Cohen Scott A; Ser Sarah E; Marini Simone; Lucero Robert J; Bian Jiang; Prosperi Mattia",
      "year": "2023",
      "journal": "Proceedings of machine learning research",
      "doi": "10.1038/s41586-022-05583-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37854935/",
      "mesh_terms": "",
      "keywords": "Antibiotic Resistance; Causal Machine Learning; Causal Survival Forest; Dynamic Treatment Optimization; G-Formula; Individualized Treatment Effect",
      "pub_types": "Journal Article",
      "pmcid": "PMC10584043"
    },
    {
      "pmid": "33408882",
      "title": "A Satellite-Based Spatio-Temporal Machine Learning Model to Reconstruct Daily PM2.5 Concentrations across Great Britain.",
      "abstract": "Epidemiological studies on the health effects of air pollution usually rely on measurements from fixed ground monitors, which provide limited spatio-temporal coverage. Data from satellites, reanalysis, and chemical transport models offer additional information used to reconstruct pollution concentrations at high spatio-temporal resolutions. This study aims to develop a multi-stage satellite-based machine learning model to estimate daily fine particulate matter (PM2.5) levels across Great Britain between 2008-2018. This high-resolution model consists of random forest (RF) algorithms applied in four stages. Stage-1 augments monitor-PM2.5 series using co-located PM10 measures. Stage-2 imputes missing satellite aerosol optical depth observations using atmospheric reanalysis models. Stage-3 integrates the output from previous stages with spatial and spatio-temporal variables to build a prediction model for PM2.5. Stage-4 applies Stage-3 models to estimate daily PM2.5 concentrations over a 1 km grid. The RF architecture performed well in all stages, with results from Stage-3 showing an average cross-validated R2 of 0.767 and minimal bias. The model performed better over the temporal scale when compared to the spatial component, but both presented good accuracy with an R2 of 0.795 and 0.658, respectively. These findings indicate that direct satellite observations must be integrated with other satellite-based products and geospatial variables to derive reliable estimates of air pollution exposure. The high spatio-temporal resolution and the relatively high precision allow these estimates (approximately 950 million points) to be used in epidemiological analyses to assess health risks associated with both short- and long-term exposure to PM2.5.",
      "authors": "Schneider Rochelle; Vicedo-Cabrera Ana M; Sera Francesco; Masselot Pierre; Stafoggia Massimo; de Hoogh Kees; Kloog Itai; Reis Stefan; Vieno Massimo; Gasparrini Antonio",
      "year": "2020",
      "journal": "Remote sensing",
      "doi": "10.3390/rs12223803",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33408882/",
      "mesh_terms": "",
      "keywords": "aerosol optical depth; fine particulate matter; machine learning; random forest; reanalysis; satellite",
      "pub_types": "Journal Article",
      "pmcid": "PMC7116547"
    },
    {
      "pmid": "35230273",
      "title": "Development and Structure of an Accurate Machine Learning Algorithm to Predict Inpatient Mortality and Hospice Outcomes in the Coronavirus Disease 2019 Era.",
      "abstract": "BACKGROUND: The coronavirus disease 2019 (COVID-19) pandemic has challenged the accuracy and racial biases present in traditional mortality scores. An accurate prognostic model that can be applied to hospitalized patients irrespective of race or COVID-19 status may benefit patient care. RESEARCH DESIGN: This cohort study utilized historical and ongoing electronic health record features to develop and validate a deep-learning model applied on the second day of admission predicting a composite outcome of in-hospital mortality, discharge to hospice, or death within 30 days of admission. Model features included patient demographics, diagnoses, procedures, inpatient medications, laboratory values, vital signs, and substance use history. Conventional performance metrics were assessed, and subgroup analysis was performed based on race, COVID-19 status, and intensive care unit admission. SUBJECTS: A total of 35,521 patients hospitalized between April 2020 and October 2020 at a single health care system including a tertiary academic referral center and 9 community hospitals. RESULTS: Of 35,521 patients, including 9831 non-White patients and 2020 COVID-19 patients, 2838 (8.0%) met the composite outcome. Patients who experienced the composite outcome were older (73 vs. 61\u2009y old) with similar sex and race distributions between groups. The model achieved an area under the receiver operating characteristic curve of 0.89 (95% confidence interval: 0.88, 0.91) and an average positive predictive value of 0.46 (0.40, 0.52). Model performance did not differ significantly in White (0.89) and non-White (0.90) subgroups or when grouping by COVID-19 status and intensive care unit admission. CONCLUSION: A deep-learning model using large-volume, structured electronic health record data can effectively predict short-term mortality or hospice outcomes on the second day of admission in the general inpatient population without significant racial bias.",
      "authors": "Chi Stephen; Guo Aixia; Heard Kevin; Kim Seunghwan; Foraker Randi; White Patrick; Moore Nathan",
      "year": "2022",
      "journal": "Medical care",
      "doi": "10.1097/MLR.0000000000001699",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35230273/",
      "mesh_terms": "Algorithms; COVID-19; Cohort Studies; Hospices; Hospitalization; Humans; Inpatients; Machine Learning; Retrospective Studies; SARS-CoV-2",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8989608"
    },
    {
      "pmid": "37034681",
      "title": "Validation of an open-source smartphone step counting algorithm in clinical and non-clinical settings.",
      "abstract": "BACKGROUND: Step counts are increasingly used in public health and clinical research to assess wellbeing, lifestyle, and health status. However, estimating step counts using commercial activity trackers has several limitations, including a lack of reproducibility, generalizability, and scalability. Smartphones are a potentially promising alternative, but their step-counting algorithms require robust validation that accounts for temporal sensor body location, individual gait characteristics, and heterogeneous health states. OBJECTIVE: Our goal was to evaluate an open-source step-counting method for smartphones under various measurement conditions against step counts estimated from data collected simultaneously from different body locations (\"internal\" validation), manually ascertained ground truth (\"manual\" validation), and step counts from a commercial activity tracker (Fitbit Charge 2) in patients with advanced cancer (\"wearable\" validation). METHODS: We used eight independent datasets collected in controlled, semi-controlled, and free-living environments with different devices (primarily Android smartphones and wearable accelerometers) carried at typical body locations. Five datasets (N=103) were used for internal validation, two datasets (N=107) for manual validation, and one dataset (N=45) used for wearable validation. In each scenario, step counts were estimated using a previously published step-counting method for smartphones that uses raw sub-second level accelerometer data. We calculated mean bias and limits of agreement (LoA) between step count estimates and validation criteria using Bland-Altman analysis. RESULTS: In the internal validation datasets, participants performed 751.7\u00b1581.2 (mean\u00b1SD) steps, and the mean bias was -7.2 steps (LoA -47.6, 33.3) or -0.5%. In the manual validation datasets, the ground truth step count was 367.4\u00b1359.4 steps while the mean bias was -0.4 steps (LoA -75.2, 74.3) or 0.1 %. In the wearable validation dataset, Fitbit devices indicated mean step counts of 1931.2\u00b12338.4, while the calculated bias was equal to -67.1 steps (LoA -603.8, 469.7) or a difference of 0.3 %. CONCLUSIONS: This study demonstrates that our open-source step counting method for smartphone data provides reliable step counts across sensor locations, measurement scenarios, and populations, including healthy adults and patients with cancer.",
      "authors": "Straczkiewicz Marcin; Keating Nancy L; Thompson Embree; Matulonis Ursula A; Campos Susana M; Wright Alexi A; Onnela Jukka-Pekka",
      "year": "2023",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2023.03.28.23287844",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37034681/",
      "mesh_terms": "",
      "keywords": "accelerometer; cancer; open-source; smartphone; step count; validation; wearable",
      "pub_types": "Preprint; Journal Article",
      "pmcid": "PMC10081434"
    },
    {
      "pmid": "35854872",
      "title": "The effect of oxygen and carbon dioxide cross-sensitivity sensor error in the Eco Medics Exhalyzer D device on measures of conductive and acinar airway function.",
      "abstract": "INTRODUCTION: The multiple breath nitrogen washout (MBNW) test provides important clinical information in obstructive airways diseases. Recently, a significant cross-sensitivity error in the O2 and CO2 sensors of a widely used commercial MBNW device (Exhalyzer D, Eco Medics AG, Duernten, Switzerland) was detected, which leads to overestimation of N2 concentrations. Significant errors in functional residual capacity (FRC) and lung clearance index (LCI) have been reported in infants and children. This study investigated the impact in adults, and on additional important indices reflecting conductive (S cond) and acinar (S acin) ventilation heterogeneity, in health and disease. METHODS: Existing MBNW measurements of 27 healthy volunteers, 20 participants with asthma and 16 smokers were reanalysed using SPIROWARE V 3.3.1, which incorporates an error correction algorithm. Uncorrected and corrected indices were compared using paired t-tests and Bland-Altman plots. RESULTS: Correction of the sensor error significantly lowered FRC (mean difference 9%) and LCI (8-10%) across all three groups. S cond was higher following correction (11%, 14% and 36% in health, asthma and smokers, respectively) with significant proportional bias. S acin was significantly lower following correction in the asthma and smoker groups, but the effect was small (2-5%) and with no proportional bias. DISCUSSION: The O2 and CO2 cross-sensitivity sensor error significantly overestimated FRC and LCI in adults, consistent with data in infants and children. There was a high degree of underestimation of S cond but minimal impact on S acin. The presence of significant proportional bias indicates that previous studies will require reanalysis to confirm previous findings and to allow comparability with future studies.",
      "authors": "Bozier Jack; Jeagal Edward; Robinson Paul D; Prisk G Kim; Chapman David G; King Gregory G; Thamrin Cindy; Rutting Sandra",
      "year": "2022",
      "journal": "ERJ open research",
      "doi": "10.1183/23120541.00614-2021",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35854872/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9289373"
    },
    {
      "pmid": "30613799",
      "title": "Point-of-contact interactive record linkage (PIRL) between demographic surveillance and health facility data in rural Tanzania.",
      "abstract": "INTRODUCTION: Health and demographic surveillance systems (HDSS) have been an invaluable resource for monitoring the health status of populations, but often contain self-reported health service utilisation, which are subject to reporting bias. OBJECTIVE: To implement point-of-contact interactive record linkage (PIRL) between demographic and health facility systems data, characterise attributes associated with (un)successful record linkage, and compare findings with a fully automated retrospective linkage approach. METHODS: Individuals visiting the Kisesa Health Centre were matched to their HDSS records during a short up-take interview in the waiting area of the health facility. The search algorithm was used to rank potential matches, from which the true match(es) were selected after consultation with the patient. Multivariable logistic regression models were used to identify characteristics associated with being matched to an HDSS record. Records matched based on respondent's clarifications were subsequently used as the gold-standard to evaluate fully automated retrospective record linkage by calculating sensitivity and positive predictive value (PPV). RESULTS: Among 2,624 individuals who reportedly lived in the HDSS coverage area, we matched 2,206 (84.1%) to their HDSS records. Characteristics associated with a higher odds of being matched were increased age (OR 1.07, 95% CI 1.02, 1.12; per 5-year increment), a later consent into the study (OR 2.07, 95% CI 1.37, 3.12; in the most recent six-month period), and fieldworker level of experience. The main drivers of the linkage algorithm were name, sex, year of birth, village, sub-village, and household member name. At the lowest match score threshold, automated retrospective linkage would have only correctly identified and linked 55% (1440/2612) of the records with a PPV of 55% (1440/2612). CONCLUSION: Where resources are available, PIRL is a viable approach to link HDSS and other administrative data sources that outperforms purely retrospective approaches.",
      "authors": "Rentsch Christopher T; Reniers Georges; Kabudula Chodziwadziwa; Machemba Richard; Mtenga Baltazar; Harron Katie; Mee Paul; Michael Denna; Natalis Redempta; Urassa Mark; Todd Jim; Zaba Basia",
      "year": "2017",
      "journal": "International journal of population data science",
      "doi": "10.23889/ijpds.v2i1.408",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30613799/",
      "mesh_terms": "",
      "keywords": "data linkage; health and demographic surveillance systems; health facility; point-of-contact interactive record linkage; sub-Saharan Africa",
      "pub_types": "Journal Article",
      "pmcid": "PMC6314455"
    },
    {
      "pmid": "32782916",
      "title": "Pneumonia Hospitalization Coding Changes Associated With Transition From the 9th to 10th Revision of International Classification of Diseases.",
      "abstract": "OBJECTIVES: To evaluate the impact of International Classification of Disease, 10th revision, Clinical Modification (ICD-10-CM) implementation on pneumonia hospitalizations rates, which had declined following pneumococcal conjugate vaccine introduction for infants in 2000. METHODS: We randomly selected records from a single hospital 1 year before (n = 500) and after (n = 500) October 2015 implementation of ICD-10-CM coding. We used a validated ICD-9-CM algorithm and translation of that algorithm to ICD-10-CM to identify pneumonia hospitalizations pre- and post-implementation, respectively. We recoded ICD-10-CM records to ICD-9-CM and vice versa. We calculated sensitivity and positive predictive value (PPV) of the ICD-10-CM algorithm using ICD-9-CM coding as the reference. We used sensitivity and PPV values to calculate an adjustment factor to apply to ICD-10 era rates to enable comparison with ICD-9-CM rates. We reviewed primary diagnoses of charts not meeting the pneumonia definition when recoded. RESULTS: Sensitivity and PPV of the ICD-10-CM algorithm were 94% and 92%, respectively, for young children and 74% and 79% for older adults. The estimated adjustment factor for ICD-10-CM period rates was -2.09% (95% credible region [CR], -7.71% to +3.0%) for children and +6.76% (95% CR, -3.06% to +16.7%) for older adults. We identified a change in coding adult charts that met the ICD-9-CM pneumonia definition that led to recoding in ICD-10-CM as chronic obstructive pulmonary disease (COPD) exacerbation. CONCLUSIONS: The ICD-10-CM algorithm derived from a validated ICD-9-CM algorithm should not introduce substantial bias for evaluating pneumonia trends in children. However, changes in coding of pneumonia associated with COPD in adults warrant further study.",
      "authors": "Smithee Ryan B; Markus Tiffanie M; Soda Elizabeth; Grijalva Carlos G; Xing Wei; Shang Nong; Griffin Marie R; Lessa Fernanda C",
      "year": "2020",
      "journal": "Health services research and managerial epidemiology",
      "doi": "10.1177/2333392820939801",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32782916/",
      "mesh_terms": "",
      "keywords": "ICD-10-CM transition; algorithms; pneumonia hospitalizations; public health; trends",
      "pub_types": "Journal Article",
      "pmcid": "PMC7383658"
    },
    {
      "pmid": "40622759",
      "title": "Scalable Precision Psychiatry With an Objective Measure of Psychological Stress: Prospective Real-World Study.",
      "abstract": "BACKGROUND: Before meaningful progress toward precision psychiatry is possible, objective (unbiased) assessment of patient mental well-being must be validated and adopted broadly. OBJECTIVE: This study aims to compare the fidelity of a precision psychiatry therapy recommendation algorithm when trained with an objective quantification of psychological stress versus subjective ecological momentary assessments (EMAs) of stress and mood. METHODS: From 2786 unique individuals engaging between March 2015 and December 2022 in English language psychotherapy sessions and providing pre- and postsession self-report and facial biometric data via a mobile health platform (Mobio Interactive Pte Ltd, Singapore), analysis was conducted on 67 \"super users\" that completed a minimum of 28 sessions with all pre- and postsession measures. The platform used has previously demonstrated reduced psychiatric symptom severity and improved overall mental well-being. Psychotherapy recordings (\"sessions\") within the platform, available asynchronously and on demand, span mindfulness, meditation, cognitive behavioral therapy, client-centered therapy, music therapy, and self-hypnosis. The platform also has the unusual ability to rapidly assess mental well-being without bias via an easy-to-use objective measure of psychological stress derived from artificial intelligence-based analysis of facial biomarkers (objective stress level [OSL]). In tandem with the objective measure, EMAs obtain self-reported values of stress (SRS) and mood (SRM). \u2206OSL, \u2206SRS, and \u2206SRM (with delta referring to the presession subtracted from the postsession measurement) were used to independently train a therapy recommendation algorithm designed to predict what future sessions would prove most efficacious for each individual. Algorithm predictions were compared against the efficacy of the individual's self-selected sessions. RESULTS: The objective measure of psychological stress provided a differentiated delta for the measurement of therapeutic efficacy compared to the 2 EMA deltas, as shown by clear divergence in \u2206OSL vs \u2206SRS or \u2206SRM (r<0.03), while the EMA deltas showed significant convergence (r=0.53, P<.01). The recommendation algorithm selected increasingly efficacious therapy sessions as a function of training data when trained with either \u2206OSL (F1,16=5.37, P=.03) or \u2206SRM data (F1,16=3.69, P<.05). However, the sequential improvement in prediction efficacy only surpassed the efficacy of self-selected therapy when the algorithm was trained using objective data (P<.01). Training the algorithm with EMA data showed potential trends that did not reach significance (\u2206SRS: P=.09; \u2206SRM: P=.12). As a final insight, self-selected therapy sessions were overrepresented among the algorithmically recommended sessions, an effect most pronounced when the algorithm was trained with \u2206OSL data (F1,14=30.94, P<.001). CONCLUSIONS: These prospective data demonstrate that a rapid, scalable, and objective measure of psychological stress, in combination with a robust recommendation algorithm, can autonomously identify clinically meaningful therapy for individuals. More broadly, this work illustrates the potential for objective data on mental well-being to improve precision psychiatry and the capacity for mental health care professionals to match global demand. TRIAL REGISTRATION: ClinicalTrials.gov NCT06265909; https://clinicaltrials.gov/ct2/show/NCT06265909.",
      "authors": "Wang Helena; Farb Norman; Saab Bechara",
      "year": "2025",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/56086",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40622759/",
      "mesh_terms": "Adult; Female; Humans; Male; Middle Aged; Algorithms; Artificial Intelligence; Ecological Momentary Assessment; Precision Medicine; Prospective Studies; Psychiatry; Psychotherapy; Stress, Psychological",
      "keywords": "data-driven; digital biomarkers; digital therapeutics; ecological momentary assessment; fidelity; forms; mental health; mental healthcare; mental well-being; mood; patient data; personalization; precision psychiatry; psychiatry; psychological stress; psychotherapy; real world; recommendations; recommender system; self-report; sessions; therapy; therapy algorithm; users",
      "pub_types": "Journal Article; Observational Study",
      "pmcid": "PMC12280831"
    },
    {
      "pmid": "34560604",
      "title": "A standardized analytics pipeline for reliable and rapid development and validation of prediction models using observational health data.",
      "abstract": "BACKGROUND AND OBJECTIVE: As a response to the ongoing COVID-19 pandemic, several prediction models in the existing literature were rapidly developed, with the aim of providing evidence-based guidance. However, none of these COVID-19 prediction models have been found to be reliable. Models are commonly assessed to have a risk of bias, often due to insufficient reporting, use of non-representative data, and lack of large-scale external validation. In this paper, we present the Observational Health Data Sciences and Informatics (OHDSI) analytics pipeline for patient-level prediction modeling as a standardized approach for rapid yet reliable development and validation of prediction models. We demonstrate how our analytics pipeline and open-source software tools can be used to answer important prediction questions while limiting potential causes of bias (e.g., by validating phenotypes, specifying the target population, performing large-scale external validation, and publicly providing all analytical source code). METHODS: We show step-by-step how to implement the analytics pipeline for the question: 'In patients hospitalized with COVID-19, what is the risk of death 0 to 30 days after hospitalization?'. We develop models using six different machine learning methods in a USA claims database containing over 20,000 COVID-19 hospitalizations and externally validate the models using data containing over 45,000 COVID-19 hospitalizations from South Korea, Spain, and the USA. RESULTS: Our open-source software tools enabled us to efficiently go end-to-end from problem design to reliable Model Development and evaluation. When predicting death in patients hospitalized with COVID-19, AdaBoost, random forest, gradient boosting machine, and decision tree yielded similar or lower internal and external validation discrimination performance compared to L1-regularized logistic regression, whereas the MLP neural network consistently resulted in lower discrimination. L1-regularized logistic regression models were well calibrated. CONCLUSION: Our results show that following the OHDSI analytics pipeline for patient-level prediction modelling can enable the rapid development towards reliable prediction models. The OHDSI software tools and pipeline are open source and available to researchers from all around the world.",
      "authors": "Khalid Sara; Yang Cynthia; Blacketer Clair; Duarte-Salles Talita; Fern\u00e1ndez-Bertol\u00edn Sergio; Kim Chungsoo; Park Rae Woong; Park Jimyung; Schuemie Martijn J; Sena Anthony G; Suchard Marc A; You Seng Chan; Rijnbeek Peter R; Reps Jenna M",
      "year": "2021",
      "journal": "Computer methods and programs in biomedicine",
      "doi": "10.1016/j.cmpb.2021.106394",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34560604/",
      "mesh_terms": "COVID-19; Humans; Logistic Models; Machine Learning; Pandemics; SARS-CoV-2",
      "keywords": "COVID-19; Data harmonization; Data quality control; Distributed data network; Machine learning; Risk prediction",
      "pub_types": "Journal Article",
      "pmcid": "PMC8420135"
    },
    {
      "pmid": "19716846",
      "title": "Estimating the prevalence of clinical manganism using a cascaded screening process in a South African manganese smelter.",
      "abstract": "OBJECTIVES: A diagnostic algorithm for clinical manganism was developed to screen all employees at a South African manganese smelter. METHODS: The study design was for all 754 smelter employees in 2006/7 to be screened by an occupational health nurse using nine questions and nine brief neurological examination procedures. More than one symptom, any neurological sign, or blood manganese exceeding 40 microg/l triggered referral for neurological examination by an Occupational Medical Practioner (OMP). Abnormal findings by the OMP triggered referral to a movement disorders specialist neurologist and to a neuropsychologist. Features of parkinsonism and a clinical picture consistent with the scientific literature were used to diagnose manganism. RESULTS: Total manganese dust was mostly within (<5 mg/m(3)) or near (<9 mg/m(3)) the South African Occupational Exposure Limit, with one outlier near 20 mg/m(3). Occupational Health Service problems and uncertainty about the nature of manganism before the full diagnostic algorithm was developed, resulted in 10 referrals who were certified as manganism cases by the state compensation authorities. They were only assessed in the early stages of this screening programme, and never examined by the above specialists. Of 744 employees screened with the full diagnostic algorithm, the nurse referred 152 (20.3%) and the OMP 27 (3.5%) of all those screened respectively. No definite manganism cases were diagnosed, while one (0.13%) employee was found to have possible manganism and another had an indeterminate neurological diagnosis. A sensitivity analysis assuming that all 10 compensated cases were either normal, or alternatively had definite manganism, yielded a prevalence range for definite manganism from 0% to 1.3%. CONCLUSION: Acknowledging possible downward bias when excluding the 10 employees who did not receive the full workup, the true prevalence of definite manganism was likely to be either zero or close to zero.",
      "authors": "Myers J E; Fine J; Ormond-Brown D; Fry J; Thomson A; Thompson M L",
      "year": "2009",
      "journal": "Neurotoxicology",
      "doi": "10.1016/j.neuro.2009.08.004",
      "url": "https://pubmed.ncbi.nlm.nih.gov/19716846/",
      "mesh_terms": "Algorithms; Cross-Sectional Studies; Environmental Monitoring; Epidemiological Monitoring; Humans; Manganese Poisoning; Neurologic Examination; Neuropsychological Tests; Occupational Exposure; Prevalence; Risk Assessment; South Africa; Surveys and Questionnaires",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41463017",
      "title": "Machine Learning-Enabled Medical Devices Authorized by the US Food and Drug Administration in 2024: Regulatory Characteristics, Predicate Lineage, and Transparency Reporting.",
      "abstract": "Background: The US Food and Drug Administration (FDA) authorized over 690 machine learning (ML)-enabled medical devices between 1995 and 2023. In 2024, new guidance enabled the inclusion of Predetermined Change Control Plans (PCCPs), raising expectations for transparency, equity, and safety under the Good Machine Learning Practice (GMLP) framework. Objective: The objective was to assess regulatory pathways, predicate lineage, demographic transparency, performance reporting, and PCCP uptake among ML-enabled devices approved by the FDA in 2024. Methods: We conducted a cross-sectional analysis of all FDA-authorized ML-enabled devices in 2024. Data extracted from FDA summaries included regulatory pathway, predicate genealogy, performance metrics, demographic disclosures, PCCPs, and cybersecurity statements. Descriptive and nonparametric statistics were used. Results: The FDA authorized 168 ML-enabled Class II devices in 2024. Most (94.6%) were cleared via 510(k); 5.4% were cleared via De Novo. Radiology dominated (74.4%), followed by cardiovascular (6.5%) and neurology (6.0%). Non-US sponsors accounted for 57.7% of clearances. Among 159 510(k) devices, 97.5% cited an identifiable predicate; the median predicate age was 2.2 years (IQR 1.2-4.1), and 64.5% ML-enabled. Predicate reuse remained uncommon (9.9%). Median review time was 162 days (151 days for 510(k) vs. 372 days De Novo; p < 0.001). A total of 49 devices (29.2%) reported both sensitivity and specificity; 15.5% provided demographic data. PCCPs appeared in 16.7% of summaries, and cybersecurity considerations appeared in 54.2%. Conclusions: While 2024 marked a record year for ML-enabled device approvals and internationalization, uptake of PCCPs and transparent performance and demographic reporting remained limited. Policy efforts to standardize disclosures and strengthen post market oversight are critical for realizing the promises of GMLP.",
      "authors": "Almarie Bassel; Gonzalez-Gonzalez Luis Fernando; Dos Santos Barbosa Lucas Ant\u00f4nio; Lutz Amelie; Grosse Ulrich; Fregni Felipe",
      "year": "2025",
      "journal": "Biomedicines",
      "doi": "10.3390/biomedicines13123005",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41463017/",
      "mesh_terms": "",
      "keywords": "FDA 510(k); algorithmic bias; artificial intelligence; demographic representation; health equity; machine learning; medical device regulation; predetermined change control plans; regulatory transparency",
      "pub_types": "Journal Article",
      "pmcid": "PMC12730494"
    },
    {
      "pmid": "41248391",
      "title": "Predicting disease progression in people living with HIV using machine learning and a nomogram: a 10-year cohort study based in Xinjiang, China.",
      "abstract": "OBJECTIVES: Current prediction models for disease progression to AIDS in people living with HIV primarily rely on traditional statistical methods. This study aimed to develop and compare four machine learning models and to create a clinically applicable nomogram for identifying risk factors associated with AIDS progression. DESIGN: A retrospective cohort study conducted from January 2013 to December 2022. SETTING: Yining City, Xinjiang, China. PARTICIPANTS: Newly diagnosed HIV-infected patients (aged 18-60 years) who received antiretroviral therapy and had not progressed to AIDS at baseline. PRIMARY OUTCOME MEASURES: Progression from HIV infection to AIDS, as defined by the Chinese Center for Disease Control and Prevention criteria. RESULTS: Among the 2305 patients included, 652 progressed to AIDS. The cohort was predominantly male, with a mean baseline CD4 cell count of 384 cells/\u03bcL. Four machine learning models-Support Vector Machine, Random Forest, Logistic Regression and Extreme Gradient Boosting (XGBoost)-were developed. The XGBoost model demonstrated the best predictive performance (area under the curve, AUC: 0.877). Univariate and multivariate analyses identified WHO clinical stages, CD4 cell count, HIV transmission route, platelet count and haemoglobin level as significant predictors. The developed nomogram achieved an AUC of 0.840. Its calibration curve, after bias correction, showed good agreement with the ideal curve, and decision curve analysis indicated potential clinical utility. CONCLUSIONS: In this cohort, the XGBoost model showed superior performance for predicting AIDS progression. The proposed nomogram may serve as a practical tool to facilitate rapid risk assessment in similar clinical settings. These findings suggest that enhanced monitoring and regular follow-up might be beneficial for patients with low CD4 counts for timely intervention and to improve outcomes.",
      "authors": "Mao Qianru; He Qian; Ni Yongkang; Ni Zhen; Zeng Changyu; Wang Jiliang; He Xiaoyan; Feng Xinhuan; Ni Mingjian",
      "year": "2025",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2025-105026",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41248391/",
      "mesh_terms": "Humans; Male; Disease Progression; Nomograms; Adult; China; Female; Retrospective Studies; Machine Learning; Middle Aged; HIV Infections; CD4 Lymphocyte Count; Young Adult; Adolescent; Risk Factors; Acquired Immunodeficiency Syndrome",
      "keywords": "EPIDEMIOLOGIC STUDIES; HIV & AIDS; Machine Learning; PREVENTIVE MEDICINE; Public health",
      "pub_types": "Journal Article",
      "pmcid": "PMC12588026"
    },
    {
      "pmid": "40935595",
      "title": "Finding the Optimal Number of Splits and Repetitions in Double Cross-Fitting Targeted Maximum Likelihood Estimators.",
      "abstract": "Flexible machine learning algorithms are increasingly utilized in real-world data analyses. When integrated within double robust methods, such as the Targeted Maximum Likelihood Estimator (TMLE), complex estimators can result in significant undercoverage-an issue that is even more pronounced in singly robust methods. The Double Cross-Fitting (DCF) procedure complements these methods by enabling the use of diverse machine learning estimators, yet optimal guidelines for the number of data splits and repetitions remain unclear. This study aims to explore the effects of varying the number of splits and repetitions in DCF on TMLE estimators through statistical simulations and a data analysis. We discuss two generalizations of DCF beyond the conventional three splits and apply a range of splits to fit the TMLE estimator, incorporating a super learner without transforming covariates. The statistical properties of these configurations are compared across two sample sizes (3000 and 5000) and two DCF generalizations (equal splits and full data use). Additionally, we conduct a real-world analysis using data from the National Health and Nutrition Examination Survey (NHANES) 2017-18\u2009cycle to illustrate the practical implications of varying DCF splits, focusing on the association between obesity and the risk of developing diabetes. Our simulation study reveals that five splits in DCF yield satisfactory bias, variance, and coverage across scenarios. In the real-world application, the DCF TMLE method showed consistent risk difference estimates over a range of splits, though standard errors increased with more splits in one generalization, suggesting potential drawbacks to excessive splitting. This research underscores the importance of judicious selection of the number of splits and repetitions in DCF TMLE methods to achieve a balance between computational efficiency and accurate statistical inference. Optimal performance seems attainable with three to five splits. Among the generalizations considered, using full data for nuisance estimation offered more consistent variance estimation and is preferable for applied use. Additionally, increasing the repetitions beyond 25 did not enhance performance, providing crucial guidance for researchers employing complex machine learning algorithms in causal studies and advocating for cautious split management in DCF procedures.",
      "authors": "Karim Mohammad Ehsanul; Mondol Momenul Haque",
      "year": "2025",
      "journal": "Pharmaceutical statistics",
      "doi": "10.1002/pst.70022",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40935595/",
      "mesh_terms": "Likelihood Functions; Humans; Nutrition Surveys; Computer Simulation; Machine Learning; Algorithms; Obesity; Sample Size; Data Interpretation, Statistical; Models, Statistical",
      "keywords": "TMLE; causal inference; cross\u2010fit; double robust; machine learning; sample splitting",
      "pub_types": "Journal Article",
      "pmcid": "PMC12425639"
    },
    {
      "pmid": "41169421",
      "title": "Stage prediction of acute kidney injury in sepsis patients using explainable machine learning approaches.",
      "abstract": "BACKGROUND: Acute kidney injury (AKI) is a prevalent and serious complication among sepsis patients, closely associated with high mortality rates and substantial disease burden. Early prediction of AKI is vital for prompt and effective intervention and improved prognosis. This research seeks to construct and assess forecasting frameworks that leverage advanced machine learning algorithms to anticipate AKI progression in high-risk sepsis patients. METHODS: This study utilized the MIMIC-IV database, a large, publicly available critical care dataset containing comprehensive, de-identified electronic health records of over 70,000 ICU admissions at Beth Israel Deaconess Medical Center, to extract sepsis patient data for model training and test. Following feature selection, various machine learning algorithms were employed, including Decision Tree (DT), Efficient Neural Network (ENet), k-Nearest Neighbor (KNN), Light Gradient Boosting Machine (LightGBM), Multi-Layer Perceptron (MLP), Multinomial Mixture Model (Multinom), Random Forest (RF), and eXtreme Gradient Boosting (XGBoost). A five-fold cross-test strategy was implemented to minimize bias and assess model performance. SHapley Additive exPlanations (SHAP) was used to interpret the results. RESULTS: A total of 6,866 critically ill sepsis patients were analyzed, of whom 5,896 developed AKI during hospitalization The RF model demonstrated superior performance, attaining an average AUC score of 0.89 on the ROC curve. SHAP analysis provided detailed insights into feature importance, including urine output, BMI, SOFA score, and maximum blood urea nitrogen, enhancing the clinical applicability of the model. CONCLUSION: The machine learning models developed in this study effectively predicted the stages of AKI in severely ill sepsis patients, with the Random Forest model demonstrating optimal performance. SHAP analysis offered crucial insights into the risk factors, facilitating timely and personalized interventions within a clinical setting. Additional multi-center research is essential to confirm the validity of these findings and to ultimately improve patient outcomes and quality of life.",
      "authors": "Quan Zhen; Han Zheng; Zeng Siyao; Wen Lianghe; Wang Jingkai; Li Yue; Wang Hongliang",
      "year": "2025",
      "journal": "Frontiers in medicine",
      "doi": "10.3389/fmed.2025.1667488",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41169421/",
      "mesh_terms": "",
      "keywords": "MIMIC-IV database; acute kidney injury; machine learning; prediction model; sepsis",
      "pub_types": "Journal Article",
      "pmcid": "PMC12568512"
    },
    {
      "pmid": "40155866",
      "title": "Machine learning in lymphocyte and immune biomarker analysis for childhood thyroid diseases in China.",
      "abstract": "OBJECTIVE: This study aims to characterize and analyze the expression of representative biomarkers like lymphocytes and immune subsets in children with thyroid disorders. It also intends to develop and evaluate a machine learning model to predict if patients have thyroid disorders based on their clinical characteristics, ultimately providing insights to enhance the clinical guidelines for the pathogenesis of childhood thyroid disorders. METHOD: This cross-sectional study conducted in China examined diagnosed cases to describe the characteristics and expression of lymphocyte and immune subsets as predicted by the model. The study included two groups of children: 139 who were hospitalized in the Department of Endocrinology and a control group consisting of 283 children who underwent routine health checks at the Department of Children Healthcare. Cases were classified into three groups based on diagnoses: Graves' disease (GD), Hashimoto's thyroiditis (HT), and hypothyroidism. By employing 11 readily obtainable serum biochemical indicators within three days of admission, the median concentrations and percentages of subset measurements were analyzed. Additionally, nine machine learning (ML) algorithms were utilized to construct prediction models. Various evaluation metrics, including the area under the receiver operating characteristic curve (AUC), were employed to compare predictive performance. RESULTS: GD cases had increased levels of CD3-CD19\u2009+\u2009and CD3\u2009+\u2009CD4\u2009+\u2009T lymphocytes, and a higher CD4+/CD8\u2009+\u2009ratio. In both GD and HT, the levels of complement C3c, IgA, and IgG were higher than those in the control group. HT cases also had an increasing percentage of CD3-CD16\u2009+\u200956\u2009+\u2009T lymphocytes. Most immune markers increased in hypothyroidism, except for some T lymphocyte percentages and the CD4+/CD8\u2009+\u2009ratio. To reduce age-related bias, propensity score matching was used, yielding consistent results. Among the nine machine learning models evaluated, logistic regression showed the best performance, being useful in clinical practice. CONCLUSIONS: Specific lymphocytes with different biomarkers are positively correlated with autoimmune thyroid disease (AITD) in children. Complement proteins C3c and C4, along with IgG, IgA, IgM, and T/B cells, are significant in childhood thyroid diseases. Our best model can effectively distinguish these conditions, but to enhance accuracy, more detailed information such as clinical images might be needed.",
      "authors": "Yang Ruizhe; Li Wei; Niu Qing; Yang WenTao; Gu Wei; Wang Xu",
      "year": "2025",
      "journal": "BMC pediatrics",
      "doi": "10.1186/s12887-024-05368-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40155866/",
      "mesh_terms": "Humans; Machine Learning; Male; Female; Child; Biomarkers; Cross-Sectional Studies; China; Child, Preschool; Graves Disease; Adolescent; Hashimoto Disease; Hypothyroidism; Case-Control Studies; Thyroid Diseases; ROC Curve",
      "keywords": "Childhood AITD; Explainable prediction model; Immune biomarker; Machine learning; Propensity score match",
      "pub_types": "Journal Article",
      "pmcid": "PMC11951590"
    },
    {
      "pmid": "39866887",
      "title": "Novel approach for noninvasive pelvic floor muscle strength measurement using extracorporeal surface perineal pressure measurement and machine learning modeling.",
      "abstract": "OBJECTIVE: Accurate measurement of pelvic floor muscle (PFM) strength is crucial for the management of pelvic floor disorders. However, the current methods are invasive, uncomfortable, and lack standardization. This study aimed to introduce a novel noninvasive approach for precise PFM strength quantification by leveraging extracorporeal surface perineal pressure (ESPP) measurements and machine learning algorithms. METHODS: Twenty-one healthy women participated in this study. ESPP measurements were obtained using a 10\u2009\u00d7\u200910 pressure array sensor during maximal voluntary PFM contractions in a seated position. Simultaneously, transabdominal ultrasound was used to measure bladder base displacement (mm) as a reference for PFM contraction strength. Seven ESPP variables were calculated based on ESPP data and intra- and inter-rater reliabilities were assessed. Machine learning algorithms predicted bladder base displacement from ESPP variables. RESULTS: The ESPP measurements demonstrated good to excellent intra-rater (ICC\u2009=\u20090.881) and inter-rater (ICC\u2009=\u20090.967) reliability. Significant correlations were observed between bladder base displacement and middle (r\u2009=\u2009.619, P\u2009<\u2009.001) and front (r\u2009=\u2009-.379, P\u2009=.002) vectors. The top-performing models for predicting bladder base displacement were the support vector machine [root mean square error (RMSE)\u2009=\u20090.139, R2\u2009=\u20090.542], random forest (RMSE\u2009=\u20090.123, R2\u2009=\u20090.367), and AdaBoost (RMSE\u2009=\u20090.123, R2\u2009=\u20090.320) on the training set, and AdaBoost (RMSE\u2009=\u20090.173, R2\u2009=\u20090.537), random forest (RMSE\u2009=\u20090.177, R2\u2009=\u20090.512), and support vector machine (RMSE\u2009=\u20090.178, R2\u2009=\u20090.508) on the test set. In predicting bladder base displacement, Bland-Altman analysis revealed these models had minimal systematic bias, with mean differences ranging from -0.007 to 0.066, and clinically acceptable limits of agreement. CONCLUSION: This study demonstrates the potential of ESPP measurements and machine learning algorithms as a reliable and valid noninvasive approach for assessing PFM strength by quantifying the directionality of contractions, overcoming the limitations of traditional techniques.",
      "authors": "Hwang Ui-Jae; Ahn Sun-Hee; Lee Hyeon-Ju; Jeon Yurin; Jeon Myung Jae",
      "year": "2025",
      "journal": "Digital health",
      "doi": "10.1177/20552076251316730",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39866887/",
      "mesh_terms": "",
      "keywords": "Exercise; machine learning; musculoskeletal; rehabilitation; women\u2019s health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11758543"
    },
    {
      "pmid": "32885165",
      "title": "A frequency-domain machine learning method for dual-calibrated fMRI mapping of oxygen extraction fraction (OEF) and cerebral metabolic rate of oxygen consumption (CMRO2).",
      "abstract": "Magnetic resonance imaging (MRI) offers the possibility to non-invasively map the brain's metabolic oxygen consumption (CMRO2), which is essential for understanding and monitoring neural function in both health and disease. However, in depth study of oxygen metabolism with MRI has so far been hindered by the lack of robust methods. One MRI method of mapping CMRO2 is based on the simultaneous acquisition of cerebral blood flow (CBF) and blood oxygen level dependent (BOLD) weighted images during respiratory modulation of both oxygen and carbon dioxide. Although this dual-calibrated methodology has shown promise in the research setting, current analysis methods are unstable in the presence of noise and/or are computationally demanding. In this paper, we present a machine learning implementation for the multi-parametric assessment of dual-calibrated fMRI data. The proposed method aims to address the issues of stability, accuracy, and computational overhead, removing significant barriers to the investigation of oxygen metabolism with MRI. The method utilizes a time-frequency transformation of the acquired perfusion and BOLD-weighted data, from which appropriate feature vectors are selected for training of machine learning regressors. The implemented machine learning methods are chosen for their robustness to noise and their ability to map complex non-linear relationships (such as those that exist between BOLD signal weighting and blood oxygenation). An extremely randomized trees (ET) regressor is used to estimate resting blood flow and a multi-layer perceptron (MLP) is used to estimate CMRO2 and the oxygen extraction fraction (OEF). Synthetic data with additive noise are used to train the regressors, with data simulated to cover a wide range of physiologically plausible parameters. The performance of the implemented analysis method is compared to published methods both in simulation and with in-vivo data (n=30). The proposed method is demonstrated to significantly reduce computation time, error, and proportional bias in both CMRO2 and OEF estimates. The introduction of the proposed analysis pipeline has the potential to not only increase the detectability of metabolic difference between groups of subjects, but may also allow for single subject examinations within a clinical context.",
      "authors": "Germuska Michael; Chandler Hannah; Okell Thomas; Fasano Fabrizio; Tomassini Valentina; Murphy Kevin; Wise Richard",
      "year": "2020",
      "journal": "Frontiers in artificial intelligence",
      "doi": "10.3389/frai.2020.00012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32885165/",
      "mesh_terms": "",
      "keywords": "BOLD; CMRO2; OEF; artificial neural networks; calibrated-fMRI; machine learning; magnetic resonance imaging; metabolism; oxygen extraction fraction",
      "pub_types": "Journal Article",
      "pmcid": "PMC7116003"
    },
    {
      "pmid": "39289666",
      "title": "Prevalence estimates for COVID-19-related health behaviors based on the cheating detection triangular model.",
      "abstract": "BACKGROUND: Survey studies in medical and health sciences predominantly apply a conventional direct questioning (DQ) format to gather private and highly personal information. If the topic under investigation is sensitive or even stigmatizing, such as COVID-19-related health behaviors and adherence to non-pharmaceutical interventions in general, DQ surveys can lead to nonresponse and untruthful answers due to the influence of social desirability bias (SDB). These effects seriously threaten the validity of the results obtained, potentially leading to distorted prevalence estimates for behaviors for which the prevalence in the population is unknown. While this issue cannot be completely avoided, indirect questioning techniques (IQTs) offer a means to mitigate the harmful influence of SDB by guaranteeing the confidentiality of individual responses. The present study aims at assessing the validity of a recently proposed IQT, the Cheating Detection Triangular Model (CDTRM), in estimating the prevalence of COVID-19-related health behaviors while accounting for cheaters who disregard the instructions. METHODS: In an online survey of 1,714 participants in Taiwan, we obtained CDTRM prevalence estimates via an Expectation-Maximization algorithm for three COVID-19-related health behaviors with different levels of sensitivity. The CDTRM estimates were compared to DQ estimates and to available official statistics provided by the Taiwan Centers for Disease Control. Additionally, the CDTRM allowed us to estimate the share of cheaters who disregarded the instructions and adjust the prevalence estimates for the COVID-19-related health behaviors accordingly. RESULTS: For a behavior with low sensitivity, CDTRM and DQ estimates were expectedly comparable and in line with official statistics. However, for behaviors with medium and high sensitivity, CDTRM estimates were higher and thus presumably more valid than DQ estimates. Analogously, the estimated cheating rate increased with higher sensitivity of the behavior under study. CONCLUSIONS: Our findings strongly support the assumption that the CDTRM successfully controlled for the validity-threatening influence of SDB in a survey on three COVID-19-related health behaviors. Consequently, the CDTRM appears to be a promising technique to increase estimation validity compared to conventional DQ for health-related behaviors, and sensitive attributes in general, for which a strong influence of SDB is to be expected.",
      "authors": "Hsieh Shu-Hui; Perri Pier Francesco; Hoffmann Adrian",
      "year": "2024",
      "journal": "BMC public health",
      "doi": "10.1186/s12889-024-19819-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39289666/",
      "mesh_terms": "Humans; COVID-19; Health Behavior; Male; Female; Adult; Prevalence; Middle Aged; Taiwan; Deception; Young Adult; Surveys and Questionnaires; Adolescent; Models, Statistical; Aged",
      "keywords": "COVID-19; Cheating detection; Indirect questioning; Misreporting; Nonresponse; Privacy protection; Social desirability bias",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11406834"
    },
    {
      "pmid": "31025002",
      "title": "Smartwatches Can Detect Walker and Cane Use in Older Adults.",
      "abstract": "BACKGROUND AND OBJECTIVES: Clinicians commonly prescribe assistive devices such as walkers or canes to reduce older adults' fall risk. However, older adults may not consistently use their assistive device, and measuring adherence can be challenging due to self-report bias or cognitive deficits. Because walking patterns can change while using an assistive device, we hypothesized that smartphones and smartwatches, combined with machine-learning algorithms, could detect whether an older adult was walking with an assistive device. RESEARCH DESIGN AND METHODS: Older adults at an Adult Day Center (n = 14) wore an Android smartphone and Actigraph smartwatch while completing the six-minute walk, 10-meter walk, and Timed Up and Go tests with and without their assistive device on five separate days. We used accelerometer data from the devices to build machine-learning algorithms to detect whether the participant was walking with or without their assistive device. We tested our algorithms using cross-validation. RESULTS: Smartwatch classifiers could accurately detect assistive device use, but smartphone classifiers performed poorly. Customized smartwatch classifiers, which were created specifically for one participant, had greater than 95% classification accuracy for all participants. Noncustomized smartwatch classifiers (ie, an \"off-the-shelf\" system) had greater than 90% accuracy for 10 of the 14 participants. A noncustomized system performed better for walker users than cane users. DISCUSSION AND IMPLICATIONS: Our approach can leverage data from existing commercial devices to provide a deeper understanding of walker or cane use. This work can inform scalable public health monitoring tools to quantify assistive device adherence and enable proactive fall interventions.",
      "authors": "Antos Stephen A; Danilovich Margaret K; Eisenstein Amy R; Gordon Keith E; Kording Konrad P",
      "year": "2019",
      "journal": "Innovation in aging",
      "doi": "10.1093/geroni/igz008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31025002/",
      "mesh_terms": "",
      "keywords": "Accelerometer; Assistive Technology; Falls; Function/Mobility; Wearables",
      "pub_types": "Journal Article",
      "pmcid": "PMC6476414"
    },
    {
      "pmid": "30354090",
      "title": "Machine Learning Approach To Estimate Hourly Exposure to Fine Particulate Matter for Urban, Rural, and Remote Populations during Wildfire Seasons.",
      "abstract": "Exposure to wildfire smoke averaged over 24-hour periods has been associated with a wide range of acute cardiopulmonary events, but little is known about the effects of sub-daily exposures immediately preceding these events. One challenge for studying sub-daily effects is the lack of spatially and temporally resolved estimates of smoke exposures. Inexpensive and globally applicable tools to reliably estimate exposure are needed. Here we describe a Random Forests machine learning approach to estimate 1-hour average population exposure to fine particulate matter during wildfire seasons from 2010 to 2015 in British Columbia, Canada, at a 5 km \u00d7 5 km resolution. The model uses remotely sensed fire activity, meteorology assimilated from multiple data sources, and geographic/ecological information. Compared with observations, model predictions had a correlation of 0.93, root mean squared error of 3.2 \u03bcg/m3, mean fractional bias of 15.1%, and mean fractional error of 44.7%. Spatial cross-validation indicated an overall correlation of 0.60, with an interquartile range from 0.48 to 0.70 across monitors. This model can be adapted for global use, even in locations without air quality monitoring. It is useful for epidemiologic studies on sub-daily exposure to wildfire smoke and for informing public health actions if operationalized in near-real-time.",
      "authors": "Yao Jiayun; Brauer Michael; Raffuse Sean; Henderson Sarah B",
      "year": "2018",
      "journal": "Environmental science & technology",
      "doi": "10.1021/acs.est.8b01921",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30354090/",
      "mesh_terms": "Air Pollutants; British Columbia; Humans; Machine Learning; Particulate Matter; Seasons; Wildfires",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41184919",
      "title": "Causal Forests Versus Inverse Probability of Treatment Weighting to Adjust for Cluster-Level Confounding: A Parametric and Plasmode Simulation Study Based on US Hospital Electronic Health Record Data.",
      "abstract": "BACKGROUND: Rapid innovation and new regulations increase the need for post-marketing surveillance of implantable devices. However, complex multi-level confounding related to patient-level and surgeon or hospital covariates hampers observational studies of risks and benefits. We conducted two simulation studies to compare the performance of Causal Forests (CF) versus Inverse Probability of Treatment Weighting (IPTW) to reduce confounding bias in the presence of strong surgeon impact on treatment allocation. METHODS: Two Monte Carlo simulation studies were carried out: (1) Parametric simulations with patients nested in clusters (ratio 10:1, 50:1, 100:1, 200:1, 500:1) and sample size n\u2009=\u200910\u2009000 were conducted with patient and cluster level confounders; (2) Plasmode simulations generated from a cohort of 9981 patients admitted for pancreatectomy between 2015 and 2019 from the US PINC AT hospital research database. Different CF algorithms and IPTW were used to estimate binary treatment effects. RESULTS: Performance varied with the strength of cluster-level confounding. Under weak to moderate surgeon influence, CF and IPTW performed similarly. When confounding was strong (OR\u2009=\u20092.5), CF reduced bias compared with IPTW: in parametric simulations, relative bias averaged 11.2% for CF versus 19.9% for IPTW, with similar advantages observed in plasmode simulations. CONCLUSIONS: CF shows promise as a method for estimating treatment effects in scenarios where cluster-level confounding strongly impacts treatment allocation. More research is needed to guide its use.",
      "authors": "Du Mike; Johnston Stephen; Coplan Paul M; Strauss Victoria Y; Khalid Sara; Prieto-Alhambra Daniel",
      "year": "2025",
      "journal": "Pharmacoepidemiology and drug safety",
      "doi": "10.1002/pds.70257",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41184919/",
      "mesh_terms": "Humans; Electronic Health Records; Monte Carlo Method; United States; Confounding Factors, Epidemiologic; Computer Simulation; Cluster Analysis; Probability; Databases, Factual; Product Surveillance, Postmarketing; Algorithms; Bias",
      "keywords": "causal forests; causal inference; clustered data; machine learning; propensity score; simulation study",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": "PMC12583492"
    },
    {
      "pmid": "30473402",
      "title": "Predicting treatment response to antidepressant medication using early changes in emotional processing.",
      "abstract": "Antidepressants must be taken for weeks before response can be assessed with many patients not responding to the first medication prescribed. This often results in long delays before effective treatment is started. Antidepressants induce changes in the processing of emotional stimuli early in the course of treatment. In the current study we assessed whether changes in emotional processing and subjective symptoms over the first week of antidepressant treatment predicted clinical response after 4-8 weeks of treatment. Such a predictive test may shorten the time taken to initiate effective treatment in depressed patients. Seventy-four depressed primary care patients completed measures of emotional bias and subjective symptoms before starting antidepressant treatment and then again 1 week later. Response to treatment was assessed after 4-6 weeks. The performance of classifiers based on these measures was assessed using a leave-one-out validation procedure with the best classifier then tested in an independent sample from a second study of 239 patients. The combination of a facial emotion recognition task and subjective symptoms predicted response with 77% accuracy in the training sample and 60% accuracy in the independent study, significantly better than possible using baseline response rates. The face based measure of emotional bias provided good quality data with high acceptability ratings. Changes in emotional processing can provide a sensitive early measure of antidepressant efficacy for individual patients. Early treatment induced changes in emotional processing may be used to guide antidepressant therapy and reduce the time taken for depressed patients to return to good mental health.",
      "authors": "Browning Michael; Kingslake Jonathan; Dourish Colin T; Goodwin Guy M; Harmer Catherine J; Dawson Gerard R",
      "year": "2019",
      "journal": "European neuropsychopharmacology : the journal of the European College of Neuropsychopharmacology",
      "doi": "10.1016/j.euroneuro.2018.11.1102",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30473402/",
      "mesh_terms": "Adolescent; Adult; Aged; Algorithms; Antidepressive Agents; Citalopram; Depression; Diagnosis, Computer-Assisted; Emotions; Facial Expression; Female; Forecasting; Humans; Male; Middle Aged; Primary Health Care; Recognition, Psychology; Time Factors; Treatment Outcome; Young Adult",
      "keywords": "Antidepressant; Depression; Emotional bias; Machine learning; Prediction; Treatment",
      "pub_types": "Clinical Trial; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41094430",
      "title": "Identifying subjective life expectancy risk factors in physically active and inactive middle-aged and older adults using machine learning models.",
      "abstract": "BACKGROUND: Physical activity is a key focus in the field of public health, and subjective life expectancy is closely associated with individuals' physical and psychological well-being. This study aimed to identify the risk factors for subjective life expectancy among middle-aged and older adults with active and inactive physical activity levels, and to provide an evidence base for developing differentiated health intervention strategies. METHODS: Based on data from the China Health and Retirement Longitudinal Study (CHARLS) 2018 survey, a total of 10,945 participants were included. Five machine learning models, including Random Forest (RF), Logistic Regression (LR), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), and Light Gradient Boosting Machine (LightGBM), were separately constructed for the active and inactive groups. To reduce bias caused by class imbalance, the Synthetic Minority Over-sampling Technique (SMOTE) was applied to generate synthetic samples for the minority class. The dataset was split into a training set (70%) and a testing set (30%), and ten-fold cross-validation combined with grid search was employed to optimize hyperparameters, ensuring both robustness and generalizability of the models. Model performance was evaluated using the Area Under the Receiver Operating Characteristic Curve (AUC), accuracy, sensitivity, specificity, and F1-score. RESULTS: The active group (4,707 men and 4,885 women) had a mean age of 59.76 years, while the inactive group (662 men and 691 women) had a mean age of 63.00 years. The Support Vector Machine (SVM) model achieved the best performance in the inactive group (AUC: 0.797; accuracy: 0.722; sensitivity: 0.747), whereas the Light Gradient Boosting Machine (LightGBM) model achieved the best performance in the active group (AUC: 0.775; accuracy: 0.745; specificity: 0.814). Feature importance analysis indicated that \"age\" was the most important variable in the Support Vector Machine (SVM) model, while \"perceived health\" was the most important variable in the Light Gradient Boosting Machine (LightGBM) model. CONCLUSION: Machine learning methods can effectively identify key risk factors influencing subjective life expectancy among middle-aged and older adults, and provide valuable guidance for targeted health management strategies tailored to populations with different levels of physical activity.",
      "authors": "Yang Jian; Li Zhihui; Wu Ming; Zhang Yuan; Zhang Bianjiang; Shi Huiyu",
      "year": "2025",
      "journal": "BMC public health",
      "doi": "10.1186/s12889-025-24657-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41094430/",
      "mesh_terms": "Humans; Machine Learning; Male; Female; Middle Aged; Aged; Exercise; Risk Factors; Life Expectancy; China; Longitudinal Studies; Sedentary Behavior",
      "keywords": "Machine learning; Middle-aged and elderly people; Physical activity; Subjective life expectancy",
      "pub_types": "Journal Article",
      "pmcid": "PMC12522564"
    },
    {
      "pmid": "39109827",
      "title": "Artificial Intelligence in Stroke Imaging: A Comprehensive Review.",
      "abstract": "The aging population challenges the health-care system with chronic diseases. Cerebrovascular diseases are important components of these chronic conditions. Stroke is the acute cessation of blood in the brain, which can lead to rapid tissue loss. Therefore, fast, accurate, and reliable automatic methods are required to facilitate stroke management. The performance of artificial intelligence (AI) methods is increasing in all domains. Vision tasks, including natural images and medical images, are particularly benefiting from the skills of AI models. The AI methods that can be applied to stroke imaging have a broad range, including classical machine learning tools such as support vector machines, random forests, logistic regression, and linear discriminant analysis, as well as deep learning models, such as convolutional neural networks, recurrent neural networks, autoencoders, and U-Net. Both tools can be applied to various aspects of stroke management, including time-to-event onset determination, stroke confirmation, large vessel occlusion detection, difusion restriction, perfusion deficit, core and penumbra identification, afected region segmentation, and functional outcome prediction. While building these AI models, maximum care should be exercised in order to reduce bias and build generalizable models. One of the most important prerequisites for building unbiased models is collecting large, diverse, and quality data that reflects the underlying population well and splitting the training and testing parts in a way that both represent a similar distribution. Explainability and trustworthiness are other important properties of machine learning models that could be widely adopted in clinical practices.",
      "authors": "Koska \u0130lker \u00d6zg\u00fcr; Selver Alper",
      "year": "2023",
      "journal": "The Eurasian journal of medicine",
      "doi": "10.5152/eurasianjmed.2023.23347",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39109827/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11075039"
    },
    {
      "pmid": "33548370",
      "title": "The accuracy of fully automated algorithms for surveillance of healthcare-associated urinary tract infections in hospitalized patients.",
      "abstract": "BACKGROUND: Surveillance for healthcare-associated infections such as healthcare-associated urinary tract infections (HA-UTI) is important for directing resources and evaluating interventions. However, traditional surveillance methods are resource-intensive and subject to bias. AIM: To develop and validate a fully automated surveillance algorithm for HA-UTI using electronic health record (EHR) data. METHODS: Five algorithms were developed using EHR data from 2979 admissions at Karolinska University Hospital from 2010 to 2011: (1) positive urine culture (UCx); (2) positive UCx\u00a0+ UTI codes (International Statistical Classification of Diseases and Related Health Problems, 10th revision); (3) positive UCx\u00a0+ UTI-specific antibiotics; (4) positive UCx\u00a0+ fever and/or UTI symptoms; (5) algorithm 4 with negation for fever without UTI symptoms. Natural language processing (NLP) was used for processing free-text medical notes. The algorithms were validated in 1258 potential UTI episodes from January to March 2012 and results extrapolated to all UTI episodes within this period (N\u00a0= 16,712). The reference standard for HA-UTIs was manual record review according to the European Centre for Disease Prevention and Control (and US Centers for Disease Control and Prevention) definitions by trained healthcare personnel. FINDINGS: Of the 1258 UTI episodes, 163 fulfilled the ECDC HA-UTI definition and the algorithms classified 391, 150, 189, 194, and 153 UTI episodes, respectively, as HA-UTI. Algorithms 1, 2, and 3 had insufficient performances. Algorithm 4 achieved better performance and algorithm 5 performed best for surveillance purposes with sensitivity 0.667 (95% confidence interval: 0.594-0.733), specificity 0.997 (0.996-0.998), positive predictive value 0.719 (0.624-0.807) and negative predictive value 0.997 (0.996-0.997). CONCLUSION: A fully automated surveillance algorithm based on NLP to find UTI symptoms in free-text had acceptable performance to detect HA-UTI compared to manual record review. Algorithms based on administrative and microbiology data only were not sufficient.",
      "authors": "van der Werff S D; Thiman E; Tanushi H; Valik J K; Henriksson A; Ul Alam M; Dalianis H; Ternhag A; Naucl\u00e9r P",
      "year": "2021",
      "journal": "The Journal of hospital infection",
      "doi": "10.1016/j.jhin.2021.01.023",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33548370/",
      "mesh_terms": "Algorithms; Cross Infection; Delivery of Health Care; Electronic Data Processing; Electronic Health Records; Epidemiological Monitoring; Hospitalization; Humans; Inpatients; Urinary Tract Infections",
      "keywords": "Algorithms; Automated surveillance; Healthcare-associated infection; Natural language processing; Urinary tract infections",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "31651956",
      "title": "Imputation and characterization of uncoded self-harm in major mental illness using machine learning.",
      "abstract": "OBJECTIVE: We aimed to impute uncoded self-harm in administrative claims data of individuals with major mental illness (MMI), characterize self-harm incidence, and identify factors associated with coding bias. MATERIALS AND METHODS: The IBM MarketScan database (2003-2016) was used to analyze visit-level self-harm in 10\u00a0120\u00a0030 patients with \u22652 MMI codes. Five machine learning (ML) classifiers were tested on a balanced data subset, with XGBoost selected for the full dataset. Classification performance was validated via random data mislabeling and comparison with a clinician-derived \"gold standard.\" The incidence of coded and imputed self-harm was characterized by year, patient age, sex, U.S. state, and MMI diagnosis. RESULTS: Imputation identified 1\u00a0592\u00a0703 self-harm events vs 83\u00a0113 coded events, with areas under the curve >0.99 for the balanced and full datasets, and 83.5% agreement with the gold standard. The overall coded and imputed self-harm incidence were 0.28% and 5.34%, respectively, varied considerably by age and sex, and was highest in individuals with multiple MMI diagnoses. Self-harm undercoding was higher in male than in female individuals and increased with age. Substance abuse, injuries, poisoning, asphyxiation, brain disorders, harmful thoughts, and psychotherapy were the main features used by ML to classify visits. DISCUSSION: Only 1 of 19 self-harm events was coded for individuals with MMI. ML demonstrated excellent performance in recovering self-harm visits. Male individuals and seniors with MMI are particularly vulnerable to self-harm undercoding and may be at risk of not getting appropriate psychiatric care. CONCLUSIONS: ML can effectively recover unrecorded self-harm in claims data and inform psychiatric epidemiological and observational studies.",
      "authors": "Kumar Praveen; Nestsiarovich Anastasiya; Nelson Stuart J; Kerner Berit; Perkins Douglas J; Lambert Christophe G",
      "year": "2020",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocz173",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31651956/",
      "mesh_terms": "Adult; Algorithms; Classification; Clinical Coding; Datasets as Topic; Electronic Health Records; Female; Humans; Incidence; Machine Learning; Male; Mental Disorders; Self-Injurious Behavior; Suicidal Ideation",
      "keywords": "coding; electronic health records; machine learning; self-harm; suicide",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7647246"
    },
    {
      "pmid": "37193196",
      "title": "Survival Modelling For Data From Combined Cohorts: Opening the Door to Meta Survival Analyses and Survival Analysis using Electronic Health Records.",
      "abstract": "Non-parametric estimation of the survival function using observed failure time data depends on the underlying data generating mechanism, including the ways in which the data may be censored and/or truncated. For data arising from a single source or collected from a single cohort, a wide range of estimators have been proposed and compared in the literature. Often, however, it may be possible, and indeed advantageous, to combine and then analyze survival data that have been collected under different study designs. We review non-parametric survival analysis for data obtained by combining the most common types of cohort. We have two main goals: (i) To clarify the differences in the model assumptions, and (ii) to provide a single lens through which some of the proposed estimators may be viewed. Our discussion is relevant to the meta analysis of survival data obtained from different types of study, and to the modern era of electronic health records.",
      "authors": "McVittie James H; Best Ana F; Wolfson David B; Stephens David A; Wolfson Julian; Buckeridge David L; Gadalla Shahinaz M",
      "year": "2023",
      "journal": "International statistical review = Revue internationale de statistique",
      "doi": "10.1111/insr.12510",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37193196/",
      "mesh_terms": "",
      "keywords": "EM algorithm; censoring; incident cohort; length bias; prevalent cohort",
      "pub_types": "Journal Article",
      "pmcid": "PMC10181797"
    },
    {
      "pmid": "37981713",
      "title": "Evaluating a Targeted Minimum Loss-Based Estimator for Capture-Recapture Analysis: An Application to HIV Surveillance in San Francisco, California.",
      "abstract": "The capture-recapture method is a common tool used in epidemiology to estimate the size of \"hidden\" populations and correct the underascertainment of cases, based on incomplete and overlapping lists of the target population. Log-linear models are often used to estimate the population size yet may produce implausible and unreliable estimates due to model misspecification and small cell sizes. A novel targeted minimum loss-based estimation (TMLE) model developed for capture-recapture makes several notable improvements to conventional modeling: \"targeting\" the parameter of interest, flexibly fitting the data to alternative functional forms, and limiting bias from small cell sizes. Using simulations and empirical data from the San Francisco, California, Department of Public Health's human immunodeficiency virus (HIV) surveillance registry, we evaluated the performance of the TMLE model and compared results with those of other common models. Based on 2,584 people observed on 3 lists reportable to the surveillance registry, the TMLE model estimated the number of San Francisco residents living with HIV as of December 31, 2019, to be 13,523 (95% confidence interval: 12,222, 14,824). This estimate, compared with a \"ground truth\" of 12,507, was the most accurate and precise of all models examined. The TMLE model is a significant advancement in capture-recapture studies, leveraging modern statistical methods to improve estimation of the sizes of hidden populations.",
      "authors": "Wesson Paul; Das Manjari; Chen Mia; Hsu Ling; McFarland Willi; Kennedy Edward; Jewell Nicholas P",
      "year": "2024",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwad231",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37981713/",
      "mesh_terms": "Humans; HIV; San Francisco; Linear Models; Bias; HIV Infections",
      "keywords": "SuperLearner; bias; capture-recapture method; hidden populations; human immunodeficiency virus; machine learning; prevalence estimation; targeted minimum loss-based estimation",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10999650"
    },
    {
      "pmid": "33548542",
      "title": "Bagged random causal networks for interventional queries on observational biomedical datasets.",
      "abstract": "Learning causal effects from observational data, e.g. estimating the effect of a treatment on survival by data-mining electronic health records (EHRs), can be biased due to unmeasured confounders, mediators, and colliders. When the causal dependencies among features/covariates are expressed in the form of a directed acyclic graph, using do-calculus it is possible to identify one or more adjustment sets for eliminating the bias on a given causal query under certain assumptions. However, prior knowledge of the causal structure might be only partial; algorithms for causal structure discovery often provide ambiguous solutions, and their computational complexity becomes practically intractable when the feature sets grow large. We hypothesize that the estimation of the true causal effect of a causal query on to an outcome can be approximated as an ensemble of lower complexity estimators, namely bagged random causal networks. A bagged random causal network is an ensemble of subnetworks constructed by sampling the feature subspaces (with the query, the outcome, and a random number of other features), drawing conditional dependencies among the features, and inferring the corresponding adjustment sets. The causal effect can be then estimated by any regression function of the outcome by the query paired with the adjustment sets. Through simulations and a real-world clinical dataset (class III malocclusion data), we show that the bagged estimator is -in most cases- consistent with the true causal effect if the structure is known, has a good variance/bias trade-off when the structure is unknown (estimated using heuristics), has lower computational complexity than learning a full network, and outperforms boosted regression. In conclusion, the bagged random causal network is well-suited to estimate query-target causal effects from observational studies on EHR and other high-dimensional biomedical databases.",
      "authors": "Prosperi Mattia; Guo Yi; Bian Jiang",
      "year": "2021",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2021.103689",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33548542/",
      "mesh_terms": "Algorithms; Bias; Causality",
      "keywords": "Bagging; Causal inference; Directed acyclic graph; Electronic health record; Machine learning; Treatment effect",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC8085906"
    },
    {
      "pmid": "32068684",
      "title": "MsFLASH network vaginal health trial: absence of evidence is NOT evidence of absence.",
      "abstract": "Approximately 50% of postmenopausal women experience vulvovaginal symptoms associated with genitourinary syndrome of menopause (GSM). GSM is a chronic and progressive condition with a well-defined treatment algorithm. Analysis of the MsFLASH Vaginal Health Trial data produced two main conclusions, which were that prescribed vaginal 10\u200a\u03bcg estradiol tablet and over-the-counter (OTC) vaginal moisturizer did not provide additional benefit over placebo vaginal tablet and placebo gel in reducing postmenopausal vulvovaginal symptoms; or increasing the proportions of women reporting sexual activity or improving pain scores with sexual activity. These treatment conclusions are contrary to all prior robust clinical trial data for dyspareunia and vaginal dryness, and not in line with the good clinical practice for GSM management presented by the American College of Obstetricians and Gynecologists, The North American Menopause Society, and the Endocrine Society. Overall, the flaws of the MsFLASH Vaginal Health Trial were to incorrectly identify the therapeutic outcomes of most interest using metrics that exhibit high degrees of placebo bias; and to utilize low statistical power with which to appreciate any significant differences between groups.",
      "authors": "Lukas Vanessa A; Simon James A",
      "year": "2020",
      "journal": "Menopause (New York, N.Y.)",
      "doi": "10.1097/GME.0000000000001516",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32068684/",
      "mesh_terms": "Atrophy; Dyspareunia; Female; Humans; Menopause; Postmenopause; Vagina; Vaginal Creams, Foams, and Jellies; Vaginal Diseases",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40386992",
      "title": "Multi-Study Factor Regression Model: An Application in Nutritional Epidemiology.",
      "abstract": "Diet is a risk factor for many diseases. In nutritional epidemiology, studying reproducible dietary patterns is critical to reveal important associations with health. However, this task is challenging: diverse cultural and ethnic backgrounds may critically impact eating patterns by showing heterogeneity, leading to incorrect dietary patterns and obscuring the components shared across different groups or populations. Moreover, covariate effects generated from observed variables, such as demographics and other confounders, can further bias these dietary patterns. Identifying the shared and group-specific dietary components and covariate effects is essential to drive accurate conclusions. To address these issues, we introduce a new modeling factor regression, the Multistudy Factor Regression (MSFR) model. The MSFR model analyzes different populations simultaneously, achieving three goals: capturing shared component(s) across populations, identifying group-specific structures, and correcting for covariate effects. We use this novel method to derive common and ethnic-specific dietary patterns in a multicenter epidemiological study in Hispanic/Latinos community. Our model improves the accuracy of common and group dietary signals, provides a robust estimation of factor cardinality, and yields better prediction than other techniques, revealing important associations with health and cardiovascular disease. In summary, we provide a tool to integrate different groups, providing accurate dietary signals crucial to inform public health policy.",
      "authors": "De Vito Roberta; Avalos-Pacheco Alejandra",
      "year": "2025",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.70108",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40386992/",
      "mesh_terms": "Humans; Diet; Hispanic or Latino; Models, Statistical; Regression Analysis; Female; Male; Factor Analysis, Statistical; Feeding Behavior",
      "keywords": "Dietary patterns; ECM algorithm; factor analysis; joint analysis; nutritional epidemiology",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41037360",
      "title": "Towards learning healthcare systems in Italy: opportunities and challenges of AI at point-of-care.",
      "abstract": "In Italy, the growing enthusiasm for artificial intelligence (AI) in healthcare contrasts with significant infrastructural, cultural, and trust-related barriers hindering its real-world adoption. Moving beyond the hype requires a systems thinking approach, proposing the learning health system (LHS) framework as a structured path for integration. We highlight the complementary roles of AI models: traditional machine learning (ML) is proven for diagnostics and prognostics, while large language models (LLMs) excel at administrative tasks and can structure unstructured data to train robust ML tools. The LHS cycle reveals key challenges for Italy: moving from Practice-to-Data requires overcoming data fragmentation; from Data-to-Knowledge involves transforming data into insights while mitigating bias; and from Knowledge-to-Practice necessitates bridging the gap between evidence and clinical workflow by building trust and AI literacy. Ultimately, successful and equitable AI implementation depends on a holistic strategy combining infrastructure development, multidisciplinary collaboration, and robust governance to enhance the quality and sustainability of the national healthcare system.",
      "authors": "De Angelis Luigi; Pivetta Alessio; Baglivo Francesco; Cappellini Luca Alessandro; Sacchi Francesca Aurora; Di Pumpo Marcello; Mercier Mattia; Diedenhofen Giacomo; Di Bartolomeo Mattia; Causio Francesco Andrea; Belpiede Alessandro; Tozzi Alberto Eugenio; Ferro Diana",
      "year": "2025",
      "journal": "Recenti progressi in medicina",
      "doi": "10.1701/4573.45776",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41037360/",
      "mesh_terms": "Italy; Artificial Intelligence; Humans; Point-of-Care Systems; Learning Health System; Machine Learning; Delivery of Health Care",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37274833",
      "title": "Adaptability of High Dimensional Propensity Score Procedure in the Transition from ICD-9 to ICD-10 in the US Healthcare System.",
      "abstract": "BACKGROUND: High-Dimensional Propensity Score procedure (HDPS) is a data-driven approach to assist control for confounding in pharmacoepidemiologic research. The transition to the International Classification of Disease (ICD-9/10) in the US health system may pose uncertainty in applying the HDPS procedure. METHODS: We assembled a base cohort of patients in MarketScan\u00ae Commercial Claims Database who had newly initiated celecoxib or traditional NSAIDs to compare gastrointestinal bleeding risk. We then created bootstrapped hypothetical cohorts from the base cohort with predefined patient selection patterns from the ICD eras. Three strategies for HDPS deployment were tested: 1) split the cohort by ICD era, deploy HDPS twice, and pool the relative risks (pooled RR), 2) consider codes from each ICD era as a separate data dimension and deploy HDPS in the entire cohort (data dimensions) and 3) map ICD codes from both eras to Clinical Classifications Software (CCS) concepts before deploying HDPS in the entire cohort (CCS mapping). We calculated percent bias and root-mean-squared error to compare the strategies. RESULTS: A similar bias reduction was observed in cohorts where patient selection pattern from each ICD era was comparable between the exposure groups. In the presence of considerable disparity in patient selection, we observed a bimodal distribution of propensity scores in the data dimensions strategy, indicating instrument-like covariates. Moreover, the CCS mapping strategy resulted in at least 30% less bias than pooled RR and data dimensions strategies (RMSE: 0.14, 0.19, 0.21, respectively) in this scenario. CONCLUSION: Mapping ICD codes to a stable terminology like CCS serves as a helpful strategy to reduce residual bias when deploying HDPS in pharmacoepidemiologic studies spanning both ICD eras.",
      "authors": "Sarayani Amir; Brown Joshua D; Hampp Christian; Donahoo William T; Winterstein Almut G",
      "year": "2023",
      "journal": "Clinical epidemiology",
      "doi": "10.2147/CLEP.S405165",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37274833/",
      "mesh_terms": "",
      "keywords": "HDPS algorithm; ICD-10; ICD-9; comparative effectiveness research; confounding; propensity score; real-world evidence",
      "pub_types": "Journal Article",
      "pmcid": "PMC10237200"
    },
    {
      "pmid": "28086961",
      "title": "Longitudinal multiple imputation approaches for body mass index or other variables with very low individual-level variability: the mibmi command in Stata.",
      "abstract": "BACKGROUND: In modern health care systems, the computerization of all aspects of clinical care has led to the development of large data repositories. For example, in the UK, large primary care databases hold millions of electronic medical records, with detailed information on diagnoses, treatments, outcomes and consultations. Careful analyses of these observational datasets of routinely collected data can complement evidence from clinical trials or even answer research questions that cannot been addressed in an experimental setting. However, 'missingness' is a common problem for routinely collected data, especially for biological parameters over time. Absence of complete data for the whole of a individual's study period is a potential bias risk and standard complete-case approaches may lead to biased estimates. However, the structure of the data values makes standard cross-sectional multiple-imputation approaches unsuitable. In this paper we propose and evaluate mibmi, a new command for cleaning and imputing longitudinal body mass index data. RESULTS: The regression-based data cleaning aspects of the algorithm can be useful when researchers analyze messy longitudinal data. Although the multiple imputation algorithm is computationally expensive, it performed similarly or even better to existing alternatives, when interpolating observations. CONCLUSION: The mibmi algorithm can be a useful tool for analyzing longitudinal body mass index data, or other longitudinal data with very low individual-level variability.",
      "authors": "Kontopantelis Evangelos; Parisi Rosa; Springate David A; Reeves David",
      "year": "2017",
      "journal": "BMC research notes",
      "doi": "10.1186/s13104-016-2365-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28086961/",
      "mesh_terms": "Algorithms; Body Mass Index; Humans; Longitudinal Studies; United Kingdom",
      "keywords": "Body mass index; Cleaning; Longitudinal data; Multiple imputation",
      "pub_types": "Journal Article",
      "pmcid": "PMC5234260"
    },
    {
      "pmid": "41265477",
      "title": "Prediction of quality-of-life improvement after total hip arthroplasty : a simplified and internally validated model based on 82,526 total hip arthroplasties from the Swedish Arthroplasty Register.",
      "abstract": "AIMS: Pain and poor health-related quality of life measures serve as the primary indication for primary elective total hip arthroplasty (THA). It remains challenging to predict whether THA delivers the patient-anticipated improvements. Our study aimed to develop and validate statistical and machine learning prediction models of one-year clinical improvement in patient-reported outcome measures (PROMs) after elective THA. METHODS: We included 82,526 patients with primary elective THAs from the Swedish Arthroplasty Register (SAR) for forecasting one-year improvements in the EuroQol five-dimension questionnaire (EQ-5D) index, EQ-visual analogue scale (VAS), and combined EQ-5D/EQ-VAS scores. Two minimal clinically important difference (MCID) thresholds were applied for the EQ-5D index score based on the approaches of standardized response mean (SRM) of 0.196 and capacity of benefit (CoB) of 0.428. MCID cutoff for the EQ-VAS was set to 7.81. A total of 21 features were used to feed the models. To avoid estimates bias, we eliminated missing data. Model performance was tested using the area under the receiver operating characteristic curve (AUC), and importance of features was identified in the best performing algorithm. RESULTS: Applying the SRM MCID, approximately two-thirds of patients reported one-year improvements in EQ-5D index (66.3%) and EQ-VAS (69.1%). The improvement rate decreased to 51.7% when we combined improvements in both outcomes. A higher CoB cut-off for EQ-5D index yielded lower rates (~40% for the EQ-5D index and 31.3% for the combined measure). The gradient boosting machine (GBM) consistently outperformed other models by a narrow margin in predicting significant clinical improvements in one-year PROMs and achieved a good to excellent binary discriminative power (AUC range 0.80% to 0.97%). Preoperative PROMs, EQ-5D index, EQ-VAS, and Charnley Hip Score, along with age, collectively contributed to over 80% of the algorithmic power in the ensemble GBM model. CONCLUSION: We developed an interpretable machine learning model on a Swedish cohort that may facilitate personalized assessment of meaningful clinical improvement after elective THA.",
      "authors": "Alagha M Abdulhadi; Cobb Justin P; Liddle Alexander D; Malchau Henrik; Mohaddes Maziar; Rolfson Ola",
      "year": "2025",
      "journal": "Bone & joint open",
      "doi": "10.1302/2633-1462.611.BJO-2025-0138.R1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41265477/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12634151"
    },
    {
      "pmid": "40713187",
      "title": "Parsimonious machine learning model to predict 1-year mortality and procedural futility after transcatheter aortic valve replacement.",
      "abstract": "BACKGROUND: Current risk scores inadequately predict long-term mortality after transcatheter aortic valve replacement (TAVR), limiting their ability to guide decisions around procedural futility. We aimed to develop and externally validate a machine learning (ML) model using only preprocedural variables to predict 1-year all-cause mortality. METHODS: An ML model was trained on a retrospective cohort of 1025 TAVR patients using 52 clinical and echocardiographic variables. Feature selection and model tuning were performed via a multiobjective evolutionary algorithm to optimise predictive performance and model simplicity. The final model used 13 preprocedural variables and was externally validated in an independent cohort of 270 patients. Performance was compared with European System for Cardiac Operative Risk Evaluation II (EuroSCORE II), FRANCE-2 and TAVI2-SCORE using the area under the curve (AUC), calibration and net reclassification improvement (NRI). RESULTS: The ML model demonstrated excellent discrimination, with AUCs of 0.81 in the discovery cohort and 0.84 in the external validation cohort. This exceeded the performance of EuroSCORE II (AUC: 0.61 and 0.70), FRANCE-2 (0.52 and 0.58) and TAVI2-SCORE (0.56 and 0.64). Calibration plots showed strong agreement between predicted and observed risks. NRI in the test set compared with FRANCE-2 was 0.62 (95% CI: 0.49 to 0.75); compared with TAVI2-SCORE, it was 0.36 (95% CI: 0.14 to 0.61). The final model incorporated age, atrial fibrillation, creatinine, haemoglobin, pulmonary function, frailty markers (Katz Index, poor mobility) and tricuspid regurgitation. Misclassification analysis revealed that most errors were clustered near the decision threshold, with no evidence of systematic bias. Performance was consistent across subgroups and robust to temporal and institutional variation. CONCLUSION: This externally validated ML model, using 13 routinely available variables, significantly outperforms existing risk scores in predicting 1-year mortality post-TAVR. Its simplicity and generalisability support its potential use in real-world clinical decision-making to identify patients at high risk of procedural futility.",
      "authors": "Bharucha Apurva H; Brown Samuel; Theofilatos Konstantinos; Singh Bhawana; Galusko Victor; Rashid Hashrul; Abdelgawad Hoda; Dworakowski Rafal; Papachristidis Alexandros; Patterson Tiffany; Redwood Simon R; Prendergast Bernard; Byrne Jonathan A; MacCarthy Philip A; O'Gallagher Kevin; Eskandari Mehdi",
      "year": "2025",
      "journal": "Heart (British Cardiac Society)",
      "doi": "10.1136/heartjnl-2025-325928",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40713187/",
      "mesh_terms": "",
      "keywords": "Aortic stenosis; Electronic Health Records; Risk Assessment; Transcatheter Aortic Valve Replacement",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38875695",
      "title": "Accuracy of Fully Automated 3D Imaging System for Child Anthropometry in a Low-Resource Setting: Effectiveness Evaluation in Malakal, South Sudan.",
      "abstract": "BACKGROUND: Adoption of 3D imaging systems in humanitarian settings requires accuracy comparable with manual measurement notwithstanding additional constraints associated with austere settings. OBJECTIVE: This study aimed to evaluate the accuracy of child stature and mid-upper arm circumference (MUAC) measurements produced by the AutoAnthro 3D imaging system (third generation) developed by Body Surface Translations Inc. METHODS: A study of device accuracy was embedded within a 2-stage cluster survey at the Malakal Protection of Civilians site in South Sudan conducted between September 2021 and October 2021. All children aged 6 to 59 months within selected households were eligible. For each child, manual measurements were obtained by 2 anthropometrists following the protocol used in the 2006 World Health Organization Child Growth Standards study. Scans were then captured by a different enumerator using a Samsung Galaxy 8 phone loaded with a custom software, AutoAnthro, and an Intel RealSense 3D scanner. The scans were processed using a fully automated algorithm. A multivariate logistic regression model was fit to evaluate the adjusted odds of achieving a successful scan. The accuracy of the measurements was visually assessed using Bland-Altman plots and quantified using average bias, limits of agreement (LoAs), and the 95% precision interval for individual differences. Key informant interviews were conducted remotely with survey enumerators and Body Surface Translations Inc developers to understand challenges in beta testing, training, data acquisition and transmission. RESULTS: Manual measurements were obtained for 539 eligible children, and scan-derived measurements were successfully processed for 234 (43.4%) of them. Caregivers of at least 10.4% (56/539) of the children refused consent for scan capture; additional scans were unsuccessfully transmitted to the server. Neither the demographic characteristics of the children (age and sex), stature, nor MUAC were associated with availability of scan-derived measurements; team was significantly associated (P<.001). The average bias of scan-derived measurements in cm was -0.5 (95% CI -2.0 to 1.0) for stature and 0.7 (95% CI 0.4-1.0) for MUAC. For stature, the 95% LoA was -23.9 cm to 22.9 cm. For MUAC, the 95% LoA was -4.0 cm to 5.4 cm. All accuracy metrics varied considerably by team. The COVID-19 pandemic-related physical distancing and travel policies limited testing to validate the device algorithm and prevented developers from conducting in-person training and field oversight, negatively affecting the quality of scan capture, processing, and transmission. CONCLUSIONS: Scan-derived measurements were not sufficiently accurate for the widespread adoption of the current technology. Although the software shows promise, further investments in the software algorithms are needed to address issues with scan transmission and extreme field contexts as well as to enable improved field supervision. Differences in accuracy by team provide evidence that investment in training may also improve performance.",
      "authors": "Leidman Eva; Jatoi Muhammad Ali; Bollemeijer Iris; Majer Jennifer; Doocy Shannon",
      "year": "2022",
      "journal": "JMIR biomedical engineering",
      "doi": "10.2196/40066",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38875695/",
      "mesh_terms": "",
      "keywords": "3D imaging; accuracy; algorithm; anthropometry; arm circumference; automated; child health; child nutrition; child stature; device; height; imaging; length; mHealth; measurement; mobile health; pediatric health; software",
      "pub_types": "Journal Article",
      "pmcid": "PMC11041446"
    },
    {
      "pmid": "38872398",
      "title": "Internal validation of Automated Visual Evaluation (AVE) on smartphone images for cervical cancer screening in a prospective study in Zambia.",
      "abstract": "OBJECTIVES: Visual inspection with acetic acid (VIA) is a low-cost approach for cervical cancer screening used in most low- and middle-income countries (LMICs) but, similar to other visual tests, is subjective and requires sustained training and quality assurance. We developed, trained, and validated an artificial-intelligence-based \"Automated Visual Evaluation\" (AVE) tool that can be adapted to run on smartphones to assess smartphone-captured images of the cervix and identify precancerous lesions, helping augment VIA performance. DESIGN: Prospective study. SETTING: Eight public health facilities in Zambia. PARTICIPANTS: A total of 8204 women aged 25-55. INTERVENTIONS: Cervical images captured on commonly used low-cost smartphone models were matched with key clinical information including human immunodeficiency virus (HIV) and human papillomavirus (HPV) status, plus histopathology analysis (where applicable), to develop and train an AVE algorithm and evaluate its performance for use as a primary screen and triage test for women who are HPV positive. MAIN OUTCOME MEASURES: Area under the receiver operating curve (AUC); sensitivity; specificity. RESULTS: As a general population screening tool for cervical precancerous lesions, AVE identified cases of cervical precancerous and cancerous (CIN2+) lesions with high performance (AUC\u2009=\u20090.91, 95% confidence interval [CI]\u2009=\u20090.89-0.93), which translates to a sensitivity of 85% (95% CI\u2009=\u200981%-90%) and specificity of 86% (95% CI\u2009=\u200984%-88%) based on maximizing the Youden's index. This represents a considerable improvement over naked eye VIA, which as per a meta-analysis by the World Health Organization (WHO) has a sensitivity of 66% and specificity of 87%. For women living with HIV, the AUC of AVE was 0.91 (95% CI\u2009=\u20090.88-0.93), and among those testing positive for high-risk HPV types, the AUC was 0.87 (95% CI\u2009=\u20090.83-0.91). CONCLUSIONS: These results demonstrate the feasibility of utilizing AVE on images captured using a commonly available smartphone by nurses in a screening program, and support our ongoing efforts for moving to more broadly evaluate AVE for its clinical sensitivity, specificity, feasibility, and acceptability across a wider range of settings. Limitations of this study include potential inflation of performance estimates due to verification bias (as biopsies were only obtained from participants with visible aceto-white cervical lesions) and due to this being an internal validation (the test data, while independent from that used to develop the algorithm was drawn from the same study).",
      "authors": "Hu Liming; Mwanahamuntu Mulindi H; Sahasrabuddhe Vikrant V; Barrett Caroline; Horning Matthew P; Shah Ishan; Laverriere Zohreh; Banik Dipayan; Ji Ye; Shibemba Aaron Lunda; Chisele Samson; Munalula Mukatimui Kalima; Kaunga Friday; Musonda Francis; Malyangu Evans; Hariharan Karen Milch; Parham Groesbeck P",
      "year": "2024",
      "journal": "Cancer medicine",
      "doi": "10.1002/cam4.7355",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38872398/",
      "mesh_terms": "Humans; Female; Uterine Cervical Neoplasms; Smartphone; Zambia; Adult; Early Detection of Cancer; Prospective Studies; Middle Aged; Sensitivity and Specificity; Papillomavirus Infections; Algorithms; Uterine Cervical Dysplasia; Mass Screening; ROC Curve; Artificial Intelligence",
      "keywords": "cancer prevention; cancer risk factors; deep learning; epidemiology and prevention; gynecological oncology; machine learning; statistical methods; women's cancer",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC11176573"
    },
    {
      "pmid": "38400653",
      "title": "Handling missing data when estimating causal effects with targeted maximum likelihood estimation.",
      "abstract": "Targeted maximum likelihood estimation (TMLE) is increasingly used for doubly robust causal inference, but how missing data should be handled when using TMLE with data-adaptive approaches is unclear. Based on data (1992-1998) from the Victorian Adolescent Health Cohort Study, we conducted a simulation study to evaluate 8 missing-data methods in this context: complete-case analysis, extended TMLE incorporating an outcome-missingness model, the missing covariate missing indicator method, and 5 multiple imputation (MI) approaches using parametric or machine-learning models. We considered 6 scenarios that varied in terms of exposure/outcome generation models (presence of confounder-confounder interactions) and missingness mechanisms (whether outcome influenced missingness in other variables and presence of interaction/nonlinear terms in missingness models). Complete-case analysis and extended TMLE had small biases when outcome did not influence missingness in other variables. Parametric MI without interactions had large bias when exposure/outcome generation models included interactions. Parametric MI including interactions performed best in bias and variance reduction across all settings, except when missingness models included a nonlinear term. When choosing a method for handling missing data in the context of TMLE, researchers must consider the missingness mechanism and, for MI, compatibility with the analysis method. In many settings, a parametric MI approach that incorporates interactions and nonlinearities is expected to perform well.",
      "authors": "Dashti S Ghazaleh; Lee Katherine J; Simpson Julie A; White Ian R; Carlin John B; Moreno-Betancur Margarita",
      "year": "2024",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwae012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38400653/",
      "mesh_terms": "Humans; Likelihood Functions; Causality; Adolescent; Data Interpretation, Statistical; Bias; Models, Statistical; Computer Simulation",
      "keywords": "causal inference; missing data; multiple imputation; targeted maximum likelihood estimation",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11228874"
    },
    {
      "pmid": "39350114",
      "title": "Detection of sedentary time and bouts using consumer-grade wrist-worn devices: a hidden semi-Markov model.",
      "abstract": "BACKGROUND: Wrist-worn data from commercially available devices has potential to characterize sedentary time for research and for clinical and public health applications. We propose a model that utilizes heart rate in addition to step count data to estimate the proportion of time spent being sedentary and the usual length of sedentary bouts. METHODS: We developed and trained two Hidden semi-Markov models, STEPHEN (STEP and Heart ENcoder) and STEPCODE (STEP enCODEr; a steps-only based model) using consumer-grade Fitbit device data from participants under free living conditions, and validated model performance using two external datasets. We used the median absolute percentage error (MDAPE) to measure the accuracy of the proposed models against research-grade activPAL device data as the referent. Bland-Altman plots summarized the individual-level agreement with activPAL. RESULTS: In OPTIMISE cohort, STEPHEN's estimates of the proportion of time spent sedentary had significantly (p\u2009<\u20090.001) better accuracy (MDAPE [IQR]\u2009=\u20090.15 [0.06-0.25] vs. 0.23 [0.13-0.53)]) and agreement (Bias Mean [SD]=-0.03[0.11] vs. 0.14 [0.11]) than the proprietary software, estimated the usual sedentary bout duration more accurately (MDAPE[IQR]\u2009=\u20090.11[0.06-0.26] vs. 0.42[0.32-0.48]), and had better agreement (Bias Mean [SD]\u2009=\u20093.91[5.67] minutes vs. -11.93[5.07] minutes). With the ALLO-Active dataset, STEPHEN and STEPCODE did not improve the estimation of proportion of time spent sedentary, but STEPHEN estimated usual sedentary bout duration more accurately than the proprietary software (MDAPE[IQR]\u2009=\u20090.19[0.03-0.25] vs. 0.36[0.15-0.48]) and had smaller bias (Bias Mean[SD]\u2009=\u20090.70[8.89] minutes vs. -11.35[9.17] minutes). CONCLUSIONS: STEPHEN can characterize the proportion of time spent being sedentary and usual sedentary bout length. The methodology is available as an open access R package available from https://github.com/limfuxing/stephen/ . The package includes trained models, but users have the flexibility to train their own models.",
      "authors": "Salim Agus; Brakenridge Christian J; Lekamlage Dulari Hakamuwa; Howden Erin; Grigg Ruth; Dillon Hayley T; Bondell Howard D; Simpson Julie A; Healy Genevieve N; Owen Neville; Dunstan David W; Winkler Elisabeth A H",
      "year": "2024",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/s12874-024-02311-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39350114/",
      "mesh_terms": "Humans; Sedentary Behavior; Male; Female; Wrist; Adult; Accelerometry; Heart Rate; Wearable Electronic Devices; Exercise; Middle Aged; Fitness Trackers; Time Factors; Young Adult",
      "keywords": "Bouts; Heart rate; Machine learning; Step counts; Wearables data",
      "pub_types": "Journal Article",
      "pmcid": "PMC11440759"
    },
    {
      "pmid": "12720281",
      "title": "A redetermination of absolute values for 17RVPDB-CO2 and 17RVSMOW.",
      "abstract": "In a companion paper in this issue we presented a review of the current state of (17)O-corrections for CO(2) mass spectrometry and considered an approach (including algebraic formulae) of how to determine absolute values for (17)R(VPDB-CO2) and (17)R(VSMOW). Here we present the results of experiments conducted to determine these values. Two oxygen gases (one depleted in heavy isotopes and the other isotopically normal oxygen) were analysed to obtain the relative (17)O content. Samples of both gases were converted into CO(2), and the resulting CO(2) samples were analysed as well. Possible experimental and analytical errors are carefully considered and eliminated as far as feasible. Much attention was paid to understanding and dealing with cross-contamination effects occurring in the mass spectrometer. Based on the data obtained, the absolute values are calculated to be: (17)R(VPDB-CO2) = 0.00039511 +/- 0.00000094 and (17)R(VSMOW) = 0.00038672 +/- 0.00000087 (expanded uncertainties). Both values are on the original scale of Craig (Geochim. Cosmochim. Acta 1957; 12: 133-149) with (13)R(VPDB-CO2) = 0.0112372. A (17)O-correction algorithm incorporating the newly determined value for (17)R(VPDB-CO2) and lambda = 0.528 by Meijer and Li (Isot. Environ. Health Stud. 1998; 34: 349-369) is constructed. A computational test is performed to demonstrate the degree of delta(13)C bias relative to the previously known correction algorithms. delta(13)C values produced by the constructed algorithm are in the middle of the values produced by the other algorithms. We refrain, however, from giving any recommendation concerning which (17)O-correction algorithm to use in order to obtain delta(13)C data in the most accurate way. The present work illuminates the need to reconsider recommendations concerning the correction algorithm.",
      "authors": "Assonov Sergey S; Brenninkmeijer Carl A M",
      "year": "2003",
      "journal": "Rapid communications in mass spectrometry : RCM",
      "doi": "10.1002/rcm.1011",
      "url": "https://pubmed.ncbi.nlm.nih.gov/12720281/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40383962",
      "title": "Identifying ventricular arrhythmia and sudden cardiac arrest in clinical notes of an electronic health record database.",
      "abstract": "AIM: Validating an operational algorithm for identifying ventricular arrhythmia and sudden cardiac arrest (VA/SCA) in electronic health record (EHR) data may be useful to minimize measurement bias in studies characterizing real-world VA/SCA risk; however, validation studies require an appropriate reference standard. We aimed to assess if adequate information is documented in unstructured clinical notes of a large EHR database to serve as a reference standard for future validation studies of VA/SCA. METHODS: Twenty potential VA/SCA events were randomly selected from unstructured clinical notes of a large EHR database, TriNetX Dataworks - USA. These notes were reviewed to assess if key clinical elements were documented to confirm the occurrence of VA/SCA and describe their clinical features. These included explicit documentation of an acute event, electrocardiogram (ECG) findings, urgent medical interventions, and other elements. RESULTS: Explicit documentation of an acute event was recorded for 17 patients (85.0%) and ECG findings were documented for 15 patients (75.0%). Generally, unstructured clinical notes also contained information about signs and symptoms, care setting, medical interventions administered, and event resolution. CONCLUSIONS: The unstructured clinical notes of a large EHR database contained the information necessary to serve as a reference standard for validation studies of a VA/SCA operational algorithm in EHR data.",
      "authors": "Dhopeshwarkar Neil; Dharmani Charles; Fofah Oluwatosin; Tu Nora; Khan Nasser; Kou Tzuyung Douglas; Chan K Arnold",
      "year": "2025",
      "journal": "Future cardiology",
      "doi": "10.1080/14796678.2025.2506956",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40383962/",
      "mesh_terms": "Humans; Electronic Health Records; Death, Sudden, Cardiac; Arrhythmias, Cardiac; Male; Female; Electrocardiography; Databases, Factual; Algorithms; Middle Aged; Aged",
      "keywords": "Ventricular arrhythmia; electronic health records; sudden cardiac arrest; unstructured data; validation",
      "pub_types": "Journal Article",
      "pmcid": "PMC12150596"
    },
    {
      "pmid": "41459176",
      "title": "Tribulations, Triumphs, and Governance: Shaping the Future of Artificial Intelligence in Healthcare.",
      "abstract": "Artificial intelligence (AI) is driving a profound transformation across the healthcare landscape, with the potential to enhance diagnostic accuracy, optimize clinical decision-making, improve resource allocation, and advance personalized medicine. In public health, AI is redefining infectious disease epidemiology by enabling outbreak forecasting, genomic surveillance, and data-driven policy support, even in the presence of incomplete information. Within clinical laboratories, AI plays a pivotal and expanding role. It facilitates automation of complex workflows, supports diagnostic interpretation, and contributes to analytical performance improvements. Particularly promising is its integration into point-of-care testing, enabling decentralized diagnostics and broader access to timely care, especially in resource-constrained settings. However, these advancements are not without challenges. Concerns regarding algorithmic bias, lack of data representativeness, and risks to privacy and transparency must be carefully addressed. Moreover, the ethical and societal implications of AI are increasingly central. As emphasized by Pope Francis, while AI may accelerate access to knowledge and innovation, it also risks deepening global disparities and promoting a \"throwaway culture\" that undermines human dignity. His appeal for a \"culture of encounter\" rooted in equity, justice, and inclusion aligns with the mission of public health and laboratory medicine. This paper, based on the invited lecture delivered at the Clinical Laboratories Artificial Intelligence Revolution (CLAIR) 2025 conference, explores these themes through a critical lens. International scientific societies such as the IFCC are called to foster equitable implementation of AI by promoting access to training, infrastructure, and governance frameworks thus ensuring that AI contributes meaningfully to global health solidarity and equity.",
      "authors": "Carobene Anna",
      "year": "2025",
      "journal": "EJIFCC",
      "doi": "10.1057/s41599-024-02894-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41459176/",
      "mesh_terms": "",
      "keywords": "Artificial Intelligence; Ethics and Governance; Health Equity; Laboratory Medicine; Machine Learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC12743338"
    },
    {
      "pmid": "40460332",
      "title": "Clinical Trial Design Approach to Auditing Language Models in Health Care Setting.",
      "abstract": "PURPOSE: Rapid advancements in natural language processing have led to the development of sophisticated language models. Inspired by their success, these models are now used in health care for tasks such as clinical documentation and medical record classification. However, language models are prone to errors, which can have serious consequences in critical domains such as health care, ensuring that their reliability is essential to maintain patient safety and data integrity. METHODS: To address this, we propose an innovative auditing process based on principles from clinical trial design. Our approach involves subject matter experts (SMEs) manually reviewing pathology reports without previous knowledge of the model's classification. This single-blind setup minimizes bias and allows us to apply statistical rigor to assess model performance. RESULTS: Deployed at the British Columbia Cancer Registry, our audit process effectively identified the core issues in the operational models. Early interventions addressed these issues, maintaining data integrity and patient care standards. CONCLUSION: The audit provides real-world performance metrics and underscores the importance of human-in-the-loop machine learning. Even advanced models require SME oversight to ensure accuracy and reliability. To our knowledge, we have developed the first continuous audit process for language models in health care, modeled after clinical trial principles. This methodology ensures that audits are statistically sound and operationally feasible, setting a new standard for evaluating language models in critical applications.",
      "authors": "Gondara Lovedeep; Simkin Jonathan; Devji Shebnum",
      "year": "2025",
      "journal": "JCO clinical cancer informatics",
      "doi": "10.1200/CCI-24-00331",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40460332/",
      "mesh_terms": "Humans; Natural Language Processing; Clinical Trials as Topic; Delivery of Health Care; Research Design; Registries; Machine Learning; Reproducibility of Results",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32597863",
      "title": "Ground-level Unmanned Aerial System Imagery Coupled with Spatially Balanced Sampling and Route Optimization to Monitor Rangeland Vegetation.",
      "abstract": "Rangeland ecosystems cover 3.6 billion hectares globally with 239 million hectares located in the United States. These ecosystems are critical for maintaining global ecosystem services. Monitoring vegetation in these ecosystems is required to assess rangeland health, to gauge habitat suitability for wildlife and domestic livestock, to combat invasive weeds, and to elucidate temporal environmental changes. Although rangeland ecosystems cover vast areas, traditional monitoring techniques are often time-consuming and cost-inefficient, subject to high observer bias, and often lack adequate spatial information. Image-based vegetation monitoring is faster, produces permanent records (i.e., images), may result in reduced observer bias, and inherently includes adequate spatial information. Spatially balanced sampling designs are beneficial in monitoring natural resources. A protocol is presented for implementing a spatially balanced sampling design known as balanced acceptance sampling (BAS), with imagery acquired from ground-level cameras and unmanned aerial systems (UAS). A route optimization algorithm is used in addition to solve the 'travelling salesperson problem' (TSP) to increase time and cost efficiency. While UAS images can be acquired 2-3x faster than handheld images, both types of images are similar to each other in terms of accuracy and precision. Lastly, the pros and cons of each method are discussed and examples of potential applications for these methods in other ecosystems are provided.",
      "authors": "Curran Michael F; Hodza Paddington; Cox Samuel E; Lanning Shawn G; Robertson Blair L; Robinson Timothy J; Stahl Peter D",
      "year": "2020",
      "journal": "Journal of visualized experiments : JoVE",
      "doi": "10.3791/61052",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32597863/",
      "mesh_terms": "Aircraft; Algorithms; Animals; Animals, Wild; Conservation of Natural Resources; Ecosystem; Environmental Monitoring; Photography; Plant Physiological Phenomena; Remote Sensing Technology",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Video-Audio Media",
      "pmcid": ""
    },
    {
      "pmid": "18687759",
      "title": "Measurement characteristics of the ankle-brachial index: results from the Action for Health in Diabetes study.",
      "abstract": "Many protocols have been used in clinical and research settings for collecting systolic blood pressure (SBP) measurements to calculate the ankle-brachial index (ABI); however, it is not known how useful it is to replicate measurements and which measures best reflect cardiovascular risk. Standardized measurements of ankle and arm SBP from 5140 overweight or obese individuals with type 2 diabetes were used to estimate sources of variation. Measurement characteristics of leg-specific ABI, as calculated using a standard algorithm based on the highest SBP of the dorsalis pedis or posterior tibial arteries, were projected using simulations. Coefficients of variability ranged from 2% to 3% when single SBP measurements were used and ABI was overestimated by 2-3%. Taking two SBP measurements at each site reduced standard errors and bias each by 30-40%. The sensitivity of detecting low ABI ranges exceeded 90% for ABI within 0.05 of the 0.90 clinical cut-point. The average and the minimum of the two (i.e. right and left) leg-specific ABI values had similar U-shaped relationships with Framingham risk scores; however, the average leg ABI had slightly greater precision. Replicating SBP measurements reduces the error and bias of ABI. Averaging leg-specific values may increase power for characterizing cardiovascular disease risk.",
      "authors": "Espeland Mark A; Regensteiner Judith G; Jaramillo Sarah A; Gregg Edward; Knowler William C; Wagenknecht Lynne E; Bahnson Judy; Haffner Steven; Hill James; Hiatt William R",
      "year": "2008",
      "journal": "Vascular medicine (London, England)",
      "doi": "10.1177/1358863X08091338",
      "url": "https://pubmed.ncbi.nlm.nih.gov/18687759/",
      "mesh_terms": "Aged; Algorithms; Ankle Joint; Blood Pressure; Brachial Artery; Cohort Studies; Diabetes Mellitus, Type 2; Female; Humans; Male; Middle Aged; Obesity; Peripheral Vascular Diseases; Risk Factors; Sensitivity and Specificity",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, N.I.H., Intramural; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC2713116"
    },
    {
      "pmid": "39677484",
      "title": "Longitudinal Digital Phenotyping of Multiple Sclerosis Severity Using Passively Sensed Behaviors and Ecological Momentary Assessments.",
      "abstract": "BACKGROUND: Longitudinal tracking of multiple sclerosis (MS) symptoms in an individual's own environment may improve self-monitoring and clinical management for people with MS (pwMS). OBJECTIVE: We present a machine learning approach that enables longitudinal monitoring of clinically relevant patient-reported symptoms for pwMS by harnessing passively collected data from sensors in smartphones and fitness trackers. METHODS: We divide the collected data into discrete periods for each patient. For each prediction period, we first extract patient-level behavioral features from the current period (action features) and the previous period (context features). Then, we apply a machine learning (ML) approach based on Support Vector Machine with Radial Bias Function Kernel and AdaBoost to predict the presence of depressive symptoms (every two weeks) and high global MS symptom burden, severe fatigue, and poor sleep quality (every four weeks). RESULTS: Between November 16, 2019, and January 24, 2021, 104 pwMS (84.6% women, 93.3% non-Hispanic White, 44.0\u00b111.8 years mean\u00b1SD age) from a clinic-based MS cohort completed 12-weeks of data collection, including a subset of 44 pwMS (88.6% women, 95.5% non-Hispanic White, 45.7\u00b111.2 years) who completed 24-weeks of data collection. In total, we collected approximately 12,500 days of passive sensor and behavioral health data from the participants. Among the best-performing models with the least sensor data requirement, ML algorithm predicts depressive symptoms with an accuracy of 80.6% (35.5% improvement over baseline; F1-score: 0.76), high global MS symptom burden with an accuracy of 77.3% (51.3% improvement over baseline; F1-score: 0.77), severe fatigue with an accuracy of 73.8% (45.0% improvement over baseline; F1-score: 0.74), and poor sleep quality with an accuracy of 72.0% (28.1% improvement over baseline; F1-score: 0.70). Further, sensor data were largely sufficient for predicting symptom severity, while the prediction of depressive symptoms benefited from minimal active patient input in the form of response to two brief questions on the day before the prediction point. CONCLUSIONS: Our digital phenotyping approach using passive sensors on smartphones and fitness trackers may help patients with real-world, continuous, self-monitoring of common symptoms in their own environment and assist clinicians with better triage of patient needs for timely interventions in MS (and potentially other chronic neurological disorders).",
      "authors": "Xia Zongqi; Chikersal Prerna; Venkatesh Shruthi; Walker Elizabeth; Dey Anind; Goel Mayank",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.11.02.24316647",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39677484/",
      "mesh_terms": "",
      "keywords": "Digital phenotyping; depression; disability; ecological momentary assessments; fatigue; machine learning; mobile sensing; multiple sclerosis; sleep; wearable",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC11643184"
    },
    {
      "pmid": "31769528",
      "title": "Estimating the intervention effect in calibration substudies.",
      "abstract": "Exposure assessment is often subject to measurement errors. We consider here the analysis of studies aimed at reducing exposure to potential health hazards, in which exposure is the outcome variable. In these studies, the intervention effect may be estimated using either biomarkers or self-report data, but it is not common to combine these measures of exposure. Bias in the self-reported measures of exposure is a well-known fact; however, only few studies attempt to correct it. Recently, Keogh et al addressed this problem, presenting a model for measurement error in this setting and investigating how self-report and biomarker data can be combined. Keogh et al find the maximum likelihood estimate for the intervention effect in their model via direct numerical maximization of the likelihood. Here, we exploit an alternative presentation of the model that leads us to a closed formula for the MLE and also for its variance, when the number of biomarker replicates is the same for all subjects in the substudy. The variance formula enables efficient design of such intervention studies. When the number of biomarker replicates is not constant, our approach can be used along with the EM-algorithm to quickly compute the MLE. We compare the MLE to Buonaccorsi's method (Buonaccorsi, 1996) and find that they have similar efficiency when most subjects have biomarker data, but that the MLE has clear advantages when only a small fraction of subjects has biomarker data. This conclusion extends the findings of Keogh et al (2016) and has practical importance for efficiently designing studies.",
      "authors": "Talitman Michal; Gorfine Malka; Steinberg David M",
      "year": "2020",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.8394",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31769528/",
      "mesh_terms": "Biomarkers; Calibration; Computer Simulation; Environmental Exposure; Humans; Likelihood Functions; Risk Assessment",
      "keywords": "EM algorithm; intervention effect; measurement error; self-report data",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37689132",
      "title": "Raman imaging to identify microplastics released from toothbrushes: algorithms and particle analysis.",
      "abstract": "Microplastics are small plastic fragments that are of increasing concern due to their potential impacts on the environment and human health. The source of microplastics is not completely clear and might originate in daily lives such as from toothbrushes. When toothbrushes are used to clean teeth, small plastic debris and fragments can be potentially released into mouths directly or environment indirectly. This study aims to examine the release of microplastics from toothbrushes, using Raman imaging to identify and visualise the plastic debris with an increased signal-noise ratio via hyper-spectrum analysis. Using algorithms to convert the hyper-spectrum to an image, the plastic can be distinguished from the co-formulated titanium oxide particles that are not uniformly distributed along the plastics. The non-uniform distribution can lead to the bias results if a single spectrum analysis is conducted at one position rather than imaging analysis to scan an area. The potential false image originating from the off-focal position for the confocal Raman is overcome using the terrain map to guide the Raman imaging. The imaging analysis balancing between the low magnification to capture the overview and the high magnification to test the details is also discussed. While the release amount of microplastics from the toothbrush is estimated at thousands daily with the expected variation, the results of this study have confirmed the release of microplastics in daily lives. The imaging analysis approach along with algorithm can help to identify the chemical elements of microplastics from the complex background, which can benefit the further research on microplastics towards risk assessment and remediation.",
      "authors": "Fang Cheng; Gopalan Saianand; Zhang Xian; Xu Lei; Niu Junfeng; Naidu Ravi",
      "year": "2023",
      "journal": "Environmental pollution (Barking, Essex : 1987)",
      "doi": "10.1016/j.envpol.2023.122510",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37689132/",
      "mesh_terms": "Humans; Microplastics; Plastics; Water Pollutants, Chemical; Environmental Monitoring; Algorithms; Spectrum Analysis, Raman",
      "keywords": "Algorithm; Microplastic; Particle analysis; Raman imaging; SEM; Toothbrush",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33092203",
      "title": "Clustering on Human Microbiome Sequencing Data: A Distance-Based Unsupervised Learning Model.",
      "abstract": "Modeling and analyzing human microbiome allows the assessment of the microbial community and its impacts on human health. Microbiome composition can be quantified using 16S rRNA technology into sequencing data, which are usually skewed and heavy-tailed with excess zeros. Clustering methods are useful in personalized medicine by identifying subgroups for patients stratification. However, there is currently a lack of standardized clustering method for the complex microbiome sequencing data. We propose a clustering algorithm with a specific beta diversity measure that can address the presence-absence bias encountered for sparse count data and effectively measure the sample distances for sample stratification. Our distance measure used for clustering is derived from a parametric based mixture model producing sample-specific distributions conditional on the observed operational taxonomic unit (OTU) counts and estimated mixture weights. The method can provide accurate estimates of the true zero proportions and thus construct a precise beta diversity measure. Extensive simulation studies have been conducted and suggest that the proposed method achieves substantial clustering improvement compared with some widely used distance measures when a large proportion of zeros is presented. The proposed algorithm was implemented to a human gut microbiome study on Parkinson's diseases to identify distinct microbiome states with biological interpretations.",
      "authors": "Yang Dongyang; Xu Wei",
      "year": "2020",
      "journal": "Microorganisms",
      "doi": "10.3390/microorganisms8101612",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33092203/",
      "mesh_terms": "",
      "keywords": "clustering; high-dimension; microbiome; unsupervised learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC7589204"
    },
    {
      "pmid": "41282085",
      "title": "A qualitative Interview Study Investigating Patient, Health Professional, and Developer Perspectives on Real-World Implementation of Patient-Centered AI Systems.",
      "abstract": "Our objective was to triangulate patient, health professional, and developer perspectives for implementing patient-centered artificial intelligence (AI) systems. We conducted semi-structured interviews with patients (N = 18), health professionals (N = 8), and AI developers (N = 8). We created interview guides informed by frameworks in bioethics and health information informatics. We utilized a predictive algorithm for determining risk for postpartum depression as a use case to concretize our discussions. Our team analyzed transcripts from interview recordings using thematic, directed content analysis and the constant comparative process. Participants found mitigating potential harms caused by AI (e.g., bias, stigma, or patient anxiety) greatly important. They also believed that AI must provide clinical benefits by allowing health professionals and patients to easily take actions based on AI output. To take safe action, end users needed transparency to understand the AI's accuracy and predictors driving risk. Patient participants wanted health professionals to interpret AI output, but health professionals did not always feel they had the time or training to do so. Participants also raised concerns regarding how data quality may affect AI accuracy, who may be responsible for inappropriate actions taken based on AI, and issues regarding data security, privacy, and accessibility. Our results support real-world implementation of more patient-centered AI tools by: providing health professionals with competencies for discussing AI-based risks; engaging patients and health professionals throughout the development process; inclusively communicating AI output to health professionals and patients; and implementing multi-layer systems of AI governance.",
      "authors": "Benda Natalie; Desai Pooja; Reza Zayan; Winogora Victoria; Suresh Uday; Zhang Yiye; Hermann Alison; Joly Rochelle; Pathak Jyotishman; Turchioe Meghan Reading",
      "year": "2025",
      "journal": "Research square",
      "doi": "10.21203/rs.3.rs-7908218/v1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41282085/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; bioethics; patient-centered care; predictive algorithms",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12637806"
    },
    {
      "pmid": "41225988",
      "title": "Machine Learning-Based Prediction of Three-Year Heart Failure and Mortality After Premature Ventricular Contraction Ablation.",
      "abstract": "Introduction: Long-term heart failure and mortality after catheter ablation for premature ventricular contraction (PVC) remain underexplored. Methods: We retrospectively analyzed 4195 adults who underwent PVC ablation in a nationwide claims database. To address class imbalance, we used synthetic minority over-sampling technique (SMOTE) and random over-sampling examples (ROSE). Five supervised algorithms were compared: logistic regression, decision tree, random forest, XGBoost, and LightGBM. Discrimination was assessed by stratified five-fold cross-validation using the area under the receiver operating characteristic curve (ROC AUC). Because rare events can bias ROC, we also examined precision-recall (PR) curves. Results: For predicting three-year heart failure, LightGBM with ROSE achieved the highest ROC AUC at 0.822. For three-year mortality, logistic regression with ROSE and LightGBM with ROSE showed balanced performance with ROC AUCs of 0.886 and 0.882. Pairwise DeLong tests indicated that these leading models formed a high-performing cluster without significant differences in ROC AUC. Age, prior heart failure, malignancy, and end-stage renal disease were the most influential predictors by model explainability analysis. Discussion: Addressing class imbalance and benchmarking modern learners against a transparent logistic baseline yielded robust, clinically interpretable risk stratification after PVC ablation. These models are suitable for integration into electronic health record dashboards, with external validation and local threshold optimization as next steps.",
      "authors": "Lin Chung-Yu; Lai Yu-Te; Chuang Chien-Wei; Yu Chih-Hsien; Lo Chiung-Yun; Chen Mingchih; Shia Ben-Chang",
      "year": "2025",
      "journal": "Diagnostics (Basel, Switzerland)",
      "doi": "10.3390/diagnostics15212693",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41225988/",
      "mesh_terms": "",
      "keywords": "PVC; artificial intelligence; catheter ablation surgery; good health and well-being; heart failure; machine learning; risk factor",
      "pub_types": "Journal Article",
      "pmcid": "PMC12607369"
    },
    {
      "pmid": "36711695",
      "title": "Comparing risk prediction models aimed at predicting hospitalizations for adverse drug events in community dwelling older adults: a protocol paper.",
      "abstract": "BACKGROUND: The objective of this paper is to describe the creation, validation, and comparison of two risk prediction modeling approaches for community-dwelling older adults to identify individuals at highest risk for adverse drug event-related hospitalizations. One approach will use traditional statistical methods, the second will use a machine learning approach. METHODS: We will construct medication, clinical, health care utilization, and other variables known to be associated with adverse drug event-related hospitalizations. To create the cohort, we will include older adults (\u2265 65 years of age) empaneled to a primary care physician within the Cedars-Sinai Health System primary care clinics with polypharmacy (\u2265 5 medications) or at least 1 medication commonly implicated in ADEs (certain oral hypoglycemics, anti-coagulants, anti-platelets, and insulins). We will use a Fine-Gray Cox proportional hazards model for one risk modeling approach and DataRobot, a data science and analytics platform, to run and compare several widely used supervised machine learning algorithms, including Random Forest, Support Vector Machine, Extreme Gradient Boosting (XGBoost), Decision Tree, Na\u00efve Bayes, and K-Nearest Neighbors. We will use a variety of metrics to compare model performance and to assess the risk of algorithmic bias. DISCUSSION: In conclusion, we hope to develop a pragmatic model that can be implemented in the primary care setting to risk stratify older adults to further optimize medication management.",
      "authors": "Keller Michelle S; Qureshi Nabeel; Albertson Elaine; Pevnick Joshua; Brandt Nicole; Bui Alex; Sarkisian Catherine A",
      "year": "2023",
      "journal": "Research square",
      "doi": "10.21203/rs.3.rs-2429369/v1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36711695/",
      "mesh_terms": "",
      "keywords": "Drug adverse events; medications; older adults; polypharmacy; primary care",
      "pub_types": "Preprint; Journal Article",
      "pmcid": "PMC9882666"
    },
    {
      "pmid": "29862536",
      "title": "Comparing methods for estimation of heterogeneous treatment effects using observational data from health care databases.",
      "abstract": "There is growing interest in using routinely collected data from health care databases to study the safety and effectiveness of therapies in \"real-world\" conditions, as it can provide complementary evidence to that of randomized controlled trials. Causal inference from health care databases is challenging because the data are typically noisy, high dimensional, and most importantly, observational. It requires methods that can estimate heterogeneous treatment effects while controlling for confounding in high dimensions. Bayesian additive regression trees, causal forests, causal boosting, and causal multivariate adaptive regression splines are off-the-shelf methods that have shown good performance for estimation of heterogeneous treatment effects in observational studies of continuous outcomes. However, it is not clear how these methods would perform in health care database studies where outcomes are often binary and rare and data structures are complex. In this study, we evaluate these methods in simulation studies that recapitulate key characteristics of comparative effectiveness studies. We focus on the conditional average effect of a binary treatment on a binary outcome using the conditional risk difference as an estimand. To emulate health care database studies, we propose a simulation design where real covariate and treatment assignment data are used and only outcomes are simulated based on nonparametric models of the real outcomes. We apply this design to 4 published observational studies that used records from 2 major health care databases in the United States. Our results suggest that Bayesian additive regression trees and causal boosting consistently provide low bias in conditional risk difference estimates in the context of health care database studies.",
      "authors": "Wendling T; Jung K; Callahan A; Schuler A; Shah N H; Gallego B",
      "year": "2018",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.7820",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29862536/",
      "mesh_terms": "Bayes Theorem; Biostatistics; Causality; Computer Simulation; Databases, Factual; Humans; Machine Learning; Models, Statistical; Observational Studies as Topic; Outcome Assessment, Health Care; Propensity Score; Regression Analysis; Statistics, Nonparametric; Treatment Outcome",
      "keywords": "health care databases; heterogeneous treatment effects; machine learning; propensity score; simulation",
      "pub_types": "Comparative Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41364792",
      "title": "Adoption of Machine Learning in US Hospital Electronic Health Record Systems: Retrospective Observational Study.",
      "abstract": "BACKGROUND: While machine learning (ML) technologies have shifted from development to real-world deployment over the past decade, US health care providers and hospital administrators have increasingly embraced ML, particularly through its integration with electronic health record (EHR) systems. This evolving landscape underscores the need for empirical evidence on ML adoption and its determinants; however, the relationship between hospital characteristics and ML integration within EHR systems remains insufficiently explored. OBJECTIVE: This study aimed to examine the current state of ML adoption within EHR systems across US general acute care hospitals and to identify hospital characteristics associated with ML implementation. METHODS: We used linked data between the 2022-2023 American Hospital Association Annual Survey and the 2023-2024 American Hospital Association Information Technology Supplement Survey. The sample includes 2562 general and acute care hospitals in the United States with a total of 4055 observations over 2 years. Applying inverse probability weighting to address nonresponse bias, we used descriptive statistics to assess ML adoption patterns and multivariate logistic regression models to identify hospital characteristics associated with ML adoption. RESULTS: Overall, about 75% of the hospitals had adopted ML functions within their EHR systems in 2023-2024, and the majority tended to adopt both clinical and operational ML functions simultaneously. The most commonly adopted individual functions were predicting inpatient risks and outpatient follow-ups. ML model evaluation practices, while still limited overall, showed notable improvement. Multivariate regression estimates indicate that hospitals were more likely to adopt any ML if they were not-for-profit (4.4 percentage points, 95% CI 0.6-8.2; P=.02), large hospitals (15 percentage points, 95% CI 9.4-21; P<.001), operated in metropolitan areas (4.3 percentage points, 95% CI 0.8-7.8; P=.02), contracted with leading EHR vendors (20.6 percentage points, 95% CI 17.1-24; P<.001), and affiliated with a health system (26.8 percentage points, 95% CI 22.4-31.3; P<.001). Similar patterns were observed for predicting the adoption of both clinical and operative ML. We also identified specific hospital characteristics associated with the adoption of individual ML functions. CONCLUSIONS: ML adoption in hospitals is influenced by organizational resources and strategic priorities, raising concerns about potential digital inequities. Limited quality control and evaluation practices highlight the need for stronger regulatory oversight and targeted support for underresourced hospitals. As the integration of ML into EHR systems expands, disparities in both adoption and oversight become increasingly critical. To ensure the equitable, safe, and effective implementation of ML technologies in health care, well-designed policies must address these gaps and promote inclusive innovation across all hospital settings.",
      "authors": "Huang Huang; Lyu Wei; Hasan Md Mahmud; Houser Shannon H",
      "year": "2025",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/76126",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41364792/",
      "mesh_terms": "Machine Learning; Electronic Health Records; United States; Retrospective Studies; Humans; Hospitals",
      "keywords": "artificial intelligence; electronic health record; health information technology adoption; machine learning; organizational behavior",
      "pub_types": "Journal Article; Observational Study",
      "pmcid": "PMC12688049"
    },
    {
      "pmid": "36767778",
      "title": "Application of a Machine Learning Method for Prediction of Urban Neighborhood-Scale Air Pollution.",
      "abstract": "Urban air pollution has aroused growing attention due to its associated adverse health effects. A model which could promptly predict urban air quality with considerable accuracy is, therefore, important and will benefit the development of smart cities. However, only a computational fluid dynamics (CFD) model could better resolve the dispersion behavior within an urban canyon layer. A machine learning (ML) model using the Artificial Neural Network (ANN) approach was formulated in the current study to investigate vehicle-derived airborne particulate (PM10) dispersion within a compact high-rise-built environment. Various measured meteorological parameters and PM10 concentrations were adopted as the model inputs to train the ANN model. A building-resolved CFD model under the same environmental settings was also set up to compare its model performance with the ANN model. Our results showed that the ANN model exhibited promising performance (r = 0.82, fractional bias = 0.002) when comparing the > 1000 h PM10 measurements. When comparing the diurnal hourly measured PM10 variations in a clear-sky day, both the ANN and CFD models performed well (r > 0.8). The good performance of the CFD model relied on the knowledge of the in situ diurnal traffic profile, the adoption of suitable mobile source emission factor(s) (e.g., from MOBILE 6 and COPERT4), and the use of urban thermal and dynamical variables to capture PM10 variations in both neutral and unstable atmospheric conditions. These requirements/constraints make it impractical for daily operation. On the contrary, the ML (ANN) model adopted here is free from these constraints and is fast (less than 0.1% computational time relative to the CFD model). These results demonstrate that the ANN model is a superior option for a smart city application.",
      "authors": "Wai Ka-Ming; Yu Peter K N",
      "year": "2023",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph20032412",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36767778/",
      "mesh_terms": "Air Pollutants; Particulate Matter; Environmental Monitoring; Models, Theoretical; Air Pollution; Cities",
      "keywords": "ENVI-met model; air quality model; machine learning; smart city; urban environment",
      "pub_types": "Journal Article",
      "pmcid": "PMC9915966"
    },
    {
      "pmid": "26980459",
      "title": "Sequential BART for imputation of missing covariates.",
      "abstract": "To conduct comparative effectiveness research using electronic health records (EHR), many covariates are typically needed to adjust for selection and confounding biases. Unfortunately, it is typical to have missingness in these covariates. Just using cases with complete covariates will result in considerable efficiency losses and likely bias. Here, we consider the covariates missing at random with missing data mechanism either depending on the response or not. Standard methods for multiple imputation can either fail to capture nonlinear relationships or suffer from the incompatibility and uncongeniality issues. We explore a flexible Bayesian nonparametric approach to impute the missing covariates, which involves factoring the joint distribution of the covariates with missingness into a set of sequential conditionals and applying Bayesian additive regression trees to model each of these univariate conditionals. Using data augmentation, the posterior for each conditional can be sampled simultaneously. We provide details on the computational algorithm and make comparisons to other methods, including parametric sequential imputation and two versions of multiple imputation by chained equations. We illustrate the proposed approach on EHR data from an affiliated tertiary care institution to examine factors related to hyperglycemia.",
      "authors": "Xu Dandan; Daniels Michael J; Winterstein Almut G",
      "year": "2016",
      "journal": "Biostatistics (Oxford, England)",
      "doi": "10.1093/biostatistics/kxw009",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26980459/",
      "mesh_terms": "Bayes Theorem; Data Interpretation, Statistical; Electronic Health Records; Humans; Models, Statistical; Regression Analysis",
      "keywords": "Bayesian additive regression trees; Congenial models; Multiple imputation",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC4915613"
    },
    {
      "pmid": "40292768",
      "title": "Detection and Severity Classification of Sleep Apnea Using Continuous Wearable SpO2 Signals: A Multi-Scale Feature Approach.",
      "abstract": "The use of wearable devices for sleep apnea detection is growing, but their limited signal resolution poses challenges for accurate diagnosis. This study explores the feasibility of using SpO2 signals from wearable sensors for detecting sleep apnea and classifying its severity. We propose a novel multi-scale feature engineering approach, which extracts features from coarsely grained SpO2 signals across timescales ranging from 1 s to 600 s. Our results show that traditional SpO2 markers, such as the oxygen desaturation index (ODI) and Lempel-Zip complexity, lose their relevance with the Apnea-Hypopnea Index (AHI) at longer timescales. In contrast, non-linear features like complex entropy, sample entropy, and fuzzy entropy maintain strong correlations with AHI, even at the coarsest timescales (up to 600 s), making them well suited for low-resolution data. Multi-scale feature extraction improves model performance across various machine learning algorithms by alleviating model bias, particularly with the Bayes and CatBoost models. These findings highlight the potential of multi-scale feature engineering for wearable device applications where only low-resolution data are commonly available. This could improve accessibility to low-cost, at-home sleep apnea screening, reducing reliance on expensive and labor-intensive polysomnography. Moreover, it would allow even healthy individuals to proactively monitor their sleep health at home, facilitating the early identification of potential sleep problems.",
      "authors": "Hoang Nhung H; Liang Zilu",
      "year": "2025",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s25061698",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40292768/",
      "mesh_terms": "Wearable Electronic Devices; Humans; Sleep Apnea Syndromes; Algorithms; Polysomnography; Machine Learning; Signal Processing, Computer-Assisted; Oxygen Saturation; Male; Oximetry; Female",
      "keywords": "SpO2; feature engineering; machine learning; sleep apnea; wearable",
      "pub_types": "Journal Article",
      "pmcid": "PMC11944722"
    },
    {
      "pmid": "39078410",
      "title": "The circadian rhythm: A key variable in aging?",
      "abstract": "The determination of age-related transcriptional changes may contribute to the understanding of health and life expectancy. The broad application of results from age cohorts may have limitations. Altering sample sizes per time point or sex, using a single mouse strain or tissue, a limited number of replicates, or omitting the middle of life can bias the surveys. To achieve higher general validity and to identify less distinctive players, bulk RNA sequencing of a mouse cohort, including seven organs of two strains from both sexes of 5 ages, was performed. Machine learning by bootstrapped variable importance and selection methodology (Boruta) was used to identify common aging features where the circadian rhythms (CiR) transcripts appear as promising age markers in an unsupervised analysis. Pathways of 11 numerically analyzed local network clusters were affected and classified into four major gene expression profiles, whereby CiR and proteostasis candidates were particularly conspicuous with partially opposing changes. In a data-based interaction association network, the CiR-proteostasis axis occupies an exposed central position, highlighting its relevance. The computation of 11,830 individual transcript associations provides potential superordinate contributors, such as hormones, to age-related changes, as in CiR. In hormone-sensitive LNCaP cells, short-term supraphysiologic levels of the sex hormones dihydrotestosterone or estradiol increase the expression of the CiR transcript Bhlhe40 and the associated senescence regulator Cdkn2b (p15). According to these findings, the bilateral dysregulation of CiR appears as a fundamental protagonist of aging, whose transcripts could serve as a biological marker and its restoration as a therapeutic opportunity.",
      "authors": "Winterhalter Patrick R; Georgevici Adrian-Iustin; Gharpure Nitin J; Szab\u00f3 G\u00e1bor; Simm Andreas",
      "year": "2024",
      "journal": "Aging cell",
      "doi": "10.1111/acel.14268",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39078410/",
      "mesh_terms": "Aging; Animals; Circadian Rhythm; Mice; Male; Female; Humans; Mice, Inbred C57BL",
      "keywords": "Bhlhe40 (Dec1); aging hallmarks; circadian rhythms; interaction network; machine learning; mouse cohort; organ strain sex; sex hormones",
      "pub_types": "Journal Article",
      "pmcid": "PMC11561671"
    },
    {
      "pmid": "32993005",
      "title": "Exploring U.S. Shifts in Anti-Asian Sentiment with the Emergence of COVID-19.",
      "abstract": "Background: Anecdotal reports suggest a rise in anti-Asian racial attitudes and discrimination in response to COVID-19. Racism can have significant social, economic, and health impacts, but there has been little systematic investigation of increases in anti-Asian prejudice. Methods: We utilized Twitter's Streaming Application Programming Interface (API) to collect 3,377,295 U.S. race-related tweets from November 2019-June 2020. Sentiment analysis was performed using support vector machine (SVM), a supervised machine learning model. Accuracy for identifying negative sentiments, comparing the machine learning model to manually labeled tweets was 91%. We investigated changes in racial sentiment before and following the emergence of COVID-19. Results: The proportion of negative tweets referencing Asians increased by 68.4% (from 9.79% in November to 16.49% in March). In contrast, the proportion of negative tweets referencing other racial/ethnic minorities (Blacks and Latinx) remained relatively stable during this time period, declining less than 1% for tweets referencing Blacks and increasing by 2% for tweets referencing Latinx. Common themes that emerged during the content analysis of a random subsample of 3300 tweets included: racism and blame (20%), anti-racism (20%), and daily life impact (27%). Conclusion: Social media data can be used to provide timely information to investigate shifts in area-level racial sentiment.",
      "authors": "Nguyen Thu T; Criss Shaniece; Dwivedi Pallavi; Huang Dina; Keralis Jessica; Hsu Erica; Phan Lynn; Nguyen Leah H; Yardi Isha; Glymour M Maria; Allen Amani M; Chae David H; Gee Gilbert C; Nguyen Quynh C",
      "year": "2020",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph17197032",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32993005/",
      "mesh_terms": "Asian People; Betacoronavirus; COVID-19; Coronavirus Infections; Health Knowledge, Attitudes, Practice; Humans; Pandemics; Pneumonia, Viral; Racism; SARS-CoV-2; Social Media; Supervised Machine Learning; Support Vector Machine; United States",
      "keywords": "big data; content analysis; minority groups; racial bias; social media",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC7579565"
    },
    {
      "pmid": "41213532",
      "title": "[AI Application in Nephrological Diagnostics].",
      "abstract": "Artificial intelligence (AI) is rapidly reshaping medical diagnostics, and nephrology - characterized by multifactorial disease patterns - stands to benefit markedly. Machine\u2011learning and deep\u2011learning algorithms, especially convolutional neural networks (CNNs) and large language models (LLMs), can analyze heterogeneous data streams from electronic health records, imaging, histopathology and genomics to support diagnosis, prognosis and therapeutic planning. AI\u2011driven automation of routine workflows (e.g., appointment scheduling, NLP\u2011based documentation, chatbot\u2011guided anamneses) enables clinicians to focus on complex decision\u2011making, while real\u2011time decision\u2011support tools can integrate laboratory, imaging and guideline data. Recent advances include CNN\u2011based detection of renal lesions, deep\u2011learning prognostic scores for IgA nephropathy, and AI\u2011enhanced variant calling (e.g., DeepVariant). Nevertheless, challenges persist: data bias, limited external validation, \"hallucinations\" of LLMs, regulatory compliance (MDR, GDPR), and the need for transparent, locally hosted models. Successful implementation requires interoperable, FHIR\u2011compatible data, robust training of staff, and integration of AI education into medical education. With this, AI promises substantial efficiency gains, improved diagnostic precision, and sustained care quality in nephrology.",
      "authors": "Hohenstein Bernd; Binder Tim; Kramann Rafael",
      "year": "2025",
      "journal": "Deutsche medizinische Wochenschrift (1946)",
      "doi": "10.1055/a-2595-7238",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41213532/",
      "mesh_terms": "Humans; Artificial Intelligence; Kidney Diseases; Machine Learning; Nephrology; Neural Networks, Computer",
      "keywords": "",
      "pub_types": "English Abstract; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "29743531",
      "title": "Identifying Suicide Ideation and Suicidal Attempts in a Psychiatric Clinical Research Database using Natural Language Processing.",
      "abstract": "Research into suicide prevention has been hampered by methodological limitations such as low sample size and recall bias. Recently, Natural Language Processing (NLP) strategies have been used with Electronic Health Records to increase information extraction from free text notes as well as structured fields concerning suicidality and this allows access to much larger cohorts than previously possible. This paper presents two novel NLP approaches - a rule-based approach to classify the presence of suicide ideation and a hybrid machine learning and rule-based approach to identify suicide attempts in a psychiatric clinical database. Good performance of the two classifiers in the evaluation study suggest they can be used to accurately detect mentions of suicide ideation and attempt within free-text documents in this psychiatric database. The novelty of the two approaches lies in the malleability of each classifier if a need to refine performance, or meet alternate classification requirements arises. The algorithms can also be adapted to fit infrastructures of other clinical datasets given sufficient clinical recording practice knowledge, without dependency on medical codes or additional data extraction of known risk factors to predict suicidal behaviour.",
      "authors": "Fernandes Andrea C; Dutta Rina; Velupillai Sumithra; Sanyal Jyoti; Stewart Robert; Chandran David",
      "year": "2018",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-018-25773-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29743531/",
      "mesh_terms": "Data Mining; Databases, Factual; Humans; Natural Language Processing; Suicidal Ideation; Suicide, Attempted",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC5943451"
    },
    {
      "pmid": "36263918",
      "title": "Flexible propensity score estimation strategies for clustered data in observational studies.",
      "abstract": "Existing studies have suggested superior performance of nonparametric machine learning over logistic regression for propensity score estimation. However, it is unclear whether the advantages of nonparametric propensity score modeling are carried to settings where there is clustering of individuals, especially when there is unmeasured cluster-level confounding. In this work we examined the performance of logistic regression (all main effects), Bayesian additive regression trees and generalized boosted modeling for propensity score weighting in clustered settings, with the clustering being accounted for by including either cluster indicators or random intercepts. We simulated data for three hypothetical observational studies of varying sample and cluster sizes. Confounders were generated at both levels, including a cluster-level confounder that is unobserved in the analyses. A binary treatment and a continuous outcome were generated based on seven scenarios with varying relationships between the treatment and confounders (linear and additive, nonlinear/nonadditive, nonadditive with the unobserved cluster-level confounder). Results suggest that when the sample and cluster sizes are large, nonparametric propensity score estimation may provide better covariate balance, bias reduction, and 95% confidence interval coverage, regardless of the degree of nonlinearity or nonadditivity in the true propensity score model. When the sample or cluster sizes are small, however, nonparametric approaches may become more vulnerable to unmeasured cluster-level confounding and thus may not be a better alternative to multilevel logistic regression. We applied the methods to the National Longitudinal Study of Adolescent to Adult Health data, estimating the effect of team sports participation during adolescence on adulthood depressive symptoms.",
      "authors": "Chang Ting-Hsuan; Nguyen Trang Quynh; Lee Youjin; Jackson John W; Stuart Elizabeth A",
      "year": "2022",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.9551",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36263918/",
      "mesh_terms": "Humans; Adolescent; Adult; Propensity Score; Confounding Factors, Epidemiologic; Bayes Theorem; Longitudinal Studies; Logistic Models; Bias",
      "keywords": "clustering; machine learning; observational studies; propensity score weighting; unmeasured confounder",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9996644"
    },
    {
      "pmid": "41237026",
      "title": "Generative Neural Networks for Data Imputation in Longitudinal Epidemiological Studies.",
      "abstract": "Longitudinal epidemiological studies often face challenges with incomplete follow-up and missing data, which can bias results and reduce statistical power. Conventional imputation methods may not adequately capture the complex patterns and dependencies in such multivariate time series data. While more recently developed generative machine learning models offer improved solutions, few methods are available which can handle inconsistently spaced intervals between measurements across long time periods and completely missing time steps, characteristics which are common in real-world studies evaluating long-term health outcomes. This paper introduces a variational autoencoder-based generative neural network designed for imputing partially and fully missing information in irregular time series with extensive missingness. Our approach exploits both correlations between features at a single time step and trends of the same feature over time to reconstruct missing values. Experiments on synthetic data designed to resemble the characteristics of longitudinal epidemiological studies and a case study on a real-world dataset demonstrate the effectiveness of our approach. We show superior performance and parameter stability across varying degrees of missingness and missingness patterns compared to prior work.",
      "authors": "Killing Christoph; Elsbernd Kira; Wekerle Maximilian; Hoelscher Michael; Rachow Andrea; Castelletti Noemi",
      "year": "2026",
      "journal": "IEEE journal of biomedical and health informatics",
      "doi": "10.1109/JBHI.2025.3632647",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41237026/",
      "mesh_terms": "Humans; Neural Networks, Computer; Longitudinal Studies; Epidemiologic Studies; Machine Learning; Algorithms",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39013794",
      "title": "Invited commentary: deep learning-methods to amplify epidemiologic data collection and analyses.",
      "abstract": "Deep learning is a subfield of artificial intelligence and machine learning, based mostly on neural networks and often combined with attention algorithms, that has been used to detect and identify objects in text, audio, images, and video. Serghiou and Rough (Am J Epidemiol. 2023;192(11):1904-1916) presented a primer for epidemiologists on deep learning models. These models provide substantial opportunities for epidemiologists to expand and amplify their research in both data collection and analyses by increasing the geographic reach of studies, including more research subjects, and working with large or high-dimensional data. The tools for implementing deep learning methods are not as straightforward or ubiquitous for epidemiologists as traditional regression methods found in standard statistical software, but there are exciting opportunities for interdisciplinary collaboration with deep learning experts, just as epidemiologists have with statisticians, health care providers, urban planners, and other professionals. Despite the novelty of these methods, epidemiologic principles of assessing bias, study design, interpretation, and others still apply when implementing deep learning methods or assessing the findings of studies that have used them.",
      "authors": "Quistberg D Alex; Mooney Stephen J; Tasdizen Tolga; Arbelaez Pablo; Nguyen Quynh C",
      "year": "2025",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwae215",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39013794/",
      "mesh_terms": "Deep Learning; Humans; Data Collection; Epidemiologic Methods",
      "keywords": "artificial intelligence; computer vision; data analysis; data collection; deep learning; epidemiologic methods; neural networks",
      "pub_types": "Journal Article",
      "pmcid": "PMC11815488"
    },
    {
      "pmid": "35879277",
      "title": "An analysis of 45 large-scale wastewater sites in England to estimate SARS-CoV-2 community prevalence.",
      "abstract": "Accurate surveillance of the COVID-19 pandemic can be weakened by under-reporting of cases, particularly due to asymptomatic or pre-symptomatic infections, resulting in bias. Quantification of SARS-CoV-2 RNA in wastewater can be used to infer infection prevalence, but uncertainty in sensitivity and considerable variability has meant that accurate measurement remains elusive. Here, we use data from 45 sewage sites in England, covering 31% of the population, and estimate SARS-CoV-2 prevalence to within 1.1% of estimates from representative prevalence surveys (with 95% confidence). Using machine learning and phenomenological models, we show that differences between sampled sites, particularly the wastewater flow rate, influence prevalence estimation and require careful interpretation. We find that SARS-CoV-2 signals in wastewater appear 4-5 days earlier in comparison to clinical testing data but are coincident with prevalence surveys suggesting that wastewater surveillance can be a leading indicator for symptomatic viral infections. Surveillance for viruses in wastewater complements and strengthens clinical surveillance, with significant implications for public health.",
      "authors": "Morvan Mario; Jacomo Anna Lo; Souque Celia; Wade Matthew J; Hoffmann Till; Pouwels Koen; Lilley Chris; Singer Andrew C; Porter Jonathan; Evens Nicholas P; Walker David I; Bunce Joshua T; Engeli Andrew; Grimsley Jasmine; O'Reilly Kathleen M; Danon Leon",
      "year": "2022",
      "journal": "Nature communications",
      "doi": "10.1038/s41467-022-31753-y",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35879277/",
      "mesh_terms": "COVID-19; Humans; Pandemics; Prevalence; RNA, Viral; SARS-CoV-2; Wastewater; Wastewater-Based Epidemiological Monitoring",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9312315"
    },
    {
      "pmid": "34010259",
      "title": "ARTIFICIAL INTELLIGENCE IN MEDICAL DEVICES: PAST, PRESENT AND FUTURE.",
      "abstract": "Artificial Intelligence (AI) has been drawing attention in the field of medical devices. However, due to system complexity, the variability of their architecture, as well as ethical and regulatory concerns there is an ongoing need to analyze its application and performance.This study presents a narrative commentary on the applications of artificial neural networks (ANN) and machine learning (ML) algorithms in medical devices, past, current and future perspectives of application. One research focus of this study was on identifying problems and issues related to the implementation of AI in medical devices. The commentary is based on scientific articles published in PubMed, Scopus ad ScienceDirect databases, official publications of international organizations: European Comission (EC), Food and Drug Administration (FDA), and World Health Organisation (WHO) published in 2009 - 2020 period. AI is revolutionizing healthcare, from medical applications to clinical engineering. However, before grasp-ing the full potential ethical, legal and social concerns need to be resolved and its application needs to be harmonized and regulated regarding equitable access, privacy, appropriate uses and users, liability and bias and inclusiveness.",
      "authors": "Badnjevi\u0107 Almir; Avdihod\u017ei\u0107 Halida; Gurbeta Pokvi\u0107 Lejla",
      "year": "2021",
      "journal": "Psychiatria Danubina",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34010259/",
      "mesh_terms": "Artificial Intelligence; Delivery of Health Care; Humans; Machine Learning",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33072224",
      "title": "A Model-Based Approach to Detection Limits in Studying Environmental Exposures and Human Fecundity.",
      "abstract": "Human exposure to persistent environmental pollutants often results in concentrations with a range of values below the laboratory detection limits. Growing evidence suggests that inadequate handling of concentrations below the limit of detection (LOD) may bias assessment of health effects in relation to environmental exposures. We seek to quantify such bias in models focusing on the day-specific probability of pregnancy during the fertile window and propose a model-based approach to reduce such bias. A multivariate skewed generalized t-distribution constrained by the LOD is assumed for the chemical concentrations, which realistically represents the underlying distribution. A latent variable-based framework is used to model fecundibility, which nonlinearly relates conception probability to chemical concentrations, daily intercourses, and other important covariates. The advantages of the proposed approach include the use of multiple chemical concentrations to aid the estimation of left censored chemical exposures, as well as the model-based feedback mechanism for fecundibility outcome to inform the estimations, and an adequate handling of model uncertainty through a joint modeling framework. A Markov chain Monte Carlo sampling algorithm is developed for implementing the Bayesian computations and the logarithm of pseudo-marginal likelihood measure is used for model choices. We conduct simulation studies to demonstrate the performance of the proposed approach and apply the framework to the Longitudinal Investigation of Fertility and the Environment study which evaluates the effects of exposures to environmental pollutants on the probability of pregnancy. We found that p,p'-DDT is negatively associated with the day-specific probability of pregnancy.",
      "authors": "Kim Sungduk; Chen Zhen; Perkins Neil J; Schisterman Enrique F; Buck Louis Germaine M",
      "year": "2019",
      "journal": "Statistics in biosciences",
      "doi": "10.1007/s12561-019-09243-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33072224/",
      "mesh_terms": "",
      "keywords": "Fecundity; Generalized t-distribution; Markov chain Monte Carlo; Menstrual cycle; Posterior distribution; Pregnancy",
      "pub_types": "Journal Article",
      "pmcid": "PMC7561047"
    },
    {
      "pmid": "41458976",
      "title": "Health disinformation: a call to action for the hemostasis and thrombosis community.",
      "abstract": "The COVID-19 pandemic has exposed a parallel crisis: an infodemic of unprecedented scale and impact. This wave of misinformation and disinformation-particularly around thrombosis, vaccines, and hemostasis-has undermined public health measures, eroded institutional trust, and endangered scientific credibility. Within this hostile informational ecosystem, fringe theories proliferated across social media, falsely linking COVID-19 vaccines to widespread thrombosis via misinterpretations of D-dimer levels and anecdotal claims unsupported by clinical evidence. Political agendas, emotional manipulation, and algorithm-driven amplification created fertile ground for disinformation to thrive-especially among vulnerable populations like youth and vaccine-hesitant communities. The article dissects how belief bias, trust shortcuts, groupthink, and platform algorithms contributed to the viral spread of falsehoods about thrombosis and hemostasis. Case studies include the misuse of hydroxychloroquine, antivaccine conspiracy movements, and the misleading portrayal of rare vaccine-induced clotting events. The consequences were severe: declining vaccine uptake, harassment of scientists, and growing skepticism toward evidence-based medicine. This article calls on the hemostasis and thrombosis community to move beyond passive dissemination of knowledge. It proposes a 4-pillar strategy: embedding scientific voices in digital discourse, reforming media and health literacy education, enforcing stronger regulatory frameworks, and institutionalizing collective scientific engagement in mainstream and social media. As future health crises loom, communication must become as central as research itself. The article argues that the next battle for public health will be waged not only in hospitals and laboratories but also in the information spaces where truth competes with virality. It is time for science to go viral-for the right reasons.",
      "authors": "Smadja David M",
      "year": "2025",
      "journal": "Research and practice in thrombosis and haemostasis",
      "doi": "10.1016/j.rpth.2025.103272",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41458976/",
      "mesh_terms": "",
      "keywords": "COVID-19; artificial intelligence; communication; disinformation; education",
      "pub_types": "Editorial",
      "pmcid": "PMC12743549"
    },
    {
      "pmid": "32885290",
      "title": "Construction and Application of a Medical-Grade Wireless Monitoring System for Physiological Signals at General Wards.",
      "abstract": "Physiological signals can contain abundant personalized information and indicate health status and disease deterioration. However, in current medical practice, clinicians working in the general wards are usually lack of plentiful means and tools to continuously monitor the physiological signals of the inpatients. To address this problem, we here presented a medical-grade wireless monitoring system based on wearable and artificial intelligence technology. The system consists of a multi-sensor wearable device, database servers and user interfaces. It can monitor physiological signals such as electrocardiography and respiration and transmit data wirelessly. We highly integrated the system with the existing hospital information system and explored a set of processes of physiological signal acquisition, storage, analysis, and combination with electronic health records. Multi-scale information extracted from physiological signals and related to the deterioration or abnormality of patients could be shown on the user interfaces, while a variety of reports could be provided daily based on time-series signal processing technology and machine learning to make more information accessible to clinicians. Apart from an initial attempt to implement the system in a realistic clinical environment, we also conducted a preliminary validation of the core processes in the workflow. The heart rate veracity validation of 22 patient volunteers showed that the system had a great consistency with ECG Holter, and bias for heart rate was 0.04 (95% confidence interval: -7.34 to 7.42) beats per minute. The Bland-Altman analysis showed that 98.52% of the points were located between Mean\u2009\u00b1\u20091.96SD. This system has been deployed in the general wards of the Hyperbaric Oxygen Department and Respiratory Medicine Department and has collected more than 1000 cases from the clinic. The whole system will continue to be updated based on clinical feedback. It has been demonstrated that this system can provide reliable physiological monitoring for patients in general wards and has the potential to generate more personalized pathophysiological information related to disease diagnosis and treatment from the continuously monitored physiological data.",
      "authors": "Xu Haoran; Li Peiyao; Yang Zhicheng; Liu Xiaoli; Wang Zhao; Yan Wei; He Maoqing; Chu Wenya; She Yingjia; Li Yuzhu; Cao Desen; Yan Muyang; Zhang Zhengbo",
      "year": "2020",
      "journal": "Journal of medical systems",
      "doi": "10.1007/s10916-020-01653-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32885290/",
      "mesh_terms": "Artificial Intelligence; Electrocardiography; Electrocardiography, Ambulatory; Humans; Monitoring, Physiologic; Patients' Rooms; Wearable Electronic Devices; Wireless Technology",
      "keywords": "Electronic health records; Machine learning applications; Physiological signals; Wearable technology; Wireless monitoring system",
      "pub_types": "Journal Article",
      "pmcid": "PMC7471584"
    },
    {
      "pmid": "41422036",
      "title": "AI-Driven SaO2 prediction from pulse oximetry and electronic health records.",
      "abstract": "OBJECTIVE: To address limitations in pulse oximetry accuracy associated with low saturation and melanin content using machine learning (ML) and to compare our results to standard pulse oximetry and gold standard arterial blood gas readings. BACKGROUND: Oxygen saturation is traditionally measured through the gold standard arterial blood gas (SaO2) or pulse oximetry (SpO2), which approximates SaO2 using light absorption patterns. However, SpO2 has been shown to overestimate oxygen saturation, particularly in individuals with darker skin tone, leading to hidden hypoxemia and delayed medical interventions. METHOD: We developed a machine learning (ML) model trained on the BOLD dataset, integrating patient data from eICU, MIMIC-III, and MIMIC-IV (n\u2009=\u200949,093). With 64 clinical features and 2 outcomes (SaO2 and hidden hypoxemia events), we trained regression ML models (linear regression, random forest, and XGBoost) to predict SaO2, minimizing the mean squared error between predicted SaO2 and ground truth SaO2. We used our test data to compare model performance to standard SaO2 measurement with accuracy root mean square error (Arms), R2, and change in hidden hypoxemia events. We used SHapley Additive exPlanations (SHAP) to rank important features for SaO2 prediction. RESULTS: The XGBoost-Vanilla model improved Arms to 3.3% from a baseline of 4.1%. In low SaO2 patients (SaO2\u2009<\u200990%), the accuracy of pulse oximetry was heavily compromised with Arms of 10.3%; the linear regression model with weighted loss was able to reduce Arms to 8.6%. We found that SpO2, creatinine level, mean corpuscular hemoglobin level, respiratory rate, and age at admission were the leading features driving the SaO2 prediction. CONCLUSION: These findings suggest that ML-based models can enhance the accuracy of the standard SpO2. Further investigation is warranted to address SpO\u2082 inaccuracies and bias. SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1186/s13040-025-00511-3.",
      "authors": "Woo JiWon; Stapleton Orian; Luo Jay; Chuang Chao Cheng; Su Yolanda; Sankararaman Sreenidhi; Mukherjee Esanika; Sivakumar Nikita; Calligy Katherine; Duffy Summer; Mosier Rebecca; Greenstein Joseph; Taylor Casey Overby; Sen Danielle Gottlieb",
      "year": "2025",
      "journal": "BioData mining",
      "doi": "10.1186/s13040-025-00511-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41422036/",
      "mesh_terms": "",
      "keywords": "Health equity; Hidden hypoxemia; Machine learning; Pulse oximetry",
      "pub_types": "Journal Article",
      "pmcid": "PMC12752230"
    },
    {
      "pmid": "35157155",
      "title": "Merging of the Case 2\u00a0Regional Coast Colour and Maximum-Peak Height chlorophyll-a algorithms: validation and demonstration of satellite-derived retrievals across US lakes.",
      "abstract": "Water quality monitoring is relevant for protecting the designated, or beneficial uses, of water such as drinking, aquatic life, recreation, irrigation, and food supply that support the economy, human well-being, and aquatic ecosystem health. Managing finite water resources to support these designated uses requires information on water quality so that managers can make sustainable decisions. Chlorophyll-a (chl-a, \u00b5g L-1) concentration can serve as a proxy for phytoplankton biomass and may be used as an indicator of increased anthropogenic nutrient stress. Satellite remote sensing may present a complement to in situ measures for assessments of water quality through the retrieval of chl-a with in-water algorithms. Validation of chl-a algorithms across US lakes improves algorithm maturity relevant for monitoring applications. This study compares performance of the Case 2 Regional Coast Colour (C2RCC) chl-a retrieval algorithm, a revised version of the Maximum-Peak Height (MPH(P)) algorithm, and three scenarios merging these two approaches. Satellite data were retrieved from the MEdium Resolution Imaging Spectrometer (MERIS) and the Ocean and Land Colour Instrument (OLCI), while field observations were obtained from 181 lakes matched with U.S. Water Quality Portal chl-a data. The best performance based on mean absolute multiplicative error (MAEmult) was demonstrated by the merged algorithm referred to as C15-M10 (MAEmult\u2009=\u20091.8, biasmult\u2009=\u20090.97, n\u2009=\u2009836). In the C15-M10 algorithm, the MPH(P) chl-a value was retained if it was\u2009>\u200910\u00a0\u00b5g L-1; if the MPH(P) value was\u2009\u2264\u200910\u00a0\u00b5g L-1, the C2RCC value was selected, as long as that value was\u2009<\u200915\u00a0\u00b5g L-1. Time-series and lake-wide gradients compared against independent assessments from Lake Champlain and long-term ecological research stations in Wisconsin were used as complementary examples supporting water quality reporting requirements. Trophic state assessments for Wisconsin lakes provided examples in support of inland water quality monitoring applications. This study presents and assesses merged adaptations of chl-a algorithms previously reported independently. Additionally, it contributes to the transition of chl-a algorithm maturity by quantifying error statistics for a number of locations and times.",
      "authors": "Schaeffer Blake; Salls Wilson; Coffer Megan; Lebreton Carole; Werther Mortimer; Stelzer Kerstin; Urquhart Erin; Gurlin Daniela",
      "year": "2022",
      "journal": "Environmental monitoring and assessment",
      "doi": "10.1007/s10661-021-09684-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35157155/",
      "mesh_terms": "Algorithms; Chlorophyll; Chlorophyll A; Color; Ecosystem; Environmental Monitoring; Humans; Lakes",
      "keywords": "Chlorophyll; Lakes; Reservoirs; Satellite; Trophic state; Water quality",
      "pub_types": "Journal Article",
      "pmcid": "PMC8843926"
    },
    {
      "pmid": "36138394",
      "title": "A novel dynamic Bayesian network approach for data mining and survival data analysis.",
      "abstract": "BACKGROUND: Censorship is the primary challenge in survival modeling, especially in human health studies. The classical methods have been limited by applications like Kaplan-Meier or restricted assumptions like the Cox regression model. On the other hand, Machine learning algorithms commonly rely on the high dimensionality of data and ignore the censorship attribute. In addition, these algorithms are more sophisticated to understand and utilize. We propose a novel approach based on the Bayesian network to address these issues. METHODS: We proposed a two-slice temporal Bayesian network model for the survival data, introducing the survival and censorship status in each observed time as the dynamic states. A score-based algorithm learned the structure of the directed acyclic graph. The likelihood approach conducted parameter learning. We conducted a simulation study to assess the performance of our model in comparison with the Kaplan-Meier and Cox proportional hazard regression. We defined various scenarios according to the sample size, censoring rate, and shapes of survival and censoring distributions across time. Finally, we fit the model on a real-world dataset that includes 760 post gastrectomy surgery due to gastric cancer. The validation of the model was explored using the hold-out technique based on the posterior classification error. Our survival model performance results were compared using the Kaplan-Meier and Cox proportional hazard models. RESULTS: The simulation study shows the superiority of DBN in bias reduction for many scenarios compared with Cox regression and Kaplan-Meier, especially in the late survival times. In the real-world data, the structure of the dynamic Bayesian network model satisfied the finding from Kaplan-Meier and Cox regression classical approaches. The posterior classification error found from the validation technique did not exceed 0.04, representing that our network predicted the state variables with more than 96% accuracy. CONCLUSIONS: Our proposed dynamic Bayesian network model could be used as a data mining technique in the context of survival data analysis. The advantages of this approach are feature selection ability, straightforward interpretation, handling of high-dimensional data, and few assumptions.",
      "authors": "Sheidaei Ali; Foroushani Abbas Rahimi; Gohari Kimiya; Zeraati Hojjat",
      "year": "2022",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-022-02000-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36138394/",
      "mesh_terms": "Algorithms; Bayes Theorem; Data Analysis; Data Mining; Humans; Likelihood Functions; Proportional Hazards Models; Survival Analysis",
      "keywords": "Directed acyclic graph; Dynamic Bayesian network; Gastric cancer; Survival analysis",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9503243"
    },
    {
      "pmid": "35089986",
      "title": "Validation of a deep learning-based image analysis system to diagnose subclinical endometritis in dairy cows.",
      "abstract": "The assessment of polymorphonuclear leukocyte (PMN) proportions (%) of endometrial samples is the hallmark for subclinical endometritis (SCE) diagnosis. Yet, a non-biased, automated diagnostic method for assessing PMN% in endometrial cytology slides has not been validated so far. We aimed to validate a computer vision software based on deep machine learning to quantify the PMN% in endometrial cytology slides. Uterine cytobrush samples were collected from 116 postpartum Holstein cows. After sampling, each cytobrush was rolled onto three different slides. One slide was stained using Diff-Quick, while a second was stained using Naphthol (golden standard to stain PMN). One single observer evaluated the slides twice at different days under light microscopy. The last slide was stained with a fluorescent dye, and the PMN% were assessed twice by using a fluorescence microscope connected to a smartphone. Fluorescent images were analyzed via the Oculyze Monitoring Uterine Health (MUH) system, which uses a deep learning-based algorithm to identify PMN. Substantial intra-method repeatabilities (via Spearman correlation) were found for Diff-Quick, Naphthol, and Oculyze MUH (r = 0.67 to 0.76). The intra-method agreements (via Kappa value) at \u22651% PMN (\u03ba = 0.44 to 0.47) were lower than at >5 (\u03ba = 0.69 to 0.78) or >10% (\u03ba = 0.67 to 0.85) PMN cut-offs. The inter-method repeatabilities (via Lin's correlation) were also substantial, and values between Diff-Quick and Oculyze MUH, Naphthol and Diff-Quick, and Naphthol and Oculyze MUH were 0.68, 0.69, and 0.77, respectively. The agreements among evaluation methods at \u22651% PMN were weak (\u03ba = 0.06 to 0.28), while it increased at >5 (\u03ba = 0.48 to 0.81) or >10% (\u03ba = 0.50 to 0.65) PMN cut-offs. To conclude, deep learning-based algorithms in endometrial cytology are reliable and useful for simplifying and reducing the diagnosis bias of SCE in dairy cows.",
      "authors": "Sadeghi Hafez; Braun Hannah-Sophie; Panti Berner; Opsomer Geert; Bogado Pascottini Osvaldo",
      "year": "2022",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0263409",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35089986/",
      "mesh_terms": "Animals; Cattle; Dairying; Deep Learning; Endometritis; Endometrium; Female; Image Processing, Computer-Assisted; Leukocytes, Mononuclear; Reproducibility of Results",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Validation Study",
      "pmcid": "PMC8797203"
    },
    {
      "pmid": "39281744",
      "title": "Large language models outperform traditional natural language processing methods in extracting patient-reported outcomes in IBD.",
      "abstract": "BACKGROUND AND AIMS: Patient-reported outcomes (PROs) are vital in assessing disease activity and treatment outcomes in inflammatory bowel disease (IBD). However, manual extraction of these PROs from the free-text of clinical notes is burdensome. We aimed to improve data curation from free-text information in the electronic health record, making it more available for research and quality improvement. This study aimed to compare traditional natural language processing (tNLP) and large language models (LLMs) in extracting three IBD PROs (abdominal pain, diarrhea, fecal blood) from clinical notes across two institutions. METHODS: Clinic notes were annotated for each PRO using preset protocols. Models were developed and internally tested at the University of California San Francisco (UCSF), and then externally validated at Stanford University. We compared tNLP and LLM-based models on accuracy, sensitivity, specificity, positive and negative predictive value. Additionally, we conducted fairness and error assessments. RESULTS: Inter-rater reliability between annotators was >90%. On the UCSF test set (n=50), the top-performing tNLP models showcased accuracies of 92% (abdominal pain), 82% (diarrhea) and 80% (fecal blood), comparable to GPT-4, which was 96%, 88%, and 90% accurate, respectively. On external validation at Stanford (n=250), tNLP models failed to generalize (61-62% accuracy) while GPT-4 maintained accuracies >90%. PaLM-2 and GPT-4 showed similar performance. No biases were detected based on demographics or diagnosis. CONCLUSIONS: LLMs are accurate and generalizable methods for extracting PROs. They maintain excellent accuracy across institutions, despite heterogeneity in note templates and authors. Widespread adoption of such tools has the potential to enhance IBD research and patient care.",
      "authors": "Patel Perseus V; Davis Conner; Ralbovsky Amariel; Tinoco Daniel; Williams Christopher Y K; Slatter Shadera; Naderalvojoud Behzad; Rosen Michael J; Hernandez-Boussard Tina; Rudrapatna Vivek",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2024.09.05.24313139",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39281744/",
      "mesh_terms": "",
      "keywords": "GPT-4; PaLM-2; clinical data science; machine learning",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC11398594"
    },
    {
      "pmid": "36407783",
      "title": "Machine learning nonresponse adjustment of patient-reported opioid consumption data to enable consumption-informed postoperative opioid prescribing guidelines.",
      "abstract": "BACKGROUND: Post-discharge opioid consumption is a crucial patient-reported outcome informing opioid prescribing guidelines, but its collection is resource-intensive and vulnerable to inaccuracy due to nonresponse bias. METHODS: We developed a post-discharge text message-to-web survey system for efficient collection of patient-reported pain outcomes. We prospectively recruited surgical patients at Beth Israel Deaconess Medical Center in Boston, Massachusetts from March 2019 through October 2020, sending an SMS link to a secure web survey to quantify opioids consumed after discharge from hospitalization. Patient factors extracted from the electronic health record were tested for nonresponse bias and observable confounding. Following targeted learning-based nonresponse adjustment, procedure-specific opioid consumption quantiles (medians and 75th percentiles) were estimated and compared to a previous telephone-based reference survey. RESULTS: 6553 patients were included. Opioid consumption was measured in 44% of patients (2868), including 21% (1342) through survey response. Characteristics associated with inability to measure opioid consumption included age, tobacco use, and prescribed opioid dose. Among the 10 most common procedures, median consumption was only 36% of the median prescription size; 64% of prescribed opioids were not consumed. Among those procedures, nonresponse adjustment corrected the median opioid consumption by an average of 37% (IQR: 7, 65%) compared to unadjusted estimates, and corrected the 75th percentile by an average of 5% (IQR: 0, 12%). This brought median estimates for 5/10 procedures closer to telephone survey-based consumption estimates, and 75th percentile estimates for 2/10 procedures closer to telephone survey-based estimates. CONCLUSIONS: SMS-recruited online surveying can generate reliable opioid consumption estimates after nonresponse adjustment using patient factors recorded in the electronic health record, protecting patients from the risk of inaccurate prescription guidelines.",
      "authors": "Kennedy Chris J; Marwaha Jayson S; Beaulieu-Jones Brendin R; Scalise P Nina; Robinson Kortney A; Booth Brandon; Fleishman Aaron; Nathanson Larry A; Brat Gabriel A",
      "year": "2022",
      "journal": "Surgery in practice and science",
      "doi": "10.1016/j.sipas.2022.100098",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36407783/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9675048"
    },
    {
      "pmid": "38317207",
      "title": "The accuracy of fully-automated algorithms for the surveillance of central venous catheter-related bloodstream infection in hospitalised patients.",
      "abstract": "BACKGROUND: Continuous surveillance for healthcare-associated infections such as central venous catheter-related bloodstream infections (CVC-BSI) is crucial for prevention. However, traditional surveillance methods are resource-intensive and prone to bias. This study aimed to develop and validate fully-automated surveillance algorithms for CVC-BSI. METHODS: Two algorithms were developed using electronic health record data from 1000 admissions with a positive blood culture (BCx) at Karolinska University Hospital from 2017: (1) Combining microbiological findings in BCx and CVC cultures with BSI symptoms; (2) Only using microbiological findings. These algorithms were validated in 5170 potential CVC-BSI-episodes from all admissions in 2018-2019, and results extrapolated to all potential CVC-BSI-episodes within this period (n\u2009=\u2009181,354). The reference standard was manual record review according to ECDC's definition of microbiologically confirmed CVC-BSI (CRI3-CVC). RESULTS: In the potential CVC-BSI-episodes, 51 fulfilled ECDC's definition and the algorithms identified 47 and 49 episodes as CVC-BSI, respectively. Both algorithms performed well in assessing CVC-BSI. Overall, algorithm 2 performed slightly better with in the total period a sensitivity of 0.880 (95%-CI 0.783-0.959), specificity of 1.000 (95%-CI 0.999-1.000), PPV of 0.918 (95%-CI 0.833-0.981) and NPV of 1.000 (95%-CI 0.999-1.000). Incidence according to the reference and algorithm 2 was 0.33 and 0.31 per 1000 in-patient hospital-days, respectively. CONCLUSIONS: Both fully-automated surveillance algorithms for CVC-BSI performed well and could effectively replace manual surveillance. The simpler algorithm, using only microbiology data, is suitable when BCx testing adheres to recommendations, otherwise the algorithm using symptom data might be required. Further validation in other settings is necessary to assess the algorithms' generalisability.",
      "authors": "Karmefors Idvall Moa; Tanushi Hideyuki; Berge Andreas; Naucl\u00e9r Pontus; van der Werff Suzanne Desir\u00e9e",
      "year": "2024",
      "journal": "Antimicrobial resistance and infection control",
      "doi": "10.1186/s13756-024-01373-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38317207/",
      "mesh_terms": "Humans; Central Venous Catheters; Catheter-Related Infections; Cross Infection; Hospitalization; Sepsis",
      "keywords": "Algorithms; Automated surveillance; Catheter-related infection; Central venous catheter-related bloodstream infection; Electronic health record data; Healthcare-associated infections",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10840273"
    },
    {
      "pmid": "34997053",
      "title": "Three-step matching algorithm to enhance between-group comparability and minimize confounding in comparative effectiveness studies.",
      "abstract": "We developed a three-step matching algorithm to enhance the between-group comparability for comparative drug effect studies involving prevalent new-users of the newer study drug versus older comparator drug(s). The three-step matching scheme is to match on: (1) index date of initiating the newer study drug to align the cohort entry time between study groups, (2) medication possession ratio measures that consider prior exposure to all older comparator drugs, and (3) propensity scores estimated from potential confounders. Our approach is illustrated with a comparative cardiovascular safety study of glucagon-like peptide-1 receptor agonist (GLP-1ra) versus sulfonylurea (SU) in type 2 diabetes patients using Taiwan's National Health Insurance Research Database 2003-2015. 66% of 3195 GLP-1ra users had previously exposed to SU. The between-group comparability was well-achieved after implementing the matching algorithm (i.e., standardized mean difference <\u20090.2 for all baseline patient characteristics). Compared to SU, the use of GLP-1ra yielded a significantly reduced risk of the primary composite cardiovascular events (hazard ratio [95% confidence interval]: 0.71 [0.54-0.95], p\u2009=\u20090.022). Our matching scheme can enhance the between-group comparability in prevalent new-user cohort designs to minimize time-related bias, improve confounder adjustment, and ensure the reliability and validity of study findings.",
      "authors": "Yang Chen-Yi; Kuo Shihchen; Lai Edward Chia-Cheng; Ou Huang-Tz",
      "year": "2022",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-021-04014-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34997053/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8741962"
    },
    {
      "pmid": "38082891",
      "title": "Comparison of Wired and Wireless Heart Rate Monitoring in the Neonatal Intensive Care Unit.",
      "abstract": "In the Neonatal Intensive Care Unit (NICU), infants' vital signs are monitored on a continuous basis via wired devices. These often interfere with patient care and pose increased risks of skin damage, infection, and tangling around the body. Recently, a wireless system for neonatal monitoring called ANNE\u24c7 One (Sibel Health, Chicago, USA) was developed. We designed an ongoing study to evaluate the feasibility, reliability and accuracy, of using this system in the NICU. Vital signals were simultaneously acquired by using the standard, wired clinical monitor and the ANNE\u24c7 device. Data from 10 NICU infants were recorded for 8 hours per day during 4 consecutive days. Initial analysis of the heart rate (HR) data revealed four problems in comparing the signals: 1) gaps in the signals - periods of time for which data were unavailable, 2) wired and wireless signals were sampled at different rates, 3) a delay between the sampled values of wired and wireless signals, and 4) this delay increased with time. To address these problems, we developed a pre-processing algorithm that interpolated samples in short gaps, resampled the signals to an equal rate, estimated the delay and drift rate between corresponding signals, and aligned the signals. Applications of the pre-processing algorithm to 40 recordings demonstrated that it was very effective. A strong agreement between wireless and wired HR signals was seen, with an average correlation of 0.95\u00b10.04, a slope of 1.00, and a variance accounted for 89.56\u00b17.62%. Bland-Altman analysis showed a low bias across the ensemble, with an average difference of 0.11 (95% confidence interval of -0.02 to 0.24) bpm.Clinical relevance- This algorithm provides the means for a detailed comparison of wired and wireless monitors in the NICU.",
      "authors": "Radeschi Daniel J; Senechal Eva; Tao Lydia; Lv Shasha; Shalish Wissam; Sant'Anna Guilherme; Kearney Robert E",
      "year": "2023",
      "journal": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference",
      "doi": "10.1109/EMBC40787.2023.10340972",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38082891/",
      "mesh_terms": "Infant, Newborn; Humans; Intensive Care Units, Neonatal; Heart Rate Determination; Reproducibility of Results; Wireless Technology; Monitoring, Physiologic",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "31842854",
      "title": "Representation learning for clinical time series prediction tasks in electronic health records.",
      "abstract": "BACKGROUND: Electronic health records (EHRs) provide possibilities to improve patient care and facilitate clinical research. However, there are many challenges faced by the applications of EHRs, such as temporality, high dimensionality, sparseness, noise, random error and systematic bias. In particular, temporal information is difficult to effectively use by traditional machine learning methods while the sequential information of EHRs is very useful. METHOD: In this paper, we propose a general-purpose patient representation learning approach to summarize sequential EHRs. Specifically, a recurrent neural network based denoising autoencoder (RNN-DAE) is employed to encode inhospital records of each patient into a low dimensional dense vector. RESULTS: Based on EHR data collected from Shuguang Hospital affiliated to Shanghai University of Traditional Chinese Medicine, we experimentally evaluate our proposed RNN-DAE method on both mortality prediction task and comorbidity prediction task. Extensive experimental results show that our proposed RNN-DAE method outperforms existing methods. In addition, we apply the \"Deep Feature\" represented by our proposed RNN-DAE method to track similar patients with t-SNE, which also achieves some interesting observations. CONCLUSION: We propose an effective unsupervised RNN-DAE method to summarize patient sequential information in EHR data. Our proposed RNN-DAE method is useful on both mortality prediction task and comorbidity prediction task.",
      "authors": "Ruan Tong; Lei Liqi; Zhou Yangming; Zhai Jie; Zhang Le; He Ping; Gao Ju",
      "year": "2019",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-019-0985-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31842854/",
      "mesh_terms": "Algorithms; China; Comorbidity; Electronic Health Records; Forecasting; Heart Failure; Humans; Machine Learning; Mortality; Neural Networks, Computer",
      "keywords": "Electronic health records; Mortality prediction; Recurrent neural network; Representation learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6916209"
    },
    {
      "pmid": "39805501",
      "title": "Exploring the triglyceride-glucose index's role in depression and cognitive dysfunction: Evidence from NHANES with machine learning support.",
      "abstract": "BACKGROUND: Depression and cognitive impairments are prevalent among older adults, with evidence suggesting potential links to obesity and lipid metabolism disturbances. This study investigates the relationships between the triglyceride-glucose (TyG) index, body mass index (BMI), depression, and cognitive dysfunction in older adults, leveraging data from the NHANES survey and employing machine learning techniques. METHODS: We analysed 1352 participants aged 60-79 from the 2011-2014 NHANES dataset, who underwent cognitive function testing, depression assessments, and TyG index measurements. Multivariate linear regression and subgroup analyses were conducted to examine associations between the TyG index and depression/cognitive impairment. Machine learning models evaluated the importance of predictive factors for depression, while Mendelian randomization (MR) was employed to explore the causal relationship between BMI and depression/cognitive function. RESULTS: The TyG index was negatively associated with cognitive function scores and positively associated with depression scores in adjusted models (p\u00a0<\u00a00.001). In fully adjusted subgroup analyses, among obese individuals (BMI\u00a0\u2265\u00a028), a 100-unit increase in the TyG index was linked to a 3.79-point decrease in depression scores. Machine learning models (Xgboost, AUC\u00a0=\u00a00.960) identified BMI, TyG-BMI, gender, and comorbidities (e.g., asthma, stroke, emphysema) as key determinants of depression. MR analyses revealed a negative association between BMI and depression risk [OR: 0.9934; 95\u00a0% CI (0.9901-0.9968), p\u00a0=\u00a00.0001] and cognitive dysfunction risk [OR: 0.8514; 95\u00a0% CI (0.7929-0.9143), p\u00a0<\u00a00.05]. No evidence of heterogeneity or pleiotropy was detected. LIMITATIONS: Depression and cognitive impairments were self-reported, potentially introducing bias. The observed associations may be influenced by unmeasured confounders, necessitating further research into the underlying mechanisms. CONCLUSIONS: Our findings reveal associations between the TyG index and psychocognitive health in older adults. While these results highlight lipid metabolism as a potential factor in depression and cognitive dysfunction, further studies are needed to validate these findings and explore underlying mechanisms.",
      "authors": "Ding Chao; Lu Renjie; Kong Zhiyu; Huang Rong",
      "year": "2025",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2025.01.051",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39805501/",
      "mesh_terms": "Humans; Male; Female; Machine Learning; Middle Aged; Aged; Triglycerides; Cognitive Dysfunction; Nutrition Surveys; Body Mass Index; Blood Glucose; Depression; Obesity; Mendelian Randomization Analysis",
      "keywords": "BMI; Cognitive function; Depression; NHANES; Older people; Triglyceride-glucose index",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40571798",
      "title": "Optimizing surgical efficiency: predicting case duration of common general surgery procedures using machine learning.",
      "abstract": "BACKGROUND: Accurate prediction of surgical duration is critical to optimizing use of operating room resources. Currently, cases are scheduled using subjective estimates of length by surgeons, relying heavily on prior experience. This study aims to develop and compare various predictive models-from conventional statistics to machine learning-based algorithms-to accurately and objectively predict case duration for common elective general surgical procedures. METHODS: Electronic health record data across three academic tertiary centers were used to train models to predict \"case time duration,\" defined as the time between patient entry to and departure from the operating room. Model performance was evaluated based on predictive accuracy as well as residual analysis, and ultimately benchmarked against \"scheduled duration,\" defined as case time estimated preoperatively by primary surgeons. RESULTS: Predictive models, including simple linear regression, Ridge regression, Lasso regression, Support Vector Regression, Random Forest, Gradient Boosting Machine, XGBoost, and Artificial Neural Network (ANN), were trained on a cohort of 16,159 patients [mean age, 56.85\u2009\u00b1\u200915.95; 47.48% male] having undergone 17,246 elective general surgery procedures. The ANN model demonstrated superior predictive accuracy (Root Mean Squared Error, 49.7\u00a0min [95% CI 47.5 to 52.0]; Mean Absolute Error, 31.8\u00a0min [95% CI 30.6 to 33.0]). Residual analysis showed that the ANN resulted in an average residual of -0.37\u00a0min [95% CI -\u00a040.42 to 39.68, p\u2009=\u20090.34], while the scheduled duration produced an average residual of -\u00a018.52\u00a0min [95% CI -\u00a055.24 to 18.2, p\u2009<\u20090.01], demonstrating that the ANN provided a more accurate case time estimation by more than 18\u00a0min. CONCLUSION: The ANN model estimates of case time were meaningfully more accurate than provider knowledge-based estimates. By eliminating the subjective bias and dogma inherent in the traditional scheduling methods, future applications of machine learning to predict case duration may improve healthcare resource utilization.",
      "authors": "Kwong Michelle; Noorchenarboo Mohammad; Grolinger Katarina; Hawel Jeff; Schlachta Christopher M; Elnahas Ahmad",
      "year": "2025",
      "journal": "Surgical endoscopy",
      "doi": "10.1007/s00464-025-11885-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40571798/",
      "mesh_terms": "Humans; Machine Learning; Male; Female; Middle Aged; Elective Surgical Procedures; Operative Time; Electronic Health Records; Neural Networks, Computer; Adult; Aged; Algorithms; Operating Rooms",
      "keywords": "Case duration prediction; Case scheduling; Elective surgery; General surgery; Machine learning",
      "pub_types": "Journal Article; Multicenter Study",
      "pmcid": "7747850"
    },
    {
      "pmid": "40009644",
      "title": "A spectral machine learning approach to derive central aortic pressure waveforms from a brachial cuff.",
      "abstract": "Analyzing cardiac pulse waveforms offers valuable insights into heart health and cardiovascular disease risk, although obtaining the more informative measurements from the central aorta remains challenging due to their invasive nature and limited noninvasive options. To address this, we employed a laboratory-developed cuff device for high-resolution pulse waveform acquisition and constructed a spectral machine learning model to nonlinearly map the brachial wave components to the aortic site. Simultaneous invasive aortic catheter and brachial cuff waveforms were acquired in 115 subjects to evaluate the clinical performance of the developed wave-based approach. Magnitude, shape, and pulse waveform analysis on the measured and reconstructed aortic waveforms were correlated on a beat-to-beat basis. The proposed cuff-based method reconstructed aortic waveform contours with high fidelity (mean normalized-RMS error = 11.3%). Furthermore, continuous signal reconstruction captured dynamic aortic systolic blood pressure (BP) oscillations (r = 0.76, P < 0.05). Method-derived central pressures showed strong correlation with the independent invasive measurement for systolic BP (R2 = 0.83; B [LOA] = -0.3 [-17.0, 16.4] mmHg) and diastolic BP (R2 = 0.58; B [LOA] = -0.7 [-13.1, 11.6] mmHg). Shape-based features are effectively captured by the spectral machine learning method, showing strong correlations and no systemic bias for systolic pressure-time integral (r = 0.91, P < 0.05), diastolic pressure-time integral (r = 0.95, P < 0.05), and subendocardial viability ratio (r = 0.86, P < 0.05). These results suggest that the nonlinear transformation of wave components from the distal to the central site predicts the morphological waveform changes resulting from complex wave propagation and reflection within the cardiovascular network. The proposed wave-based approach holds promise for future applications of noninvasive devices in clinical cardiology.",
      "authors": "Tamborini Alessio; Aghilinejad Arian; Gharib Morteza",
      "year": "2025",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "doi": "10.1073/pnas.2416006122",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40009644/",
      "mesh_terms": "Humans; Machine Learning; Male; Female; Middle Aged; Aorta; Adult; Brachial Artery; Pulse Wave Analysis; Arterial Pressure; Blood Pressure; Blood Pressure Determination; Aged",
      "keywords": "aortic catheterization; central pressure waveform; cuff-based device; machine learning; transfer function",
      "pub_types": "Journal Article",
      "pmcid": "PMC11892652"
    },
    {
      "pmid": "34696767",
      "title": "Utilisation of community care services and self-rated health among elderly population in China: a survey-based analysis with propensity score matching method.",
      "abstract": "BACKGROUND: Elderly care and elderly health are the enormous challenges in such an aging society as China. Community care services have been developing rapidly in recent years in China as an increasingly mainstream care resource to promote elderly health. The purpose of this study is to examine the association between using community care services and self-rated health among Chinese elderly. METHODS: A cross-sectional survey was conducted in 2019 and 612 elderly people from China's Shaanxi province were enrolled. The binary logistic regression was first employed to explore the association between community care services utilisation and elderly health. Given the potential selection bias issue, the propensity score matching method was hired to generate comparable samples between participants who used these services and participants who didn't, and further examine the health benefits of using four types of services. RESULTS: The results of the binary logistic regression showed that the use of community care services predicted a better health status of elderly individuals. Overall, the results of the propensity score matching method showed the similar results. Specifically, with the nearest neighbors matching algorithm, using daily care services was significantly associated with a 0.246 increase in the self-rated health of the elderly (T\u2009=\u20091.83). For medical care services, the mean of self-rated health of elderly individuals who used these services was 3.542, significantly higher than those who didn't (T\u2009=\u20092.15). For spiritual comfort services, elderly individuals using these services showed a significant increase by 0.280 in the self-rated health (T\u2009=\u20091.82). For social and recreational services, the result of the nearest neighbor matching method was not statistically significant, while the results of kernel matching method and the mahalanobis matching method showed a significant increase in the self-rated health among elderly individuals using these services (T\u2009=\u20092.03, T\u2009=\u20092.03, respectively). All the estimated results passed the Rosenbaum bounds analysis and were not sensitive to hidden bias. CONCLUSIONS: Using community care services improved the self-rated health of the elderly. More effective measures may be implemented to increase access to care resources for senior citizens, and further improve their health status.",
      "authors": "Yang Liu; Wang Lijian; Di Xiaodong; Dai Xiuliang",
      "year": "2021",
      "journal": "BMC public health",
      "doi": "10.1186/s12889-021-11989-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34696767/",
      "mesh_terms": "Aged; China; Cross-Sectional Studies; Health Services; Humans; Propensity Score; Urban Population",
      "keywords": "China; Community care services utilisation; Elderly health; Propensity score matching",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8546940"
    },
    {
      "pmid": "23323800",
      "title": "Redundancy in electronic health record corpora: analysis, impact on text mining performance and mitigation strategies.",
      "abstract": "BACKGROUND: The increasing availability of Electronic Health Record (EHR) data and specifically free-text patient notes presents opportunities for phenotype extraction. Text-mining methods in particular can help disease modeling by mapping named-entities mentions to terminologies and clustering semantically related terms. EHR corpora, however, exhibit specific statistical and linguistic characteristics when compared with corpora in the biomedical literature domain. We focus on copy-and-paste redundancy: clinicians typically copy and paste information from previous notes when documenting a current patient encounter. Thus, within a longitudinal patient record, one expects to observe heavy redundancy. In this paper, we ask three research questions: (i) How can redundancy be quantified in large-scale text corpora? (ii) Conventional wisdom is that larger corpora yield better results in text mining. But how does the observed EHR redundancy affect text mining? Does such redundancy introduce a bias that distorts learned models? Or does the redundancy introduce benefits by highlighting stable and important subsets of the corpus? (iii) How can one mitigate the impact of redundancy on text mining? RESULTS: We analyze a large-scale EHR corpus and quantify redundancy both in terms of word and semantic concept repetition. We observe redundancy levels of about 30% and non-standard distribution of both words and concepts. We measure the impact of redundancy on two standard text-mining applications: collocation identification and topic modeling. We compare the results of these methods on synthetic data with controlled levels of redundancy and observe significant performance variation. Finally, we compare two mitigation strategies to avoid redundancy-induced bias: (i) a baseline strategy, keeping only the last note for each patient in the corpus; (ii) removing redundant notes with an efficient fingerprinting-based algorithm. (a)For text mining, preprocessing the EHR corpus with fingerprinting yields significantly better results. CONCLUSIONS: Before applying text-mining techniques, one must pay careful attention to the structure of the analyzed corpora. While the importance of data cleaning has been known for low-level text characteristics (e.g., encoding and spelling), high-level and difficult-to-quantify corpus characteristics, such as naturally occurring redundancy, can also hurt text mining. Fingerprinting enables text-mining techniques to leverage available data in the EHR corpus, while avoiding the bias introduced by redundancy.",
      "authors": "Cohen Raphael; Elhadad Michael; Elhadad No\u00e9mie",
      "year": "2013",
      "journal": "BMC bioinformatics",
      "doi": "10.1186/1471-2105-14-10",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23323800/",
      "mesh_terms": "Algorithms; Data Mining; Electronic Health Records; Health Records, Personal; Humans; Semantics",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC3599108"
    },
    {
      "pmid": "19694857",
      "title": "Creating case scenarios or vignettes using factorial study design methods.",
      "abstract": "AIM: This paper is a report of a study conducted to develop clinical case vignettes using an adaptation of an incomplete factorial study design methodology. BACKGROUND: In health care, vignettes or cases scenarios are core to problem-based learning, common in practice guideline development processes, and increasingly being used in patient or care-giver studies of chronic or life-threatening illnesses. A large number of behavioural, psycho-social and clinical factors can be relevant in such decision problems. Unbiased methods for choosing what factors to include are needed, when it is not possible to include all relevant combinations of factors in the vignettes. METHOD: The factors to be considered, number of levels or categories for each factor, and desired number of scenarios were decided in advance. An algorithm was used first to create the full factorial data set, and then a random subset of combinations was generated, according to predefined criteria, based on maximizing determinants. The subset of combinations was incorporated into written vignettes. The study was conducted in 2004-2005. FINDINGS: Application of the method yielded diverse and balanced scenarios that covered the full range of factors to be considered for a project to elicit health providers' processes in diet counselling for dyslipidemia. CONCLUSION: The approach is flexible, decreases possible researcher bias in the creation of vignettes, and can improve statistical power in survey research. This novel application of study design methodology merits consideration when vignettes are being developed to elicit opinions or decisions in studies of complex health issues.",
      "authors": "Brauer Paula M; Hanning Rhona M; Arocha Jose F; Royall Dawna; Goy Richard; Grant Andrew; Dietrich Linda; Martino Roselle; Horrocks Julie",
      "year": "2009",
      "journal": "Journal of advanced nursing",
      "doi": "10.1111/j.1365-2648.2009.05055.x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/19694857/",
      "mesh_terms": "Decision Making; Humans; Male; Medical Records; Middle Aged; Pilot Projects; Problem-Based Learning; Research Design",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "38864118",
      "title": "Appropriateness of Hysterectomy as Treatment for Benign Gynecological Conditions.",
      "abstract": "Objective: To assess the appropriateness of hysterectomies performed at a large tertiary health system using the 1997 RAND appropriateness classification system and an updated algorithm. Design: We abstracted structured and unstructured data from electronic medical records on patient demographics, primary indication(s) for hysterectomy, diagnosis codes associated with the hysterectomy, previous treatments, and laboratory results. Subjects: Patients aged 18-44 years. Exposure: Receipt of hysterectomy for benign and nonobstetric conditions from October 2014 to December 2017. Main Outcome Measures: Using these data, we provided a RAND-based (dichotomous: inappropriate/appropriate) and Wright-based (3-level: inappropriate/ambiguous/appropriate) appropriateness rating and characterized missing information patterns associated with inappropriate ratings. Results: We analyzed 1,829 hysterectomies across 30 nonmutually exclusive primary indications for surgery. Nearly a third (32.8%) of surgeries had only one primary indication for surgery. Using the RAND-based classifier, 31.3% of hysterectomies were rated as appropriate and 68.7% as inappropriate. Using the Wright-based algorithm, 58.1% of hysterectomies were rated as appropriate, 15.7% as ambiguous, and 26.2% as inappropriate. Missing information on diagnostic procedures was the most common characteristic related to both RAND-based (46.1%) and Wright-based (51.2%) inappropriate ratings. Conclusions: The 1997 RAND classification lacked guidance for several contemporary indications, including gender-affirming care. RAND also has an outdated requirement for diagnostic surgeries such as laparoscopies, which have decreased in practice as diagnostic imaging has improved. Sensitivity analyses suggest that inappropriate surgeries cannot all be attributed to bias from missing electronic medical record data. Accurately documenting care delivery for benign gynecological conditions is key to ensuring quality and equity in gynecological care.",
      "authors": "Wright Maya A; Kinlaw Alan C; McClurg Asha B; Carey Erin; Doll Kemi M; Vines Anissa I; Olshan Andrew F; Robinson Whitney R",
      "year": "2024",
      "journal": "Journal of women's health (2002)",
      "doi": "10.1089/jwh.2024.0142",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38864118/",
      "mesh_terms": "Humans; Female; Hysterectomy; Adult; Adolescent; Young Adult; Genital Diseases, Female; Electronic Health Records; Algorithms",
      "keywords": "abnormal uterine bleeding; benign; endometriosis; fibroids; gynecology; hysterectomy; prophylactic hysterectomy; quality improvement; quality metrics; women\u2019s health",
      "pub_types": "Journal Article",
      "pmcid": "PMC12209708"
    },
    {
      "pmid": "38124256",
      "title": "New Horizons in artificial intelligence in the healthcare of older people.",
      "abstract": "Artificial intelligence (AI) in healthcare describes algorithm-based computational techniques which manage and analyse large datasets to make inferences and predictions. There are many potential applications of AI in the care of older people, from clinical decision support systems that can support identification of delirium from clinical records to wearable devices that can predict the risk of a fall. We held four meetings of older people, clinicians and AI researchers. Three priority areas were identified for AI application in the care of older people. These included: monitoring and early diagnosis of disease, stratified care and care coordination between healthcare providers. However, the meetings also highlighted concerns that AI may exacerbate health inequity for older people through bias within AI models, lack of external validation amongst older people, infringements on privacy and autonomy, insufficient transparency of AI models and lack of safeguarding for errors. Creating effective interventions for older people requires a person-centred approach to account for the needs of older people, as well as sufficient clinical and technological governance to meet standards of generalisability, transparency and effectiveness. Education of clinicians and patients is also needed to ensure appropriate use of AI technologies, with investment in technological infrastructure required to ensure equity of access.",
      "authors": "Shiwani Taha; Relton Samuel; Evans Ruth; Kale Aditya; Heaven Anne; Clegg Andrew; Todd Oliver",
      "year": "2023",
      "journal": "Age and ageing",
      "doi": "10.1093/ageing/afad219",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38124256/",
      "mesh_terms": "Humans; Aged; Artificial Intelligence; Algorithms; Decision Support Systems, Clinical; Educational Status; Delivery of Health Care",
      "keywords": "ageing; artificial intelligence; health; older people; technology",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10733173"
    },
    {
      "pmid": "17206601",
      "title": "On modelling response propensity for dwelling unit (DU) level non-response adjustment in the Medical Expenditure Panel Survey (MEPS).",
      "abstract": "Non-response is a common problem in household sample surveys. The Medical Expenditure Panel Survey (MEPS), sponsored by the Agency for Healthcare Research and Quality (AHRQ), is a complex national probability sample survey. The survey is designed to produce annual national and regional estimates of health-care use, expenditures, sources of payment, and insurance coverage for the U.S. civilian non-institutionalized population. The MEPS sample is a sub-sample of respondents to the prior year's National Health Interview Survey (NHIS) conducted by the National Center for Health Statistics (NCHS). The MEPS, like most sample surveys, experiences unit, or total, non-response despite intensive efforts to maximize response rates. This paper summarizes research on comparing alternative approaches for modelling response propensity to compensate for dwelling unit (DU), i.e. household level non-response in the MEPS.Non-response in sample surveys is usually compensated for by some form of weighting adjustment to reduce the bias in survey estimates. To compensate for potential bias in survey estimates in the MEPS, two separate non-response adjustments are carried out. The first is an adjustment for DU level non-response at the round one interview to account for non-response among those households subsampled from NHIS for the MEPS. The second non-response adjustment is a person level adjustment to compensate for attrition across the five rounds of data collection. This paper deals only with the DU level non-response adjustment. Currently, the categorical search tree algorithm method, the chi-squared automatic interaction detector (CHAID), is used to model the response probability at the DU level and to create the non-response adjustment cells. In this study, we investigate an alternative approach, i.e. logistic regression to model the response probability. Main effects models and models with interaction terms are both evaluated. We further examine inclusion of the base weights as a covariate in the logistic models. We compare variability of weights of the two alternative response propensity approaches as well as direct use of propensity scores. The logistic regression approaches produce results similar to CHAID; however, using propensity scores from logistic models with interaction terms to form five classification groups for weight adjustment appears to perform best in terms of limiting variability and bias. Published in 2007 by John Wiley & Sons, Ltd.",
      "authors": "Wun Lap-Ming; Ezzati-Rice Trena M; Diaz-Tena Nuria; Greenblatt Janet",
      "year": "2007",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.2809",
      "url": "https://pubmed.ncbi.nlm.nih.gov/17206601/",
      "mesh_terms": "Family Characteristics; Health Care Surveys; Health Expenditures; Humans; Logistic Models; United States",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41127255",
      "title": "Ethical sourcing in the context of health data supply chain management: a value sensitive design approach.",
      "abstract": "OBJECTIVE: The Bridge2AI program is establishing rules of practice for creating ethically sourced health data repositories to support the effective use of ML/AI in biomedical and behavioral research. Given the initially undefined nature of ethically sourced data, this work concurrently developed definitions and guidelines alongside repository creation, grounded in a practical, operational framework. MATERIALS AND METHODS: A Value Sensitive Design (VSD) approach was used to explore ethical tensions across stages of health data repository development. The conceptual investigation drew from supply chain management (SCM) processes to (1) identify actors who would interact with or be affected by the data repository use and outcomes; (2) determine what values to consider (ie, traceability accountability, security); and (3) analyze and document value trade-offs (ie, balancing risks of harm to improvements in healthcare). This SCM framework provides operational guidance for managing complex, multi-source data flows with embedded bias mitigation strategies. RESULTS: This conceptual investigation identified the actors, values, and tensions that influence ethical sourcing when creating a health data repository. The SCM steps provide a scaffolding to support ethical sourcing across the pre-model stages of health data repository development. Ethical sourcing includes documenting data provenance, articulating expectations for experts, and practices for ensuring data privacy, equity, and public benefit. Challenges include risks of ethics washing and highlight the need for transparent, value-driven practices. DISCUSSION: Integrating VSD with SCM frameworks enables operationalization of ethical values, improving data integrity, mitigating biases, and enhancing trust. This approach highlights how foundational decisions influence repository quality and AI/ML system usability, addressing provenance, traceability, redundancy, and risk management central to ethical data sourcing. CONCLUSION: To create authentic, impactful health data repositories that serve public health goals, organizations must prioritize transparency, accountability, and operational frameworks like SCM that comprehensively address the complexities and risks inherent in data stewardship.",
      "authors": "Nebeker Camille; B\u00e9lisle-Pipon Jean Christophe; Collins Benjamin X; Cordes Ashley; Ferryman Kadija; McInnis Brian J; McWeeney Shannon K; Novak Laurie L; Rose Susannah; Yracheta Joseph M; Williams Ishan C; Jiang Xiaoqian; Clayton Ellen W; Malin Bradley A",
      "year": "2025",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooaf101",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41127255/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; ethically sourced; health data repository; machine learning; research ethics",
      "pub_types": "Journal Article",
      "pmcid": "PMC12539179"
    },
    {
      "pmid": "28936917",
      "title": "Scalable collaborative targeted learning for high-dimensional data.",
      "abstract": "Robust inference of a low-dimensional parameter in a large semi-parametric model relies on external estimators of infinite-dimensional features of the distribution of the data. Typically, only one of the latter is optimized for the sake of constructing a well-behaved estimator of the low-dimensional parameter of interest. Optimizing more than one of them for the sake of achieving a better bias-variance trade-off in the estimation of the parameter of interest is the core idea driving the general template of the collaborative targeted minimum loss-based estimation procedure. The original instantiation of the collaborative targeted minimum loss-based estimation template can be presented as a greedy forward stepwise collaborative targeted minimum loss-based estimation algorithm. It does not scale well when the number p of covariates increases drastically. This motivates the introduction of a novel instantiation of the collaborative targeted minimum loss-based estimation template where the covariates are pre-ordered. Its time complexity is O(p) as opposed to the original O(p2) , a remarkable gain. We propose two pre-ordering strategies and suggest a rule of thumb to develop other meaningful strategies. Because it is usually unclear a priori which pre-ordering strategy to choose, we also introduce another instantiation called SL-C-TMLE algorithm that enables the data-driven choice of the better pre-ordering strategy given the problem at hand. Its time complexity is O(p) as well. The computational burden and relative performance of these algorithms were compared in simulation studies involving fully synthetic data or partially synthetic data based on a real world large electronic health database; and in analyses of three real, large electronic health databases. In all analyses involving electronic health databases, the greedy collaborative targeted minimum loss-based estimation algorithm is unacceptably slow. Simulation studies seem to indicate that our scalable collaborative targeted minimum loss-based estimation and SL-C-TMLE algorithms work well. All C-TMLEs are publicly available in a Julia software package.",
      "authors": "Ju Cheng; Gruber Susan; Lendle Samuel D; Chambaz Antoine; Franklin Jessica M; Wyss Richard; Schneeweiss Sebastian; van der Laan Mark J",
      "year": "2019",
      "journal": "Statistical methods in medical research",
      "doi": "10.1177/0962280217729845",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28936917/",
      "mesh_terms": "Aged; Algorithms; Anti-Inflammatory Agents, Non-Steroidal; Computer Simulation; Gastrointestinal Hemorrhage; Humans; Models, Statistical; Observational Studies as Topic; Peptic Ulcer; Peptic Ulcer Perforation; Propensity Score",
      "keywords": "Observational study; electronic healthcare database; high-dimensional data; propensity score; targeted minimum loss-based estimation; variable selection",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6086775"
    },
    {
      "pmid": "39647524",
      "title": "Does Adjuvant Radiotherapy Enhance Survival in Intracranial Solitary Fibrous Tumor Patients?",
      "abstract": "OBJECTIVE: Intracranial solitary fibrous tumor is a rare central nervous system tumor that lacks a reliable prognostic clinical model. Uncertainty persists regarding the treatment outcomes of surgery and adjuvant radiotherapy (ART). To address this, we investigated the efficacy of ART and applied machine learning (ML) to develop accurate prognostic models. METHODS: The Surveillance, Epidemiology, and End Results database was used for this study's analysis. To identify the prognostic variables, we conducted Cox regression analysis and constructed prognostic models using 5 ML algorithms to predict 5-year survival. A validation method incorporating the area under the curve of the receiver operating characteristic curve was used to validate the accuracy and reliability of the models. We investigated the role of ART and surgery using Kaplan-Meier survival analysis, competing risk analysis, and Bias Reduction through Analysis of Competing Events method. RESULTS: The study population comprised 747 patients. Among them are 316 patients with \"surgery\" and 431 patients with \"surgery\u00a0+ ART.\" The therapeutic groups showed significant differences in overall survival. Multivariate Cox regression analysis revealed that older age and surgery alone were poor prognostic factors. The most significant prognostic factors were the local tumor excision, followed by lobectomy and age. CONCLUSIONS: Although ART did not lead to a substantial decrease in cancer-specific deaths, it did improve overall survival. This underscores the broader health benefits of ART, including effective management of comorbid conditions. Caution is advised when interpreting these survival benefits because of potential confounding factors in patient health and treatment management. Our web tool and ML models aid in clinical decision-making.",
      "authors": "Alshwayyat Sakhr; Kamal Haya; Alshwayyat Tala Abdulsalam; Alshwayyat Mustafa; Alkhatib Mesk; Erjan Ayah",
      "year": "2025",
      "journal": "World neurosurgery",
      "doi": "10.1016/j.wneu.2024.12.004",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39647524/",
      "mesh_terms": "Humans; Male; Female; Solitary Fibrous Tumors; Radiotherapy, Adjuvant; Middle Aged; Brain Neoplasms; Adult; Aged; SEER Program; Machine Learning; Prognosis; Young Adult; Kaplan-Meier Estimate; Treatment Outcome; Adolescent",
      "keywords": "Central nervous system neoplasms; Clinical decision-making; Machine learning; Solitary fibrous tumor; Survival analysis; Treatment outcome",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33375630",
      "title": "Recognizing Context-Aware Human Sociability Patterns Using Pervasive Monitoring for Supporting Mental Health Professionals.",
      "abstract": "Traditionally, mental health specialists monitor their patients' social behavior by applying subjective self-report questionnaires in face-to-face meetings. Usually, the application of the self-report questionnaire is limited by cognitive biases (e.g., memory bias and social desirability). As an alternative, we present a solution to detect context-aware sociability patterns and behavioral changes based on social situations inferred from ubiquitous device data. This solution does not focus on the diagnosis of mental states, but works on identifying situations of interest to specialized professionals. The proposed solution consists of an algorithm based on frequent pattern mining and complex event processing to detect periods of the day in which the individual usually socializes. Social routine recognition is performed under different context conditions to differentiate abnormal social behaviors from the variation of usual social habits. The proposed solution also can detect abnormal behavior and routine changes. This solution uses fuzzy logic to model the knowledge of the mental health specialist necessary to identify the occurrence of behavioral change. Evaluation results show that the prediction performance of the identified context-aware sociability patterns has strong positive relation (Pearson's correlation coefficient >70%) with individuals' social routine. Finally, the evaluation conducted recognized that the proposed solution leading to the identification of abnormal social behaviors and social routine changes consistently.",
      "authors": "de Moura Ivan Rodrigues; Teles Ariel Soares; Endler Markus; Coutinho Luciano Reis; da Silva E Silva Francisco Jos\u00e9",
      "year": "2020",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s21010086",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33375630/",
      "mesh_terms": "Health Personnel; Humans; Mental Health; Social Behavior; Surveys and Questionnaires",
      "keywords": "context awareness; mental health; pervasive computing; sociability; sociability pattern; social behavior",
      "pub_types": "Journal Article",
      "pmcid": "PMC7795828"
    },
    {
      "pmid": "28856493",
      "title": "Joint modeling of survival time and longitudinal outcomes with flexible random effects.",
      "abstract": "Joint models with shared Gaussian random effects have been conventionally used in analysis of longitudinal outcome and survival endpoint in biomedical or public health research. However, misspecifying the normality assumption of random effects can lead to serious bias in parameter estimation and future prediction. In this paper, we study joint models of general longitudinal outcomes and survival endpoint but allow the underlying distribution of shared random effect to be completely unknown. For inference, we propose to use a mixture of Gaussian distributions as an approximation to this unknown distribution and adopt an Expectation-Maximization (EM) algorithm for computation. Either AIC and BIC criteria are adopted for selecting the number of mixtures. We demonstrate the proposed method via a number of simulation studies. We illustrate our approach with the data from the Carolina Head and Neck Cancer Study (CHANCE).",
      "authors": "Choi Jaeun; Zeng Donglin; Olshan Andrew F; Cai Jianwen",
      "year": "2018",
      "journal": "Lifetime data analysis",
      "doi": "10.1007/s10985-017-9405-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28856493/",
      "mesh_terms": "Algorithms; Biometry; Computer Simulation; Head and Neck Neoplasms; Humans; Likelihood Functions; Linear Models; Longitudinal Studies; Normal Distribution; North Carolina; Proportional Hazards Models; Quality of Life; Survival Analysis",
      "keywords": "Gaussian mixtures; Generalized linear mixed model; Maximum likelihood estimator; Random effect; Simultaneous modeling; Stratified Cox proportional hazards model",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC5756108"
    },
    {
      "pmid": "39859000",
      "title": "Development of a Predictive Model of Occult Cancer After a Venous Thromboembolism Event Using Machine Learning: The CLOVER Study.",
      "abstract": "Background and Objectives: Venous thromboembolism (VTE) can be the first manifestation of an underlying cancer. This study aimed to develop a predictive model to assess the risk of occult cancer between 30 days and 24 months after a venous thrombotic event using machine learning (ML). Materials and Methods: We designed a case-control study nested in a cohort of patients with VTE included in a prospective registry from two Spanish hospitals between 2005 and 2021. Both clinically and ML-driven feature selection were performed to identify predictors for occult cancer. XGBoost, LightGBM, and CatBoost algorithms were used to train different prediction models, which were subsequently validated in a hold-out dataset. Results: A total of 815 patients with VTE were included (51.5% male and median age of 59). During follow-up, 56 patients (6.9%) were diagnosed with cancer. One hundred and twenty-one variables were explored for the predictive analysis. CatBoost obtained better performance metrics among the ML models analyzed. The final CatBoost model included, among the top 15 variables to predict hidden malignancy, age, gender, systolic blood pressure, heart rate, weight, chronic lung disease, D-dimer, alanine aminotransferase, hemoglobin, serum creatinine, cholesterol, platelets, triglycerides, leukocyte count and previous VTE. The model had an ROC-AUC of 0.86 (95% CI, 0.83-0.87) in the test set. Sensitivity, specificity, and negative and positive predictive values were 62%, 94%, 93% and 75%, respectively. Conclusions: This is the first risk score developed for identifying patients with VTE who are at increased risk of occult cancer using ML tools, obtaining a remarkably high diagnostic accuracy. This study's limitations include potential information bias from electronic health records and a small cancer sample size. In addition, variability in detection protocols and evolving clinical practices may affect model accuracy. Our score needs external validation.",
      "authors": "Franco-Moreno Anabel; Madro\u00f1al-Cerezo Elena; de Ancos-Aracil Cristina Luc\u00eda; Farf\u00e1n-Sedano Ana Isabel; Mu\u00f1oz-Rivas Nuria; Bascu\u00f1ana Morej\u00f3n-Gir\u00f3n Jos\u00e9; Ruiz-Giard\u00edn Jos\u00e9 Manuel; \u00c1lvarez-Rodr\u00edguez Federico; Prada-Alonso Jes\u00fas; Gala-Garc\u00eda Yvonne; Casado-Suela Miguel \u00c1ngel; Bustamante-Fermosel Ana; Alfaro-Fern\u00e1ndez Nuria; Torres-Macho Juan",
      "year": "2024",
      "journal": "Medicina (Kaunas, Lithuania)",
      "doi": "10.3390/medicina61010018",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39859000/",
      "mesh_terms": "Humans; Male; Machine Learning; Venous Thromboembolism; Middle Aged; Female; Case-Control Studies; Aged; Prospective Studies; Spain; Risk Assessment; ROC Curve; Risk Factors; Neoplasms; Adult; Neoplasms, Unknown Primary; Registries",
      "keywords": "early detection of cancer; machine learning; occult malignancy; predictive model; venous thromboembolism",
      "pub_types": "Journal Article",
      "pmcid": "PMC11766885"
    },
    {
      "pmid": "38517194",
      "title": "Determination of minimum inhibitory concentrations using machine-learning-assisted agar dilution.",
      "abstract": "UNLABELLED: Effective policy to address the global threat of antimicrobial resistance requires robust antimicrobial susceptibility data. Traditional methods for measuring minimum inhibitory concentration (MIC) are resource intensive, subject to human error, and require considerable infrastructure. AIgarMIC streamlines and standardizes MIC measurement and is especially valuable for large-scale surveillance activities. MICs were measured using agar dilution for n = 10 antibiotics against clinical Enterobacterales isolates (n = 1,086) obtained from a large tertiary hospital microbiology laboratory. Escherichia coli (n = 827, 76%) was the most common organism. Photographs of agar plates were divided into smaller images covering one inoculation site. A labeled data set of colony images was created and used to train a convolutional neural network to classify images based on whether a bacterial colony was present (first-step model). If growth was present, a second-step model determined whether colony morphology suggested antimicrobial growth inhibition. The ability of the AI to determine MIC was then compared with standard visual determination. The first-step model classified bacterial growth as present/absent with 94.3% accuracy. The second-step model classified colonies as \"inhibited\" or \"good growth\" with 88.6% accuracy. For the determination of MIC, the rate of essential agreement was 98.9% (644/651), with a bias of -7.8%, compared with manual annotation. AIgarMIC uses artificial intelligence to automate endpoint assessments for agar dilution and potentially increases throughput without bespoke equipment. AIgarMIC reduces laboratory barriers to generating high-quality MIC data that can be used for large-scale surveillance programs. IMPORTANCE: This research uses modern artificial intelligence and machine-learning approaches to standardize and automate the interpretation of agar dilution minimum inhibitory concentration testing. Artificial intelligence is currently of significant topical interest to researchers and clinicians. In our manuscript, we demonstrate a use-case in the microbiology laboratory and present validation data for the model's performance against manual interpretation.",
      "authors": "Gerada Alessandro; Harper Nicholas; Howard Alex; Reza Nada; Hope William",
      "year": "2024",
      "journal": "Microbiology spectrum",
      "doi": "10.1128/spectrum.04209-23",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38517194/",
      "mesh_terms": "Microbial Sensitivity Tests; Machine Learning; Anti-Bacterial Agents; Humans; Agar; Escherichia coli; Enterobacteriaceae; Neural Networks, Computer",
      "keywords": "antimicrobial resistance; artificial intelligence; assay validation; digital health; image recognition; laboratory software; machine learning; minimum inhibitory concentration",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC11064640"
    },
    {
      "pmid": "38988507",
      "title": "Neural activity during inhibitory control predicts suicidal ideation with machine learning.",
      "abstract": "Suicide is a leading cause of death in the US and worldwide. Current strategies for preventing suicide are often focused on the identification and treatment of risk factors, especially suicidal ideation (SI). Hence, developing data-driven biomarkers of SI may be key for suicide prevention and intervention. Prior attempts at biomarker-based prediction models for SI have primarily used expensive neuroimaging technologies, yet clinically scalable and affordable biomarkers remain elusive. Here, we investigated the classification of SI using machine learning (ML) on a dataset of 76 subjects with and without SI(+/-) (n\u2009=\u200938 each), who completed a neuro-cognitive assessment session synchronized with electroencephalography (EEG). SI+/- groups were matched for age, sex, and mental health symptoms of depression and anxiety. EEG was recorded at rest and while subjects engaged in four cognitive tasks of inhibitory control, interference processing, working memory, and emotion bias. We parsed EEG signals in physiologically relevant theta (4-8\u2009Hz), alpha (8-13\u2009Hz), and beta (13-30\u2009Hz) frequencies and performed cortical source imaging on the neural signals. These data served as SI predictors in ML models. The best ML model was obtained for beta band power during the inhibitory control (IC) task, demonstrating high sensitivity (89%), specificity (98%). Shapley explainer plots further showed top neural predictors as feedback-related power in the visual and posterior default mode networks and response-related power in the ventral attention, fronto-parietal, and sensory-motor networks. We further tested the external validity of the model in an independent clinically depressed sample (n\u2009=\u200935, 12 SI+) that engaged in an adaptive test version of the IC task, demonstrating 50% sensitivity and 61% specificity in this sample. Overall, the study suggests a promising, scalable EEG-based biomarker approach to predict SI that may serve as a target for risk identification and intervention.",
      "authors": "Nan Jason; Grennan Gillian; Ravichandran Soumya; Ramanathan Dhakshin; Mishra Jyoti",
      "year": "2024",
      "journal": "NPP - digital psychiatry and neuroscience",
      "doi": "10.1038/s44277-024-00012-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38988507/",
      "mesh_terms": "",
      "keywords": "Predictive markers; Psychiatric disorders",
      "pub_types": "Journal Article",
      "pmcid": "PMC11230903"
    },
    {
      "pmid": "36016703",
      "title": "Perceptions of Canadian vascular surgeons toward artificial intelligence and machine learning.",
      "abstract": "BACKGROUND: Artificial intelligence (AI) and machine learning (ML) are rapidly advancing fields with increasing utility in health care. We conducted a survey to determine the perceptions of Canadian vascular surgeons toward AI/ML. METHODS: An online questionnaire was distributed to 162 members of the Canadian Society for Vascular Surgery. Self-reported knowledge, attitudes, and perceptions with respect to potential applications, limitations, and facilitators of AI/ML were assessed. RESULTS: Overall, 50 of the 162 Canadian vascular surgeons (31%) responded to the survey. Most respondents were aged 30 to 59\u00a0years (72%), male (80%), and White (67%) and practiced in academic settings (72%). One half of the participants reported that their knowledge of AI/ML was poor or very poor. Most were excited or very excited about AI/ML (66%) and were interested or very interested in learning more about the field (83.7%). The respondents believed that AI/ML would be useful or very useful for diagnosis (62%), prognosis (72%), patient selection (56%), image analysis (64%), intraoperative guidance (52%), research (88%), and education (80%). The limitations that the participants were most concerned about were errors leading to patient harm (42%), bias based on patient demographics (42%), and lack of clinician knowledge and skills in AI/ML (40%). Most were not concerned or were mildly concerned about job replacement (86%). The factors that were most important to encouraging clinicians to use AI/ML models were improvements in efficiency (88%), accurate predictions (84%), and ease of use (84%). The comments from respondents focused on the pressing need for the implementation of AI/ML in vascular surgery owing to the potential to improve care delivery. CONCLUSIONS: Canadian vascular surgeons have positive views on AI/ML and believe this technology can be applied to multiple aspects of the specialty to improve patient care, research, and education. Current self-reported knowledge is poor, although interest was expressed in learning more about the field. The facilitators and barriers to the effective use of AI/ML identified in the present study can guide future development of these tools in vascular surgery.",
      "authors": "Li Ben; de Mestral Charles; Mamdani Muhammad; Al-Omran Mohammed",
      "year": "2022",
      "journal": "Journal of vascular surgery cases and innovative techniques",
      "doi": "10.1016/j.jvscit.2022.06.018",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36016703/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Machine learning; Perceptions; Survey; Vascular surgery",
      "pub_types": "Journal Article",
      "pmcid": "PMC9396444"
    },
    {
      "pmid": "35893436",
      "title": "Prediction of Influenza Complications: Development and Validation of a Machine Learning Prediction Model to Improve and Expand the Identification of Vaccine-Hesitant Patients at Risk of Severe Influenza Complications.",
      "abstract": "Influenza vaccinations are recommended for high-risk individuals, but few population-based strategies exist to identify individual risks. Patient-level data from unvaccinated individuals, stratified into retrospective cases (n = 111,022) and controls (n = 2,207,714), informed a machine learning model designed to create an influenza risk score; the model was called the Geisinger Flu-Complications Flag (GFlu-CxFlag). The flag was created and validated on a cohort of 604,389 unique individuals. Risk scores were generated for influenza cases; the complication rate for individuals without influenza was estimated to adjust for unrelated complications. Shapley values were used to examine the model\u2019s correctness and demonstrate its dependence on different features. Bias was assessed for race and sex. Inverse propensity weighting was used in the derivation stage to correct for biases. The GFlu-CxFlag model was compared to the pre-existing Medial EarlySign Flu Algomarker and existing risk guidelines that describe high-risk patients who would benefit from influenza vaccination. The GFlu-CxFlag outperformed other traditional risk-based models; the area under curve (AUC) was 0.786 [0.783\u22120.789], compared with 0.694 [0.690\u22120.698] (p-value < 0.00001). The presence of acute and chronic respiratory diseases, age, and previous emergency department visits contributed most to the GFlu-CxFlag model\u2019s prediction. When higher numerical scores were assigned to more severe complications, the GFlu-CxFlag AUC increased to 0.828 [0.823\u22120.833], with excellent discrimination in the final model used to perform the risk stratification of the population. The GFlu-CxFlag can better identify high-risk individuals than existing models based on vaccination guidelines, thus creating a population-based risk stratification for individual risk assessment and deployment in vaccine hesitancy reduction programs in our health system.",
      "authors": "Wolk Donna M; Lanyado Alon; Tice Ann Marie; Shermohammed Maheen; Kinar Yaron; Goren Amir; Chabris Christopher F; Meyer Michelle N; Shoshan Avi; Abedi Vida",
      "year": "2022",
      "journal": "Journal of clinical medicine",
      "doi": "10.3390/jcm11154342",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35893436/",
      "mesh_terms": "",
      "keywords": "Clinical Lab 2.0; EHR; RT-PCR; decision support; electronic medical records; influenza; machine learning; precision medicine; risk stratification; vaccine",
      "pub_types": "Journal Article",
      "pmcid": "PMC9332321"
    },
    {
      "pmid": "27057328",
      "title": "Global network for women's and children's health research: a system for low-resource areas to determine probable causes of stillbirth, neonatal, and maternal death.",
      "abstract": "BACKGROUND: Determining cause of death is needed to develop strategies to reduce maternal death, stillbirth, and newborn death, especially for low-resource settings where 98% of deaths occur. Most existing classification systems are designed for high income settings where extensive testing is available. Verbal autopsy or audits, developed as an alternative, are time-intensive and not generally feasible for population-based evaluation. Furthermore, because most classification is user-dependent, reliability of classification varies over time and across settings. Thus, we sought to develop classification systems for maternal, fetal and newborn mortality based on minimal data to produce reliable cause-of-death estimates for low-resource settings. RESULTS: In six low-resource countries (India, Pakistan, Guatemala, DRC, Zambia and Kenya), we evaluated data which are collected routinely at antenatal care and delivery and could be obtained with interview, observation, or basic equipment from the mother, lay-health provider or family to inform causes of death. Using these basic data collected in a standard way, we then developed an algorithm to assign cause of death that could be computer-programmed. Causes of death for maternal (trauma, abortion, hemorrhage, infection and hypertensive disease of pregnancy), stillbirth (birth trauma, congenital anomaly, infection, asphyxia, complications of preterm birth) and neonatal death (congenital anomaly, infection, asphyxia, complications of preterm birth) are based on existing cause of death classifications, and compatible with the World Health Organization International Classification of Disease system. CONCLUSIONS: Our system to assign cause of maternal, fetal and neonatal death uses basic data from family or lay-health providers to assign cause of death by an algorithm to eliminate a source of inconsistency and bias. The major strengths are consistency, transparency, and comparability across time or regions with minimal burden on the healthcare system. This system will be an important contribution to determining cause of death in low-resource settings.",
      "authors": "McClure Elizabeth M; Bose Carl L; Garces Ana; Esamai Fabian; Goudar Shivaprasad S; Patel Archana; Chomba Elwyn; Pasha Omrana; Tshefu Antoinette; Kodkany Bhalchandra S; Saleem Sarah; Carlo Waldemar A; Derman Richard J; Hibberd Patricia L; Liechty Edward A; Hambidge K Michael; Krebs Nancy F; Bauserman Melissa; Koso-Thomas Marion; Moore Janet; Wallace Dennis D; Jobe Alan H; Goldenberg Robert L",
      "year": "2015",
      "journal": "Maternal health, neonatology and perinatology",
      "doi": "10.1186/s40748-015-0012-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27057328/",
      "mesh_terms": "",
      "keywords": "Cause of death classification; Low-income Countries; Maternal mortality; Neonatal mortality; Stillbirth",
      "pub_types": "Journal Article",
      "pmcid": "PMC4823684"
    },
    {
      "pmid": "30392702",
      "title": "French administrative health care database (SNDS): The value of its enrichment.",
      "abstract": "SNIIRAM/SNDS, the French administrative health care database, covers around 99% of the population. Its main limitation is the absence of clinical information and biological results. This report exposes the value of SNIIRAM/SNDS enrichment by external databases, and the linkage issues. It is illustrated by examples: the well-known population-based cohort CONSTANCES created to answer to epidemiological research questions with a specific interest on occupational and social factors, chronic diseases, and aging; the CANARI study, a regional-based study that collected Gleason score in all pathology laboratories in Brittany and then, linked pathology results to an ad hoc extraction from SNIIRAM database; the goal was to investigate the risk of high grade prostate cancer in patients treated by 5-alpha-reductase inhibitors for a symptomatic benign prostatic hyperplasia; the SACHA study, that identified and medically validated major bleeding event referred to emergency wards, then linked those clinical data to SNIIRAM; the goal was to minimize misclassification bias when estimating bleeding risk in patients who were prescribed antithrombotic drugs; the ISO-PSY study linked the SNIIRAM with the national cause of death registry (C\u00e9piDc) and the nationwide emergency department surveillance system (OSCOUR\u00ae network) to investigate the potential link between isotretinoin and suicidal risk; the EFEMERIS cohort that assesses drugs prescriptions in French pregnant women who delivered in the Haute-Garonne region; the EPI-GETB-AM study that derived a SNIIRAM/SNDS-based algorithm to identify venous thromboembolism and linked SNIIRAM/SNDS to the EPI-GETBO-III survey for validation. Another perspective of SNDS enrichment is clinical trials' data for medico-economic assessment, and extended follow-up without attrition bias. Linkage is not straightforward. Apart from regulatory approbation and authorized data center issues, which could be solved by the Health Data Hub Initiative, a multidisciplinary team with medical, pharmacological and methodological knowledge, as well as with technical skills is essential to handle the whole process.",
      "authors": "Scailteux Lucie-Marie; Droitcourt Catherine; Balusson Fr\u00e9d\u00e9ric; Nowak Emmanuel; Kerbrat Sandrine; Dupuy Alain; Drezen Erwan; Happe Andr\u00e9; Oger Emmanuel",
      "year": "2019",
      "journal": "Therapie",
      "doi": "10.1016/j.therap.2018.09.072",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30392702/",
      "mesh_terms": "Algorithms; Databases, Factual; Delivery of Health Care; Emergency Service, Hospital; Epidemiologic Research Design; France; Humans; Medical Record Linkage; Registries",
      "keywords": "Administrative database; Linkage; Matching; Population-based study; SNDS; SNIIRAM",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40030473",
      "title": "Detecting Opioid Use Disorder in Health Claims Data With Positive Unlabeled Learning.",
      "abstract": "Accurate detection and prevalence estimation of behavioral health conditions, such as opioid use disorder (OUD), are crucial for identifying at-risk individuals, determining treatment needs, monitoring prevention and intervention efforts, and recruiting treatment-naive participants for clinical trials. The availability of extensive health data, combined with advancements in machine learning (ML) frameworks, has enabled researchers to employ various ML techniques to predict or identify OUD within patient health data. Ideally, we could directly estimate the prevalence, or the proportion of a population with a condition over time. However, underdiagnosis and undercoding of conditions in patient health records make it challenging to determine the true prevalence of these conditions and to identify at-risk patients with less severe conditions who are more likely to be missed. Consequently, patients without diagnoses may comprise positive and negative examples for a given condition. Treating all undiagnosed (uncoded) patients as negative when applying ML methods can introduce bias into models, affecting their predictive power. To address this issue, we employed Positive Unlabeled Learning Selected Not At Random (PULSNAR), a Positive and Unlabeled (PU) learning technique, to estimate the probability of a given patient having OUD during a time window and the overall population prevalence of OUD. In a sample of 3,342,044 commercially insured US patients with at least one opioid prescription filled, PULSNAR estimated that 5.08% of patients have a cumulative prevalence of OUD over a 2-5 a observation period, compared to the 1.35% with a recorded OUD diagnosis, with 73.5% of cases not diagnosed/coded. The prevalence estimates provided by PULSNAR are consistent with those reported in other studies.",
      "authors": "Kumar Praveen; Moomtaheen Fariha; Malec Scott A; Yang Jeremy J; Bologa Cristian G; Schneider Kristan A; Zhu Yiliang; Tohen Mauricio; Villarreal Gerardo; Perkins Douglas J; Fielstein Elliot M; Davis Sharon E; Matheny Michael E; Lambert Christophe G",
      "year": "2025",
      "journal": "IEEE journal of biomedical and health informatics",
      "doi": "10.1109/JBHI.2024.3515805",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40030473/",
      "mesh_terms": "Humans; Opioid-Related Disorders; Machine Learning; Male; Female; Adult; Middle Aged; Young Adult; Insurance Claim Review; Electronic Health Records; Prevalence",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC11971012"
    },
    {
      "pmid": "29621255",
      "title": "Empirical estimation of life expectancy from a linked health database of adults who entered care for HIV.",
      "abstract": "BACKGROUND: While combination antiretroviral therapy (cART) has significantly improved survival times for persons diagnosed with HIV, estimation of life expectancy (LE) for this cohort remains a challenge, as mortality rates are a function of both time since diagnosis and age, and mortality rates for the oldest age groups may not be available. METHODS: A validated case-finding algorithm for HIV was used to update the cohort of HIV-positive adults who had entered care in Ontario, Canada as of 2012. The Chiang II abridged life table algorithm was modified to use mortality rates stratified by time since entering the cohort and to include various methods for extrapolation of the excess HIV mortality rates to older age groups. RESULTS: As of 2012, there were approximately 15,000 adults in care for HIV in Ontario. The crude all-cause mortality rate declined from 2.6% (95%CI 2.3, 2.9) per year in 2000 to 1.3% (1.2, 1.5) in 2012. Mortality rates were elevated for the first year of care compared to subsequent years (rate ratio of 2.6 (95% CI 2.3, 3.1)). LE for a 20-year old living in Ontario was 62 years (expected age at death is 82), while LE for a 20-year old with HIV was estimated to be reduced to 47 years, for a loss of 15 years of life. Ignoring the higher mortality rates among new cases introduced a modest bias of 1.5 additional years of life lost. In comparison, using 55+ as the open-ended age group was a major source of bias, adding 11 years to the calculated LE. CONCLUSIONS: Use of age limits less than the expected age at death for the open-ended age group significantly overstates the estimated LE and is not recommended. The Chiang II method easily accommodated input of stratified mortality rates and extrapolation of excess mortality rates.",
      "authors": "Schanzer Dena; Antoniou Tony; Kwong Jeffrey; Timmerman Karen; Yan Ping",
      "year": "2018",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0195031",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29621255/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Cause of Death; Databases, Factual; Female; HIV Infections; History, 20th Century; History, 21st Century; Humans; Incidence; Life Expectancy; Life Tables; Male; Middle Aged; Ontario; Prevalence; Public Health Surveillance; Young Adult",
      "keywords": "",
      "pub_types": "Historical Article; Journal Article",
      "pmcid": "PMC5886421"
    },
    {
      "pmid": "15596685",
      "title": "Validity of the American Thoracic Society and other spirometric algorithms using FVC and forced expiratory volume at 6 s for predicting a reduced total lung capacity.",
      "abstract": "OBJECTIVES: (1) To compare the performance of three spirometric algorithms developed to predict whether the total lung capacity (TLC) is reduced vs normal or increased, (2) to determine if forced expiratory volume at 6 s (FEV(6)) can be substituted for FVC in these algorithms, and (3) to determine if ascertainment bias was present in patients referred for the measurement of spirometry and TLC compared to patients referred for spirometry only. METHODS: We analyzed the results of 219 consenting consecutive patients referred to a New Zealand tertiary hospital respiratory laboratory for spirometry and TLC measurements. Spirometry results from 370 patients referred for spirometry but not lung volumes were used to test for potential ascertainment bias. Spirometry results were analyzed using the lower limit of normal (LLN) values from the third National Health and Nutrition Examination Study reference equations. The equations of Goldman and Becklake, and Crapo were used to classify TLC as normal or abnormal. Receiver operator characteristic curves were used to produce an algorithm using the LLN for FVC and FEV(6). The performances of previous algorithms and our own algorithms were analyzed for predicting a reduced lung volume against the \"gold standard,\" plethysmographic TLC. RESULTS: All three algorithms predicted a reduced TLC with an accuracy of approximately 50%. In contrast, all algorithms predicted TLC was either normal or increased with an accuracy of > or = 99% regardless of the reference set used. The algorithms based on FEV(6) performed equally as well as the FVC algorithms. No ascertainment bias was found. CONCLUSIONS: This study provides evidence that spirometry-based algorithms can accurately predict when TLC is either normal or increased, and can also increase the a priori probability that TLC is reduced to approximately 50%. FEV(6) is equivalent to FVC in these predictions.",
      "authors": "Swanney Maureen P; Beckert Lutz E; Frampton Chris M; Wallace Lauren A; Jensen Robert L; Crapo Robert O",
      "year": "2004",
      "journal": "Chest",
      "doi": "10.1378/chest.126.6.1861",
      "url": "https://pubmed.ncbi.nlm.nih.gov/15596685/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Algorithms; Female; Forced Expiratory Volume; Humans; Lung Diseases, Obstructive; Male; Middle Aged; Predictive Value of Tests; ROC Curve; Reproducibility of Results; Sensitivity and Specificity; Spirometry; Total Lung Capacity; Vital Capacity",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40874843",
      "title": "DeePosit, an AI-based tool for detecting mouse urine and fecal depositions from thermal video clips of behavioral experiments.",
      "abstract": "In many mammals, including rodents, social interactions are often accompanied by active urination (micturition), which is considered a mechanism for spatial scent marking. Urine and fecal deposits contain a variety of chemosensory signals that convey information about the individual's identity, genetic strain, social rank, and physiological or hormonal state. Furthermore, scent marking has been shown to be influenced by the social context and by the individual's internal state and experience. Therefore, analyzing scent-marking behavior during social interactions can provide valuable insight into the structure of mammalian social interactions in health and disease. However, conducting such analyses has been hindered by several technical challenges. For example, the widely used void spot assay lacks temporal resolution and is prone to artifacts, such as urine smearing. To solve these issues, recent studies employed thermal imaging for the spatio-temporal analysis of urination activity. However, this method involved manual analysis, which is time-consuming and susceptible to observer bias. Moreover, defecation activity was hardly analyzed by previous studies. In the present study, we integrate thermal imaging with an open-source algorithm based on a transformer-based video classifier for automatic detection and classification of urine and fecal deposits made by male and female mice during various social behavior assays. Our results reveal distinct dynamics of urination and defecation in a test-, strain-, and sex-dependent manner, indicating two separate processes of scent marking in mice. We validate this algorithm, termed by us DeePosit, and show that its accuracy is comparable to that of a human annotator and that it is efficient in various setups and conditions. Thus, the method and tools introduced here enable efficient and unbiased automatic spatio-temporal analysis of scent-marking behavior in the context of behavioral experiments in small rodents.",
      "authors": "Peles David; Netser Shai; Ray Natalie; Suliman Taghreed; Wagner Shlomo",
      "year": "2025",
      "journal": "eLife",
      "doi": "10.7554/eLife.100739",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40874843/",
      "mesh_terms": "Animals; Feces; Mice; Male; Female; Urine; Behavior, Animal; Video Recording; Urination; Odorants; Social Behavior; Defecation; Artificial Intelligence",
      "keywords": "fecal deposition; machine learning; micturition; mouse; neuroscience; social behavior; thermal imaging; urination",
      "pub_types": "Journal Article",
      "pmcid": "PMC12393880"
    },
    {
      "pmid": "39644580",
      "title": "ToxSTK: A multi-target toxicity assessment utilizing molecular structure and stacking ensemble learning.",
      "abstract": "Drug registration requires risk assessment of new active pharmaceutical ingredients or excipients to ensure they are safe for human health and the environment. However, traditional risk assessment is expensive and relies heavily on animal testing. Machine learning (ML) has been used as a risk assessment tool, providing less time, money, and involved animals than in vivo experiments. Despite that, the ML models often rely on a single model, which may introduce bias and unreliable prediction. Stacking ensemble learning is an ML framework that makes predictions based on multimodal outcomes. This framework performs well in quantitative structure-activity relationship (QSAR) studies. In this study, we developed ToxSTK, a multi-target toxicity assessment using stacking ensemble learning. We aimed to create an ML tool that facilitates toxicity assessments more affordably with reduced reliance on animal models. We focused on four key targets generally assessed in early-stage drug development: hERG toxicity, mTOR toxicity, PBMCs toxicity, and mutagenicity. Our model integrated 12 molecular fingerprints with 3\u00a0ML algorithms, generating 36 novel predictive features (PFs). These PFs were then combined to construct the final meta-decision model. Our results demonstrated that the ToxSTK model surpasses standard regression and classification metrics, ensuring it is highly reliable and accurate in predicting chemical toxicities within its application domain. This model passed the y-randomization test, confirming that the identified QSAR is robust and not due to random chance. Additionally, this model outperforms the existing ML methods for these endpoints, suggesting its effectiveness for risk assessment applications. We recommend incorporating this stacking ensemble learning framework into the chemical risk assessment pipeline to improve model generalization, accuracy, robustness, and reliability.",
      "authors": "Boonsom Surapong; Chamnansil Panisara; Boonseng Sarote; Srisongkram Tarapong",
      "year": "2025",
      "journal": "Computers in biology and medicine",
      "doi": "10.1016/j.compbiomed.2024.109480",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39644580/",
      "mesh_terms": "Machine Learning; Quantitative Structure-Activity Relationship; Humans; Risk Assessment; Animals; Toxicity Tests; Ensemble Learning",
      "keywords": "Machine learning; Multitarget toxicity assessment; Risk assessment; Stacking ensemble learning",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36737010",
      "title": "Development of an integrated machine-learning and data assimilation framework for NOx emission inversion.",
      "abstract": "As major air pollutants, nitrogen oxides (NOx, mainly comprising NO and NO2) not only have adverse effects on human health but also contribute to the formation of secondary pollutants, such as ozone and particulate nitrate. To acquire reasonable NOx simulation results for further analysis, a reasonable emission inventory is needed for three-dimensional chemical transport models (3D-CTMs). In this study, a comprehensive emission adjustment framework for NOx emission, which integrates the simulation results of the 3D-CTM, surface NO2 measurements, the three-dimensional variational data assimilation method, and an ensemble back propagation neural network, was proposed and applied to correct NOx emissions over China for the summers of 2015 and 2020. Compared with the simulation using prior NOx emissions, the root-mean-square error, normalized mean error, and normalized mean bias decreased by approximately 40 %, 40 %, and 60 % in NO2 simulation using posterior NOx emissions corrected by the framework proposed in this work. Compared with the emissions for 2015, the NOx emission generally decreased by an average of 5 % in the simulation domain for 2020, especially in Henan and Anhui provinces, where the percentage reductions reached 24 % and 19 %, respectively. The proposed framework is sufficiently flexible to correct emissions in other periods and regions. The framework can provide reliable and up-to-date emission information and can thus contribute to both scientific research and policy development relating to NOx pollution.",
      "authors": "Chen Yiang; Fung Jimmy C H; Yuan Dehao; Chen Wanying; Fung Tung; Lu Xingcheng",
      "year": "2023",
      "journal": "The Science of the total environment",
      "doi": "10.1016/j.scitotenv.2023.161951",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36737010/",
      "mesh_terms": "",
      "keywords": "3D-Var data assimilation method; Emission inversion; Machine learning; NO(x) emissions; WRF-CAMx",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38015925",
      "title": "Automated cell counting for Trypan blue-stained cell cultures using machine learning.",
      "abstract": "Cell counting is a vital practice in the maintenance and manipulation of cell cultures. It is a crucial aspect of assessing cell viability and determining proliferation rates, which are integral to maintaining the health and functionality of a culture. Additionally, it is critical for establishing the time of infection in bioreactors and monitoring cell culture response to targeted infection over time. However, when cell counting is performed manually, the time involved can become substantial, particularly when multiple cultures need to be handled in parallel. Automated cell counters, which enable significant time reduction, are commercially available but remain relatively expensive. Here, we present a machine learning (ML) model based on YOLOv4 that is able to perform cell counts with a high accuracy (>95%) for Trypan blue-stained insect cells. Images of two distinctly different cell lines, Trichoplusia ni (High FiveTM; Hi5 cells) and Spodoptera frugiperda (Sf9), were used for training, validation, and testing of the model. The ML model yielded F1 scores of 0.97 and 0.96 for alive and dead cells, respectively, which represents a substantially improved performance over that of other cell counters. Furthermore, the ML model is versatile, as an F1 score of 0.96 was also obtained on images of Trypan blue-stained human embryonic kidney (HEK) cells that the model had not been trained on. Our implementation of the ML model comes with a straightforward user interface and can image in batches, which makes it highly suitable for the evaluation of multiple parallel cultures (e.g. in Design of Experiments). Overall, this approach for accurate classification of cells provides a fast, bias-free alternative to manual counting.",
      "authors": "Kuijpers Louis; van Veen Edo; van der Pol Leo A; Dekker Nynke H",
      "year": "2023",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0291625",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38015925/",
      "mesh_terms": "Animals; Humans; Trypan Blue; Cell Count; Cell Culture Techniques; Cell Line; Spodoptera",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10684072"
    },
    {
      "pmid": "41262821",
      "title": "From Design to Closure: Artificial Intelligence Transforming Clinical Research.",
      "abstract": "Clinical research is essential as it advances medical innovation, from developing new treatments and improving existing ones for additional disease indications\u00a0to creating better processes and the availability of medical devices, yet traditional trial methods are often slow, costly, and full of challenges. Over the past decade, the use of artificial intelligence (AI) and machine learning (ML) has evolved across all phases of the clinical research cycle, from study design and planning to initiation, conduct, and closure. This editorial explores how AI can create new opportunities to enhance patient recruitment, optimize trial design, improve dose adherence and participant retention, strengthen safety monitoring, and enable advanced data analysis. It also highlights key challenges associated with the use of AI/ML, including selection bias, privacy, ethical considerations, and regulatory compliance. Since these tools generate\u00a0outputs based on trained datasets, issues like data drift must be carefully managed to ensure ongoing accuracy and reliability. By recognizing both opportunities and challenges of using AI/ML across all stages of clinical research, we have proposed potential solutions to help overcome these challenges and promote responsible adoption of this new technological era. Responsible deployment and rigorous validation are essential; although hybrid approaches combine AI-driven insights with human oversight, these technologies can improve trial efficiency, improve patient outcomes, and accelerate development of novel therapies, while ensuring that accountability, safety, and ethical integrity remain firmly with humans. This editorial provides a roadmap for integrating responsible use of AI into clinical trials, ensuring ethical integrity, regulatory alignment, and trust, so that AI ultimately strengthens trial outcomes and benefits the patients these studies are designed to serve.",
      "authors": "Vats Kanika; Alam Mohammad Mazhar",
      "year": "2025",
      "journal": "Cureus",
      "doi": "10.7759/cureus.94895",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41262821/",
      "mesh_terms": "",
      "keywords": "artificial intelligence (ai); clinical research; clinical trial; data monitoring; digital health; machine learning; participant recruitment; safety monitoring; trial design; trial efficiency",
      "pub_types": "Editorial",
      "pmcid": "PMC12624242"
    },
    {
      "pmid": "27747831",
      "title": "Improving the Identification of Out-of-Hospital Sudden Cardiac Deaths in a General Practice Research Database.",
      "abstract": "BACKGROUND: The ascertainment of sudden cardiac death (SCD) in electronic health databases is challenging. OBJECTIVES: Our objective was to evaluate the applicability of the validated computer definition of SCD developed by Chung et al. in a retrospective study of SCD and domperidone exposure in the Clinical Practice Research Datalink (CPRD). METHODS: We assessed out-of-hospital SCD by applying the validated computer definition and linking data with Hospital Episode Statistics and death certificates. We developed a separate algorithm to identify end-of-life care in noninstitutionalized patients and excluded associated deaths from the analysis to address their misclassification as SCD. RESULTS: Of the 681,104 patients in the study cohort, 3444 were initially classified as out-of-hospital SCD. Next, 163 deaths were identified as expected deaths by our algorithm for end-of-life home care. After review of patient profiles, 162 were classified as expected deaths because of evidence that the patient received palliative or end-of-life care, but one was a false negative. The exclusion of such cases appreciably changed the odds ratio for current exposure to domperidone compared with non-use of study medications from 2.09 (95\u00a0% confidence interval [CI] 1.16-3.74) to 1.71 (95\u00a0% CI 0.92-3.18). A similar effect on the odds ratio was observed for current exposure to metoclopramide but not to proton pump inhibitors. CONCLUSIONS: Our algorithm to identify end-of-life care at home in the CPRD performed well, with only one false negative. The exclusion of misclassified cases of SCD reduced the magnitude of the odds ratios for SCD associated with domperidone and metoclopramide exposure by controlling protopathic bias.",
      "authors": "Varas-Lorenzo Cristina; Arana Alejandro; Johannes Catherine B; McQuay Lisa J; Rothman Kenneth J; Fife Daniel",
      "year": "2016",
      "journal": "Drugs - real world outcomes",
      "doi": "10.1007/s40801-016-0086-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27747831/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC5042942"
    },
    {
      "pmid": "40951919",
      "title": "Association between shift work and brain age gap: a neuroimaging study using MRI-based brain age prediction algorithms.",
      "abstract": "BACKGROUND: Shift work is increasingly common and associated with numerous adverse health effects. Although studies show that shift work affects brain structure and neurological stress, its direct impact on brain aging remains unclear. Therefore, this study aims to investigate the association between shift work and brain aging using the brain age gap (BAG)-a neuroimaging biomarker calculated by comparing predicted brain age derived from structural magnetic resonance imaging (MRI) scans to chronological age. METHODS: Structural MRI data (T1-weighted and T2-weighted) were collected from 113 healthcare workers, including 33 shift workers and 80 fixed daytime workers. Brain age was estimated using seven validated machine learning models. BAG was calculated as the difference between predicted brain age and chronological age. Statistical analyses, including ANCOVA, adjusted for chronological age, sex, intracranial volume (ICV), education level, and occupational type. RESULTS: The association between BAG and shift work duration was also evaluated. Model performance varied (maximum R2 = 0.79) and showed systematic age-related bias, typically underestimating brain age in older participants. Unadjusted analyses initially indicated lower BAG values in younger shift workers. However, after covariate adjustments, shift workers consistently exhibited significantly higher BAG values, suggesting accelerated brain aging. Two models retained statistical significance despite adjustment for potential confounders. Longer shift work duration correlated with a decreasing BAG trend, suggesting potential neuroadaptive changes or selective retention of resilient workers. CONCLUSION: These findings demonstrate that shift work is associated with accelerated apparent brain aging, even after controlling for systematic model bias and demographic covariates. The observed reduction in BAG with extended shift work exposure may reflect adaptive or selective effects, emphasizing the need for longitudinal studies to clarify these mechanisms. This research highlights the importance of incorporating occupational exposures in neuroimaging and brain health investigations.",
      "authors": "Kim Youjin; Choi Joon Yul; Petrovskiy Evgeny; Lee Wanhyung",
      "year": "2025",
      "journal": "Frontiers in aging neuroscience",
      "doi": "10.3389/fnagi.2025.1650497",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40951919/",
      "mesh_terms": "",
      "keywords": "MRI; brain; brain age gap; brain aging; neuroimaging; shift work",
      "pub_types": "Journal Article",
      "pmcid": "PMC12425934"
    },
    {
      "pmid": "37153090",
      "title": "Rating and ranking preparedness characteristics important for veterinary workplace clinical training: a novel application of pairwise comparisons and the Elo algorithm.",
      "abstract": "Quantitatively eliciting perspectives about a large number of similar entities (such as a list of competences) is a challenge for researchers in health professions education (HPE). Traditional survey methods may include using Likert items. However, a Likert item approach that generates absolute ratings of the entities may suffer from the \"ceiling effect,\" as ratings cluster at one end of the scale. This impacts on researchers' ability to detect differences in ratings between the entities themselves and between respondent groups. This paper describes the use of pairwise comparison (this or that?) questions and a novel application of the Elo algorithm to generate relative ratings and rankings of a large number of entities, on a unidimensional scale. A study assessing the relative importance of 91 student \"preparedness characteristics\" for veterinary workplace clinical training (WCT) is presented as an example of this method in action. The Elo algorithm uses pairwise comparison responses to generate an importance rating for each preparedness characteristic on a scale from zero to one. This is continuous data with measurement variability which, by definition, spans an entire spectrum and is not susceptible to the ceiling effect. The output should allow for the detection of differences in perspectives between groups of survey respondents (such as students and workplace supervisors) which Likert ratings may be insensitive to. Additional advantages of the pairwise comparisons are their low susceptibility to systematic bias and measurement error, they can be quicker and arguably more engaging to complete than Likert items, and they should carry a low cognitive load for respondents. Methods for evaluating the validity and reliability of this survey design are also described. This paper presents a method that holds great potential for a diverse range of applications in HPE research. In the pursuit quantifying perspectives on survey items which are measured on a relative basis and a unidimensional scale (e.g., importance, priority, probability), this method is likely to be a valuable option.",
      "authors": "Routh Jennifer; Paramasivam Sharmini Julita; Cockcroft Peter; Wood Sarah; Remnant John; Westermann Corn\u00e9lie; Reid Alison; Pawson Patricia; Warman Sheena; Nadarajah Vishna Devi; Jeevaratnam Kamalan",
      "year": "2023",
      "journal": "Frontiers in medicine",
      "doi": "10.3389/fmed.2023.1128058",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37153090/",
      "mesh_terms": "",
      "keywords": "Likert; comparison; methods; preparedness; questionnaire; ranking; rating; survey",
      "pub_types": "Journal Article",
      "pmcid": "PMC10160665"
    },
    {
      "pmid": "23462966",
      "title": "Regional epidemiologic assessment of prevalent periodontitis using an electronic health record system.",
      "abstract": "An oral health surveillance platform that queries a clinical/administrative data warehouse was applied to estimate regional prevalence of periodontitis. Cross-sectional analysis of electronic health record data collected between January 1, 2006, and December 31, 2010, was undertaken in a population sample residing in Ladysmith, Wisconsin. Eligibility criteria included: 1) residence in defined zip codes, 2) age 25-64 years, and 3) \u22651 Marshfield dental clinic comprehensive examination. Prevalence was established using 2 independent methods: 1) via an algorithm that considered clinical attachment loss and probe depth and 2) via standardized Current Dental Terminology (CDT) codes related to periodontal treatment. Prevalence estimates were age-standardized to 2000 US Census estimates. Inclusion criteria were met by 2,056 persons. On the basis of the American Academy of Periodontology/Centers for Disease Control and Prevention method, the age-standardized prevalence of moderate or severe periodontitis (combined) was 407 per 1,000 males and 308 per 1,000 females (348/1,000 males and 269/1,000 females using the CDT code method). Increased prevalence and severity of periodontitis was noted with increasing age. Local prevalence of periodontitis was consistent with national estimates. The need to address potential sample selection bias in future electronic health record-based periodontitis research was identified by this approach. Methods outlined herein may be applied to refine oral health surveillance systems, inform dental epidemiologic methods, and evaluate interventional outcomes.",
      "authors": "Acharya Amit; VanWormer Jeffrey J; Waring Stephen C; Miller Aaron W; Fuehrer Jay T; Nycz Gregory R",
      "year": "2013",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kws293",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23462966/",
      "mesh_terms": "Adult; Age Factors; Algorithms; Centers for Disease Control and Prevention, U.S.; Cross-Sectional Studies; Electronic Health Records; Female; Humans; Male; Middle Aged; Periodontitis; Prevalence; Severity of Illness Index; Smoking; Socioeconomic Factors; United States; Wisconsin",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC3613126"
    },
    {
      "pmid": "39316421",
      "title": "Extracting Critical Information from Unstructured Clinicians' Notes Data to Identify Dementia Severity Using a Rule-Based Approach: Feasibility Study.",
      "abstract": "BACKGROUND: The severity of Alzheimer disease and related dementias (ADRD) is rarely documented in structured data fields in electronic health records (EHRs). Although this information is important for clinical monitoring and decision-making, it is often undocumented or \"hidden\" in unstructured text fields and not readily available for clinicians to act upon. OBJECTIVE: We aimed to assess the feasibility and potential bias in using keywords and rule-based matching for obtaining information about the severity of ADRD from EHR data. METHODS: We used EHR data from a large academic health care system that included patients with a primary discharge diagnosis of ADRD based on ICD-9 (International Classification of Diseases, Ninth Revision) and ICD-10 (International Statistical Classification of Diseases, Tenth Revision) codes between 2014 and 2019. We first assessed the presence of ADRD severity information and then the severity of ADRD in the EHR. Clinicians' notes were used to determine the severity of ADRD based on two criteria: (1) scores from the Mini Mental State Examination and Montreal Cognitive Assessment and (2) explicit terms for ADRD severity (eg, \"mild dementia\" and \"advanced Alzheimer disease\"). We compiled a list of common ADRD symptoms, cognitive test names, and disease severity terms, refining it iteratively based on previous literature and clinical expertise. Subsequently, we used rule-based matching in Python using standard open-source data analysis libraries to identify the context in which specific words or phrases were mentioned. We estimated the prevalence of documented ADRD severity and assessed the performance of our rule-based algorithm. RESULTS: We included 9115 eligible patients with over 65,000 notes from the providers. Overall, 22.93% (2090/9115) of patients were documented with mild ADRD, 20.87% (1902/9115) were documented with moderate or severe ADRD, and 56.20% (5123/9115) did not have any documentation of the severity of their ADRD. For the task of determining the presence of any ADRD severity information, our algorithm achieved an accuracy of >95%, specificity of >95%, sensitivity of >90%, and an F1-score of >83%. For the specific task of identifying the actual severity of ADRD, the algorithm performed well with an accuracy of >91%, specificity of >80%, sensitivity of >88%, and F1-score of >92%. Comparing patients with mild ADRD to those with more advanced ADRD, the latter group tended to contain older, more likely female, and Black patients, and having received their diagnoses in primary care or in-hospital settings. Relative to patients with undocumented ADRD severity, those with documented ADRD severity had a similar distribution in terms of sex, race, and rural or urban residence. CONCLUSIONS: Our study demonstrates the feasibility of using a rule-based matching algorithm to identify ADRD severity from unstructured EHR report data. However, it is essential to acknowledge potential biases arising from differences in documentation practices across various health care systems.",
      "authors": "Prakash Ravi; Dupre Matthew E; \u00d8stbye Truls; Xu Hanzhang",
      "year": "2024",
      "journal": "JMIR aging",
      "doi": "10.2196/57926",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39316421/",
      "mesh_terms": "Humans; Feasibility Studies; Electronic Health Records; Dementia; Severity of Illness Index; Male; Female; Aged; Alzheimer Disease; Aged, 80 and over",
      "keywords": "AD; ADRD; AI; Alzheimer's disease; Alzheimer's disease and related dementias; EHR; EMR; LLM; NLP; PHR; artificial intelligence; deep learning; dementia; electric medical record; electronic health record; geriatric syndromes; health record; large language model; natural language processing; patient record; personal health record; rule based analysis; unstructured data",
      "pub_types": "Journal Article",
      "pmcid": "PMC11462099"
    },
    {
      "pmid": "37813920",
      "title": "COVID-Net Biochem: an explainability-driven framework to building machine learning models for predicting survival and kidney injury of COVID-19 patients from clinical and biochemistry data.",
      "abstract": "Since the World Health Organization declared COVID-19 a pandemic in 2020, the global community has faced ongoing challenges in controlling and mitigating the transmission of the SARS-CoV-2 virus, as well as its evolving subvariants and recombinants. A significant challenge during the pandemic has not only been the accurate detection of positive cases but also the efficient prediction of risks associated with complications and patient survival probabilities. These tasks entail considerable clinical resource allocation and attention. In this study, we introduce COVID-Net Biochem, a versatile and explainable framework for constructing machine learning models. We apply this framework to predict COVID-19 patient survival and the likelihood of developing Acute Kidney Injury during hospitalization, utilizing clinical and biochemical data in a transparent, systematic approach. The proposed approach advances machine learning model design by seamlessly integrating domain expertise with explainability tools, enabling model decisions to be based on key biomarkers. This fosters a more transparent and interpretable decision-making process made by machines specifically for medical applications. More specifically, the framework comprises two phases: In the first phase, referred to as the \"clinician-guided design\" phase, the dataset is preprocessed using explainable AI and domain expert input. To better demonstrate this phase, we prepared a benchmark dataset of carefully curated clinical and biochemical markers based on clinician assessments for survival and kidney injury prediction in COVID-19 patients. This dataset was selected from a patient cohort of 1366 individuals at Stony Brook University. Moreover, we designed and trained a diverse collection of machine learning models, encompassing gradient-based boosting tree architectures and deep transformer architectures, specifically for survival and kidney injury prediction based on the selected markers. In the second phase, called the \"explainability-driven design refinement\" phase, the proposed framework employs explainability methods to not only gain a deeper understanding of each model's decision-making process but also to identify the overall impact of individual clinical and biochemical markers for bias identification. In this context, we used the models constructed in the previous phase for the prediction task and analyzed the explainability outcomes alongside a clinician with over 8 years of experience to gain a deeper understanding of the clinical validity of the decisions made. The explainability-driven insights obtained, in conjunction with the associated clinical feedback, are then utilized to guide and refine the training policies and architectural design iteratively. This process aims to enhance not only the prediction performance but also the clinical validity and trustworthiness of the final machine learning models. Employing the proposed explainability-driven framework, we attained 93.55% accuracy in survival prediction and 88.05% accuracy in predicting kidney injury complications. The models have been made available through an open-source platform. Although not a production-ready solution, this study aims to serve as a catalyst for clinical scientists, machine learning researchers, and citizen scientists to develop innovative and trustworthy clinical decision support solutions, ultimately assisting clinicians worldwide in managing pandemic outcomes.",
      "authors": "Aboutalebi Hossein; Pavlova Maya; Shafiee Mohammad Javad; Florea Adrian; Hryniowski Andrew; Wong Alexander",
      "year": "2023",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-023-42203-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37813920/",
      "mesh_terms": "Humans; COVID-19; SARS-CoV-2; Acute Kidney Injury; Kidney; Biomarkers",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10562395"
    },
    {
      "pmid": "39877865",
      "title": "Large Language Models Outperform Traditional Natural Language Processing Methods in Extracting Patient-Reported Outcomes in Inflammatory Bowel Disease.",
      "abstract": "BACKGROUND AND AIMS: Patient-reported outcomes (PROs) are vital in assessing disease activity and treatment outcomes in inflammatory bowel disease (IBD). However, manual extraction of these PROs from the free-text of clinical notes is burdensome. We aimed to improve data curation from free-text information in the electronic health record, making it more available for research and quality improvement. This study aimed to compare traditional natural language processing (tNLP) and large language models (LLMs) in extracting 3 IBD PROs (abdominal pain, diarrhea, fecal blood) from clinical notes across 2 institutions. METHODS: Clinic notes were annotated for each PRO using preset protocols. Models were developed and internally tested at the University of California, San Francisco, and then externally validated at Stanford University. We compared tNLP and LLM-based models on accuracy, sensitivity, specificity, positive, and negative predictive value. In addition, we conducted fairness and error assessments. RESULTS: Interrater reliability between annotators was >90%. On the University of California, San Francisco test set (n\u00a0= 50), the top-performing tNLP models showcased accuracies of 92% (abdominal pain), 82% (diarrhea) and 80% (fecal blood), comparable to GPT-4, which was 96%, 88%, and 90% accurate, respectively. On external validation at Stanford (n\u00a0= 250), tNLP models failed to generalize (61%-62% accuracy) while GPT-4 maintained accuracies >90%. Pathways Language Model-2 and Generative Pre-trained Transformer-4 showed similar performance. No biases were detected based on demographics or diagnosis. CONCLUSION: LLMs are accurate and generalizable methods for extracting PROs. They maintain excellent accuracy across institutions, despite heterogeneity in note templates and authors. Widespread adoption of such tools has the potential to enhance IBD research and patient care.",
      "authors": "Patel Perseus V; Davis Conner; Ralbovsky Amariel; Tinoco Daniel; Williams Christopher Y K; Slatter Shadera; Naderalvojoud Behzad; Rosen Michael J; Hernandez-Boussard Tina; Rudrapatna Vivek",
      "year": "2025",
      "journal": "Gastro hep advances",
      "doi": "10.1016/j.gastha.2024.10.003",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39877865/",
      "mesh_terms": "",
      "keywords": "Clinical data science; GPT-4; Machine learning; PaLM-2",
      "pub_types": "Journal Article",
      "pmcid": "PMC11772946"
    },
    {
      "pmid": "36949164",
      "title": "Smartphone-based point-of-care anemia screening in rural Bihar in India.",
      "abstract": "BACKGROUND: The high prevalence of anemia in resource-constrained settings calls for easy-to-use, inexpensive screening tools. The Sanguina Smartphone App, an innovative tool for non-invasive hemoglobin estimation via color-sensitive, algorithm-based analysis of fingernail bed images, was validated in the United States. This study evaluates the performance of the App in a population with different socio-economic, ethnic, demographic and cultural composition in rural Bihar, India. METHODS: For 272 mainly adult patients of a private health centre, hemoglobin measurement with the App is compared with the gold standard laboratory blood analysis. For a second sample of 179 children attending pre-schools, hemoglobin measurement with the App is compared to the results of the HemoCue Hb 301, a point-of-care device using a small blood sample, serving as the reference standard for field-based settings. RESULTS: The App reaches \u00b14.43\u2009g/dl accuracy and 0.38\u2009g/dl bias of comparator values in the clinic-based sample, and \u00b13.54\u2009g/dl and 1.30\u2009g/dl, respectively in the pre-school sample. After retraining the algorithm with the collected data, the validity of the upgraded version is retested showing an improved performance (accuracy of \u00b12.25\u2009g/dl, bias of 0.25\u2009g/dl), corresponding to the results of the original validation study from the United States. CONCLUSIONS: The initial version of the App does not achieve the accuracy needed for diagnosis or screening. After retraining the algorithm, it achieves an accuracy sufficient for screening. The improved version with the potential for further adaptions is a promising easy-to-use, inexpensive screening tool for anemia in resource-constrained point-of-care settings.",
      "authors": "Haggenm\u00fcller Verena; Bogler Lisa; Weber Ann-Charline; Kumar Abhijeet; B\u00e4rnighausen Till; Danquah Ina; Vollmer Sebastian",
      "year": "2023",
      "journal": "Communications medicine",
      "doi": "10.1038/s43856-023-00267-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36949164/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10033918"
    },
    {
      "pmid": "35687826",
      "title": "Artificial Intelligence in Oncology: Current Capabilities, Future Opportunities, and Ethical Considerations.",
      "abstract": "The promise of highly personalized oncology care using artificial intelligence (AI) technologies has been forecasted since the emergence of the field. Cumulative advances across the science are bringing this promise to realization, including refinement of machine learning- and deep learning algorithms; expansion in the depth and variety of databases, including multiomics; and the decreased cost of massively parallelized computational power. Examples of successful clinical applications of AI can be found throughout the cancer continuum and in multidisciplinary practice, with computer vision-assisted image analysis in particular having several U.S. Food and Drug Administration-approved uses. Techniques with emerging clinical utility include whole blood multicancer detection from deep sequencing, virtual biopsies, natural language processing to infer health trajectories from medical notes, and advanced clinical decision support systems that combine genomics and clinomics. Substantial issues have delayed broad adoption, with data transparency and interpretability suffering from AI's \"black box\" mechanism, and intrinsic bias against underrepresented persons limiting the reproducibility of AI models and perpetuating health care disparities. Midfuture projections of AI maturation involve increasing a model's complexity by using multimodal data elements to better approximate an organic system. Far-future positing includes living databases that accumulate all aspects of a person's health into discrete data elements; this will fuel highly convoluted modeling that can tailor treatment selection, dose determination, surveillance modality and schedule, and more. The field of AI has had a historical dichotomy between its proponents and detractors. The successful development of recent applications, and continued investment in prospective validation that defines their impact on multilevel outcomes, has established a momentum of accelerated progress.",
      "authors": "Shreve Jacob T; Khanani Sadia A; Haddad Tufia C",
      "year": "2022",
      "journal": "American Society of Clinical Oncology educational book. American Society of Clinical Oncology. Annual Meeting",
      "doi": "10.1200/EDBK_350652",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35687826/",
      "mesh_terms": "Algorithms; Artificial Intelligence; Humans; Machine Learning; Medical Oncology; Neoplasms; Reproducibility of Results",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "26805004",
      "title": "Using data mining techniques to characterize participation in observational studies.",
      "abstract": "Data mining techniques are gaining in popularity among health researchers for an array of purposes, such as improving diagnostic accuracy, identifying high-risk patients and extracting concepts from unstructured data. In this paper, we describe how these techniques can be applied to another area in the health research domain: identifying characteristics of individuals who do and do not choose to participate in observational studies. In contrast to randomized studies where individuals have no control over their treatment assignment, participants in observational studies self-select into the treatment arm and therefore have the potential to differ in their characteristics from those who elect not to participate. These differences may explain part, or all, of the difference in the observed outcome, making it crucial to assess whether there is differential participation based on observed characteristics. As compared to traditional approaches to this assessment, data mining offers a more precise understanding of these differences. To describe and illustrate the application of data mining in this domain, we use data from a primary care-based medical home pilot programme and compare the performance of commonly used classification approaches - logistic regression, support vector machines, random forests and classification tree analysis (CTA) - in correctly classifying participants and non-participants. We find that CTA is substantially more accurate than the other models. Moreover, unlike the other models, CTA offers transparency in its computational approach, ease of interpretation via the decision rules produced and provides statistical results familiar to health researchers. Beyond their application to research, data mining techniques could help administrators to identify new candidates for participation who may most benefit from the intervention.",
      "authors": "Linden Ariel; Yarnold Paul R",
      "year": "2016",
      "journal": "Journal of evaluation in clinical practice",
      "doi": "10.1111/jep.12515",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26805004/",
      "mesh_terms": "Adult; Data Mining; Female; Humans; Machine Learning; Male; Middle Aged; Observational Studies as Topic; Selection Bias",
      "keywords": "data mining; machine learning; observational studies; observed characteristics; selection; selection bias",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "23122901",
      "title": "Linkage of a clinical surgical registry with Medicare inpatient claims data using indirect identifiers.",
      "abstract": "BACKGROUND: A variety of data sources are available for measuring the quality of health care. Linking records from different sources can create unique and powerful databases that can be used to evaluate clinically relevant questions and direct health care policy. The objective of this study was to develop and validate a deterministic linkage algorithm that uses indirect patient identifiers to reliably match records from a surgical clinical registry with Medicare inpatient claims data. METHODS: Patient records from the American College of Surgeons National Surgical Quality Improvement Program (ACS-NSQIP), years 2005-2008, were linked to claims data in the Medicare Provider Analysis and Review file (MedPAR) by the use of a deterministic linkage algorithm and the following indirect patient identifiers: hospital, age, sex, diagnosis, procedure and dates of admission, discharge, and procedure. We validated the linkage procedure by systematically reviewing subsets of matched and unmatched records and by determining agreement on patient-level coding of inpatient mortality. RESULTS: Of the 150,454 records in ACS-NSQIP eligible for matching, 80.5% were linked to a MedPAR record. This percentage is within the expected match range given the estimated percentage of ACS-NSQIP patients likely to be Medicare beneficiaries. Systematic checks revealed no evidence of bias in the linkage procedure and there was excellent agreement on patient-level coding of mortality (kappa 0.969). The final linked database contained 121,070 patient records from 217 hospitals. CONCLUSION: This study demonstrates the feasibility and validity of a method for linking 2 data sources without direct personal identifiers. As clinical registries and other data sources continue to proliferate, linkage algorithms such as described here will be critical for quality measurement purposes.",
      "authors": "Lawson Elise H; Ko Clifford Y; Louie Rachel; Han Lein; Rapp Michael; Zingmond David S",
      "year": "2013",
      "journal": "Surgery",
      "doi": "10.1016/j.surg.2012.08.065",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23122901/",
      "mesh_terms": "Aged; Female; General Surgery; Hospitals; Humans; Inpatients; Male; Medical Record Linkage; Medical Records Systems, Computerized; Medicare Part A; Protein Precursors; Quality of Health Care; Registries; Societies, Medical; United States",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.; Validation Study",
      "pmcid": ""
    },
    {
      "pmid": "32775691",
      "title": "Privacy and ethical challenges in next-generation sequencing.",
      "abstract": "INTRODUCTION: Next-generation sequencing (NGS) is expected to revolutionize health care. NGS allows for sequencing of the whole genome more cheaply and quickly than previous techniques. NGS offers opportunities to advance medical diagnostics and treatments, but also raises complicated ethical questions that need to be addressed. AREAS CONSIDERED: This article draws from the literature on research and clinical ethics, as well as next-generation sequencing, in order to provide an overview of the ethical challenges involved in next-generation sequencing. This article includes a discussion of the ethics of NGS in research and clinical contexts. EXPERT OPINION: The use of NGS in clinical and research contexts has features that pose challenges for traditional ethical frameworks for protecting research participants and patients. NGS generates massive amounts of data and results that vary in terms of known clinical relevance. It is important to determine appropriate processes for protecting, managing and communicating the data. The use of machine learning for sequencing and interpretation of genomic data also raises concerns in terms of the potential for bias and potential implications for fiduciary obligations. NGS poses particular challenges in three main ethical areas: privacy, informed consent, and return of results.",
      "authors": "Martinez-Martin Nicole; Magnus David",
      "year": "2019",
      "journal": "Expert review of precision medicine and drug development",
      "doi": "10.1080/23808993.2019.1599685",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32775691/",
      "mesh_terms": "",
      "keywords": "Next generation sequencing; ethics; privacy",
      "pub_types": "Journal Article",
      "pmcid": "PMC7413244"
    },
    {
      "pmid": "23997760",
      "title": "Automated Segmentation and Object Classification of CT Images: Application to In Vivo Molecular Imaging of Avian Embryos.",
      "abstract": "Background. Although chick embryogenesis has been studied extensively, there has been growing interest in the investigation of skeletogenesis. In addition to improved poultry health and minimized economic loss, a greater understanding of skeletal abnormalities can also have implications for human medicine. True in vivo studies require noninvasive imaging techniques such as high-resolution microCT. However, the manual analysis of acquired images is both time consuming and subjective. Methods. We have developed a system for automated image segmentation that entails object-based image analysis followed by the classification of the extracted image objects. For image segmentation, a rule set was developed using Definiens image analysis software. The classification engine was implemented using the WEKA machine learning tool. Results. Our system reduces analysis time and observer bias while maintaining high accuracy. Applying the system to the quantification of long bone growth has allowed us to present the first true in ovo data for bone length growth recorded in the same chick embryos. Conclusions. The procedures developed represent an innovative approach for the automated segmentation, classification, quantification, and visualization of microCT images. MicroCT offers the possibility of performing longitudinal studies and thereby provides unique insights into the morpho- and embryogenesis of live chick embryos.",
      "authors": "Heidrich Alexander; Schmidt Jana; Zimmermann Johannes; Saluz Hans Peter",
      "year": "2013",
      "journal": "International journal of biomedical imaging",
      "doi": "10.1155/2013/508474",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23997760/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC3753761"
    },
    {
      "pmid": "41167996",
      "title": "Artificial intelligence for precision medicine.",
      "abstract": "INTRODUCTION: Precision medicine aims to tailor healthcare decisions and interventions to the unique biological and clinical characteristics of each patient. The recent convergence of artificial intelligence (AI) with advances in digital health, omics, and big data analytics has accelerated progress toward this goal. AI technologies\u00a0-\u00a0particularly machine learning, deep learning, natural language processing and generative large language models\u00a0-\u00a0enable the rapid and meaningful analysis of complex biomedical datasets, supporting more individualized care. PURPOSE OF REVIEW: In this narrative review, we provide an accessible overview of the core principles of AI for healthcare professionals and explore its practical applications across the spectrum of precision medicine. Real-world examples highlight how AI is being used to enhance early diagnosis, guide treatment selection, support disease prevention, and even contribute directly to therapeutic interventions. Alongside these advances, we discuss critical limitations and challenges, including ethical considerations, algorithmic bias, data privacy concerns, environmental impact, and practical barriers to clinical implementation. CONCLUSION: This review offers both an introduction to AI and a practical overview of how it is being used, and where its limitations lie, in precision medicine, with the goal of helping healthcare professionals understand these evolving tools and use them efficiently and responsibly in clinical practice.",
      "authors": "Martel Marie-Elise; Jos\u00e9-Garcia Adan; Vens Celine; De Vos Maarten; Sobanski Vincent",
      "year": "2025",
      "journal": "Therapie",
      "doi": "10.1016/j.therap.2025.10.003",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41167996/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Healthcare; Precision medicine; Review",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "33888583",
      "title": "Scalable deep learning to identify brick kilns and aid regulatory capacity.",
      "abstract": "Improving compliance with environmental regulations is critical for promoting clean environments and healthy populations. In South Asia, brick manufacturing is a major source of pollution but is dominated by small-scale, informal producers who are difficult to monitor and regulate-a common challenge in low-income settings. We demonstrate a low-cost, scalable approach for locating brick kilns in high-resolution satellite imagery from Bangladesh. Our approach identifies kilns with 94.2% accuracy and 88.7% precision and extracts the precise GPS coordinates of every brick kiln across Bangladesh. Using these estimates, we show that at least 12% of the population of Bangladesh (>18 million people) live within 1 km of a kiln and that 77% and 9% of kilns are (illegally) within 1 km of schools and health facilities, respectively. Finally, we show how kilns contribute up to 20.4 \u03bcg/[Formula: see text] of [Formula: see text] (particulate matter of a diameter less than 2.5 \u03bcm) in Dhaka when the wind blows from an unfavorable direction. We document inaccuracies and potential bias with respect to local regulations in the government data. Our approach demonstrates how machine learning and Earth observation can be combined to better understand the extent and implications of regulatory compliance in informal industry.",
      "authors": "Lee Jihyeon; Brooks Nina R; Tajwar Fahim; Burke Marshall; Ermon Stefano; Lobell David B; Biswas Debashish; Luby Stephen P",
      "year": "2021",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "doi": "10.1073/pnas.2018863118",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33888583/",
      "mesh_terms": "Air Pollutants; Air Pollution; Asia; Bangladesh; Carbon Monoxide; Conservation of Natural Resources; Deep Learning; Environmental Monitoring; Environmental Pollution; Guideline Adherence; Humans; Image Processing, Computer-Assisted; Industry; Particulate Matter; Satellite Imagery",
      "keywords": "Bangladesh; air pollution; deep learning; environmental regulations; satellite imagery",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC8092470"
    },
    {
      "pmid": "41496956",
      "title": "Early detection in oral cancer: are we ready for AI-driven precision?",
      "abstract": "Oral cancer, particularly oral squamous cell carcinoma, remains a serious health concern, with a poor prognosis and a late diagnosis. Leukoplakia, erythroplakia, lichen planus, and submucous fibrosis are examples of oral potentially malignant illnesses. However, traditional diagnostic approaches are typically laborious, subjective, and unreliable, leading to delayed diagnosis - when therapy options are limited and survival is compromised. In oral cancer, artificial intelligence (AI) and precision medicine are becoming game-changing technologies that enhance individualized care, treatment planning, and diagnostic precision. Machine learning and deep learning algorithms, particularly convolutional neural networks, can analyze massive, complex datasets from fluorescence to hyperspectral imaging, revealing patterns that are beyond human detection. Recent trials have shown AI systems based on smartphones have demonstrated expert-level accuracy in identifying oral lesions in recent experiments. Through the discovery of biomarkers and the integration of several omics, AI-driven precision medicine also makes customized treatments possible. Nonetheless, issues with patient privacy, data bias, and the opaque \"black box\" nature of AI systems persist. The future of proactive and individualized oral cancer therapy relies on creating Explainable AI and strong ethical frameworks that encourage transparency, trust, and equitable integration.",
      "authors": "Kumari Sinha; Kumar Nikil; Khan Muhamma Saad; Sultana Sadia; Khalid Muddassir",
      "year": "2026",
      "journal": "Annals of medicine and surgery (2012)",
      "doi": "10.1097/MS9.0000000000004418",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41496956/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; oral cancer care; personalized treatment",
      "pub_types": "Editorial",
      "pmcid": "PMC12768076"
    },
    {
      "pmid": "35459930",
      "title": "Optimal-design domain-adaptation for exposure prediction in two-stage epidemiological studies.",
      "abstract": "BACKGROUND: In the first stage of a two-stage study, the researcher uses a statistical model to impute the unobserved exposures. In the second stage, imputed exposures serve as covariates in epidemiological models. Imputation error in the first stage operate as measurement errors in the second stage, and thus bias exposure effect estimates. OBJECTIVE: This study aims to improve the estimation of exposure effects by sharing information between the first and second stages. METHODS: At the heart of our estimator is the observation that not all second-stage observations are equally important to impute. We thus borrow ideas from the optimal-experimental-design theory, to identify individuals of higher importance. We then improve the imputation of these individuals using ideas from the machine-learning literature of domain adaptation. RESULTS: Our simulations confirm that the exposure effect estimates are more accurate than the current best practice. An empirical demonstration yields smaller estimates of PM effect on hyperglycemia risk, with tighter confidence bands. SIGNIFICANCE: Sharing information between environmental scientist and epidemiologist improves health effect estimates. Our estimator is a principled approach for harnessing this information exchange, and may be applied to any two stage study.",
      "authors": "Sarafian Ron; Kloog Itai; Rosenblatt Jonathan D",
      "year": "2023",
      "journal": "Journal of exposure science & environmental epidemiology",
      "doi": "10.1038/s41370-022-00438-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35459930/",
      "mesh_terms": "Humans; Epidemiologic Studies; Research Design; Models, Statistical; Bias",
      "keywords": "Domain-adaptation; Environmental epidemiology; Optimal-design; Two-stage studies",
      "pub_types": "Journal Article",
      "pmcid": "3169665"
    },
    {
      "pmid": "34655140",
      "title": "The role of wage beliefs in the decision to become a nurse.",
      "abstract": "In light of skilled-labor shortage, the effect of a change in the wage of nurses on their labor supply is intensely discussed in recent literature. Using extensive data of German 14- to 15-year-olds, I analyze the role of the beliefs about a nurse's wage in the decision to become one. To estimate a partial effect, I select controls and their functional form using post-double-selection, which is a data-driven selection method based on regression shrinkage. Highlighting the importance of wages at the extensive margin of labor supply, the wage beliefs play a positive and statistically significant role. Although information is publicly available, educational choices knowingly suffer from misinformation. I find that especially those who do not become a nurse understate the wage. The results lead to two important policy implications. First, increasing the wage may help to overcome the shortage observed in many countries. Second, providing more information on the (relative) wage may be a successful strategy to attract more individuals into this profession. To assess the sensitivity of the results regarding omitted variable bias, I apply a novel approach. It turns out that potential unobserved confounders would have to be strong to overrule the conclusions.",
      "authors": "Kugler Philipp",
      "year": "2022",
      "journal": "Health economics",
      "doi": "10.1002/hec.4442",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34655140/",
      "mesh_terms": "Educational Status; Humans; Salaries and Fringe Benefits; Workforce",
      "keywords": "health professional; machine learning; occupational choice; wage beliefs; wage information",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "27896987",
      "title": "DISCOVERY OF FUNCTIONAL AND DISEASE PATHWAYS BY COMMUNITY DETECTION IN PROTEIN-PROTEIN INTERACTION NETWORKS.",
      "abstract": "Advances in cellular, molecular, and disease biology depend on the comprehensive characterization of gene interactions and pathways. Traditionally, these pathways are curated manually, limiting their efficient annotation and, potentially, reinforcing field-specific bias. Here, in order to test objective and automated identification of functionally cooperative genes, we compared a novel algorithm with three established methods to search for communities within gene interaction networks. Communities identified by the novel approach and by one of the established method overlapped significantly (q < 0.1) with control pathways. With respect to disease, these communities were biased to genes with pathogenic variants in ClinVar (p \u226a 0.01), and often genes from the same community were co-expressed, including in breast cancers. The interesting subset of novel communities, defined by poor overlap to control pathways also contained co-expressed genes, consistent with a possible functional role. This work shows that community detection based on topological features of networks suggests new, biologically meaningful groupings of genes that, in turn, point to health and disease relevant hypotheses.",
      "authors": "Wilson Stephen J; Wilkins Angela D; Lin Chih-Hsu; Lua Rhonald C; Lichtarge Olivier",
      "year": "2017",
      "journal": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
      "doi": "10.1142/9789813207813_0032",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27896987/",
      "mesh_terms": "Algorithms; Bardet-Biedl Syndrome; Breast Neoplasms; Computational Biology; Epistasis, Genetic; Female; Gene Regulatory Networks; Genetic Predisposition to Disease; Humans; Protein Interaction Maps; Zellweger Syndrome",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC5140035"
    },
    {
      "pmid": "40303570",
      "title": "Robust estimation of the incubation period and the time of exposure using \u03b3-divergence.",
      "abstract": "Estimating the exposure time to single infectious pathogens and the associated incubation period, based on symptom onset data, is crucial for identifying infection sources and implementing public health interventions. However, data from rapid surveillance systems designed for early outbreak warning often come with outliers originated from individuals who were not directly exposed to the initial source of infection (i.e. tertiary and subsequent infection cases), making the estimation of exposure time challenging. To address this issue, this study uses a three-parameter lognormal distribution and proposes a new \u03b3-divergence-based robust approach for estimating the parameter corresponding to exposure time with a tailored optimization procedure using the majorization-minimization algorithm, which ensures the monotonic decreasing property of the objective function. Comprehensive numerical experiments and real data analyses suggest that our method is superior to conventional methods in terms of bias, mean squared error, and coverage probability of 95% confidence intervals.",
      "authors": "Yoneoka Daisuke; Kawashima Takayuki; Tanoue Yuta; Nomura Shuhei; Eguchi Akifumi",
      "year": "2025",
      "journal": "Journal of applied statistics",
      "doi": "10.1080/02664763.2024.2420221",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40303570/",
      "mesh_terms": "",
      "keywords": "62F35; 92B15; exposure time; infectious disease; robust estimation; three-parameter lognormal; \u03b3-divergence",
      "pub_types": "Journal Article",
      "pmcid": "PMC12035932"
    },
    {
      "pmid": "30034201",
      "title": "Selecting Optimal Subset to release under Differentially Private M-estimators from Hybrid Datasets.",
      "abstract": "Privacy concern in data sharing especially for health data gains particularly increasing attention nowadays. Now some patients agree to open their information for research use, which gives rise to a new question of how to effectively use the public information to better understand the private dataset without breaching privacy. In this paper, we specialize this question as selecting an optimal subset of the public dataset for M-estimators in the framework of differential privacy (DP) in [1]. From a perspective of non-interactive learning, we first construct the weighted private density estimation from the hybrid datasets under DP. Along the same line as [2], we analyze the accuracy of the DP M-estimators based on the hybrid datasets. Our main contributions are (i) we find that the bias-variance tradeoff in the performance of our M-estimators can be characterized in the sample size of the released dataset; (2) based on this finding, we develop an algorithm to select the optimal subset of the public dataset to release under DP. Our simulation studies and application to the real datasets confirm our findings and set a guideline in the real application.",
      "authors": "Wang Meng; Ji Zhanglong; Kim Hyeon-Eui; Wang Shuang; Xiong Li; Jiang Xiaoqian",
      "year": "2018",
      "journal": "IEEE transactions on knowledge and data engineering",
      "doi": "10.1109/TKDE.2017.2773545",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30034201/",
      "mesh_terms": "",
      "keywords": "M-estimators; differential privacy; hybrid datasets",
      "pub_types": "Journal Article",
      "pmcid": "PMC6051552"
    },
    {
      "pmid": "39548096",
      "title": "MIMIC-BP: A curated dataset for blood pressure estimation.",
      "abstract": "Blood pressure (BP) is one of the most prominent indicators of potential cardiovascular disorders. Traditionally, BP measurement relies on inflatable cuffs, which is inconvenient and limit the acquisition of such important health-related information in general population. Based on large amounts of well-collected and annotated data, deep-learning approaches present a generalization potential that arose as an alternative to enable more pervasive approaches. However, most existing work in this area currently uses datasets with limitations, such as lack of subject identification and severe data imbalance that can result in data leakage and algorithm bias. Thus, to offer a more properly curated source of information, we propose a derivative dataset composed of 380 hours of the most common biomedical signals, including arterial blood pressure, photoplethysmography, and electrocardiogram for 1,524 anonymized subjects, each having 30 segments of 30 seconds of those signals. We also validated the proposed dataset through experiments using state-of-the-art deep-learning methods, as we highlight the importance of standardized benchmarks for calibration-free blood pressure estimation scenarios.",
      "authors": "Sanches Ivandro; Gomes Victor V; Caetano Carlos; Cabrera Lizeth S B; Cene Vinicius H; Beltrame Thomas; Lee Wonkyu; Baek Sanghyun; Penatti Ot\u00e1vio A B",
      "year": "2024",
      "journal": "Scientific data",
      "doi": "10.1038/s41597-024-04041-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39548096/",
      "mesh_terms": "Humans; Deep Learning; Blood Pressure; Blood Pressure Determination; Photoplethysmography; Electrocardiography; Male",
      "keywords": "",
      "pub_types": "Dataset; Journal Article",
      "pmcid": "PMC11568151"
    },
    {
      "pmid": "34301954",
      "title": "Gridded daily weather data for North America with comprehensive uncertainty quantification.",
      "abstract": "Access to daily high-resolution gridded surface weather data based on direct observations and over long time periods is essential for many studies and applications including vegetation, wildlife, soil health, hydrological modelling, and as driver data in Earth system models. We present Daymet V4, a 40-year daily meteorological dataset on a 1\u2009km grid for North America, Hawaii, and Puerto Rico, providing temperature, precipitation, shortwave radiation, vapor pressure, snow water equivalent, and day length. The dataset includes an objective quantification of uncertainty based on strict cross-validation analysis for temperature and precipitation results. The dataset represents several improvements from a previous version, and this data descriptor provides complete documentation for updated methods. Improvements include: reductions in the timing bias of input reporting weather station measurements; improvement to the three-dimensional regression model techniques in the core algorithm; and a novel approach to handling high elevation temperature measurement biases. We show cross-validation analyses with the underlying weather station data to demonstrate the technical validity of new dataset generation methods, and to quantify improved accuracy.",
      "authors": "Thornton Peter E; Shrestha Rupesh; Thornton Michele; Kao Shih-Chieh; Wei Yaxing; Wilson Bruce E",
      "year": "2021",
      "journal": "Scientific data",
      "doi": "10.1038/s41597-021-00973-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34301954/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC8302764"
    },
    {
      "pmid": "41196886",
      "title": "Sea surface temperature modulates El Ni\u00f1o and La Ni\u00f1a driven leptospirosis patterns: Evidence from causal machine learning in Colombia.",
      "abstract": "Leptospirosis is a zoonotic disease prevalent in tropical regions influenced by climatic factors such as precipitation and soil moisture, which are regulated by the El Ni\u00f1o-Southern Oscillation (ENSO). This study examines the causal relationship between El Ni\u00f1o and La Ni\u00f1a episodes and leptospirosis cases in Colombia at the municipal level from 2007 to 2023. Using an ecological longitudinal design, we analyzed laboratory-confirmed cases from the National Public Health Surveillance System, environmental data from remote sensing, and socioeconomic data, employing a causal machine learning framework with doubly robust estimation and overlap weighting. We estimated the Average Treatment Effect (ATE) and the Conditional Average Treatment Effect (CATE) for three scenarios: Neutral vs. La Ni\u00f1a, Neutral vs. El Ni\u00f1o, and El Ni\u00f1o vs. La Ni\u00f1a. Results showed 10,629 cases, predominantly in males, with the highest incidence in Cali, Barranquilla, San Jos\u00e9 del Guaviare, and Cartagena. La Ni\u00f1a was associated with a 1.2 percentage point reduction in the probability of excess leptospirosis cases (ATE\u2009=\u2009-0.012, 95% CI: -0.015 - -0.008), while El Ni\u00f1o corresponded with a 7.2 percentage point increase in the probability of excess leptospirosis cases (ATE\u2009=\u20090.072, 95% CI: 0.041 - 0.103) compared to Neutral episodes. The El Ni\u00f1o vs. La Ni\u00f1a comparison showed no significant effect. As sea surface temperatures rose in the Pacific Ocean off the Colombian coast, the impact of both El Ni\u00f1o and La Ni\u00f1a episodes was observed to diminish, according to the CATE analysis. Regional variations, particularly in the Orinoco and Amazon regions, seem to drive these national trends, probably due to inverse hydro-climatic responses to ENSO. Refutation tests indicated the presence of remaining bias for the scenarios Neutral vs. El Ni\u00f1o and El Ni\u00f1o vs. La Ni\u00f1a. These findings highlight the complex interplay between climate and leptospirosis, underscoring the need for region-specific public health strategies to mitigate climate-driven disease risks in Colombia.",
      "authors": "Guti\u00e9rrez Juan David; Wilches-Vega Juan; Galvis-Serrano Fabi\u00e1n; Parada-Jurado Holver; Cortes-Ram\u00edrez Javier",
      "year": "2025",
      "journal": "PLOS global public health",
      "doi": "10.1371/journal.pgph.0005238",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41196886/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12591457"
    },
    {
      "pmid": "34518201",
      "title": "Simplified models to assess newborn gestational age in low-middle income countries: findings from a multicountry, prospective cohort study.",
      "abstract": "INTRODUCTION: Preterm birth is the leading cause of child mortality. This study aimed to develop and validate programmatically feasible and accurate approaches to estimate newborn gestational age (GA) in low resource settings. METHODS: The WHO Alliance for Maternal and Newborn Health Improvement (AMANHI) study recruited pregnant women from population-based cohorts in five countries (Bangladesh, Ghana, Pakistan, Tanzania and Zambia). Women <20 weeks gestation by ultrasound-based dating were enrolled. Research staff assessed newborns for: (1) anthropometry, (2) neuromuscular/physical signs and (3) feeding maturity. Machine-learning techniques were used to construct ensemble models. Diagnostic accuracy was assessed by areas under the receiver operating curve (AUC) and Bland-Altman analysis. RESULTS: 7428 liveborn infants were included (n=536 preterm, <37 weeks). The Ballard examination was biased compared with ultrasound dating (mean difference: +9\u2009days) with 95% limits of agreement (LOA) -15.3 to 33.6\u2009days (precision \u00b124.5\u2009days). A model including 10 newborn characteristics (birth weight, head circumference, chest circumference, foot length, breast bud diameter, breast development, plantar creases, skin texture, ankle dorsiflexion and infant sex) estimated GA with no bias, 95% LOA \u00b117.3\u2009days and an AUC=0.88 for classifying the preterm infant. A model that included last menstrual period (LMP) with the 10 characteristics had 95% LOA \u00b115.7\u2009days and high diagnostic accuracy (AUC 0.91). An alternative simpler model including birth weight and LMP had 95% LOA of \u00b116.7 and an AUC of 0.88. CONCLUSION: The best machine-learning model (10 neonatal characteristics and LMP) estimated GA within \u00b115.7\u2009days of early ultrasound dating. Simpler models performed reasonably well with marginal increases in prediction error. These models hold promise for newborn GA estimation when ultrasound dating is unavailable.",
      "authors": "",
      "year": "2021",
      "journal": "BMJ global health",
      "doi": "10.1136/bmjgh-2021-005688",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34518201/",
      "mesh_terms": "Child; Developing Countries; Female; Gestational Age; Humans; Infant; Infant, Newborn; Infant, Premature; Pregnancy; Premature Birth; Prospective Studies",
      "keywords": "child health; obstetrics",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8438948"
    },
    {
      "pmid": "40988329",
      "title": "Causal Machine Learning Methods and Use of Cross-Fitting in Settings With High-Dimensional Confounding.",
      "abstract": "Observational epidemiological studies commonly seek to estimate the causal effect of an exposure on an outcome. Adjustment for potential confounding bias in modern studies is challenging due to the presence of high-dimensional confounding, which occurs when there are many confounders relative to sample size or complex relationships between continuous confounders and exposure and outcome. Doubly robust methods such as Augmented Inverse Probability Weighting (AIPW) and Targeted Maximum Likelihood Estimation (TMLE) have the potential to address these challenges, using data-adaptive approaches and cross-fitting, but despite recent advances, limited evaluation and guidance are available on their implementation in realistic settings where high-dimensional confounding is present. Motivated by an early-life cohort study, we conducted an extensive simulation study to compare the relative performance of AIPW and TMLE using data-adaptive approaches for estimating the average causal effect (ACE). We evaluated the benefits of using cross-fitting with a varying number of folds, as well as the impact of using a reduced versus full (larger, more diverse) library in the Super Learner ensemble learning approach used for implementation. We found that AIPW and TMLE performed similarly in most cases for estimating the ACE, but TMLE was more stable. Cross-fitting improved the performance of both methods, but was more important for variance estimation and coverage than for point estimates, with the number of folds a less important consideration. Using a full Super Learner library was important to reduce bias and variance in complex scenarios typical of modern health research studies.",
      "authors": "Ellul Susan; Vansteelandt Stijn; Carlin John B; Moreno-Betancur Margarita",
      "year": "2025",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.70272",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40988329/",
      "mesh_terms": "Humans; Machine Learning; Likelihood Functions; Computer Simulation; Causality; Confounding Factors, Epidemiologic; Bias; Cohort Studies; Models, Statistical; Observational Studies as Topic",
      "keywords": "augmented inverse probability weighting; causal inference; cross\u2010fitting; doubly robust; high\u2010dimensional confounding; targeted maximum likelihood estimation",
      "pub_types": "Journal Article",
      "pmcid": "PMC12457817"
    },
    {
      "pmid": "35224055",
      "title": "Comparison of a Machine Learning Method and Various Equations for Estimating Low-Density Lipoprotein Cholesterol in Korean Populations.",
      "abstract": "BACKGROUND: LDL-C is the primary target of lipid-lowering therapy and used to classify patients by cardiovascular disease risk. We aimed to develop a deep neural network (DNN) model to estimate LDL-C levels and compare its performance with that of previous LDL-C estimation equations using two large independent datasets of Korean populations. METHODS: The final analysis included participants from two independent population-based cohorts: 129,930 from the Gangnam Severance Health Check-up (GSHC) and 46,470 participants from the Korean Initiatives on Coronary Artery Calcification registry (KOICA). The DNN model was derived from the GSHC dataset and validated in the KOICA dataset. We measured our proposed model's performance according to bias, root mean-square error (RMSE), proportion (P)10-P20, and concordance. P was defined as the percentage of patients whose LDL was within \u00b110-20% of the measured LDL. We further determined the RMSE scores of each LDL equation according to Pooled cohort equation intervals. RESULTS: Our DNN method has lower bias and root mean-square error than Friedewald's, Martin's, and NIH equations, showing a high agreement with LDL-C measured by homogenous assay. The DNN method offers more precise LDL estimation in all pooled cohort equation strata. CONCLUSION: This method may be particularly helpful for managing a patient's cholesterol levels based on their atherosclerotic cardiovascular disease risk.",
      "authors": "Kwon Yu-Jin; Lee Hyangkyu; Baik Su Jung; Chang Hyuk-Jae; Lee Ji-Won",
      "year": "2022",
      "journal": "Frontiers in cardiovascular medicine",
      "doi": "10.3389/fcvm.2022.824574",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35224055/",
      "mesh_terms": "",
      "keywords": "Korean; cardiovascular disease; deep neural network; low-density lipoprotein; pooled cohort equation",
      "pub_types": "Journal Article",
      "pmcid": "PMC8866707"
    },
    {
      "pmid": "39727896",
      "title": "Evaluation of Photoplethysmography-Based Monitoring of Respiration Rate During High-Intensity Interval Training: Implications for Healthcare Monitoring.",
      "abstract": "Monitoring respiration rate (RR) is crucial in various healthcare settings, particularly during demanding (physical) activities where respiratory dynamics are critical indicators of health status. This study aimed to evaluate the accuracy of photoplethysmography (PPG)-based monitoring of RR during high-intensity interval training (HIIT) and its potential applications in healthcare. Between January and March 2024, healthy volunteers participated in a cycling HIIT session with increasing resistance levels. The RR measurements obtained using the PPG-based CardioWatch 287-2 (Corsano Health) were compared with an ECG patch-derived (Vivalink) reference. Subgroup analyses were conducted based on skin type and sex. A total of 35 participants contributed 1794 paired RR measurements. The PPG algorithm for RR monitoring showed an average root mean square (Arms) error of 2.13 breaths per minute (brpm), a bias of -0.09 brpm, and limits of agreement (LoA) from -4.28 to 4.09 brpm. Results were consistent across the different demographic subgroups. The CardioWatch 287-2 therefore demonstrated reliable RR monitoring during HIIT, supporting its potential use in healthcare settings for continuous, non-invasive respiratory monitoring, particularly in physical rehabilitation and chronic respiratory condition management.",
      "authors": "Muller Marjolein; Ebrahimkheil Kambiz; Vijgeboom Tara; van Eijck Casper; Ronner Eelko",
      "year": "2024",
      "journal": "Biosensors",
      "doi": "10.3390/bios14120631",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39727896/",
      "mesh_terms": "Humans; Photoplethysmography; Respiratory Rate; Male; Female; Adult; Monitoring, Physiologic; High-Intensity Interval Training; Algorithms; Young Adult",
      "keywords": "continuous monitoring; high-intensity interval training; photoplethysmography; remote monitoring; respiration rate",
      "pub_types": "Journal Article",
      "pmcid": "PMC11674237"
    },
    {
      "pmid": "28943779",
      "title": "Accounting for misclassification in electronic health records-derived exposures using generalized linear finite mixture models.",
      "abstract": "Exposures derived from electronic health records (EHR) may be misclassified, leading to biased estimates of their association with outcomes of interest. An example of this problem arises in the context of cancer screening where test indication, the purpose for which a test was performed, is often unavailable. This poses a challenge to understanding the effectiveness of screening tests because estimates of screening test effectiveness are biased if some diagnostic tests are misclassified as screening. Prediction models have been developed for a variety of exposure variables that can be derived from EHR, but no previous research has investigated appropriate methods for obtaining unbiased association estimates using these predicted probabilities. The full likelihood incorporating information on both the predicted probability of exposure-class membership and the association between the exposure and outcome of interest can be expressed using a finite mixture model. When the regression model of interest is a generalized linear model (GLM), the expectation-maximization algorithm can be used to estimate the parameters using standard software for GLMs. Using simulation studies, we compared the bias and efficiency of this mixture model approach to alternative approaches including multiple imputation and dichotomization of the predicted probabilities to create a proxy for the missing predictor. The mixture model was the only approach that was unbiased across all scenarios investigated. Finally, we explored the performance of these alternatives in a study of colorectal cancer screening with colonoscopy. These findings have broad applicability in studies using EHR data where gold-standard exposures are unavailable and prediction models have been developed for estimating proxies.",
      "authors": "Hubbard Rebecca A; Johnson Eric; Chubak Jessica; Wernli Karen J; Kamineni Aruna; Bogart Andy; Rutter Carolyn M",
      "year": "2017",
      "journal": "Health services & outcomes research methodology",
      "doi": "10.1007/s10742-016-0149-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28943779/",
      "mesh_terms": "",
      "keywords": "Colorectal cancer; Electronic health records; Mixture model; Multiple imputation; Screening",
      "pub_types": "Journal Article",
      "pmcid": "PMC5608281"
    },
    {
      "pmid": "25894707",
      "title": "A latent transition analysis for the assessment of structured diagnostic interviews.",
      "abstract": "Structured diagnostic interviews administered by lay people are commonly used to assess psychiatric disorders, including depression, in large epidemiologic studies. Many interviews utilize \"gate\" questions, such as screening questions, that allow interviewers to skip entire survey sections for a particular respondent, saving time and reducing respondent fatigue. However, most depression estimates based on these response data are predicated on the assumption that the gate questions function without measurement error or bias. The tenability of this assumption is questionable, and its violation could compromise the reliability and validity of those estimates of depression. In this study, we used a novel application of latent transition analysis to cross-sectional data, accounting for measurement error in different response pathways through the depression module in the World Mental Health Composite International Diagnostic Interview. The analysis included data from 19,734 participants \u226518 years of age in the Comprehensive Psychiatric Epidemiologic Surveys. The latent transition analysis, allowing for measurement error in screening questions and exclusion criteria, produced a higher estimate of the lifetime probability of experiencing depression than did the algorithm based on the Diagnostic and Statistical Manual for Mental Disorders, 4th Edition, Text Revision. This illustration of latent transition analysis applied to item-level data from a complex structured diagnostic tool with gate questions demonstrates the potential utility of an analytic approach that does not automatically assume gate questions function without measurement error. This model could also be used to probe for evidence of measurement bias in the form of differential item function when using structured diagnostic tools in different cultures and languages.",
      "authors": "Scorza Pamela; Masyn Katherine E; Salomon Joshua A; Betancourt Theresa S",
      "year": "2015",
      "journal": "Psychological assessment",
      "doi": "10.1037/pas0000094",
      "url": "https://pubmed.ncbi.nlm.nih.gov/25894707/",
      "mesh_terms": "Adult; Algorithms; Bias; Cross-Sectional Studies; Depression; Major Depressive Disorder; Diagnostic and Statistical Manual of Mental Disorders; Epidemiologic Studies; Female; Humans; Interview, Psychological; Male; Mass Screening; Middle Aged; Reproducibility of Results",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC5729585"
    },
    {
      "pmid": "30897441",
      "title": "Mapping dynamics of soil organic matter in croplands with MODIS data and machine learning algorithms.",
      "abstract": "As an important indicator of soil quality, soil organic matter (SOM) significantly contributes to land productivity and ecosystem health. Accurately mapping SOM at regional scales is of critical importance for sustainable agriculture and soil utilization management and remains a grand challenge. Many studies used soil sampling data and machine learning algorithms to predict SOM at regional scales for a given year, while few studies mapped SOM for multiple years and examined its temporal dynamics. We compared the performance of four machine learning algorithms: decision tree (DT), bagging decision tree (BDT), random forest (RF), and gradient boosting regression trees (GBRT) in mapping SOM in Hubei province, China over the 18-year period from 2000 to 2017. Our results showed that RF and DT had the highest coefficient of determination (R2) (0.61) and the lowest potential bias (9.48\u202fg/kg), respectively, while GBRT had the lowest mean error (ME) (1.26\u202fg/kg), root mean squared error (RMSE) (5.41\u202fg/kg) and Lin's concordance correlation coefficient (LCCC) (0.72). The SOM map based on GBRT better captured the distribution of the soil sample data than that based on RF. The trained GBRT model and the spatially explicitly data on explanatory variables (e.g., climate, terrain, remote sensing) were used to predict SOM for each 500\u202fm\u202f\u00d7\u202f500\u202fm grid cell in Hubei for the period from 2000 to 2017. Our results showed that the SOM content of cropland was relatively high in the southeast and relatively low in the north. The SOM content in the topsoil varied from 0.89 to 58.86\u202fg/kg and was averaged at 20.52\u202fg/kg. The mean cropland SOM content of the province exhibited an increasing trend from 2000 to 2017 with an increase of 0.\u202f26\u202fg/kg and a growth rate of 1.28%. Spatially, the SOM content increased in southern Hubei and decreased in central and northern parts of the province. A large portion of the areas with decreasing SOM content in northern Hubei was reclaimed cropland, while a large part of the high-quality cropland with rising SOM content in the east (~0.45\u202f\u00d7\u202f104\u202fha) was lost due to land use change (e.g., urbanization).",
      "authors": "Chen Di; Chang Naijie; Xiao Jingfeng; Zhou Qingbo; Wu Wenbin",
      "year": "2019",
      "journal": "The Science of the total environment",
      "doi": "10.1016/j.scitotenv.2019.03.151",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30897441/",
      "mesh_terms": "",
      "keywords": "Cropland; Digital soil mapping; MODIS; Machine learning algorithms; Multi-year; Soil organic carbon",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "22747900",
      "title": "Enhanced reporting of deaths among Aboriginal and Torres Strait Islander peoples using linked administrative health datasets.",
      "abstract": "BACKGROUND: Aboriginal and Torres Strait Islander peoples are under-reported in administrative health datasets in NSW, Australia. Correct reporting of Aboriginal and Torres Strait Islander peoples is essential to measure the effectiveness of policies and programmes aimed at reducing the health disadvantage experienced by Aboriginal and Torres Strait Islander peoples. This study investigates the potential of record linkage to enhance reporting of deaths among Aboriginal and Torres Strait Islander peoples in NSW, Australia. METHODS: Australian Bureau of Statistics death registration data for 2007 were linked with four population health datasets relating to hospitalisations, emergency department attendances and births. Reporting of deaths was enhanced from linked records using two methods, and effects on patterns of demographic characteristics and mortality indicators were examined. RESULTS: Reporting of deaths increased by 34.5% using an algorithm based on a weight of evidence of a person being Aboriginal or Torres Strait Islander, and by 56.6% using an approach based on 'at least one report' of a person being Aboriginal or Torres Strait Islander. The increase was relatively greater in older persons and those living in less geographically remote areas. Enhancement resulted in a reduction in the urban-remote differential in median age at death and increases in standardised mortality ratios particularly for chronic conditions. CONCLUSIONS: Record linkage creates a statistical construct that helps to correct under-reporting of deaths and potential bias in mortality statistics for Aboriginal and Torres Strait Islander peoples.",
      "authors": "Taylor Lee K; Bentley Jason; Hunt Jennifer; Madden Richard; McKeown Sybille; Brandt Peter; Baker Deborah",
      "year": "2012",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/1471-2288-12-91",
      "url": "https://pubmed.ncbi.nlm.nih.gov/22747900/",
      "mesh_terms": "Adult; Aged; Birth Certificates; Cardiovascular Diseases; Cause of Death; Emergency Medical Services; Female; Hospitalization; Humans; Male; Medical Record Linkage; Middle Aged; Neoplasms; New South Wales; Australian Aboriginal and Torres Strait Islander Peoples",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC3413579"
    },
    {
      "pmid": "41333646",
      "title": "Association between bat-predator species richness and Nipah virus spillover risk in Bangladesh.",
      "abstract": "Species biodiversity is considered to reduce infectious diseases spillover from wildlife to human. However, despite the potential role of predator biodiversity in this process through trophic cascade, few studies have addressed this issue. In this study, we investigated the association between predator biodiversity and spillover risk, using Nipah virus infection in Bangladesh as an example, where spillover from bats to human has been reported since 2021. We defined counties of Bangladesh as epidemiological units. From three Orders (Strigiformes, Accipitriformes, and Falconiformes) known as bat-preying predators, we extracted 39 species occurrences data and then built species distribution model using MaxEnt algorithm with climate and environmental predictors, also incorporating a bias grid to account for reporting bias. Species presence and richness were estimated under varying classification thresholds and species subsets reported to prey bats to allow sensitivity analyses, yielding 12 measures of species richness for each Order. We then used spatial model to identify the association between the species richness and the counties with spillover event, while adjusting for confounders. Results showed that greater biodiversity of owls (Strigiformes) is likely to reduce the risk of Nipah virus spillover. In contrast, the biodiversity of eagles (Accipitriformes) and falcons (Falconiformes) have a potential of positive association, but evidence was insufficient. This result can be explained by the differences in activity rhythms. Owls share a nocturnal activity rhythm with bats, providing more opportunities to prey on bats and reduce their activity, thereby lowering spillover risk. In contrast, eagles and falcons are diurnal, and thus less likely to suppress bat activity directly. Instead, they may suppress species that compete with bats for food, inadvertently facilitating bat activity and increasing spillover risk. These results suggest that biodiversity should be more explicitly considered in public health governance and spillover prevention strategies.",
      "authors": "Lim Jun-Sik; Min Kyung-Duk",
      "year": "2025",
      "journal": "One health (Amsterdam, Netherlands)",
      "doi": "10.1016/j.onehlt.2025.101274",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41333646/",
      "mesh_terms": "",
      "keywords": "Biodiversity; Nipah virus; Predator; Spillover",
      "pub_types": "Journal Article",
      "pmcid": "PMC12666050"
    },
    {
      "pmid": "39877172",
      "title": "Automating hock wound detection in dairy cattle.",
      "abstract": "Hock scoring in dairy cattle is a crucial welfare assessment tool used to evaluate the condition of a cow's hocks, particularly for signs of injury, swelling, or lesions. These scores provide insight into the overall well-being of the animals and are essential for ensuring proper management and housing conditions. Accurate hock scoring is vital because it can indicate issues such as poor bedding quality or inadequate space, which directly affect the health and productivity of the herd. Traditionally, hock scoring is performed manually by trained observers. However, consistency in scoring can be a challenge. Two studies were conducted to quantify inconsistency in hock scoring. In one study, manual scoring reproducibility was measured. In the second study, manual and video scoring repeatability was measured. Repeatability was quantified with a weighted Cohen's kappa metric. Manual scoring was found to be inconsistent but more consistent than video scoring. This variability highlights the need for a more reliable, objective method of scoring. To address this, we explored the automation of hock score detection using artificial intelligence. Specifically, we employed a simple U-net semantic segmentation algorithm to detect wounds on the hocks without classifying them into specific categories. Automating the detection process can reduce observer bias, improve consistency, and allow for continuous monitoring of large herds. This approach holds promise for enhancing animal welfare by providing a more efficient and accurate method of assessing hock health in dairy cattle.",
      "authors": "Flanders W; Basran P S; Wieland M",
      "year": "2025",
      "journal": "JDS communications",
      "doi": "10.3168/jdsc.2024-0671",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39877172/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11770321"
    },
    {
      "pmid": "37856186",
      "title": "Patient Health Questionnaire-9 Item Pairing Predictiveness for Prescreening Depressive Symptomatology: Machine Learning Analysis.",
      "abstract": "BACKGROUND: Anhedonia and depressed mood are considered the cardinal symptoms of major depressive disorder. These are the first 2 items of the Patient Health Questionnaire (PHQ)-9 and comprise the ultrabrief PHQ-2 used for prescreening depressive symptomatology. The prescreening performance of alternative PHQ-9 item pairings is rarely compared with that of the PHQ-2. OBJECTIVE: This study aims to use machine learning (ML) with the PHQ-9 items to identify and validate the most predictive 2-item depressive symptomatology ultrabrief questionnaire and to test the generalizability of the best pairings found on the primary data set, with 6 external data sets from different populations to validate their use as prescreening instruments. METHODS: All 36 possible PHQ-9 item pairings (each yielding scores of 0-6) were investigated using ML-based methods with logistic regression models. Their performances were evaluated based on the classification of depressive symptomatology, defined as PHQ-9 scores \u226510. This gave each pairing an equal opportunity and avoided any bias in item pairing selection. RESULTS: The ML-based PHQ-9 items 2 and 4 (phq2&4), the depressed mood and low-energy item pairing, and PHQ-9 items 2 and 8 (phq2&8), the depressed mood and psychomotor retardation or agitation item pairing, were found to be the best on the primary data set training split. They generalized well on the primary data set test split with area under the curves (AUCs) of 0.954 and 0.946, respectively, compared with an AUC of 0.942 for the PHQ-2. The phq2&4 had a higher AUC than the PHQ-2 on all 6 external data sets, and the phq2&8 had a higher AUC than the PHQ-2 on 3 data sets. The phq2&4 had the highest Youden index (an unweighted average of sensitivity and specificity) on 2 external data sets, and the phq2&8 had the highest Youden index on another 2. The PHQ-2\u22652 cutoff also had the highest Youden index on 2 external data sets, joint highest with the phq2&4 on 1, but its performance fluctuated the most. The PHQ-2\u22653 cutoff had the highest Youden index on 1 external data set. The sensitivity and specificity achieved by the phq2&4 and phq2&8 were more evenly balanced than the PHQ-2\u22652 and \u22653 cutoffs. CONCLUSIONS: The PHQ-2 did not prove to be a more effective prescreening instrument when compared with other PHQ-9 item pairings. Evaluating all item pairings showed that, compared with alternative partner items, the anhedonia item underperformed alongside the depressed mood item. This suggests that the inclusion of anhedonia as a core symptom of depression and its presence in ultrabrief questionnaires may be incompatible with the empirical evidence. The use of the PHQ-2 to prescreen for depressive symptomatology could result in a greater number of misclassifications than alternative item pairings.",
      "authors": "Glavin Darragh; Grua Eoin Martino; Nakamura Carina Akemi; Scazufca Marcia; Ribeiro Dos Santos Edinilza; Wong Gloria H Y; Hollingworth William; Peters Tim J; Araya Ricardo; Van de Ven Pepijn",
      "year": "2023",
      "journal": "JMIR mental health",
      "doi": "10.2196/48444",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37856186/",
      "mesh_terms": "",
      "keywords": "PHQ-2; PHQ-9 items; Patient Health Questionnaire-2; Patient Health Questionnaire-9; cardinal symptoms; depressed mood; depressive symptomatology; low energy; machine learning; prescreening; psychomotor dysfunction; ultrabrief questionnaires",
      "pub_types": "Journal Article",
      "pmcid": "PMC10623235"
    },
    {
      "pmid": "29019317",
      "title": "PRECEPT: an evidence assessment framework for infectious disease epidemiology, prevention and control.",
      "abstract": "Decisions in public health should be based on the best available evidence, reviewed and appraised using a rigorous and transparent methodology. The Project on a Framework for Rating Evidence in Public Health (PRECEPT) defined a methodology for evaluating and grading evidence in infectious disease epidemiology, prevention and control that takes different domains and question types into consideration. The methodology rates evidence in four domains: disease burden, risk factors, diagnostics and intervention. The framework guiding it has four steps going from overarching questions to an evidence statement. In step 1, approaches for identifying relevant key areas and developing specific questions to guide systematic evidence searches are described. In step 2, methodological guidance for conducting systematic reviews is provided; 15 study quality appraisal tools are proposed and an algorithm is given for matching a given study design with a tool. In step 3, a standardised evidence-grading scheme using the Grading of Recommendations Assessment, Development and Evaluation Working Group (GRADE) methodology is provided, whereby findings are documented in evidence profiles. Step 4 consists of preparing a narrative evidence summary. Users of this framework should be able to evaluate and grade scientific evidence from the four domains in a transparent and reproducible way.",
      "authors": "Harder Thomas; Takla Anja; Eckmanns Tim; Ellis Simon; Forland Frode; James Roberta; Meerpohl Joerg J; Morgan Antony; Rehfuess Eva; Sch\u00fcnemann Holger; Zuiderent-Jerak Teun; de Carvalho Gomes Helena; Wichmann Ole",
      "year": "2017",
      "journal": "Euro surveillance : bulletin Europeen sur les maladies transmissibles = European communicable disease bulletin",
      "doi": "10.2807/1560-7917.ES.2017.22.40.16-00620",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29019317/",
      "mesh_terms": "Communicable Disease Control; Communicable Diseases; Evidence-Based Medicine; Humans; Public Health",
      "keywords": "GRADE; decision-making; evidence-based medicine; meta-analysis; methodology; risk of bias; systematic reviews",
      "pub_types": "Journal Article",
      "pmcid": "PMC5710124"
    },
    {
      "pmid": "35562401",
      "title": "Improving the design stage of air pollution studies based on wind patterns.",
      "abstract": "A growing literature in economics and epidemiology has exploited changes in wind patterns as a source of exogenous variation to better measure the acute health effects of air pollution. Since the distribution of wind components is not randomly distributed over time and related to other weather parameters, multivariate regression models are used to adjust for these confounding factors. However, this type of analysis relies on its ability to correctly adjust for all confounding factors and extrapolate to units without empirical counterfactuals. As an alternative to current practices and to gauge the extent of these issues, we propose to implement a causal inference pipeline to embed this type of observational study within an hypothetical randomized experiment. We illustrate this approach using daily data from Paris, France, over the 2008-2018 period. Using the Neyman-Rubin potential outcomes framework, we first define the treatment of interest as the effect of North-East winds on particulate matter concentrations compared to the effects of other wind directions. We then implement a matching algorithm to approximate a pairwise randomized experiment. It adjusts nonparametrically for observed confounders while avoiding model extrapolation by discarding treated days without similar control days. We find that the effective sample size for which treated and control units are comparable is surprisingly small. It is however reassuring that results on the matched sample are consistent with a standard regression analysis of the initial data. We finally carry out a quantitative bias analysis to check whether our results could be altered by an unmeasured confounder: estimated effects seem robust to a relatively large hidden bias. Our causal inference pipeline is a principled approach to improve the design of air pollution studies based on wind patterns.",
      "authors": "Zabrocki L\u00e9o; Alari Anna; Benmarhnia Tarik",
      "year": "2022",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-022-11939-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35562401/",
      "mesh_terms": "Air Pollutants; Air Pollution; Environmental Monitoring; Particulate Matter; Weather; Wind",
      "keywords": "",
      "pub_types": "Journal Article; Observational Study",
      "pmcid": "PMC9106699"
    },
    {
      "pmid": "40151928",
      "title": "Exposure to Systemic Antimicrobials During Pregnancy and Risk of Miscarriage: A Population-Based Registry Study.",
      "abstract": "OBJECTIVE: To estimate miscarriage risk following gestational antimicrobial exposure while addressing biases that have affected previous studies. DESIGN: Population-based cohort study. SETTING: Linkage of four nationwide registries: Medical Birth Registry of Norway (MBRN), Norwegian Prescribed Drug Registry (NorPD), Norwegian Patient Registry (NPR) and Norwegian Control and Payment of Health Reimbursements Database (KUHR). POPULATION OR SAMPLE: A total of 704\u2009082 pregnancies (2009-2018), with 91\u2009836 (13.0%) exposed to systemic antimicrobials in early pregnancy. METHODS: Time-stratified Cox regression models with overlap weights were used, considering time-varying exposures and a 14-day lag to prevent reverse causation. Elective terminations were right-censored to address competing risks, with adjustment for common infections and probabilistic bias analysis for confounding by indication. MAIN OUTCOME MEASURES: Miscarriage and gestational age at miscarriage, captured from NPR, KUHR and MBRN, using the UiO pregnancy algorithm. RESULTS: Nitrofurantoin, pivmecillinam and amoxicillin were not associated with increased miscarriage risk. Metronidazole (HR\u2009=\u20092.00; 95% CI: 1.82-2.21), ciprofloxacin (HR\u2009=\u20091.89; 95% CI: 1.62-2.20), cephalexin (HR\u2009=\u20091.87; 95% CI: 1.57-2.22), fluconazole (HR\u2009=\u20091.61; 95% CI: 1.45-1.78), trimethoprim-sulfas (HR\u2009=\u20091.49; 95% CI: 1.36-1.63) and others showed associations with miscarriage. Probabilistic bias analysis indicated that associations for common antimicrobials may be driven by the underlying infections. CONCLUSIONS: Nitrofurantoin, pivmecillinam and amoxicillin did not increase miscarriage risk, but other less commonly used antimicrobials may carry higher risks. By addressing key biases, this study provided a more reliable assessment of miscarriage risks associated with antimicrobial use in early pregnancy.",
      "authors": "Boissiere-O'Neill Thomas; van Gelder Marleen M H J; Engjom Hilde M; Nordeng Hedvig M E",
      "year": "2025",
      "journal": "BJOG : an international journal of obstetrics and gynaecology",
      "doi": "10.1111/1471-0528.18155",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40151928/",
      "mesh_terms": "",
      "keywords": "antibiotics; antimycotics; competing risk; elective termination; miscarriage; time\u2010related bias",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34912547",
      "title": "Validation of community health worker identification of maternal puerperal sepsis using a clinical diagnostic algorithm in Bangladesh and Pakistan.",
      "abstract": "BACKGROUND: Puerperal sepsis (PP sepsis) is a leading cause of maternal mortality globally. The majority of maternal sepsis cases and deaths occur at home and remain undiagnosed and under-reported. In this paper, we present findings from a nested case-control study in Bangladesh and Pakistan which sought to assess the validity of community health worker (CHW) identification of PP sepsis using a clinical diagnostic algorithm with physician assessment and classification used as the gold standard. METHODS: Up to 300 postpartum women were enrolled in each of the 3 sites 1) Sylhet, Bangladesh (n\u2009=\u2009278), 2) Karachi, Pakistan (n\u2009=\u2009278) and 3) Matiari, Pakistan (n\u2009=\u2009300). Index cases were women with suspected PP Sepsis as diagnosed by CHWs clinical assessment of one or more of the following signs and symptoms: temperature (recorded fever \u226538.1\u00b0C, reported history of fever, lower abdominal or pelvic pain, and abnormal or foul-smelling discharge. Each case was matched with 3 control women who were diagnosed by CHWs to have no infection. Cases and controls were assessed by trained physicians using the same algorithm implemented by the CHWs. Using physician assessment as the gold standard, Kappa statistics for reliability and diagnostic validity (sensitivity and specificity) are presented with 95% CI. Sensitivity and specificity were adjusted for verification bias. RESULTS: The adjusted sensitivity and specificity of CHW identification of PP sepsis across all sites was 82% (Karachi: 78%, Matiari: 78%, Sylhet: 95%) and 90% (Karachi: 95%, Matiari: 85%, Sylhet: 90%) respectively. CHW-Physician agreement was highest for moderate and high fever (range across sites: K\u2009=\u20090.84-0.97) and lowest for lower abdominal pain (K\u2009=\u20090.30-0.34). The clinical signs and symptoms for other conditions were reported infrequently, however, the CHW-physician agreement was high for all symptoms except severe headache/ blurred vision (K\u2009=\u20090.13-0.38) and reported \"lower abdominal pain without fever\" (K\u2009=\u20090.39-0.57). CONCLUSION: In all sites, CHWs with limited training were able to identify signs and symptoms and to classify cases of PP sepsis with high validity. Integrating postpartum infection screening into existing community-based platforms and post-natal visits is a promising strategy to monitor women for PP sepsis - improving delivery of cohesive maternal and child health care in low resource settings.",
      "authors": "LeFevre Amnesty E; Mir Fatima; Mitra Dipak K; Ariff Shabina; Mohan Diwakar; Ahmed Imran; Sultana Shazia; Winch Peter J; Shakoor Sadia; Connor Nicholas E; Islam Mohammad Shahidul; El-Arifeen Shams; Quaiyum M A; Baqui Abdullah H; Gravett Michael G; Santosham Mathuram; Bhutta Zulfiqar A; Zaidi Anita; Saha Samir K; Ahmed Saifuddin; Soofi Sajid; Bartlett Linda A",
      "year": "2021",
      "journal": "Journal of global health",
      "doi": "10.7189/jogh.11.04039",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34912547/",
      "mesh_terms": "Algorithms; Bangladesh; Case-Control Studies; Child; Community Health Workers; Female; Humans; Pakistan; Postpartum Period; Pregnancy; Pregnancy Complications, Infectious; Reproducibility of Results; Sepsis",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC8645220"
    },
    {
      "pmid": "35617022",
      "title": "Life Course Digital Twins-Intelligent Monitoring for Early and Continuous Intervention and Prevention (LifeTIME): Proposal for a Retrospective Cohort Study.",
      "abstract": "BACKGROUND: Multimorbidity, which is associated with significant negative outcomes for individuals and health care systems, is increasing in the United Kingdom. However, there is a lack of knowledge about the risk factors (including health, behavior, and environment) for multimorbidity over time. An interdisciplinary approach is essential, as data science, artificial intelligence, and engineering concepts (digital twins) can identify key risk factors throughout the life course, potentially enabling personalized simulation of life-course risk for the development of multimorbidity. Predicting the risk of developing clusters of health conditions before they occur would add clinical value by enabling targeted early preventive interventions, advancing personalized care to improve outcomes, and reducing the burden on health care systems. OBJECTIVE: This study aims to identify key risk factors that predict multimorbidity throughout the life course by developing an intelligent agent using digital twins so that early interventions can be delivered to improve health outcomes. The objectives of this study are to identify key predictors of lifetime risk of multimorbidity, create a series of simulated computational digital twins that predict risk levels for specific clusters of factors, and test the feasibility of the system. METHODS: This study will use machine learning to develop digital twins by identifying key risk factors throughout the life course that predict the risk of later multimorbidity. The first stage of the development will be the training of a base predictive model. Data from the National Child Development Study, the North West London Integrated Care Record, the Clinical Practice Research Datalink, and Cerner's Real World Data will be split into subsets for training and validation, which will be done following the k-fold cross-validation procedure and assessed with the Prediction Model Risk of Bias Assessment Tool (PROBAST). In addition, 2 data sets-the Early-Life Data Cross-linkage in Research study and the Children and Young People's Health Partnership randomized controlled trial-will be used to develop a series of digital twin personas that simulate clusters of factors to predict different risk levels of developing multimorbidity. RESULTS: The expected results are a validated model, a series of digital twin personas, and a proof-of-concept assessment. CONCLUSIONS: Digital twins could provide an individualized early warning system that predicts the risk of future health conditions and recommends the most effective intervention to minimize that risk. These insights could significantly improve an individual's quality of life and healthy life expectancy and reduce population-level health burdens. INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): PRR1-10.2196/35738.",
      "authors": "Milne-Ives Madison; Fraser Lorna K; Khan Asiya; Walker David; van Velthoven Michelle Helena; May Jon; Wolfe Ingrid; Harding Tracey; Meinert Edward",
      "year": "2022",
      "journal": "JMIR research protocols",
      "doi": "10.2196/35738",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35617022/",
      "mesh_terms": "",
      "keywords": "AI; NCDS; artificial intelligence; health care; machine learning; mental health; mulitmorbidity; national child development study; outcome",
      "pub_types": "Journal Article",
      "pmcid": "PMC9185337"
    },
    {
      "pmid": "41217035",
      "title": "A novel, standardised approach to balancing effectiveness, efficiency and utility of surveillance AI prediction models for hospitalised patients using sepsis prediction as an exemplar.",
      "abstract": "OBJECTIVE: To introduce a novel, standardised approach to evaluating AI prediction models in balancing effectiveness, efficiency and utility, using a sepsis prediction model case study. MATERIALS AND METHODS: Retrospective patient data from electronic medical records of 7 public hospitals was used to retrain and evaluate a machine learning sepsis prediction model. Four conventional metrics-area under the receiver operating curve (AUROC), sensitivity, positive predictive value, and specificity-were compared with a novel graphical display integrating metrics of predictive accuracy (effectiveness), alert burden (efficiency) and lead time of alerts relative to clinical events (utility) for different alert thresholds. RESULTS: The dataset comprised 977,506 inpatient admissions. The novel methodology produced a plot of four vertically aligned graphs that enables decision-makers to identify an alert threshold that optimally balances effectiveness, efficiency and utility (EEU) at the level of an entire admission, and which differs from that derived using conventional metrics. DISCUSSION: Conventional evaluation metrics do not consider alert timing relative to clinical events and are often applied to different evaluation datasets (sample and admission level), introducing bias and confusion. In contrast, the EEU methodology (i) generates admission level evaluations at different alert thresholds; (ii) measures alert timing relative to clinical events; and (iii) provides a visual display that enables identification of the alert threshold that optimally balances EEU factors. CONCLUSION: Evaluations of prediction models for adverse events in hospitalised patients should incorporate the EEU approach in assessing model suitability and selecting alert thresholds.",
      "authors": "van der Vegt Anton H; Campbell Victoria K; Webb Robert; Venkatesh Balasubramanian; Lane Paul J; Wilks Kathryn; McPhail Steven; Rice Michael; Isaacs Tara; Abdel-Hafez Ahmad; Whebell Stephen; Irwin Adam; Schnetler Rudolf J; Shetty Amith; Scott Ian A",
      "year": "2026",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf192",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41217035/",
      "mesh_terms": "Humans; Sepsis; Retrospective Studies; Machine Learning; Hospitalization; Electronic Health Records; ROC Curve; Female; Male; Sensitivity and Specificity; Area Under Curve",
      "keywords": "ROC curve; adult; clinical; decision support systems; electronic health records/statistics and numerical data; emergency service; hospital/statistics and numerical data; hospitalization/statistics and numerical data; machine learning; retrospective studies; sepsis/mortality",
      "pub_types": "Journal Article",
      "pmcid": "PMC12844580"
    },
    {
      "pmid": "37571616",
      "title": "Failure Severity Prediction for Protective-Coating Disbondment via the Classification of Acoustic Emission Signals.",
      "abstract": "Structural health monitoring is a popular inspection method that utilizes acoustic emission (AE) signals for fault detection in engineering infrastructures. Diagnosis based on the propagation of AE signals along any surface material offers an attractive solution for fault identification. However, the classification of AE signals originating from failure events, especially coating failure (coating disbondment), is a challenging task given the AE signature of each material. Thus, different experimental settings and analyses of AE signals are required to classify the various types of coating failures, and they are time-consuming and expensive. Hence, to address these issues, we utilized machine learning (ML) classification models in this work to evaluate epoxy-based-protective-coating disbondment based on the AE principle. A coating disbondment experiment consisting of coated carbon steel test panels for the collection of AE signals was implemented. The obtained AE signals were then processed to construct the final dataset to train various state-of-the-art ML classification models to divide the failure severity of coating disbondment into three classes. Consequently, methods for the extraction of useful features, the handling of data imbalance, and a reduction in the bias of ML models were also effectively utilized in this study. Evaluations of state-of-the-art ML classification models on the AE signal dataset in terms of standard metrics revealed that the decision forest classification model outperformed the other state-of-the-art models, with accuracy, precision, recall, and F1 score values of 99.48%, 98.76%, 97.58%, and 98.17%, respectively. These results demonstrate the effectiveness of utilizing ML classification models for the failure severity prediction of protective-coating defects via AE signals.",
      "authors": "Rahman Noor A'in A; May Zazilah; Jaffari Rabeea; Hanif Mehwish",
      "year": "2023",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s23156833",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37571616/",
      "mesh_terms": "",
      "keywords": "acoustic emission; classification; coating disbondment; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC10422202"
    },
    {
      "pmid": "40118896",
      "title": "Exploring PM2.5 and PM10 ML forecasting models: a comparative study in the UAE.",
      "abstract": "Particulate Matters PM[Formula: see text] and PM[Formula: see text] present a major health and environmental concern in urban regions. This research compares machine learning and time series models, such as Decision Tree (DT), Random Forest (RF), Support Vector Regression (SVR), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), and Facebook Prophet, for predictions of these matters. Their performances have been evaluated over 1-2 hours, 1 day and 1 week forecasting periods using five years real-life data from six ground stations in Abu Dhabi, UAE. Performance metrics including Mean Absolute Percentage Error (MAPE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Percent Bias (PBIAS) were applied. Linear SVR was generally the best performing model for PM[Formula: see text] predictions at all stations with averages of 18.7% and 28.2% MAPE for 1 and 2-hour periods, respectively. However, CNN performed best in forecasting PM[Formula: see text] for 1-hour horizon, with an average MAPE of 12.6%. For the 2-hour forecast, SVR outperformed other models, with 18.3% MAPE. Facebook Prophet consistently outperformed others for both PM[Formula: see text] and PM[Formula: see text] with 21.8% and 13.4% MAPE for 1-day and 21.3% and 13.8% MAPE for 1-week, respectively. These best performing models yielded similar RMSE, MAE, and PBIAS values for both PM[Formula: see text] and PM[Formula: see text].",
      "authors": "Abuouelezz Waad; Ali Nazar; Aung Zeyar; Altunaiji Ahmed; Shah Shaik Basheeruddin; Gliddon Derek",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-94013-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40118896/",
      "mesh_terms": "",
      "keywords": "Air pollution; Convolutional neural network; Decision tree; Facebook Prophet; Long short-term memory; Machine learning; PM10; PM2.5; Random forest; Support vector regression",
      "pub_types": "Journal Article",
      "pmcid": "PMC11928502"
    },
    {
      "pmid": "34141981",
      "title": "Patient Determinants for Histologic Diagnosis of NAFLD in the Real World: A TARGET-NASH Study.",
      "abstract": "Much of the current data on nonalcoholic fatty liver disease (NAFLD) are derived from biopsy-based studies that may introduce ascertainment and selection bias. Selection of patients for liver biopsy has implications for clinical practice and the reported epidemiology of NAFLD. The aim of this study was to determine patient factors predictive of histologic versus empiric clinical diagnosis of NAFLD in real-world practice. Adults from TARGET-NASH were included in this study. Descriptive statistics are provided for the cohort and compare the characteristics of histologic NAFLD versus patients with clinically diagnosed NAFLD, followed by logistic regression and machine-learning models to describe predictors of liver biopsy. The records of 3,474 subjects were analyzed; median age was 59 years, 59% were female, 75% were White, and median body mass index was 32 kg/m2. Using histologic and/or clinical criteria, a diagnosis of nonalcoholic steatohepatitis was made in 37%, and cirrhosis in 33%. Comorbid conditions included cardiovascular disease (19%), mental health diagnoses (49%), and osteoarthritis (10%). Predictors of a biopsy diagnosis included White race, female sex, diabetes, and elevated alanine aminotransferase (ALT). ALT increased the odds of liver biopsy by 14% per 10-point rise. Machine-learning analyses showed non-White patients with ALT <69 had only a 0.06 probability of undergoing liver biopsy. ALT was the dominant variable that determined liver biopsy. Conclusions: In this real-world cohort of patients with NAFLD, two-thirds of patients did not have a liver biopsy. These patients were more likely to be non-White, older, with a normal ALT, showing potential gaps in or knowledge about this population.",
      "authors": "Barritt A Sidney; Watkins Stephanie; Gitlin Norman; Klein Samuel; Lok Anna S; Loomba Rohit; Schoen Cheryl; Reddy K Rajender; Trinh Huy Ngoc; Mospan Andrea R; Vos Miriam B; Weiss L Michael; Cusi Kenneth; Neuschwander-Tetri Brent A; Sanyal Arun J",
      "year": "2021",
      "journal": "Hepatology communications",
      "doi": "10.1002/hep4.1689",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34141981/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC8183178"
    },
    {
      "pmid": "40472281",
      "title": "Investigating Symptom Duration Using Current Status Data: A Case Study of Postacute COVID-19 Syndrome.",
      "abstract": "BACKGROUND: For infectious diseases, characterizing symptom duration is of clinical and public health importance. Symptom duration may be assessed by surveying infected individuals and querying symptom status at the time of survey response. For example, in a severe acute respiratory syndrome coronavirus 2 testing program at the University of Washington, participants were surveyed at least 28 days after testing positive and asked to report current symptom status. This study design yielded current status data: outcome measurements for each respondent consisted only of the time of survey response and a binary indicator of whether symptoms had resolved by that time. Such study design benefits from limited risk of recall bias, but analyzing the resulting data necessitates tailored statistical tools. METHODS: We review methods for current status data and describe a novel application of modern nonparametric techniques to this setting. The proposed approach is valid under weaker assumptions compared with existing methods, allows the use of flexible machine learning tools, and handles potential survey nonresponse. Our method relies on the assumption that the survey response time is conditionally independent of symptom resolution time within strata of measured covariates, and we propose an approach to assess the sensitivity of results to deviations from conditional independence. RESULTS: From the university study, we estimate that 19% of participants experienced ongoing symptoms 30 days after testing positive, decreasing to 7% at 90 days. We found the estimates to be more sensitive to violations of the conditional independence assumption at 30 days compared with 90 days. Female sex, fatigue during acute infection, and higher viral load were associated with slower symptom resolution. CONCLUSION: The proposed method and accompanying sensitivity analysis procedure provide tools for investigators faced with current status data.",
      "authors": "Wolock Charles J; Jacob Susan; Bennett Julia C; Elias-Warren Anna; O'Hanlon Jessica; Kenny Avi; Jewell Nicholas P; Rotnitzky Andrea; Cole Stephen R; Weil Ana A; Chu Helen Y; Carone Marco",
      "year": "2025",
      "journal": "Epidemiology (Cambridge, Mass.)",
      "doi": "10.1097/EDE.0000000000001882",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40472281/",
      "mesh_terms": "Humans; COVID-19; Post-Acute COVID-19 Syndrome; Time Factors; Female; Male; SARS-CoV-2; Adult; Middle Aged; Washington",
      "keywords": "Interval censoring; Long COVID; Machine learning; Nonparametric; Survival analysis",
      "pub_types": "Journal Article",
      "pmcid": "PMC12854790"
    },
    {
      "pmid": "41082207",
      "title": "Derivation and Validation of Predictive Models for Early Pediatric Sepsis.",
      "abstract": "IMPORTANCE: Sepsis is a leading cause of death in children. Early recognition and treatment improve outcomes, but predictive models have not to date improved early diagnosis. OBJECTIVE: To develop machine learning models to estimate the probability of developing sepsis in the subsequent 48 hours. DESIGN, SETTING, AND PARTICIPANTS: This was a multisite registry for model derivation and validation using electronic health record (EHR) data from January 2016 through February 2020 and temporal validation from January 2021 through December 2022. The performance of machine learning algorithms was compared to predict development of sepsis and septic shock via logistic regression, specifically ridge regression and gradient tree boosting. Five health systems contributing to the Pediatric Emergency Care Applied Research Network were included. Emergency department (ED) visits for children aged 2 months or older to less than 18 years of age excluding patients with ED disposition of death or transfer, trauma diagnosis, or sepsis present during predictive features window. The TRIPOD-AI reporting guideline was followed, and data analysis was conducted from September 2023 to July 2025. EXPOSURES: Patient and physiologic characteristics within the first 4 hours of ED care. MAIN OUTCOMES AND MEASURES: Sepsis, defined as suspected infection with a Phoenix Sepsis Criteria (PSC) score of 2 or more or death within 48 hours of ED arrival. RESULTS: The dataset included 1\u202f604\u202f422 eligible visits in the training cohort and 719\u202f298 visits in the test cohort. Performance characteristics for the PSC sepsis prediction models were AUROC of 0.92 (95% CI, 0.92-0.93) for logistic regression and 0.94 (95% CI, 0.93-0.94) for gradient tree boosting. AUROCs for PSC shock models were 0.92 or greater. The gradient tree boosting models had positive likelihood ratios ranging from 4.67 (95% CI, 4.61-4.74) to 6.18 (95% CI, 6.08-6.28) for sepsis and from 4.16 (95% CI, 4.07-4.24) to 5.83 (95% CI, 5.67-5.99) for septic shock. Predictive features included emergency severity index, age-adjusted vital signs, and medical complexity. Assessment of model performance fairness was similar for all demographic characteristics except payor; AUROC for patients with Medicaid insurance was better than for those with commercial payers. CONCLUSIONS AND RELEVANCE: Using a large multicenter population, models were developed and validated with high AUROC to predict the future development of sepsis based on EHR data collected in the ED. The models achieved positive likelihood ratios to predict sepsis and septic shock. The results highlight the opportunity for future studies that combine EHR-based models with clinical judgment to improve prediction.",
      "authors": "Alpern Elizabeth R; Scott Halden F; Balamuth Fran; Chamberlain James M; Depinet Holly; Bajaj Lalit; Simon Norma-Jean E; Carter Camille P; Elsholz Cara; Webb Michael; Campos Diego; Deakyne Davies Sara J; Cook Lawrence J; Ungar Lyle; Grundmeier Robert",
      "year": "2025",
      "journal": "JAMA pediatrics",
      "doi": "10.1001/jamapediatrics.2025.3892",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41082207/",
      "mesh_terms": "Humans; Sepsis; Male; Female; Child, Preschool; Infant; Child; Machine Learning; Emergency Service, Hospital; Adolescent; Early Diagnosis; Registries; Electronic Health Records; Logistic Models; Predictive Value of Tests",
      "keywords": "",
      "pub_types": "Journal Article; Multicenter Study; Validation Study",
      "pmcid": "PMC12519407"
    },
    {
      "pmid": "41358286",
      "title": "Prior knowledge informs graph neural networks to improve phenotype prediction from proteomics.",
      "abstract": "High-throughput proteomics data provides dense individual-level molecular readouts, enabling the development of machine learning models for predicting diverse phenotypes relevant to patient health. Proteins interact in the cell in complex, nonlinear relationships that may not be reflected by linear models or simple machine learning approaches, highlighting the potential for more expressive deep neural networks to improve performance. Despite this possibility, in practice, developing neural network approaches in biological domains has been a significant challenge. We developed a deep learning framework for predicting disease-related traits from protein expression data using an innovative model architecture designed to exploit structured biological knowledge. The core of the model is a graph neural network (GNN) operating on bipartite graphs where one set of nodes represents protein expression levels and the other represents hundreds of protein sets derived from gene ontology libraries. Edges encode set membership, providing a compact and biologically meaningful structure. We trained our model using the UK Biobank plasma proteomics and individual phenotype data. Of the architectures we examined, the best-performing architecture had three parallel heads: two GNNs each using graphs constructed with independent protein set libraries and one global head consisting of tabular protein expression data. Their outputs are concatenated and passed through a dense feed-forward network to predict phenotype. When applied to predicting glycated hemoglobin (HbA1c) levels and a range of other phenotypes, our model showed strong predictive performance, outperforming other deep learning architectures and simpler linear models. Control models with permuted protein labels displayed worse performance demonstrating that the model benefits from the inductive bias from incorporating prior knowledge, especially in settings with limited training data. We present an innovative model architecture incorporating biological domain knowledge to predict complex traits from large scale proteomic data.",
      "authors": "Dastidar Prabuddha Ghosh; Fridell Gus; Popp Joshua M; Arvanitis Marios; Battle Alexis",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2025.11.23.25340814",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41358286/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12676398"
    },
    {
      "pmid": "37430279",
      "title": "Combining crowd-sourcing, census data, and public review forums for real-time, high-resolution food desert estimation.",
      "abstract": "BACKGROUND: It has been hypothesized that low access to healthy and nutritious food increases health disparities. Low-accessibility areas, called food deserts, are particularly commonplace in lower-income neighborhoods. The metrics for measuring the food environment's health, called food desert indices, are primarily based on decadal census data, limiting their frequency and geographical resolution to that of the census. We aimed to create a food desert index with finer geographic resolution than census data and better responsiveness to environmental changes. MATERIALS AND METHODS: We augmented decadal census data with real-time data from platforms such as Yelp and Google Maps and crowd-sourced answers to questionnaires by the Amazon Mechanical Turks to create a real-time, context-aware, and geographically refined food desert index. Finally, we used this refined index in a concept application that suggests alternative routes with similar ETAs between a source and destination in the Atlanta metropolitan area as an intervention to expose a traveler to better food environments. RESULTS: We made 139,000 pull requests to Yelp, analyzing 15,000 unique food retailers in the metro Atlanta area. In addition, we performed 248,000 walking and driving route analyses on these retailers using Google Maps' API. As a result, we discovered that the metro Atlanta food environment creates a strong bias towards eating out rather than preparing a meal at home when access to vehicles is limited. Contrary to the food desert index that we started with, which changed values only at neighborhood boundaries, the food desert index that we built on top of it captured the changing exposure of a subject as they walked or drove through the city. This model was also sensitive to the changes in the environment that occurred after the census data was collected. CONCLUSIONS: Research on the environmental components of health disparities is flourishing. New machine learning models have the potential to augment various information sources and create fine-tuned models of the environment. This opens the way to better understanding the environment and its effects on health and suggesting better interventions.",
      "authors": "Salari Mohsen; Kramer Michael R; Reyna Matthew A; Taylor Herman A; Clifford Gari D",
      "year": "2023",
      "journal": "Biomedical engineering online",
      "doi": "10.1186/s12938-023-01108-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37430279/",
      "mesh_terms": "Humans; Censuses; Crowdsourcing; Food Deserts; Information Sources; Machine Learning",
      "keywords": "Crowd-sourcing; Food accessibility; Food desert; Geographic information system; Health; Population health",
      "pub_types": "Journal Article",
      "pmcid": "PMC10334591"
    },
    {
      "pmid": "34706445",
      "title": "Difference in patterns of prescribing antidepressants known for their weight-modulating and cardiovascular side effects for patients with obesity compared to patients with normal weight.",
      "abstract": "BACKGROUND: Patients with depression and comorbid obesity may be more prone to weight modulating and cardiovascular side effects of selected antidepressants (AD). It is important to ascertain whether these AD prescriptions differ by patient weight status. METHODS: Canadian Primary Care Sentinel Surveillance Network (CPCSSN) electronic medical records were used. Participants were adults with depression prescribed an AD in 2000-2016, with weight categories established before the first prescription. Logistic regression and mixed effects models were applied to examine associations between obesity and AD prescribing, adjusted for sex, age, and comorbidities. Machine learning algorithm random forest (RF) was used to evaluate the importance of weight in predicting prescribing patterns. RESULTS: Of 26,571 participants, 72.4% were women, mean age was 38.9 years (standard deviation (SD)=14.2) and mean BMI 27.0\u00a0kg/m2 (SD\u00a0=\u00a06.5); 9.5% had \u2265 1 comorbidity. Patients with obesity, compared to normal weight patients, were more likely to receive bupropion (adjusted odds ratio (aOR) 1.24, 95%CI: 1.09,1.42), fluoxetine (aOR 1.14, 95%CI: 0.97,1.34), and amitriptyline (aOR 1.13, 95%CI: 0.93,1.36), and less likely to receive mirtazapine (aOR 0.55, 95%CI: 0.44,0.68) and escitalopram (aOR 0.88, 95%CI: 0.80, 0.97). RF analysis showed that weight was among the most important predictors of prescribing patterns, equivalent to age and more important than sex. CONCLUSIONS: AD prescribing patterns for patients with obesity appear to be different for selected AD types, including AD known for their weight-modulating and cardiovascular side effects. Longitudinal studies are needed to examine whether these prescribing patterns are associated with significant health outcomes.",
      "authors": "Puzhko S; Schuster T; Barnett T A; Renoux C; Munro K; Barber D; Bartlett G",
      "year": "2021",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2021.08.018",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34706445/",
      "mesh_terms": "Adult; Antidepressive Agents; Canada; Citalopram; Female; Humans; Mirtazapine; Obesity",
      "keywords": "Antidepressants; Cardiovascular; Obesity bias; Prescribing patterns; Side effects",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "38019581",
      "title": "Incivility in COVID-19 Vaccine Mandate Discourse and Moral Foundations: Natural Language Processing Approach.",
      "abstract": "BACKGROUND: Vaccine hesitancy poses a substantial threat to efforts to mitigate the harmful effects of the COVID-19 pandemic. To combat vaccine hesitancy, officials in the United States issued vaccine mandates, which were met with strong antivaccine discourse on social media platforms such as Reddit. The politicized and polarized nature of COVID-19 on social media has fueled uncivil discourse related to vaccine mandates, which is known to decrease confidence in COVID-19 vaccines. OBJECTIVE: This study examines the moral foundations underlying uncivil COVID-19 vaccine discourse. Moral foundations theory poses that individuals make decisions to express approval or disapproval (ie, uncivil discourse) based on innate moral values. We examine whether moral foundations are associated with dimensions of incivility. Further, we explore whether there are any differences in the presence of incivility between the r/coronaviruscirclejerk and r/lockdownskepticism subreddits. METHODS: Natural language processing methodologies were leveraged to analyze the moral foundations underlying uncivil discourse in 2 prominent antivaccine subreddits, r/coronaviruscirclejerk and r/lockdownskepticism. All posts and comments from both of the subreddits were collected since their inception in March 2022. This was followed by filtering the data set for key terms associated with the COVID-19 vaccine (eg, \"vaccinate\" and \"Pfizer\") and mandates (eg, \"forced\" and \"mandating\"). These key terms were selected based on a review of existing literature and because of their salience in both of the subreddits. A 10% sample of the filtered key terms was used for the final analysis. RESULTS: Findings suggested that moral foundations play a role in the psychological processes underlying uncivil vaccine mandate discourse. Specifically, we found substantial associations between all moral foundations (ie, care and harm, fairness and cheating, loyalty and betrayal, authority and subversion, and sanctity and degradation) and dimensions of incivility (ie, toxicity, insults, profanity, threat, and identity attack) except for the authority foundation. We also found statistically significant differences between r/coronaviruscirclejerk and r/lockdownskepticism for the presence of the dimensions of incivility. Specifically, the mean of identity attack, insult, toxicity, profanity, and threat in the r/lockdownskepticism subreddit was significantly lower than that in the r/coronaviruscirclejerk subreddit (P<.001). CONCLUSIONS: This study shows that moral foundations may play a substantial role in the presence of incivility in vaccine discourse. On the basis of the findings of the study, public health practitioners should tailor messaging by addressing the moral values underlying the concerns people may have about vaccines, which could manifest as uncivil discourse. Another way to tailor public health messaging could be to direct it to parts of social media platforms with increased uncivil discourse. By integrating moral foundations, public health messaging may increase compliance and promote civil discourse surrounding COVID-19.",
      "authors": "Tin Jason; Stevens Hannah; Rasul Muhammad Ehab; Taylor Laramie D",
      "year": "2023",
      "journal": "JMIR formative research",
      "doi": "10.2196/50367",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38019581/",
      "mesh_terms": "",
      "keywords": "COVID-19; incivility; machine learning; moral foundations; morality; natural language processing; social media; vaccine hesitancy; vaccines",
      "pub_types": "Journal Article",
      "pmcid": "PMC10719818"
    },
    {
      "pmid": "41224138",
      "title": "Behavior of prediction performance metrics with rare events.",
      "abstract": "OBJECTIVE: Area under the receiver operating characteristic curve (AUC) is commonly reported alongside prediction models for binary outcomes. Recent articles have raised concerns that AUC might be a misleading measure of prediction performance in the rare event setting. This setting is common since many events of clinical importance are rare. We aimed to determine whether the bias and variance of AUC are driven by the number of events or the event rate. We also investigated the behavior of other commonly used measures of prediction performance, including positive predictive value, accuracy, sensitivity, and specificity. STUDY DESIGN AND SETTING: We conducted a simulation study to determine when or whether AUC is unstable in the rare event setting by varying the size of datasets used to train and evaluate prediction models. This plasmode simulation study was based on data from the Mental Health Research Network; the data contained 149 predictors and the outcome of interest, suicide attempt, which had event rate 0.92% in the original dataset. RESULTS: Our results indicate that poor AUC behavior-as measured by empirical bias, variability of cross-validated AUC estimates, and empirical coverage of confidence intervals-is driven by the number of events in a rare-event setting, not event rate. Performance of sensitivity is driven by the number of events, while that of specificity is driven by the number of nonevents. Other measures, including positive predictive value and accuracy, depend on the event rate even in large samples. CONCLUSION: AUC is reliable in the rare event setting provided that the total number of events is moderately large; in our simulations, we observed near zero bias with 1000 events. PLAIN LANGUAGE SUMMARY: Predicting self-harm or suicidal behavior is medically important for guiding clinicians in providing care to patients. Several research teams have developed and evaluated suicide risk prediction models based on health records data. Part of evaluating these models is calculating area under the receiver operating characteristic curve (AUC) and other prediction performance metrics. Self-harm and suicide are rare events. Recent research has raised concerns with using AUC in rare-event settings. We aimed to determine whether having a sufficiently large dataset could remove these concerns. In our experiments, we found that AUC can be used without concern in settings with 1000 events or more. Thus, AUC is a valid measure of suicide risk prediction model performance in many large healthcare databases.",
      "authors": "Minus Emily; Coley R Yates; Shortreed Susan M; Williamson Brian D",
      "year": "2026",
      "journal": "Journal of clinical epidemiology",
      "doi": "10.1016/j.jclinepi.2025.112046",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41224138/",
      "mesh_terms": "Humans; Area Under Curve; ROC Curve; Computer Simulation; Suicide, Attempted; Predictive Value of Tests; Models, Statistical",
      "keywords": "Area under the receiver operating characteristic curve; Classification; Machine learning; Model evaluation; Prediction; Rare outcome",
      "pub_types": "Journal Article",
      "pmcid": "PMC12667734"
    },
    {
      "pmid": "37997122",
      "title": "Parental and health visitor perceptions on growth screening in early childhood: a qualitative study.",
      "abstract": "BACKGROUND: Growth screening in early childhood can help identify children with a range of medical and psychosocial vulnerabilities. In the UK, childhood growth and development up to age 5 years are assessed through the Healthy Child Programme, delivered by health visitors. However, formal criteria to trigger referrals for onward investigation are unclear. There is a lack of qualitative data on the acceptability and feasibility of formal growth screening programmes. This study aimed to build understanding of the perceptions and motivations of caregivers and health visitors in relation to child growth and growth screening. METHODS: This longitudinal observational study was part of a larger study piloting an automated growth screening algorithm in Tower Hamlets, London. We conducted three separate qualitative focus group interviews with health visitors (n=10), English-speaking parents (n=6), and Sylheti-speaking parents (n=5). Participants were purposively sampled, and written informed consent was obtained. A bilingual researcher facilitated each group, using a semi-structured interview guide. Data were analysed by two researchers using thematic analysis and assessed for intercoder reliability. The interview guide was translated into Sylheti, and data from the Sylheti group were translated into English by the same bilingual researcher. FINDINGS: Findings suggest that parents desire holistic care in which health visitors are empowered to refer to other health professionals and council services. Parents also want easier access to health visitors, frequent visits with the same health-care provider, and advice on raising their children. Health visitors were seen as well positioned to play an essential role in educating parents on health and developmental milestones and in helping them identify when their child might need additional support. Both parents and health visitors stressed that resources need to be in place not only to assess children but also to provide access to services when problems are identified. INTERPRETATION: These findings suggest that implementing growth screening through health visitors is feasible and acceptable, provided health visitors are given the resources and capabilities to refer children to appropriate services. Interpretation is limited by the purposive nature of the sampling and possible response bias. FUNDING: Barts Charity.",
      "authors": "Rahman Tahmid; Orr Joanna; Freer Joseph; Cordani Isabella; Prendergast Andrew J",
      "year": "2023",
      "journal": "Lancet (London, England)",
      "doi": "10.1016/S0140-6736(23)02102-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37997122/",
      "mesh_terms": "Child, Preschool; Humans; Language; Nurses, Community Health; Parents; Qualitative Research; Reproducibility of Results",
      "keywords": "",
      "pub_types": "Observational Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "15769294",
      "title": "Estimating a preference-based index for a menopause specific health quality of life questionnaire.",
      "abstract": "BACKGROUND: The aim of the study was to develop a menopause-specific, preference-based health-related quality-of-life (HRQoL) index reflecting both menopausal symptoms and potential side-effects of Hormone Replacement Therapy (HRT). METHODS: The study had three phases: the development of a health state classification, a prospective valuation survey and the estimation of a model to interpolate HRQoL indices for all remaining health states as defined by the classification. A menopausal health state classification was developed with seven dimensions: hot flushes, aching joints/muscles, anxious/frightened feelings, breast tenderness, bleeding, vaginal dryness and undesirable androgenic signs. Each dimension contains between three and five levels and defines a total of 6,075 health states. A sample of 96 health states was selected for the valuation survey. These states were valued by a sample of 229 women aged 45 to 60, randomly selected from 6 general practice lists in Sheffield, UK. Respondents were asked to complete a time trade-off (TTO) task for nine health states, resulting in an average of 16.5 values for each health state. RESULTS: Mean health states valued range from 0.48 to 0.98 (where 1.0 is full health and zero is for states regarded as equivalent to death). Symptoms, as described by the classification system, can be rank-ordered in terms of their impact (from high to low) on menopausal HRQoL as follows: aching joints and muscles, bleeding, breast tenderness, anxious or frightened feelings, vaginal dryness, androgenic signs. Hot flushes did not significantly contribute to model fit. The preferred model produced a mean absolute error of 0.053, but suffered from bias at both ends of the scale. CONCLUSION: This article presents an attempt to directly value a condition specific health state classification. The overall fit was disappointing, but the results demonstrate that menopausal symptoms are perceived by patients to have a significant impact on utility. The overall effect is modest compared to the more generic health state descriptions such as the EQ-5D. The resultant algorithm generates a preference-based index that can be used economic evaluation and that reflects the impact of this condition.",
      "authors": "Brazier John E; Roberts Jennifer; Platts Maria; Zoellner York F",
      "year": "2005",
      "journal": "Health and quality of life outcomes",
      "doi": "10.1186/1477-7525-3-13",
      "url": "https://pubmed.ncbi.nlm.nih.gov/15769294/",
      "mesh_terms": "Female; Health Status; Humans; Menopause; Middle Aged; Patient Satisfaction; Psychometrics; Quality of Life; Sickness Impact Profile; Time Factors; United Kingdom; Women's Health",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC555752"
    },
    {
      "pmid": "40901706",
      "title": "Negative descriptors in electronic health records of patients with diabetes.",
      "abstract": "BACKGROUND: Negative descriptors in electronic health records (EHR) contribute to worse health outcomes; studies show they are also more prevalent in EHRs of women and racial minorities and affect downstream research biases. Similar and unique patterns of negative descriptors may also exist in the records of blind patients, including those with diabetic retinopathy. Diabetic retinopathy is a preventable but leading cause of blindness in the US that is disproportionally high among women and racial and ethnic minorities. METHODS: Using EHR from a large medical center, we created \"matched\" cohorts of patients with a type 2 diabetes-only diagnosis and patients with a diagnosis of diabetic retinopathy. We identified previously used and new, disability and patient-related negative descriptors and assessed patterns of biased language in the EHR, comparing patients by retinopathy diagnosis (yes/no), and changes in patterns of language usage pre- and post- the retinopathy diagnosis. We also assessed differences between patients with type 2 diabetes at the intersection of blindness (ie, retinopathy diagnosis) and self-reported gender and race and ethnicity marginalization. RESULTS: The EHRs of patients with diabetic retinopathy were significantly more likely than those of patients with diabetes-only diagnoses to contain biased language, across queried negative descriptors. The biasing language was consistently more prevalent in EHRs of patients with diabetic retinopathy identifying as women, Black/African Americans and Hispanic compared to White men and more likely to occur following patients' retinopathy diagnosis. CONCLUSIONS: Our study indicates the presence of both disability- and intersectional biases in EHRs. We discuss findings' implications and suggest steps to address them.",
      "authors": "Sun Tony Y; Baugh Mika; Gordon Emily R; Ekanayake Cameron; Moise Nathalie; Elhadad Noemie; Sabatello Maya",
      "year": "2025",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaf132",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40901706/",
      "mesh_terms": "Humans; Electronic Health Records; Female; Diabetic Retinopathy; Diabetes Mellitus, Type 2; Male; Middle Aged; Aged; Language",
      "keywords": "Artificial Intelligence/Machine Learning (AI/ML); bias; disability; medical records; negative descriptors",
      "pub_types": "Journal Article",
      "pmcid": "PMC12451930"
    },
    {
      "pmid": "40807716",
      "title": "Sustainable THz SWIPT via RIS-Enabled Sensing and Adaptive Power Focusing: Toward Green 6G IoT.",
      "abstract": "Terahertz (THz) communications and simultaneous wireless information and power transfer (SWIPT) hold the potential to energize battery-less Internet-of-Things (IoT) devices while enabling multi-gigabit data transmission. However, severe path loss, blockages, and rectifier nonlinearity significantly hinder both throughput and harvested energy. Additionally, high-power THz beams pose safety concerns by potentially exceeding specific absorption rate (SAR) limits. We propose a sensing-adaptive power-focusing (APF) framework in which a reconfigurable intelligent surface (RIS) embeds low-rate THz sensors. Real-time backscatter measurements construct a spatial map used for the joint optimisation of (i) RIS phase configurations, (ii) multi-tone SWIPT waveforms, and (iii) nonlinear power-splitting ratios. A weighted MMSE inner loop maximizes the data rate, while an outer alternating optimisation applies semidefinite relaxation to enforce passive-element constraints and SAR compliance. Full-stack simulations at 0.3 THz with 20 GHz bandwidth and up to 256 RIS elements show that APF (i) improves the rate-energy Pareto frontier by 30-75% over recent adaptive baselines; (ii) achieves a 150% gain in harvested energy and a 440 Mbps peak per-user rate; (iii) reduces energy-efficiency variance by half while maintaining a Jain fairness index of 0.999;; and (iv) caps SAR at 1.6 W/kg, which is 20% below the IEEE C95.1 safety threshold. The algorithm converges in seven iterations and executes within <3 ms on a Cortex-A78 processor, ensuring compliance with real-time 6G control budgets. The proposed architecture supports sustainable THz-powered networks for smart factories, digital-twin logistics, wire-free extended reality (XR), and low-maintenance structural health monitors, combining high-capacity communication, safe wireless power transfer, and carbon-aware operation for future 6G cyber-physical systems.",
      "authors": "Enahoro Sunday; Ekpo Sunday Cookey; Uko Mfonobong; Elias Fanuel; Unnikrishnan Rahul; Alabi Stephen; Olasunkanmi Nurudeen Kolawole",
      "year": "2025",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s25154549",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40807716/",
      "mesh_terms": "",
      "keywords": "6G IoT; SAR constraint; adaptive power focusing; channel sensing; green wireless; nonlinear energy harvesting; reconfigurable intelligent surface; terahertz SWIPT",
      "pub_types": "Journal Article",
      "pmcid": "PMC12349027"
    },
    {
      "pmid": "28716074",
      "title": "Evaluation of record linkage of two large administrative databases in a middle income country: stillbirths and notifications of dengue during pregnancy in Brazil.",
      "abstract": "BACKGROUND: Due to the increasing availability of individual-level information across different electronic datasets, record linkage has become an efficient and important research tool. High quality linkage is essential for producing robust results. The objective of this study was to describe the process of preparing and linking national Brazilian datasets, and to compare the accuracy of different linkage methods for assessing the risk of stillbirth due to dengue in pregnancy. METHODS: We linked mothers and stillbirths in two routinely collected datasets from Brazil for 2009-2010: for dengue in pregnancy, notifications of infectious diseases (SINAN); for stillbirths, mortality (SIM). Since there was no unique identifier, we used probabilistic linkage based on maternal name, age and municipality. We compared two probabilistic approaches, each with two thresholds: 1) a bespoke linkage algorithm; 2) a standard linkage software widely used in Brazil (ReclinkIII), and used manual review to identify further links. Sensitivity and positive predictive value (PPV) were estimated using a subset of gold-standard data created through manual review. We examined the characteristics of false-matches and missed-matches to identify any sources of bias. RESULTS: From records of 678,999 dengue cases and 62,373 stillbirths, the gold-standard linkage identified 191 cases. The bespoke linkage algorithm with a conservative threshold produced 131 links, with sensitivity\u00a0=\u00a064.4% (68 missed-matches) and PPV\u00a0=\u00a092.5% (8 false-matches). Manual review of uncertain links identified an additional 37 links, increasing sensitivity to 83.7%. The bespoke algorithm with a relaxed threshold identified 132 true matches (sensitivity\u00a0=\u00a069.1%), but introduced 61 false-matches (PPV\u00a0=\u00a068.4%). ReclinkIII produced lower sensitivity and PPV than the bespoke linkage algorithm. Linkage error was not associated with any recorded study variables. CONCLUSION: Despite a lack of unique identifiers for linking mothers and stillbirths, we demonstrate a high standard of linkage of large routine databases from a middle income country. Probabilistic linkage and manual review were essential for accurately identifying cases for a case-control study, but this approach may not be feasible for larger databases or for linkage of more common outcomes.",
      "authors": "Paix\u00e3o Enny S; Harron Katie; Andrade Kleydson; Teixeira Maria Gl\u00f3ria; Fiaccone Rosemeire L; Costa Maria da Concei\u00e7\u00e3o N; Rodrigues Laura C",
      "year": "2017",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-017-0506-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28716074/",
      "mesh_terms": "Brazil; Dengue; Electronic Health Records; Female; Humans; Medical Record Linkage; Pregnancy; Pregnancy Complications, Infectious; Risk; Stillbirth",
      "keywords": "Data linkage; Dengue; Electronic health records; Linkage accuracy; Linkage quality; Routine data; Stillbirth",
      "pub_types": "Evaluation Study; Journal Article",
      "pmcid": "PMC5513351"
    },
    {
      "pmid": "28675551",
      "title": "Incidence, Treatment Patterns, and Health Care Costs of Infantile Hemangioma: Results of a Retrospective German Database Analysis.",
      "abstract": "OBJECTIVES: To determine the incidence, effect (defined according to treatment rate), and health care costs of infantile hemangiomas (IHs) in Germany from 2007 to 2012 by analyzing patient data of German statutory health insurances. METHODS: A retrospective analysis using data from a database matched with the overall population covered by German statutory health insurance was performed. To describe the treatment rate and costs of IHs, a search algorithm was developed dividing the study population into three groups (patients with IHs, patients with IHs possibly requiring treatment, and patients with IHs receiving treatment). RESULTS: The incidence of IHs was 2.0% to 3.2%, with a slight increase during the later years of the study period and a female:male ratio of 1.4:1. IH incidence was lower and girls were less likely to present with IHs than in previous reports. The mean treatment rate of IHs was 11.3%. Mean health care costs during first year of life for infants diagnosed with IHs in 2012 were slightly lower (\u20ac2,396) than for all infants (\u20ac2,649), whereas costs for infants diagnosed and treated for IHs were considerably higher (\u20ac10,550). The majority of these costs were due to hospitalization (\u20ac8,658). CONCLUSION: This retrospective study is the first to analyze the incidence and sex ratio of IHs based on German claims data. The treatment rate of IHs was consistent with previous reports. The mean health care costs for treated patients with IHs were substantially higher than those for all newborns. Limitations of this study are coding bias, a limited sample size, and claims perspective (nonclinical approach).",
      "authors": "Seiffert Anna; Schneider Markus; Roessler Jochen; Larisch Katharina; Pfeiffer Dunja",
      "year": "2017",
      "journal": "Pediatric dermatology",
      "doi": "10.1111/pde.13187",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28675551/",
      "mesh_terms": "Databases, Factual; Female; Germany; Health Care Costs; Hemangioma; Humans; Incidence; Infant; Infant, Newborn; Male; Retrospective Studies",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37632862",
      "title": "Crowdsourcing Medical Costs in Dermatology: Cross-sectional Study Analyzing Dermatologic GoFundMe Campaigns.",
      "abstract": "BACKGROUND: Crowdfunding for medical costs is becoming increasingly popular. Few previous studies have described the fundraising characteristics and qualities associated with success. OBJECTIVE: This study aimed to characterize and investigate the qualities associated with successful dermatological fundraisers. METHODS: This cross-sectional study of dermatological GoFundMe campaigns collected data, including demographic variables, thematic variables using an inductive qualitative method, and quantitative information. Linear regression examined the qualities associated with success, which are defined based on funds raised when controlling for campaign goals. Logistic regression was used to examine qualities associated with extremely successful campaigns, defined as those raising >1.5 times the IQR. Statistical significance was set at P<.05. RESULTS: A total of 2008 publicly available campaigns at the time of data collection were evaluated. Nonmodifiable factors associated with greater success included male gender, age 20-40 years, and White race. Modifiable factors associated with success included more updates posted to the campaign page, non-self-identity of the campaign creator, mention of a chronic condition, and smiling in campaign profile photographs. CONCLUSIONS: Understanding the modifiable factors of medical crowdfunding may inform future campaigns, and nonmodifiable factors may have policy implications for improving health care equity and financing. Crowdfunding for medical disease treatment may have potential implications for medical privacy and exacerbation of existing health care disparities. This study was limited to publicly available GoFundMe campaigns. Potential limitations for this study include intercoder variability, misclassification bias because of the data abstraction process, and prioritization of campaigns based on the proprietary GoFundMe algorithm.",
      "authors": "Mark Erica; Sridharan Mira; Florenzo Brian; Schenck Olivia L; Noland Mary-Margaret B; Barbieri John S; Lipoff Jules B",
      "year": "2022",
      "journal": "JMIR dermatology",
      "doi": "10.2196/34111",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37632862/",
      "mesh_terms": "",
      "keywords": "GoFundMe; crowdfunding; crowdsourcing; financial burden; fundraising; health equity; medical expenses; social media",
      "pub_types": "Journal Article",
      "pmcid": "PMC10334893"
    },
    {
      "pmid": "38556440",
      "title": "Using Concurrent Complication Reporting to Evaluate Resident Critical Thinking and Enhance Adult Learning.",
      "abstract": "OBJECTIVE: Critical thinking and accurate case analysis is difficult to quantify even within the context of routine morbidity and mortality reporting. We designed and implemented a HIPAA-compliant adverse outcome reporting system that collects weekly resident assessments of clinical care across multiple domains (case summary, complications, error analysis, Clavien-Dindo Harm, cognitive bias, standard of care, and ACGME core competencies). We hypothesized that incorporation of this system into the residency program's core curriculum would allow for identification of areas of cognitive weakness or strength and provide a longitudinal evaluation of critical thinking development. DESIGN: A validated, password-protected electronic platform linked to our electronic medical record was used to collect cases weekly in which surgical adverse events occurred. General surgery residents critiqued 1932 cases over a 4-year period from 3 major medical centers within our system. These data were reviewed by teaching faculty, corrected for accuracy and graded utilizing the software's critique algorithm. Grades were emailed to the residents at the time of the review, collected prospectively, stratified, and analyzed by post-graduate year (PGY). Evaluation of the resident scores for each domain and the resultant composite scores allowed for comparison of critical thinking skills across post-graduate year (PGY) over time. SETTING: Data was collected from 3 independently ACGME-accredited surgery residency programs over 3 tertiary hospitals within our health system. PARTICIPANTS: General surgery residents in clinical PGY 1-5. RESULTS: Residents scored highest in properly identifying ACGME core competencies and determining Clavien-Dindo scores (p < 0.006) with no improvement in providing accurate and concise clinical summaries. However, residents improved in recording data sufficient to identify error (p < 0.00001). A positive linear trend in median scores for all remaining domains except for cognitive bias was demonstrated (p < 0.001). Senior residents scored significantly higher than junior residents in all domains. Scores > 90% were never achieved. CONCLUSIONS: The use of an electronic standardized critique algorithm in the evaluation and assessment of adverse surgical case outcomes enabled the measure of residents' critical thinking skills. Feedback in the form of teaching faculty-facilitated discussion and emailed grades enhanced adult learning with a steady improvement in performance over PGY. Although residents improved with PGY, the data suggest that further improvement in all categories is possible. Implementing this standardized critique algorithm across PGY allows for evaluation of areas of individual resident weakness vs. strength, progression over time, and comparisons to peers. These data suggest that routine complication reporting may be enhanced as a critical thinking assessment tool and that improvement in critical thinking can be quantified. Incorporation of this platform into M&M conference has the potential to augment executive function and professional identity development.",
      "authors": "Carsky Katie; Rindskopf David; Patel Vihas M; Ansari Parswa; Dechario Samuel P; Giangola Gary; Coppa Gene F; Antonacci Anthony C",
      "year": "2024",
      "journal": "Journal of surgical education",
      "doi": "10.1016/j.jsurg.2024.02.002",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38556440/",
      "mesh_terms": "Internship and Residency; Humans; Clinical Competence; General Surgery; Thinking; Adult; Education, Medical, Graduate; Male; Female; Curriculum; Postoperative Complications; Educational Measurement",
      "keywords": "Knowles\u2019 principles; adult learning; andragogy; complication reporting; resident critical thinking",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32864983",
      "title": "Handling Missing Data in the Short Form-12 Health Survey (SF-12): Concordance of Real Patient Data and Data Estimated by Missing Data Imputation Procedures.",
      "abstract": "If information on single items in the Short Form-12 health survey (SF-12) is missing, the analysis of only complete cases causes a loss of statistical power and, in case of nonrandom missing data (MD), systematic bias. This study aimed at evaluating the concordance of real patient data and data estimated by different MD imputation procedures in the items of the SF-12 assessment. For this ends, MD were examined in a sample of 1,137 orthopedic patients. Additionally, MD were simulated (a) in the subsample of orthopedic patients exhibiting no MD (n = 810; 71%) as well as (b) in a sample of 6,970 respondents representing the German general population (95.8% participants with complete data) using logistic regression modelling. Simulated MD were replaced by mean values as well as regression-, expectation-maximization- (EM-), and multiple imputation estimates. Higher age and lower education were associated with enhanced probabilities of MD. In terms of accuracy in both data sets, the EM-procedure (ICC2,1 = .33-.72) outperformed alternative estimation approaches substantially (e.g., regression imputation: ICC2,1 = .18-.48). The EM-algorithm can be recommended to estimate MD in the items of the SF-12, because it reproduces the actual patient data most accurately.",
      "authors": "Wirtz Markus A; R\u00f6ttele Nicole; Morfeld Matthias; Br\u00e4hler Elmar; Glaesmer Heide",
      "year": "2021",
      "journal": "Assessment",
      "doi": "10.1177/1073191120952886",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32864983/",
      "mesh_terms": "Algorithms; Bias; Health Surveys; Humans; Logistic Models; Probability",
      "keywords": "Short Form\u201312 health survey; expectation-maximization-procedure; health-related quality of life; imputation methods; missing data",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8450993"
    },
    {
      "pmid": "31151893",
      "title": "A Road Map for Translational Research on Artificial Intelligence in Medical Imaging: From the 2018 National Institutes of Health/RSNA/ACR/The Academy Workshop.",
      "abstract": "Advances in machine learning in medical imaging are occurring at a rapid pace in research laboratories both at academic institutions and in industry. Important artificial intelligence (AI) tools for diagnostic imaging include algorithms for disease detection and classification, image optimization, radiation reduction, and workflow enhancement. Although advances in foundational research are occurring rapidly, translation to routine clinical practice has been slower. In August 2018, the National Institutes of Health assembled multiple relevant stakeholders at a public meeting to discuss the current state of knowledge, infrastructure gaps, and challenges to wider implementation. The conclusions of that meeting are summarized in two publications that identify and prioritize initiatives to accelerate foundational and translational research in AI for medical imaging. This publication summarizes key priorities for translational research developed at the workshop including: (1) creating structured AI use cases, defining and highlighting clinical challenges potentially solvable by AI; (2) establishing methods to encourage data sharing for training and testing AI algorithms to promote generalizability to widespread clinical practice and mitigate unintended bias; (3) establishing tools for validation and performance monitoring of AI algorithms to facilitate regulatory approval; and (4) developing standards and common data elements for seamless integration of AI tools into existing clinical workflows. An important goal of the resulting road map is to grow an ecosystem, facilitated by professional societies, industry, and government agencies, that will allow robust collaborations between practicing clinicians and AI researchers to advance foundational and translational research relevant to medical imaging.",
      "authors": "Allen Bibb; Seltzer Steven E; Langlotz Curtis P; Dreyer Keith P; Summers Ronald M; Petrick Nicholas; Marinac-Dabic Danica; Cruz Marisa; Alkasab Tarik K; Hanisch Robert J; Nilsen Wendy J; Burleson Judy; Lyman Kevin; Kandarpa Krishna",
      "year": "2019",
      "journal": "Journal of the American College of Radiology : JACR",
      "doi": "10.1016/j.jacr.2019.04.014",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31151893/",
      "mesh_terms": "Artificial Intelligence; Diagnostic Imaging; Humans; Research Design; Translational Research, Biomedical; United States",
      "keywords": "",
      "pub_types": "Consensus Development Conference, NIH; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35276892",
      "title": "Validating Accuracy of a Mobile Application against Food Frequency Questionnaire on Key Nutrients with Modern Diets for mHealth Era.",
      "abstract": "In preparation for personalized nutrition, an accurate assessment of dietary intakes on key essential nutrients using smartphones can help promote health and reduce health risks across vulnerable populations. We, therefore, validated the accuracy of a mobile application (app) against Food Frequency Questionnaire (FFQ) using artificial intelligence (AI) machine-learning-based analytics, assessing key macro- and micro-nutrients across various modern diets. We first used Bland and Altman analysis to identify and visualize the differences between the two measures. We then applied AI-based analytics to enhance prediction accuracy, including generalized regression to identify factors that contributed to the differences between the two measures. The mobile app underestimated most macro- and micro-nutrients compared to FFQ (ranges: -5% for total calories, -19% for cobalamin, -33% for vitamin E). The average correlations between the two measures were 0.87 for macro-nutrients and 0.84 for micro-nutrients. Factors that contributed to the differences between the two measures using total calories as an example, included caloric range (1000-2000 versus others), carbohydrate, and protein; for cobalamin, included caloric range, protein, and Chinese diet. Future studies are needed to validate actual intakes and reporting of various diets, and to examine the accuracy of mobile App. Thus, a mobile app can be used to support personalized nutrition in the mHealth era, considering adjustments with sources that could contribute to the inaccurate estimates of nutrients.",
      "authors": "Kusuma Joyce D; Yang Hsiao-Ling; Yang Ya-Ling; Chen Zhao-Feng; Shiao Shyang-Yun Pamela Koong",
      "year": "2022",
      "journal": "Nutrients",
      "doi": "10.3390/nu14030537",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35276892/",
      "mesh_terms": "Artificial Intelligence; Diet; Health Promotion; Mobile Applications; Nutrients; Surveys and Questionnaires; Telemedicine",
      "keywords": "Food Frequency Questionnaire (FFQ); agreement and bias; dietary record; generalized regression; mHealth; mobile applications (mobile app); modern diets; personalized nutrition",
      "pub_types": "Journal Article",
      "pmcid": "PMC8839756"
    },
    {
      "pmid": "34694233",
      "title": "Digital Biomarkers for Depression Screening With Wearable Devices: Cross-sectional Study With Machine Learning Modeling.",
      "abstract": "BACKGROUND: Depression is a prevalent mental disorder that is undiagnosed and untreated in half of all cases. Wearable activity trackers collect fine-grained sensor data characterizing the behavior and physiology of users (ie, digital biomarkers), which could be used for timely, unobtrusive, and scalable depression screening. OBJECTIVE: The aim of this study was to examine the predictive ability of digital biomarkers, based on sensor data from consumer-grade wearables, to detect risk of depression in a working population. METHODS: This was a cross-sectional study of 290 healthy working adults. Participants wore Fitbit Charge 2 devices for 14 consecutive days and completed a health survey, including screening for depressive symptoms using the 9-item Patient Health Questionnaire (PHQ-9), at baseline and 2 weeks later. We extracted a range of known and novel digital biomarkers characterizing physical activity, sleep patterns, and circadian rhythms from wearables using steps, heart rate, energy expenditure, and sleep data. Associations between severity of depressive symptoms and digital biomarkers were examined with Spearman correlation and multiple regression analyses adjusted for potential confounders, including sociodemographic characteristics, alcohol consumption, smoking, self-rated health, subjective sleep characteristics, and loneliness. Supervised machine learning with statistically selected digital biomarkers was used to predict risk of depression (ie, symptom severity and screening status). We used varying cutoff scores from an acceptable PHQ-9 score range to define the depression group and different subsamples for classification, while the set of statistically selected digital biomarkers remained the same. For the performance evaluation, we used k-fold cross-validation and obtained accuracy measures from the holdout folds. RESULTS: A total of 267 participants were included in the analysis. The mean age of the participants was 33 (SD 8.6, range 21-64) years. Out of 267 participants, there was a mild female bias displayed (n=170, 63.7%). The majority of the participants were Chinese (n=211, 79.0%), single (n=163, 61.0%), and had a university degree (n=238, 89.1%). We found that a greater severity of depressive symptoms was robustly associated with greater variation of nighttime heart rate between 2 AM and 4 AM and between 4 AM and 6 AM; it was also associated with lower regularity of weekday circadian rhythms based on steps and estimated with nonparametric measures of interdaily stability and autocorrelation as well as fewer steps-based daily peaks. Despite several reliable associations, our evidence showed limited ability of digital biomarkers to detect depression in the whole sample of working adults. However, in balanced and contrasted subsamples comprised of depressed and healthy participants with no risk of depression (ie, no or minimal depressive symptoms), the model achieved an accuracy of 80%, a sensitivity of 82%, and a specificity of 78% in detecting subjects at high risk of depression. CONCLUSIONS: Digital biomarkers that have been discovered and are based on behavioral and physiological data from consumer wearables could detect increased risk of depression and have the potential to assist in depression screening, yet current evidence shows limited predictive ability. Machine learning models combining these digital biomarkers could discriminate between individuals with a high risk of depression and individuals with no risk.",
      "authors": "Rykov Yuri; Thach Thuan-Quoc; Bojic Iva; Christopoulos George; Car Josip",
      "year": "2021",
      "journal": "JMIR mHealth and uHealth",
      "doi": "10.2196/24872",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34694233/",
      "mesh_terms": "Adult; Biomarkers; Cross-Sectional Studies; Depression; Female; Fitness Trackers; Humans; Machine Learning; Middle Aged; Young Adult",
      "keywords": "circadian rhythm; depression; digital biomarkers; fitness tracker; heart rate; machine learning; rest-activity rhythm; screening; wearable electronic device",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8576601"
    },
    {
      "pmid": "30135037",
      "title": "Advances and Controversies in Diet and Physical Activity Measurement in Youth.",
      "abstract": "UNLABELLED: Technological advancements in the past decades have improved dietary intake and physical activity measurements. This report reviews current developments in dietary intake and physical activity assessment in youth. Dietary intake assessment has relied predominantly on self-report or image-based methods to measure key aspects of dietary intake (e.g., food types, portion size, eating occasion), which are prone to notable methodologic (e.g., recall bias) and logistic (e.g., participant and researcher burden) challenges. Although there have been improvements in automatic eating detection, artificial intelligence, and sensor-based technologies, participant input is often needed to verify food categories and portions. Current physical activity assessment methods, including self-report, direct observation, and wearable devices, provide researchers with reliable estimations for energy expenditure and bodily movement. Recent developments in algorithms that incorporate signals from multiple sensors and technology-augmented self-reporting methods have shown preliminary efficacy in measuring specific types of activity patterns and relevant contextual information. However, challenges in detecting resistance (e.g., in resistance training, weight lifting), prolonged physical activity monitoring, and algorithm (non)equivalence remain to be addressed. In summary, although dietary intake assessment methods have yet to achieve the same validity and reliability as physical activity measurement, recent developments in wearable technologies in both arenas have the potential to improve current assessment methods. THEME INFORMATION: This article is part of a theme issue entitled Innovative Tools for Assessing Diet and Physical Activity for Health Promotion, which is sponsored by the North American branch of the International Life Sciences Institute.",
      "authors": "Spruijt-Metz Donna; Wen Cheng K Fred; Bell Brooke M; Intille Stephen; Huang Jeannie S; Baranowski Tom",
      "year": "2018",
      "journal": "American journal of preventive medicine",
      "doi": "10.1016/j.amepre.2018.06.012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30135037/",
      "mesh_terms": "Adolescent; Child; Diet; Exercise; Health Promotion; Humans; Inventions; Mental Recall; Nutrition Assessment; Portion Size; Wearable Electronic Devices",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC6151143"
    },
    {
      "pmid": "12720280",
      "title": "On the 17O correction for CO2 mass spectrometric isotopic analysis.",
      "abstract": "To calculate delta(13)C from raw CO(2) isotope data, the ion beam ratio of m/z 45 to 44 is corrected for the contribution arising from the contribution of (17)O-bearing molecules. First, a review on the current state of (17)O-corrections for CO(2) mass spectrometry is presented. The three correction algorithms that are generally in use, however, do produce biased delta(13)C values, and the bias is actually larger than the precision of modern isotope ratio mass spectrometers. The origin of this bias is twofold: different values for (17)R(VPDB-CO2) as well as different values for lambda are used in the correction algorithms. Despite both values being of high importance, large discrepancies between the absolute values published for (17)R(VPDB-CO2) appear to be the main reason for the delta(13)C biases. Next, the question of how to choose the value of lambda to best be used is considered. Natural (e.g. tropospheric) CO(2) as well as primary reference materials (PDB and NBS-19), having been in isotope exchange with water, are assumed to lie on the fractionation line for waters. On this ground, lambda = 0.5281 +/- 0.0015, as determined for waters (Meijer and Li, Isot. Environ. Health Stud., 1998; 34: 349-369), is suggested to be a base for the (17)O-correction algorithm. Finally, an approach to determine the absolute value for (17)R(VPDB-CO2), based on data of relative isotope measurements on two CO(2) gases having a large (17)O difference, is discussed and algebraic formulas are considered. Experimental data and new numerical values determined for (17)R(VPDB-CO2) and (17)R(VSMOW) are given in a companion paper.",
      "authors": "Assonov Sergey S; Brenninkmeijer Carl A M",
      "year": "2003",
      "journal": "Rapid communications in mass spectrometry : RCM",
      "doi": "10.1002/rcm.1012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/12720280/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41080607",
      "title": "Intra-tumor heterogeneity-resistant gene signature predicts prognosis and immune infiltration in breast cancer.",
      "abstract": "BACKGROUND: Breast cancer (BC) remains a significant threat to human health, with substantial variations in prognosis and treatment responses. Intra-tumor heterogeneity (ITH) presents a critical challenge in developing reliable prognostic models. METHODS: This study integrated multi-region RNA sequencing data from BC patients with the TCGA BC dataset. Genes resistant to sampling bias were identified by evaluating inter-patient heterogeneity (IPH) and ITH. A machine learning framework incorporating ten algorithms was used to construct a prognostic signature.The expression levels and oncogenic function of the prognostic genes were validated through RT-qPCR and in vitro experiments. RESULTS: The signature, comprising CFL2 and SPNS2, demonstrated stable predictive performance in both training and validation cohorts (C-index > 0.6). High-risk patients exhibited enriched immune infiltration, particularly CD8+ T cells, and higher expression of immune checkpoint molecules, suggesting sensitivity to immunotherapy. A nomogram integrating risk score with clinical variables further improved prognostic accuracy. The dysregulation of signature genes was confirmed in BC cell lines. CONCLUSION: By minimizing ITH interference, this study developed a robust prognostic signature for BC, offering insights into the tumor immune microenvironment and potential therapeutic strategies.",
      "authors": "Shen Haixing; Zheng Qing; Pan Jie; Jin Yukai; Zheng Xiaohong; Yuan Qingyue; Tan Da; Zhou Qiang; Wang Jingzhi; Sun Tianmiao",
      "year": "2025",
      "journal": "Frontiers in immunology",
      "doi": "10.3389/fimmu.2025.1598858",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41080607/",
      "mesh_terms": "Humans; Breast Neoplasms; Female; Prognosis; Tumor Microenvironment; Biomarkers, Tumor; Gene Expression Regulation, Neoplastic; Lymphocytes, Tumor-Infiltrating; Transcriptome; Nomograms; Gene Expression Profiling; Cell Line, Tumor; Genetic Heterogeneity",
      "keywords": "breast cancer; immune infiltration; immunotherapy; intra-tumor heterogeneity; prognosis; tumor microenvironment",
      "pub_types": "Journal Article",
      "pmcid": "PMC12511067"
    },
    {
      "pmid": "28378815",
      "title": "Prediction of oxygen uptake dynamics by machine learning analysis of wearable sensors during activities of daily living.",
      "abstract": "Currently, oxygen uptake () is the most precise means of investigating aerobic fitness and level of physical activity; however, can only be directly measured in supervised conditions. With the advancement of new wearable sensor technologies and data processing approaches, it is possible to accurately infer work rate and predict during activities of daily living (ADL). The main objective of this study was to develop and verify the methods required to predict and investigate the dynamics during ADL. The variables derived from the wearable sensors were used to create a predictor based on a random forest method. The temporal dynamics were assessed by the mean normalized gain amplitude (MNG) obtained from frequency domain analysis. The MNG provides a means to assess aerobic fitness. The predicted during ADL was strongly correlated (r\u2009=\u20090.87, P\u2009<\u20090.001) with the measured and the prediction bias was 0.2\u2009ml\u00b7min-1\u00b7kg-1. The MNG calculated based on predicted was strongly correlated (r\u2009=\u20090.71, P\u2009<\u20090.001) with MNG calculated based on measured data. This new technology provides an important advance in ambulatory and continuous assessment of aerobic fitness with potential for future applications such as the early detection of deterioration of physical health.",
      "authors": "Beltrame T; Amelard R; Wong A; Hughson R L",
      "year": "2017",
      "journal": "Scientific reports",
      "doi": "10.1038/srep45738",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28378815/",
      "mesh_terms": "Activities of Daily Living; Adult; Biosensing Techniques; Humans; Machine Learning; Male; Monitoring, Ambulatory; Oxygen; Wearable Electronic Devices",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC5381118"
    },
    {
      "pmid": "39220676",
      "title": "Considerations and targeted approaches to identifying bad actors in exposure mixtures.",
      "abstract": "Variable importance is a key statistical issue in exposure mixtures, as it allows a ranking of exposures as potential targets for intervention, and helps to identify bad actors within a mixture. In settings where mixtures have many constituents or high between-constituent correlations, estimators of importance can be subject to bias or high variance. Current approaches to assessing variable importance have major limitations, including reliance on overly strong or incorrect constraints or assumptions, excessive model extrapolation, or poor interpretability, especially regarding practical significance. We sought to overcome these limitations by applying an established doubly-robust, machine learning-based approach to estimating variable importance in a mixtures context. This method reduces model extrapolation, appropriately controls confounding, and provides both interpretability and model flexibility. We illustrate its use with an evaluation of the relationship between telomere length, a measure of biologic aging, and exposure to a mixture of polychlorinated biphenyls (PCBs), dioxins, and furans among 979 US adults from the National Health and Nutrition Examination Survey (NHANES). In contrast with standard approaches for mixtures, our approach selected PCB 180 and PCB 194 as important contributors to telomere length. We hypothesize that this difference could be due to residual confounding in standard methods that rely on variable selection. Further empirical evaluation of this method is needed, but it is a promising tool in the search for bad actors within a mixture.",
      "authors": "Keil Alexander P; O'Brien Katie M",
      "year": "2024",
      "journal": "Statistics in biosciences",
      "doi": "10.1007/s12561-023-09409-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39220676/",
      "mesh_terms": "",
      "keywords": "Causal inference; Mixtures; Variable importance; persistent organic pollutants",
      "pub_types": "Journal Article",
      "pmcid": "PMC11364366"
    },
    {
      "pmid": "38712428",
      "title": "A short report on the current landscape of Artificial Intelligence (AI) in vascular surgery in Pakistan.",
      "abstract": "This study focuses on the current applications, potential, and challenges to Artificial Intelligence (AI) integration in vascular surgery with specific emphasis on its relevance in Pakistan. Despite the benefits of AI in vascular surgery, there is a substantial gap in its adoption in Pakistan compared to global standards. In our context with limited resources and a scarcity of vascular surgeons, AI can serve as a promising solution. It can enhance healthcare accessibility, improve diagnostic accuracy, and alleviate the workload on vascular surgeons. However, hurdles including the absence of a comprehensive vascular surgery database, a shortage of AI experts, and potential algorithmic biases pose significant challenges to AI implementation. Despite these obstacles, the study underscores the imperative for continued research, collaborative efforts, and investments to unlock the full potential of AI and elevate vascular healthcare standards in Pakistan.",
      "authors": "Siddiqui Nadeem Ahmed; Anees Muhammad; Shaikh Fareed; Rehman Zia Ur",
      "year": "2024",
      "journal": "JPMA. The Journal of the Pakistan Medical Association",
      "doi": "10.47391/JPMA.AKU-9S-27",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38712428/",
      "mesh_terms": "Pakistan; Humans; Artificial Intelligence; Vascular Surgical Procedures",
      "keywords": "Artificial Intelligence, Health Care, Surgeons, Vascular Surgical Procedures, Bias, machine learning, vascular surgery, peripheral arterial disease, abdominal aortic aneurysm.",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34528081",
      "title": "Harnessing of real-world data and real-world evidence using digital tools: utility and potential models in rheumatology practice.",
      "abstract": "The diversity of diseases in rheumatology and variability in disease prevalence necessitates greater data parity in disease presentation, treatment responses including adverse events to drugs and various comorbidities. Randomized controlled trials are the gold standard for drug development and performance evaluation. However, when the drug is applied outside the controlled environment, the outcomes may differ in patient populations. In this context, the need to understand the macro and micro changes involved in disease evolution and progression becomes important and so is the need for harvesting and harnessing the real-world data from various resources to use them in generating real-world evidence. Digital tools with potential relevance to rheumatology can potentially be leveraged to obtain greater patient insights, greater information on disease progression and disease micro processes and even in the early diagnosis of diseases. Since the patients spend only a minuscule portion of their time in hospital or in a clinic, using modern digital tools to generate realistic, bias-proof, real-world data in a non-invasive patient-friendly manner becomes critical. In this review we have appraised different digital mediums and mechanisms for collecting real-world data and proposed digital care models for generating real-world evidence in rheumatology.",
      "authors": "Kataria Suchitra; Ravindran Vinod",
      "year": "2022",
      "journal": "Rheumatology (Oxford, England)",
      "doi": "10.1093/rheumatology/keab674",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34528081/",
      "mesh_terms": "Artificial Intelligence; Big Data; Humans; Monitoring, Physiologic; Rheumatic Diseases",
      "keywords": "artificial intelligence; big data; data analytics; electronic health records; machine learning",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41497043",
      "title": "Early detection in oral cancer: Are we prepared for artificial intelligence-driven precision medicine?",
      "abstract": "Oral cancer, particularly oral squamous cell carcinoma, remains a serious health concern, with a poor prognosis and a late diagnosis. Leukoplakia, erythroplakia, lichen planus, and submucous fibrosis are examples of oral potentially malignant disorders that must be detected early but are not always so by traditional, laborious, and subjective diagnostic techniques. In oral cancer, artificial intelligence (AI) and precision medicine are becoming game-changing technologies that enhance individualized care, treatment planning, and diagnostic precision. Complex imaging and histopathology data may be analyzed using machine learning and deep learning algorithms, particularly convolutional neural networks, which can identify patterns that are invisible to the human eye. AI systems based on smartphones have demonstrated expert-level accuracy in identifying oral lesions in recent experiments. Through the discovery of biomarkers and the integration of several omics, AI-driven precision medicine also makes customized treatments possible. Nonetheless, issues with patient privacy, data bias, and the opaque \"black box\" nature of AI systems persist. The future of proactive, individualized oral cancer care will be shaped by the development of Explainable AI and robust ethical frameworks, both of which are necessary to ensure transparency, trust, and equitable integration.",
      "authors": "Kumar Nikil; Kumari Sinnha; Sultana Sadia; Khan Muhammad Saad; Patel Tirath; Anand Nikhilesh",
      "year": "2026",
      "journal": "Annals of medicine and surgery (2012)",
      "doi": "10.1097/MS9.0000000000004397",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41497043/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; oral cancer care; personalized treatment",
      "pub_types": "Letter",
      "pmcid": "PMC12768078"
    },
    {
      "pmid": "41134625",
      "title": "Improving outbreak forecasts through model augmentation.",
      "abstract": "Accurate forecasts of disease outbreaks are critical for effective public health responses, management of healthcare surge capacity, and communication of public risk. There are a growing number of powerful forecasting methods that fall into two broad categories-empirical models that extrapolate from historical data, and mechanistic models based on fixed epidemiological assumptions. However, these methods often underperform precisely when reliable predictions are most urgently needed-during periods of rapid epidemic escalation. Here, we introduce epimodulation, a hybrid approach that integrates fundamental epidemiological principles into existing predictive models to enhance forecasting accuracy, especially around epidemic peaks. When applied to empirical and machine learning forecasting methods (Autoregressive Integrated Moving Average, Holt-Winters, gradient-boosting machines, Prophet, and spline models), epimodulation improved overall prediction accuracy by an average of 12.3% (range: 8.5 to 18.7%) for COVID-19 hospital admissions and by 32.9% (range: 24.2 to 43.7%) for influenza hospital admissions; accuracy during epidemic peaks improved even further, by an average of 27.9% and 43.8%, respectively. Epimodulation also substantially enhanced the performance of complex forecasting methods, including the COVID-19 Forecast Hub ensemble model, demonstrating its broad utility in improving forecast reliability at critical moments in disease outbreaks.",
      "authors": "Gibson Graham C; Fox Spencer J; Javan Emily; Ptak Susan E; Ibrahim Oluwasegun M; Lachmann Michael; Meyers Lauren Ancel",
      "year": "2025",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "doi": "10.1073/pnas.2508575122",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41134625/",
      "mesh_terms": "Humans; Forecasting; Disease Outbreaks; COVID-19; Influenza, Human; Machine Learning; SARS-CoV-2; Epidemiological Models; Models, Statistical",
      "keywords": "COVID-19; bias correction; influenza; outbreak forecasting",
      "pub_types": "Journal Article",
      "pmcid": "PMC12582271"
    },
    {
      "pmid": "38796834",
      "title": "Nutrition facts, drug facts, and model facts: putting AI ethics into practice in gun violence research.",
      "abstract": "OBJECTIVE: Firearm injury research necessitates using data from often-exploited vulnerable populations of Black and Brown Americans. In order to reduce bias against protected attributes, this study provides a theoretical framework for establishing trust and transparency in the use of AI with the general population. METHODS: We propose a Model Facts template that is easily extendable and decomposes accuracy and demographics into standardized and minimally complex values. This framework allows general users to assess the validity and biases of a model without diving into technical model documentation. EXAMPLES: We apply the Model Facts template on 2 previously published models, a violence risk identification model and a suicide risk prediction model. We demonstrate the ease of accessing the appropriate information when the data are structured appropriately. DISCUSSION: The Model Facts template is limited in its current form to human based data and biases. Like nutrition facts, it will require educational programs for users to grasp its full utility. Human computer interaction experiments should be conducted to ensure model information is communicated accurately and in a manner that improves user decisions. CONCLUSION: The Model Facts label is the first framework dedicated to establishing trust with end users and general population consumers. Implementation of Model Facts into firearm injury research will provide public health practitioners and those impacted by firearm injury greater faith in the tools the research provides.",
      "authors": "Zhu Jessica; Cukier Michel; Richardson Joseph",
      "year": "2024",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocae102",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38796834/",
      "mesh_terms": "Humans; Gun Violence; Artificial Intelligence; Wounds, Gunshot; Risk Assessment; Firearms; Models, Theoretical; Suicide",
      "keywords": "artificial intelligence; ethics; firearm violence; machine learning; model cards",
      "pub_types": "Journal Article",
      "pmcid": "PMC11413431"
    },
    {
      "pmid": "38620726",
      "title": "Pruning-based oversampling technique with smoothed bootstrap resampling for imbalanced clinical dataset of Covid-19.",
      "abstract": "The Coronavirus Disease (COVID-19) was declared a pandemic disease by the World Health Organization (WHO), and it has not ended so far. Since the infection rate of the COVID-19 increases, the computational approach is needed to predict patients infected with COVID-19 in order to speed up the diagnosis time and minimize human error compared to conventional diagnoses. However, the number of negative data that is higher than positive data can result in a data imbalance situation that affects the classification performance, resulting in a bias in the model evaluation results. This study proposes a new oversampling technique, i.e., TRIM-SBR, to generate the minor class data for diagnosing patients infected with COVID-19. It is still challenging to develop the oversampling technique due to the data's generalization issue. The proposed method is based on pruning by looking for specific minority areas while retaining data generalization, resulting in minority data seeds that serve as benchmarks in creating new synthesized data using bootstrap resampling techniques. Accuracy, Specificity, Sensitivity, F-measure, and AUC are used to evaluate classifier performance in data imbalance cases. The results show that the TRIM-SBR method provides the best performance compared to other oversampling techniques.",
      "authors": "Wibowo Prasetyo; Fatichah Chastine",
      "year": "2022",
      "journal": "Journal of King Saud University. Computer and information sciences",
      "doi": "10.1016/j.jksuci.2021.09.021",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38620726/",
      "mesh_terms": "",
      "keywords": "COVID-19; Imbalanced data; Machine learning; Oversampling; Smoothed bootstrap resampling",
      "pub_types": "Journal Article",
      "pmcid": "PMC8482553"
    },
    {
      "pmid": "37560093",
      "title": "Internal Validation of Automated Visual Evaluation (AVE) on Smartphone Images for Cervical Cancer Screening in a Prospective Study in Zambia.",
      "abstract": "OBJECTIVES: Visual inspection with acetic acid (VIA) is a low-cost approach for cervical cancer screening used in most low- and middle-income countries (LMICs) but, similar to other visual tests like histopathology, is subjective and requires sustained training and quality assurance. We developed, trained, and validated an artificial-intelligence-based \"Automated Visual Evaluation\" (AVE) tool that can be adapted to run on smartphones to assess smartphone-captured images of the cervix and identify precancerous lesions, helping augment performance of VIA. DESIGN: Prospective study. SETTING: Eight public health facilities in Zambia. PARTICIPANTS: 8,204 women aged 25-55. INTERVENTIONS: Cervical images captured on commonly used low-cost smartphone models were matched with key clinical information including human immunodeficiency virus (HIV) and human papillomavirus (HPV) status, plus histopathology analysis (where applicable), to develop and train an AVE algorithm and evaluate its performance for use as a primary screen and triage test for women who are HPV positive. MAIN OUTCOME MEASURES: Area under the receiver operating curve (AUC); sensitivity; specificity. RESULTS: As a general population screening for cervical precancerous lesions, AVE identified cases of cervical precancerous and cancerous (CIN2+) lesions with high performance (AUC = 0.91, 95% confidence interval [CI] = 0.89 to 0.93), which translates to a sensitivity of 85% (95% CI = 81% to 90%) and specificity of 86% (95% CI = 84% to 88%) based on maximizing the Youden's index. This represents a considerable improvement over VIA, which a meta-analysis by the World Health Organization (WHO) estimates to have sensitivity of 66% and specificity of 87%. For women living with HIV, the AUC of AVE was 0.91 (95% CI = 0.88 to 0.93), and among those testing positive for high-risk HPV types, the AUC was 0.87 (95% CI = 0.83 to 0.91). CONCLUSIONS: These results demonstrate the feasibility of utilizing AVE on images captured using a commonly available smartphone by screening nurses and support our transition to clinical evaluation of AVE's sensitivity, specificity, feasibility, and acceptability across a broader range of settings. The performance of the algorithm as reported may be inflated, as biopsies were obtained only from study participants with visible aceto-white cervical lesions, which can lead to verification bias; and the images and data sets used for testing of the model, although \"unseen\" by the algorithm during training, were acquired from the same set of patients and devices, limiting the study to that of an internal validation of the AVE algorithm.",
      "authors": "Hu Liming; Mwanahamuntu Mulindi H; Sahasrabuddhe Vikrant V; Barrett Caroline; Horning Matthew P; Shah Ishan; Laverriere Zohreh; Banik Dipayan; Ji Ye; Shibemba Aaron Lunda; Chisele Samson; Munalula Mukatimui Kalima; Kaunga Friday; Musonda Francis; Malyangu Evans; Hariharan Karen Milch; Parham Groesbeck P",
      "year": "2024",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.1101/2023.07.19.23292888",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37560093/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Preprint; Journal Article",
      "pmcid": "PMC10407974"
    },
    {
      "pmid": "35313511",
      "title": "Application Effect Analysis of Operating Room Detailed Nursing Based on Medical Big Data in Patients Undergoing Gastrointestinal Tumor Surgery.",
      "abstract": "With the continuous development of internet information computing, the continuous improvement of medical and health systems, and the continuous increase of medical big data, traditional operating room care also needs to be further optimized. Medical big data is a forum data set for medical industry healthcare, electronic medical record information, clinical case record information, medical financial data, remote patient monitoring data, clinical decision support data, medical insurance data set, online consulting platform, and so on. Gastrointestinal tumors are currently one of the largest malignant tumors. Compared with ordinary patients, the presence of fear, depression, irritability, and other unhealthy emotions in patients with gastrointestinal tumors will reduce the therapeutic effect. Without careful care, the use of chemotherapy and other treatments makes patients vulnerable to various side effects. This article aims to study the use of medical big data intelligent algorithms to perform detailed care for patients during gastrointestinal tumor surgery and analyze the effects of care. This paper proposes an improved DNN algorithm; the DNN algorithm is to use several weight coefficient matrices and bias vectors to perform a series of linear operations and activation operations with the input value vector, starting from the input layer, backward calculation layer by layer, until the operation reaches the output layer, and the output result is obtained. This algorithm is used to study the theory, use mathematical formulas for method calculation and model design, and use the model to carry out detailed nursing experiments in the relevant operating room. The results of the experiment show that patients who have performed detailed care have a 27.2% improvement in treatment and rehabilitation effects than those who have not, and the level of detailed care has an obvious positive relationship with the rate of condition conversion. In the end, the hospital's detailed care quality evaluation index, which is QEI, increases by 1 point, which can increase the rate of condition conversion by 0.4.",
      "authors": "Meng Yan; Sun Aixue; Ji Ge; Wei Caiye; Jia Junhong",
      "year": "2022",
      "journal": "Journal of healthcare engineering",
      "doi": "10.1155/2022/8575305",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35313511/",
      "mesh_terms": "Algorithms; Big Data; Decision Support Systems, Clinical; Gastrointestinal Neoplasms; Humans; Operating Rooms",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Retracted Publication",
      "pmcid": "PMC8934229"
    },
    {
      "pmid": "38165797",
      "title": "Predictive Modeling for Hospital Readmissions for Patients with Heart Disease: An updated review from 2012-2023.",
      "abstract": "Hospital readmissions are a major concern for healthcare leaders, policy makers, and patients, resulting in adverse health outcomes and imposing an increased burden on hospital resources. This review aims to synthesize existing literature on predictive models focused on patients diagnosed with heart disease, which is known for its high readmission rates. Seven databases (i.e., Web of Science, Scopus, PubMed, ProQuest, Ovid, Cochrane Library and EBSCO) were consulted resulting in the inclusion of 56 eligible studies. Among these, 44 focused on model development, 7 on model validation, 4 on model improvement, and 1 on model implementation. Data were extracted on readmission types, data sources, modeling methods, and predictors, while assessments were conducted to analyze the quality of the studies. Findings showed that readmission types were significantly influenced by policy decisions, data predominantly originated from hospitals, and the prevalent modeling methods used were regression and single-layer machine learning techniques. The most important clinical predictors were related to comorbidities and complications, while the key demographic predictors were age and race. The study found that, despite advancements during the last decade, several limitations exist in current research, particularly in addressing attrition bias and handling missing data. Future research should, therefore, focus on optimizing readmission types, enhancing model generalization, using interpretable models, and emphasizing model implementation.",
      "authors": "Zhang Wei; Cheng Weihan; Fujiwara Koichi; Evans Richard; Zhu Chengyan",
      "year": "2024",
      "journal": "IEEE journal of biomedical and health informatics",
      "doi": "10.1109/JBHI.2023.3349353",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38165797/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32344284",
      "title": "Can human posture and range of motion be measured automatically by smart mobile applications?",
      "abstract": "Human posture and Range of Motion (ROM) are important components of a physical assessment and, from the collected data, it is possible to identify postural deviations such as scoliosis or joint and muscle limitations, hence identifying risks of more serious injuries. Posture assessment and ROM measures are also necessary metrics to monitor the effect of treatments used in the motor rehabilitation of patients, as well as to monitor their clinical progress. These evaluation processes are more frequently performed through visual inspection and manual palpation, which are simple and low cost methods. These methods, however, can be optimized with the use of tools such as photogrammetry and goniometry. Mobile solutions have also been developed to help health professionals to capture more objective data and with less risk of bias. Although there are already several systems proposed for assessing human posture and ROM in the literature, they have not been able to automatically identify and mark Anatomical and Segment Points (ASPs). The hypothesis presented here considers the development of a mobile application for automatic identification of ASPs by using machine learning algorithms and computer vision models associated with technologies embedded in smartphones. From ASPs identification, it will be possible to identify changes in postural alignment and ROM. In this context, our view is that an application derived from the hypothesis will serve as an additional tool to assist in the physical assessment process and, consequently, in the diagnosis of disorders related to postural and movement changes.",
      "authors": "Moreira Rayele; Teles Ariel; Fialho Renan; Dos Santos Thalyta Cibele Passos; Vasconcelos Samila Sousa; de S\u00e1 Itamara Carvalho; Bastos Victor Hugo; Silva Francisco; Teixeira Silmar",
      "year": "2020",
      "journal": "Medical hypotheses",
      "doi": "10.1016/j.mehy.2020.109741",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32344284/",
      "mesh_terms": "Humans; Mobile Applications; Movement; Photogrammetry; Posture; Range of Motion, Articular",
      "keywords": "Applications; Human postural assessment; Mobile; Spinal misalignment; Wearable devices",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36543265",
      "title": "Denoising of diffusion MRI in the cervical spinal cord - effects of denoising strategy and acquisition on intra-cord contrast, signal modeling, and feature conspicuity.",
      "abstract": "Quantitative diffusion MRI (dMRI) is a promising technique for evaluating the spinal cord in health and disease. However, low signal-to-noise ratio (SNR) can impede interpretation and quantification of these images. The purpose of this study is to evaluate several dMRI denoising approaches on their ability to improve the quality, reliability, and accuracy of quantitative diffusion MRI of the spinal cord. We evaluate three denoising approaches (Non-Local Means, Marchenko-Pastur PCA, and a newly proposed Patch2Self algorithm) and conduct five experiments to validate the denoising performance on clinical-quality and commonly-acquired dMRI acquisitions: 1) a phantom experiment to assess denoising error and bias; 2) a multi-vendor, multi-acquisition open experiment for both qualitative and quantitative evaluation of noise residuals; 3) a bootstrapping experiment to estimate uncertainty of parametric maps; 4) an assessment of spinal cord lesion conspicuity in a multiple sclerosis group; and 5) an evaluation of denoising for advanced parametric multi-compartment modeling. We find that all methods improve signal-to-noise ratio and conspicuity of MS lesions in individual diffusion weighted images (DWIs), but MPPCA and Patch2Self excel at improving the quality and intra-cord contrast of diffusion weighted images - removing signal fluctuations due to thermal noise while improving precision of estimation of diffusion parameters even with very few DWIs (i.e., 16-32) typical of clinical acquisitions. These denoising approaches hold promise for facilitating reliable diffusion observations and measurements in the spinal cord to investigate biological and pathological processes.",
      "authors": "Schilling Kurt G; Fadnavis Shreyas; Batson Joshua; Visagie Mereze; Combes Anna J E; By Samantha; McKnight Colin D; Bagnato Francesca; Garyfallidis Eleftherios; Landman Bennett A; Smith Seth A; O'Grady Kristin P",
      "year": "2023",
      "journal": "NeuroImage",
      "doi": "10.1016/j.neuroimage.2022.119826",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36543265/",
      "mesh_terms": "Humans; Cervical Cord; Reproducibility of Results; Diffusion Magnetic Resonance Imaging; Spinal Cord; Signal-To-Noise Ratio; Algorithms",
      "keywords": "Diffusion MRI; Diffusion tensor imaging; Image denoising; Multiple sclerosis; Spinal cord",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC9843739"
    },
    {
      "pmid": "34990827",
      "title": "What is the prevalence of drug use in the general population? Simulating underreported and unknown use for more accurate national estimates.",
      "abstract": "PURPOSE: To outline a method for obtaining more accurate estimates of drug use in the United States (US) general population by correcting survey data for underreported and unknown drug use. METHODS: We simulated a population (n\u00a0=\u00a0100,000) reflecting the demographics of the US adult population per the 2018 American Community Survey. Within this population, we simulated the \"true\" and self-reported prevalence of past-month cannabis and cocaine use by using available estimates of underreporting. We applied our algorithm to samples of the simulated population to correct self-reported estimates and recover the \"true\" population prevalence, validating our approach. We applied this same method to 2018 National Survey on Drug Use and Health (NSDUH) data to produce a range of underreporting-corrected estimates. RESULTS: Simulated self-report sensitivities varied by drug and sampling method (cannabis: 77.6%-78.5%, cocaine: 14.3%-22.1%). Across repeated samples, mean corrected prevalences (calculated by dividing self-reported prevalence by estimated sensitivity) closely approximated simulated \"true\" prevalences. Applying our algorithm substantially increased 2018 NSDUH estimates (self-report: cannabis\u00a0=\u00a010.5%, cocaine\u00a0=\u00a00.8%; corrected: cannabis\u00a0=\u00a015.6%-16.6%, cocaine\u00a0=\u00a02.7%-5.5%). CONCLUSIONS: National drug use prevalence estimates can be corrected for underreporting using a simple method. However, valid application of this method requires accurate data on the extent and correlates of misclassification in the general US population.",
      "authors": "Levy Natalie S; Palamar Joseph J; Mooney Stephen J; Cleland Charles M; Keyes Katherine M",
      "year": "2022",
      "journal": "Annals of epidemiology",
      "doi": "10.1016/j.annepidem.2021.12.013",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34990827/",
      "mesh_terms": "Adult; Cocaine; Health Surveys; Humans; Prevalence; Self Report; Substance-Related Disorders; United States",
      "keywords": "Algorithms; Cannabis; Cocaine; Prevalence; Quantitative bias analysis; Self-report; Surveys",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9216169"
    },
    {
      "pmid": "41114280",
      "title": "Kefir and healthy aging: revealing thematic gaps through AI-assisted screening and semantic evidence mapping.",
      "abstract": "Kefir, fermented milk rich in probiotics, has attracted growing attention for its potential anti-aging effects. Yet, studies specifically addressing kefir in the context of aging remain limited and scattered across diverse biological fields. To overcome this fragmentation, we applied an integrative approach that combines a cutting-edge AI-assisted algorithm for evidence screening with a Python-based semantic clustering pipeline. This allowed us to systematically map and classify the existing literature into four functional domains of aging: changes in body composition, energy balance, homeostatic signaling networks, and neurodegeneration. The resulting evidence map revealed a marked thematic imbalance, with most studies concentrated in mechanistic pathways such as inflammation and oxidative stress, and far fewer addressing neurocognitive or metabolic outcomes. This asymmetry suggests a structural bias in current research priorities and highlights the need to expand kefir-related studies toward more clinically relevant aging endpoints. By merging AI with domain-specific linguistic tools, our study provides a reproducible and data-driven strategy to uncover thematic blind spots and guide future investigations into kefir's anti-aging potential.",
      "authors": "Chiani Francesco",
      "year": "2025",
      "journal": "Frontiers in aging",
      "doi": "10.3389/fragi.2025.1628474",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41114280/",
      "mesh_terms": "",
      "keywords": "aging; gut-brain axes; kefir; microbiota; multisystem health effects; probiotcs; systematic evidence mapping; systematic review",
      "pub_types": "Journal Article",
      "pmcid": "PMC12528173"
    },
    {
      "pmid": "24985688",
      "title": "Robustness of automated hippocampal volumetry across magnetic resonance field strengths and repeat images.",
      "abstract": "BACKGROUND: Low HCV has recently been qualified by the European Medicines Agency as a biomarker for enrichment of clinical trials in predementia stages of Alzheimer's disease. For automated methods to meet the necessary regulatory requirements, it is essential they be standardized and their performance be well characterized. METHODS: The within-image and between-field strength reproducibility of automated hippocampal volumetry using the Learning Embeddings for Atlas Propagation (or LEAP) algorithm was assessed on 153 Alzheimer's Disease Neuroimaging Initiative subjects. RESULTS: Tests/retests at 1.5 T and 3 T, and a comparison between 1.5 T and 3 T, yielded average unsigned variabilities in HCVs of 1.51%, 1.52%, and 2.68%. A small bias between field strengths (mean signed difference, 1.17%; standard deviation, 3.07%) was observed. CONCLUSIONS: The measured reproducibility characteristics confirm the suitability of using automated magnetic resonance imaging analyses to assess HCVs quantitatively and to represent a fundamental characterization that is critical to meet the regulatory requirements for using hippocampal volumetry in clinical trials and health care.",
      "authors": "Wolz Robin; Schwarz Adam J; Yu Peng; Cole Patricia E; Rueckert Daniel; Jack Clifford R; Raunig David; Hill Derek",
      "year": "2014",
      "journal": "Alzheimer's & dementia : the journal of the Alzheimer's Association",
      "doi": "10.1016/j.jalz.2013.09.014",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24985688/",
      "mesh_terms": "Aged; Aged, 80 and over; Algorithms; Alzheimer Disease; Cognitive Dysfunction; Diagnosis, Differential; Female; Hippocampus; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Mental Status Schedule; Reproducibility of Results",
      "keywords": "Alzheimer's disease; Clinical trials; Hippocampus; Reproducibility; Segmentation; Test/retest",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "9018832",
      "title": "Evaluation of two inversion techniques for retrieving health-related aerosol fractions from personal cascade impactor measurements.",
      "abstract": "Personal cascade impactors are widely used in occupational aerosol exposure assessment. Appropriate algorithms must be used to determine the total particle size distribution from masses collected on the stages of the cascade impactor. Such algorithms should be regarded as integral components of the measurement system. When evaluating algorithms for reconstruction of size distributions from cascade impactor data, the eventual use of the size distribution must be considered. So, from an industrial hygiene perspective, an appropriate basis for comparison of given measurement systems is the accurate retrieval of the inhalable, thoracic, and respirable aerosol fractions as described by the new, internationally accepted, particle size-selective sampling conventions (which are expected to form the basis of future aerosol standards). This article compares two inversion routines in terms of their abilities to retrieve these aerosol mass fractions relative to the masses that would have been obtained using an ideal sampler that perfectly followed the sampling convention. The routines were used to invert measurements made with the Institute of Occupational Medicine personal inhalable dust spectrometer, a miniature cascade impactor that aspirates the inhalable aerosol fraction, and the results are presented graphically as contours of equal mass bias. The simplest algorithm, based on the a priori assumption of lognormality, appears to provide the best results.",
      "authors": "Ramachandran G; Vincent J H",
      "year": "1997",
      "journal": "American Industrial Hygiene Association journal",
      "doi": "10.1080/15428119791013026",
      "url": "https://pubmed.ncbi.nlm.nih.gov/9018832/",
      "mesh_terms": "Aerosols; Air Pollutants, Occupational; Algorithms; Bias; Data Interpretation, Statistical; Environmental Monitoring; Humans; Particle Size; Reproducibility of Results",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "15933309",
      "title": "Crises in clinical care: an approach to management.",
      "abstract": "A \"crisis\" in health care is \"the point in the course of a disease at which a decisive change occurs, leading either to recovery or to death\". The daunting challenges faced by clinicians when confronted with a crisis are illustrated by a tragic case in which a teenage boy died after a minor surgical procedure. Crises are challenging for reasons which include: presentation with non-specific signs or symptoms, interaction of complex factors, progressive evolution, new situations, \"revenge effects\", inadequate assistance, and time constraints. In crises, clinicians often experience anxiety- and overload-induced performance degradation, tend to use \"frequency gambling\", run out of \"rules\" and have to work from first principles, and are prone to \"confirmation bias\". The effective management of crises requires formal training, usually simulator-based, and ideally in the inter-professional groups who will need to function as a team. \"COVER ABCD-A SWIFT CHECK\" is a pre-compiled algorithm which can be applied quickly and effectively to facilitate a systematic and effective response to the wide range of potentially lethal problems which may occur suddenly in anaesthesia. A set of 25 articles describing additional pre-compiled responses collated into a manual for the management of any crisis under anaesthesia has been published electronically as companion papers to this article. This approach to crisis management should be applied to other areas of clinical medicine as well as anaesthesia.",
      "authors": "Runciman W B; Merry A F",
      "year": "2005",
      "journal": "Quality & safety in health care",
      "doi": "10.1136/qshc.2004.012856",
      "url": "https://pubmed.ncbi.nlm.nih.gov/15933309/",
      "mesh_terms": "Algorithms; Anesthesia; Anesthesiology; Australia; Consensus; Emergencies; Humans; Intraoperative Complications; Monitoring, Intraoperative; Outcome Assessment, Health Care; Risk Management; Task Performance and Analysis",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC1744000"
    },
    {
      "pmid": "38503789",
      "title": "Lightweight federated learning for STIs/HIV prediction.",
      "abstract": "This paper presents a solution that prioritises high privacy protection and improves communication throughput for predicting the risk of sexually transmissible infections/human immunodeficiency virus (STIs/HIV). The approach utilised Federated Learning (FL) to construct a model from multiple clinics and key stakeholders. FL ensured that only models were shared between clinics, minimising the risk of personal information leakage. Additionally, an algorithm was explored on the FL manager side to construct a global model that aligns with the communication status of the system. Our proposed method introduced Random Forest Federated Learning for assessing the risk of STIs/HIV, incorporating a flexible aggregation process that can be adjusted to accommodate the capacious communication system. Experimental results demonstrated the significant potential of a solution for estimating STIs/HIV risk. In comparison with recent studies, our approach yielded superior results in terms of AUC (0.97) and accuracy ( 93 %  ). Despite these promising findings, a limitation of the study lies in the experiment for man's data, due to the self-reported nature of the data and sensitive content. which may be subject to participant bias. Future research could check the performance of the proposed framework in partnership with high-risk populations (e.g., men who have sex with men) to provide a more comprehensive understanding of the proposed framework's impact and ultimately aim to improve health outcomes/health service optimisation.",
      "authors": "Nguyen Thi Phuoc Van; Yang Wencheng; Tang Zhaohui; Xia Xiaoyu; Mullens Amy B; Dean Judith A; Li Yan",
      "year": "2024",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-024-56115-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38503789/",
      "mesh_terms": "Male; Humans; HIV; Homosexuality, Male; Sexual and Gender Minorities; Sexually Transmitted Diseases; HIV Infections",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10950866"
    },
    {
      "pmid": "38127730",
      "title": "Detection of Medication Taking Using a Wrist-Worn Commercially Available Wearable Device.",
      "abstract": "PURPOSE: Medication nonadherence is a persistent and costly problem across health care. Measures of medication adherence are ineffective. Methods such as self-report, prescription claims data, or smart pill bottles have been used to monitor medication adherence, but these are subject to recall bias, lack real-time feedback, and are often expensive. METHODS: We proposed a method for monitoring medication adherence using a commercially available wearable device. Passively collected motion data were analyzed on the basis of the Movelet algorithm, a dictionary learning framework that builds person-specific chapters of movements from short frames of elemental activities within the movements. We adapted and extended the Movelet method to construct a within-patient prediction model that identifies medication-taking behaviors. RESULTS: Using 15 activity features recorded from wrist-worn wearable devices of 10 patients with breast cancer on endocrine therapy, we demonstrated that medication-taking behavior can be predicted in a controlled clinical environment with a median accuracy of 85%. CONCLUSION: These results in a patient-specific population are exemplar of the potential to measure real-time medication adherence using a wrist-worn commercially available wearable device.",
      "authors": "Laughlin Amy I; Cao Quy; Bryson Richard; Haughey Virginia; Abdul-Salaam Rashad; Gonzenbach Virgilio; Rudraraju Mridini; Eydman Igor; Tweed Christopher M; Fala Glenn J; Patel Kash; Fox Kevin R; Hanson C William; Bekelman Justin E; Shou Haochang",
      "year": "2023",
      "journal": "JCO clinical cancer informatics",
      "doi": "10.1200/CCI.22.00107",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38127730/",
      "mesh_terms": "Humans; Wrist; Wearable Electronic Devices; Patients; Self Report; Medication Adherence",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34549573",
      "title": "[Thalidomide and unilateral limb defects: the Italian chapter of a neverending story].",
      "abstract": "Fifty years after the event, Italy introduced legislation to compensate malformations in children - now in their sixties - born to mothers who had been prescribed the antiemetic drug thalidomide for morning sickness. However, compensation has been denied to people 'only' damaged in one half of their body as opposed to those with bilateral malformations. The present study reviews the papers describing case series of children born with 'thalidomide embryopathy' in the UK, Germany, and other countries around 1960. Most clinical series were not organized on the basis of inclusion/exclusion criteria, thus allowing for probable selection and information biases on maternal use of thalidomide. In any case, they included a sizable number of children with a unilateral limb defect born from mothers certainly exposed to thalidomide during the relevant pregnancy. In many of these children, limb defects were associated with visceral malformations, as frequently observed following exposure to thalidomide in utero. Similarly, later literature reviews were not bias-free in their choice of articles, as is the case of a recently proposed 'diagnostic algorithm' for thalidomide-caused specific malformations and of the advice by the Italian National Institute of Health ruling out the possibility of thalidomide producing unilateral limb defects. Overall, the scientific evidence suggests that thalidomide can cause unilateral limb defects.",
      "authors": "Terracini Benedetto",
      "year": "2021",
      "journal": "Epidemiologia e prevenzione",
      "doi": "10.19191/EP21.4.P302.087",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34549573/",
      "mesh_terms": "Child; Female; Germany; Humans; Italy; Limb Deformities, Congenital; Mothers; Pregnancy; Thalidomide",
      "keywords": "Thalidomide; Thalidomide embryopathy",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38128118",
      "title": "Semi-supervised ROC analysis for reliable and streamlined evaluation of phenotyping algorithms.",
      "abstract": "OBJECTIVE: High-throughput phenotyping will accelerate the use of electronic health records (EHRs) for translational research. A critical roadblock is the extensive medical supervision required for phenotyping algorithm (PA) estimation and evaluation. To address this challenge, numerous weakly-supervised learning methods have been proposed. However, there is a paucity of methods for reliably evaluating the predictive performance of PAs when a very small proportion of the data is labeled. To fill this gap, we introduce a semi-supervised approach (ssROC) for estimation of the receiver operating characteristic (ROC) parameters of PAs (eg, sensitivity, specificity). MATERIALS AND METHODS: ssROC uses a small labeled dataset to nonparametrically impute missing labels. The imputations are then used for ROC parameter estimation to yield more precise estimates of PA performance relative to classical supervised ROC analysis (supROC) using only labeled data. We evaluated ssROC with synthetic, semi-synthetic, and EHR data from Mass General Brigham (MGB). RESULTS: ssROC produced ROC parameter estimates with minimal bias and significantly lower variance than supROC in the simulated and semi-synthetic data. For the 5 PAs from MGB, the estimates from ssROC are 30% to 60% less variable than supROC on average. DISCUSSION: ssROC enables precise evaluation of PA performance without demanding large volumes of labeled data. ssROC is also easily implementable in open-source R software. CONCLUSION: When used in conjunction with weakly-supervised PAs, ssROC facilitates the reliable and streamlined phenotyping necessary for EHR-based research.",
      "authors": "Gao Jianhui; Bonzel Clara-Lea; Hong Chuan; Varghese Paul; Zakir Karim; Gronsbell Jessica",
      "year": "2024",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocad226",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38128118/",
      "mesh_terms": "ROC Curve; Algorithms; Software; Electronic Health Records; Phenotype",
      "keywords": "ROC analysis; electronic health records; phenotyping; semi-supervised",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10873838"
    },
    {
      "pmid": "36799303",
      "title": "Understanding search autocompletes from the perspectives of English and Spanish speakers during the early months of the COVID-19 pandemic.",
      "abstract": "The purpose of the study was to explore differences in Google search autocompletes between English and Spanish-speaking users during the first wave of the\u00a0coronavirus disease 2019 (COVID-19) pandemic. Twenty-nine individuals who were in areas with shelter-in-place state orders participated in a virtual focus group meeting to understand the algorithm bias of COVID-19 Google autocompletes. The three focus group meetings lasted for 90-120\u2009minutes. A codebook was created and transcripts were coded using NVivo qualitative software with a 95% intercoder reliability between two coders. Thematic analysis was used to analyze the data. Among the 29 participants, six self-identified as White, seven as Black/African American, five as American Indian or Alaska Native, four as Asian Indian, and three as Native Hawaiian or Pacific Islander. In terms of ethnicity, 21 participants identified as Hispanic/Latino. The themes that emerged from the study were: (1) autocompletes evoked fear and stress; (2) skepticism and hesitation towards autocomplete search; (3) familiarity with COVID-19 information impacts outlook on autocomplete search; (4) autocompletes can promote preselection of searches; and (5) lesser choice of autocomplete results for Spanish-speaking searchers. Spanish speakers expressed concerns and hesitation due to social factors and lack of information about COVID-19.",
      "authors": "Valera Pamela; Carmona David; Singh Vivek; Malarkey Sarah; Baquerizo Humberto; Smith Nadia",
      "year": "2024",
      "journal": "Journal of community psychology",
      "doi": "10.1002/jcop.23013",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36799303/",
      "mesh_terms": "Focus Groups; South Asian People; Pandemics; Female; American Indian or Alaska Native; Humans; Native Hawaiian or Pacific Islander; Hispanic or Latino; Middle Aged; Information Seeking Behavior; White; Adult; COVID-19; Male; Young Adult; SARS-CoV-2; Search Engine; Black or African American; Language",
      "keywords": "COVID\u201019; Hispanics/Latinos; autocomplete search; focus groups; health equity; health information; qualitative methods",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "30467878",
      "title": "Estimating the receiver operating characteristic curve in matched case control studies.",
      "abstract": "The matched case-control design is frequently used in the study of complex disorders and can result in significant gains in efficiency, especially in the context of measuring biomarkers; however, risk prediction in this setting is not straightforward. We propose an inverse-probability weighting approach to estimate the predictive ability associated with a set of covariates. In particular, we propose an algorithm for estimating the summary index, area under the curve corresponding to the Receiver Operating Characteristic curve associated with a set of pre-defined covariates for predicting a binary outcome. By combining data from the parent cohort with that generated in a matched case control study, we describe methods for estimation of the population parameters of interest and the corresponding area under the curve. We evaluate the bias associated with the proposed methods in simulations by considering a range of parameter settings. We illustrate the methods in two data applications: (1) a prospective cohort study of cardiovascular disease in women, the Women's Health Study, and (2)\u00a0a matched case-control study nested within the Nurses' Health Study aimed at risk prediction of invasive breast cancer.",
      "authors": "Xu Hui; Qian Jing; Paynter Nina P; Zhang Xuehong; Whitcomb Brian W; Tworoger Shelley S; Rexrode Kathryn M; Hankinson Susan E; Balasubramanian Raji",
      "year": "2019",
      "journal": "Statistics in medicine",
      "doi": "10.1002/sim.7986",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30467878/",
      "mesh_terms": "Adult; Age Factors; Aged; Aged, 80 and over; Breast Neoplasms; Cardiovascular Diseases; Case-Control Studies; Female; Humans; Middle Aged; Models, Statistical; Probability; ROC Curve; Risk Factors",
      "keywords": "AUC; biomarker discovery; inverse probability weighting; matched case control studies; receiver operating characteristic (ROC) curve",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC6768691"
    },
    {
      "pmid": "31078000",
      "title": "Cluster-based bagging of constrained mixed-effects models for high spatiotemporal resolution nitrogen oxides prediction over large regions.",
      "abstract": "BACKGROUND: Accurate estimation of nitrogen dioxide (NO2) and nitrogen oxide (NOx) concentrations at high spatiotemporal resolutions is crucial for improving evaluation of their health effects, particularly with respect to short-term exposures and acute health outcomes. For estimation over large regions like California, high spatial density field campaign measurements can be combined with more sparse routine monitoring network measurements to capture spatiotemporal variability of NO2 and NOx concentrations. However, monitors in spatially dense field sampling are often highly clustered and their uneven distribution creates a challenge for such combined use. Furthermore, heterogeneities due to seasonal patterns of meteorology and source mixtures between sub-regions (e.g. southern vs. northern California) need to be addressed. OBJECTIVES: In this study, we aim to develop highly accurate and adaptive machine learning models to predict high-resolution NO2 and NOx concentrations over large geographic regions using measurements from different sources that contain samples with heterogeneous spatiotemporal distributions and clustering patterns. METHODS: We used a comprehensive Kruskal-K-means method to cluster the measurement samples from multiple heterogeneous sources. Spatiotemporal cluster-based bootstrap aggregating (bagging) of the base mixed-effects models was then applied, leveraging the clusters to obtain balanced and less correlated training samples for less bias and improvement in generalization. Further, we used the machine learning technique of grid search to find the optimal interaction of temporal basis functions and the scale of spatial effects, which, together with spatiotemporal covariates, adequately captured spatiotemporal variability in NO2 and NOx at the state and local levels. RESULTS: We found an optimal combination of four temporal basis functions and 200\u202fm scale spatial effects for the base mixed-effects models. With the cluster-based bagging of the base models, we obtained robust predictions with an ensemble cross validation R2 of 0.88 for both NO2 and NOx [RMSE (RMSEIQR): 3.62\u202fppb (0.28) and 9.63\u202fppb (0.37) respectively]. In independent tests of random sampling, our models achieved similarly strong performance (R2 of 0.87-0.90; RMSE of 3.97-9.69\u202fppb; RMSEIQR of 0.21-0.27), illustrating minimal over-fitting. CONCLUSIONS: Our approach has important implications for fusing data from highly clustered and heterogeneous measurement samples from multiple data sources to produce highly accurate concentration estimates of air pollutants such as NO2 and NOx at high resolution over a large region.",
      "authors": "Li Lianfa; Girguis Mariam; Lurmann Frederick; Wu Jun; Urman Robert; Rappaport Edward; Ritz Beate; Franklin Meredith; Breton Carrie; Gilliland Frank; Habre Rima",
      "year": "2019",
      "journal": "Environment international",
      "doi": "10.1016/j.envint.2019.04.057",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31078000/",
      "mesh_terms": "Air Pollutants; Air Pollution; California; Cluster Analysis; Environmental Monitoring; Machine Learning; Models, Theoretical; Nitrogen Dioxide; Nitrogen Oxides",
      "keywords": "Air pollution; Cluster methods; Generalization; Machine learning; Nitrogen oxides; Spatiotemporal variability",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6538277"
    },
    {
      "pmid": "38441952",
      "title": "Machine Learning-Based Approach for Identifying Research Gaps: COVID-19 as a Case Study.",
      "abstract": "BACKGROUND: Research gaps refer to unanswered questions in the existing body of knowledge, either due to a lack of studies or inconclusive results. Research gaps are essential starting points and motivation in scientific research. Traditional methods for identifying research gaps, such as literature reviews and expert opinions, can be time consuming, labor intensive, and prone to bias. They may also fall short when dealing with rapidly evolving or time-sensitive subjects. Thus, innovative scalable approaches are needed to identify research gaps, systematically assess the literature, and prioritize areas for further study in the topic of interest. OBJECTIVE: In this paper, we propose a machine learning-based approach for identifying research gaps through the analysis of scientific literature. We used the COVID-19 pandemic as a case study. METHODS: We conducted an analysis to identify research gaps in COVID-19 literature using the COVID-19 Open Research (CORD-19) data set, which comprises 1,121,433 papers related to the COVID-19 pandemic. Our approach is based on the BERTopic topic modeling technique, which leverages transformers and class-based term frequency-inverse document frequency to create dense clusters allowing for easily interpretable topics. Our BERTopic-based approach involves 3 stages: embedding documents, clustering documents (dimension reduction and clustering), and representing topics (generating candidates and maximizing candidate relevance). RESULTS: After applying the study selection criteria, we included 33,206 abstracts in the analysis of this study. The final list of research gaps identified 21 different areas, which were grouped into 6 principal topics. These topics were: \"virus of COVID-19,\" \"risk factors of COVID-19,\" \"prevention of COVID-19,\" \"treatment of COVID-19,\" \"health care delivery during COVID-19,\" \"and impact of COVID-19.\" The most prominent topic, observed in over half of the analyzed studies, was \"the impact of COVID-19.\" CONCLUSIONS: The proposed machine learning-based approach has the potential to identify research gaps in scientific literature. This study is not intended to replace individual literature research within a selected topic. Instead, it can serve as a guide to formulate precise literature search queries in specific areas associated with research questions that previous publications have earmarked for future exploration. Future research should leverage an up-to-date list of studies that are retrieved from the most common databases in the target area. When feasible, full texts or, at minimum, discussion sections should be analyzed rather than limiting their analysis to abstracts. Furthermore, future studies could evaluate more efficient modeling algorithms, especially those combining topic modeling with statistical uncertainty quantification, such as conformal prediction.",
      "authors": "Abd-Alrazaq Alaa; Nashwan Abdulqadir J; Shah Zubair; Abujaber Ahmad; Alhuwail Dari; Schneider Jens; AlSaad Rawan; Ali Hazrat; Alomoush Waleed; Ahmed Arfan; Aziz Sarah",
      "year": "2024",
      "journal": "JMIR formative research",
      "doi": "10.2196/49411",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38441952/",
      "mesh_terms": "",
      "keywords": "BERT; BERTopic; COVID; COVID-19; NLP; SARS-CoV-2; coronavirus; literature review; machine learning; natural language processing; research gap; research gaps; research topic; research topics; review methodology; review methods; scientific literature; text analysis; topic clustering",
      "pub_types": "Journal Article",
      "pmcid": "PMC10916961"
    },
    {
      "pmid": "40039210",
      "title": "Real-World Measures of Cardiorespiratory Function Can Stratify Primary Sjogren's Syndrome Participants with Persistent Fatigue.",
      "abstract": "Many individuals with various chronic diseases experience debilitating fatigue that substantially impacts their quality of life. Currently, assessments of fatigue rely on patient reported outcomes (PROs), which are subjective and prone to recall bias. Wearable devices, however, can provide valid and continuous estimates of human activity and physiology, which are essential components of health, and may provide objective evidence of fatigue. This study aims to stratify primary Sjogren's syndrome (PSS) patients with different fatigue levels using real-world measures of activity and cardiorespiratory function. 72 participants with PSS wore a VitalPatch sensor on the chest for two 7-day continuous periods. Concurrently, the participants completed PROs relating to fatigue up to 4 times a day. The mean, standard deviation, minimum, and maximum of the heart rate (HR) and respiratory rate (RR), both overall and during periods of walking, sitting, and standing were calculated, along with the difference in HR and RR between these activities, and the time spent in each activity. The Mann-Whitney U test and four machine learning classifiers were used to assess if the digital measures could separate the participants categorised as \"persistent\" or \"non-persistent\" fatigue. The categorization of these two groups were tested using 5 different thresholds.None of the activity-time measures were statistically different and very few of the RR measures were statistically different between the groups (p<0.05). However, 64% of HR measures differentiated persistent fatigue from non-persistent fatigue participants (p<0.05). Machine learning also found that HR measures could separate the fatigue persistency groups with accuracies up to 77%. Therefore, this analysis has shown that real-world measures from a digital wearable are able to stratify PSS participants with persistent and non-persistent fatigue. Thus, leading to an objective, single-device approach to identifying fatigue severity in an immune-mediated inflammatory disease.",
      "authors": "Hinchliffe Chloe; Zhai Bing; Macrae Victoria; Walton Jade; Ng Wan-Fai; Del Din Silvia",
      "year": "2024",
      "journal": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference",
      "doi": "10.1109/EMBC53108.2024.10782454",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40039210/",
      "mesh_terms": "Humans; Sjogren's Syndrome; Fatigue; Female; Middle Aged; Male; Heart Rate; Adult; Respiratory Rate; Machine Learning; Aged; Wearable Electronic Devices",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36184985",
      "title": "Development and validation of the Chinese Geriatric Depression Risk calculator (CGD-risk): A screening tool to identify elderly Chinese with depression.",
      "abstract": "BACKGROUND: The prevalence of depression among China's elderly is high, but stigma surrounding mental illness and a shortage of psychiatrists limit widespread screening and diagnosis of geriatric depression. We sought to develop a screening tool using easy-to-obtain and minimally sensitive predictors to identify elderly Chinese with depressive symptoms (depression hereafter) for referral to mental health services and determine the most important factors for effective screening. METHODS: Using nationally representative survey data, we developed and externally validated the Chinese Geriatric Depression Risk calculator (CGD-Risk). CGD-Risk, a gradient boosting machine learning model, was evaluated based on discrimination (Concordance (C) statistic), calibration, and through a decision curve analysis. We conducted a sensitivity analysis on a cohort of middle-aged Chinese, a sub-group analysis using three data sets, and created predictor importance and partial dependence plots to enhance interpretability. RESULTS: A total of 5681 elderly Chinese were included in the development data and 12,373 in the external validation data. CGD-Risk showed good discrimination during internal validation (C: 0.81, 95\u00a0% CI 0.79 to 0.84) and external validation (C: 0.77, 95\u00a0% CI: 0.76, 0.78). Compared to an alternative screening strategy CGD-Risk would correctly identify 17.8 more elderly with depression per 100 people screened. LIMITATIONS: We were only able to externally validate a partial version of CGD-Risk due to differences between the internal and external validation data. CONCLUSIONS: CGD-Risk is a clinically viable, minimally sensitive screening tool that could identify elderly Chinese at high risk of depression while circumventing issues of response bias from stigma surrounding emotional openness.",
      "authors": "Sakal Collin; Li Juan; Xiang Yu-Tao; Li Xinyue",
      "year": "2022",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2022.09.034",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36184985/",
      "mesh_terms": "Middle Aged; Aged; Humans; Depression; Reproducibility of Results; Asian People; Mass Screening; China",
      "keywords": "China; Depression; Geriatrics; Machine learning; Prediction",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37545750",
      "title": "Ability of artificial intelligence to identify self-reported race in chest x-ray using pixel intensity counts.",
      "abstract": "PURPOSE: Prior studies show convolutional neural networks predicting self-reported race using x-rays of chest, hand and spine, chest computed tomography, and mammogram. We seek an understanding of the mechanism that reveals race within x-ray images, investigating the possibility that race is not predicted using the physical structure in x-ray images but is embedded in the grayscale pixel intensities. APPROACH: Retrospective full year 2021, 298,827 AP/PA chest x-ray images from 3 academic health centers across the United States and MIMIC-CXR, labeled by self-reported race, were used in this study. The image structure is removed by summing the number of each grayscale value and scaling to percent per image (PPI). The resulting data are tested using multivariate analysis of variance (MANOVA) with Bonferroni multiple-comparison adjustment and class-balanced MANOVA. Machine learning (ML) feed-forward networks (FFN) and decision trees were built to predict race (binary Black or White and binary Black or other) using only grayscale value counts. Stratified analysis by body mass index, age, sex, gender, patient type, make/model of scanner, exposure, and kilovoltage peak setting was run to study the impact of these factors on race prediction following the same methodology. RESULTS: MANOVA rejects the null hypothesis that classes are the same with 95% confidence (F 7.38, P<0.0001) and balanced MANOVA (F 2.02, P<0.0001). The best FFN performance is limited [area under the receiver operating characteristic (AUROC) of 69.18%]. Gradient boosted trees predict self-reported race using grayscale PPI (AUROC 77.24%). CONCLUSIONS: Within chest x-rays, pixel intensity value counts alone are statistically significant indicators and enough for ML classification tasks of patient self-reported race.",
      "authors": "Burns John Lee; Zaiman Zachary; Vanschaik Jack; Luo Gaoxiang; Peng Le; Price Brandon; Mathias Garric; Mittal Vijay; Sagane Akshay; Tignanelli Christopher; Chakraborty Sunandan; Gichoya Judy Wawira; Purkayastha Saptarshi",
      "year": "2023",
      "journal": "Journal of medical imaging (Bellingham, Wash.)",
      "doi": "10.1117/1.JMI.10.6.061106",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37545750/",
      "mesh_terms": "",
      "keywords": "bias; machine learning; population imaging; x-ray",
      "pub_types": "Journal Article",
      "pmcid": "PMC10400898"
    },
    {
      "pmid": "38413276",
      "title": "Region-wide assessment of National Immunization Technical Advisory Groups (NITAGs) using the NITAG Maturity Assessment Tool (NMAT) - Experience from the Eastern Mediterranean Region of the World Health Organization, 2023.",
      "abstract": "National Immunization Technical Advisory Groups (NITAGs) are independent bodies that help improve national immunization programmes in decision making on immunization policy. The new NITAG Maturity Assessment Tool (NMAT) provided an opportunity to conduct a region-wide assessment to improve NITAG capacity and foster institutional growth. We share experience of the Eastern Mediterranean Region (EMR) of the World Health Organization (WHO) in using NMAT and the use of findings to develop improvement plans. NITAG chairs and secretariats from 22 EMR countries attended a virtual NMAT training in 2023. They self-assessed their NITAGs using the tool and developed improvement plans. An algorithm used the data to determine maturity levels for seven indicators. We consolidated results for the region by income groups. Of 22 countries (or NITAGs), 20 (91%) submitted NITAG assessment findings and 19 an improvement plan. The proportion of criteria met per indicator varied from 36% for independence and non-bias to 74% for establishment and composition. Maturity level varied by indicator. Of 20 NITAGs, less than half had an intermediate or higher-level maturity for the indicators of independence and non-bias 1 (5%), operations 3 (15%), making recommendations 4 (20%), stakeholder recognition 6 (30%), and resources and secretariat support 7 (35%). Meanwhile 11 (55%) NITAGs had an intermediate or higher maturity level for the indicators of establishment and composition and for integration into policy making process. Participants described NMAT as a concise, useful, user-friendly tool. NMAT is a practical tool that can be used by NITAGs to provide insights and strategic direction for individual countries and regionally. Prevention and management of conflict of interest is the domain that requires the most improvement in EMR. Planned activities should be implemented, monitored and a follow up assessment conducted in 2025.",
      "authors": "Sume Gerald Etapelong; Hasan Quamrul; Shefer Abigail; Henaff Louise; Cavallaro Kathleen F; Tencza Catherine B; Hadler Stephen C; Sidy Ndiaye; Sardar Parwiz; Kagina Benjamin M; Hutin Yvan",
      "year": "2024",
      "journal": "Vaccine",
      "doi": "10.1016/j.vaccine.2024.02.058",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38413276/",
      "mesh_terms": "Humans; Health Policy; Advisory Committees; Immunization Programs; Immunization; World Health Organization",
      "keywords": "Eastern Mediterranean Region (EMR); Maturity level; NITAG Maturity Assessment Tool (NMAT); National Immunization Technical Advisory Groups (NITAG)",
      "pub_types": "Journal Article",
      "pmcid": "PMC11007386"
    },
    {
      "pmid": "28899847",
      "title": "Enhancing Seasonal Influenza Surveillance: Topic Analysis of Widely Used Medicinal Drugs Using Twitter Data.",
      "abstract": "BACKGROUND: Uptake of medicinal drugs (preventive or treatment) is among the approaches used to control disease outbreaks, and therefore, it is of vital importance to be aware of the counts or frequencies of most commonly used drugs and trending topics about these drugs from consumers for successful implementation of control measures. Traditional survey methods would have accomplished this study, but they are too costly in terms of resources needed, and they are subject to social desirability bias for topics discovery. Hence, there is a need to use alternative efficient means such as Twitter data and machine learning (ML) techniques. OBJECTIVE: Using Twitter data, the aim of the study was to (1) provide a methodological extension for efficiently extracting widely consumed drugs during seasonal influenza and (2) extract topics from the tweets of these drugs and to infer how the insights provided by these topics can enhance seasonal influenza surveillance. METHODS: From tweets collected during the 2012-13 flu season, we first identified tweets with mentions of drugs and then constructed an ML classifier using dependency words as features. The classifier was used to extract tweets that evidenced consumption of drugs, out of which we identified the mostly consumed drugs. Finally, we extracted trending topics from each of these widely used drugs' tweets using latent Dirichlet allocation (LDA). RESULTS: Our proposed classifier obtained an F1 score of 0.82, which significantly outperformed the two benchmark classifiers (ie, P<.001 with the lexicon-based and P=.048 with the 1-gram term frequency [TF]). The classifier extracted 40,428 tweets that evidenced consumption of drugs out of 50,828 tweets with mentions of drugs. The most widely consumed drugs were influenza virus vaccines that had around 76.95% (31,111/40,428) share of the total; other notable drugs were Theraflu, DayQuil, NyQuil, vitamins, acetaminophen, and oseltamivir. The topics of each of these drugs exhibited common themes or experiences from people who have consumed these drugs. Among these were the enabling and deterrent factors to influenza drugs uptake, which are keys to mitigating the severity of seasonal influenza outbreaks. CONCLUSIONS: The study results showed the feasibility of using tweets of widely consumed drugs to enhance seasonal influenza surveillance in lieu of the traditional or conventional surveillance approaches. Public health officials and other stakeholders can benefit from the findings of this study, especially in enhancing strategies for mitigating the severity of seasonal influenza outbreaks. The proposed methods can be extended to the outbreaks of other diseases.",
      "authors": "Kagashe Ireneus; Yan Zhijun; Suheryani Imran",
      "year": "2017",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/jmir.7393",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28899847/",
      "mesh_terms": "Disease Outbreaks; Drug Therapy; Humans; Influenza, Human; Machine Learning; Public Health; Social Media",
      "keywords": "Twitter messaging; disease outbreaks; influenza; influenza vaccines; machine learning; natural language processing; public health surveillance; social media",
      "pub_types": "Journal Article",
      "pmcid": "PMC5617904"
    },
    {
      "pmid": "30911365",
      "title": "Development of a Wireless Health Monitoring System for Measuring Core Body Temperature from the Back of the Body.",
      "abstract": "In this paper, a user-friendly and low-cost wireless health monitoring system that measures skin temperature from the back of the body for monitoring the core body temperature is proposed. To measure skin temperature accurately, a semiconductor-based microtemperature sensor with a maximum accuracy of \u00b10.3\u00b0C was chosen and controlled by a high-performance/low-power consumption Acorn-Reduced Instruction Set Computing Machine (ARM) architecture microcontroller to build the temperature measuring device. Relying on a 2.4\u2009GHz multichannel Gaussian frequency shift keying (GFSK) RF communication technology, up to 100 proposed temperature measuring devices can transmit the data to one receiver at the same time. The shell of the proposed wireless temperature-measuring device was manufactured via a 3D printer, and the device was assembled to conduct the performance tests and in vivo experiments. The performance test was conducted with a K-type temperature sensor in a temperature chamber to observe temperature measurement performance. The results showed an error value between two devices was less than 0.1\u00b0C from 25 to 40\u00b0C. For the in vivo experiments, the device was attached on the back of 10 younger male subjects to measure skin temperature to investigate the relationship with ear temperature. According to the experimental results, an algorithm based on the curve-fitting method was implemented in the proposed device to estimate the core body temperature by the measured skin temperature value. The algorithm was established as a linear model and set as a quadratic formula with an interpolant and with each coefficient for the equation set with 95% confidence bounds. For evaluating the goodness of fit, the sum of squares due to error (SSE), R-square, adjusted R-square, and root mean square error (RMSE) values were 33.0874, 0.0212, 0.0117, and 0.3998, respectively. As the experimental results have shown, the mean value for an error between ear temperature and estimated core body temperature is about \u00b10.19\u00b0C, and the mean bias is 0.05\u2009\u00b1\u20090.14\u00b0C when the subjects are in steady status.",
      "authors": "Wei Qun; Park Hee-Joon; Lee Jyung Hyun",
      "year": "2019",
      "journal": "Journal of healthcare engineering",
      "doi": "10.1155/2019/8936121",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30911365/",
      "mesh_terms": "Adult; Algorithms; Back; Equipment Design; Humans; Male; Monitoring, Physiologic; Skin Temperature; Thermometry; Wireless Technology; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6397989"
    },
    {
      "pmid": "30195660",
      "title": "An evaluation of clinical order patterns machine-learned from clinician cohorts stratified by patient mortality outcomes.",
      "abstract": "OBJECTIVE: Evaluate the quality of clinical order practice patterns machine-learned from clinician cohorts stratified by patient mortality outcomes. MATERIALS AND METHODS: Inpatient electronic health records from 2010 to 2013 were extracted from a tertiary academic hospital. Clinicians (n\u202f=\u202f1822) were stratified into low-mortality (21.8%, n\u202f=\u202f397) and high-mortality (6.0%, n\u202f=\u202f110) extremes using a two-sided P-value score quantifying deviation of observed vs. expected 30-day patient mortality rates. Three patient cohorts were assembled: patients seen by low-mortality clinicians, high-mortality clinicians, and an unfiltered crowd of all clinicians (n\u202f=\u202f1046, 1046, and 5230 post-propensity score matching, respectively). Predicted order lists were automatically generated from recommender system algorithms trained on each patient cohort and evaluated against (i) real-world practice patterns reflected in patient cases with better-than-expected mortality outcomes and (ii) reference standards derived from clinical practice guidelines. RESULTS: Across six common admission diagnoses, order lists learned from the crowd demonstrated the greatest alignment with guideline references (AUROC range\u202f=\u202f0.86-0.91), performing on par or better than those learned from low-mortality clinicians (0.79-0.84, P\u202f<\u202f10-5) or manually-authored hospital order sets (0.65-0.77, P\u202f<\u202f10-3). The same trend was observed in evaluating model predictions against better-than-expected patient cases, with the crowd model (AUROC mean\u202f=\u202f0.91) outperforming the low-mortality model (0.87, P\u202f<\u202f10-16) and order set benchmarks (0.78, P\u202f<\u202f10-35). DISCUSSION: Whether machine-learning models are trained on all clinicians or a subset of experts illustrates a bias-variance tradeoff in data usage. Defining robust metrics to assess quality based on internal (e.g. practice patterns from better-than-expected patient cases) or external reference standards (e.g. clinical practice guidelines) is critical to assess decision support content. CONCLUSION: Learning relevant decision support content from all clinicians is as, if not more, robust than learning from a select subgroup of clinicians favored by patient outcomes.",
      "authors": "Wang Jason K; Hom Jason; Balasubramanian Santhosh; Schuler Alejandro; Shah Nigam H; Goldstein Mary K; Baiocchi Michael T M; Chen Jonathan H",
      "year": "2018",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2018.09.005",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30195660/",
      "mesh_terms": "Algorithms; Area Under Curve; Data Mining; Decision Making; Decision Support Systems, Clinical; Electronic Health Records; Evidence-Based Medicine; Hospitalization; Humans; Inpatients; Machine Learning; Mortality; Pattern Recognition, Automated; Practice Guidelines as Topic; Practice Patterns, Physicians'; ROC Curve; Regression Analysis; Treatment Outcome",
      "keywords": "Clinical decision support; Data mining; Electronic health records; Machine learning; Mortality",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6250126"
    },
    {
      "pmid": "24504175",
      "title": "Beyond crosswalks: reliability of exposure assessment following automated coding of free-text job descriptions for occupational epidemiology.",
      "abstract": "Epidemiologists typically collect narrative descriptions of occupational histories because these are less prone than self-reported exposures to recall bias of exposure to a specific hazard. However, the task of coding these narratives can be daunting and prohibitively time-consuming in some settings. The aim of this manuscript is to evaluate the performance of a computer algorithm to translate the narrative description of occupational codes into standard classification of jobs (2010 Standard Occupational Classification) in an epidemiological context. The fundamental question we address is whether exposure assignment resulting from manual (presumed gold standard) coding of the narratives is materially different from that arising from the application of automated coding. We pursued our work through three motivating examples: assessment of physical demands in Women's Health Initiative observational study, evaluation of predictors of exposure to coal tar pitch volatiles in the US Occupational Safety and Health Administration's (OSHA) Integrated Management Information System, and assessment of exposure to agents known to cause occupational asthma in a pregnancy cohort. In these diverse settings, we demonstrate that automated coding of occupations results in assignment of exposures that are in reasonable agreement with results that can be obtained through manual coding. The correlation between physical demand scores based on manual and automated job classification schemes was reasonable (r = 0.5). The agreement between predictive probability of exceeding the OSHA's permissible exposure level for polycyclic aromatic hydrocarbons, using coal tar pitch volatiles as a surrogate, based on manual and automated coding of jobs was modest (Kendall rank correlation = 0.29). In the case of binary assignment of exposure to asthmagens, we observed that fair to excellent agreement in classifications can be reached, depending on presence of ambiguity in assigned job classification (\u03ba = 0.5-0.8). Thus, the success of automated coding appears to depend on the setting and type of exposure that is being assessed. Our overall recommendation is that automated translation of short narrative descriptions of jobs for exposure assessment is feasible in some settings and essential for large cohorts, especially if combined with manual coding to both assess reliability of coding and to further refine the coding algorithm.",
      "authors": "Burstyn Igor; Slutsky Anton; Lee Derrick G; Singer Alison B; An Yuan; Michael Yvonne L",
      "year": "2014",
      "journal": "The Annals of occupational hygiene",
      "doi": "10.1093/annhyg/meu006",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24504175/",
      "mesh_terms": "Adult; Aged; Algorithms; Asthma, Occupational; Coal Tar; Electronic Data Processing; Epidemiologic Methods; Female; Humans; Job Description; Male; Middle Aged; Occupational Exposure; Occupations; Pregnancy; Reproducibility of Results",
      "keywords": "allergens; coal tar pitch volatiles; epidemiology methodology; ergonomics; exposure assessment methodology; job-exposure matrix",
      "pub_types": "Evaluation Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "16930494",
      "title": "Radiographic 2D:4D index in females: no relation to anthropometric, behavioural, nutritional, health-related, occupational or fertility variables.",
      "abstract": "BACKGROUND: The ratio of index finger to ring finger length (2D:4D index) may be an indicator of gonadal hormone exposure, because the differentiation of gonads, fingers and toes is influenced by the same HOXA and HOHD genes. Some previous studies have found significant associations between the 2D:4D index and sexual, psychological or behavioural variables. We studied the usability of the radiographic 2D:4D index as a potential predictor of several features in a large female sample. METHODS: 271 female dentists and 219 teachers (age 45 - 63 years) had their hands radiographed and their right 2nd and 4th fingers measured from the base of the bony proximal phalanxes to the tip of the distal phalanxes to define the radiographic 2D:4D index. The study subjects were classified into two distinctly separate clusters (by using cluster analysis with the K-means algorithm) in each of the following dimensions: anthropometric (including four items), behavioural (five items), nutritional (five items), health-related (seven items), occupational (Karasek job control and job demand scores) and fertility (four items). RESULTS: The radiographic 2D:4D index ranged from 0.845 to 0.981 (mean 0.925, SD 0.021). The intraclass correlation between three radiographers' measurements (31 cases) was 0.971. No differences concerning the 2D:4D index were found between clusters 1 and 2 in any studied dimension, nor did any of the items in clusters have relations with the 2D:4D index when tested separately with bivariate tests. CONCLUSION: Despite the ideal set-up of the measuring possibilities in a relatively large radiographic material the variables currently studied were not dependent on the length of finger bones. It can therefore be questioned whether any real associations between the bony 2D:4D index in adult life and (direct or indirect) hormone dependent effects exist. There may be a publication bias explaining that mostly positive findings have been the previously reported. However, the associations of the 2D:4D index with various features, if present, may be related to the soft parts of fingers rather than to the length of bones.",
      "authors": "Vehmas Tapio; Solovieva Svetlana; Leino-Arjas P\u00e4ivi",
      "year": "2006",
      "journal": "Journal of negative results in biomedicine",
      "doi": "10.1186/1477-5751-5-12",
      "url": "https://pubmed.ncbi.nlm.nih.gov/16930494/",
      "mesh_terms": "Adult; Anthropometry; Behavior; Body Mass Index; Cluster Analysis; Diet; Employment; Female; Fertility; Fingers; Humans; Middle Aged; Personality; Radiography; Women's Health",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC1564413"
    },
    {
      "pmid": "26958849",
      "title": "Incidence of Hospitalization for Respiratory Syncytial Virus Infection amongst Children in Ontario, Canada: A Population-Based Study Using Validated Health Administrative Data.",
      "abstract": "IMPORTANCE: RSV is a common illness among young children that causes significant morbidity and health care costs. OBJECTIVE: Routinely collected health administrative data can be used to track disease incidence, explore risk factors and conduct health services research. Due to potential for misclassification bias, the accuracy of data-elements should be validated prior to use. The objectives of this study were to validate an algorithm to accurately identify pediatric cases of hospitalized respiratory syncytial virus (RSV) from within Ontario's health administrative data, estimate annual incidence of hospitalization due to RSV and report the prevalence of major risk factors within hospitalized patients. STUDY DESIGN AND SETTING: A retrospective chart review was performed to establish a reference-standard cohort of children from the Ottawa region admitted to the Children's Hospital of Eastern Ontario (CHEO) for RSV-related disease in 2010 and 2011. Chart review data was linked to Ontario's administrative data and used to evaluate the diagnostic accuracy of algorithms of RSV-related ICD-10 codes within provincial hospitalization and emergency department databases. Age- and sex-standardized incidence was calculated over time, with trends in incidence assessed using Poisson regression. RESULTS: From a total of 1411 admissions, chart review identified 327 children hospitalized for laboratory confirmed RSV-related disease. Following linkage to administrative data and restriction to first admissions, there were 289 RSV patients in the reference-standard cohort. The best algorithm, based on hospitalization data, resulted in sensitivity 97.9% (95%CI: 95.5-99.2%), specificity 99.6% (95%CI: 98.2-99.8%), PPV 96.9% (95%CI: 94.2-98.6%), NPV 99.4% (95%CI: 99.4-99.9%). Incidence of hospitalized RSV in Ontario from 2005-2012 was 10.2 per 1000 children under 1 year and 4.8 per 1000 children aged 1 to 3 years. During the surveillance period, there was no identifiable increasing or decreasing linear trend in the incidence of hospitalized RSV, hospital length of stay and PICU admission rates. Among the Ontario RSV cohort, 16.3% had one or more major risk factors, with a decreasing trend observed over time. CONCLUSION: Children hospitalized for RSV-related disease can be accurately identified within population-based health administrative data. RSV is a major public health concern and incidence has not changed over time, suggesting a lack of progress in prevention.",
      "authors": "Pisesky Andrea; Benchimol Eric I; Wong Coralie A; Hui Charles; Crowe Megan; Belair Marc-Andre; Pojsupap Supichaya; Karnauchow Tim; O'Hearn Katie; Yasseen Abdool S; McNally James D",
      "year": "2016",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0150416",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26958849/",
      "mesh_terms": "Child; Child, Preschool; Female; Hospitalization; Humans; Incidence; Male; Ontario; Respiratory Syncytial Virus Infections; Retrospective Studies",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC4784925"
    },
    {
      "pmid": "32886064",
      "title": "Estimation of the 10-Year Risk of Fatal Cardiovascular Disease in the Portuguese Population: Results from the First Portuguese Health Examination Survey (INSEF 2015).",
      "abstract": "INTRODUCTION: Cardiovascular disease is the leading cause of morbidity and mortality in Portugal and globally. Cardiovascular risk algorithms, namely the SCORE (Systematic Coronary Risk Evaluation), are recommended in the context of cardiovascular disease prevention. Our aim is to estimate and characterize the cardiovascular risk of the Portuguese population aged between 40 and 65 years old, in 2015, using the SCORE algorithm. MATERIAL AND METHODS: This study was performed on a subsample of the first Portuguese National Health Examination Survey - INSEF, including all participants between 40 and 65 years old with available data on sex, age, smoking status, total cholesterol and systolic blood pressure (n = 2945). The prevalence of the cardiovascular risk categories were stratified by sex, age group, marital status, educational level, occupational activity, urbanization of living area, region and income. RESULTS: In 2015, about 5.1% and 11.9% of the Portuguese resident population aged between 40 and 65 years old were, respectively, at high and very high risk of having a fatal CV event in the following 10 years. The highest prevalence of very high cardiovascular risk was found in males, individuals aged 60-65 years old, married or living with someone, without any formal education or just with the 1st cycle of basic education and belonging to the less skilled category of the occupational activity (C category) in comparison with the othercorresponding groups. DISCUSSION: A previous national study found a similar proportion of the population at high/very high cardiovascular risk (19.5% versus 17.1%). Our study is representative of the adult Portuguese population and adopted the European Health Examination Survey procedures, which are essential for future comparisons with other European countries. Some of the limitations of this study include the possible participation bias and the non-calibration of the SCORE algorithm for the Portuguese population. CONCLUSION: In 2015, a considerable proportion of the Portuguese population aged between 40 and 65 years old had a high or very high risk of developing a fatal cardiovascular event in the next 10 years. Due to the possible overestimation of the cardiovascular risk already reported in other European countries, it will be important to carry out a follow-up study to validate the adequacy of using the SCORE algorithm in the Portuguese population.",
      "authors": "Gaio V\u00e2nia; Rodrigues Ana Paula; Kislaya Irina; Barreto Marta; Namorado S\u00f3nia; Dias Carlos Matias",
      "year": "2020",
      "journal": "Acta medica portuguesa",
      "doi": "10.20344/amp.13009",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32886064/",
      "mesh_terms": "Adult; Aged; Cardiovascular Diseases; Cross-Sectional Studies; Follow-Up Studies; Humans; Male; Middle Aged; Portugal; Risk Assessment; Risk Factors; Socioeconomic Factors",
      "keywords": "Cardiovascular Diseases; Portugal; Risk Assessment; Risk Factors; Socioeconomic Factors",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32609749",
      "title": "Feature sensitivity criterion-based sampling strategy from the Optimization based on Phylogram Analysis (Fs-OPA) and Cox regression applied to mental disorder datasets.",
      "abstract": "Digital datasets in several health care facilities, as hospitals and prehospital services, accumulated data from thousands of patients for more than a decade. In general, there is no local team with enough experts with the required different skills capable of analyzing them in entirety. The integration of those abilities usually demands a relatively long-period and is cost. Considering that scenario, this paper proposes a new Feature Sensitivity technique that can automatically deal with a large dataset. It uses a criterion-based sampling strategy from the Optimization based on Phylogram Analysis. Called FS-opa, the new approach seems proper for dealing with any types of raw data from health centers and manipulate their entire datasets. Besides, FS-opa can find the principal features for the construction of inference models without depending on expert knowledge of the problem domain. The selected features can be combined with usual statistical or machine learning methods to perform predictions. The new method can mine entire datasets from scratch. FS-opa was evaluated using a relatively large dataset from electronic health records of mental disorder prehospital services in Brazil. Cox's approach was integrated to FS-opa to generate survival analysis models related to the length of stay (LOS) in hospitals, assuming that it is a relevant aspect that can benefit estimates of the efficiency of hospitals and the quality of patient treatments. Since FS-opa can work with raw datasets, no knowledge from the problem domain was used to obtain the preliminary prediction models found. Results show that FS-opa succeeded in performing a feature sensitivity analysis using only the raw data available. In this way, FS-opa can find the principal features without bias of an inference model, since the proposed method does not use it. Moreover, the experiments show that FS-opa can provide models with a useful trade-off according to their representativeness and parsimony. It can benefit further analyses by experts since they can focus on aspects that benefit problem modeling.",
      "authors": "Gholi Zadeh Kharrat Fatemeh; Shydeo Brand\u00e3o Miyoshi Newton; Cobre Juliana; Mazzoncini De Azevedo-Marques Jo\u00e3o; Mazzoncini de Azevedo-Marques Paulo; Cl\u00e1udio Botazzo Delbem Alexandre",
      "year": "2020",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0235147",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32609749/",
      "mesh_terms": "Adult; Algorithms; Brazil; Data Mining; Datasets as Topic; Electronic Health Records; Humans; Mental Disorders; Proportional Hazards Models",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7329087"
    },
    {
      "pmid": "36153493",
      "title": "Evaluating sensitivity to classification uncertainty in latent subgroup effect analyses.",
      "abstract": "BACKGROUND: Increasing attention is being given to assessing treatment effect heterogeneity among individuals belonging to qualitatively different latent subgroups. Inference routinely proceeds by first partitioning the individuals into subgroups, then estimating the subgroup-specific average treatment effects. However, because the subgroups are only latently associated with the observed variables, the actual individual subgroup memberships are rarely known with certainty in practice and thus have to be imputed. Ignoring the uncertainty in the imputed memberships precludes misclassification errors, potentially leading to biased results and incorrect conclusions. METHODS: We propose a strategy for assessing the sensitivity of inference to classification uncertainty when using such classify-analyze approaches for subgroup effect analyses. We exploit each individual's typically nonzero predictive or posterior subgroup membership probabilities to gauge the stability of the resultant subgroup-specific average causal effects estimates over different, carefully selected subsets of the individuals. Because the membership probabilities are subject to sampling variability, we propose Monte Carlo confidence intervals that explicitly acknowledge the imprecision in the estimated subgroup memberships via perturbations using a parametric bootstrap. The proposal is widely applicable and avoids stringent causal or structural assumptions that existing bias-adjustment or bias-correction methods rely on. RESULTS: Using two different publicly available real-world datasets, we illustrate how the proposed strategy supplements existing latent subgroup effect analyses to shed light on the potential impact of classification uncertainty on inference. First, individuals are partitioned into latent subgroups based on their medical and health history. Then within each fixed latent subgroup, the average treatment effect is assessed using an augmented inverse propensity score weighted estimator. Finally, utilizing the proposed sensitivity analysis reveals different subgroup-specific effects that are mostly insensitive to potential misclassification. CONCLUSIONS: Our proposed sensitivity analysis is straightforward to implement, provides both graphical and numerical summaries, and readily permits assessing the sensitivity of any machine learning-based causal effect estimator to classification uncertainty. We recommend making such sensitivity analyses more routine in latent subgroup effect analyses.",
      "authors": "Loh Wen Wei; Kim Jee-Seon",
      "year": "2022",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/s12874-022-01720-8",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36153493/",
      "mesh_terms": "Bias; Causality; Humans; Monte Carlo Method; Propensity Score; Uncertainty",
      "keywords": "Causal inference; Finite mixture models; Latent class analysis; Parametric bootstrap; Perturbed confidence interval; Sensitivity analysis; Subgroup average treatment effect (ATE)",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9508766"
    },
    {
      "pmid": "22226226",
      "title": "Modeling causes of death: an integrated approach using CODEm.",
      "abstract": "BACKGROUND: Data on causes of death by age and sex are a critical input into health decision-making. Priority setting in public health should be informed not only by the current magnitude of health problems but by trends in them. However, cause of death data are often not available or are subject to substantial problems of comparability. We propose five general principles for cause of death model development, validation, and reporting. METHODS: We detail a specific implementation of these principles that is embodied in an analytical tool - the Cause of Death Ensemble model (CODEm) - which explores a large variety of possible models to estimate trends in causes of death. Possible models are identified using a covariate selection algorithm that yields many plausible combinations of covariates, which are then run through four model classes. The model classes include mixed effects linear models and spatial-temporal Gaussian Process Regression models for cause fractions and death rates. All models for each cause of death are then assessed using out-of-sample predictive validity and combined into an ensemble with optimal out-of-sample predictive performance. RESULTS: Ensemble models for cause of death estimation outperform any single component model in tests of root mean square error, frequency of predicting correct temporal trends, and achieving 95% coverage of the prediction interval. We present detailed results for CODEm applied to maternal mortality and summary results for several other causes of death, including cardiovascular disease and several cancers. CONCLUSIONS: CODEm produces better estimates of cause of death trends than previous methods and is less susceptible to bias in model specification. We demonstrate the utility of CODEm for the estimation of several major causes of death.",
      "authors": "Foreman Kyle J; Lozano Rafael; Lopez Alan D; Murray Christopher Jl",
      "year": "2012",
      "journal": "Population health metrics",
      "doi": "10.1186/1478-7954-10-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/22226226/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC3315398"
    },
    {
      "pmid": "36897886",
      "title": "Extracting patient-level data from the electronic health record: Expanding opportunities for health system research.",
      "abstract": "BACKGROUND: Epidemiological studies of interstitial lung disease (ILD) are limited by small numbers and tertiary care bias. Investigators have leveraged the widespread use of electronic health records (EHRs) to overcome these limitations, but struggle to extract patient-level, longitudinal clinical data needed to address many important research questions. We hypothesized that we could automate longitudinal ILD cohort development using the EHR of a large, community-based healthcare system. STUDY DESIGN AND METHODS: We applied a previously validated algorithm to the EHR of a community-based healthcare system to identify ILD cases between 2012-2020. We then extracted disease-specific characteristics and outcomes using fully automated data-extraction algorithms and natural language processing of selected free-text. RESULTS: We identified a community cohort of 5,399 ILD patients (prevalence = 118 per 100,000). Pulmonary function tests (71%) and serologies (54%) were commonly used in the diagnostic evaluation, whereas lung biopsy was rare (5%). IPF was the most common ILD diagnosis (n = 972, 18%). Prednisone was the most commonly prescribed medication (911, 17%). Nintedanib and pirfenidone were rarely prescribed (n = 305, 5%). ILD patients were high-utilizers of inpatient (40%/year hospitalized) and outpatient care (80%/year with pulmonary visit), with sustained utilization throughout the post-diagnosis study period. DISCUSSION: We demonstrated the feasibility of robustly characterizing a variety of patient-level utilization and health services outcomes in a community-based EHR cohort. This represents a substantial methodological improvement by alleviating traditional constraints on the accuracy and clinical resolution of such ILD cohorts; we believe this approach will make community-based ILD research more efficient, effective, and scalable.",
      "authors": "Farrand Erica; Collard Harold R; Guarnieri Michael; Minowada George; Block Lawrence; Lee Mei; Iribarren Carlos",
      "year": "2023",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0280342",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36897886/",
      "mesh_terms": "Humans; Electronic Health Records; Lung Diseases, Interstitial; Lung; Algorithms",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10004557"
    },
    {
      "pmid": "33313765",
      "title": "Incorporating Exposure Measurement Data from Similar Exposure Scenarios to Inform Exposure Modeling Estimates: A Demonstration Using Cluster Analysis and Bayesian Modeling.",
      "abstract": "Addressing occupational health and safety concerns early in the design stage anticipates hazards and enables health professionals to recommend control measures that can best protect workers' health. This method is a well-established tool in public health. Importantly, its success depends on a comprehensive exposure assessment that incorporates previous exposure data and outcomes. Traditional methods for characterizing similar occupational exposure scenarios rely on expert judgment or qualitative descriptions of relevant exposure data, which often include undisclosed underlying assumptions about specific exposure conditions. Thus, improved methods for predicting exposure modeling estimates based on available data are needed. This study proposes that cluster analysis can be used to quantify the relevance of existing exposure scenarios that are similar to a new scenario. We demonstrate how this method improves exposure predictions. Exposure data and contextual information of the scenarios were collected from past exposure assessment reports. Prior distributions for the exposure distribution parameters were specified using Stoffenmanager\u00ae 8 predictions. Gower distance and k-Medoids clustering algorithm analyses grouped existing scenarios into clusters based on similarity. The information was used in a Bayesian model to specify the degree of correlation between similar scenarios and the scenarios to be assessed. Using the distance metric to characterize the degree of similarity, the performance of the Bayesian model was improved in terms of the average bias of model estimates and measured data, reducing from 0.77 (SD: 2.0) to 0.49 (SD: 1.8). Nevertheless, underestimation of exposures still occurred for some rare scenarios, which tended to be those with highly variable exposure data. In conclusion, the cluster analysis approach may enable transparent selection of similar exposure scenarios for factoring into design-phase assessments and thereby improve exposure modeling estimates.",
      "authors": "Huang Shao-Zu; Chuang Yu-Chuan; Hung Po-Chen; Chen Chih-Yong; Chiang Su-Yin; Wu Kuen-Yuh",
      "year": "2021",
      "journal": "Annals of work exposures and health",
      "doi": "10.1093/annweh/wxaa088",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33313765/",
      "mesh_terms": "Bayes Theorem; Cluster Analysis; Environmental Monitoring; Humans; Occupational Exposure; Risk Assessment",
      "keywords": "k-Medoids clustering; Bayesian modeling; Gower distance; cluster analysis; model calibration; worker exposure scenarios",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "29304138",
      "title": "The use of automated Ki67 analysis to predict Oncotype DX risk-of-recurrence categories in early-stage breast cancer.",
      "abstract": "Ki67 is a commonly used marker of cancer cell proliferation, and has significant prognostic value in breast cancer. In spite of its clinical importance, assessment of Ki67 remains a challenge, as current manual scoring methods have high inter- and intra-user variability. A major reason for this variability is selection bias, in that different observers will score different regions of the same tumor. Here, we developed an automated Ki67 scoring method that eliminates selection bias, by using whole-slide analysis to identify and score the tumor regions with the highest proliferative rates. The Ki67 indices calculated using this method were highly concordant with manual scoring by a pathologist (Pearson's r = 0.909) and between users (Pearson's r = 0.984). We assessed the clinical validity of this method by scoring Ki67 from 328 whole-slide sections of resected early-stage, hormone receptor-positive, human epidermal growth factor receptor 2-negative breast cancer. All patients had Oncotype DX testing performed (Genomic Health) and available Recurrence Scores. High Ki67 indices correlated significantly with several clinico-pathological correlates, including higher tumor grade (1 versus 3, P<0.001), higher mitotic score (1 versus 3, P<0.001), and lower Allred scores for estrogen and progesterone receptors (P = 0.002, 0.008). High Ki67 indices were also significantly correlated with higher Oncotype DX risk-of-recurrence group (low versus high, P<0.001). Ki67 index was the major contributor to a machine learning model which, when trained solely on clinico-pathological data and Ki67 scores, identified Oncotype DX high- and low-risk patients with 97% accuracy, 98% sensitivity and 80% specificity. Automated scoring of Ki67 can thus successfully address issues of consistency, reproducibility and accuracy, in a manner that integrates readily into the workflow of a pathology laboratory. Furthermore, automated Ki67 scores contribute significantly to models that predict risk of recurrence in breast cancer.",
      "authors": "Thakur Satbir Singh; Li Haocheng; Chan Angela M Y; Tudor Roxana; Bigras Gilbert; Morris Don; Enwere Emeka K; Yang Hua",
      "year": "2018",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0188983",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29304138/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Automation, Laboratory; Breast Neoplasms; Cell Proliferation; Cohort Studies; Female; Humans; Image Processing, Computer-Assisted; Immunohistochemistry; Ki-67 Antigen; Machine Learning; Middle Aged; Neoplasm Recurrence, Local; Prognosis; Erb-b2 Receptor Tyrosine Kinases; Receptors, Estrogen; Receptors, Progesterone; Reproducibility of Results; Retrospective Studies; Risk Factors; Selection Bias",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC5755729"
    },
    {
      "pmid": "15908858",
      "title": "Utility scores for the Health Utilities Index Mark 2: an empirical assessment of alternative mapping functions.",
      "abstract": "INTRODUCTION: The Health Utilities Index is one of the most widely used generic health status classification systems. The valuation algorithm rests upon a power transformation between visual analog scale (VAS) and standard gamble (SG) data. This transformation has been the subject of much debate. To date, the literature has concentrated upon the mapping functions themselves. We examine whether alternative mapping functions produce more accurate utility predictions. METHODS: We undertook valuation interviews with 201 members of the UK general population, following the methods of the original Health Utilities Index-2 valuation survey. We estimated a cubic and a power mapping function using the mean VAS and SG data from the survey and calculated 2 alternative Multiplicative Multi Attribute Utility Functions (MAUFs). Using a validation sample, we assessed the predictive precision of the models in terms of accuracy (root mean square error and mean absolute error); clinical importance of the prediction error (% states with prediction error greater than 0.03); bias (t test); and whether the prediction error was related to the health state severity (Ljung Box Q statistic). RESULTS: The power MAUF was an extremely poor predictive model, mean absolute error = 0.18, root mean square error = 0.206. The predictions were biased (t = -12.92). The errors were not related to the severity of the health state, (Liung Box = 10.87). The Cubic MAUF was a better predictive model than the Power MAUF (mean absolute error = 0.084, root mean square error = 0.101). The Cubic MAUF also produced biased predictions (t = -3.57). The prediction errors were not related to the severity of the health state (Liung Box = 5.242). DISCUSSION: The Power MAUF is considerably worse than the Cubic MAUF. Our results suggest that the problems with the power function can translate into significant problems with predictive performance of the MAUF.",
      "authors": "McCabe Christopher J; Stevens Katherine J; Brazier John E",
      "year": "2005",
      "journal": "Medical care",
      "doi": "10.1097/01.mlr.0000163666.00471.8e",
      "url": "https://pubmed.ncbi.nlm.nih.gov/15908858/",
      "mesh_terms": "Activities of Daily Living; Attitude to Health; Data Interpretation, Statistical; Health Status Indicators; Humans; Interviews as Topic; Linear Models; Models, Statistical; Pain Measurement; Socioeconomic Factors; Surveys and Questionnaires; United Kingdom",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Validation Study",
      "pmcid": ""
    },
    {
      "pmid": "41385782",
      "title": "Stakeholder Criteria for Trust in Artificial Intelligence-Based Computer Perception Tools in Health Care: Qualitative Interview Study.",
      "abstract": "BACKGROUND: Computer perception (CP) technologies hold significant promise for advancing precision mental health care systems, given their ability to leverage algorithmic analysis of continuous, passive sensing data from wearables and smartphones (eg, behavioral activity, geolocation, vocal features, and ambient environmental data) to infer clinically meaningful behavioral and physiological states. However, successful implementation critically depends on cultivating well-founded stakeholder trust. OBJECTIVE: This study aims to investigate, across adolescents, caregivers, clinicians, and developers, the contingencies under which CP technologies are deemed trustworthy in health care. METHODS: We conducted 80 semistructured interviews with a purposive sample of adolescents (n=20) diagnosed with autism, Tourette syndrome, anxiety, obsessive-compulsive disorder, or attention-deficit/hyperactivity disorder and their caregivers (n=20); practicing clinicians across psychiatry, psychology, and pediatrics (n=20); and CP system developers (n=20). Interview transcripts were coded by 2 independent coders and analyzed using multistage, inductive thematic content analysis to identify prominent themes. RESULTS: Across stakeholder groups, 5 core criteria emerged as prerequisites for trust in CP outputs: (1) epistemic alignment-consistency between system outputs, personal experience, and existing diagnostic frameworks; (2) demonstrable rigor-training on representative data and validation in real-world contexts; (3) explainability-transparent communication of input variables, thresholds, and decision logic; (4) sensitivity to complexity-the capacity to accommodate heterogeneity and comorbidity in symptom expression; and (5) a nonsubstitutive role-technologies must augment, rather than supplant, clinical judgment. A novel and cautionary finding was that epistemic alignment-whether outputs affirmed participants' preexisting beliefs, diagnostic expectations, or internal states-was a dominant factor in determining whether the tool was perceived as trustworthy. Participants also expressed relational trust, placing confidence in CP systems based on endorsements from respected peers, academic institutions, or regulatory agencies. However, both trust strategies raise significant concerns: confirmation bias may lead users to overvalue outputs that align with their assumptions, while surrogate trust may be misapplied in the absence of robust performance validation. CONCLUSIONS: This study advances empirical understanding of how trust is formed and calibrated around artificial intelligence-based CP technologies. While trust is commonly framed as a function of technical performance, our findings show that it is deeply shaped by cognitive heuristics, social relationships, and alignment with entrenched epistemologies. These dynamics can facilitate intuitive verification but may also constrain the transformative potential of CP systems by reinforcing existing beliefs. To address this, we recommend a dual strategy: (1) embedding CP tools within institutional frameworks that uphold rigorous validation, ethical oversight, and transparent design; and (2) providing clinicians with training and interface designs that support critical appraisal and minimize susceptibility to cognitive bias. Recalibrating trust to reflect actual system capacities-rather than familiarity or endorsement-is essential for ethically sound and clinically meaningful integration of CP technologies.",
      "authors": "Rai Ansh; Hurley Meghan E; Herrington John; Storch Eric A; Zampella Casey J; Parrish-Morris Julia; Sonig Anika; L\u00e1zaro-Mu\u00f1oz Gabriel; Kostick-Quenet Kristin",
      "year": "2025",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/78757",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41385782/",
      "mesh_terms": "Humans; Artificial Intelligence; Trust; Adolescent; Female; Male; Interviews as Topic; Qualitative Research; Delivery of Health Care; Adult",
      "keywords": "artificial intelligence; computing; machine learning; psychiatry; technology; trust; trustworthiness",
      "pub_types": "Journal Article",
      "pmcid": "PMC12743233"
    },
    {
      "pmid": "41336504",
      "title": "Contactless heart rate and heart rate variability estimation from neck videos.",
      "abstract": "Video-based pulse extraction is a non-contact technique for estimating physiological signals from video recordings. While traditional approaches focus on facial regions due to their high vascularity and accessibility, this study explored the feasibility of extracting pulse signals from neck region, an area less studied in the literature. Nech and chest video data were collected from 14 healthy subjects during breath-hold. A region of interest on the neck was tracked using a template-based algorithm, and pixel intensity variations within this region were processed using six established video-based pulse extraction methods: GREEN, the chrominance-based method, plant-orthogonal-to-skin method, orthogonal matrix image transformation method, independent component analysis method, and local group invariance method. The extracted pulse signals were validated against synchronized electrocardiogram (ECG) recordings. Among the methods, GREEN exhibited the highest agreement with ECG-derived heart rate (HR), with a bias of -4.89 bpm and limits of agreement (LoA) ranging from 29.97 to 20.17 bpm. After excluding two subjects with significant noise interference, the agreement improved to a bias of -1.42 bpm and LoA of -4.95 to 2.09 bpm. HR variability (HRV) was assessed using SDNN. SDNN values from GREEN method were generally higher than those from ECG, likely due to signal differences, motion artifacts, and the short duration (1015 seconds) of the recordings, which may have inflated variability estimates. Findings suggested that the neck region, particularly when using the GREEN method, is a viable site for video-based pulse signal extraction and HR estimation. However, variations in SDNN underscore the need for further refinement in video-based pulse extraction techniques. Expanding this technology to the neck region offers promising applications in remote health monitoring and physiological assessment, particularly to mitigate the privacy concerns of facial recordings.",
      "authors": "Rahman Mohammad Muntasir; Taebi Amirtaha",
      "year": "2025",
      "journal": "Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference",
      "doi": "10.1109/EMBC58623.2025.11251812",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41336504/",
      "mesh_terms": "Humans; Heart Rate; Neck; Video Recording; Electrocardiography; Algorithms; Male; Adult; Female; Signal Processing, Computer-Assisted",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "24726925",
      "title": "RReACT goes global: perils and pitfalls of constructing a global open-access database of registered analgesic clinical trials and trial results.",
      "abstract": "Eliminating publication bias requires ensuring public awareness of studies and access to results. Clinical trial registries provide basic trial information, but access to unbiased trial results is inadequate. Nearly all studies of trial registration and results reporting have been limited to the ClinicalTrials.gov registry. We analyzed trial registration, registry functionality, cross-registry harmonization, and results reporting on all 15 primary registries in the World Health Organization International Clinical Trials Registry Platform (ICTRP) for postherpetic neuralgia, painful diabetic neuropathy, and fibromyalgia. A total of 447 unique trials were identified, with 86 trials listed on more than one registry. A comprehensive search algorithm was used to find trial results in the peer-reviewed literature and the grey literature. Creating a global database of registered trials and trial results proved surprisingly difficult for several reasons: (1) ICTRP does not reliably identify trials listed on multiple registries, manual searches are necessary; (2) Searching ICTRP yields different results than searching individual registries; (3) Outcome measure descriptions for multiply registered trials vary between registries; (4) Registry-publication pairings are often inaccurate or incomplete; (5) Grey literature results are not permanent. Overall, only 46% of all trials had results available. Trials registered on ClinicalTrials.gov were significantly more likely to have results (52% vs. 18%, P<0.001), partly due to the ability to post results directly to the registry. In addition to the simple remedy of including trial registration numbers on all meeting abstracts and peer-reviewed papers, specific strategies are offered to facilitate identifying multiply registered studies and ensuring accurate pairing of results and publications.",
      "authors": "Munch Troels; Dufka Faustine L; Greene Kaitlin; Smith Shannon M; Dworkin Robert H; Rowbotham Michael C",
      "year": "2014",
      "journal": "Pain",
      "doi": "10.1016/j.pain.2014.04.007",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24726925/",
      "mesh_terms": "Access to Information; Algorithms; Clinical Trials as Topic; Databases, Factual; Diabetic Neuropathies; Fibromyalgia; Humans; Neuralgia, Postherpetic; Publication Bias; Registries",
      "keywords": "Clinical trial registries; Clinical trials; Databases; Open-access; Publication bias; Transparency in research",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "41464861",
      "title": "Automated Classification of Enamel Caries from Intraoral Images Using Deep Learning Models: A Diagnostic Study.",
      "abstract": "Background: Dental caries is a prevalent global oral health issue. The early detection of enamel caries, the initial stage of decay, is critical to preventive dentistry but is often limited by the subjectivity and variability of conventional diagnostic methods. Objective: This study aims to develop and evaluate two explainable deep learning models for the automated classification of enamel caries from intraoral images. Dataset and Methodology: A publicly available dataset of 2000 intraoral images showing early-stage enamel caries, advanced enamel caries, no-caries was used. The dataset was split into training, validation, and test sets in a 70:15:15 ratio, and data preprocessing and augmentation were applied to the training set to balance the dataset and prevent model overfitting. Two models were developed, ExplainableDentalNet, a custom lightweight CNN, and Interpretable ResNet50-SE, a fine-tuned ResNet50 model with Squeeze-and-Excitation blocks, and both were integrated with Gradient-Weighted Class Activation Mapping (Grad-CAM) for visual interpretability. Results: As evaluated on the test set, ExplainableDentalNet achieved an overall accuracy of 96.66% and a Matthews Correlation Coefficient [MCC] = 0.95, while Interpretable ResNet50-SE achieved 98.30% accuracy (MCC = 0.975). McNemar's test indicated no significant prediction bias, with p > 0.05, and internal bootstrap and cross-validation analyses indicated stable performance. Conclusions: The proposed explainable models demonstrated high diagnostic accuracy in enamel caries classification on the studied dataset. While the present findings are promising, future clinical applications will require external validation on multi-center datasets.",
      "authors": "Asiri Faris Yahya I",
      "year": "2025",
      "journal": "Journal of clinical medicine",
      "doi": "10.3390/jcm14248959",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41464861/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; dental caries; dental public health; diagnostic imaging; machine learning; preventive dentistry",
      "pub_types": "Journal Article",
      "pmcid": "PMC12734310"
    },
    {
      "pmid": "35627495",
      "title": "A Deep Learning Approach to Estimate the Incidence of Infectious Disease Cases for Routinely Collected Ambulatory Records: The Example of Varicella-Zoster.",
      "abstract": "The burden of infectious diseases is crucial for both epidemiological surveillance and prompt public health response. A variety of data, including textual sources, can be fruitfully exploited. Dealing with unstructured data necessitates the use of methods for automatic data-driven variable construction and machine learning techniques (MLT) show promising results. In this framework, varicella-zoster virus (VZV) infection was chosen to perform an automatic case identification with MLT. Pedianet, an Italian pediatric primary care database, was used to train a series of models to identify whether a child was diagnosed with VZV infection between 2004 and 2014 in the Veneto region, starting from free text fields. Given the nature of the task, a recurrent neural network (RNN) with bidirectional gated recurrent units (GRUs) was chosen; the same models were then used to predict the children's status for the following years. A gold standard produced by manual extraction for the same interval was available for comparison. RNN-GRU improved its performance over time, reaching the maximum value of area under the ROC curve (AUC-ROC) of 95.30% at the end of the period. The absolute bias in estimates of VZV infection was below 1.5% in the last five years analyzed. The findings in this study could assist the large-scale use of EHRs for clinical outcome predictive modeling and help establish high-performance systems in other medical domains.",
      "authors": "Lanera Corrado; Baldi Ileana; Francavilla Andrea; Barbieri Elisa; Tramontan Lara; Scamarcia Antonio; Cantarutti Luigi; Giaquinto Carlo; Gregori Dario",
      "year": "2022",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph19105959",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35627495/",
      "mesh_terms": "Chickenpox; Child; Communicable Diseases; Deep Learning; Herpes Zoster; Humans; Incidence",
      "keywords": "deep learning; electronic health records; infectious disease; natural language processing; varicella-zoster",
      "pub_types": "Journal Article",
      "pmcid": "PMC9141951"
    },
    {
      "pmid": "31787799",
      "title": "Single Season Changes in Resting State Network Power and the Connectivity between Regions: Distinguish Head Impact Exposure Level in High School and Youth Football Players.",
      "abstract": "The effect of repetitive sub-concussive head impact exposure in contact sports like American football on brain health is poorly understood, especially in the understudied populations of youth and high school players. These players, aged 9-18 years old may be particularly susceptible to impact exposure as their brains are undergoing rapid maturation. This study helps fill the void by quantifying the association between head impact exposure and functional connectivity, an important aspect of brain health measurable via resting-state fMRI (rs-fMRI). The contributions of this paper are three fold. First, the data from two separate studies (youth and high school) are combined to form a high-powered analysis with 60 players. These players experience head acceleration within overlapping impact exposure making their combination particularly appropriate. Second, multiple features are extracted from rs-fMRI and tested for their association with impact exposure. One type of feature is the power spectral density decomposition of intrinsic, spatially distributed networks extracted via independent components analysis (ICA). Another feature type is the functional connectivity between brain regions known often associated with mild traumatic brain injury (mTBI). Third, multiple supervised machine learning algorithms are evaluated for their stability and predictive accuracy in a low bias, nested cross-validation modeling framework. Each classifier predicts whether a player sustained low or high levels of head impact exposure. The nested cross validation reveals similarly high classification performance across the feature types, and the Support Vector, Extremely randomized trees, and Gradboost classifiers achieve F1-score up to 75%.",
      "authors": "Murugesan Gowtham; Saghafi Behrouz; Davenport Elizabeth; Wagner Ben; Urban Jillian; Kelley Mireille; Jones Derek; Powers Alex; Whitlow Christopher; Stitzel Joel; Maldjian Joseph; Montillo Albert",
      "year": "2018",
      "journal": "Proceedings of SPIE--the International Society for Optical Engineering",
      "doi": "10.1117/12.2293199",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31787799/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC6884358"
    },
    {
      "pmid": "41404849",
      "title": "Enhancing Patient Empowerment Through Artificial Intelligence in Liver Cancer.",
      "abstract": "Chronic liver disease and liver cancer such as hepatocellular carcinoma have a growing global health burden. In many areas, liver disease and cancer have a rising incidence, later diagnosis, and higher mortality. Although guidelines recommend regular surveillance, the timely detection of liver disease and hepatocellular carcinoma remains inconsistent. This is largely due to low awareness, restricted access to care, and fragmented healthcare systems. It is well known that patient empowerment through knowledge, engagement, and shared decision-making could therefore help to improve outcomes. However, this is frequently complicated by stigma, low health literacy, and comorbidities. These challenges could be improved by artificial intelligence (AI). AI methods can analyze healthcare data and could directly affect screening and risk stratification. In addition, the emergence of large language models such as ChatGPT provides new tools that can support the patient journey. Here, we provide a systematic overview of the capabilities of AI methods to potentially improve liver cancer care. We highlight that AI tools in liver cancer care could be used in 2 ways: They can help healthcare professionals and patients alike. Help healthcare professionals-focused AI tools can constitute clinical decision-support systems and improve care continuity through telemedicine and remote monitoring. Patient-focused AI applications can have the potential to empower patients, by providing personalized education, counseling, and improved patient engagement. However, we also point out the need for caution in the implementation of this technology. Key concerns are related to ethical considerations, regulation, data privacy, transparency, algorithmic bias, rigorous clinical validation, and patient preferences and needs. When these concerns are resolved, AI could help to deliver more personalized, participatory, and equitable liver disease care.",
      "authors": "Lee Dee; Maravic Zorana; Moon Andrew M; Langenbacher Diane; Kautz Achim; Peck Raquel; Allaire Manon; Kather Jakob Nikolas",
      "year": "2025",
      "journal": "The American journal of gastroenterology",
      "doi": "10.14309/ajg.0000000000003872",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41404849/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; chronic liver disease; liver cancer; machine learning",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32940710",
      "title": "Trialstreamer: A living, automatically updated database of clinical trial reports.",
      "abstract": "OBJECTIVE: Randomized controlled trials (RCTs) are the gold standard method for evaluating whether a treatment works in health care but can be difficult to find and make use of. We describe the development and evaluation of a system to automatically find and categorize all new RCT reports. MATERIALS AND METHODS: Trialstreamer continuously monitors PubMed and the World Health Organization International Clinical Trials Registry Platform, looking for new RCTs in humans using a validated classifier. We combine machine learning and rule-based methods to extract information from the RCT abstracts, including free-text descriptions of trial PICO (populations, interventions/comparators, and outcomes) elements and map these snippets to normalized MeSH (Medical Subject Headings) vocabulary terms. We additionally identify sample sizes, predict the risk of bias, and extract text conveying key findings. We store all extracted data in a database, which we make freely available for download, and via a search portal, which allows users to enter structured clinical queries. Results are ranked automatically to prioritize larger and higher-quality studies. RESULTS: As of early June 2020, we have indexed 673\u00a0191 publications of RCTs, of which 22\u00a0363 were published in the first 5 months of 2020 (142 per day). We additionally include 304\u00a0111 trial registrations from the International Clinical Trials Registry Platform. The median trial sample size was 66. CONCLUSIONS: We present an automated system for finding and categorizing RCTs. This yields a novel resource: a database of structured information automatically extracted for all published RCTs in humans. We make daily updates of this database available on our website (https://trialstreamer.robotreviewer.net).",
      "authors": "Marshall Iain J; Nye Benjamin; Kuiper Jo\u00ebl; Noel-Storr Anna; Marshall Rachel; Maclean Rory; Soboczenski Frank; Nenkova Ani; Thomas James; Wallace Byron C",
      "year": "2020",
      "journal": "Journal of the American Medical Informatics Association : JAMIA",
      "doi": "10.1093/jamia/ocaa163",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32940710/",
      "mesh_terms": "Bias; Data Curation; Data Management; Databases, Factual; Evidence-Based Medicine; Humans; Medical Subject Headings; Randomized Controlled Trials as Topic",
      "keywords": "automatic database curation; evidence based medicine; randomized controlled trials; research synthesis",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7727361"
    },
    {
      "pmid": "38379573",
      "title": "Impact of Potential Case Misclassification by Administrative Diagnostic Codes on Outcome Assessment of Observational Study for People Who Inject Drugs.",
      "abstract": "INTRODUCTION: Initiation of medications for opioid use disorder (MOUD) within the hospital setting may improve outcomes for people who inject drugs (PWID) hospitalized because of an infection. Many studies used International Classification of Diseases (ICD) codes to identify PWID, although these may be misclassified and thus, inaccurate. We hypothesized that bias from misclassification of PWID using ICD codes may impact analyses of MOUD outcomes. METHODS: We analyzed a cohort of 36 868 cases of patients diagnosed with Staphylococcus aureus bacteremia at 124 US Veterans Health Administration hospitals between 2003 and 2014. To identify PWID, we implemented an ICD code-based algorithm and a natural language processing (NLP) algorithm for classification of admission notes. We analyzed outcomes of prescribing MOUD as an inpatient using both approaches. Our primary outcome was 365-day all-cause mortality. We fit mixed-effects Cox regression models with receipt or not of MOUD during the index hospitalization as the primary predictor and 365-day mortality as the outcome. RESULTS: NLP identified 2389 cases as PWID, whereas ICD codes identified 6804 cases as PWID. In the cohort identified by NLP, receipt of inpatient MOUD was associated with a protective effect on 365-day survival (adjusted hazard ratio, 0.48; 95% confidence interval, .29-.81; P < .01) compared with those not receiving MOUD. There was no significant effect of MOUD receipt in the cohort identified by ICD codes (adjusted hazard ratio, 1.00; 95% confidence interval, .77-1.30; P = .99). CONCLUSIONS: MOUD was protective of all-cause mortality when NLP was used to identify PWID, but not significant when ICD codes were used to identify the analytic subjects.",
      "authors": "Goodman-Meza David; Goto Michihiko; Salimian Anabel; Shoptaw Steven; Bui Alex A T; Gordon Adam J; Goetz Matthew B",
      "year": "2024",
      "journal": "Open forum infectious diseases",
      "doi": "10.1093/ofid/ofae030",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38379573/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10878055"
    },
    {
      "pmid": "37435749",
      "title": "A smartphone-integrated low-cost, reagent-free, non-destructive dried blood spot-based paper sensor for hematocrit measurement.",
      "abstract": "The blood hematocrit (Hct) level provides vital information about a person's health. Traditional Hct measurement equipment relies heavily on infrastructure and skilled manpower, limiting its broad implementation in resource-limited contexts. Therefore, we developed a simple, reagent-free, non-destructive, smartphone-integrated paper-based device for Hct measurement by analyzing blood-spreading area on a paper substrate. Blood spreading area was found to be dependent on the Hct value, paper properties, and assay duration. This device was calibrated using a custom-made Python algorithm with 10 \u03bcl of blood, which produced a sensitivity of -1.90 \u00b1 0.03 mm2/Hct (%) with a LOD as low as 2.17% Hct. The device linear range (8.8 to 58% Hct) is wide enough to cover the clinically relevant range of blood Hct (%). Furthermore, this Python algorithm was coupled with a user-friendly and clinically beneficial Android application (app) to establish an automated tool for quantitative estimation. Comparing the app performance with the result obtained from the gold standard hematology analyzer using blood from 87 subjects reveals a strong correlation (r = 0.99), an average bias of 0.15 with limits of agreement of -2.5 to 2.79 at 95% CI. The device exhibits an accuracy of 96.85% and acceptable reproducibility, with CV ranging from 0.8 to 7.5%. An integrated detection cum readout guiding pattern may allow this device to be suitable for simultaneous quantitative and qualitative estimation and to be employed in both developed and resource-limited clinical settings for Hct measurement in routine checkups and regular monitoring during critical care, as well as in the initial screening of large anemic populations.",
      "authors": "Sinha Smriti; Basu Akashlina; Shukla Jai; Dasgupta Shirin; Dutta Gorachand; Das Soumen",
      "year": "2023",
      "journal": "Analytical methods : advancing methods and applications",
      "doi": "10.1039/d3ay00688c",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37435749/",
      "mesh_terms": "Humans; Dried Blood Spot Testing; Hematocrit; Reproducibility of Results; Smartphone; Algorithms",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40682491",
      "title": "Investigating the Consequences of Measurement Error of Gradually More Sophisticated Long-Term Personal Exposure Models in Assessing Health Effects: The London Study (MELONS).",
      "abstract": "INTRODUCTION: Cohort studies have been widely used to estimate the effects of long-term exposure to air pollutants on health outcomes. The nature of the exposure (i.e., personal exposure to outdoor-generated pollution) and the large number of participants in cohorts preclude measuring individual exposure longitudinally. Thus, surrogate measures, such as exposure models, are increasingly used in epidemiological studies to estimate individualized long-term exposures. We evaluated whether increasingly detailed estimates of long-term individual exposure in large-scale studies yield better estimates of the health effects of exposure to outdoor air pollution. We utilized several personal exposure measurement campaigns, which were implemented before the start of MELONS, the uniquely dense monitoring network and surrogate measures previously developed for London. METHODS: Data from 344 participants in four personal measurement campaigns, two measuring particulate matter \u22642.5 \u03bcm in aerodynamic diameter (PM2.5), nitrogen dioxide (NO2), and ozone (O3), and two measuring black carbon, covering 12,901 person days during 2015-2019, were used. The total personal exposure measurements were separated into exposures from outdoor and indoor sources by estimating appropriate infiltration factors and behaviors. The exposures were extrapolated from the measurement period per subject (from a few days to >9 months) to annual exposures, taking ambient concentration, infiltration, and behavior variability into account. These annual exposures were defined as true exposures, although it is acknowledged that several assumptions involved in their estimation introduce uncertainty. Surrogate measures of exposure were assigned based on the nearest fixed-site monitor to the residence or the prediction from combined dispersion, machine learning, and land use regression models at the participants' residence. The models were adjusted for age-group and area-specific time-activity patterns based on a large survey. Measurement errors (MEs) were calculated between \"true\" and surrogate exposures and used as input in a simulation study to investigate the resulting bias in health effect estimates, using total mortality as a health outcome. We estimated the amount of classical and Berkson error in the ME. In addition, we tested, in several theoretical error scenarios, the effectiveness of two correction methods: simulation extrapolation (SIMEX) and regression calibration (RCAL). Finally, we applied the different surrogate exposure methods using data from the UK Biobank London cohort (~62,000 subjects) to assess associations with several mortality and morbidity outcomes in Cox regression models adjusted for multiple covariates and applied correction methods. RESULTS: Exposure to outdoor-generated pollution accounted for at least 50% of total personal exposure, even in subjects spending almost all of their time indoors. We found large MEs, possibly due not only to the nature and uncertainty of using surrogate measures but also to several uncertainties incorporated in the \"true\" exposure assessment. The resulting bias in health effect estimates from ME was large and almost always toward the null (i.e., the health effects are underestimated, sometimes by as much as 100%). Larger total ME and larger proportion of classical ME led to more underestimation of effects. SIMEX and RCAL were effective methods for bias correction. Furthermore, the different scale (magnitude) of measurement of surrogate exposure estimates of ambient concentrations introduced additional systematic ME, which was addressed by expressing the effects per interquartile range and not per fixed increment of the pollutant. The application to the UK Biobank cohort data showed hazard ratios above 1 for a few outcomes and surrogate exposures, which were corrected, leading to larger estimated effects. CONCLUSIONS: Our results underline the importance of exposure to ambient air pollution ME in estimating health effects and the difficulty in obtaining an accurate estimate of the \"true\" personal exposure to outdoor-generated pollutants. The common use of surrogate measures of exposure introduces ME, which can be substantial and largely classical, leading to a large underestimation of effects on health. Researchers should consider correcting for ME when reporting results from epidemiological studies on the effects of long-term air pollution exposures and plan ahead by designing appropriate validation studies.",
      "authors": "Katsouyanni K; Evangelopoulos D; Wood D; Barratt B; Zhang H; Walton H; de Nazelle A; Evangelou V; Beevers S; Butland B; Samoli E; Schwartz J",
      "year": "2025",
      "journal": "Research report (Health Effects Institute)",
      "doi": "10.1021/es301948k",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40682491/",
      "mesh_terms": "Humans; London; Environmental Exposure; Air Pollutants; Particulate Matter; Air Pollution; Male; Female; Environmental Monitoring; Ozone; Nitrogen Dioxide; Middle Aged; Adult; Aged; Soot",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12275175"
    },
    {
      "pmid": "33886492",
      "title": "Tweet Topics and Sentiments Relating to COVID-19 Vaccination Among Australian Twitter Users: Machine Learning Analysis.",
      "abstract": "BACKGROUND: COVID-19 is one of the greatest threats to human beings in terms of health care, economy, and society in recent history. Up to this moment, there have been no signs of remission, and there is no proven effective cure. Vaccination is the primary biomedical preventive measure against the novel coronavirus. However, public bias or sentiments, as reflected on social media, may have a significant impact on the progression toward achieving herd immunity. OBJECTIVE: This study aimed to use machine learning methods to extract topics and sentiments relating to COVID-19 vaccination on Twitter. METHODS: We collected 31,100 English tweets containing COVID-19 vaccine-related keywords between January and October 2020 from Australian Twitter users. Specifically, we analyzed tweets by visualizing high-frequency word clouds and correlations between word tokens. We built a latent Dirichlet allocation (LDA) topic model to identify commonly discussed topics in a large sample of tweets. We also performed sentiment analysis to understand the overall sentiments and emotions related to COVID-19 vaccination in Australia. RESULTS: Our analysis identified 3 LDA topics: (1) attitudes toward COVID-19 and its vaccination, (2) advocating infection control measures against COVID-19, and (3) misconceptions and complaints about COVID-19 control. Nearly two-thirds of the sentiments of all tweets expressed a positive public opinion about the COVID-19 vaccine; around one-third were negative. Among the 8 basic emotions, trust and anticipation were the two prominent positive emotions observed in the tweets, while fear was the top negative emotion. CONCLUSIONS: Our findings indicate that some Twitter users in Australia supported infection control measures against COVID-19 and refuted misinformation. However, those who underestimated the risks and severity of COVID-19 may have rationalized their position on COVID-19 vaccination with conspiracy theories. We also noticed that the level of positive sentiment among the public may not be sufficient to increase vaccination coverage to a level high enough to achieve vaccination-induced herd immunity. Governments should explore public opinion and sentiments toward COVID-19 and COVID-19 vaccination, and implement an effective vaccination promotion scheme in addition to supporting the development and clinical administration of COVID-19 vaccines.",
      "authors": "Kwok Stephen Wai Hang; Vadde Sai Kumar; Wang Guanjin",
      "year": "2021",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/26953",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33886492/",
      "mesh_terms": "Australia; COVID-19; COVID-19 Vaccines; Humans; Machine Learning; Public Opinion; SARS-CoV-2; Social Media; Vaccination",
      "keywords": "COVID-19; Twitter; infodemic; infodemiology; infoveillance; latent Dirichlet allocation; machine learning; natural language processing; public sentiments; public topics; social listening; social media; vaccination",
      "pub_types": "Journal Article",
      "pmcid": "PMC8136408"
    },
    {
      "pmid": "39777077",
      "title": "Low-carbohydrate diet score and chronic obstructive pulmonary disease: a machine learning analysis of NHANES data.",
      "abstract": "BACKGROUND: Recent research has identified the Low-Carbohydrate Diet (LCD) score as a novel biomarker, with studies showing that LCDs can reduce carbon dioxide retention, potentially improving lung function. While the link between the LCD score and chronic obstructive pulmonary disease (COPD) has been explored, its relevance in the US population remains uncertain. This study aims to explore the association between the LCD score and the likelihood of COPD prevalence in this population. METHODS: Data from 16,030 participants in the National Health and Nutrition Examination Survey (NHANES) collected between 2007 and 2023 were analyzed to examine the relationship between LCD score and COPD. Propensity score matching (PSM) was employed to reduce baseline bias. Weighted multivariable logistic regression models were applied, and restricted cubic spline (RCS) regression was used to explore possible nonlinear relationships. Subgroup analyses were performed to evaluate the robustness of the results. Additionally, we employed eight machine learning methods-Boost Tree, Decision Tree, Logistic Regression, MLP, Naive Bayes, KNN, Random Forest, and SVM RBF-to build predictive models and evaluate their performance. Based on the best-performing model, we further examined variable importance and model accuracy. RESULTS: Upon controlling for variables, the LCD score demonstrated a strong correlation with the odds of COPD prevalence. In compared to the lowest quartile, the adjusted odds ratios (ORs) for the high quartile were 0.77 (95% CI: 0.63, 0.95), 0.74 (95% CI: 0.59, 0.93), and 0.61 (95% CI: 0.48, 0.78). RCS analysis demonstrated a linear inverse relationship between the LCD score and the odds of COPD prevalence. Furthermore, the random forest model exhibited robust predictive efficacy, with an area under the curve (AUC) of 71.6%. CONCLUSION: Our study of American adults indicates that adherence to the LCD may be linked to lower odds of COPD prevalence. These findings underscore the important role of the LCD score as a tool for enhancing COPD prevention efforts within the general population. Nonetheless, additional prospective cohort studies are required to assess and validate these results.",
      "authors": "Zhang Xin; Mo Jipeng; Yang Kaiyu; Tan Tiewu; Zhao Cuiping; Qin Hui",
      "year": "2024",
      "journal": "Frontiers in nutrition",
      "doi": "10.3389/fnut.2024.1519782",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39777077/",
      "mesh_terms": "",
      "keywords": "NHANES; chronic obstructive pulmonary disease; cross-sectional study; low-carbohydrate diet score; machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11706202"
    },
    {
      "pmid": "34485922",
      "title": "Cultural Evolution and Digital Media: Diffusion of Fake News About COVID-19 on Twitter.",
      "abstract": "UNLABELLED: Disinformation (fake news) is a major problem that affects modern populations, especially in an era when information can be spread from one corner of the world to another in just one click. The diffusion of misinformation becomes more problematic when it addresses issues related to health, as it can affect people at both the individual and population levels. Through the ideas proposed by cultural evolution theory, in this study, we seek to understand the dynamics of disseminating messages (cultural traits) with untrue content (maladaptive traits). For our investigation, we used the scenario caused by the Coronavirus Disease 2019 (COVID-19) pandemic as a model. The instability caused by the pandemic provides a good model for the study of adapted and maladaptive traits, as the information can directly affect individual and population fitness. Through data collected on the Twitter platform (259,176 tweets) and using machine learning techniques and web scraping, we built a predictive model to analyze the following questions: (1) Is false information more shared? (2) Is false information more adopted? (3) Do people with social prestige influence the dissemination of maladaptive traits of COVID-19? We observed that fake news features contained in messages with false information were shared and adopted as unblemished messages. We also observed that social prestige was not a determining factor for the diffusion of maladaptive traits. Even with the ability to allow connections between individuals participating in social media, some factors such as attachment to cultural traits and the formation of social bubbles can favor isolation and decrease connectivity between individuals. Consequently, in the scenario of isolation between groups and low connectivity between individuals, there is a reduction in cultural exchange between people, which interferes with the dynamics of the selection of cultural traits. Thus, maladaptive (harmful) traits are favored and maintained in the cultural system. We also argue that the local Brazilian cultural context can be a determining factor for maintaining maladaptive traits. We conclude that in an unstable (pandemic) scenario, the information transmitted on Twitter is not reliable in relation to the increase in fitness, which may occur because of the low cultural exchange promoted by the personalization of the social network and cultural context of the population. SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1007/s42979-021-00836-w.",
      "authors": "de Oliveira Danilo Vicente Batista; Albuquerque Ulysses Paulino",
      "year": "2021",
      "journal": "SN computer science",
      "doi": "10.1007/s42979-021-00836-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34485922/",
      "mesh_terms": "",
      "keywords": "Cultural selection bias; Machine learning; Maladaptive traits; Misinformation; Online information; Pandemic",
      "pub_types": "News",
      "pmcid": "PMC8397611"
    },
    {
      "pmid": "41322085",
      "title": "Game-Based Cognitive Aging Assessment: Toward a Digital Biomarker of Cognitive Health.",
      "abstract": "INTRODUCTION: Cognitive performance declines with age and predicts important life outcomes, making it a promising - yet underutilized - biomarker of aging. In this study, we aimed to establish the feasibility and value of game-based digital biomarkers of cognitive aging using data from a home-based cognitive assessment game. METHODS: Participants (N = 871; age 18-75) completed Tunnel Runner, a 20-25 min cognitive game measuring reaction speed, response inhibition, interference control, response-rule switching, and decision-making. To assess the game's out-of-sample predictive accuracy, we trained machine learning models to predict participants' chronological age based on 17 game-based cognitive metrics and evaluated their performance using nested cross-validation. Cognitive aging scores were calculated as out-of-sample prediction errors from the best-performing model, and then adjusted for age-dependence using generalized additive models. These aging scores were then considered alongside three other variables: depression, ADHD, and gamer identity. RESULTS: The best-performing model, stacked ensemble from the automated machine learning framework AutoGluon, predicted out-of-sample chronological age with a mean absolute error of 6.97 years, a correlation of 0.626, and concordance of 0.698. No evidence of bias in predictive accuracy was found for gender or gaming identity. Prediction patterns and cognitive aging values met several expectations based on previous research: reduced cognitive aging in participants with self-reported ADHD, negative association between cognitive aging and gamer identity, and limited predictive differentiation under age 30. Findings regarding self-reported depression were inconclusive, though consistent with prior work. CONCLUSION: Game-based assessment can produce accessible digital biomarkers of cognitive aging that reflect meaningful individual differences. This approach enables scalable and low-burden cognitive aging assessment, with potential applications for early detection of cognitive decline, longitudinal tracking, and intervention evaluation.",
      "authors": "Markovitch Benny; Markopoulos Panos; Birk Max V",
      "year": "2025",
      "journal": "Digital biomarkers",
      "doi": "10.1159/000548350",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41322085/",
      "mesh_terms": "",
      "keywords": "Biomarkers of aging; Cognitive aging; Cognitive assessment; Cognitive games; Game-based digital biomarkers",
      "pub_types": "Journal Article",
      "pmcid": "PMC12659009"
    },
    {
      "pmid": "36801340",
      "title": "Effects of heatwave features on machine-learning-based heat-related ambulance calls prediction models in Japan.",
      "abstract": "Researchers agree that there is substantial evidence of an increasing trend in both the frequency and duration of extreme temperature events. Increasing extreme temperature events will place more pressure on public health and emergency medical resources, and societies will need to find effective and reliable solutions to adapt to hotter summers. This study developed an effective method to predict the number of daily heat-related ambulance calls. Both national- and regional-level models were developed to evaluate the performance of machine-learning-based methods on heat-related ambulance call prediction. The national model showed a high prediction accuracy and can be applied over most regions, while the regional model showed extremely high prediction accuracy in each corresponding region and reliable accuracy in special cases. We found that the introduction of heatwave features, including accumulated heat stress, heat acclimatization, and optimal temperature, significantly improved prediction accuracy. The adjusted coefficient of determination (adjusted R2) of the national model improved from 0.9061 to 0.9659 by including these features, and the adjusted R2 of the regional model also improved from 0.9102 to 0.9860. Furthermore, we used five bias-corrected global climate models (GCMs) to forecast the total number of summer heat-related ambulance calls under three different future climate scenarios nationally and regionally. Our analysis demonstrated that, at the end of the 21st century, the total number of heat-related ambulance calls in Japan will reach approximately 250,000 per year (nearly four times the current amount) under SSP-5.85. Our results suggest that disaster management agencies can use this highly accurate model to forecast potential high emergency medical resource burden caused by extreme heat events, allowing them to raise and improve public awareness and prepare countermeasures in advance. The method proposed in Japan in this paper can be applied to other countries that have relevant data and weather information systems.",
      "authors": "Ke Deng; Takahashi Kiyoshi; Takakura Jun'ya; Takara Kaoru; Kamranzad Bahareh",
      "year": "2023",
      "journal": "The Science of the total environment",
      "doi": "10.1016/j.scitotenv.2023.162283",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36801340/",
      "mesh_terms": "Ambulances; Japan; Temperature; Hot Temperature; Weather",
      "keywords": "Climate change; Emergency ambulance calls; Extreme Gradient Boosting; Heat-related impacts; Shared Socioeconomic Pathways (SSP)",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32301414",
      "title": "Predictors of attrition in a longitudinal population-based study of aging.",
      "abstract": "BACKGROUND: Longitudinal studies predictably experience non-random attrition over time. Among older adults, risk factors for attrition may be similar to risk factors for outcomes such as cognitive decline and dementia, potentially biasing study results. OBJECTIVE: To characterize participants lost to follow-up which can be useful in the study design and interpretation of results. METHODS: In a longitudinal aging population study with 10 years of annual follow-up, we characterized the attrited participants (77%) compared to those who remained in the study. We used multivariable logistic regression models to identify attrition predictors. We then implemented four machine learning approaches to predict attrition status from one wave to the next and compared the results of all five approaches. RESULTS: Multivariable logistic regression identified those more likely to drop out as older, male, not living with another study participant, having lower cognitive test scores and higher clinical dementia ratings, lower functional ability, fewer subjective memory complaints, no physical activity, reported hobbies, or engagement in social activities, worse self-rated health, and leaving the house less often. The four machine learning approaches using areas under the receiver operating characteristic curves produced similar discrimination results to the multivariable logistic regression model. CONCLUSIONS: Attrition was most likely to occur in participants who were older, male, inactive, socially isolated, and cognitively impaired. Ignoring attrition would bias study results especially when the missing data might be related to the outcome (e.g. cognitive impairment or dementia). We discuss possible solutions including oversampling and other statistical modeling approaches.",
      "authors": "Jacobsen Erin; Ran Xinhui; Liu Anran; Chang Chung-Chou H; Ganguli Mary",
      "year": "2021",
      "journal": "International psychogeriatrics",
      "doi": "10.1017/S1041610220000447",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32301414/",
      "mesh_terms": "Activities of Daily Living; Aged; Aged, 80 and over; Aging; Female; Health Behavior; Humans; Logistic Models; Longitudinal Studies; Lost to Follow-Up; Machine Learning; Male; Patient Dropouts; Population Surveillance; Quality of Life",
      "keywords": "artificial neural network (ANN); epidemiology; gradient boosting machine (GBM); least absolute shrinkage and selection operator-type regression (LASSO); loss to follow-up; random forest (RF)",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC7572515"
    },
    {
      "pmid": "41172342",
      "title": "Governing AI in Mental Health: 50-State Legislative Review.",
      "abstract": "BACKGROUND: Mental health-related artificial intelligence (MH-AI) systems are proliferating across consumer and clinical contexts, outpacing regulatory frameworks and raising urgent questions about safety, accountability, and clinical integration. Reports of adverse events, including instances of self-harm and harmful clinical advice, highlight the risks of deploying such tools without clear standards and oversight. Federal authority over MH-AI is fragmented, leaving state legislatures to serve as de facto laboratories for MH-AI policy. Some states have been highly active in this area during recent legislative sessions. Yet, clinicians and professional organizations have mainly remained absent or sidelined from public commentary and policymaking bodies, raising concerns that new laws may diverge from the realities of mental health care. OBJECTIVE: To systematically analyze recent state-level legislation relevant to MH-AI, categorize bills by relevance to mental health, identify major regulatory themes and gaps, and evaluate implications for clinicians and patients. METHODS: We conducted a systematic analysis of bills introduced in all 50 US states between January 1, 2022, and May 19, 2025, using standardized searches on the legislative research website (LegiScan). Bills were screened and categorized using a custom 4-tier taxonomy based on their applicability to MH-AI. Bills passing threshold review were coded by topic using a 25-tag system developed through iterative consensus. Legally trained reviewers adjudicated final classifications to ensure consistency and rigor. RESULTS: Among 793 state bills reviewed, 143 were identified as potentially impactful to MH-AI: 28 explicitly referenced mental health uses, while 115 had substantial or indirect implications. Of these 143 bills, 20 were enacted across 11 states. Legislative efforts varied widely, but 4 thematic domains consistently emerged: (1) professional oversight, including deployer liability and licensure obligations; (2) harm prevention, encompassing safety protocols, malpractice exposure, and risk stratification frameworks; (3) patient autonomy, particularly in areas of disclosure, consent, and transparency; and (4) data governance, with notable gaps in privacy protections for sensitive mental health data. CONCLUSIONS: State legislatures are rapidly shaping the regulatory landscape for MH-AI, but most laws treat mental health as incidental to broader artificial intelligence or health care regulation. Explicit mental health provisions remain rare, and clinician and patient perspectives are seldom incorporated into policymaking. The result is a fragmented and uneven environment that risks leaving patients unprotected and clinicians overburdened. Mental health professionals must proactively engage with legislators, professional organizations, and patient advocates to ensure that emerging frameworks address oversight, harm, autonomy, and privacy in ways that are clinically realistic, ethically sound, and supportive of flexible-but responsible-innovation.",
      "authors": "Shumate J Nicholas; Rozenblit Eden; Flathers Matthew; Larrauri Carlos A; Hau Christine; Xia Winna; Torous E Nicholas; Torous John",
      "year": "2025",
      "journal": "JMIR mental health",
      "doi": "10.2196/80739",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41172342/",
      "mesh_terms": "Humans; Artificial Intelligence; United States; Mental Health; Mental Health Services; State Government",
      "keywords": "AI oversight; AI regulation; AI risk; AI safety; LLM; MH-AI; algorithmic bias; artificial intelligence; chatbot; clinical oversight; digital companions; digital health; digital therapy; digital treatments; generative AI; health law; healthcare policy; large language model; law; legislation; legislative trends; liability; machine learning; malpractice; medical regulation; mental health\u2013related artificial intelligence; policy analysis; psychiatric tools; regulatory gaps; technology ethics; therapy bots",
      "pub_types": "Journal Article",
      "pmcid": "PMC12578431"
    },
    {
      "pmid": "40127267",
      "title": "The narrow search effect and how broadening search promotes belief updating.",
      "abstract": "Information search platforms, from Google to AI-assisted search engines, have transformed information access but may fail to promote a shared factual foundation. We demonstrate that the combination of users' prior beliefs influencing their search terms and the narrow scope of search algorithms can limit belief updating from search. We test this \"narrow search effect\" across 21 studies (14 preregistered) using various topics (e.g., health, financial, societal, political) and platforms (e.g., Google, ChatGPT, AI-powered Bing, our custom-designed search engine and AI chatbot interfaces). We then test user-based and algorithm-based interventions to counter the \"narrow search effect\" and promote belief updating. Studies 1 to 5 show that users' prior beliefs influence the direction of the search terms, thereby generating narrow search results that limit belief updating. This effect persists across various domains (e.g., beliefs related to coronavirus, nuclear energy, gas prices, crime rates, bitcoin, caffeine, and general food or beverage health concerns; Studies 1a to 1b, 2a to 2g, 3, 4), platforms (e.g., Google-Studies 1a to 1b, 2a to 2g, 4, 5; ChatGPT, Study 3), and extends to consequential choices (Study 5). Studies 6 and 7 demonstrate the limited efficacy of prompting users to correct for the impact of narrow searches on their beliefs themselves. Using our custom-designed search engine and AI chatbot interfaces, Studies 8 and 9 show that modifying algorithms to provide broader results can encourage belief updating. These findings highlight the need for a behaviorally informed approach to the design of search algorithms.",
      "authors": "Leung Eugina; Urminsky Oleg",
      "year": "2025",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "doi": "10.1073/pnas.2408175122",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40127267/",
      "mesh_terms": "Humans; Search Engine; Algorithms; Artificial Intelligence; Information Seeking Behavior",
      "keywords": "algorithmic search; artificial intelligence; belief updating; confirmation bias",
      "pub_types": "Journal Article",
      "pmcid": "PMC12002208"
    },
    {
      "pmid": "32472068",
      "title": "Validation of a hybrid approach to standardize immunophenotyping analysis in large population studies: The Health and Retirement Study.",
      "abstract": "Traditional manual gating strategies are often time-intensive, place a high burden on the analyzer, and are susceptible to bias between analyzers. Several automated gating methods have shown to exceed performance of manual gating for a limited number of cell subsets. However, many of the automated algorithms still require significant manual interventions or have yet to demonstrate their utility in large datasets. Therefore, we developed an approach that utilizes a previously published automated algorithm (OpenCyto framework) with a manually created hierarchically cell gating template implemented, along with a custom developed visualization software (FlowAnnotator) to rapidly and efficiently analyze immunophenotyping data in large population studies. This approach allows pre-defining populations that can be analyzed solely by automated analysis and incorporating manual refinement for smaller downstream populations. We validated this method with traditional manual gating strategies for 24 subsets of T cells, B cells, NK cells, monocytes and dendritic cells in 931 participants from the Health and Retirement Study (HRS). Our results show a high degree of correlation (r\u2009\u2265\u20090.80) for 18 (78%) of the 24 cell subsets. For the remaining subsets, the correlation was low (<0.80) primarily because of the low numbers of events recorded in these subsets. The mean difference in the absolute counts between the hybrid method and manual gating strategy of these cell subsets showed results that were very similar to the traditional manual gating method. We describe a practical method for standardization of immunophenotyping methods in large scale population studies that provides a rapid, accurate and reproducible alternative to labor intensive manual gating strategies.",
      "authors": "Hunter-Schlichting DeVon; Lane John; Cole Benjamin; Flaten Zachary; Barcelo Helene; Ramasubramanian Ramya; Cassidy Erin; Faul Jessica; Crimmins Eileen; Pankratz Nathan; Thyagarajan Bharat",
      "year": "2020",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-020-65016-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32472068/",
      "mesh_terms": "Algorithms; Computational Biology; Datasets as Topic; Dendritic Cells; Feasibility Studies; Flow Cytometry; Health Surveys; High-Throughput Screening Assays; Humans; Immunophenotyping; Longitudinal Studies; Lymphocyte Subsets; Reproducibility of Results; Software",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Validation Study",
      "pmcid": "PMC7260195"
    },
    {
      "pmid": "33411794",
      "title": "A novel cross-validation strategy for artificial neural networks using distributed-lag environmental factors.",
      "abstract": "In recent years, machine learning methods have been applied to various prediction scenarios in time-series data. However, some processing procedures such as cross-validation (CV) that rearrange the order of the longitudinal data might ruin the seriality and lead to a potentially biased outcome. Regarding this issue, a recent study investigated how different types of CV methods influence the predictive errors in conventional time-series data. Here, we examine a more complex distributed lag nonlinear model (DLNM), which has been widely used to assess the cumulative impacts of past exposures on the current health outcome. This research extends the DLNM into an artificial neural network (ANN) and investigates how the ANN model reacts to various CV schemes that result in different predictive biases. We also propose a newly designed permutation ratio to evaluate the performance of the CV in the ANN. This ratio mimics the concept of the R-square in conventional statistical regression models. The results show that as the complexity of the ANN increases, the predicted outcome becomes more stable, and the bias shows a decreasing trend. Among the different settings of hyperparameters, the novel strategy, Leave One Block Out Cross-Validation (LOBO-CV), demonstrated much better results, and the lowest mean square error was observed. The hyperparameters of the ANN trained by the LOBO-CV yielded the minimum number of prediction errors. The newly proposed permutation ratio indicates that LOBO-CV can contribute up to 34% of the prediction accuracy.",
      "authors": "Guo Chao-Yu; Liu Tse-Wei; Chen Yi-Hau",
      "year": "2021",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0244094",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33411794/",
      "mesh_terms": "Neural Networks, Computer; Nonlinear Dynamics; Reproducibility of Results",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7790373"
    },
    {
      "pmid": "32167557",
      "title": "Association between the pregnancy exposome and fetal growth.",
      "abstract": "BACKGROUND: Several environmental contaminants were shown to possibly influence fetal growth, generally from single exposure family studies, which are prone to publication bias and confounding by co-exposures. The exposome paradigm offers perspectives to avoid selective reporting of findings and to control for confounding by co-exposures. We aimed to characterize associations of fetal growth with the pregnancy chemical and external exposomes. METHODS: Within the Human Early-Life Exposome project, 131 prenatal exposures were assessed using biomarkers and environmental models in 1287 mother-child pairs from six European cohorts. We investigated their associations with fetal growth using a deletion-substitution-addition (DSA) algorithm considering all exposures simultaneously, and an exposome-wide association study (ExWAS) considering each exposure independently. We corrected for exposure measurement error and tested for exposure-exposure and sex-exposure interactions. RESULTS: The DSA model identified lead blood level, which was associated with a 97\u2009g birth weight decrease for each doubling in lead concentration. No exposure passed the multiple testing-corrected significance threshold of ExWAS; without multiple testing correction, this model was in favour of negative associations of lead, fine particulate matter concentration and absorbance with birth weight, and of a positive sex-specific association of parabens with birth weight in boys. No two-way interaction between exposure variables was identified. CONCLUSIONS: This first large-scale exposome study of fetal growth simultaneously considered >100 environmental exposures. Compared with single exposure studies, our approach allowed making all tests (usually reported in successive publications) explicit. Lead exposure is still a health concern in Europe and parabens health effects warrant further investigation.",
      "authors": "Agier Lydiane; Basaga\u00f1a Xavier; Hernandez-Ferrer Carles; Maitre L\u00e9a; Tamayo Uria Ibon; Urquiza Jose; Andrusaityte Sandra; Casas Maribel; de Castro Montserrat; Cequier Enrique; Chatzi Leda; Donaire-Gonzalez David; Giorgis-Allemand Lise; Gonzalez Juan R; Grazuleviciene Regina; G\u00fctzkow Kristine B; Haug Line S; Sakhi Amrit K; McEachan Rosemary R C; Meltzer Helle M; Nieuwenhuijsen Mark; Robinson Oliver; Roumeliotaki Theano; Sunyer Jordi; Thomsen Cathrine; Vafeiadi Marina; Valentin Antonia; West Jane; Wright John; Siroux Val\u00e9rie; Vrijheid Martine; Slama R\u00e9my",
      "year": "2020",
      "journal": "International journal of epidemiology",
      "doi": "10.1093/ije/dyaa017",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32167557/",
      "mesh_terms": "Cohort Studies; Europe; Exposome; Female; Fetal Development; Humans; Male; Maternal Exposure; Pregnancy",
      "keywords": "Biomarkers; chemical exposures; cohort; environment; exposome; fetal growth; mixtures",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7266545"
    },
    {
      "pmid": "38190236",
      "title": "Determining Distinct Suicide Attempts From Recurrent Electronic Health Record Codes: Classification Study.",
      "abstract": "BACKGROUND: Prior suicide attempts are a relatively strong risk factor for future suicide attempts. There is growing interest in using longitudinal electronic health record (EHR) data to derive statistical risk prediction models for future suicide attempts and other suicidal behavior outcomes. However, model performance may be inflated by a largely unrecognized form of \"data leakage\" during model training: diagnostic codes for suicide attempt outcomes may refer to prior attempts that are also included in the model as predictors. OBJECTIVE: We aimed to develop an automated rule for determining when documented suicide attempt diagnostic codes identify distinct suicide attempt events. METHODS: From a large health care system's EHR, we randomly sampled suicide attempt codes for 300 patients with at least one pair of suicide attempt codes documented at least one but no more than 90 days apart. Supervised chart reviewers assigned the clinical settings (ie, emergency department [ED] versus non-ED), methods of suicide attempt, and intercode interval (number of days). The probability (or positive predictive value) that the second suicide attempt code in a given pair of codes referred to a distinct suicide attempt event from its preceding suicide attempt code was calculated by clinical setting, method, and intercode interval. RESULTS: Of 1015 code pairs reviewed, 835 (82.3%) were nonindependent (ie, the 2 codes referred to the same suicide attempt event). When the second code in a pair was documented in a clinical setting other than the ED, it represented a distinct suicide attempt 3.3% of the time. The more time elapsed between codes, the more likely the second code in a pair referred to a distinct suicide attempt event from its preceding code. Code pairs in which the second suicide attempt code was assigned in an ED at least 5 days after its preceding suicide attempt code had a positive predictive value of 0.90. CONCLUSIONS: EHR-based suicide risk prediction models that include International Classification of Diseases codes for prior suicide attempts as a predictor may be highly susceptible to bias due to data leakage in model training. We derived a simple rule to distinguish codes that reflect new, independent suicide attempts: suicide attempt codes documented in an ED setting at least 5 days after a preceding suicide attempt code can be confidently treated as new events in EHR-based suicide risk prediction models. This rule has the potential to minimize upward bias in model performance when prior suicide attempts are included as predictors in EHR-based suicide risk prediction models.",
      "authors": "Bentley Kate H; Madsen Emily M; Song Eugene; Zhou Yu; Castro Victor; Lee Hyunjoon; Lee Younga H; Smoller Jordan W",
      "year": "2024",
      "journal": "JMIR formative research",
      "doi": "10.2196/46364",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38190236/",
      "mesh_terms": "",
      "keywords": "EHR; automated rule; electronic health record; informatics; machine learning; model; predict; prediction; predictive model; psychiatry; self-injury; suicidal; suicide; suicide attempt",
      "pub_types": "Journal Article",
      "pmcid": "PMC10804255"
    },
    {
      "pmid": "34599439",
      "title": "Fuzzy-based adaptive learning network using search and rescue optimization for e-waste management model: case study.",
      "abstract": "In recent days, the expansion of e-waste disposal should be increased due to environmental hazards, contamination of groundwater, an unconcerned consequence on marine life, human health, and decrease in the fertility of the soil. The majority of the developing countries are facing massive issues in implementing sustainable e-waste management schemes. The unofficial e-waste management schemes in the region of Chandigarh, India, have become a serious dispute for the government and several stakeholders due to human health and environmental effects. To overcome such shortcomings, this paper proposes an efficient e-waste management system using fuzzy c-means based adaptive optimal neural network. Here fuzzy c-means clustering approach is employed to classify the household e-wastes and adaptive optimal neural network is employed to analyze the relative weights as well as the grading of the obstructions. Here, the financial and economic limitations are regarded as the most important obstructions of e-waste formalization. The sensitivity analysis is carried out to verify the structure robustness and address the bias effect. This study assists the lawmakers to create organized strategies for an efficient e-waste management system. The sustainable set of e-waste management system advances the e-waste management in India quality thereby raising the recycling rate to 40%.",
      "authors": "Batoo Khalid Mujasam; Pandiaraj Saravanan; Muthuramamoorthy Muthumareeswaran; Raslan Emad; Krishnamoorthy Sujatha",
      "year": "2022",
      "journal": "Environmental science and pollution research international",
      "doi": "10.1007/s11356-021-15320-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34599439/",
      "mesh_terms": "Electronic Waste; Machine Learning; Recycling; Refuse Disposal; Waste Management",
      "keywords": "Barriers; E-waste management; Electronic waste; Fuzzy C-means; Neural network; Search and rescue optimization algorithm",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "37789443",
      "title": "ChatGPT in pharmacy practice: a cross-sectional exploration of Jordanian pharmacists' perception, practice, and concerns.",
      "abstract": "OBJECTIVES: The purpose of this study is to find out how much pharmacists know and have used ChatGPT in their practice. We investigated the advantages and disadvantages of utilizing ChatGPT in a pharmacy context, the amount of training necessary to use it proficiently, and the influence on patient care using a survey. METHODS: This cross-sectional study was carried out between May and June 2023 to assess the potential and problems that pharmacists observed while integrating chatbots powered by AI (ChatGPT) in pharmacy practice. The correlation between perceived benefits and concerns was evaluated using Spearman's rho correlation due to the data's non-normal distribution.Any pharmacists licensed by the Jordanian\u00a0Pharmacists Association were included in the study. A convenient\u00a0sampling technique was used to choose the participants, and the study questionnaire was distributed utilizing an online medium (Facebook and WhatsApp). Anyone who expressed interest in taking part was given a link to the study's instructions so they may read them before giving their electronic consent and accessing the survey. RESULTS: The potential advantages of ChatGPT in the pharmacy practice were widely acknowledged by the participants. The majority of participants (69.9%) concurred that educational material about pharmacy items or therapeutic areas can be provided using ChatGPT, with 66.9% of respondents believing that ChatGPT is a machine learning algorithm. Concerns about the accuracy of AI-generated responses were also prevalent. More than half of the participants (55.7%) raised the possibility that AI systems such as ChatGPT could pick up on and replicate prejudices and discriminatory patterns from the data they were trained on. Analysis shows a statistically significant positive link, albeit a minor one, between the perceived advantages of ChatGPT and its drawbacks (r\u2009=\u20090.255, p\u2009<\u20090.001). However, concerns were strongly correlated with knowledge of ChatGPT. In contrast to those who were either unsure or had not heard of ChatGPT (64.2%), individuals who had heard of it were more likely to have strong concerns (79.8%) (p\u2009=\u20090.002). Finally, the results show a statistically significant association between the frequency of ChatGPT use and positive perceptions of the tool (p\u2009<\u20090.001). CONCLUSIONS: Although ChatGPT has shown promise in health and pharmaceutical practice, its application should be rigorously regulated by evidence-based law. According to the study's findings, pharmacists support the use of ChatGPT in pharmacy practice but have concerns about its use due to ethical reasons, legal problems, privacy concerns, worries about the accuracy of the data generated, data learning, and bias risk.",
      "authors": "Abu Hammour Khawla; Alhamad Hamza; Al-Ashwal Fahmi Y; Halboup Abdulsalam; Abu Farha Rana; Abu Hammour Adnan",
      "year": "2023",
      "journal": "Journal of pharmaceutical policy and practice",
      "doi": "10.1186/s40545-023-00624-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37789443/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; ChatGPT; Pharmacy practice",
      "pub_types": "Journal Article",
      "pmcid": "PMC10548710"
    },
    {
      "pmid": "33606586",
      "title": "In vivo application and validation of a novel noninvasive method to estimate the end-systolic elastance.",
      "abstract": "Accurate assessment of the left ventricular (LV) systolic function is indispensable in the clinic. However, estimation of a precise index of cardiac contractility, i.e., the end-systolic elastance (Ees), is invasive and cannot be established as clinical routine. The aim of this work was to present and validate a methodology that allows for the estimation of Ees from simple and readily available noninvasive measurements. The method is based on a validated model of the cardiovascular system and noninvasive data from arm-cuff pressure and routine echocardiography to render the model patient-specific. Briefly, the algorithm first uses the measured aortic flow as model input and optimizes the properties of the arterial system model to achieve correct prediction of the patient's peripheral pressure. In a second step, the personalized arterial system is coupled with the cardiac model (time-varying elastance model) and the LV systolic properties, including Ees, are tuned to predict accurately the aortic flow waveform. The algorithm was validated against invasive measurements of Ees (multiple pressure-volume loop analysis) taken from n = 10 patients with heart failure with preserved ejection fraction and n = 9 patients without heart failure. Invasive measurements of Ees (median = 2.4\u2009mmHg/mL, range = [1.0, 5.0] mmHg/mL) agreed well with method predictions (normalized root mean square error\u2009=\u20099%, \u03c1 = 0.89, bias = -0.1\u2009mmHg/mL, and limits of agreement = [-0.9, 0.6] mmHg/mL). This is a promising first step toward the development of a valuable tool that can be used by clinicians to assess systolic performance of the LV in the critically ill.NEW & NOTEWORTHY In this study, we present a novel model-based method to estimate the left ventricular (LV) end-systolic elastance (Ees) according to measurement of the patient's arm-cuff pressure and a routine echocardiography examination. The proposed method was validated in vivo against invasive multiple-loop measurements of Ees, achieving high correlation and low bias. This tool could be most valuable for clinicians to assess the cardiovascular health of critically ill patients.",
      "authors": "Pagoulatou Stamatia; Rommel Karl-Philipp; Kresoja Karl-Patrik; von Roeder Maximilian; Lurz Philipp; Thiele Holger; Bikia Vasiliki; Rovas Georgios; Adamopoulos Dionysios; Stergiopulos Nikolaos",
      "year": "2021",
      "journal": "American journal of physiology. Heart and circulatory physiology",
      "doi": "10.1152/ajpheart.00703.2020",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33606586/",
      "mesh_terms": "Aged; Algorithms; Blood Pressure Determination; Echocardiography; Female; Heart Failure; Hemodynamics; Humans; Male; Middle Aged; Models, Cardiovascular; Predictive Value of Tests; Reproducibility of Results; Sphygmomanometers; Systole; Ventricular Function, Left",
      "keywords": "P-V loop; cardiovascular modeling; inverse methods; left ventricular contractility; nonivasive monitoring",
      "pub_types": "Comparative Study; Journal Article; Research Support, Non-U.S. Gov't; Validation Study",
      "pmcid": ""
    },
    {
      "pmid": "34320952",
      "title": "Overcoming the problems caused by collinearity in mixed-effects logistic model: determining the contribution of various types of violence on depression in pregnant women.",
      "abstract": "BACKGROUND: Collinearity is a common and problematic phenomenon in studies on public health. It leads to inflation in variance of estimator and reduces test power. This phenomenon can occur in any model. In this study, a new ridge mixed-effects logistic model (RMELM) is proposed to overcome consequences of collinearity in correlated binary responses. METHODS: Parameters were estimated through penalized log-likelihood with combining expectation maximization (EM) algorithm, gradient ascent, and Fisher-scoring methods. A simulation study was performed to compare new model with mixed-effects logistic model(MELM). Mean square error, relative bias, empirical power, and variance of random effects were used to evaluate RMELM. Also, contribution of various types of violence, and intervention on depression among pregnant women experiencing intimate partner violence(IPV) were analyzed by new and previous models. RESULTS: Simulation study showed that mean square errors of fixed effects were decreased for RMELM than MELM and empirical power were increased. Inflation in variance of estimators due to collinearity was clearly shown in the MELM in data on IPV and RMELM adjusted the variances. CONCLUSIONS: According to simulation results and analyzing IPV data, this new estimator is appropriate to deal with collinearity problems in the modelling of correlated binary responses.",
      "authors": "Khalili Sanaz; Faradmal Javad; Mahjub Hossein; Moeini Babak; Ezzati-Rastegar Khadijeh",
      "year": "2021",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/s12874-021-01325-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34320952/",
      "mesh_terms": "Cross-Sectional Studies; Depression; Female; Humans; Intimate Partner Violence; Logistic Models; Pregnancy; Pregnant People",
      "keywords": "Collinearity; Mixed-effects logistic model; Ridge estimator; Violence",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8317320"
    },
    {
      "pmid": "41161183",
      "title": "Microplastics and nanoplastics released by peeling off aluminium foil cap sealing liner.",
      "abstract": "Most of our food, drinks, medicines, health care products and cosmetics are bottled for delivery and sealed using aluminium foil liner that is coated with a plastic layer. Once we open it by peeling off the liner, some debris might be released as microplastics that are tested here. By advancing the Raman imaging and the statistical analysis, we can capture \u223c25 microplastics per 0.04\u202fmm2 or \u223c625 / mm2, particularly when scratch or scrape the container or liner surface, which might be a big concern as the potential microplastic source in our daily lives. The traditional analysis based on a homogenised sample such as an aqueous solution might generated bias for microplastics that is neither ion nor molecule. The subsequent point analysis via a single spectrum can be improved to imaging analysis via a hyper spectrum matrix that can contain hundreds-to-thousands of spectra / points (as pixels in the image) to enhance the signal-to-noise ratio. Raman imaging analysis can be further improved by algorithm to effectively decode the hyper spectrum matrix, to separately image the background and the targeted item. The generated images can identify and visualise microplastics towards quantification analysis. A statistical analysis is developed to capture the details at a high magnification and expand the statistic results to a big area at a low magnification, to estimate the release amount and the detailed morphology. The Raman imaging results are cross-checked with scanning electron microscopy (SEM) to benefit each other. Overall, the results send us a warning that microplastic and even nanoplastic contamination can happen in our daily livers in our kitchen and entre our food chain directly.",
      "authors": "Liu Siyuan; Naidu Ravi",
      "year": "2025",
      "journal": "Journal of hazardous materials",
      "doi": "10.1016/j.jhazmat.2025.140265",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41161183/",
      "mesh_terms": "Microplastics; Aluminum; Spectrum Analysis, Raman; Food Packaging",
      "keywords": "Aluminium foil sealing liner; Microplastic; Nanoplastic; Peeling off; Raman imaging; SEM",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34213008",
      "title": "Efficient odds ratio estimation under two-phase sampling using error-prone data from a multi-national HIV research cohort.",
      "abstract": "Persons living with HIV engage in routine clinical care, generating large amounts of data in observational HIV cohorts. These data are often error-prone, and directly using them in biomedical research could bias estimation and give misleading results. A cost-effective solution is the two-phase design, under which the error-prone variables are observed for all patients during Phase I, and that information is used to select patients for data auditing during Phase II. For example, the Caribbean, Central, and South America network for HIV epidemiology (CCASAnet) selected a random sample from each site for data auditing. Herein, we consider efficient odds ratio estimation with partially audited, error-prone data. We propose a semiparametric approach that uses all information from both phases and accommodates a number of error mechanisms. We allow both the outcome and covariates to be error-prone and these errors to be correlated, and selection of the Phase II sample can depend on Phase I data in an arbitrary manner. We devise a computationally efficient, numerically stable EM algorithm to obtain estimators that are consistent, asymptotically normal, and asymptotically efficient. We demonstrate the advantages of the proposed methods over existing ones through extensive simulations. Finally, we provide applications to the CCASAnet\u00a0cohort.",
      "authors": "Lotspeich Sarah C; Shepherd Bryan E; Amorim Gustavo G C; Shaw Pamela A; Tao Ran",
      "year": "2022",
      "journal": "Biometrics",
      "doi": "10.1111/biom.13512",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34213008/",
      "mesh_terms": "Humans; Odds Ratio; Research Design; Bias; Data Interpretation, Statistical; HIV Infections",
      "keywords": "case-control sampling; data audits; electronic health records; measurement error; missing data; semiparametric efficiency",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8720323"
    },
    {
      "pmid": "27442234",
      "title": "Predictive models of cytotoxicity as mediated by exposure to chemicals or drugs.",
      "abstract": "Predicting cytotoxicity is a challenging task because of the complex biological mechanisms behind it. Cytotoxicity due to toxin - biologically produced poison - is known to play a substantial role in a disease process. Two objectives in this research are to derive robust general predictive cytotoxicity models to minimize unnecessary toxicity. The first objective is to build accurate predictive statistical models for cytotoxicity data based on lymphoblastoid cell lines obtained from in vitro studies. This could be an important step for accomplishing a goal in biomedecial/biophamarceutical research, by obtaining the best medical outcomes by minimizing toxicity in regard to a person's genetic profile. The second objective is to build predictive models to predict population-level cytotoxicity for unknown compounds based on chemical structural features. These two objectives were accomplished by a proposed variable selection process, the random forests, and the least absolute shrinkage and selection operator method. We achieved an excellent prediction result with the random forests algorithm using SNP markers from the proposed approach, having the smallest root mean squared error among the teams which participated in the DREAM Toxicogenetics Challenge. Since chemical compounds for drugs have great influence on human health, the predictive statistical models for these objectives could be helpful to government agencies in relevant decision-making.",
      "authors": "Moon H; Cong M",
      "year": "2016",
      "journal": "SAR and QSAR in environmental research",
      "doi": "10.1080/1062936X.2016.1208272",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27442234/",
      "mesh_terms": "Algorithms; Cell Line; Drug-Related Side Effects and Adverse Reactions; Hazardous Substances; Humans; Lymphocytes; Machine Learning; Models, Statistical; Pharmaceutical Preparations; Polymorphism, Single Nucleotide; Quantitative Structure-Activity Relationship",
      "keywords": "Bias-skewness correction; correlation, genetic biomarkers; random forests, the LASSO",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "25196084",
      "title": "Evaluation of matched control algorithms in EHR-based phenotyping studies: a case study of inflammatory bowel disease comorbidities.",
      "abstract": "The success of many population studies is determined by proper matching of cases to controls. Some of the confounding and bias that afflict electronic health record (EHR)-based observational studies may be reduced by creating effective methods for finding adequate controls. We implemented a method to match case and control populations to compensate for sparse and unequal data collection practices common in EHR data. We did this by matching the healthcare utilization of patients after observing that more complete data was collected on high healthcare utilization patients vs. low healthcare utilization patients. In our results, we show that many of the anomalous differences in population comparisons are mitigated using this matching method compared to other traditional age and gender-based matching. As an example, the comparison of the disease associations of ulcerative colitis and Crohn's disease show differences that are not present when the controls are chosen in a random or even a matched age/gender/race algorithm. In conclusion, the use of healthcare utilization-based matching algorithms to find adequate controls greatly enhanced the accuracy of results in EHR studies. Full source code and documentation of the control matching methods is available at https://community.i2b2.org/wiki/display/conmat/.",
      "authors": "Castro Victor M; Apperson W Kay; Gainer Vivian S; Ananthakrishnan Ashwin N; Goodson Alyssa P; Wang Taowei D; Herrick Christopher D; Murphy Shawn N",
      "year": "2014",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.jbi.2014.08.012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/25196084/",
      "mesh_terms": "Algorithms; Case-Control Studies; Comorbidity; Electronic Health Records; Humans; Inflammatory Bowel Diseases; Medical Informatics; Patient Acceptance of Health Care",
      "keywords": "Comorbidity; Controls; EHR; Inflammatory bowel disease; Matching",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC4261034"
    },
    {
      "pmid": "37552742",
      "title": "Wastewater-Based Epidemiology for COVID-19: Handling qPCR Nondetects and Comparing Spatially Granular Wastewater and Clinical Data Trends.",
      "abstract": "Wastewater-based epidemiology (WBE) is a useful complement to clinical testing for managing COVID-19. While community-scale wastewater and clinical data frequently correlate, less is known about subcommunity relationships between the two data types. Moreover, nondetects in qPCR wastewater data are typically handled through methods known to bias results, overlooking perhaps better alternatives. We address these knowledge gaps using data collected from September 2020-June 2021 in Davis, California (USA). We hypothesize that coupling the expectation maximization (EM) algorithm with the Markov Chain Monte Carlo (MCMC) method could improve estimation of \"missing\" values in wastewater qPCR data. We test this hypothesis by applying EM-MCMC to city wastewater treatment plant data and comparing output to more conventional nondetect handling methods. Dissimilarities in results (i) underscore the importance of specifying nondetect handling method in reporting and (ii) suggest that using EM-MCMC may yield better agreement between community-scale clinical and wastewater data. We also present a novel framework for spatially aligning clinical data with wastewater data collected upstream of a treatment plant (i.e., distributed across a sewershed). Applying the framework to data from Davis reveals reasonable agreement between wastewater and clinical data at highly granular spatial scales-further underscoring the public-health value of WBE.",
      "authors": "Safford Hannah; Zuniga-Montanez Rogelio E; Kim Minji; Wu Xiaoliu; Wei Lifeng; Sharpnack James; Shapiro Karen; Bischel Heather N",
      "year": "2022",
      "journal": "ACS ES&T water",
      "doi": "10.1021/acsestwater.2c00053",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37552742/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "20486928",
      "title": "Survival analysis with error-prone time-varying covariates: a risk set calibration approach.",
      "abstract": "Occupational, environmental, and nutritional epidemiologists are often interested in estimating the prospective effect of time-varying exposure variables such as cumulative exposure or cumulative updated average exposure, in relation to chronic disease endpoints such as cancer incidence and mortality. From exposure validation studies, it is apparent that many of the variables of interest are measured with moderate to substantial error. Although the ordinary regression calibration (ORC) approach is approximately valid and efficient for measurement error correction of relative risk estimates from the Cox model with time-independent point exposures when the disease is rare, it is not adaptable for use with time-varying exposures. By recalibrating the measurement error model within each risk set, a risk set regression calibration (RRC) method is proposed for this setting. An algorithm for a bias-corrected point estimate of the relative risk using an RRC approach is presented, followed by the derivation of an estimate of its variance, resulting in a sandwich estimator. Emphasis is on methods applicable to the main study/external validation study design, which arises in important applications. Simulation studies under several assumptions about the error model were carried out, which demonstrated the validity and efficiency of the method in finite samples. The method was applied to a study of diet and cancer from Harvard's Health Professionals Follow-up Study (HPFS).",
      "authors": "Liao Xiaomei; Zucker David M; Li Yi; Spiegelman Donna",
      "year": "2011",
      "journal": "Biometrics",
      "doi": "10.1111/j.1541-0420.2010.01423.x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/20486928/",
      "mesh_terms": "Biometry; Cluster Analysis; Computer Simulation; Data Interpretation, Statistical; Humans; Male; Models, Statistical; Proportional Hazards Models; Risk Assessment; Risk Factors; Survival Analysis; Survival Rate",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC2927810"
    },
    {
      "pmid": "29391288",
      "title": "Differences in Longitudinal Health Utility between Stereotactic Body Radiation Therapy and Surgery in Stage I Non-Small Cell Lung Cancer.",
      "abstract": "INTRODUCTION: There is an ongoing debate on the optimal treatment for stage I NSCLC, with increasing evidence for comparable health outcomes after surgery and stereotactic body radiation therapy (SBRT). For clinical decision making, the experienced quality of life, summarized as health utility, is of importance to choosing between treatments. In this study, we evaluated differences in longitudinal health utility in stage I NSCLC in the first year after surgical resection versus after SBRT before any recurrence of disease. We also assessed the impact of potential prognostic variables on health utility. METHODS: Prospectively collected databases containing data on patients with stage I NSCLC treated with either SBRT or surgery were pooled from two large hospitals in the Netherlands. Quality of life data were measured by the Quality of Life Questionnaire-Core 30 questionnaire at baseline and 3, 6, and 12 months after treatment. Health utility (measured using the European Quality of Life Five-Dimension questionnaire) was calculated from the Quality of Life Questionnaire-Core 30 questionnaire by using a mapping algorithm. Propensity score matching was used to adjust for selection bias. Treatment effects were estimated for the matched patients by using a longitudinal mixed model approach. RESULTS: After correction for Eastern Cooperative Oncology Group score, sex, and age, the difference in 1-year averaged health utility between the SBRT and surgery groups was 0.026 (95% confidence interval: 0.028-0.080). Differences in health utility decreased over time. CONCLUSIONS: A small but not statistically significant difference in health utility was found between patients with stage I\u00a0NSCLC treated with surgery and those treated with SBRT. Current analysis strengthens existing evidence that SBRT is\u00a0an\u00a0equivalent treatment option for early-stage NSCLC. Comparative cost-effectiveness remains to be determined.",
      "authors": "Wolff Henri B; Alberts Leonie; Kastelijn Elisabeth A; Lissenberg-Witte Birgit I; Twisk Jos W; Lagerwaard Frank J; Senan Suresh; El Sharouni Sherif Y; Schramel Franz M N H; Coup\u00e9 Veerle M H",
      "year": "2018",
      "journal": "Journal of thoracic oncology : official publication of the International Association for the Study of Lung Cancer",
      "doi": "10.1016/j.jtho.2018.01.021",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29391288/",
      "mesh_terms": "Aged; Carcinoma, Non-Small-Cell Lung; Cohort Studies; Female; Humans; Lung Neoplasms; Male; Neoplasm Staging; Prospective Studies; Radiosurgery",
      "keywords": "Early stage; Health utility; NSCLC; SBRT; Surgery",
      "pub_types": "Comparative Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "38866172",
      "title": "Dimensional Measures of Psychopathology in Children and Adolescents Using Large Language Models.",
      "abstract": "BACKGROUND: To enable greater use of National Institute of Mental Health Research Domain Criteria (RDoC) in real-world settings, we applied large language models (LLMs) to estimate dimensional psychopathology from narrative clinical notes. METHODS: We conducted a cohort study using health records from individuals age \u226418 years evaluated in the psychiatric emergency department of a large academic medical center between November 2008 and March 2015. Outcomes were hospital admission and length of emergency department stay. RDoC domains were estimated using a Health Insurance Portability and Accountability Act-compliant LLM (gpt-4-1106-preview) and compared with a previously validated token-based approach. RESULTS: The cohort included 3059 individuals (median age 16 years [interquartile range, 13-18]; 1580 [52%] female, 1479 [48%] male; 105 [3.4%] identified as Asian, 329 [11%] as Black, 288 [9.4%] as Hispanic, 474 [15%] as other race, and 1863 [61%] as White), of whom 1695 (55%) were admitted. Correlation between LLM-extracted RDoC scores and the token-based scores ranged from small to medium as assessed by Kendall's tau (0.14-0.22). In logistic regression models adjusting for sociodemographic and clinical features, admission likelihood was associated with greater scores on all domains, with the exception of the sensorimotor domain, which was inversely associated (p < .001 for all adjusted associations). Tests for bias suggested modest but statistically significant differences in positive valence scores by race (p < .05 for Asian, Black, and Hispanic individuals). CONCLUSIONS: An LLM extracted estimates of 6 RDoC domains in an explainable manner, which were associated with clinical outcomes. This approach can contribute to a new generation of prediction models or biological investigations based on dimensional psychopathology.",
      "authors": "McCoy Thomas H; Perlis Roy H",
      "year": "2024",
      "journal": "Biological psychiatry",
      "doi": "10.1016/j.biopsych.2024.05.008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38866172/",
      "mesh_terms": "Humans; Male; Female; Adolescent; Mental Disorders; Cohort Studies; Child; United States; Emergency Service, Hospital; Language; Psychopathology; Length of Stay; National Institute of Mental Health (U.S.); Hospitalization",
      "keywords": "Anxiety; Artificial intelligence; Deep learning; Depression; Machine learning; Research domain criteria",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35768575",
      "title": "Smartphone camera based assessment of adiposity: a validation study.",
      "abstract": "Body composition is a key component of health in both individuals and populations, and excess adiposity is associated with an increased risk of developing chronic diseases. Body mass index (BMI) and other clinical or commercially available tools for quantifying body fat (BF) such as DXA, MRI, CT, and photonic scanners (3DPS) are often inaccurate, cost prohibitive, or cumbersome to use. The aim of the current study was to evaluate the performance of a novel automated computer vision method, visual body composition (VBC), that uses two-dimensional photographs captured via a conventional smartphone camera to estimate percentage total body fat (%BF). The VBC algorithm is based on a state-of-the-art convolutional neural network (CNN). The hypothesis is that VBC yields better accuracy than other consumer-grade fat measurements devices. 134 healthy adults ranging in age (21-76 years), sex (61.2% women), race (60.4% White; 23.9% Black), and body mass index (BMI, 18.5-51.6\u2009kg/m2) were evaluated at two clinical sites (N\u2009=\u200964 at MGH, N\u2009=\u200970 at PBRC). Each participant had %BF measured with VBC, three consumer and two professional bioimpedance analysis (BIA) systems. The PBRC participants also had air displacement plethysmography (ADP) measured. %BF measured by dual-energy x-ray absorptiometry (DXA) was set as the reference against which all other %BF measurements were compared. To test our scientific hypothesis we run multiple, pair-wise Wilcoxon signed rank tests where we compare each competing measurement tool (VBC, BIA, \u2026) with respect to the same ground-truth (DXA). Relative to DXA, VBC had the lowest mean absolute error and standard deviation (2.16\u2009\u00b1\u20091.54%) compared to all of the other evaluated methods (p\u2009<\u20090.05 for all comparisons). %BF measured by VBC also had good concordance with DXA (Lin's concordance correlation coefficient, CCC: all 0.96; women 0.93; men 0.94), whereas BMI had very poor concordance (CCC: all 0.45; women 0.40; men 0.74). Bland-Altman analysis of VBC revealed the tightest limits of agreement (LOA) and absence of significant bias relative to DXA (bias -0.42%, R2\u2009=\u20090.03; p\u2009=\u20090.062; LOA -5.5% to +4.7%), whereas all other evaluated methods had significant (p\u2009<\u20090.01) bias and wider limits of agreement. Bias in Bland-Altman analyses is defined as the discordance between the y\u2009=\u20090 axis and the regressed line computed from the data in the plot. In this first validation study of a novel, accessible, and easy-to-use system, VBC body fat estimates were accurate and without significant bias compared to DXA as the reference; VBC performance exceeded those of all other BIA and ADP methods evaluated. The wide availability of smartphones suggests that the VBC method for evaluating %BF could play an important role in quantifying adiposity levels in a wide range of settings.Trial registration: ClinicalTrials.gov Identifier: NCT04854421.",
      "authors": "Majmudar Maulik D; Chandra Siddhartha; Yakkala Kiran; Kennedy Samantha; Agrawal Amit; Sippel Mark; Ramu Prakash; Chaudhri Apoorv; Smith Brooke; Criminisi Antonio; Heymsfield Steven B; Stanford Fatima Cody",
      "year": "2022",
      "journal": "NPJ digital medicine",
      "doi": "10.1038/s41746-022-00628-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35768575/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9243018"
    },
    {
      "pmid": "31034040",
      "title": "Economic Impact of Adherence to Pain Treatment Guidelines in Chronic Pain Patients.",
      "abstract": "OBJECTIVES: This research compared health care resource use (HCRU) and costs for pharmacotherapy prescribing that was adherent vs nonadherent to published pain management guidelines. Conditions included osteoarthritis (OA) and gout (GT) for nociceptive/inflammatory pain, painful diabetic peripheral neuropathy (pDPN) and post-herpetic neuralgia (PHN) for neuropathic pain, and fibromyalgia (FM) for sensory hypersensitivity pain. METHODS: This retrospective cohort study used claims from MarketScan Commercial and Medicare Databases identifying adults newly diagnosed with OA, GT, pDPN, PHN, or FM during July 1, 2006, to June 30, 2013, with 12-month continuous coverage before and after initial (index) diagnosis. Patients were grouped according to their pharmacotherapy pattern as adherent, nonadherent, or \"unsure\" according to published pain management guidelines using a claims-based algorithm. Adherent and nonadherent populations were compared descriptively and using multivariate statistical analyses for controlling bias. RESULTS: Final cohort sizes were 441,465 OA, 76,361 GT, 10,645 pDPN, 4,010 PHN, and 150,321 FM, with adherence to guidelines found in 51.1% of OA, 25% of GT, 59.5% of pDPN, 54.9% of PHN, and 33.5% of FM. Adherent cohorts had significantly (P\u2009<\u20090.05) fewer emergency department (ED) visits and lower proportions with hospitalizations or ED visits. Mean health care costs increased following diagnosis across all conditions; however, adherent cohorts had significantly lower increases in adjusted costs pre-index to postindex (OA $5,286 vs $9,532; GT $3,631 vs $7,873; pDPN $9,578 vs $16,337; PHN $2,975 vs $5,146; FM $2,911 vs $3,708; all P\u2009<\u20090.001; adherent vs nonadherent, respectively). CONCLUSIONS: Adherence to pain management guidelines was associated with significantly lower HCRU and costs compared with nonadherence to guidelines.",
      "authors": "Margolis Jay M; Princic Nicole; Smith David M; Abraham Lucy; Cappelleri Joseph C; Shah Sonali N; Park Peter W",
      "year": "2019",
      "journal": "Pain medicine (Malden, Mass.)",
      "doi": "10.1093/pm/pnz085",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31034040/",
      "mesh_terms": "Adolescent; Adult; Aged; Aged, 80 and over; Chronic Pain; Cohort Studies; Databases, Factual; Female; Fibromyalgia; Gout; Guideline Adherence; Health Care Costs; Humans; Longitudinal Studies; Male; Middle Aged; Neuralgia; Osteoarthritis; Pain Management; Patient Compliance; Retrospective Studies; Young Adult; Drug Monitoring",
      "keywords": "Adherence; Chronic Pain; Drug Therapy; Health Care Costs; Health Care Resource Utilization; Treatment Guidelines",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "26685289",
      "title": "The Effect of Patient-Specific Cerebral Oxygenation Monitoring on Postoperative Cognitive Function: A Multicenter Randomized Controlled Trial.",
      "abstract": "BACKGROUND: Indices of global tissue oxygen delivery and utilization such as mixed venous oxygen saturation, serum lactate concentration, and arterial hematocrit are commonly used to determine the adequacy of tissue oxygenation during cardiopulmonary bypass (CPB). However, these global measures may not accurately reflect regional tissue oxygenation and ischemic organ injury remains a common and serious complication of CPB. Near-infrared spectroscopy (NIRS) is a noninvasive technology that measures regional tissue oxygenation. NIRS may be used alongside global measures to optimize regional perfusion and reduce organ injury. It may also be used as an indicator of the need for red blood cell transfusion in the presence of anemia and tissue hypoxia. However, the clinical benefits of using NIRS remain unclear and there is a lack of high-quality evidence demonstrating its efficacy and cost effectiveness. OBJECTIVE: The aim of the patient-specific cerebral oxygenation monitoring as part of an algorithm to reduce transfusion during heart valve surgery (PASPORT) trial is to determine whether the addition of NIRS to CPB management algorithms can prevent cognitive decline, postoperative organ injury, unnecessary transfusion, and reduce health care costs. METHODS: Adults aged 16 years or older undergoing valve or combined coronary artery bypass graft and valve surgery at one of three UK cardiac centers (Bristol, Hull, or Leicester) are randomly allocated in a 1:1 ratio to either a standard algorithm for optimizing tissue oxygenation during CPB that includes a fixed transfusion threshold, or a patient-specific algorithm that incorporates cerebral NIRS monitoring and a restrictive red blood cell transfusion threshold. Allocation concealment, Internet-based randomization stratified by operation type and recruiting center, and blinding of patients, ICU and ward care staff, and outcome assessors reduce the risk of bias. The primary outcomes are cognitive function 3 months after surgery and infectious complications during the first 3 months after surgery. Secondary outcomes include measures of inflammation, organ injury, and volumes of blood transfused. The cost effectiveness of the NIRS-based algorithm is described in terms of a cost-effectiveness acceptability curve. The trial tests the superiority of the patient-specific algorithm versus standard care. A sample size of 200 patients was chosen to detect a small to moderate target difference with 80% power and 5% significance (two tailed). RESULTS: Over 4 years, 208 patients have been successfully randomized and have been followed up for a 3-month period. Results are to be reported in 2015. CONCLUSIONS: This study provides high-quality evidence, both valid and widely applicable, to determine whether the use of NIRS monitoring as part of a patient-specific management algorithm improves clinical outcomes and is cost effective. TRIAL REGISTRATION: International Standard Randomized Controlled Trial Number (ISRCTN): 23557269; http://www.isrctn.com/ISRCTN23557269 (Archived by Webcite at http://www.webcitation.org/6buyrbj64).",
      "authors": "Ellis Lucy; Murphy Gavin J; Culliford Lucy; Dreyer Lucy; Clayton Gemma; Downes Richard; Nicholson Eamonn; Stoica Serban; Reeves Barnaby C; Rogers Chris A",
      "year": "2015",
      "journal": "JMIR research protocols",
      "doi": "10.2196/resprot.4562",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26685289/",
      "mesh_terms": "",
      "keywords": "asepsis; cardiac surgery; cardiopulmonary bypass; cerebral oxygenation; cognition; coronary artery; infection; randomized clinical trial; transfusion; valve",
      "pub_types": "Journal Article",
      "pmcid": "PMC4704972"
    },
    {
      "pmid": "16641664",
      "title": "A propensity score analysis of brief worksite crisis interventions after the World Trade Center disaster: implications for intervention and research.",
      "abstract": "BACKGROUND: Postdisaster crisis interventions have been viewed by some as appropriate to enhance the mental health status of persons affected by large-scale traumatic events. However, studies and systematic reviews have challenged the effectiveness of these efforts. OBJECTIVES: The focus of this study was to examine the impact of brief mental health interventions received by employees at the worksite after the World Trade Center disaster (WTCD) among workers in New York City (NYC). RESEARCH DESIGN: The data for the present study come from a prospective cohort study of 1121 employed adults interviewed by telephone in a household survey 1 year and 2 years after the WTCD. All study participants were living in NYC at the time of the attacks. For the current study, we used propensity scores to match intervention cases (n = 150) to nonintervention controls (n = 971) using a 1:5 matching ratio based on a bias-corrected nearest-neighbor algorithm. RESULTS: Approximately 7% of NYC adults (approximately 425,000 persons) reported receiving employer-sponsored, worksite crisis interventions related to the WTCD provided by mental health professionals. In addition, analyses indicated that attending 1 to 3 brief worksite sessions was associated with positive outcomes up to 2 years after the WTCD across a spectrum of results, including reduced alcohol dependence, binge drinking, depression, PTSD severity, and reduced anxiety symptoms. CONCLUSIONS: Although our study had limitations, it is one of the few to suggest that brief postdisaster crisis interventions may be effective for employees after mass exposure to psychologically traumatic events. The reasons for the effectiveness of these interventions are unclear at this time and warrant further investigation.",
      "authors": "Boscarino Joseph A; Adams Richard E; Foa Edna B; Landrigan Philip J",
      "year": "2006",
      "journal": "Medical care",
      "doi": "10.1097/01.mlr.0000207435.10138.36",
      "url": "https://pubmed.ncbi.nlm.nih.gov/16641664/",
      "mesh_terms": "Adult; Cohort Studies; Crisis Intervention; Depression; Follow-Up Studies; Health Care Surveys; Humans; New York City; Occupational Health Services; Outcome and Process Assessment, Health Care; Prospective Studies; September 11 Terrorist Attacks; Sex Distribution; Socioeconomic Factors; Stress Disorders, Post-Traumatic; Treatment Outcome",
      "keywords": "",
      "pub_types": "Evaluation Study; Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC1538970"
    },
    {
      "pmid": "10357030",
      "title": "The prevalence of depression in Alzheimer's disease and vascular dementia in a population sample.",
      "abstract": "BACKGROUND: Previous studies have shown that depression is more prevalent in vascular dementia than Alzheimer's disease (AD). Subjects for these studies were either psychiatry or neurology patients, raising the issue of whether factors leading to treatment might have introduced sampling bias. METHODS: Data for the present study came from the Canadian Study of Health and Aging (CSHA, 1994), a population-based prevalence study of dementia. AD was diagnosed using NINCDS-ADRDA criteria (McKhann et al., 1984), vascular dementia was diagnosed using draft ICD-10 criteria (World Health Organization, 1987) and the Ischemic Scale (Hachinski et al., 1975), major depression was diagnosed using an algorithm based on DSM-III-R criteria (American Psychiatric Association, 1987). The sample for the present study consisted of 481 subjects with AD and 140 with vascular dementia. RESULTS: The weighted prevalence rate of major depression was 3.2% for AD and 21.2% for vascular dementia, giving a crude odds ratio of 8.2 (95% Confidence Interval: 1.7-40.2). This finding was confirmed by a logistic regression analysis which adjusted for age, sex, place of residence (community, institution), self-reported health, severity of cognitive impairment, and antidepressant or beta-blocker use. LIMITATIONS: Data on depressive symptoms were more often missing in subjects with dementia resulting in differential loss of potential study subjects. Data on depressive symptoms were not sufficiently detailed to permit DSM-III-R criteria to be implemented rigorously. The method of diagnosing vascular dementia was subject to misclassification. CONCLUSIONS: This study confirms in a population sample that depression is more prevalent in vascular dementia compared to AD.",
      "authors": "Newman S C",
      "year": "1999",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/s0165-0327(98)00070-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/10357030/",
      "mesh_terms": "Aged; Aged, 80 and over; Alzheimer Disease; Cognition Disorders; Dementia, Vascular; Depressive Disorder; Female; Humans; Male; Neuropsychological Tests; Population Surveillance; Prevalence; Psychiatric Status Rating Scales; Severity of Illness Index",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40958968",
      "title": "Accounting for clustering for self-reported outcomes in the design and analysis of population-based surveys: A case study of estimation of prevalence of epilepsy in Nairobi, Kenya.",
      "abstract": "Population-based surveys are common for estimation of important public health metrics such as prevalence. Often, survey data tend to have a hierarchical structure where households are clustered within villages or sites and interviewers are assigned specific locations to conduct the survey. Self-reported outcomes such as diagnosis of diseases like epilepsy present more complex structure, where interviewer or physician-related effects may bias the results. Standard estimation techniques that ignore clustering may lead to underestimated standard errors and overconfident inferences. In this paper, we examine these effects for estimation of prevalence of epilepsy in a two-stage population-based survey in Nairobi and we discuss how clustering can be taken into account in design and analysis of population-based prevalence studies. We used data from the Epilepsy Pathway Innovation in Africa project conducted in Nairobi and simulated attrition levels at 10% and 20% assuming missing at random (MAR) mechanism. Attrition was accounted for using sequential k-nearest neighbor method. We adjusted the expected prevalence based on clustering at multiple levels, such as site, interviewer and household using a random effects model. Intraclass correlation (ICC) > 0.1 indicated presence of substantial clustering. We report point estimates with 95% confidence interval (CI). Crude prevalence of epilepsy was 9.40 cases per 1,000 people (95% CI: 8.60-10.20). There was substantial clustering at household level (ICC = 0.397), interviewer level (ICC = 0.101) and site level (ICC = 0.070). Prevalence adjusted for clustering at household, interviewer and site was 9.15/1,000 (95% CI 7.11-11.20). Overall, not accounting for clustering was associated with underestimation of standard errors. Not accounting for attrition on the other hand led to underestimation of prevalence. Imputation of the missing data due to attrition mitigated the attrition bias under appropriate assumptions. Accounting for clustering, particularly household, interviewer and site levels, is critical for valid estimation of standard errors in population-based surveys. Rigorous training and pre-survey testing can minimize measurement error in self-reported outcomes. Attrition can lead to underestimation of prevalence if not properly addressed. Attrition bias can be minimized by conducting targeted mobilization of participants to improve response rates and using statistical methods such as multiple imputation or machine learning-based imputation methods to address it.",
      "authors": "Mwanga Daniel M; Kipchirchir Isaac C; Muhua George O; Newton Charles R; Kadengye Damazo T",
      "year": "2025",
      "journal": "Frontiers in research metrics and analytics",
      "doi": "10.3389/frma.2025.1583476",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40958968/",
      "mesh_terms": "",
      "keywords": "clustering; epilepsy; hierarchical structure; interviewer effects; multi-level modeling; population-based surveys; prevalence",
      "pub_types": "Journal Article",
      "pmcid": "PMC12433999"
    },
    {
      "pmid": "37903120",
      "title": "Ethical and legal implications of implementing risk algorithms for early detection and screening for oesophageal cancer, now and in the future.",
      "abstract": "BACKGROUND: Oesophageal cancer has significant morbidity and mortality but late diagnosis is common since early signs of disease are frequently misinterpreted. Project DELTA aims to enable earlier detection and treatment through targeted screening using a novel risk prediction algorithm for oesophageal cancer (incorporating risk factors of Barrett's oesophagus including prescriptions for acid-reducing medications (CanPredict)), together with a non-invasive, low-cost sampling device (CytospongeTM). However, there are many barriers to implementation, and this paper identifies key ethical and legal challenges to implementing these personalised prevention strategies for Barrett's oesophagus/oesophageal cancer. METHODS: To identify ethical and legal issues relevant to the deployment of a risk prediction tool for oesophageal cancer into primary care, we adopted an interdisciplinary approach, incorporating targeted informal literature reviews, interviews with expert collaborators, a multidisciplinary workshop and ethical and legal analysis. RESULTS: Successful implementation raises many issues including ensuring transparency and effective risk communication; addressing bias and inequity; managing resources appropriately and avoiding exceptionalism. Clinicians will need support and training to use cancer risk prediction algorithms, ensuring that they understand how risk algorithms supplement rather than replace medical decision-making. Workshop participants had concerns about liability for harms arising from risk algorithms, including from potential bias and inequitable implementation. Determining strategies for risk communication enabling transparency but avoiding exceptionalist approaches are a significant challenge. Future challenges include using artificial intelligence to bolster risk assessment, incorporating genomics into risk tools, and deployment by non-health professional users. However, these strategies could improve detection and outcomes. CONCLUSIONS: Novel pathways incorporating risk prediction algorithms hold considerable promise, especially when combined with low-cost sampling. However immediate priorities should be to develop risk communication strategies that take account of using validated risk algorithms, and to ensure equitable implementation. Resolving questions about liability for harms arising should be a longer-term objective.",
      "authors": "Brigden Tanya; Mitchell Colin; Redrup Hill Elizabeth; Hall Alison",
      "year": "2023",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0293576",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37903120/",
      "mesh_terms": "Humans; Barrett Esophagus; Artificial Intelligence; Early Detection of Cancer; Esophageal Neoplasms; Risk Factors",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10615292"
    },
    {
      "pmid": "34140791",
      "title": "Risk of Thyroid Cancer Associated with Use of Liraglutide and Other Antidiabetic Drugs in a US Commercially Insured Population.",
      "abstract": "BACKGROUND: Quantify association between the glucagon-like peptide-1 receptor agonist liraglutide and risk of thyroid cancer (TC) compared to other antidiabetics. PATIENTS AND METHODS: Initiators of liraglutide, exenatide, metformin, pioglitazone or groups of dipeptidyl peptidase-4 inhibitors or sulfonylureas were identified in a US health plan (2010-2014) and followed for a median of 17\u2009months. Thyroid cancer cases during follow-up were identified via a validated algorithm. Incidence rates of TC among liraglutide and comparators were assessed using relative risks estimated within propensity score-matched cohorts using intention to treat (ITT) and time on drug analyses. Latency effects and potential surveillance bias were evaluated. RESULTS: Relative risks from ITT analyses ranged from 1.00 (95% confidence interval (CI) 0.56-1.79) versus metformin to 1.70 (95% CI 1.03-2.81) versus all comparators excluding exenatide. Effect estimates from latency analyses were slightly attenuated. Time on drug analyses suggested no increased risk for either longer duration or higher cumulative dose of liraglutide. Medical record review found 85% were papillary or a follicular variant of papillary or both; 46% were microcarcinomas (\u226410 millimeters), which were more prevalent in the liraglutide cohort (67% versus 43% in all comparators). CONCLUSION: Relative risks were elevated for several comparisons, which should be interpreted cautiously because of potential residual confounding and surveillance bias. Liraglutide cases had smaller thyroid nodules and shorter time-to-diagnosis, suggesting increased surveillance for TC among liraglutide initiators, especially shortly after the drug\u00b4s approval. After adjusting the primary analyses (ITT) for latency, no significant elevated risk of TC was observed among liraglutide initiators.",
      "authors": "Funch Donnie; Mortimer Kathleen; Ziyadeh Najat J; D Seeger John; Zhou Li; Ng Eva; Ross Douglas; Major-Pedersen Atheline; Bosch-Traberg Heidrun; Gydesen Helge; Dore David D",
      "year": "2021",
      "journal": "Diabetes, metabolic syndrome and obesity : targets and therapy",
      "doi": "10.2147/DMSO.S305496",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34140791/",
      "mesh_terms": "",
      "keywords": "administrative claims; glucagon-like peptide-1 receptor agonist; intention-to-treat; time-on-drug; type 2 diabetes",
      "pub_types": "Journal Article",
      "pmcid": "PMC8203194"
    },
    {
      "pmid": "24126796",
      "title": "Predicting utility scores for prostate cancer: mapping the Prostate Cancer Index to the Patient-Oriented Prostate Utility Scale (PORPUS).",
      "abstract": "BACKGROUND: The Prostate Cancer Index (PCI) is a health profile instrument that measures health-related quality of life with six subscales: urinary, sexual, and bowel function and bother. The Patient-Oriented Prostate Utility Scale (PORPUS-U) measures utility (0=dead and 1=full health). Utility is a preference-based approach to measure health-related quality of life, required for decision analyses and cost-effectiveness analyses. We developed a function to estimate PORPUS-U utilities from PCI scores. METHODS: The development data set included 676 community-dwelling prostate cancer (PC) survivors who completed the PCI and PORPUS-U by mail. We fit three linear regression models: one used original PORPUS-U scores and two used log-transformed PORPUS-U scores, one with a hierarchy constraint and one without. The model selection was performed using stepwise selection and fivefold cross validation. The validation data included 248 PC outpatients with three assessments on the PCI and PORPUS-U. Scores were retransformed for validation, with Duan's smearing estimator applied to correct potential bias. The predictive ability of the models was assessed with R(2), root mean square error (RMSE) and by comparing predicted and observed utilities. RESULTS: The best-fitting model used the log-transformed PORPUS-U with no hierarchy constraint. The R(2) was 0.72. The RMSE ranged from 0.040 to 0.061 for the three validation data sets. Differences between predicted and observed utilities ranged from 0.000 to 0.006 but predicted utilities overestimated the lowest 5% of observed PORPUS-U scores and underestimated the highest observed scores. CONCLUSIONS: Our algorithm can calculate PORPUS-U utility scores from PCI scores, thus supplementing descriptive quality of life measures with utility scores in PC patients. Utilities derived from mapping algorithms are useful for assigning utility to groups of patients but are less accurate at predicting utility of individual patients. We are exploring statistical methods to improve the mapping of utilities from descriptive instruments.",
      "authors": "Bremner K E; Mitsakakis N; Wilson L; Krahn M D",
      "year": "2014",
      "journal": "Prostate cancer and prostatic diseases",
      "doi": "10.1038/pcan.2013.44",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24126796/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Cohort Studies; Comorbidity; Humans; Male; Middle Aged; Models, Statistical; Neoplasm Metastasis; Prostatic Neoplasms; Quality of Life; Risk Factors; Severity of Illness Index",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37853309",
      "title": "Longitudinal plasmode algorithms to evaluate statistical methods in realistic scenarios: an illustration applied to occupational epidemiology.",
      "abstract": "INTRODUCTION: Plasmode simulations are a type of simulations that use real data to determine the synthetic data-generating equations. Such simulations thus allow evaluating statistical methods under realistic conditions. As far as we know, no plasmode algorithm has been proposed for simulating longitudinal data. In this paper, we propose a longitudinal plasmode framework to generate realistic data with both a time-varying exposure and time-varying covariates. This work was motivated by the objective of comparing different methods for estimating the causal effect of a cumulative exposure to psychosocial stressors at work over time. METHODS: We developed two longitudinal plasmode algorithms: a parametric and a nonparametric algorithms. Data from the PROspective Qu\u00e9bec (PROQ) Study on Work and Health were used as an input to generate data with the proposed plasmode algorithms. We evaluated the performance of multiple estimators of the parameters of marginal structural models (MSMs): inverse probability of treatment weighting, g-computation and targeted maximum likelihood estimation. These estimators were also compared to standard regression approaches with either adjustment for baseline covariates only or with adjustment for both baseline and time-varying covariates. RESULTS: Standard regression methods were susceptible to yield biased estimates with confidence intervals having coverage probability lower than their nominal level. The bias was much lower and coverage of confidence intervals was much closer to the nominal level when considering MSMs. Among MSM estimators, g-computation overall produced the best results relative to bias, root mean squared error and coverage of confidence intervals. No method produced unbiased estimates with adequate coverage for all parameters in the more realistic nonparametric plasmode simulation. CONCLUSION: The proposed longitudinal plasmode algorithms can be important methodological tools for evaluating and comparing analytical methods in realistic simulation scenarios. To facilitate the use of these algorithms, we provide R functions on GitHub. We also recommend using MSMs when estimating the effect of cumulative exposure to psychosocial stressors at work.",
      "authors": "Souli Youssra; Trudel Xavier; Diop Awa; Brisson Chantal; Talbot Denis",
      "year": "2023",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/s12874-023-02062-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37853309/",
      "mesh_terms": "Humans; Models, Statistical; Prospective Studies; Computer Simulation; Probability; Algorithms; Bias",
      "keywords": "Causal inference; Longitudinal data; Plasmode; Psychosocial stressors; Random forest; Regression modeling; Simulation",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10585912"
    },
    {
      "pmid": "24342484",
      "title": "Comparative evaluation of the Bio-Rad Geenius HIV-1/2 Confirmatory Assay and the Bio-Rad Multispot HIV-1/2 Rapid Test as an alternative differentiation assay for CLSI M53 algorithm-I.",
      "abstract": "INTRODUCTION: The CLSI-M53-A, Criteria for Laboratory Testing and Diagnosis of Human Immunodeficiency Virus (HIV) Infection; Approved Guideline includes an algorithm in which samples that are reactive on a 4th generation EIA screen proceed to a supplemental assay that is able to confirm and differentiate between antibodies to HIV-1 and HIV-2. The recently CE-marked Bio-Rad Geenius HIV-1/2 Confirmatory Assay was evaluated as an alternative to the FDA-approved Bio-Rad Multispot HIV-1/HIV-2 Rapid Test which has been previously validated for use in this new algorithm. METHODS: This study used reference samples submitted to the Canadian - NLHRS and samples from commercial sources. Data was tabulated in 2\u00d72 tables for statistical analysis; sensitivity, specificity, predictive values, kappa and likelihood ratios. RESULTS: The overall performance of the Geenius and Multispot was very high; sensitivity (100%, 100%), specificity (96.3%, 99.1%), positive (45.3, 181) and negative (0, 0) likelihood ratios respectively, high kappa (0.96) and low bias index (0.0068). The ability to differentiate HIV-1 (99.2%, 100%) and HIV-2 (98.1%, 98.1%) Ab was also very high. CONCLUSION: The Bio-Rad Geenius HIV-1/2 Confirmatory Assay is a suitable alternative to the validated Multispot for use in the second stage of CLSI M53 algorithm-I. The Geenius has additional features including traceability and sample and cassette barcoding that improve the quality management/assurance of HIV testing. It is anticipated that the CLSI M53 guideline and assays such as the Geenius will reduce the number of indeterminate test results previously associated with the HIV-1 WB and improve the ability to differentiate HIV-2 infections.",
      "authors": "Malloch L; Kadivar K; Putz J; Levett P N; Tang J; Hatchette T F; Kadkhoda K; Ng D; Ho J; Kim J",
      "year": "2013",
      "journal": "Journal of clinical virology : the official publication of the Pan American Society for Clinical Virology",
      "doi": "10.1016/j.jcv.2013.08.008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24342484/",
      "mesh_terms": "Algorithms; Clinical Laboratory Techniques; Diagnostic Tests, Routine; HIV Antibodies; HIV Infections; HIV-1; HIV-2; Humans; Immunoassay; Predictive Value of Tests; Sensitivity and Specificity; Virology",
      "keywords": "APHL; Ab; Ag; Algorithm; Association of Public Health Laboratories; CDC; CE; CI; CLSI; CRF; Centers for Disease Control and Prevention; Clinical and Laboratory Standards Institute; Ctrl; DNA; DPP; Dual Path Platform; EIA; European Conformity; FDA; Food and Drug Administration; GS; Geenius; HIV; HIV-1; HIV-2; IFA; IND; INNO-LIA HIV I/II Score; Inno-LIA; M53; Multispot; N/A; NAT; NEG; NLHRS; NPV; National Laboratory for HIV Reference Services; PCR; PCS; POS; PPV; RNA; SK; Saskatchewan; UNT; WB; Western blot; antibody; antigen; circulating recombinant form; confidence interval; control; deoxyribonucleic acid; enzyme immunoassay; genetic systems; glycoprotein; gp; human immunodeficiency virus; immunofluorescence assay; indeterminate; k; kappa; negative; negative predictive value; not applicable; nucleic acid testing; p; polymerase chain reaction; positive; positive predictive value; procedural control spot; protein; r-gp; recombinant glycoprotein; ribonucleic acid; sp; synthetic peptide; untypeable; w; weighted for prevalence",
      "pub_types": "Comparative Study; Evaluation Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "35615042",
      "title": "Classifying Characteristics of Opioid Use Disorder From Hospital Discharge Summaries Using Natural Language Processing.",
      "abstract": "BACKGROUND: Opioid use disorder (OUD) is underdiagnosed in health system settings, limiting research on OUD using electronic health records (EHRs). Medical encounter notes can enrich structured EHR data with documented signs and symptoms of OUD and social risks and behaviors. To capture this information at scale, natural language processing (NLP) tools must be developed and evaluated. We developed and applied an annotation schema to deeply characterize OUD and related clinical, behavioral, and environmental factors, and automated the annotation schema using machine learning and deep learning-based approaches. METHODS: Using the MIMIC-III Critical Care Database, we queried hospital discharge summaries of patients with International Classification of Diseases (ICD-9) OUD diagnostic codes. We developed an annotation schema to characterize problematic opioid use, identify individuals with potential OUD, and provide psychosocial context. Two annotators reviewed discharge summaries from 100 patients. We randomly sampled patients with their associated annotated sentences and divided them into training (66 patients; 2,127 annotated sentences) and testing (29 patients; 1,149 annotated sentences) sets. We used the training set to generate features, employing three NLP algorithms/knowledge sources. We trained and tested prediction models for classification with a traditional machine learner (logistic regression) and deep learning approach (Autogluon based on ELECTRA's replaced token detection model). We applied a five-fold cross-validation approach to reduce bias in performance estimates. RESULTS: The resulting annotation schema contained 32 classes. We achieved moderate inter-annotator agreement, with F1-scores across all classes increasing from 48 to 66%. Five classes had a sufficient number of annotations for automation; of these, we observed consistently high performance (F1-scores) across training and testing sets for drug screening (training: 91-96; testing: 91-94) and opioid type (training: 86-96; testing: 86-99). Performance dropped from training and to testing sets for other drug use (training: 52-65; testing: 40-48), pain management (training: 72-78; testing: 61-78) and psychiatric (training: 73-80; testing: 72). Autogluon achieved the highest performance. CONCLUSION: This pilot study demonstrated that rich information regarding problematic opioid use can be manually identified by annotators. However, more training samples and features would improve our ability to reliably identify less common classes from clinical text, including text from outpatient settings.",
      "authors": "Poulsen Melissa N; Freda Philip J; Troiani Vanessa; Davoudi Anahita; Mowery Danielle L",
      "year": "2022",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2022.850619",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35615042/",
      "mesh_terms": "Analgesics, Opioid; Hospitals; Humans; Natural Language Processing; Opioid-Related Disorders; Patient Discharge; Pilot Projects",
      "keywords": "deep learning; machine learning; natural language processing; opioid-related disorders; substance use; supervised learning",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9124945"
    },
    {
      "pmid": "32130188",
      "title": "Improving Exposure Assessment Methodologies for Epidemiological Studies on Pesticides: Study Protocol.",
      "abstract": "BACKGROUND: Exposure to certain pesticides has been associated with several chronic diseases. However, to determine the role of pesticides in the causation of such diseases, an assessment of historical exposures is required. Exposure measurement data are rarely available; therefore, assessment of historical exposures is frequently based on surrogate self-reported information, which has inherent limitations. Understanding the performance of the applied surrogate measures in the exposure assessment of pesticides is therefore important to allow proper evaluation of the risks. OBJECTIVE: The Improving Exposure Assessment Methodologies for Epidemiological Studies on Pesticides (IMPRESS) project aims to assess the reliability and external validity of the surrogate measures used to assign exposure within individuals or groups of individuals, which are frequently based on self-reported data on exposure determinants. IMPRESS will also evaluate the size of recall bias on the misclassification of exposure to pesticides; this in turn will affect epidemiological estimates of the effect of pesticides on human health. METHODS: The IMPRESS project will recruit existing cohort participants from previous and ongoing research studies primarily of epidemiological origin from Malaysia, Uganda, and the United Kingdom. Consenting participants of each cohort will be reinterviewed using an amended version of the original questionnaire addressing pesticide use characteristics administered to that cohort. The format and relevant questions will be retained but some extraneous questions from the original (eg, relating to health) will be excluded for ethical and practical reasons. The reliability of pesticide exposure recall over different time periods (<2 years, 6-12 years, and >15 years) will then be evaluated. Where the original cohort study is still ongoing, participants will also be asked if they wish to take part in a new exposure biomonitoring survey, which involves them providing urine samples for pesticide metabolite analysis and completing questionnaire information regarding their work activities at the time of sampling. The participant's level of exposure to pesticides will be determined by analyzing the collected urine samples for selected pesticide metabolites. The biomonitoring measurement results will be used to assess the performance of algorithm-based exposure assessment methods used in epidemiological studies to estimate individual exposures during application and re-entry work. RESULTS: The project was funded in September 2017. Enrollment and sample collection was completed for Malaysia in 2019 and is on-going for Uganda and the United Kingdom. Sample and data analysis will proceed in 2020 and the first results are expected to be submitted for publication in 2021. CONCLUSIONS: The study will evaluate the consistency of questionnaire data and accuracy of current algorithms in assessing pesticide exposures. It will indicate where amendments can be made to better capture exposure data for future epidemiology studies and thus improve the reliability of exposure-disease associations. INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): PRR1-10.2196/16448.",
      "authors": "Jones Kate; Basinas Ioannis; Kromhout Hans; van Tongeren Martie; Harding Anne-Helen; Cherrie John W; Povey Andrew; Sidek Ahmad Zulkhairul Naim; Fuhrimann Samuel; Ohlander Johan; Vermeulen Roel; Galea Karen S",
      "year": "2020",
      "journal": "JMIR research protocols",
      "doi": "10.2196/16448",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32130188/",
      "mesh_terms": "",
      "keywords": "algorithm; biomonitoring; epidemiology; occupational exposure; pesticides; questionnaire; urine",
      "pub_types": "Journal Article",
      "pmcid": "PMC7070347"
    },
    {
      "pmid": "37536424",
      "title": "Urban-rural disparities in the prevalence and trends of depressive symptoms among Chinese elderly and their associated factors.",
      "abstract": "BACKGROUND: This study aimed to examine urban-rural disparities in the prevalence and trends of depressive symptoms (DS) among Chinese elderly and associated factors. METHODS: A total of 8025, 7808, and 4887 respondents aged 60\u00a0years and above were selected from the China Family Panel Studies (CFPS) in 2016, 2018, and 2020, respectively. DS was assessed using a short version of Center for Epidemiologic Studies Depression Scale (CES-D). Twenty-two associated factors from six categories were included in random forest (RF) models. All urban-rural comparisons were conducted based on good model performance. RESULTS: The DS prevalence among all rural elderly was significantly higher than corresponding urban elderly. This disparity continued to widen among younger elderly, while it continued to narrow among older elderly. The top 10 common leading factors were sleep quality, self-rated health, life satisfaction, memory ability, child relationship, IADL disability, marital status, educational level, and gender. Urban-rural disparities in sleep quality, interpersonal trust, and child relationship continued to widen, while disparities in multimorbidity, hospitalization status, and frequency of family dinner continued to narrow. LIMITATION: This study may exist recall bias and lacks causal explanation. CONCLUSIONS: Significant and continuing disparities in the DS prevalence were observed between urban and rural elderly in China, showing opposite trends in younger and older elderly. The top 10 leading associated factors for DS were nearly consistent across urban and rural elderly, with sleep quality having strongest contribution. Urban-rural disparities in associated factors also showed different trends. This study provides a reference for mental health promotion among Chinese elderly.",
      "authors": "Wu Yu; Su Binbin; Chen Chen; Zhao Yihao; Zhong Panliang; Zheng Xiaoying",
      "year": "2023",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2023.07.117",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37536424/",
      "mesh_terms": "Aged; Humans; China; Depression; East Asian People; Educational Status; Prevalence; Rural Population; Urban Population",
      "keywords": "Depressive symptoms; Elderly; Machine learning; Random forest; Urban-rural disparity",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40706557",
      "title": "Autoencoder-Based Representation Learning for Similar Patients Retrieval From Electronic Health Records: Comparative Study.",
      "abstract": "BACKGROUND: By analyzing electronic health record snapshots of similar patients, physicians can proactively predict disease onsets, customize treatment plans, and anticipate patient-specific trajectories. However, the modeling of electronic health record data is inherently challenging due to its high dimensionality, mixed feature types, noise, bias, and sparsity. Patient representation learning using autoencoders (AEs) presents promising opportunities to address these challenges. A critical question remains: how do different AE designs and distance measures impact the quality of retrieved similar patient cohorts? OBJECTIVE: This study aims to evaluate the performance of 5 common AE variants-vanilla autoencoder, denoising autoencoder, contractive autoencoder, sparse autoencoder, and robust autoencoder-in retrieving similar patients. Additionally, it investigates the impact of different distance measures and hyperparameter configurations on model performance. METHODS: We tested the 5 AE variants on 2 real-world datasets-the University of Kansas Medical Center (n=13,752) and the Medical College of Wisconsin (n=9568)-across 168 different hyperparameter configurations. To retrieve similar patients based on the AE-produced latent representations, we applied k-nearest neighbors (k-NN) using Euclidean and Mahalanobis distances. Two prediction targets were evaluated: acute kidney injury onset and postdischarge 1-year mortality. RESULTS: Our findings demonstrate that (1) denoising autoencoders outperformed other AE variants when paired with Euclidean distance (P<.001), followed by vanilla autoencoders and contractive autoencoders; (2) learning rates significantly influenced the performance of AE variants; and (3) Mahalanobis distance-based k-NN frequently outperformed Euclidean distance-based k-NN when applied to latent representations. However, whether AE models are superior in transforming raw data into latent representations, compared with applying Mahalanobis distance-based k-NN directly to raw data, appears to be data-dependent. CONCLUSIONS: This study provides a comprehensive analysis of the performance of different AE variants in retrieving similar patients and evaluates the impact of various hyperparameter configurations on model performance. The findings lay the groundwork for future development of AE-based patient similarity estimation and personalized medicine.",
      "authors": "Li Deyi; Shukla Aditi; Chandaka Sravani; Taylor Bradley; Xu Jie; Liu Mei",
      "year": "2025",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/68830",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40706557/",
      "mesh_terms": "Humans; Electronic Health Records; Machine Learning; Information Storage and Retrieval; Autoencoder",
      "keywords": "decision support for health professionals; electronic health records; machine learning; methods and instruments in medical informatics",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": "PMC12289314"
    },
    {
      "pmid": "30822346",
      "title": "Equine syndromic surveillance in Colorado using veterinary laboratory testing order data.",
      "abstract": "INTRODUCTION: The Risk Identification Unit (RIU) of the US Dept. of Agriculture's Center for Epidemiology and Animal Health (CEAH) conducts weekly surveillance of national livestock health data and routine coordination with agricultural stakeholders. As part of an initiative to increase the number of species, health issues, and data sources monitored, CEAH epidemiologists are building a surveillance system based on weekly syndromic counts of laboratory test orders in consultation with Colorado State University laboratorians and statistical analysts from the Johns Hopkins University Applied Physics Laboratory. Initial efforts focused on 12 years of equine test records from three state labs. Trial syndrome groups were formed based on RIU experience and published literature. Exploratory analysis, stakeholder input, and laboratory workflow details were needed to modify these groups and filter the corresponding data to eliminate alerting bias. Customized statistical detection methods were sought for effective monitoring based on specialized laboratory information characteristics and on the likely presentation and animal health significance of diseases associated with each syndrome. METHODS: Data transformation and syndrome formation focused on test battery type, test name, submitter source organization, and specimen type. We analyzed time series of weekly counts of tests included in candidate syndrome groups and conducted an iterative process of data analysis and veterinary consultation for syndrome refinement and record filters. This process produced a rule set in which records were directly classified into syndromes using only test name when possible, and otherwise, the specimen type or related body system was used with test name to determine the syndrome. Test orders associated with government regulatory programs, veterinary teaching hospital testing protocols, or research projects, rather than clinical concerns, were excluded. We constructed a testbed for sets of 1000 statistical trials and applied a stochastic injection process assuming lognormally distributed incubation periods to choose an alerting algorithm with the syndrome-required sensitivity and an alert rate within the specified acceptable range for each resulting syndrome. Alerting performance of the EARS C3 algorithm traditionally used by CEAH was compared to modified C2, CuSUM, and EWMA methods, with and without outlier removal and adjustments for the total weekly number of non-mandatory tests. RESULTS: The equine syndrome groups adopted for monitoring were abortion/reproductive, diarrhea/GI, necropsy, neurological, respiratory, systemic fungal, and tickborne. Data scales, seasonality, and variance differed widely among the weekly time series. Removal of mandatory and regulatory tests reduced weekly observed counts significantly-by >80% for diarrhea/GI syndrome. The RIU group studied outcomes associated with each syndrome and called for detection of single-week signals for most syndromes with expected false-alert intervals >8 and <52 weeks, 8-week signals for neurological and tickborne monitoring (requiring enhanced sensitivity), 6-week signals for respiratory, and 4-week signals for systemic fungal. From the test-bed trials, recommended methods, settings and thresholds were derived. CONCLUSIONS: Understanding of laboratory submission sources, laboratory workflow, and of syndrome-related outcomes are crucial to form syndrome groups for routine monitoring without artifactual alerting. Choices of methods, parameters, and thresholds varied by syndrome and depended strongly on veterinary epidemiologist-specified performance requirements.",
      "authors": "Burkom Howard; Estberg Leah; Akkina Judy; Elbert Yevgeniy; Zepeda Cynthia; Baszler Tracy",
      "year": "2019",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0211335",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30822346/",
      "mesh_terms": "Algorithms; Animals; Clinical Laboratory Techniques; Colorado; Disease Outbreaks; Horse Diseases; Horses; Population Surveillance; Sentinel Surveillance",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC6396905"
    },
    {
      "pmid": "37181704",
      "title": "Recommendations to overcome barriers to the use of artificial intelligence-driven evidence in health technology assessment.",
      "abstract": "BACKGROUND: Artificial intelligence (AI) has attracted much attention because of its enormous potential in healthcare, but uptake has been slow. There are substantial barriers that challenge health technology assessment (HTA) professionals to use AI-generated evidence for decision-making from large real-world databases (e.g., based on claims data). As part of the European Commission-funded HTx H2020 (Next Generation Health Technology Assessment) project, we aimed to put forward recommendations to support healthcare decision-makers in integrating AI into the HTA processes. The barriers, addressed by the paper, are particularly focusing on Central and Eastern European (CEE) countries, where the implementation of HTA and access to health databases lag behind Western European countries. METHODS: We constructed a survey to rank the barriers to using AI for HTA purposes, completed by respondents from CEE jurisdictions with expertise in HTA. Using the results, two members of the HTx consortium from CEE developed recommendations on the most critical barriers. Then these recommendations were discussed in a workshop by a wider group of experts, including HTA and reimbursement decision-makers from both CEE countries and Western European countries, and summarized in a consensus report. RESULTS: Recommendations have been developed to address the top 15 barriers in areas of (1) human factor-related barriers, focusing on educating HTA doers and users, establishing collaborations and best practice sharing; (2) regulatory and policy-related barriers, proposing increasing awareness and political commitment and improving the management of sensitive information for AI use; (3) data-related barriers, suggesting enhancing standardization and collaboration with data networks, managing missing and unstructured data, using analytical and statistical approaches to address bias, using quality assessment tools and quality standards, improving reporting, and developing better conditions for the use of data; and (4) technological barriers, suggesting sustainable development of AI infrastructure. CONCLUSION: In the field of HTA, the great potential of AI to support evidence generation and evaluation has not yet been sufficiently explored and realized. Raising awareness of the intended and unintended consequences of AI-based methods and encouraging political commitment from policymakers is necessary to upgrade the regulatory and infrastructural environment and knowledge base required to integrate AI into HTA-based decision-making processes better.",
      "authors": "Zempl\u00e9nyi Antal; Tachkov Konstantin; Balkanyi Laszlo; N\u00e9meth Bertalan; Petyk\u00f3 Zsuzsanna Ida; Petrova Guenka; Czech Marcin; Dawoud Dalia; Goettsch Wim; Gutierrez Ibarluzea Inaki; Hren Rok; Knies Saskia; Lorenzovici L\u00e1szl\u00f3; Maravic Zorana; Piniazhko Oresta; Savova Alexandra; Manova Manoela; Tesar Tomas; Zerovnik Spela; Kal\u00f3 Zolt\u00e1n",
      "year": "2023",
      "journal": "Frontiers in public health",
      "doi": "10.3389/fpubh.2023.1088121",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37181704/",
      "mesh_terms": "Humans; Technology Assessment, Biomedical; Artificial Intelligence; Europe; Health Policy; Data Management",
      "keywords": "Central and Eastern Europe; artificial intelligence\u2014AI; evidence generation; health technology assessment; machine learning",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10171457"
    },
    {
      "pmid": "34950499",
      "title": "Public patient views of artificial intelligence in healthcare: A nominal group technique study.",
      "abstract": "OBJECTIVES: The beliefs of laypeople and medical professionals often diverge with regards to disease, and technology has had a positive impact on how research is conducted. Surprisingly, given the expanding worldwide funding and research into Artificial Intelligence (AI) applications in healthcare, there is a paucity of research exploring the public patient perspective on this technology. Our study sets out to address this knowledge gap, by applying the Nominal Group Technique (NGT) to explore patient public views on AI. METHODS: A Nominal Group Technique (NGT) was used involving four study groups with seven participants in each group. This started with a silent generation of ideas regarding the benefits and concerns of AI in Healthcare. Then a group discussion and round-robin process were conducted until no new ideas were generated. Participants ranked their top five benefits and top five concerns regarding the use of AI in healthcare. A final group consensus was reached. RESULTS: Twenty-Eight participants were recruited with the mean age of 47 years. The top five benefits were: Faster health services, Greater accuracy in management, AI systems available 24/7, reducing workforce burden, and equality in healthcare decision making. The top five concerns were: Data cybersecurity, bias and quality of AI data, less human interaction, algorithm errors and responsibility, and limitation in technology. CONCLUSION: This is the first formal qualitative study exploring patient public views on the use of AI in healthcare, and highlights that there is a clear understanding of the potential benefits delivered by this technology. Greater patient public group involvement, and a strong regulatory framework is recommended.",
      "authors": "Musbahi Omar; Syed Labib; Le Feuvre Peter; Cobb Justin; Jones Gareth",
      "year": "2021",
      "journal": "Digital health",
      "doi": "10.1177/20552076211063682",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34950499/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Digital health; Patient; Qualitative",
      "pub_types": "Journal Article",
      "pmcid": "PMC8689636"
    },
    {
      "pmid": "32556316",
      "title": "How Well Does TSTin3D Predict Risk of Active Tuberculosis in the Canadian Immigrant Population? An External Validation Study.",
      "abstract": "BACKGROUND: The online Tuberculin Skin Test/Interferon Gamma Release Assay (TST/IGRA) Interpreter V3.0 (TSTin3D), a tool for estimating the risk of active tuberculosis (TB) in individuals with latent TB infection (LTBI), has been in use for more than a decade, but its predictive performance has never been evaluated. METHODS: People with a positive TST or IGRA result from 1985 to 2015 were identified using a health data linkage that involved migrants to British Columbia, Canada. Comorbid conditions at the time of LTBI testing were identified from physician claims, hospitalizations, vital statistics, outpatient prescriptions, and kidney and HIV databases. The risk of developing active TB within 2 and 5 years was estimated using TSTin3D. The discrimination and calibration of these estimates were evaluated. RESULTS: A total of 37 163 individuals met study inclusion criteria; 10.4% were tested by IGRA. Generally, the TSTin3D algorithm assigned higher risks to demographic and clinical groups known to have higher active TB risks. Concordance estimates ranged from 0.66 to 0.68 in 2- and 5-year time frames. Comparing predicted to observed counts suggests that TSTin3D overestimates active TB risks and that overestimation increases over time (with relative bias of 3% and 12% in 2- and 5-year periods, respectively). Calibration plots also suggest that overestimation increases toward the upper end of the risk spectrum. CONCLUSIONS: TSTin3D can discriminate adequately between people who developed and did not develop active TB in this linked database of migrants with predominately positive skin tests. Further work is needed to improve TSTin3D's calibration.",
      "authors": "Puyat Joseph H; Shulha Hennady P; Balshaw Robert; Campbell Jonathon R; Law Stephanie; Menzies Richard; Johnston James C",
      "year": "2021",
      "journal": "Clinical infectious diseases : an official publication of the Infectious Diseases Society of America",
      "doi": "10.1093/cid/ciaa780",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32556316/",
      "mesh_terms": "British Columbia; Emigrants and Immigrants; Humans; Interferon-gamma Release Tests; Latent Tuberculosis; Tuberculin Test; Tuberculosis",
      "keywords": "TSTin3D; epidemiology; latent tuberculosis infection; public health; validation",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8631069"
    },
    {
      "pmid": "39481687",
      "title": "Edinburgh postpartum depression scores are associated with vaginal and gut microbiota in pregnancy.",
      "abstract": "BACKGROUND: Prenatal and postpartum depression may be influenced by the composition of host associated microbiomes. As such, the objective of this study was to elucidate the relationship between the human gut or vaginal microbiomes in pregnancy with prenatal or postpartum depression. METHODS: 140 female participants were recruited at their first prenatal visit and completed the Edinburgh Postnatal Depression Scale (EPDS) to screen for depression and anxiety, in addition the EPDS was completed one month postpartum. Vaginal and stool biospecimens were collected in the third trimester, analyzed using 16S rRNA gene sequencing, and assessed for alpha and beta diversity. Individual taxa differences and clustering using the k-medoids algorithm enabled community state type classification. RESULTS: Participants with higher postpartum EPDS scores had higher species richness and lower abundance of L. crispatus in the vaginal microbiota compared to those with lower EPDS scores. Participants with a higher prenatal EPDS score had lower species richness of the gut microbiome. Participants with a vaginal community state type dominated by L. iners had the highest mean prenatal EPDS scores, whereas postpartum EPDS scores were similar regardless of prenatal vaginal state type. LIMITATIONS: Our small sample size and participant's self-report bias limits generalizability of results. CONCLUSIONS: Depression in the prenatal and postpartum period is associated with the composition and diversity of the gut and vaginal microbiomes in the third trimester of pregnancy. These results provide a foundational understanding of the microbial relationships between maternal health and depression for identifying potential therapeutic treatments.",
      "authors": "Nel Nikita H; Marafie Anfal; Bassis Christine M; Sugino Kameron Y; Nzerem Adannaya; Knickmeyer Rebecca R; McKee Kimberly S; Comstock Sarah S",
      "year": "2025",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2024.10.086",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39481687/",
      "mesh_terms": "Humans; Female; Pregnancy; Depression, Postpartum; Vagina; Adult; Gastrointestinal Microbiome; RNA, Ribosomal, 16S; Feces; Psychiatric Status Rating Scales; Microbiota; Pregnancy Complications; Young Adult",
      "keywords": "Depression; Gut; Mental health; Microbiome; Pregnancy; Vaginal",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40101246",
      "title": "Novel composite health assessment risk model for older allogeneic transplant recipients: BMT-CTN 1704.",
      "abstract": "Allogeneic hematopoietic cell transplantation (allo-HCT) is potentially curative for older adults with hematologic malignancies. Concerns on nonrelapse mortality (NRM) in older adults limit allo-HCT utilization. We executed a prospective, observational study BMT-CTN 1704 (Blood and Marrow Transplant Clinical Trials Network) enrolling allo-HCT recipients aged \u226560 years from 49 centers in the United States. We analyzed associations between 13 measurements of older adult health and NRM within 1 year to construct a comprehensive health assessment risk model (primary-CHARM) using multivariate Fine-Gray model and grouped penalized variable selection. Two machine learning (ML) models (Cox and pseudo-value boosting) were also explored. Models' performances were compared using area under the curve (AUC), with bootstrap and cross-validation sampling to correct for optimism, decision curve analysis (DCA), calibration, and Brier scores. Among 1105 patients with median age of 67 (range, 60-82) years who received allo-HCT, NRM was 14.4% and overall survival (OS) 71.7% at 1 year. Factors statistically selected for inclusion in primary-CHARM were higher comorbidity burden, lower albumin, higher C-reactive protein, older age, higher weight-loss percentage, lower patient-reported performance score, and cognitive impairment. Primary-CHARM scores were independently associated with higher NRM (hazard ratio [HR], 2.72; P < .0001) and worse OS (HR, 2.09; P < .0001). Bootstrap bias-corrected AUC for primary-CHARM was 0.591. Comparing primary-CHARM with HCT-comorbidity index and 2 ML-CHARM models, calibration, Brier score, and DCA analysis favored primary-CHARM. Primary-CHARM, with mostly simple and readily available parameters, risk stratifies older adults for allo-HCT. Adopting primary-CHARM in practice may promote broader use of HCT by quantifying risk and enhance the design of strategies to improve outcomes. This trial was registered at www.ClinicalTrials.gov as #NCT03992352.",
      "authors": "Sorror Mohamed L; Saber Wael; Logan Brent; Geller Nancy; Bellach Anna; Kou Jianqun; Wood William; McCarty John M; Knight Thomas G; Runaas Lyndsey; Johnston Laura; Walston Jeremy; Nakamura Ryotaro; Jarrett Lori; Mishra Asmita; Uberti Joseph; Dahi Parastoo B; Saultz Jennifer N; McCurdy Shannon R; Morris Lawrence E; Imus Philip H; Hogan William J; Nadiminti Kalyan; Bhatt Vijaya Raj; Olin Rebecca; Maakaron Joseph; Sobecks Ronald; Wall Sarah A; Mattila Deborah; Protz Bailey; Devine Steven M; Horowitz Mary M; Artz Andrew S",
      "year": "2025",
      "journal": "Blood advances",
      "doi": "10.1182/bloodadvances.2025015793",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40101246/",
      "mesh_terms": "Humans; Aged; Female; Male; Middle Aged; Transplantation, Homologous; Risk Assessment; Hematopoietic Stem Cell Transplantation; Aged, 80 and over; Prospective Studies; Bone Marrow Transplantation; Transplant Recipients; Hematologic Neoplasms",
      "keywords": "",
      "pub_types": "Journal Article; Observational Study; Multicenter Study",
      "pmcid": "PMC12246602"
    },
    {
      "pmid": "39603161",
      "title": "Ecological analysis of air particulate matter exposure and depression among adolescents in developing regions of Hubei, China.",
      "abstract": "BACKGROUND: Adolescent depression is a health issue influenced by various factors, with the impact of environmental factors, particularly air pollution, being insufficiently understood. This study investigates the relationship between particulate matter (PM2.5) and adolescent mental health. METHODS: A survey of middle school students in two rural counties of Hubei Province-Tongcheng and Lichuan-was conducted using multi-stage probability sampling. Data on demographics, mental health, and social conditions were collected via self-administered questionnaires. PM2.5 exposure levels were obtained from the NASA Giovanni database using a two-step machine learning model. Depression levels were measured with the PHQ-9 scale. Generalized linear regression and structural equation modeling were used to analyze the relationship between PM2.5 and depression. RESULTS: The study included 2780 valid responses (mean age 13.49 years, 52.73% male). The findings indicated a correlation between PM2.5 exposure, left-behind children status, and negative coping strategies with higher PHQ-9 scores. Each unit increase in PM2.5 was associated with a 1.004 increase in the PHQ-9 score (P\u00a0<\u00a00.01). Left-behind children had scores 1.023 times higher than their peers (P\u00a0=\u00a00.039), while positive coping correlated with lower scores (RR\u00a0=\u00a00.855, P\u00a0<\u00a00.001). The influence of PM2.5 on depression was fully indirect, mediated by personal traits and family/community environments (\u03b2\u00a0=\u00a0-0.003, P\u00a0=\u00a00.855). LIMITATIONS: The cross-sectional design limits causal inferences, and self-reporting may introduce bias. The focus on middle schoolers from two counties may limit broader applicability. CONCLUSIONS: This research underscores the complex factors contributing to adolescent depression, with individual characteristics playing a crucial role. The impact of air pollution on depression is mediated by personal traits and the community environment.",
      "authors": "Chen Juntao; Zhou Suhua; Zhang Yifan; Huang Shiqi; Li Peizheng; Yang Chenlu; Zhang Qingyu; Li Xiangying; Luo Chenxi; Lin Jing; Diao Jiayi; Zhong Kehan; Hu Yuqi; Zhang Rui; Ma Lu",
      "year": "2025",
      "journal": "Journal of psychiatric research",
      "doi": "10.1016/j.jpsychires.2024.11.052",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39603161/",
      "mesh_terms": "Humans; Male; Particulate Matter; Adolescent; China; Female; Depression; Environmental Exposure; Air Pollution; Rural Population; Child; Air Pollutants",
      "keywords": "Adolescent depression; Ecological factors; PM(2.5); Structural equation modeling",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34417009",
      "title": "Prediction and pattern analysis of medication refill adherence through electronic health records and dispensation data.",
      "abstract": "BACKGROUND AND PURPOSE: Low adherence to medication in chronic disease patients leads to increased morbidity, mortality, and healthcare costs. The widespread adoption of electronic prescription and dispensation records allows a more comprehensive overview of medication utilization. In combination with electronic health records (EHR), such data provides new opportunities for identifying patients at risk of nonadherence and provide more targeted and effective interventions. The purpose of this article is to study the predictability of medication adherence for a cohort of hypertensive patients, focusing on healthcare utilization factors under various predictive scenarios. Furthermore, we discover common proportion of days covered patterns (PDC-patterns) for patients with index prescriptions and simulate medication-taking behaviours that might explain observed patterns. PROCEDURES: We predict refill adherence focusing on factors of healthcare utilization, such as visits, prescription information and demographics of patient and prescriber. We train models with machine learning algorithms, using four different data splits: stratified random, patient, temporal forward prediction with and without index patients. We extract frequent, two-year long PDC-patterns using K-means clustering and investigate five simple models of medication-taking that can generate such PDC-patterns. FINDINGS: Model performance varies between data splits (AUC test set: 0.77-0.89). Including historical information increases the performance slightly in most cases (approx. 1-2% absolute AUC uplift). Models show low predictive performance (AUC test set: 0.56-0.66) on index-prescriptions and patients with sudden drops in PDC (Recall: 0.58-0.63). We find 21 distinct two-year PDC-patterns, ranging from good adherence to intermittent gaps and early discontinuation in the first or second year. Simulations show that observed PDC-patterns can only be explained by specific medication consumption behaviours. CONCLUSIONS: Prediction models developed using EHR exhibit bias towards patients with high healthcare utilization. Even though actual medication-taking is not observable, consumption patterns may not be as arbitrary, provided that medication refilling and consumption is linked.",
      "authors": "Galozy Alexander; Nowaczyk Slawomir",
      "year": "2020",
      "journal": "Journal of biomedical informatics",
      "doi": "10.1016/j.yjbinx.2020.100075",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34417009/",
      "mesh_terms": "",
      "keywords": "Electronic health records; Medication refill adherence; Prediction; Refill patterns; Simulation",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "29880698",
      "title": "Evidence synthesis software.",
      "abstract": "It can be challenging to decide which evidence synthesis software to choose when doing a systematic review. This article discusses some of the important questions to consider in relation to the chosen method and synthesis approach. Software can support researchers in a range of ways. Here, a range of review conditions and software solutions. For example, facilitating contemporaneous collaboration across time and geographical space; in-built bias assessment tools; and line-by-line coding for qualitative textual analysis. EPPI-Reviewer is a review software for research synthesis managed by the EPPI-centre, UCL Institute of Education. EPPI-Reviewer has text mining automation technologies. Version 5 supports data sharing and re-use across the systematic review community. Open source software will soon be released. EPPI-Centre will continue to offer the software as a cloud-based service. The software is offered via a subscription with a one-month (extendible) trial available and volume discounts for 'site licences'. It is free to use for Cochrane and Campbell reviews. The next EPPI-Reviewer version is being built in collaboration with National Institute for Health and Care Excellence using 'surveillance' of newly published research to support 'living' iterative reviews. This is achieved using a combination of machine learning and traditional information retrieval technologies to identify the type of research each new publication describes and determine its relevance for a particular review, domain or guideline. While the amount of available knowledge and research is constantly increasing, the ways in which software can support the focus and relevance of data identification are also developing fast. Software advances are maximising the opportunities for the production of relevant and timely reviews.",
      "authors": "Park Sophie Elizabeth; Thomas James",
      "year": "2018",
      "journal": "BMJ evidence-based medicine",
      "doi": "10.1136/bmjebm-2018-110962",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29880698/",
      "mesh_terms": "Data Mining; Humans; Information Storage and Retrieval; Machine Learning; Software; Systematic Reviews as Topic",
      "keywords": "information management; world wide web technology",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39558943",
      "title": "Effects of individual characteristics and seasonality and their interaction on ectoparasite load of Daurian ground squirrels in Inner Mongolia, China.",
      "abstract": "Understanding the drivers of parasite distribution is vital for ecosystem health, disease management, and vector monitoring. While studies note the impact of host sex, size, behavior, and season on parasite load, concurrent assessments of these factors and their interactions are limited. During the spring, summer and autumn seasons from 2021 to 2023, we trapped Daurian ground squirrel (Spermophilus dauricus), a small rodent species that inhabits eastern Asian grasslands in Inner Mongolia and collected their ectoparasites. Using machine learning Lasso regression, we pinpointed factors affecting tick and flea abundance on S. dauricus. We then analyzed these factors and their seasonal interactions with a mixed negative binomial generalized linear model. Our study revealed significant but inconsistent seasonal effects on the load of ectoparasites. The tick load was significantly higher in spring and summer compared to autumn, while the flea load was higher in summer and autumn but lacked statistical significance. Furthermore, individual factors that influence the flea and tick load were moderated by seasonal effects, with a male bias in flea parasitism observed in spring. Significant interactions were also found among seasonality, sex, and body weight. The load of male squirrel fleas was positively correlated with body weight, with the highest increase observed in spring. On the contrary, the flea load of female squirrels showed a negative correlation with body weight, significantly decreasing in the autumn with increasing weight. Significant interactions were observed between season and survival status, with hosts exhibiting higher tick load during autumn survival. Our findings underscore the importance of considering seasonal variation in parasitism and the interactions between seasonal dynamics and host biological traits in shaping parasite distributions.",
      "authors": "Wang Xiaoxu; Shang Meng; Wang Zihao; Ji Haoqiang; Wang Zhenxu; Mo Guangju; Liu Qiyong",
      "year": "2024",
      "journal": "International journal for parasitology. Parasites and wildlife",
      "doi": "10.1016/j.ijppaw.2024.101014",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39558943/",
      "mesh_terms": "",
      "keywords": "Daurian ground squirrels; Flea load; Seasonal effect; Tick load; individual characteristics",
      "pub_types": "Journal Article",
      "pmcid": "PMC11570501"
    },
    {
      "pmid": "33692222",
      "title": "Texture Analysis in Brain Tumor MR Imaging.",
      "abstract": "Texture analysis, as well as its broader category radiomics, describes a variety of techniques for image analysis that quantify the variation in surface intensity or patterns, including some that are imperceptible to the human visual system. Cerebral gliomas have been most rigorously studied in brain tumors using MR-based texture analysis (MRTA) to determine the correlation of various clinical measures with MRTA features. Promising results in cerebral gliomas have been shown in the previous MRTA studies in terms of the correlation with the World Health Organization grades, risk stratification in gliomas, and the differentiation of gliomas from other brain tumors. Multiple MRTA studies in gliomas have repeatedly shown high performance of entropy, a measure of the randomness in image intensity values, of either histogram- or gray-level co-occurrence matrix parameters. Similarly, researchers have applied MRTA to other brain tumors, including meningiomas and pediatric posterior fossa tumors.However, the value of MRTA in the clinical use remains undetermined, probably because previous studies have shown only limited reproducibility of the result in the real world. The low-to-modest generalizability may be attributed to variations in MRTA methods, sampling bias that originates from single-institution studies, and overfitting problems to a limited number of samples.To enhance the reliability and reproducibility of MRTA studies, researchers have realized the importance of standardizing methods in the field of radiomics. Another advancement is the recent development of a comprehensive assessment system to ensure the quality of a radiomics study. These two-way approaches will secure the validity of upcoming MRTA studies. The clinical use of texture analysis in brain MRI will be accelerated by these continuous efforts.",
      "authors": "Kunimatsu Akira; Yasaka Koichiro; Akai Hiroyuki; Sugawara Haruto; Kunimatsu Natsuko; Abe Osamu",
      "year": "2022",
      "journal": "Magnetic resonance in medical sciences : MRMS : an official journal of Japan Society of Magnetic Resonance in Medicine",
      "doi": "10.2463/mrms.rev.2020-0159",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33692222/",
      "mesh_terms": "Brain Neoplasms; Child; Glioma; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Reproducibility of Results; Retrospective Studies",
      "keywords": "glioblastoma; machine learning; magnetic resonance imaging; radiomics; texture analysis",
      "pub_types": "Journal Article",
      "pmcid": "PMC9199980"
    },
    {
      "pmid": "39977323",
      "title": "Learning-based inference of longitudinal image changes: Applications in embryo development, wound healing, and aging brain.",
      "abstract": "Longitudinal imaging data are routinely acquired for health studies and patient monitoring. A central goal in longitudinal studies is tracking relevant change over time. Traditional methods remove nuisance variation with custom pipelines to focus on significant changes. In this work, we present a machine learning-based method that automatically ignores irrelevant changes and extracts the time-varying signal of interest. Our method, called Learning-based Inference of Longitudinal imAge Changes (LILAC), performs a pairwise comparison of longitudinal images in order to make a temporal difference prediction. LILAC employs a convolutional Siamese architecture to extract feature pairs, followed by subtraction and a bias-free fully connected layer to learn meaningful temporal image differences. We first showcase LILAC's ability to capture key longitudinal changes by simply training it to predict the temporal ordering of images. In our experiments, temporal ordering accuracy exceeded 0.98, and predicted time differences were strongly correlated with actual changes in relevant variables (Pearson Correlation Coefficient r = 0.911 with embryo phase change, and r = 0.875 with time interval in wound healing). Next, we trained LILAC to explicitly predict specific targets, such as the change in clinical scores in patients with mild cognitive impairment. LILAC models achieved over a 40% reduction in root mean square error compared to baseline methods. Our empirical results demonstrate that LILAC effectively localizes and quantifies relevant individual-level changes in longitudinal imaging data, offering valuable insights for studying temporal mechanisms or guiding clinical decisions.",
      "authors": "Kim Heejong; Karaman Batuhan K; Zhao Qingyu; Wang Alan Q; Sabuncu Mert R",
      "year": "2025",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "doi": "10.1073/pnas.2411492122",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39977323/",
      "mesh_terms": "Humans; Brain; Wound Healing; Longitudinal Studies; Machine Learning; Aging; Embryonic Development; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Female",
      "keywords": "deep learning; longitudinal image analysis; medical image analysis",
      "pub_types": "Journal Article",
      "pmcid": "PMC11873959"
    },
    {
      "pmid": "36307139",
      "title": "Global diabetes burden: analysis of regional differences to improve diabetes care.",
      "abstract": "INTRODUCTION: The current evaluation processes of the burden of diabetes are incomplete and subject to bias. This study aimed to identify regional differences in the diabetes burden on a universal level from the perspective of people with diabetes. RESEARCH DESIGN AND METHODS: We developed a worldwide online diabetes observatory based on 34\u2009million diabetes-related tweets from 172 countries covering 41 languages, spanning from 2017 to 2021. After translating all tweets to English, we used machine learning algorithms to remove institutional tweets and jokes, geolocate users, identify topics of interest and quantify associated sentiments and emotions across the seven World Bank regions. RESULTS: We identified four topics of interest for people with diabetes (PWD) in the Middle East and North Africa and another 18 topics in North America. Topics related to glycemic control and food are shared among six regions of the world. These topics were mainly associated with sadness (35% and 39% on average compared with levels of sadness in other topics). We also revealed several region-specific concerns (eg, insulin pricing in North America or the burden of daily diabetes management in Europe and Central Asia). CONCLUSIONS: The needs and concerns of PWD vary significantly worldwide, and the burden of diabetes is perceived differently. Our results will support better integration of these regional differences into diabetes programs to improve patient-centric diabetes research and care, focused on the most relevant concerns to enhance personalized medicine and self-management of PWD.",
      "authors": "Bour Charline; Ahne Adrian; Aguayo Gloria; Fischer Aur\u00e9lie; Marcic David; Kayser Philippe; Fagherazzi Guy",
      "year": "2022",
      "journal": "BMJ open diabetes research & care",
      "doi": "10.1136/bmjdrc-2022-003040",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36307139/",
      "mesh_terms": "Humans; Machine Learning; Europe; Diabetes Mellitus; Middle East; North America",
      "keywords": "algorithms; patient reported outcome measures; patient-centered care; population health",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9621169"
    },
    {
      "pmid": "32223046",
      "title": "Interpretation biases and visual attention in the processing of ambiguous information in chronic pain.",
      "abstract": "BACKGROUND: Theories propose that interpretation biases and attentional biases might account for the maintenance of chronic pain symptoms, but the interactions between these two forms of biases in the context of chronic pain are understudied. METHODS: To fill this gap, 63 participants (40 females) with and without chronic pain completed an interpretation bias task that measures participants' interpretation styles in ambiguous scenarios and a novel eye-tracking task where participants freely viewed neutral faces that were given ambiguous pain/health-related labels (i.e. 'doctor', 'patient' and 'healthy people'). Eye movements were analysed with the Hidden Markov Models (EMHMM) approach, a machine-learning data-driven method that clusters people's eye movements into different strategy subgroups. RESULTS: Adults with chronic pain endorsed more negative interpretations for scenarios related to immediate bodily injury and long-term illness than healthy controls, but they did not differ significantly in terms of their eye movements on ambiguous faces. Across groups, people who interpreted illness-related scenarios in a more negative way also focused more on the nose region and less on the eye region when looking at patients' and healthy people's faces and, to a lesser extent, doctors' faces. This association between interpretive and attentional processing was particularly apparent in participants with chronic pain. CONCLUSIONS: In summary, the present study provided evidence for the interplay between multiple forms of cognitive biases. Future studies should investigate whether this interaction might influence subsequent functioning in people with chronic pain.",
      "authors": "Chan Frederick H F; Suen Hin; Hsiao Janet H; Chan Antoni B; Barry Tom J",
      "year": "2020",
      "journal": "European journal of pain (London, England)",
      "doi": "10.1002/ejp.1565",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32223046/",
      "mesh_terms": "Adult; Attentional Bias; Bias; Chronic Pain; Eye Movements; Female; Humans",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "12957778",
      "title": "Integrating classification trees with local logistic regression in Intensive Care prognosis.",
      "abstract": "Health care effectiveness and efficiency are under constant scrutiny especially when treatment is quite costly as in the Intensive Care (IC). Currently there are various international quality of care programs for the evaluation of IC. At the heart of such quality of care programs lie prognostic models whose prediction of patient mortality can be used as a norm to which actual mortality is compared. The current generation of prognostic models in IC are statistical parametric models based on logistic regression. Given a description of a patient at admission, these models predict the probability of his or her survival. Typically, this patient description relies on an aggregate variable, called a score, that quantifies the severity of illness of the patient. The use of a parametric model and an aggregate score form adequate means to develop models when data is relatively scarce but it introduces the risk of bias. This paper motivates and suggests a method for studying and improving the performance behavior of current state-of-the-art IC prognostic models. Our method is based on machine learning and statistical ideas and relies on exploiting information that underlies a score variable. In particular, this underlying information is used to construct a classification tree whose nodes denote patient sub-populations. For these sub-populations, local models, most notably logistic regression ones, are developed using only the total score variable. We compare the performance of this hybrid model to that of a traditional global logistic regression model. We show that the hybrid model not only provides more insight into the data but also has a better performance. We pay special attention to the precision aspect of model performance and argue why precision is more important than discrimination ability.",
      "authors": "Abu-Hanna Ameen; de Keizer Nicolette",
      "year": "2003",
      "journal": "Artificial intelligence in medicine",
      "doi": "10.1016/s0933-3657(03)00047-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/12957778/",
      "mesh_terms": "Artificial Intelligence; Decision Trees; Humans; Intensive Care Units; Logistic Models; Prognosis; Quality of Health Care; Reproducibility of Results; Sensitivity and Specificity; Severity of Illness Index",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40811578",
      "title": "Association between sleep and physical activity data, and depressive symptoms in Thai elderly.",
      "abstract": "BACKGROUND: Geriatric depression often goes unnoticed due to recall bias and overlapping symptoms with normal aging by using questionnaire screening tool. Consequently, this study aims to explore the associations between passive sensing parameters, such as physical activity and sleep characteristics collected from smart devices, and depression screening scores, aiming to validate its efficacy as a detection tool for the Thai elderly. METHODS: The prospective cohort study was conducted from July to September 2023. One hundred and seventy-seven elderly individuals were purposefully selected from the main districts of each province across five regions in Thailand. Inclusion criteria required participants to be aged 60 years or older, socially active, and free from diagnoses of cognitive impairment and mental health disorders. Participants were required to wear an Actigraph wGT3X-BT collecting data on physical activity and sleep characteristics. The Patient Health Questionnaire (PHQ-9) was used to screen for depression every two weeks. Univariate and multivariate regression analyses were performed to identify association between passive sensing parameters and PHQ-9. RESULTS: There is an association between physical activity parameters and depression score. A One- unit increase in Vector Magnitude in Counts per Minute (VM CPM) and step count, PHQ-9 score would be statistically significant reduced by 0.001 and 0.00007 to 0.00008 score over both two-week periods (p-value <0.1). Only Wakefulness After Sleep Onset (WASO) of all sleep variables showed an association with PHQ-9 in univariate analysis but it did not show further relationship after adjusting with baseline PHQ-9 score and other confounders. In addition, participants who lived outside Bangkok and being younger were more likely to have lower PHQ-9 score. CONCLUSION: There is a potential to apply passive sensing data in mental health issues in Thailand. However, more evidence is needed to ensure the accuracy of sensor detection and appropriate algorithm to predict depression. Moreover, the implication of passive sensing data from smart devices supporting public health policy should be explored.",
      "authors": "Kosiyaporn Hathairat; Thiphong Jiranun; Waleewong Orratai; Adhibai Rujira; Cheujew Supika; Cetthakrikul Nisachol; Nasueb Sopit; Makchang Kamolphat; Pumsutas Yanisa; Suosot Patjirapohn",
      "year": "2025",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0329978",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40811578/",
      "mesh_terms": "Humans; Male; Female; Aged; Thailand; Exercise; Depression; Sleep; Prospective Studies; Middle Aged; Aged, 80 and over; Actigraphy; Surveys and Questionnaires; Southeast Asian People",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12352767"
    },
    {
      "pmid": "35956344",
      "title": "Validating Accuracy of an Internet-Based Application against USDA Computerized Nutrition Data System for Research on Essential Nutrients among Social-Ethnic Diets for the E-Health Era.",
      "abstract": "Internet-based applications (apps) are rapidly developing in the e-Health era to assess the dietary intake of essential macro-and micro-nutrients for precision nutrition. We, therefore, validated the accuracy of an internet-based app against the Nutrition Data System for Research (NDSR), assessing these essential nutrients among various social-ethnic diet types. The agreement between the two measures using intraclass correlation coefficients was good (0.85) for total calories, but moderate for caloric ranges outside of <1000 (0.75) and >2000 (0.57); and good (>0.75) for most macro- (average: 0.85) and micro-nutrients (average: 0.83) except cobalamin (0.73) and calcium (0.51). The app underestimated nutrients that are associated with protein and fat (protein: \u22125.82%, fat: \u221212.78%, vitamin B12: \u221213.59%, methionine: \u22128.76%, zinc: \u221212.49%), while overestimated nutrients that are associated with carbohydrate (fiber: 6.7%, B9: 9.06%). Using artificial intelligence analytics, we confirmed the factors that could contribute to the differences between the two measures for various essential nutrients, and they included caloric ranges; the differences between the two measures for carbohydrates, protein, and fat; and diet types. For total calories, as an example, the source factors that contributed to the differences between the two measures included caloric range (<1000 versus others), fat, and protein; for cobalamin: protein, American, and Japanese diets; and for folate: caloric range (<1000 versus others), carbohydrate, and Italian diet. In the e-Health era, the internet-based app has the capacity to enhance precision nutrition. By identifying and integrating the effects of potential contributing factors in the algorithm of output readings, the accuracy of new app measures could be improved.",
      "authors": "Yang Ya-Ling; Yang Hsiao-Ling; Kusuma Joyce D; Shiao Shyang-Yun Pamela Koong",
      "year": "2022",
      "journal": "Nutrients",
      "doi": "10.3390/nu14153168",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35956344/",
      "mesh_terms": "Artificial Intelligence; Carbohydrates; Diet; Energy Intake; Internet; Nutrients; Telemedicine; United States; United States Department of Agriculture; Vitamin B 12",
      "keywords": "Nutrition Data System for Research (NDSR); agreement and bias; dietary record; e-Health; generalized regression; internet-based applications; mobile app; personalized nutrition; social-ethnic diets",
      "pub_types": "Journal Article",
      "pmcid": "PMC9370220"
    },
    {
      "pmid": "38542739",
      "title": "The Use of Three-Dimensional Images and Food Descriptions from a Smartphone Device Is Feasible and Accurate for Dietary Assessment.",
      "abstract": "Technology-assisted dietary assessment has the potential to improve the accuracy of self-reported dietary intake. This study evaluates MealScan3D (MS3D), a mobile device-based food recording system, which uses three-dimensional images to obtain food volumes and an application to capture algorithm-driven food intake data. Participants (n = 179) were randomly assigned and trained to record three meals using either MS3D or a written food record (WFR). Generous amounts of standardized meals were provided, and participants self-selected portions for each food. The weights of provided and uneaten/leftover foods were used to determine true intake. For total energy intake (three meals combined), validity (Pearson correlation) was significantly higher for MS3D vs. the WFR (p < 0.001); when interpreted as the percentage of variance in energy intake explained, MS3D explained 84.6% of true variance, a 25.3% absolute and 42.6% relative increase over the 59.3% explained by the WFR. For 9 of 15 individual foods, the Pearson correlations between true and reported portion size estimates were significantly larger for MS3D than the WFR. Bias was smaller (intercepts were closer to the means) for 9 of 15 foods and the regression coefficients for 10 of 15 foods were significantly closer to 1.0 in the MS3D arm. MS3D is feasible for dietary assessment and may provide improvements in accuracy compared to WFRs.",
      "authors": "Schenk Jeannette M; Boynton Alanna; Kulik Pavel; Zyuzin Alexei; Neuhouser Marian L; Kristal Alan R",
      "year": "2024",
      "journal": "Nutrients",
      "doi": "10.3390/nu16060828",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38542739/",
      "mesh_terms": "Humans; Smartphone; Nutrition Assessment; Imaging, Three-Dimensional; Diet Records; Energy Intake; Meals; Reproducibility of Results",
      "keywords": "dietary assessment; dietary intake; food records; mHealth; public health; technology-assisted dietary assessment",
      "pub_types": "Randomized Controlled Trial; Journal Article",
      "pmcid": "PMC10976213"
    },
    {
      "pmid": "35458898",
      "title": "Sensor Fault Diagnostics Using Physics-Informed Transfer Learning Framework.",
      "abstract": "The field of smart health monitoring, intelligent fault detection and diagnosis is expanding dramatically in order to maintain successful operation in many engineering applications. Considering possible fault scenarios that can occur in a system, indicating the type of fault in a sensor is one of the most important and challenging problems in the area of intelligent sensor fault diagnostics. Within this frame of reference, we extended the physics-informed transfer learning framework, first presented previously for a fault cause assignment, to the level of sensor fault diagnostics for a range of different fault scenarios. Hence, the framework is utilized to perform intelligent sensor fault diagnostics for the first time. The underlying dynamics of the reference system are extracted using a completely data-driven methodology and dynamic mode decomposition with control (DMDc) in order to generate time-frequency illustrations of each sample with continuous wavelet transform (CWT). Then, sensor fault diagnostics for bias, drift over time, sine disturbance and increased noise sensor fault scenarios are achieved using the idea of transfer learning with a pre-trained image classification algorithm. The classification results yields a good performance on sensor fault diagnostics with 91.5% training and 84.7% test accuracy along with a fair robustness level with a set of reference benchmark system parameters.",
      "authors": "Guc Furkan; Chen Yangquan",
      "year": "2022",
      "journal": "Sensors (Basel, Switzerland)",
      "doi": "10.3390/s22082913",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35458898/",
      "mesh_terms": "Algorithms; Machine Learning; Neural Networks, Computer; Physics; Wavelet Analysis",
      "keywords": "data-driven approaches; dynamic mode decomposition with control; fault diagnostics; transfer learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC9032931"
    },
    {
      "pmid": "40419565",
      "title": "AI-assisted technology optimization in disability support systems using fuzzy rough MABAC decision-making.",
      "abstract": "The selection of AI-assistive technologies for disability support systems involves a complex decision-making problem due to the presence of uncertain evaluation criteria. The traditional methods of decision-making often do not succeed in addressing the challenges leading to potential inefficiencies in resource allocation. Aggregation operators are the fundamental tool to manage overall information into a single value. This characteristic of aggregation operators helps in ranking processes and decision-making scenarios. To overcome the issues of uncertainty and keep in mind the advantages of AOs, in this article, we have proposed the notion of fuzzy rough Maclaurin symmetric mean (FRMSM) aggregation theory. The MSM AOs reduce the sensitivity in huge amounts of data due to symmetric formulation. As a result, more accurate and authentic results can be obtained. As the MABAC approach uses border approximation area, so this characteristic reduces the bias and improves the accuracy. Therefore, we have proposed the MABAC approach based on FRMSMS AOs. For the application of the proposed work, we have delivered an algorithm and initiated an illustrative example. We have utilized the proposed work for the optimization of AI-assisted technologies in disability support systems. Thus, it shows its potential for dealing with the problems arising from the selection process of inherent challenges and will offer a reliable tool to the stakeholders in the health and assistive technology design sectors. Additionally, we have proposed a comparative analysis of the initiated approach and discussed that the introduced approach is more reliable and trustable as compared to existing notions.",
      "authors": "Ahmmad Jabbar; Al-Dayel Osamah AbdulAziz; Khan Meraj Ali; Mahmood Tahir",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-02362-8",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40419565/",
      "mesh_terms": "",
      "keywords": "AI-assistive technologies; Fuzzy rough MABAC approach; Maclaurin symmetric means aggregation operators",
      "pub_types": "Journal Article",
      "pmcid": "PMC12106766"
    },
    {
      "pmid": "15663883",
      "title": "Pediatric hospitalizations for asthma: use of a linked file to separate person-level risk and readmission.",
      "abstract": "INTRODUCTION: Disparities in asthma hospitalization by gender, age, and race/ethnicity are thought to be driven by a combination of 2 factors: disease severity and inadequate health care. Hospitalization data that fail to differentiate between numbers of admissions and numbers of individuals limit the ability to derive accurate conclusions about disparities and risks. METHODS: Hospitalization records for pediatric asthma patients (aged one to 14 years) were extracted from New Jersey Hospital Discharge Files (for the years 1994 through 2000) and then linked by patient identifiers using a probabilistic matching algorithm. The analysis file contained 30,400 hospital admissions for 21,016 children. Hospitalization statistics were decomposed into persons hospitalized and number of hospitalizations. Analysis of readmission within 180 days of discharge used additional records from 2001 to avoid bias due to truncated observation. RESULTS: Overall, 22.9% of children in our analysis had repeat asthma admissions within the same age interval, accounting for 30.9% of all hospitalizations. Also among all children, 11.7% had at least one readmission within 180 days of a prior discharge. The risk of hospitalization was higher for boys, decreased by age for both genders, was lowest for white children and highest for black children. Readmission rates were higher for black and Hispanic girls than boys in older age groups, but were otherwise relatively uniform by gender and age. CONCLUSION: Decomposition of ratios of total hospitalizations to population illuminates components of risk and suggests specific causes of disparity.",
      "authors": "Wallace Jonathan C; Denk Charles E; Kruse Lakota K",
      "year": "2004",
      "journal": "Preventing chronic disease",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/15663883/",
      "mesh_terms": "Adolescent; Age Distribution; Asthma; Black People; Child; Child, Preschool; Female; Hospital Records; Hospitalization; Humans; Infant; Male; New Jersey; Patient Readmission; Severity of Illness Index; Sex Distribution; White People; Black or African American",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": "PMC1183499"
    },
    {
      "pmid": "34736462",
      "title": "Addressing missing values in routine health information system data: an evaluation of imputation methods using data from the Democratic Republic of the Congo during the COVID-19 pandemic.",
      "abstract": "BACKGROUND: Poor data quality is limiting the use of data sourced from routine health information systems (RHIS), especially in low- and middle-income countries. An important component of this\u00a0data quality issue\u00a0comes from missing values, where health facilities, for a variety of reasons, fail to report to the central system. METHODS: Using data from the health management information system in the Democratic Republic of the Congo and the advent of COVID-19 pandemic as an illustrative case study, we implemented seven commonly used imputation methods and evaluated their performance in terms of minimizing bias in imputed values and parameter estimates generated through subsequent analytical techniques, namely segmented regression, which is widely used in interrupted time series studies, and pre-post-comparisons through paired Wilcoxon rank-sum tests. We also examined the performance of these imputation methods under different missing mechanisms and tested their stability to changes in the data. RESULTS: For regression analyses, there were no substantial differences found in the coefficient estimates generated from all methods except mean imputation and exclusion and interpolation when the data contained less than 20% missing values. However, as the missing proportion grew, k-NN started to produce biased estimates. Machine learning algorithms, i.e. missForest and k-NN, were also found to lack robustness to small changes in the data or consecutive missingness. On the other hand, multiple imputation methods generated the overall most unbiased estimates and were the most robust to all changes in data. They also produced smaller standard errors than single imputations. For pre-post-comparisons, all methods produced p values less than 0.01, regardless of the amount of missingness introduced, suggesting low sensitivity of Wilcoxon rank-sum tests to the imputation method used. CONCLUSIONS: We recommend the use of multiple imputation in addressing missing values in RHIS datasets and appropriate handling of data structure to minimize imputation standard errors. In cases where necessary computing resources are unavailable for multiple imputation, one may consider seasonal decomposition as the next best method. Mean imputation and exclusion and interpolation, however, always produced biased and misleading results in the subsequent analyses, and thus, their use in the handling of missing values should be discouraged.",
      "authors": "Feng Shuo; Hategeka Celestin; Gr\u00e9pin Karen Ann",
      "year": "2021",
      "journal": "Population health metrics",
      "doi": "10.1186/s12963-021-00274-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34736462/",
      "mesh_terms": "COVID-19; Democratic Republic of the Congo; Health Information Systems; Humans; Pandemics; SARS-CoV-2",
      "keywords": "Health management information system (HMIS); Health services research; Low- and middle-income countries (LMICs); Missing data; Multiple imputation; Routine health information systems (RHIS)",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8567342"
    },
    {
      "pmid": "37656670",
      "title": "Estimating the effect of a rifampicin resistant tuberculosis diagnosis by the Xpert MTB/RIF assay on two-year mortality.",
      "abstract": "Studies assessing patient-centred outcomes of novel rifampicin resistant tuberculosis (RR-TB) diagnostics are rare and mostly apply conventional methods which may not adequately address biases. Even though the Xpert MTB/RIF molecular assay was endorsed a decade ago for simultaneous diagnosis of tuberculosis and RR-TB, the impact of the assay on mortality among people with RR-TB has not yet been assessed. We analysed data of an observational prospective cohort study (EXIT-RIF) performed in South Africa. We applied a causal inference approach using inverse odds of sampling weights to rectify survivor bias and selection bias caused by differing screening guidelines. We also adjusted for confounding using a marginal structural model with inverse probability of treatment weights. We estimated the total effect of an RR-TB diagnosis made by the Xpert assay versus the pre-Xpert diagnostic algorithm (entailing a targeted Line Probe Assay (LPA) among TB-confirmed patients) on two-year mortality and we assessed mediation by RR-treatment initiation. Of the 749 patients diagnosed with RR-TB [247 (33%) by the pre-Xpert diagnostic algorithm and 502 (67%) by the Xpert assay], 42.7% died. Of these, 364 (48.6%) patients died in the pre-Xpert group and 200 (39.8%) in the Xpert group. People diagnosed with RR-TB by the Xpert assay had a higher odds of RR-TB treatment initiation compared to those diagnosed by the targeted LPA-based diagnostic process (OR 2.79; 95%CI 2.19-3.56). Receiving an RR-TB diagnosis by Xpert resulted in a 28% reduction in the odds of mortality within 2 years after presentation to the clinic (ORCI 0.72; 95%CI 0.53-0.99). Causal mediation analysis suggests that the higher rate of RR-TB treatment initiation in people diagnosed by the Xpert assay explains the effect of Xpert on 2-year mortality [natural indirect effect odds ratio 0.90 (95%CI 0.85-0.96). By using causal inference methods in combination with high quality observational data, we could demonstrate that the introduction of the Xpert assay caused a 28% reduction in 2-year odds of mortality of RR-TB. This finding highlights the need for advocacy for a worldwide roll-out of rapid molecular tests. Because the effect is mainly caused by increased RR-TB treatment initiation, health care systems should also ensure timely initiation of effective treatment upon an RR-TB diagnosis.",
      "authors": "De Vos Elise; Westreich Daniel; Scott Lesley; Voss de Lima Yara; Stevens Wendy; Hayes Cindy; da Silva Pedro; Van Rie Annelies",
      "year": "2023",
      "journal": "PLOS global public health",
      "doi": "10.1371/journal.pgph.0001989",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37656670/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10473529"
    },
    {
      "pmid": "40149245",
      "title": "Weibull-Type Incubation Period and Time of Exposure Using \u03b3-Divergence.",
      "abstract": "Accurately determining the exposure time to an infectious pathogen, together with the corresponding incubation period, is vital for identifying infection sources and implementing targeted public health interventions. However, real-world outbreak data often include outliers-namely, tertiary or subsequent infection cases not directly linked to the initial source-that complicate the estimation of exposure time. To address this challenge, we introduce a robust estimation framework based on a three-parameter Weibull distribution in which the location parameter naturally corresponds to the unknown exposure time. Our method employs a \u03b3-divergence criterion-a robust generalization of the standard cross-entropy criterion-optimized via a tailored majorization-minimization (MM) algorithm designed to guarantee a monotonic decrease in the objective function despite the non-convexity typically present in robust formulations. Extensive Monte Carlo simulations demonstrate that our approach outperforms conventional estimation methods in terms of bias and mean squared error as well as in estimating the incubation period. Moreover, applications to real-world surveillance data on COVID-19 illustrate the practical advantages of the proposed method. These findings highlight the method's robustness and efficiency in scenarios where data contamination from secondary or tertiary infections is common, showing its potential value for early outbreak detection and rapid epidemiological response.",
      "authors": "Yoneoka Daisuke; Kawashima Takayuki; Tanoue Yuta; Nomura Shuhei; Eguchi Akifumi",
      "year": "2025",
      "journal": "Entropy (Basel, Switzerland)",
      "doi": "10.3390/e27030321",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40149245/",
      "mesh_terms": "",
      "keywords": "exposure time; infectious disease; robust estimation; three-parameter Weibull distribution; \u03b3-divergence",
      "pub_types": "Journal Article",
      "pmcid": "PMC11941306"
    },
    {
      "pmid": "38428815",
      "title": "Assessing the Performance of Alternative Methods for Estimating Long-Term Survival Benefit of Immuno-oncology Therapies.",
      "abstract": "OBJECTIVES: This study aimed to determine the accuracy and consistency of established methods of extrapolating mean survival for immuno-oncology (IO) therapies, the extent of any systematic biases in estimating long-term clinical benefit, what influences the magnitude of any bias, and the potential implications for health technology assessment. METHODS: A targeted literature search was conducted to identify published long-term follow-up from clinical trials of immune-checkpoint inhibitors. Earlier published results were identified and Kaplan-Meier estimates for short- and long-term follow-up were digitized and converted to pseudo-individual patient data using an established algorithm. Six standard parametric, 5 flexible parametric, and 2 mixture-cure models (MCMs) were used to extrapolate long-term survival. Mean and restricted mean survival time (RMST) were estimated and compared between short- and long-term follow-up. RESULTS: Predicted RMST from extrapolation of early data underestimated observed RMST in long-term follow-up for 184 of 271 extrapolations. All models except the MCMs frequently underestimated observed RMST. Mean survival estimates increased with longer follow-up in 196 of 270 extrapolations. The increase exceeded 20% in 122 extrapolations. Log-logistic and log-normal models showed the smallest change with additional follow-up. MCM performance varied substantially with functional form. CONCLUSIONS: Standard and flexible parametric models frequently underestimate mean survival for IO treatments. Log-logistic and log-normal models may be the most pragmatic and parsimonious solutions for estimating IO mean survival from immature data. Flexible parametric models may be preferred when the data used in health technology assessment are more mature. MCMs fitted to immature data produce unreliable results and are not recommended.",
      "authors": "Monnickendam Giles",
      "year": "2024",
      "journal": "Value in health : the journal of the International Society for Pharmacoeconomics and Outcomes Research",
      "doi": "10.1016/j.jval.2024.02.008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38428815/",
      "mesh_terms": "Humans; Technology Assessment, Biomedical; Neoplasms; Immune Checkpoint Inhibitors; Immunotherapy; Kaplan-Meier Estimate; Survival Analysis; Bias; Time Factors",
      "keywords": "health technology assessment; immuno-oncology; immunotherapy; oncology; overall survival; survival benefit",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "30348631",
      "title": "Predicting Current Glycated Hemoglobin Values in Adults: Development of an Algorithm From the Electronic Health Record.",
      "abstract": "BACKGROUND: Electronic, personalized clinical decision support tools to optimize glycated hemoglobin (HbA1c) screening are lacking. Current screening guidelines are based on simple, categorical rules developed for populations of patients. Although personalized diabetes risk calculators have been created, none are designed to predict current glycemic status using structured data commonly available in electronic health records (EHRs). OBJECTIVE: The goal of this project was to create a mathematical equation for predicting the probability of current elevations in HbA1c (\u22655.7%) among patients with no history of hyperglycemia using readily available variables that will allow integration with EHR systems. METHODS: The reduced model was compared head-to-head with calculators created by Baan and Griffin. Ten-fold cross-validation was used to calculate the bias-adjusted prediction accuracy of the new model. Statistical analyses were performed in R version 3.2.5 (The R Foundation for Statistical Computing) using the rms (Regression Modeling Strategies) package. RESULTS: The final model to predict an elevated HbA1c based on 22,635 patient records contained the following variables in order from most to least importance according to their impact on the discriminating accuracy of the model: age, body mass index, random glucose, race, serum non-high-density lipoprotein, serum total cholesterol, estimated glomerular filtration rate, and smoking status. The new model achieved a concordance statistic of 0.77 which was statistically significantly better than prior models. The model appeared to be well calibrated according to a plot of the predicted probabilities versus the prevalence of the outcome at different probabilities. CONCLUSIONS: The calculator created for predicting the probability of having an elevated HbA1c significantly outperformed the existing calculators. The personalized prediction model presented in this paper could improve the efficiency of HbA1c screening initiatives.",
      "authors": "Wells Brian J; Lenoir Kristin M; Diaz-Garelli Jose-Franck; Futrell Wendell; Lockerman Elizabeth; Pantalone Kevin M; Kattan Michael W",
      "year": "2018",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/10780",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30348631/",
      "mesh_terms": "",
      "keywords": "clinical decision support; diabetes; electronic health records; hemoglobin A1c; risk prediction",
      "pub_types": "Journal Article",
      "pmcid": "PMC6231807"
    },
    {
      "pmid": "28595025",
      "title": "The Validity of Using Health Administrative Data To Identify the Involvement of Specialized Pediatric Palliative Care Teams in Children with Cancer in Ontario, Canada.",
      "abstract": "BACKGROUND: Population-based research to identify underserviced populations and the impact of palliative care (PC) is limited as the validity of such data to identify PC services is largely unknown. OBJECTIVE: To determine the validity of using such data to identify the involvement of specialized pediatric PC teams among children with cancer. DESIGN: Retrospective cohort. SUBJECTS: Ontario children with cancer who died between 2000 and 2012, received care through a pediatric institution with a specialized PC team and a clinical PC database. MEASUREMENTS: All patients in the clinical databases were linked to population-based health services administrative databases. Six algorithms were created to indicate the use of formal pediatric PC teams based on the record type (physician billings vs. inpatient records vs. both) and number of eligible codes required (\u22651 vs. \u22652). Each was validated against the pediatric PC clinical databases. RESULTS: The cohort comprised 572 children; 243 were in the clinical databases. Algorithms using only inpatient records had high specificity (80%-95%) but poor sensitivity (21%-56%). Including physician billings increased sensitivity but lowered specificity. The algorithm with overall best performance required \u22652 physician billing or inpatient diagnosis codes indicating PC [sensitivity 0.79 (95% CI 0.73-0.84), specificity 0.58 (95% CI 0.53-0.64)]. CONCLUSIONS: Health administrative data identifies involvement of specialized pediatric PC teams with good sensitivity but low specificity. Studies using such data alone to compare patients receiving and not receiving specialized pediatric PC are at significant risk of misclassification and potential bias. Population-based PC databases should be established to conduct rigorous population-based PC research.",
      "authors": "Widger Kimberley; Vadeboncoeur Christina; Zelcer Shayna; Liu Ying; Kassam Alisha; Sutradhar Rinku; Rapoport Adam; Nelson Katherine; Wolfe Joanne; Earle Craig; Pole Jason D; Gupta Sumit",
      "year": "2017",
      "journal": "Journal of palliative medicine",
      "doi": "10.1089/jpm.2017.0028",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28595025/",
      "mesh_terms": "Adolescent; Child; Child, Preschool; Cohort Studies; Electronic Health Records; Female; Humans; Infant; Infant, Newborn; Male; Neoplasms; Oncology Nursing; Ontario; Palliative Care; Patient Care Team; Pediatric Nursing; Reproducibility of Results; Retrospective Studies",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "12515929",
      "title": "[Quality of medical database to valorize the DRG model by ISA cost indicators].",
      "abstract": "BACKGROUND: The use of the French version of the DRG model is focused on cost allocation, based on the case-mix system and the use a weight called ISA (Synthetic Index of Activity) for each DRG. However, this administrative database is becoming more and more used by both researchers and health policy makers for health planning and benchmarking. In France, data abstraction and coding of medical records is done by physicians. The objective of this study was to determine the accuracy of a database of the discharge summaries used for DRGs and to compare consequences of inappropriate coding on budget estimation and risk adjustment. METHODS: Samples of discharge summaries from six cardiology units were recoded by trained physicians in data abstracting and coding. Comparison between initial and recoded diagnoses (errors on main diagnosis or on comorbidities) used by the DRG system algorithm, and the original and final case-mix were performed. The before and after abstracted data were stratified and compared by principal diagnosis (myocardial infarction or congestive heart failure) and discharge status (dead or alive). MAIN RESULTS: Comorbidities were underreported by physicians of cardiology units compared to reabstracted data (mean number of secondary diagnoses per summary: 2.1 vs. 3.6, p<0.001), especially those which had a minimal impact on the DRG classification. In spite of a 15% rate of wrong DRGs, there was no significant difference in the total amount of ISA after data reviewing. Underreporting of comorbidities is more important for medical records of dead patients at discharge but, without significant effect on rate of change in DRG and amount of ISA. CONCLUSION: Discharge summaries used in the French DRGs system consistently underestimate the presence of comorbid conditions, which has direct implications for policy-makers comparing performance between hospital units. Both clinical practitioners and policy makers should be aware of this bias when assessing patient's quality of care or performing health planning through discharge summaries.",
      "authors": "Holstein J; Taright N; Lepage E; Razafimamonjy J; Duboc D; Feldman L; Hittinger L; Lavergne T; Chatellier G",
      "year": "2002",
      "journal": "Revue d'epidemiologie et de sante publique",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/12515929/",
      "mesh_terms": "Age Factors; Aged; Algorithms; Benchmarking; Budgets; Comorbidity; Coronary Care Units; Costs and Cost Analysis; Data Interpretation, Statistical; Databases as Topic; Diagnosis-Related Groups; Diagnostic Errors; France; Heart Failure; Hospital Mortality; Humans; Medical Records; Myocardial Infarction; Patient Discharge; Policy Making; Quality Control; Quality of Health Care; Risk Assessment",
      "keywords": "",
      "pub_types": "Comparative Study; English Abstract; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38798915",
      "title": "A Principled Approach to Characterize and Analyze Partially Observed Confounder Data from Electronic Health Records.",
      "abstract": "OBJECTIVE: Partially observed confounder data pose challenges to the statistical analysis of electronic health records (EHR) and systematic assessments of potentially underlying missingness mechanisms are lacking. We aimed to provide a principled approach to empirically characterize missing data processes and investigate performance of analytic methods. METHODS: Three empirical sub-cohorts of diabetic SGLT2 or DPP4-inhibitor initiators with complete information on HbA1c, BMI and smoking as confounders of interest (COI) formed the basis of data simulation under a plasmode framework. A true null treatment effect, including the COI in the outcome generation model, and four missingness mechanisms for the COI were simulated: completely at random (MCAR), at random (MAR), and two not at random (MNAR) mechanisms, where missingness was dependent on an unmeasured confounder and on the value of the COI itself. We evaluated the ability of three groups of diagnostics to differentiate between mechanisms: 1)-differences in characteristics between patients with or without the observed COI (using averaged standardized mean differences [ASMD]), 2)-predictive ability of the missingness indicator based on observed covariates, and 3)-association of the missingness indicator with the outcome. We then compared analytic methods including \"complete case\", inverse probability weighting, single and multiple imputation in their ability to recover true treatment effects. RESULTS: The diagnostics successfully identified characteristic patterns of simulated missingness mechanisms. For MAR, but not MCAR, the patient characteristics showed substantial differences (median ASMD 0.20 vs 0.05) and consequently, discrimination of the prediction models for missingness was also higher (0.59 vs 0.50). For MNAR, but not MAR or MCAR, missingness was significantly associated with the outcome even in models adjusting for other observed covariates. Comparing analytic methods, multiple imputation using a random forest algorithm resulted in the lowest root-mean-squared-error. CONCLUSION: Principled diagnostics provided reliable insights into missingness mechanisms. When assumptions allow, multiple imputation with nonparametric models could help reduce bias.",
      "authors": "Weberpals Janick; Raman Sudha R; Shaw Pamela A; Lee Hana; Russo Massimiliano; Hammill Bradley G; Toh Sengwee; Connolly John G; Dandreo Kimberly J; Tian Fang; Liu Wei; Li Jie; Hern\u00e1ndez-Mu\u00f1oz Jos\u00e9 J; Glynn Robert J; Desai Rishi J",
      "year": "2024",
      "journal": "Clinical epidemiology",
      "doi": "10.2147/CLEP.S436131",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38798915/",
      "mesh_terms": "",
      "keywords": "analytics; diagnostics; electronic health records; imputation; missing data",
      "pub_types": "Journal Article",
      "pmcid": "PMC11127690"
    },
    {
      "pmid": "39236300",
      "title": "Ultrasound attenuation imaging as a strategy for evaluation of early and late ambulatory functions in Duchenne muscular dystrophy.",
      "abstract": "BACKGROUND: Duchenne muscular dystrophy (DMD) is a genetic neuromuscular disorder that leads to mobility loss and life-threatening cardiac or respiratory complications. Quantitative ultrasound (QUS) envelope statistics imaging, which characterizes fat infiltration and fibrosis in muscles, has been extensively used for DMD evaluations. PURPOSE: Notably, changes in muscle microstructures also result in acoustic attenuation, potentially serving as another crucial imaging biomarker for DMD. Expanding upon the reference frequency method (RFM), this study contributes to the field by introducing the robust RFM (RRFM) as a novel approach for ultrasound attenuation imaging in DMD. METHODS: The RRFM algorithm was developed using an iterative reweighted least squares technique. We conducted standard phantom measurements with a clinical ultrasound system equipped with a linear array transducer to assess the improvement in attenuation estimation bias by RRFM. Additionally, 161 DMD patients, included in both a validation dataset (n\u00a0=\u00a0130) and a testing dataset (n\u00a0=\u00a031), underwent ultrasound scanning of the gastrocnemius for RRFM-based attenuation imaging. The diagnostic performances for ambulatory functions and discrimination between early and late ambulatory stages were evaluated and compared with those of QUS envelope statistics imaging (involving Nakagami distribution, homodyned K distribution, and entropy values) using the area under the receiver operating characteristic curve (AUROC). RESULTS: The results indicated that the RRFM method more closely matched the actual attenuation properties of the phantom, reducing measurement bias by 50% compared to conventional RFM. The AUROCs for RRFM-based attenuation imaging, used to discriminate between early and late ambulatory stages, were 0.88 and 0.92 for the validation and testing datasets, respectively. These performances significantly surpassed those of QUS envelope statistics imaging (p\u00a0<\u00a00.05). CONCLUSIONS: Ultrasound attenuation imaging employing RRFM may serve as a sensitive tool for evaluating the progression of ambulatory function deterioration, offering substantial potential for the health management and follow-up care of DMD patients.",
      "authors": "Yan Dong; Li Qiang; Chuang Ya-Wen; Lu Chun-Hao; Yang Ai-Ping; Lin Chia-Wei; Shieh Jeng-Yi; Weng Wen-Chin; Tsui Po-Hsiang",
      "year": "2024",
      "journal": "Medical physics",
      "doi": "10.1002/mp.17389",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39236300/",
      "mesh_terms": "Muscular Dystrophy, Duchenne; Ultrasonography; Humans; Phantoms, Imaging; Child; Adolescent; Image Processing, Computer-Assisted; Male",
      "keywords": "Duchenne muscular dystrophy; attenuation estimation; envelope statistics; quantitative ultrasound; reference frequency method",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "30497868",
      "title": "FRAX 10-yr Fracture Risk in Rheumatoid Arthritis-Assessments With and Without Bone Mineral Density May Lead to Very Different Results in the Individual Patient.",
      "abstract": "OBJECTIVES: FRAX is a computer-based algorithm developed by the World Health Organisation for estimation of the 10-yr risk of a hip or major osteoporotic fracture. Inclusion of femoral neck bone mineral density (BMD) in the estimation is optional. The study aimed to investigate the intra-individual agreement between FRAX fracture risk calculated with and without BMD in patients with rheumatoid arthritis (RA). METHODS: Clinical data and BMD results from 50 RA patients registered in the Danish rheumatology registry (DANBIO) were used for analysis. Using the Bland-Altman method, lower and upper 95% limits of agreement [LLoA;ULoA] between intraindividual assessments of fracture risk with and without BMD and the bias (mean of individual differences) were calculated. Categorization of patients according to the National Osteoporosis foundation (NOF) treatment thresholds were also assessed with and without BMD. RESULTS: Mean age was 63.6 \u00b1 11.7 yr, mean disease activity score (DAS28-CRP) 3.3 \u00b1 3.5 and mean femoral neck T-score -1.43 \u00b1 1.15. The mean 10-yr risk of a major fracture and a hip fracture calculated with BMD was 22.9 \u00b1 15.8% and 8.5 \u00b1 10.8%, respectively. The LLoA and ULoA [bias] calculated without vs with BMD were -14.5 and 20.4 percent point (pp) [2.9 pp] for major fracture risk and -14.0 and 23.2 pp [4.6 pp] for hip fracture. NOF treatment categorization was only dependent on BMD in 4% of the patients. CONCLUSION: The FRAX fracture risk estimated with and without BMD may disagree substantially in individual patients with RA but this seems to have only little impact on treatment categorization based on the NOF guidelines.",
      "authors": "Elde Karen Dombestein; Madsen Ole Rintek",
      "year": "2019",
      "journal": "Journal of clinical densitometry : the official journal of the International Society for Clinical Densitometry",
      "doi": "10.1016/j.jocd.2018.10.007",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30497868/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Algorithms; Arthritis, Rheumatoid; Bias; Bone Density; Femur Neck; Fractures, Spontaneous; Hip Fractures; Humans; Middle Aged; Risk Assessment; Spondylosis",
      "keywords": "FRAX, osteoporosis; Fracture; rheumatoid arthritis",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41047269",
      "title": "Development and validation of diagnostic and prognostic prediction tools for dental caries in young children through prospective and cross-sectional observational studies: a protocol.",
      "abstract": "INTRODUCTION: Dental caries is the most common oral disease worldwide, affecting up to 90% of children globally. It can lead to pain, infection and impaired quality of life. Early prevention is a key strategy for reducing the prevalence of dental caries in young children. Valid and reliable diagnostic or prognostic tools that enable accurate individualised prediction of current or future dental caries are essential for facilitating personalised caries prevention and early intervention. However, no efficacious tools currently exist in early childhood-the optimal period for disease prevention. We aim to develop and validate diagnostic and prognostic prediction tools for dental caries in young children, using a combination of environmental, physical, behavioural and biological early life data. METHODS AND ANALYSIS: Data sources include two prospective studies, with a total sample size of approximately 600 children. These cohorts have collected detailed demographic, antenatal, perinatal and postnatal data from medical records and parent-completed questionnaires and biological samples including a dental plaque swab. Candidate predictor variables will include sociodemographic characteristics, health history, behavioural and microbiological characteristics. The outcome variable will be the presence, incidence or severity of dental caries diagnosed using the International Caries Detection and Assessment System. Statistical and machine learning approaches will be used for selection of predictor variables and model development. Internal validation will be conducted using resampling methods (i.e., bootstrapping) and nested cross-validation. Model performance will be evaluated using standard performance metrics such as accuracy, discrimination and calibration. Where feasible, external validation will be performed in an independent cohort. Model development and reporting will be guided by the Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias Assessment Tool (PROBAST) guidelines. ETHICS AND DISSEMINATION: This study has ethical and governance approval from The Royal Children's Hospital Melbourne Human Research Ethics Committee (HREC/111803/RCHM-2024). Results of this study will be published in peer-reviewed journals and presented at scientific conferences. TRIAL REGISTRATION NUMBER: Infant2Child: ACTRN12622000205730-pre-results; MisBair: NCT01906853-post results.",
      "authors": "Khazaei Yeganeh; Kodikara Saritha; Butler Catherine A; Messina Nicole L; L\u00ea Cao Kim-Anh; Dashper Stuart G; Silva Mihiri J",
      "year": "2025",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2025-105145",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41047269/",
      "mesh_terms": "Humans; Dental Caries; Prospective Studies; Child, Preschool; Prognosis; Cross-Sectional Studies; Research Design; Observational Studies as Topic; Female; Infant; Male",
      "keywords": "Dentistry; Diagnostic microbiology; MICROBIOLOGY; Machine Learning; Prognosis; STATISTICS & research methods",
      "pub_types": "Journal Article",
      "pmcid": "PMC12506182"
    },
    {
      "pmid": "33213435",
      "title": "Comparison of deep learning with regression analysis in creating predictive models for SARS-CoV-2 outcomes.",
      "abstract": "BACKGROUND: Accurately predicting patient outcomes in Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) could aid patient management and allocation of healthcare resources. There are a variety of methods which can be used to develop prognostic models, ranging from logistic regression and survival analysis to more complex machine learning algorithms and deep learning. Despite several models having been created for SARS-CoV-2, most of these have been found to be highly susceptible to bias. We aimed to develop and compare two separate predictive models for death during admission with SARS-CoV-2. METHOD: Between March 1 and April 24, 2020, 398 patients were identified with laboratory confirmed SARS-CoV-2 in a London teaching hospital. Data from electronic health records were extracted and used to create two predictive models using: (1) a Cox regression model and (2) an artificial neural network (ANN). Model performance profiles were assessed by validation, discrimination, and calibration. RESULTS: Both the Cox regression and ANN models achieved high accuracy (83.8%, 95% confidence interval (CI) 73.8-91.1 and 90.0%, 95% CI 81.2-95.6, respectively). The area under the receiver operator curve (AUROC) for the ANN (92.6%, 95% CI 91.1-94.1) was significantly greater than that of the Cox regression model (86.9%, 95% CI 85.7-88.2), p\u2009=\u20090.0136. Both models achieved acceptable calibration with Brier scores of 0.13 and 0.11 for the Cox model and ANN, respectively. CONCLUSION: We demonstrate an ANN which is non-inferior to a Cox regression model but with potential for further development such that it can learn as new data becomes available. Deep learning techniques are particularly suited to complex datasets with non-linear solutions, which make them appropriate for use in conditions with a paucity of prior knowledge. Accurate prognostic models for SARS-CoV-2 can provide benefits at the patient, departmental and organisational level.",
      "authors": "Abdulaal Ahmed; Patel Aatish; Charani Esmita; Denny Sarah; Alqahtani Saleh A; Davies Gary W; Mughal Nabeela; Moore Luke S P",
      "year": "2020",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-020-01316-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33213435/",
      "mesh_terms": "Algorithms; Betacoronavirus; COVID-19; Coronavirus Infections; Deep Learning; Female; Humans; London; Male; Middle Aged; Models, Theoretical; Neural Networks, Computer; Pandemics; Pneumonia, Viral; Proportional Hazards Models; SARS-CoV-2",
      "keywords": "Artificial intelligence; COVID-19; Coronavirus; Machine learning; Prognostication",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": "PMC7676403"
    },
    {
      "pmid": "32894128",
      "title": "Development, implementation, and prospective validation of a model to predict 60-day end-of-life in hospitalized adults upon admission at three sites.",
      "abstract": "BACKGROUND: Automated systems that use machine learning to estimate a patient's risk of death are being developed to influence care. There remains sparse transparent reporting of model generalizability in different subpopulations especially for implemented systems. METHODS: A prognostic study included adult admissions at a multi-site, academic medical center between 2015 and 2017. A predictive model for all-cause mortality (including initiation of hospice care) within 60\u2009days of admission was developed. Model generalizability is assessed in temporal validation in the context of potential demographic bias. A subsequent prospective cohort study was conducted at the same sites between October 2018 and June 2019. Model performance during prospective validation was quantified with areas under the receiver operating characteristic and precision recall curves stratified by site. Prospective results include timeliness, positive predictive value, and the number of actionable predictions. RESULTS: Three years of development data included 128,941 inpatient admissions (94,733 unique patients) across sites where patients are mostly white (61%) and female (60%) and 4.2% led to death within 60\u2009days. A random forest model incorporating 9614 predictors produced areas under the receiver operating characteristic and precision recall curves of 87.2 (95% CI, 86.1-88.2) and 28.0 (95% CI, 25.0-31.0) in temporal validation. Performance marginally diverges within sites as the patient mix shifts from development to validation (patients of one site increases from 10 to 38%). Applied prospectively for nine months, 41,728 predictions were generated in real-time (median [IQR], 1.3 [0.9, 32] minutes). An operating criterion of 75% positive predictive value identified 104 predictions at very high risk (0.25%) where 65% (50 from 77 well-timed predictions) led to death within 60\u2009days. CONCLUSION: Temporal validation demonstrates good model discrimination for 60-day mortality. Slight performance variations are observed across demographic subpopulations. The model was implemented prospectively and successfully produced meaningful estimates of risk within minutes of admission.",
      "authors": "Major Vincent J; Aphinyanaphongs Yindalon",
      "year": "2020",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-020-01235-6",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32894128/",
      "mesh_terms": "Adolescent; Adult; Aged; Aged, 80 and over; Electronic Health Records; Female; Hospitalization; Humans; Machine Learning; Male; Middle Aged; Mortality; Patient Admission; Prognosis; Prospective Studies; Young Adult",
      "keywords": "Advance directives; Electronic health records; End-of-life care; Machine learning; Medical informatics; Mortality prediction; Palliative care; Supportive care",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC7487547"
    },
    {
      "pmid": "30014938",
      "title": "Spatiotemporal patterns of PM10 concentrations over China during 2005-2016: A satellite-based estimation using the random forests approach.",
      "abstract": "BACKGROUND: Few studies have estimated historical exposures to PM10 at a national scale in China using satellite-based aerosol optical depth (AOD). Also, long-term trends have not been investigated. OBJECTIVES: In this study, daily concentrations of PM10 over China during the past 12 years were estimated with the most recent ground monitoring data, AOD, land use information, weather data and a machine learning approach. METHODS: Daily measurements of PM10 during 2014-2016 were collected from 1479 sites in China. Two types of Moderate Resolution Imaging Spectroradiometer (MODIS) AOD data, land use information, and weather data were downloaded and merged. A random forests model (non-parametric machine learning algorithms) and two traditional regression models were developed and their predictive abilities were compared. The best model was applied to estimate daily concentrations of PM10 across China during 2005-2016\u202fat 0.1\u2070 (\u224810\u202fkm). RESULTS: Cross-validation showed our random forests model explained 78% of daily variability of PM10 [root mean squared prediction error (RMSE)\u202f=\u202f31.5\u202f\u03bcg/m3]. When aggregated into monthly and annual averages, the models captured 82% (RMSE\u202f=\u202f19.3\u202f\u03bcg/m3) and 81% (RMSE\u202f=\u202f14.4\u202f\u03bcg/m3) of the variability. The random forests model showed much higher predictive ability and lower bias than the other two regression models. Based on the predictions of random forests model, around one-third of China experienced with PM10 pollution exceeding Grade \u2161 National Ambient Air Quality Standard (>70\u202f\u03bcg/m3) in China during the past 12 years. The highest levels of estimated PM10 were present in the Taklamakan Desert of Xinjiang and Beijing-Tianjin metropolitan region, while the lowest were observed in Tibet, Yunnan and Hainan. Overall, the PM10 level in China peaked in 2006 and 2007, and declined since 2008. CONCLUSIONS: This is the first study to estimate historical PM10 pollution using satellite-based AOD data in China with random forests model. The results can be applied to investigate the long-term health effects of PM10 in China.",
      "authors": "Chen Gongbo; Wang Yichao; Li Shanshan; Cao Wei; Ren Hongyan; Knibbs Luke D; Abramson Michael J; Guo Yuming",
      "year": "2018",
      "journal": "Environmental pollution (Barking, Essex : 1987)",
      "doi": "10.1016/j.envpol.2018.07.012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30014938/",
      "mesh_terms": "Aerosols; Air Pollutants; Air Pollution; Beijing; China; Environmental Monitoring; Particulate Matter; Satellite Imagery; Tibet; Weather",
      "keywords": "AOD; China; PM(10); Random forests",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "31320256",
      "title": "Accuracy of Cardiac Nurse Acquired and Measured Three-Dimensional Echocardiographic Left Ventricular Ejection Fraction: Comparison to Echosonographer.",
      "abstract": "BACKGROUND: Three-dimensional echocardiography (3D-Echo) performed by novice health care staff to measure left ventricular ejection fraction (LVEF) could allow cost-effective screening and monitoring for left ventricular systolic dysfunction (LVSD) prior to the development of heart failure. The aim of this study was to determine feasibility and accuracy of cardiac nurses (after completing focussed training) independently acquiring 3D-Echo images, and measuring LVEF using semi-automated software when compared to an echosonographer. METHODS: One echosonographer and three cardiac nurses acquired 3D-Echo images on 73 patients (62\u2009\u00b1\u200916 years, 62% male) with good image quality, and subsequently measured LVEF using a semi-automated algorithm. RESULTS: Overall feasibility was 89% with the three nurses successfully acquiring 3D-Echo images suitable for LVEF assessment in 65 of the 73 patients. High accuracy (r\u2009=\u20090.82; p\u2009<\u20090.0001) with minimal bias (+0.1, -10.6 to +10.8 limits of agreement; p\u2009=\u20090.91) was observed comparing the nurses to the echosonographer for measuring LVEF. Individual nurses demonstrated high feasibility (86%-92%), accuracy (r\u2009=\u20090.83-0.87; all p\u2009<\u20090.0001) and intra-observer reproducibility (r\u2009=\u20090.96-0.97; all p\u2009<\u20090.0001), with good inter-observer consistency in accuracy compared to the echosonographer (one-way analysis of variance p\u2009=\u20090.559). CONCLUSIONS: We have demonstrated that, following a focussed training protocol, it was feasible for cardiac nurses to acquire 3D-Echo images of sufficient image quality to allow measurement of LVEF using a semi-automated algorithm, with comparable accuracy and intra-observer variability to an expert echosonographer. This could potentially allow the broader application of echocardiography to screen for LVSD in high-risk cohorts.",
      "authors": "Guppy-Coles Kristyan B; Prasad Sandhir B; Smith Kym C; Lo Ada; Beard Patrick; Ng Arnold; Atherton John J",
      "year": "2020",
      "journal": "Heart, lung & circulation",
      "doi": "10.1016/j.hlc.2019.04.008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31320256/",
      "mesh_terms": "Algorithms; Echocardiography, Three-Dimensional; Feasibility Studies; Female; Heart Failure; Heart Ventricles; Humans; Male; Middle Aged; ROC Curve; Stroke Volume; Ventricular Dysfunction, Left; Ventricular Function, Left",
      "keywords": "Heart failure; Left ventricular ejection fraction; Left ventricular systolic dysfunction; Three-dimensional echocardiography",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "34980622",
      "title": "Artificial intelligence (AI) to enhance breast cancer screening: protocol for population-based cohort study of cancer detection.",
      "abstract": "INTRODUCTION: Arti\ufb01cial intelligence (AI) algorithms for interpreting mammograms have the potential to improve the effectiveness of population breast cancer screening programmes if they can detect cancers, including interval cancers, without contributing substantially to overdiagnosis. Studies suggesting that AI has comparable or greater accuracy than radiologists commonly employ 'enriched' datasets in which cancer prevalence is higher than in population screening. Routine screening outcome metrics (cancer detection and recall rates) cannot be estimated from these datasets, and accuracy estimates may be subject to spectrum bias which limits generalisabilty to real-world screening. We aim to address these limitations by comparing the accuracy of AI and radiologists in a cohort of consecutive of women attending a real-world population breast cancer screening programme. METHODS AND ANALYSIS: A retrospective, consecutive cohort of digital mammography screens from 109\u2009000 distinct women was assembled from BreastScreen WA (BSWA), Western Australia's biennial population screening programme, from November 2016 to December 2017. The cohort includes 761 screen-detected and 235 interval cancers. Descriptive characteristics and results of radiologist double-reading will be extracted from BSWA outcomes data collection. Mammograms will be reinterpreted by a commercial AI algorithm (DeepHealth). AI accuracy will be compared with that of radiologist single-reading based on the di\ufb00erence in the area under the receiver operating characteristic curve. Cancer detection and recall rates for combined AI-radiologist reading will be estimated by pairing the first radiologist read per screen with the AI algorithm, and compared with estimates for radiologist double-reading. ETHICS AND DISSEMINATION: This study has ethical approval from the Women and Newborn Health Service Ethics Committee (EC00350) and the Curtin University Human Research Ethics Committee (HRE2020-0316). Findings will be published in peer-reviewed journals and presented at national and international conferences. Results will also be disseminated to stakeholders in Australian breast cancer screening programmes and policy makers in population screening.",
      "authors": "Marinovich M Luke; Wylie Elizabeth; Lotter William; Pearce Alison; Carter Stacy M; Lund Helen; Waddell Andrew; Kim Jiye G; Pereira Gavin F; Lee Christoph I; Zackrisson Sophia; Brennan Meagan; Houssami Nehmat",
      "year": "2022",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2021-054005",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34980622/",
      "mesh_terms": "Artificial Intelligence; Australia; Breast Neoplasms; Cohort Studies; Early Detection of Cancer; Female; Humans; Infant, Newborn; Mammography; Mass Screening; Retrospective Studies",
      "keywords": "breast imaging; breast tumours; diagnostic radiology",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8724814"
    },
    {
      "pmid": "37874618",
      "title": "Applying AI and Guidelines to Assist Medical Students in Recognizing Patients With Heart Failure: Protocol for a Randomized Trial.",
      "abstract": "BACKGROUND: The integration of artificial intelligence (AI) into clinical practice is transforming both clinical practice and medical education. AI-based systems aim to improve the efficacy of clinical tasks, enhancing diagnostic accuracy and tailoring treatment delivery. As it becomes increasingly prevalent in health care for high-quality patient care, it is critical for health care providers to use the systems responsibly to mitigate bias, ensure effective outcomes, and provide safe clinical practices. In this study, the clinical task is the identification of heart failure (HF) prior to surgery with the intention of enhancing clinical decision-making skills. HF is a common and severe disease, but detection remains challenging due to its subtle manifestation, often concurrent with other medical conditions, and the absence of a simple and effective diagnostic test. While advanced HF algorithms have been developed, the use of these AI-based systems to enhance clinical decision-making in medical education remains understudied. OBJECTIVE: This research protocol is to demonstrate our study design, systematic procedures for selecting surgical cases from electronic health records, and interventions. The primary objective of this study is to measure the effectiveness of interventions aimed at improving HF recognition before surgery, the second objective is to evaluate the impact of inaccurate AI recommendations, and the third objective is to explore the relationship between the inclination to accept AI recommendations and their accuracy. METHODS: Our study used a 3 \u00d7 2 factorial design (intervention type \u00d7 order of prepost sets) for this randomized trial with medical students. The student participants are asked to complete a 30-minute e-learning module that includes key information about the intervention and a 5-question quiz, and a 60-minute review of 20 surgical cases to determine the presence of HF. To mitigate selection bias in the pre- and posttests, we adopted a feature-based systematic sampling procedure. From a pool of 703 expert-reviewed surgical cases, 20 were selected based on features such as case complexity, model performance, and positive and negative labels. This study comprises three interventions: (1) a direct AI-based recommendation with a predicted HF score, (2) an indirect AI-based recommendation gauged through the area under the curve metric, and (3) an HF guideline-based intervention. RESULTS: As of July 2023, 62 of the enrolled medical students have fulfilled this study's participation, including the completion of a short quiz and the review of 20 surgical cases. The subject enrollment commenced in August 2022 and will end in December 2023, with the goal of recruiting 75 medical students in years 3 and 4 with clinical experience. CONCLUSIONS: We demonstrated a study protocol for the randomized trial, measuring the effectiveness of interventions using AI and HF guidelines among medical students to enhance HF recognition in preoperative care with electronic health record data. INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): DERR1-10.2196/49842.",
      "authors": "Joo Hyeon; Mathis Michael R; Tam Marty; James Cornelius; Han Peijin; Mangrulkar Rajesh S; Friedman Charles P; Vydiswaran V G Vinod",
      "year": "2023",
      "journal": "JMIR research protocols",
      "doi": "10.2196/49842",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37874618/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; clinical decision support systems; digital health interventions; evidence-based medicine; guidelines; heart failure; machine learning; medical education",
      "pub_types": "Journal Article",
      "pmcid": "PMC10630872"
    },
    {
      "pmid": "34165150",
      "title": "Pharmacoepidemiology, Machine Learning, and COVID-19: An Intent-to-Treat Analysis of Hydroxychloroquine, With or Without Azithromycin, and COVID-19 Outcomes Among Hospitalized US Veterans.",
      "abstract": "Hydroxychloroquine (HCQ) was proposed as an early therapy for coronavirus disease 2019 (COVID-19) after in vitro studies indicated possible benefit. Previous in vivo observational studies have presented conflicting results, though recent randomized clinical trials have reported no benefit from HCQ among patients hospitalized with COVID-19. We examined the effects of HCQ alone and in combination with azithromycin in a hospitalized population of US veterans with COVID-19, using a propensity score-adjusted survival analysis with imputation of missing data. According to electronic health record data from the US Department of Veterans Affairs health care system, 64,055 US Veterans were tested for the virus that causes COVID-19 between March 1, 2020 and April 30, 2020. Of the 7,193 veterans who tested positive, 2,809 were hospitalized, and 657 individuals were prescribed HCQ within the first 48-hours of hospitalization for the treatment of COVID-19. There was no apparent benefit associated with HCQ receipt, alone or in combination with azithromycin, and there was an increased risk of intubation when HCQ was used in combination with azithromycin (hazard ratio = 1.55; 95% confidence interval: 1.07, 2.24). In conclusion, we assessed the effectiveness of HCQ with or without azithromycin in treatment of patients hospitalized with COVID-19, using a national sample of the US veteran population. Using rigorous study design and analytic methods to reduce confounding and bias, we found no evidence of a survival benefit from the administration of HCQ.",
      "authors": "Gerlovin Hanna; Posner Daniel C; Ho Yuk-Lam; Rentsch Christopher T; Tate Janet P; King Joseph T; Kurgansky Katherine E; Danciu Ioana; Costa Lauren; Linares Franciel A; Goethert Ian D; Jacobson Daniel A; Freiberg Matthew S; Begoli Edmon; Muralidhar Sumitra; Ramoni Rachel B; Tourassi Georgia; Gaziano J Michael; Justice Amy C; Gagnon David R; Cho Kelly",
      "year": "2021",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwab183",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34165150/",
      "mesh_terms": "Aged; Aged, 80 and over; Anti-Bacterial Agents; Azithromycin; COVID-19; Drug Therapy, Combination; Female; Hospitalization; Humans; Hydroxychloroquine; Intention to Treat Analysis; Machine Learning; Male; Middle Aged; Pharmacoepidemiology; Retrospective Studies; SARS-CoV-2; Treatment Outcome; United States; Veterans; COVID-19 Drug Treatment",
      "keywords": "COVID-19; gradient boosting; hydroxychloroquine; pharmacoepidemiology; propensity score; survival analysis; treatment outcome",
      "pub_types": "Journal Article",
      "pmcid": "PMC8384407"
    },
    {
      "pmid": "40796905",
      "title": "Dual-platform integration of HPTLC and firefly algorithm-optimized chemometrics with hammersley sequence sampling for simultaneous quantification of bisoprolol, amlodipine, and mutagenic impurity 4-hydroxybenzaldehyde.",
      "abstract": "The simultaneous quantification of active pharmaceutical ingredients alongside their mutagenic impurities represents a critical challenge in pharmaceutical quality control. This study presents the first multicolor analytical platform for concurrent determination of bisoprolol fumarate (BIP), amlodipine besylate (AML), and 4-hydroxybenzaldehyde (HBZ), a Class 3 mutagenic impurity in BIP requiring strict regulatory monitoring. Two complementary methodologies were developed: high-performance thin-layer chromatography (HPTLC)-densitometry and Firefly Algorithm-optimized partial least squares (FA-PLS) spectrophotometry, both aligned with green analytical chemistry (GAC) and white analytical chemistry (WAC) principles. The HPTLC method employed an eco-friendly mobile phase of ethyl acetate-ethanol (7:3, v/v), achieving baseline separation with Rf values of 0.29\u2009\u00b1\u20090.02 (HBZ), 0.72\u2009\u00b1\u20090.01 (AML), and 0.83\u2009\u00b1\u20090.01 (BIP). The FA-PLS model incorporated a novel Hammersley Sequence Sampling (HSS) strategy for validation set construction, ensuring uniform concentration space coverage and eliminating sampling bias inherent in conventional random approaches. This innovation, combined with a 52 mixture experimental design for calibration (25 mixtures), significantly enhanced model robustness and predictive capability. Both methods demonstrated superior analytical performance with detection limits of 3.56-20.52 ng/band (HPTLC) and 0.011-0.120 \u03bcg/mL (FA-PLS), correlation coefficients\u2009\u2265\u20090.9995, and precision (RSD)\u2009\u2264\u20092%. Comprehensive sustainability assessment using multiple evaluation tools revealed exceptional environmental profiles: perfect NEMI, AGREE, and ComplexGAPI scores, high GEMAM indices (7.015 and 7.487), minimal carbon footprints (0.037 and 0.021 kg CO\u2082/sample), and outstanding BAGI (87.50 and 90.00), VIGI (75.00 and 80.00), and RGBfast scores (81.00 and 85.00) for HPTLC and FA-PLS, respectively. NQS evaluation confirmed alignment with eleven UN Sustainable Development Goals, particularly SDG 3 (Good Health and Well-being), SDG 9 (Industry, Innovation and Infrastructure), and SDG 12 (Responsible Consumption and Production), yielding overall sustainability scores of 82% and 83%. Successful application to pharmaceutical dosage forms validated the methods' practical utility. This work establishes a new paradigm in sustainable pharmaceutical analysis, demonstrating how algorithmic optimization and environmental consciousness can synergistically advance analytical science while meeting stringent regulatory requirements.",
      "authors": "Al-Khateeb Lateefa A; Abbas Ahmed Emad F; Elghobashy Mohamed R; Abo Talib Nisreen F; Naguib Ibrahim A; Alqarni Mohammed; Halim Michael K",
      "year": "2025",
      "journal": "BMC chemistry",
      "doi": "10.1186/s13065-025-01598-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40796905/",
      "mesh_terms": "",
      "keywords": "Firefly Algorithm-PLS chemometrics; Green HPTLC-densitometry; Hammersley Sequence Sampling; Multi-dimensional sustainability assessment; Mutagenic impurity quantification",
      "pub_types": "Journal Article",
      "pmcid": "PMC12345108"
    },
    {
      "pmid": "29263018",
      "title": "E-Cigarette Surveillance With Social Media Data: Social Bots, Emerging Topics, and Trends.",
      "abstract": "BACKGROUND: As e-cigarette use rapidly increases in popularity, data from online social systems (Twitter, Instagram, Google Web Search) can be used to capture and describe the social and environmental context in which individuals use, perceive, and are marketed this tobacco product. Social media data may serve as a massive focus group where people organically discuss e-cigarettes unprimed by a researcher, without instrument bias, captured in near real time and at low costs. OBJECTIVE: This study documents e-cigarette-related discussions on Twitter, describing themes of conversations and locations where Twitter users often discuss e-cigarettes, to identify priority areas for e-cigarette education campaigns. Additionally, this study demonstrates the importance of distinguishing between social bots and human users when attempting to understand public health-related behaviors and attitudes. METHODS: E-cigarette-related posts on Twitter (N=6,185,153) were collected from December 24, 2016, to April 21, 2017. Techniques drawn from network science were used to determine discussions of e-cigarettes by describing which hashtags co-occur (concept clusters) in a Twitter network. Posts and metadata were used to describe where geographically e-cigarette-related discussions in the United States occurred. Machine learning models were used to distinguish between Twitter posts reflecting attitudes and behaviors of genuine human users from those of social bots. Odds ratios were computed from 2x2 contingency tables to detect if hashtags varied by source (social bot vs human user) using the Fisher exact test to determine statistical significance. RESULTS: Clusters found in the corpus of hashtags from human users included behaviors (eg, #vaping), vaping identity (eg, #vapelife), and vaping community (eg, #vapenation). Additional clusters included products (eg, #eliquids), dual tobacco use (eg, #hookah), and polysubstance use (eg, #marijuana). Clusters found in the corpus of hashtags from social bots included health (eg, #health), smoking cessation (eg, #quitsmoking), and new products (eg, #ismog). Social bots were significantly more likely to post hashtags that referenced smoking cessation and new products compared to human users. The volume of tweets was highest in the Mid-Atlantic (eg, Pennsylvania, New Jersey, Maryland, and New York), followed by the West Coast and Southwest (eg, California, Arizona and Nevada). CONCLUSIONS: Social media data may be used to complement and extend the surveillance of health behaviors including tobacco product use. Public health researchers could harness these data and methods to identify new products or devices. Furthermore, findings from this study demonstrate the importance of distinguishing between Twitter posts from social bots and humans when attempting to understand attitudes and behaviors. Social bots may be used to perpetuate the idea that e-cigarettes are helpful in cessation and to promote new products as they enter the marketplace.",
      "authors": "Allem Jon-Patrick; Ferrara Emilio; Uppu Sree Priyanka; Cruz Tess Boley; Unger Jennifer B",
      "year": "2017",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/publichealth.8641",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29263018/",
      "mesh_terms": "",
      "keywords": "Twitter; electronic cigarettes; electronic nicotine delivery system; infoveillance; social bots; social media; vaping",
      "pub_types": "Journal Article",
      "pmcid": "PMC5752967"
    },
    {
      "pmid": "32843907",
      "title": "Differences in cohort study data affect external validation of artificial intelligence models for predictive diagnostics of dementia - lessons for translation into clinical practice.",
      "abstract": "Artificial intelligence (AI) approaches pose a great opportunity for individualized, pre-symptomatic disease diagnosis which plays a key role in the context of personalized, predictive, and finally preventive medicine (PPPM). However, to translate PPPM into clinical practice, it is of utmost importance that AI-based models are carefully validated. The validation process comprises several steps, one of which is testing the model on patient-level data from an independent clinical cohort study. However, recruitment criteria can bias statistical analysis of cohort study data and impede model application beyond the training data. To evaluate whether and how data from independent clinical cohort studies differ from each other, this study systematically compares the datasets collected from two major dementia cohorts, namely, the Alzheimer's Disease Neuroimaging Initiative (ADNI) and AddNeuroMed. The presented comparison was conducted on individual feature level and revealed significant differences among both cohorts. Such systematic deviations can potentially hamper the generalizability of results which were based on a single cohort dataset. Despite identified differences, validation of a previously published, ADNI trained model for prediction of personalized dementia risk scores on 244 AddNeuroMed subjects was successful: External validation resulted in a high prediction performance of above 80% area under receiver operator characteristic curve up to 6 years before dementia diagnosis. Propensity score matching identified a subset of patients from AddNeuroMed, which showed significantly smaller demographic differences to ADNI. For these patients, an even higher prediction performance was achieved, which demonstrates the influence systematic differences between cohorts can have on validation results. In conclusion, this study exposes challenges in external validation of AI models on cohort study data and is one of the rare cases in the neurology field in which such external validation was performed. The presented model represents a proof of concept that reliable models for personalized predictive diagnostics are feasible, which, in turn, could lead to adequate disease prevention and hereby enable the PPPM paradigm in the dementia field.",
      "authors": "Birkenbihl Colin; Emon Mohammad Asif; Vrooman Henri; Westwood Sarah; Lovestone Simon; Hofmann-Apitius Martin; Fr\u00f6hlich Holger",
      "year": "2020",
      "journal": "The EPMA journal",
      "doi": "10.1007/s13167-020-00216-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32843907/",
      "mesh_terms": "",
      "keywords": "Alzheimer\u2019s disease; Artificial intelligence; Bioinformatics; Cohort comparison; Cohort data; Data science; Dementia; Digital clinic; Disease modeling; Disease risk prediction; Health data; Individualized patient profiling; Interdisciplinary; Machine learning; Medical data; Model performance; Model validation; Multiprofessional; Neurodegeneration; Precision medicine; Predictive preventive personalized medicine (3 PM/PPPM); Propensity score matching; Risk modeling; Sampling bias; Survival analysis; Translational medicine",
      "pub_types": "Journal Article",
      "pmcid": "PMC7429672"
    },
    {
      "pmid": "40664602",
      "title": "Life Expectancy, Loss of Life Expectancy, and Lifetime Costs in Bipolar Disorder: A Nationwide Population-Based Study.",
      "abstract": "INTRODUCTION: Bipolar disorder (BD) significantly affects life expectancy (LE), results in substantial loss of LE, and contributes to high medical costs, with these impacts varying by age at onset and gender. Previous studies have often overlooked the significance of age at the onset when estimating LE in individuals with BD. This study aimed to address this limitation and assess the impacts of BD on LE, loss of LE, and medical costs for BD patients categorized by age and gender in Taiwan using a new semiparametric extrapolation method over an 11-year duration. METHODS: A rolling-over algorithm estimated the survival function, with lifetime risk extrapolated. LE and loss of LE were calculated by comparing BD patients to matched non-BD referents by sex, age, and diagnosis year. Lifetime medical costs were determined by multiplying average monthly expenses by survival rates. Data from Taiwan's National Health Insurance (2009-2019) identified BD patients aged 5-84 with \u2265\u20092 outpatient or \u2265\u20091 inpatient BD diagnosis. The semiparametric survival extrapolation method was validated by comparing it with the Kaplan-Meier analysis. RESULTS: The results indicate that following a BD diagnosis, patients have an LE of 26.79\u2009years, reflecting a loss of 15.08\u2009years compared to matched referents. On average, patients with BD incurred annual medical expenses of around $2516, with costs rising with age for both sexes. The mean estimated lifetime cost for the study population was about $55,015. The extrapolation method demonstrated high accuracy, with a less than 5% relative bias. CONCLUSION: Semiparametric extrapolation is an effective method for estimating LE, loss of LE, and lifetime costs in BD. Future work could refine semiparametric extrapolation and assess factors influencing LE loss and lifetime costs in BD.",
      "authors": "Malau Ikbal Andrian; Chiu Ying-Ming; Chang Hui-Chih; Yang Ya-Chu; Chang Jane Pei-Chen; Correll Christoph U; Eduard Vieta; Su Kuan-Pin",
      "year": "2025",
      "journal": "Acta psychiatrica Scandinavica",
      "doi": "10.1111/acps.70013",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40664602/",
      "mesh_terms": "Humans; Bipolar Disorder; Life Expectancy; Female; Male; Taiwan; Middle Aged; Adult; Aged; Adolescent; Aged, 80 and over; Health Care Costs; Young Adult; Child; Child, Preschool",
      "keywords": "biostatistics; bipolar disorder; epidemiology; public mental health",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "30848164",
      "title": "The effect of surgical setting on anterior cruciate ligament reconstruction outcomes.",
      "abstract": "Objective: Ambulatory surgical centers (ASC's) have emerged as an alternative to the traditional hospital- based outpatient department (HOPD). We aim to determine the effect of surgical setting on adverse events following anterior cruciate ligament reconstruction (ACLR).Methods: The Humana Claims Database was queried for all patients undergoing ACLR in the HOPD or ASC setting, using the PearlDiver supercomputer. To eliminate selection bias in our study, the HOPD and ASC cohorts were propensity score matched on baseline demographics, comorbidities, and operative factors. Comparisons between the matched cohorts were made using chi-square tests. Logistic regression models were created to determine the effect of surgical setting on adverse events.Results: A total of 13,647 patients were queried in our study, 5,298 of whom underwent surgery in an ASC and 8,349 of whom underwent surgery in an HOPD. Analysis of the post-matched cohort revealed no differences between cohorts for mechanical failure, nerve injury, pulmonary embolism, septic joint, wound infection, revision surgery and readmission. Rates of deep vein thrombosis (1.18% vs 1.84%; p = .03) were significantly lower in the ASC group. On logistic regression, ASC was associated with decreased risk for deep vein thrombosis (.87, .83-.93) and pulmonary embolism (.85, .78-.95).Conclusion: ACLR performed in ASC is associated with reduced risk of venous thromboembolism and no difference in surgical morbidity and readmissions versus ACLR performed in HOPD. Development of a standardized algorithm for patient selection in the ASC setting is needed to preserve acceptability of ASC-based ACLR in cost-savings and patient safety models.",
      "authors": "Qin Charles; Helfrich Mia M; Curtis Daniel M; Ho Sherwin; Athiviraham Aravind",
      "year": "2019",
      "journal": "The Physician and sportsmedicine",
      "doi": "10.1080/00913847.2019.1592335",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30848164/",
      "mesh_terms": "Ambulatory Care; Ambulatory Care Facilities; Ambulatory Surgical Procedures; Anterior Cruciate Ligament Injuries; Anterior Cruciate Ligament Reconstruction; Cohort Studies; Comorbidity; Databases, Factual; Female; Humans; Logistic Models; Male; Outpatient Clinics, Hospital; Patient Selection; Reoperation",
      "keywords": "Health outcomes; ambulatory surgical center; anterior cruciate ligament reconstruction; health policy",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "36215866",
      "title": "Visual body composition assessment methods: A 4-compartment model comparison of smartphone-based artificial intelligence for body composition estimation in healthy adults.",
      "abstract": "BACKGROUND & AIMS: Visual body composition (VBC) estimates produced from smartphone-based artificial intelligence represent a user-friendly and convenient way to automate body composition remotely and without the inherent geographical and monetary restrictions of other body composition methods. However, there are limited studies that have assessed the reliability and agreement of this method and thus, the aim of this study was to evaluate VBC estimates compared to a 4-compartment (4C) criterion model. METHODS: A variety of body composition assessments were conducted across 184 healthy adult participants (114\u00a0F, 70\u00a0M) including dual-energy X-ray absorptiometry and bioimpedance spectroscopy for utilization in the 4C model and automated assessments produced from two smartphone applications (Amazon Halo\u00ae, HALO; and myBVI\u00ae) using either Apple\u00ae or Samsung\u00ae phones. Body composition components were compared to a 4C model using equivalence testing, root mean square error (RMSE), and Bland-Altman analysis. Separate analyses by sex and racial/ethnic groups were conducted. Precision metrics were conducted for 183 participants using intraclass correlation coefficients (ICC), root mean squared coefficients of variation (RMS-%CV) and precision error (PE). RESULTS: Only %fat produced from HALO devices demonstrated equivalence with the 4C model although mean differences for HALO were <\u00b11.0\u00a0kg for FM and FFM. RMSEs ranged from 3.9% to 6.2% for %fat and 3.1-5.2\u00a0kg for FM and FFM. Proportional bias was apparent for %fat across all VBC applications but varied for FM and FFM. Validity metrics by sex and specific racial/ethnic groups varied across applications. All VBC applications were reliable for %fat, fat mass (FM), and fat-free mass (FFM) with ICCs \u22650.99, RMS-%CV between 0.7% and 4.3%, and PEs between 0.3% and 0.6% for %fat and 0.2-0.5\u00a0kg for FM and FFM including assessments between smartphone types. CONCLUSIONS: Smartphone-based VBC estimates produce reliable body composition estimates but their equivalence with a 4C model varies by the body composition component being estimated and the VBC being employed. VBC estimates produced by HALO appear to have the lowest error, but proportional bias and estimates by sex and race vary across applications.",
      "authors": "Graybeal Austin J; Brandner Caleb F; Tinsley Grant M",
      "year": "2022",
      "journal": "Clinical nutrition (Edinburgh, Scotland)",
      "doi": "10.1016/j.clnu.2022.09.014",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36215866/",
      "mesh_terms": "Adult; Humans; Electric Impedance; Reproducibility of Results; Smartphone; Artificial Intelligence; Body Composition; Absorptiometry, Photon",
      "keywords": "Body composition assessment; Digital anthropometry; Machine learning; Mobile health; Obesity; Smartphone",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "34261173",
      "title": "Novel Nonproprietary Measures of Ambulatory Electronic Health Record Use Associated with Physician Work Exhaustion.",
      "abstract": "BACKGROUND: Accumulating evidence indicates an association between physician electronic health record (EHR) use after work hours and occupational distress including burnout. These studies are based on either physician perception of time spent in EHR through surveys which may be prone to bias or by utilizing vendor-defined EHR use measures which often rely on proprietary algorithms that may not take into account variation in physician's schedules which may underestimate time spent on the EHR outside of scheduled clinic time. The Stanford team developed and refined a nonproprietary EHR use algorithm to track the number of hours a physician spends logged into the EHR and calculates the Clinician Logged-in Outside Clinic (CLOC) time, the number of hours spent by a physician on the EHR outside of allocated time for patient care. OBJECTIVE: The objective of our study was to measure the association between CLOC metrics and validated measures of physician burnout and professional fulfillment. METHODS: Physicians from adult outpatient Internal Medicine, Neurology, Dermatology, Hematology, Oncology, Rheumatology, and Endocrinology departments who logged more than 8\u2009hours of scheduled clinic time per week and answered the annual wellness survey administered in Spring 2019 were included in the analysis. RESULTS: We observed a statistically significant positive correlation between CLOC ratio (defined as the ratio of CLOC time to allocated time for patient care) and work exhaustion (Pearson's r\u2009=\u20090.14; p\u2009=\u20090.04), but not interpersonal disengagement, burnout, or professional fulfillment. CONCLUSION: The CLOC metrics are potential objective EHR activity-based markers associated with physician work exhaustion. Our results suggest that the impact of time spent on EHR, while associated with exhaustion, does not appear to be a dominant factor driving the high rates of occupational burnout in physicians.",
      "authors": "Sinha Amrita; Shanafelt Tait D; Trockel Mickey; Wang Hanhan; Sharp Christopher",
      "year": "2021",
      "journal": "Applied clinical informatics",
      "doi": "10.1055/s-0041-1731678",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34261173/",
      "mesh_terms": "Ambulatory Care Facilities; Burnout, Professional; Electronic Health Records; Humans; Physicians; Surveys and Questionnaires",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC8279819"
    },
    {
      "pmid": "34042883",
      "title": "Quality of Life as an Indicator for Care Delivery in Clinical Oncology Using FHIR.",
      "abstract": "INTRODUCTION: Health-related quality of life (HR-QoL) as a parameter for patient well-being is becoming increasingly important.[1] Nevertheless, it is mainly used as an endpoint in studies rather than as an indicator for adjustments in therapy. In this paper we will present an approach to gradually integrate quality of life (QoL) as a control element into the care delivery of oncology. CONCEPT: Acceptance, usability, interoperability and data protection were identified and integrated as key indicators for the development. As an initial approach, a questionnaire tool was developed to provide patients a simplified answering of questionnaires and physicians a clearer presentation of the results. IMPLEMENTATION: As communication standard HL7 FHIR was used and known security concepts like OpenID Concept were integrated. In a usability study, first results were achieved by asking patients in the waiting room to answer a questionnaire, which will be discussed with the physician in the appointment. This study was conducted in 2019 at theSLK Clinics Heilbronn and achieved 86% participation of all respondents with an average age of 67 years. DISCUSSION: Although the evaluation study could prove positive results in usability and acceptance, it is necessary to aim for longitudinal surveys in order to include QoL as a control element in the therapy. However, a longitudinal survey through questionnaires leads to decreasing compliance and increasing response bias. [2] For this reason, the concept needs to be expanded. With sensors a continuous monitoring can be carried out and the data can be mapped to the individual, interpreted by machine learning. CONCLUSION: Questionnaires are a concept that has been successfully applied in studies for years. However, since care delivery poses different challenges, the integration of new concepts is inevitable. The authors are currently working on an extension of the use of questionnaires with patient generated data through sensors.",
      "authors": "Beutter Chantal N L; Ross Jan; Werner Patrick; Vladimirova Dilyana; Martens Uwe M; Fegeler Christian",
      "year": "2021",
      "journal": "Studies in health technology and informatics",
      "doi": "10.3233/SHTI210058",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34042883/",
      "mesh_terms": "Aged; Child; Delivery of Health Care; Electronic Health Records; Female; Humans; Infant, Newborn; Medical Oncology; Pregnancy; Quality of Life; Surveys and Questionnaires",
      "keywords": "FHIR; Quality of life; monitoring; oncology; patient empowerment; patient generated data; patient reported outcome",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40631502",
      "title": "Novel Algorithm to Estimate Fat-Free Muscle Volumes in Women Using the Urinary Deuterated-Creatine Dilution Method.",
      "abstract": "BACKGROUND: Muscle mass declines after menopause and is a key risk factor for frailty, falls and poor physical function as women age. The deuterated creatine (D3Cr) dilution method provides a direct assessment of muscle mass, but its accuracy in Asian women has not been evaluated. Our aim was to develop a new D3Cr algorithm incorporating anthropomorphic variables that can estimate fat-free muscle mass, using magnetic resonance imaging (MRI) as the reference standard. METHODS: The Integrated Women's Health Programme (IWHP) enrolled 1201 healthy community-dwelling women, aged 45-69\u2009years at baseline, who attended gynaecological clinics from 2014 to 2016. Between February 2021 and July 2023, 894 participants were recontacted, and 451 of the respondents agreed to ingest 30\u2009mg of D3Cr and had available MRI measurements of fat-free thigh and erector spinae volumes. Urinary levels of creatine, creatinine and D3-creatinine levels were measured by tandem mass spectrometry 4\u2009days after ingestion of D3Cr. Muscle mass was estimated using the two D3Cr algorithms (D3Croriginal and D3Crmodified) in current use and a newly developed algorithm (D3CrHt-Wt) incorporating anthropometric variables that estimate fat-free muscle volumes. Pearson's correlation analyses were used to compare the performances of the D3Cr algorithms with MRI. Bland-Altman analysis was used to ascertain agreement between D3CrHt-Wt and MRI. RESULTS: Participants (n\u2009=\u2009451, mean age 62.6\u2009\u00b1\u20095.9) were randomly divided into training (n\u2009=\u2009367) and validation (n\u2009=\u200984) cohorts. In the training cohort, stepwise multivariable regression modelling indicated that age (\u03b2\u2009=\u2009-0.011, p\u2009=\u20090.076) and ethnicity (\u03b2\u2009=\u20090.154, p\u2009=\u20090.317 [Indian]; \u03b2\u2009=\u2009-0.012, p\u2009=\u20090.942 [Malay] compared to Chinese) were not associated with fat-free muscle volumes. In the final model, D3Cr-determined creatine pool size (\u03b2\u2009=\u20090.032, p\u2009<\u20090.001), body weight (\u03b2\u2009=\u20090.030, p\u2009<\u20090.001) and height (\u03b2\u2009=\u20094.336, p\u2009<\u20090.001) were independently associated with fat-free muscle volumes and were incorporated into a new algorithm (D3CrHt-Wt). In a separate validation cohort, muscle volumes estimated using the D3CrHt-Wt algorithm (R\u2009=\u20090.813) had a higher correlation with MRI-measured fat-free muscle volumes than both D3Croriginal (R\u2009=\u20090.672) and D3Crmodified (R\u2009=\u20090.692) algorithms. Bland-Altman analysis indicated a low bias of 0.112\u2009L and limits of agreement of -0.969\u2009L to +1.190\u2009L. CONCLUSIONS: Muscle volumes estimated with the D3CrHt-Wt algorithm had high correlation and agreement with MRI-measured fat-free muscle volumes. The convenience of the D3Cr method for participants suggests its potential to be a clinically relevant method for assessing fat-free muscle volumes in sarcopenia studies.",
      "authors": "Tan Darren Yuen Zhang; Cheong Wei Fun; Ji Shanshan; Cazenave-Gassiot Amaury; Cauley Jane; Shen Liang; Yong Eu-Leong",
      "year": "2025",
      "journal": "Journal of cachexia, sarcopenia and muscle",
      "doi": "10.1002/jcsm.13872",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40631502/",
      "mesh_terms": "Humans; Female; Middle Aged; Algorithms; Aged; Creatine; Muscle, Skeletal; Magnetic Resonance Imaging; Deuterium",
      "keywords": "MRI; body composition; creatine; creatinine; muscle mass; sarcopenia",
      "pub_types": "Journal Article",
      "pmcid": "PMC12238901"
    },
    {
      "pmid": "1801203",
      "title": "Infant mortality in a Mexican-American community: Laredo, Texas, 1950-1977.",
      "abstract": "Published infant mortality rates (IMR's) for Mexican-American populations frequently are lower than expected given the socioeconomic status (SES) of these populations. It has been speculated that this is due to bias or incompleteness in Mexican-American vital statistics. In this paper an extensive genealogical data base constructed from Catholic church records and civil records for the border city of Laredo, Texas is used to study this problem. The infant mortality probabilities (IMP's) since 1950 are compared to conventional IMR's, both based strictly on the population at risk defined by baptisms, in which the deaths are a proper subset of the denominator, and these are compared with IMR's calculated in the usual way from aggregate civil records of births and infant deaths for Laredo. We find that when these data are used, the IMR's for the most recent years are about twice the conventional rates computed from registered vital statistics.",
      "authors": "Buchanan A; Weiss K M",
      "year": "1991",
      "journal": "Social biology",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/1801203/",
      "mesh_terms": "Bias; Cohort Studies; Hispanic or Latino; Humans; Infant Mortality; Infant, Newborn; Reproducibility of Results; Socioeconomic Factors; Texas; Vital Statistics",
      "keywords": "Americas; Birth Records; Cultural Background; Data Collection; Data Linkage; Death Records; Delivery Of Health Care; Demographic Factors; Developed Countries; Dual Data Collection; Economic Factors; Error Sources; Estimation Technics; Ethnic Groups; Family And Household; Family Research; Genealogies; Health; Health Facilities; Hispanics; Hospitals; Infant Mortality; Measurement; Migration; Mortality; North America; Northern America; Parish Registers; Population; Population Characteristics; Population Dynamics; Population Statistics; Poverty; Research Methodology; Research Report; Socioeconomic Factors; Statistical Studies; Studies; Temporary Migration; Texas; United States; Vital Statistics",
      "pub_types": "Journal Article; Research Support, U.S. Gov't, Non-P.H.S.; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "40921416",
      "title": "Patient Disability Status and the Use of Stigmatizing Language in Clinical Notes During Hospital Admission for Birth.",
      "abstract": "OBJECTIVE: To examine the association between patient disability status and use of stigmatizing language in clinical notes from the hospital admission for birth. DESIGN: Cross-sectional study of electronic health record data. SETTING: Two urban hospitals in the northeastern United States. PARTICIPANTS: Patients at more than 20 weeks gestation admitted for birth from 2017 to 2019 (N = 19,094). METHODS: We used a natural language processing algorithm to identify categories of stigmatizing language used in free-text clinical notes (N = 211,841 unique clinical notes). We employed multivariable logistic regression to estimate adjusted odds ratios (aORs) and 95% confidence intervals (CIs) for each stigmatizing language category by disability status, which we determined by ICD-10 (International Classification of Diseases, 10th revision) codes. RESULTS: Approximately 3% of patient records (n = 550) included ICD-10 codes for disability. Clinicians were more likely to use stigmatizing language for patients with disabilities compared with patients without disabilities (aOR = 1.75, 95% CI = [1.47, 2.09]). For patients with disabilities compared with patients without disabilities, clinicians were also more likely to use stigmatizing language in the difficult patient category (aOR = 1.96, 95% CI = [1.65, 2.33]) and the unilateral/authoritarian decisions category (aOR = 1.27, 95% CI = [1.06, 1.53]). We found no significant differences for the marginalized language/identities category by patient disability status (aOR = 1.19, 95% CI = [0.87, 1.62]). CONCLUSION: The use of stigmatizing language in birth hospitalization notes differed by patient disability status. Stigmatizing language should be used as a marker of bias and an opportunity for clinicians to reflect on their thoughts, words, and actions. Patient-centered documentation and care practices are needed to improve perinatal health for all.",
      "authors": "Harkins Sarah E; Hulchafo Ismael I; Scroggins Jihye Kim; Walsh Caroline; Didier Meghan; Topaz Maxim; Barcelona Veronica",
      "year": "2025",
      "journal": "Journal of obstetric, gynecologic, and neonatal nursing : JOGNN",
      "doi": "10.1016/j.jogn.2025.08.003",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40921416/",
      "mesh_terms": "Humans; Female; Cross-Sectional Studies; Adult; Electronic Health Records; Pregnancy; Persons with Disabilities; Stereotyping",
      "keywords": "disability discrimination; health equity; labor; natural language processing; obstetric; stigmatizing language",
      "pub_types": "Journal Article",
      "pmcid": "PMC12755039"
    },
    {
      "pmid": "35528960",
      "title": "Cross-sectional study to assess etiology and associated factors for anaemia during first trimester of pregnancy in Anuradhapura District, Sri Lanka: a protocol.",
      "abstract": "Background: Anaemia in pregnancy, which can lead to adverse maternal and fetal outcomes, is a significant global health problem. Despite Sri Lanka's strong public health system and commitment towards prevention, maternal anaemia remains a major problem in the country. While prevention is focused on iron deficiency, detailed etiological studies on this topic are scarce. Moreover, estimates of socio demographic and economic factors associated with anaemia in pregnancy, which can provide important clues for anaemia control, are also lacking. This study aims to evaluate the hemoglobin distribution, and geographical distribution, contribution of known aetiologies and associated factors for anaemia in pregnant women in Anuradhapura, Sri Lanka. Methods: This is a cross sectional study of pregnant women in their first trimester registered for antenatal care from July to September 2019 in Anuradhapura district. The minimal sample size was calculated to be 1866. Initial data collection has already been carried out in special field clinics for pregnant women between June to October 2019. An interviewer-administered questionnaire, a self-completed dietary questionnaire and an examination checklist were used for data collection. In addition, all participants underwent complete blood count testing. Further investigations are being conducted for predicting the etiology of anaemia based on a developed algorithm (such as high-performance liquid chromatography [HPLC] and peripheral blood film analysis). Discussion: Being the largest study on anaemia during pregnancy in a single geographical area in Sri Lanka, this study will provide important clues about geographical clustering of anaemia cases with similar etiology, associated factors and etiologies which would help to develop interventions to improve the health of pregnant women in the area. The possibility of selection bias is a potential limitation associated with the study design.",
      "authors": "Amarasinghe Gayani; Mendis Vasana; Agampodi Thilini; Agampodi Suneth",
      "year": "2021",
      "journal": "F1000Research",
      "doi": "10.12688/f1000research.28226.3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35528960/",
      "mesh_terms": "Anemia; Cross-Sectional Studies; Female; Humans; Pregnancy; Pregnancy Trimester, First; Pregnant People; Sri Lanka",
      "keywords": "Anemia; Anuradhapura; Pregnancy; Sri Lanka",
      "pub_types": "Journal Article",
      "pmcid": "PMC9039368"
    },
    {
      "pmid": "27716347",
      "title": "Assessing the external validity of algorithms to estimate EQ-5D-3L from the WOMAC.",
      "abstract": "BACKGROUND: The use of mapping algorithms have been suggested as a solution to predict health utilities when no preference-based measure is included in the study. However, validity and predictive performance of these algorithms are highly variable and hence assessing the accuracy and validity of algorithms before use them in a new setting is of importance. The aim of the current study was to assess the predictive accuracy of three mapping algorithms to estimate the EQ-5D-3L from the Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC) among Swedish people with knee disorders. Two of these algorithms developed using ordinary least squares (OLS) models and one developed using mixture model. METHODS: The data from 1078 subjects mean (SD) age 69.4 (7.2) years with frequent knee pain and/or knee osteoarthritis from the Malm\u00f6 Osteoarthritis study in Sweden were used. The algorithms' performance was assessed using mean error, mean absolute error, and root mean squared error. Two types of prediction were estimated for mixture model: weighted average (WA), and conditional on estimated component (CEC). RESULTS: The overall mean was overpredicted by an OLS model and underpredicted by two other algorithms (P\u2009<\u20090.001). All predictions but the CEC predictions of mixture model had a narrower range than the observed scores (22 to 90\u00a0%). All algorithms suffered from overprediction for severe health states and underprediction for mild health states with lesser extent for mixture model. While the mixture model outperformed OLS models at the extremes of the EQ-5D-3D distribution, it underperformed around the center of the distribution. CONCLUSIONS: While algorithm based on mixture model reflected the distribution of EQ-5D-3L data more accurately compared with OLS models, all algorithms suffered from systematic bias. This calls for caution in applying these mapping algorithms in a new setting particularly in samples with milder knee problems than original sample. Assessing the impact of the choice of these algorithms on cost-effectiveness studies through sensitivity analysis is recommended.",
      "authors": "Kiadaliri Aliasghar A; Englund Martin",
      "year": "2016",
      "journal": "Health and quality of life outcomes",
      "doi": "10.1186/s12955-016-0547-y",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27716347/",
      "mesh_terms": "Aged; Algorithms; Arthralgia; Female; Humans; Least-Squares Analysis; Male; Middle Aged; Models, Theoretical; Osteoarthritis, Knee; Predictive Value of Tests; Quality of Life; Surveys and Questionnaires; Sweden",
      "keywords": "EQ-5D-3L; External validity; Knee osteoarthritis; Knee pain; Mapping algorithms; WOMAC",
      "pub_types": "Journal Article",
      "pmcid": "PMC5050671"
    },
    {
      "pmid": "38490752",
      "title": "MIRO study: Do the results of a randomized controlled trial apply in a real population?",
      "abstract": "BACKGROUND: The aim of our study was to evaluate the external validity of the MIRO randomized controlled trial findings in a similar nationwide setting \"real life\" population, especially the benefit of a hybrid approach in esophageal resection for pulmonary complication. The external validity of randomized controlled trial findings to the general population with the same condition remains problematic because of the inherent selection bias and rigid inclusion criteria. METHODS: This study was a cohort study from a National Health Database (Programme de Medicalisation des Systemes d'Informations) between 2010 and 2022. All adult patients operated on using Ivor Lewis resection for esophageal cancer were included. We first validated the detection algorithm of postoperative complications in the health database. Then, we assessed the primary outcome, which was the comparison of postoperative severe pulmonary complications, leak rate, and 30-day mortality between the 2 surgical approaches (hybrid versus open) over a decade. RESULTS: Between 2010 and 2012, 162 of 205 patients in the MIRO trial were anonymously identified in the health care database. No difference between randomized controlled trials and healthcare database measurements was found within severe respiratory complications (24% vs 22%, respectively) nor within leak rate (10% vs 9%, respectively). After application of selection criteria according to the MIRO trial, 3,852 patients were included between 2013 and 2022. The hybrid approach was a protective factor against respiratory complications after adjustment for confounding variables (odds ratio\u00a0= 0.83; 95% confidence interval\u00a0= 0.71-0.98, P\u00a0= .025). No significant difference in the 30-day mortality rate or 30-day leakage rate between the types of approach was reported. CONCLUSION: This national cohort study demonstrates the external validity of the MIRO randomized controlled trial findings in a real-life population within France.",
      "authors": "Challine Alexandre; Kirouani Mehdi; Markar Sheraz R; Tzedakis Stylianos; Jaquet Romain; Piessen Guillaume; Dabakoyo-Yonli Tienhan Sandrine; Lef\u00e8vre J\u00e9r\u00e9mie H; Lazzati Andrea; Voron Thibault",
      "year": "2024",
      "journal": "Surgery",
      "doi": "10.1016/j.surg.2023.11.026",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38490752/",
      "mesh_terms": "Adult; Humans; Esophagectomy; Cohort Studies; Postoperative Complications; Esophageal Neoplasms; Randomized Controlled Trials as Topic",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39993309",
      "title": "Leveraging Medical Knowledge Graphs Into Large Language Models for Diagnosis Prediction: Design and Application Study.",
      "abstract": "BACKGROUND: Electronic health records (EHRs) and routine documentation practices play a vital role in patients' daily care, providing a holistic record of health, diagnoses, and treatment. However, complex and verbose EHR narratives can overwhelm health care providers, increasing the risk of diagnostic inaccuracies. While large language models (LLMs) have showcased their potential in diverse language tasks, their application in health care must prioritize the minimization of diagnostic errors and the prevention of patient harm. Integrating knowledge graphs (KGs) into LLMs offers a promising approach because structured knowledge from KGs could enhance LLMs' diagnostic reasoning by providing contextually relevant medical information. OBJECTIVE: This study introduces DR.KNOWS (Diagnostic Reasoning Knowledge Graph System), a model that integrates Unified Medical Language System-based KGs with LLMs to improve diagnostic predictions from EHR data by retrieving contextually relevant paths aligned with patient-specific information. METHODS: DR.KNOWS combines a stack graph isomorphism network for node embedding with an attention-based path ranker to identify and rank knowledge paths relevant to a patient's clinical context. We evaluated DR.KNOWS on 2 real-world EHR datasets from different geographic locations, comparing its performance to baseline models, including QuickUMLS and standard LLMs (Text-to-Text Transfer Transformer and ChatGPT). To assess diagnostic reasoning quality, we designed and implemented a human evaluation framework grounded in clinical safety metrics. RESULTS: DR.KNOWS demonstrated notable improvements over baseline models, showing higher accuracy in extracting diagnostic concepts and enhanced diagnostic prediction metrics. Prompt-based fine-tuning of Text-to-Text Transfer Transformer with DR.KNOWS knowledge paths achieved the highest ROUGE-L (Recall-Oriented Understudy for Gisting Evaluation-Longest Common Subsequence) and concept unique identifier F1-scores, highlighting the benefits of KG integration. Human evaluators found the diagnostic rationales of DR.KNOWS to be aligned strongly with correct clinical reasoning, indicating improved abstraction and reasoning. Recognized limitations include potential biases within the KG data, which we addressed by emphasizing case-specific path selection and proposing future bias-mitigation strategies. CONCLUSIONS: DR.KNOWS offers a robust approach for enhancing diagnostic accuracy and reasoning by integrating structured KG knowledge into LLM-based clinical workflows. Although further work is required to address KG biases and extend generalizability, DR.KNOWS represents progress toward trustworthy artificial intelligence-driven clinical decision support, with a human evaluation framework focused on diagnostic safety and alignment with clinical standards.",
      "authors": "Gao Yanjun; Li Ruizhe; Croxford Emma; Caskey John; Patterson Brian W; Churpek Matthew; Miller Timothy; Dligach Dmitriy; Afshar Majid",
      "year": "2025",
      "journal": "JMIR AI",
      "doi": "10.2196/58670",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39993309/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; diagnosis prediction; electronic health record; graph model; knowledge graph; large language model; machine learning; natural language processing",
      "pub_types": "Journal Article",
      "pmcid": "PMC11894347"
    },
    {
      "pmid": "32706730",
      "title": "Assessment of Population Well-Being With the Mental Health Quotient (MHQ): Development and Usability Study.",
      "abstract": "BACKGROUND: Existing mental health assessment tools provide an incomplete picture of symptom experience and create ambiguity, bias, and inconsistency in mental health outcomes. Furthermore, by focusing on disorders and dysfunction, they do not allow a view of mental health and well-being across a general population. OBJECTIVE: This study aims to demonstrate the outcomes and validity of a new web-based assessment tool called the Mental Health Quotient (MHQ), which is designed for the general population. The MHQ covers the complete breadth of clinical mental health symptoms and also captures healthy mental functioning to provide a complete profile of an individual's mental health from clinical to thriving. METHODS: The MHQ was developed based on the coding of symptoms assessed in 126 existing Diagnostic and Statistical Manual of Mental Disorders (DSM)-based psychiatric assessment tools as well as neuroscientific criteria laid out by Research Domain Criteria to arrive at a comprehensive set of semantically distinct mental health symptoms and attributes. These were formulated into questions on a 9-point scale with both positive and negative dimensions and developed into a web-based tool that takes approximately 14 min to complete. As its output, the assessment provides overall MHQ scores as well as subscores for 6 categories of mental health that distinguish clinical and at-risk groups from healthy populations based on a nonlinear scoring algorithm. MHQ items were also mapped to the DSM fifth edition (DSM-5), and clinical diagnostic criteria for 10 disorders were applied to the MHQ outcomes to cross-validate scores labeled at-risk and clinical. Initial data were collected from 1665 adult respondents to test the tool. RESULTS: Scores in the normal healthy range spanned from 0 to 200 for the overall MHQ, with an average score of approximately 100 (SD 45), and from 0 to 100 with average scores between 48 (SD 21) and 55 (SD 22) for subscores in each of the 6 mental health subcategories. Overall, 2.46% (41/1665) and 13.09% (218/1665) of respondents were classified as clinical and at-risk, respectively, with negative scores. Validation against DSM-5 diagnostic criteria showed that 95% (39/41) of those designated clinical were positive for at least one DSM-5-based disorder, whereas only 1.14% (16/1406) of those with a positive MHQ score met the diagnostic criteria for a mental health disorder. CONCLUSIONS: The MHQ provides a fast, easy, and comprehensive way to assess population mental health and well-being; identify at-risk individuals and subgroups; and provide diagnosis-relevant information across 10 disorders.",
      "authors": "Newson Jennifer Jane; Thiagarajan Tara C",
      "year": "2020",
      "journal": "JMIR mental health",
      "doi": "10.2196/17935",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32706730/",
      "mesh_terms": "",
      "keywords": "anxiety; attention deficit disorder with hyperactivity; autistic disorder; behavioral symptoms; depression; diagnosis; global health; internet; mental disorders; mental health; methods; mhealth; population health; psychiatry; psychopathology; public health; social determinants of health; symptom assessment",
      "pub_types": "Journal Article",
      "pmcid": "PMC7400040"
    },
    {
      "pmid": "37650944",
      "title": "UAV hyperspectral remote sensor images for mango plant disease and pest identification using MD-FCM and XCS-RBFNN.",
      "abstract": "To diminish disease transmission together with promoting effective management techniques, it is crucial to monitor plant health and detect pathogens earlier. The initial part in reducing losses sourced from plant diseases is to make an accurate and earlier identification. Thus, the usage of unmanned aerial vehicle (UAV) hyperspectral imaging (HSI) sensors for surveying and assessing crops, orchards, and forests has rapidly elevated over the last decade, particularly for the stress management like water, diseases, nutrition deficits, and pests. Using Minkowski Distance-based Fuzzy C Means (MD-FCM) clustering and Xavier initialization-adapted Cosine Similarity-induced Radial Bias Function Neural Network (XCS-RBFNN) techniques, a UAV HS imaging remote sensor for Spatial and Temporal Resolution (STR) of mango plant disease and pest identification is proposed in this scheme. Collecting the input UAV source (image or video) is eventuated initially along with the Region of Interest (ROI) calculated which is followed by preprocessing. Leaf segmentation is eventuated using Logistic U-net after preprocessing. Next, MD-FCM performs clustering to cluster the diseased leaves and pests individually. The disease and pest characteristics are then retrieved separately and classified further. The requisite features are then chosen from the retrieved features utilizing the Levy Flight Distribution-produced Butterfly Optimization Algorithm (LFD-BOA). Finally, the XCS-RBFNN classifier is utilized to categorize the various diseases together with pests found in the UAV input source using the chosen features. The proposed framework's experimental findings are then compared to some prevailing schemes, with the results revealing that the proposed work outperforms other benchmark techniques.",
      "authors": "Pansy D Lita; Murali M",
      "year": "2023",
      "journal": "Environmental monitoring and assessment",
      "doi": "10.1007/s10661-023-11678-9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37650944/",
      "mesh_terms": "Animals; Mangifera; Unmanned Aerial Devices; Environmental Monitoring; Algorithms; Birds; Plant Diseases",
      "keywords": "Crop disease identification; Fuzzy C Means (FCM) clustering; Hyperspectral imaging sensor; Remote sensing; Unmanned aerial vehicle (UAV)",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "26849644",
      "title": "Estimation of the Basic Reproductive Number and Mean Serial Interval of a Novel Pathogen in a Small, Well-Observed Discrete Population.",
      "abstract": "BACKGROUND: Accurately assessing the transmissibility and serial interval of a novel human pathogen is public health priority so that the timing and required strength of interventions may be determined. Recent theoretical work has focused on making best use of data from the initial exponential phase of growth of incidence in large populations. METHODS: We measured generational transmissibility by the basic reproductive number R0 and the serial interval by its mean Tg. First, we constructed a simulation algorithm for case data arising from a small population of known size with R0 and Tg also known. We then developed an inferential model for the likelihood of these case data as a function of R0 and Tg. The model was designed to capture a) any signal of the serial interval distribution in the initial stochastic phase b) the growth rate of the exponential phase and c) the unique combination of R0 and Tg that generates a specific shape of peak incidence when the susceptible portion of a small population is depleted. FINDINGS: Extensive repeat simulation and parameter estimation revealed no bias in univariate estimates of either R0 and Tg. We were also able to simultaneously estimate both R0 and Tg. However, accurate final estimates could be obtained only much later in the outbreak. In particular, estimates of Tg were considerably less accurate in the bivariate case until the peak of incidence had passed. CONCLUSIONS: The basic reproductive number and mean serial interval can be estimated simultaneously in real time during an outbreak of an emerging pathogen. Repeated application of these methods to small scale outbreaks at the start of an epidemic would permit accurate estimates of key parameters.",
      "authors": "Wu Kendra M; Riley Steven",
      "year": "2016",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0148061",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26849644/",
      "mesh_terms": "Basic Reproduction Number; Disease Outbreaks; Humans; Influenza A Virus, H1N1 Subtype; Influenza, Human; Severe acute respiratory syndrome-related coronavirus; Severe Acute Respiratory Syndrome",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC4744020"
    },
    {
      "pmid": "40628534",
      "title": "Validity of diagnostic codes used to ascertain maternal injuries during pregnancy.",
      "abstract": "Previous research has relied on International Classification of Diseases (ICD) codes to define maternal injuries. However, the validity of these codes remains unclear. We aimed to validate ICD-10 codes used to ascertain maternal injuries using medical chart reviews as the gold standard. A retrospective cohort study of all births occurring at Atrium Health Wake Forest Baptist Medical Center in 2022-2023. We randomly selected 100 subjects with ICD-10-indicated injury and 100 subjects without indication of injury. Two independent reviewers, blinded to the ICD-10-based classification, conducted the chart review. We examined the validity of relevant injury-related codes (V00-Y38; S00-T79; O9A.2-O9A.4) and calculated positive predictive values (PPVs) for different algorithms defined by varying the encounter type and the list of codes used. The algorithm that included all injury-related ICD-10 codes without encounter-type restrictions showed moderate PPV (71% [95% CI, 61%-79%]) and high negative predictive value (96% [90%-98%]). PPV was maximized when including codes V00-Y38 and restricting encounter type to inpatient or emergency department encounters (PPV 100% [93%-100%]). This study characterizes the accuracy of ICD-10-based algorithms for ascertaining maternal injuries during pregnancy. These findings can help improve inference by providing bias parameters for future research.",
      "authors": "Ahmed Asma M; Deria Riyan; Chavarria Rosalba Barojas; Sakowicz Allie; Stamilio David; Jensen Elizabeth T",
      "year": "2025",
      "journal": "American journal of epidemiology",
      "doi": "10.1093/aje/kwaf145",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40628534/",
      "mesh_terms": "Humans; Female; Pregnancy; International Classification of Diseases; Retrospective Studies; Wounds and Injuries; Algorithms; Adult; Pregnancy Complications; Reproducibility of Results",
      "keywords": "ICD-10 codes; PPV; car accidents; diagnostic codes; falls; maternal injuries; positive predictive value; validation",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC12634104"
    },
    {
      "pmid": "37692913",
      "title": "Use of Open Claims vs Closed Claims in Health Outcomes Research.",
      "abstract": "Background: Closed claims are frequently used in outcomes research studies. Lately, the availability of open claims has increased the possibility of obtaining information faster and on a larger scale. However, because of the possibility of missing claims and duplications, these data sets have not been highly utilized in medical research. Objective: To compare frequently used healthcare utilization measures between closed claims and open claims to analyze if the possibility of missing claims in open claims data creates a downward bias in the estimates. Methods: We identified 18 different diseases using 2022 data from 2 closed claims data sets (MarketScan\u00ae and PharMetrics\u00ae Plus) and 1 open claims database (Kythera). After applying an algorithm that removes possible duplications from open claims data, we compared healthcare utilizations such as inpatient, emergency department, and outpatient use and length of stay among these 3 data sets. We applied standardized differences to compare the medians for each outcome. Results: The sample size of the open claims data sets was 10 to 65 times larger than closed claims data sets depending on disease type. For each disease, the estimates of healthcare utilization were similar between the open claims and closed claims data. The difference was statistically insignificant. Conclusions: Open claims data with a bigger sample size and more current available information provide essential advantages for healthcare outcomes research studies. Therefore, especially for new medications and rare diseases, open claims data can provide information much earlier than closed claims, which usually have a time lag of 6 to 8 months.",
      "authors": "Baser Onur; Samayoa Gabriela; Yapar Nehir; Baser Erdem; Mete Fatih",
      "year": "2023",
      "journal": "Journal of health economics and outcomes research",
      "doi": "10.36469/001c.87538",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37692913/",
      "mesh_terms": "",
      "keywords": "Kythera; MarketScan\u00ae; PharMetrics\u00ae Plus; closed claims; open claims; outcomes research",
      "pub_types": "Journal Article",
      "pmcid": "PMC10484335"
    },
    {
      "pmid": "37453601",
      "title": "Patient Perspectives on Artificial Intelligence in Radiology.",
      "abstract": "There are two major areas for patient engagement in radiology artificial intelligence (AI). One is in the sharing of data for AI development; the second is the use of AI in patient care. In general, individuals support sharing deidentified data if used for the common good, to help others with similar health conditions, or for research. However, there is concern with risk to privacy including reidentification and use for other than intended purposes. Lack of trust is mentioned as a barrier for data sharing. Individuals want to be involved in the data-sharing process. In the use of AI in medical care, patients generally support AI as an assist to the radiologist but lack trust in unsupervised AI. Patients worry about liability in case of bad outcomes. Patients are concerned about loss of the human connection and the loss of empathy during a vulnerable time in their lives. Patients expressed concern about risk of discrimination due to bias in AI algorithms. Building trust in AI requires transparency, explainability, security, and privacy protection. Radiologists can take action to prepare their patients to become more trusting of AI. Developing and implementing data-sharing agreements allows patients to voluntarily help in the algorithm development process. Developing AI disclosure guidelines and having AI use disclosure discussions with patients will help them understand the use of AI in their care. As the use of AI increases, there is an opportunity for radiologists to develop and maintain close relationships with their patients and to become more involved in their care.",
      "authors": "Borondy Kitts Andrea",
      "year": "2023",
      "journal": "Journal of the American College of Radiology : JACR",
      "doi": "10.1016/j.jacr.2023.05.017",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37453601/",
      "mesh_terms": "Humans; Artificial Intelligence; Radiology; Radiologists; Algorithms; Privacy",
      "keywords": "AI in medical care; AI in radiology; data sharing; patient perspective on AI",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "25054627",
      "title": "Identifying keystone species in the human gut microbiome from metagenomic timeseries using sparse linear regression.",
      "abstract": "Human associated microbial communities exert tremendous influence over human health and disease. With modern metagenomic sequencing methods it is now possible to follow the relative abundance of microbes in a community over time. These microbial communities exhibit rich ecological dynamics and an important goal of microbial ecology is to infer the ecological interactions between species directly from sequence data. Any algorithm for inferring ecological interactions must overcome three major obstacles: 1) a correlation between the abundances of two species does not imply that those species are interacting, 2) the sum constraint on the relative abundances obtained from metagenomic studies makes it difficult to infer the parameters in timeseries models, and 3) errors due to experimental uncertainty, or mis-assignment of sequencing reads into operational taxonomic units, bias inferences of species interactions due to a statistical problem called \"errors-in-variables\". Here we introduce an approach, Learning Interactions from MIcrobial Time Series (LIMITS), that overcomes these obstacles. LIMITS uses sparse linear regression with boostrap aggregation to infer a discrete-time Lotka-Volterra model for microbial dynamics. We tested LIMITS on synthetic data and showed that it could reliably infer the topology of the inter-species ecological interactions. We then used LIMITS to characterize the species interactions in the gut microbiomes of two individuals and found that the interaction networks varied significantly between individuals. Furthermore, we found that the interaction networks of the two individuals are dominated by distinct \"keystone species\", Bacteroides fragilis and Bacteroided stercosis, that have a disproportionate influence on the structure of the gut microbiome even though they are only found in moderate abundance. Based on our results, we hypothesize that the abundances of certain keystone species may be responsible for individuality in the human gut microbiome.",
      "authors": "Fisher Charles K; Mehta Pankaj",
      "year": "2014",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0102451",
      "url": "https://pubmed.ncbi.nlm.nih.gov/25054627/",
      "mesh_terms": "Algorithms; Bacteroides; Bacteroides fragilis; Gastrointestinal Tract; Humans; Linear Models; Metagenomics; Microbial Interactions; Microbiota; Time Factors",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC4108331"
    },
    {
      "pmid": "33496911",
      "title": "ManoMap: an automated system for characterization of colonic propagating contractions recorded by high-resolution manometry.",
      "abstract": "RATIONALE: Colonic high-resolution manometry (cHRM) is an emerging clinical tool for defining colonic function in health and disease. Current analysis methods are conducted manually, thus being inefficient and open to interpretation bias. OBJECTIVE: The main objective of the study was to build an automated system to identify propagating contractions and compare the performance to manual marking analysis. METHODS: cHRM recordings were performed on 5 healthy subjects, 3 subjects with diarrhea-predominant irritable bowel syndrome, and 3 subjects with slow transit constipation. Two experts manually identified propagating contractions, from five randomly selected 10-min segments from each of the 11 subjects (72 channels per dataset, total duration 550 min). An automated signal processing and detection platform was developed to compare its effectiveness to manually identified propagating contractions. In the algorithm, individual pressure events over a threshold were identified and were then grouped into a propagating contraction. The detection platform allowed user-selectable thresholds, and a range of pressure thresholds was evaluated (2 to 20 mmHg). KEY RESULTS: The automated system was found to be reliable and accurate for analyzing cHRM with a threshold of 15 mmHg, resulting in a positive predictive value of 75%. For 5-h cHRM recordings, the automated method takes 22 \u00b1 2 s for analysis, while manual identification would take many hours. CONCLUSIONS: An automated framework was developed to filter, detect, quantify, and visualize propagating contractions in cHRM recordings in an efficient manner that is reliable and consistent.",
      "authors": "Paskaranandavadivel Niranchan; Lin Anthony Y; Cheng Leo K; Bissett Ian; Lowe Andrew; Arkwright John; Mollaee Saeed; Dinning Phil G; O'Grady Gregory",
      "year": "2021",
      "journal": "Medical & biological engineering & computing",
      "doi": "10.1007/s11517-021-02316-y",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33496911/",
      "mesh_terms": "Algorithms; Colon; Constipation; Humans; Manometry; Signal Processing, Computer-Assisted",
      "keywords": "Automated methods; Colonic manometry; High-resolution; Rectosigmoid brake",
      "pub_types": "Journal Article",
      "pmcid": "2892003"
    },
    {
      "pmid": "20435264",
      "title": "Simplified 10-year absolute fracture risk assessment: a comparison of men and women.",
      "abstract": "A simplified (semiquantitative) approach developed by the Canadian Association of Radiologists and Osteoporosis Canada (denoted as CAROC) for absolute fracture risk assessment incorporates age, sex, prior fragility fracture, and systemic corticosteroid use, together with bone mineral density (BMD) to define absolute fracture risk. The CAROC system has been shown to predict fracture rates in women referred for clinical BMD testing, but it is uncertain how this system performs in routine clinical practice in men who are much less likely to undergo BMD testing with potential for referral biases. Thirty-six thousand seven hundred and thirty women and 2873 men aged 50 yr or older at the time of baseline BMD testing were identified in a database containing all clinical dual-energy X-ray absorptiometry test results for the Province of Manitoba, Canada. Population-based health service records from 1987 to 2008 were assessed for fracture codes and medication use. Fracture risk under the CAROC model was categorized as low (<10%), moderate (10-20%), or high (>20%). Ten-year fracture risk estimated by the Kaplan-Meier method showed the same gradient in observed fracture risk for men and women. Despite evidence of greater referral bias in men resulting in a higher rate of clinical risk factors, the performance of the prediction algorithm was not affected.",
      "authors": "Leslie William D; Lix Lisa M",
      "year": "2010",
      "journal": "Journal of clinical densitometry : the official journal of the International Society for Clinical Densitometry",
      "doi": "10.1016/j.jocd.2010.02.002",
      "url": "https://pubmed.ncbi.nlm.nih.gov/20435264/",
      "mesh_terms": "Absorptiometry, Photon; Aged; Algorithms; Bone Density; Cohort Studies; Female; Fractures, Bone; Humans; Kaplan-Meier Estimate; Male; Manitoba; Middle Aged; Osteoporosis; Retrospective Studies; Risk Assessment; Sex Factors",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41421622",
      "title": "Integrating AI-driven technologies and facial-semantic features for depression detection: A cross-sectional study.",
      "abstract": "BACKGROUND: Depression is a major global health concern, still individuals with depressive tendencies remain undetected in outpatient settings due to the limitations of self-report, stigma, and reporting bias. Advances in artificial intelligence (AI) offer opportunities for objective, scalable, and unobtrusive methods of early detection. This study examined predictive accuracy of two AI-driven systems, the iSeeME facial-expression model and the Event-Driven Depression Tendency Warning System (EDDTW-V2) in identifying depressive symptoms among high-risk outpatients in Taiwan. METHODS: A cross-sectional study was conducted with 62 outpatients recruited from psychiatric and surgical-oncology clinics at a medical center in southern Taiwan. Participants completed standardized depression assessments, including the Hamilton Depression Rating Scale (HDRS), Beck Depression Inventory-II (BDI-II), and Patient Health Questionnaire-9 (PHQ-9). Facial-expression data were analyzed using iSeeME, while narrative transcripts were processed with EDDTW-V2. Predictive validity was assessed through accurate metrics, correlations with clinical scales, and k-means cluster analysis. RESULTS: Of the 62 participants, 39 were clinically depressed (HDRS \u22657). The iSeeME system achieved precision of 0.761, recall of 0.854, F1-score of 0.805, and accuracy of 0.770, showing stronger correlations with BDI-II (r\u00a0=\u00a00.442, p\u00a0<\u00a00.01) and PHQ-9 (r\u00a0=\u00a00.335, p\u00a0<\u00a00.01) than EDDTW-V2. Cluster analysis revealed a high-distress subgroup characterized by younger age, single status, fewer children, and predominance of psychiatric patients. CONCLUSION: Both AI systems showed potential as complementary tools to traditional assessments. iSeeME was more sensitive to affective-behavioral symptoms, while EDDTW-V2 captured cognitive-linguistic features. They support earlier detection, monitoring, and targeted interventions in outpatient settings.",
      "authors": "Lin Mei-Feng; Pan Yi-Chien; Liu Fei-Pi; Shen Hong-Ju; Lu Wen-Hsiang; Mudiyanselage Sriyani Padmalatha Konara; Tseng Huai-Hsuan",
      "year": "2026",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2025.120889",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41421622/",
      "mesh_terms": "Humans; Cross-Sectional Studies; Male; Female; Adult; Artificial Intelligence; Middle Aged; Taiwan; Depression; Facial Expression; Psychiatric Status Rating Scales; Depressive Disorder",
      "keywords": "Artificial intelligence; Depression detection; Facial expressions; Machine learning; Outpatient psychiatry; Semantic analysis",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39160852",
      "title": "Engineering Features From Advanced Medical Technology Initiative Submissions to Enable Predictive Modeling for Proposal Success.",
      "abstract": "INTRODUCTION: The U.S. Army Telemedicine and Advanced Technology Research Center Advanced Medical Technology Initiative (AMTI) demonstrate key emerging technologies related to military medicine. AMTI invites researchers to submit proposals for short-term funding opportunities that support this goal. AMTI proposal selection is guided by a time-intensive peer review process, where proposals are rated on innovation, military relevance, metrics for success, and return on investment. Utilizing machine learning (ML) could assist in proposal evaluations by learning relationships between proposal performance and proposal features. This research explores the viability of artificial intelligence/ML for predicting proposal ratings given content-based proposal features. Although not meant to replace experts, a model-based approach to evaluating proposal quality could work alongside experts to provide a fast, minimally biased estimate of proposal performance. This article presents initial stages of a project aiming to use ML to prioritize research proposals. MATERIALS AND METHODS: The initial steps included a literature review to identify potential features. Then, these features were extracted from a dataset consisting of past proposals submissions. The dataset includes 824 proposals submitted to the AMTI program from 2010 to 2022. The analysis will inform a discussion of anticipated next steps toward developing a ML model. The following features were created for future modeling: requested funds; word count by section; readability by section; citations and partners identified; and term frequency-inverse document frequency word vectors. RESULTS: This initial process identified the top ranked words (data, health, injury, device, treatment, technology, etc.) among the abstract, problem to be solved, military relevance, and metrics/outcomes text proposal fields. The analysis also evaluated the text fields for readability using the Flesch readability scale. Most proposals text fields were categorized as \"college graduate,\" indicating a challenging readability level. Finally, citations and partners were reviewed as an indicator of proposal successfulness. CONCLUSIONS: This research was the first stage of a larger project to explore the use of ML to predict proposal ratings for the purpose of providing automated support to proposal reviewers and to reveal the preferences and values of AMTI proposal reviewers and other decision-makers. The result of this work will provide practical insights regarding the review process for the AMTI program. This will facilitate reduction in bias for AMTI innovators and a streamlined and subjective process for AMTI administrators, which benefits the military health system overall.",
      "authors": "Pavliscsak Holly; Knisely Benjamin",
      "year": "2024",
      "journal": "Military medicine",
      "doi": "10.1093/milmed/usae063",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39160852/",
      "mesh_terms": "Humans; Military Medicine; Machine Learning; United States",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40845524",
      "title": "Artificial intelligence readiness among healthcare students in Nigeria: A cross-sectional study assessing knowledge gaps, exposure, and adoption willingness.",
      "abstract": "BACKGROUND: Artificial intelligence (AI) is rapidly transforming healthcare globally, yet its adoption in developing countries remains limited. As future practitioners, the readiness of healthcare students is crucial for successful AI integration, but this remains unexplored in the Nigerian context. OBJECTIVES: This study aimed to assess AI readiness among healthcare students at a major Nigerian university by evaluating their foundational knowledge, practical exposure, and willingness to adopt AI technologies in clinical practice. METHODS: A cross-sectional study was conducted among 551 healthcare students at Obafemi Awolowo University using a semi-structured, validated questionnaire. The instrument utilized distinct sections with open-ended questions to objectively measure AI knowledge, assess exposure to AI applications, and gauge attitudes toward AI adoption. Data were analyzed using descriptive statistics and one-way ANOVA, with statistical significance set at p\u00a0<\u00a00.05. RESULTS: A significant knowledge-perception paradox emerged: while 60\u00a0% of students believed they had high AI knowledge; objective assessment showed 92\u00a0% had low knowledge levels. Foundational concepts were poorly understood, with only 12\u00a0% correctly defining machine learning. Despite this, students expressed overwhelmingly positive attitudes, with 90.8\u00a0% believing AI would improve workflow efficiency and 84.4\u00a0% willing to undertake AI training. Practical exposure to AI was minimal, with electronic record keeping being the most frequently encountered application (43.4\u00a0%). Knowledge levels were significantly associated with willingness to adopt AI (p\u00a0<\u00a00.05), as students with higher knowledge showed greater confidence but also a more critical awareness of AI's limitations. CONCLUSION: Nigerian healthcare students show strong enthusiasm for AI adoption but have significant knowledge gaps and limited practical exposure. However, substantial concerns exist regarding the translation of expressed willingness into actual practice, particularly among early-year students who lack clinical exposure to understand AI limitations, bias, and real-world implementation challenges. These findings highlight an urgent need for AI curriculum integration and infrastructure development to prepare future healthcare professionals for an increasingly AI-driven healthcare landscape.",
      "authors": "Clement David-Olawade Aanuoluwapo; Wada Ojima Z; Adeniji Yinka Julianah; Aderupoko Ibukunoluwa Victoria; Olawade David B",
      "year": "2025",
      "journal": "International journal of medical informatics",
      "doi": "10.1016/j.ijmedinf.2025.106085",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40845524/",
      "mesh_terms": "Humans; Cross-Sectional Studies; Nigeria; Female; Male; Artificial Intelligence; Surveys and Questionnaires; Young Adult; Adult; Health Knowledge, Attitudes, Practice",
      "keywords": "AI adoption; AI integration; Digital health; Health curriculum reform; Medical education; Sub-Saharan Africa",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38880864",
      "title": "Scrutinizing different predictive modeling validation methodologies and data-partitioning strategies: new insights using groundwater modeling case study.",
      "abstract": "Groundwater salinity is a critical factor affecting water quality and ecosystem health, with implications for various sectors including agriculture, industry, and public health. Hence, the reliability and accuracy of groundwater salinity predictive models are paramount for effective decision-making in managing groundwater resources. This pioneering study presents the validation of a predictive model aimed at forecasting groundwater salinity levels using three different validation methods and various data partitioning strategies. This study tests three different data validation methodologies with different data-partitioning strategies while developing a group method of data handling (GMDH)-based model for predicting groundwater salinity concentrations in a coastal aquifer system. The three different methods are the hold-out strategy (last and random selection), k-fold cross-validation, and the leave-one-out method. In addition, various combinations of data-partitioning strategies are also used while using these three validation methodologies. The prediction model's validation results are assessed using various statistical indices such as root mean square error (RMSE), means squared error (MSE), and coefficient of determination (R2). The results indicate that for monitoring wells 1, 2, and 3, the hold-out (random) with 40% data partitioning strategy gave the most accurate predictive model in terms of RMSE statistical indices. Also, the results suggested that the GMDH-based models behave differently with different validation methodologies and data-partitioning strategies giving better salinity predictive capabilities. In general, the results justify that various model validation methodologies and data-partitioning strategies yield different results due to their inherent differences in how they partition the data, assess model performance, and handle sources of bias and variance. Therefore, it is important to use them in conjunction to obtain a comprehensive understanding of the groundwater salinity prediction model's behavior and performance.",
      "authors": "Lal Alvin; Sharan Ashneel; Sharma Krishneel; Ram Arishma; Roy Dilip Kumar; Datta Bithin",
      "year": "2024",
      "journal": "Environmental monitoring and assessment",
      "doi": "10.1007/s10661-024-12794-w",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38880864/",
      "mesh_terms": "Groundwater; Environmental Monitoring; Salinity; Water Pollutants, Chemical; Models, Theoretical; Reproducibility of Results",
      "keywords": "Data partitioning strategies; FEMWATER; GMDH; Groundwater salinity; Machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11519171"
    },
    {
      "pmid": "34264325",
      "title": "Smoking and Incidence of Colorectal Cancer Subclassified by Tumor-Associated Macrophage Infiltrates.",
      "abstract": "BACKGROUND: Biological evidence indicates that smoking can influence macrophage functions and polarization, thereby promoting tumor evolution. We hypothesized that the association of smoking with colorectal cancer incidence might differ by macrophage infiltrates. METHODS: Using the Nurses' Health Study and the Health Professionals Follow-up Study, we examined the association of smoking with incidence of colorectal cancer subclassified by macrophage counts. Multiplexed immunofluorescence (for CD68, CD86, IRF5, MAF, and MRC1 [CD206]) combined with digital image analysis and machine learning was used to identify overall, M1-polarized, and M2-polarized macrophages in tumor. We used inverse-probability-weighted multivariable Cox proportional hazards regression models to control for potential confounders and selection bias because of tissue data availability. All statistical tests were 2-sided. RESULTS: During follow-up of 131 144 participants (3 648 370 person-years), we documented 3092 incident colorectal cancer cases, including 871 cases with available macrophage data. The association of pack-years smoked with colorectal cancer incidence differed by stromal macrophage densities (Pheterogeneity = .003). Compared with never smoking, multivariable-adjusted hazard ratios (95% confidence interval) for tumors with low macrophage densities were 1.32 (0.97 to 1.79) for 1-19 pack-years, 1.31 (0.92 to 1.85) for 20-39 pack-years, and 1.74 (1.26 to 2.41) for 40 or more pack-years (Ptrend = .004). In contrast, pack-years smoked was not statistically significantly associated with the incidence of tumors having intermediate or high macrophage densities (Ptrend > .009, with an \u03b1 level of .005). No statistically significant differential association was found for colorectal cancer subclassified by M1-like or M2-like macrophages. CONCLUSIONS: The association of smoking with colorectal cancer incidence is stronger for tumors with lower stromal macrophage counts. Our findings suggest an interplay of smoking and macrophages in colorectal carcinogenesis.",
      "authors": "Ugai Tomotaka; V\u00e4yrynen Juha P; Haruki Koichiro; Akimoto Naohiko; Lau Mai Chan; Zhong Rong; Kishikawa Junko; V\u00e4yrynen Sara A; Zhao Melissa; Fujiyoshi Kenji; Dias Costa Andressa; Borowsky Jennifer; Arima Kota; Guerriero Jennifer L; Fuchs Charles S; Zhang Xuehong; Song Mingyang; Wang Molin; Giannakis Marios; Meyerhardt Jeffrey A; Nowak Jonathan A; Ogino Shuji",
      "year": "2022",
      "journal": "Journal of the National Cancer Institute",
      "doi": "10.1093/jnci/djab142",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34264325/",
      "mesh_terms": "Colorectal Neoplasms; Follow-Up Studies; Humans; Incidence; Risk Factors; Smoking; Tumor-Associated Macrophages",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8755510"
    },
    {
      "pmid": "19508658",
      "title": "Resource utilization and costs of schizophrenia patients treated with olanzapine versus quetiapine in a Medicaid population.",
      "abstract": "OBJECTIVE: Compare annual health-care costs and resource utilization associated with olanzapine versus quetiapine for treating schizophrenia in a Medicaid population. METHODS: Adult schizophrenia patients were selected from deidentified Pennsylvania Medicaid claims database (1999\u20132003). Included patients were continuously enrolled and initiated with olanzapine or quetiapine monotherapy after a 90-day washout period. Treatment costs were calculated for 1-year post-therapy initiation and inflation adjusted to year 2003. To control for selection bias, olanzapine and quetiapine patients were 1:1 matched using an optimal matching algorithm on propensity score, which was generated using logistic regression controlling for demographics, prior drug therapy, utilization, and costs. Treatment costs for the matched cohorts were compared directly, as well as using a difference-in-difference analysis. RESULTS: A total of 6929 patients treated with olanzapine and 2321 with quetiapine met inclusion criteria. Quetiapine patients appeared more severe at baseline. After propensity score matching, 2321 patient pairs had similar baseline characteristics, including total costs. Compared with matched quetiapine patients, for the 1-year postindex period, olanzapine patients had similar drug costs ($6131 vs. $6014, P = 0.326), lower medical costs ($9897 vs. $11,218, P = 0.0128), and lower total health-care costs ($16,028 vs. $17,232, P = 0.0279). Lower psychiatric hospitalization costs account for most of the total cost difference. Difference-in-difference regression analysis confirmed olanzapine's economic advantage. Further adjusting for baseline variations, the total cost advantage of olanzapine patients was $962 (P = 0.032), and was mostly because of reduced psychiatric hospitalization costs of $992 (P = 0.004). CONCLUSION: Schizophrenia patients treated with olanzapine had lower total costs than quetiapine patients, mostly attributable to reductions in psychiatric hospitalization costs.",
      "authors": "Yu Andrew P; Atanasov Pavel; Ben-Hamadi Rym; Birnbaum Howard; Stensland Michael D; Philips Glenn",
      "year": "2009",
      "journal": "Value in health : the journal of the International Society for Pharmacoeconomics and Outcomes Research",
      "doi": "10.1111/j.1524-4733.2008.00498.x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/19508658/",
      "mesh_terms": "Adolescent; Adult; Antipsychotic Agents; Benzodiazepines; Cost-Benefit Analysis; Dibenzothiazepines; Drug Costs; Hospitalization; Humans; Logistic Models; Medicaid; Middle Aged; Olanzapine; Pennsylvania; Propensity Score; Quetiapine Fumarate; Schizophrenia; United States; Young Adult",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "34246512",
      "title": "Cost-effectiveness evaluation of mammography screening program in Taiwan: Adjusting different distributions of age and calendar year for real world data.",
      "abstract": "BACKGROUND/PURPOSE: We estimated loss-of-life expectancy (LE) and lifetime medical expenditures (LME) stratified by stages to evaluate the cost-effectiveness of breast cancer (BC) screening in Taiwan. METHODS: We interlinked four national databases- Cancer Registry, Mortality Registry, National Health Insurance Claim, and Mammography Screening. A cohort of 123,221 BC was identified during 2002-2015 and followed until December 31, 2017. We estimated LE and loss-of-LE by rolling extrapolation algorithm using age-, sex-, and calendar-year-matched referents simulated from vital statistics. LME was estimated by multiplying monthly cost with survival probability and adjusted for annual discount rate. We calculated incremental cost-effectiveness ratio (ICER) by comparing the loss-of-LE of those detected by screening versus non-screening after accounting for administration fees and radiation-related excess BC. RESULTS: The LEs of stages I, II, III, and IV were 31.4, 27.2, 20.0, and 5.2 years, respectively, while the loss-of-LEs were 1.2, 4.9, 11.7, and 25.0 years with corresponding LMEs of US$ 73,791, 79,496, 89,962, and 66,981, respectively. The difference in LE between stages I and IV was 26.2 years while that of loss-of-LE was 23.8 years, which implies that a potential lead time bias may exist if diagnosis at younger ages for earlier stages were not adjusted for. The ICER of mammography seemed cost-saving after the coverage exceeded half a million. CONCLUSION: Mammography could detect BC early and be cost-saving after adjustment for different distributions of age and calendar year of diagnosis. Future studies exploring healthcare expenditure and impaired quality of life for false-positive cases are warranted.",
      "authors": "Lin Chia-Ni; Lee Kuo-Ting; Chang Sheng-Mao; Wang Jung-Der",
      "year": "2022",
      "journal": "Journal of the Formosan Medical Association = Taiwan yi zhi",
      "doi": "10.1016/j.jfma.2021.06.013",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34246512/",
      "mesh_terms": "Breast Neoplasms; Cost-Benefit Analysis; Early Detection of Cancer; Female; Humans; Mammography; Mass Screening; Quality of Life; Taiwan",
      "keywords": "Breast neoplasms; Health expenditures; Life expectancy; Loss-of-life expectancy; Survival",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "19376323",
      "title": "Prospective assessment of the occurrence of anemia in patients with heart failure: results from the Study of Anemia in a Heart Failure Population (STAMINA-HFP) Registry.",
      "abstract": "BACKGROUND: Although a potentially important pathophysiologic factor in heart failure, the prevalence and predictors of anemia have not been well studied in unselected patients with heart failure. METHODS: The Study of Anemia in a Heart Failure Population (STAMINA-HFP) Registry prospectively studied the prevalence of anemia and the relationship of hemoglobin to health-related quality of life and outcomes among patients with heart failure. A random selection algorithm was used to reduce bias during enrollment of patients seen in specialty clinics or clinics of community cardiologists with experience in heart failure. In this initial report, data on prevalence and correlates of anemia were analyzed in 1,076 of the 1,082 registry patients who had clinical characteristics and hemoglobin determined by finger-stick at baseline. RESULTS: Overall (n = 1,082), the registry patients were 41% female and 73% white with a mean age (+/-SD) of 64 +/- 14 years (68 +/- 13 years in community and 57 +/- 14 years in specialty sites, P < .001). Among the 1,076 patients in the prevalence analysis, mean hemoglobin was 13.3 +/- 2.1 g/dL (median 13.2 g/dL); and anemia (defined by World Health Organization criteria) was present in 34%. Age identified patients at risk for anemia, with 40% of patients >70 years affected. CONCLUSIONS: Initial results from the STAMINA-HFP Registry suggest that anemia is a common comorbidity in unselected outpatients with heart failure. Given the strong association of anemia with adverse outcomes in heart failure, this study supports further investigation concerning the importance of anemia as a therapeutic target in this condition.",
      "authors": "Adams Kirkwood F; Patterson James H; Oren Ron M; Mehra Mandeep R; O'Connor Christopher M; Pi\u00f1a Ileana L; Miller Alan B; Chiong Jun R; Dunlap Stephanie H; Cotts William G; Felker Gary M; Schocken Douglas D; Schwartz Todd A; Ghali Jalal K",
      "year": "2009",
      "journal": "American heart journal",
      "doi": "10.1016/j.ahj.2009.01.012",
      "url": "https://pubmed.ncbi.nlm.nih.gov/19376323/",
      "mesh_terms": "Aged; Anemia; Female; Follow-Up Studies; Heart Failure; Hemoglobins; Humans; Incidence; Male; Middle Aged; Prevalence; Prognosis; Prospective Studies; Quality of Life; Registries; Risk Assessment; Risk Factors",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article; Multicenter Study",
      "pmcid": ""
    },
    {
      "pmid": "39735379",
      "title": "Transgender and Gender Diverse Patients Are Diagnosed with Borderline Personality Disorder More Frequently Than Cisgender Patients Regardless of Personality Pathology.",
      "abstract": "PURPOSE: Borderline personality disorder (BPD) is a severe form of psychopathology associated with a host of negative outcomes. Some literature suggests elevated prevalence among transgender and gender diverse (TGD) samples. Elevated BPD prevalence among TGD populations could be due to factors other than BPD-specific psychopathology. Studies of TGD samples typically omit assessment of BPD, making it difficult to understand elevated BPD diagnosis. The current study explored (1) differences in BPD diagnosis among TGD patients versus cisgender patients, (2) if differences were explained by BPD-specific pathology, and (3) if BPD diagnostic disparities existed based on assessment modality. METHODS: Data from TGD (n=74) and cisgender heterosexual (n=920) patients who presented for treatment at one partial hospitalization program from 2014 to 2019 were compared to investigate differences in the frequency of BPD diagnosis. RESULTS: A larger proportion of TGD patients were diagnosed with BPD than cisgender patients (odds ratio [OR]=4.05, p<0.001). The disparity in diagnosis persisted even after controlling for BPD-specific personality pathology (OR=2.98, p<0.001). BPD diagnostic disparity occurred when assessed using structured (OR=4.78, p<0.001) and unstructured (OR=3.61, p<0.001) interview methods. There was no disparity, however, when BPD was diagnosed using an algorithm based on BPD-specific personality pathology purported to underlie the diagnosis. CONCLUSIONS: Clinical providers appear inclined to assign a BPD diagnosis to TGD patients that may not correspond with group differences in underlying personality pathology. That some BPD symptoms might be more likely in TGD samples, future research can examine criterion-level biases in BPD diagnosis among TGD individuals.",
      "authors": "Rodriguez-Seijas Craig; Morgan Theresa A; Zimmerman Mark",
      "year": "2024",
      "journal": "Transgender health",
      "doi": "10.1089/trgh.2023.0062",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39735379/",
      "mesh_terms": "",
      "keywords": "Alternative Model for Personality Disorders; LGBTQ+; Personality Inventory for DSM5; Transgender Health; borderline personality disorder; diagnostic bias; mental health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11669633"
    },
    {
      "pmid": "38213940",
      "title": "A Quantum-Enhanced Precision Medicine Application to Support Data-Driven Clinical Decisions for the Personalized Treatment of Advanced Knee Osteoarthritis: The Development and Preliminary Validation of precisionKNEE_QNN.",
      "abstract": "Background Quantum computing and quantum machine learning (QML) are promising experimental technologies that can improve precision medicine applications by reducing the computational complexity of algorithms driven by big, unstructured, real-world data. The clinical problem of knee osteoarthritis is that, although some novel therapies are safe and effective, the response is variable, and defining the characteristics of an individual who will respond remains a challenge. In this study, we tested a quantum neural network (QNN) application to support precision data-driven clinical decisions to select personalized treatments for advanced knee osteoarthritis. Methodology After obtaining patients' consent and Research Ethics Committee approval, we collected the clinicodemographic data before and after the treatment from 170 patients eligible for knee arthroplasty (Kellgren-Lawrence grade \u22653, Oxford Knee Score (OKS) \u226427, age \u226564 years, and idiopathic aetiology of arthritis) treated over a two-year period with a single injection of microfragmented fat. Gender classes were balanced (76 males and 94 females) to mitigate gender bias. A patient with an improvement \u22657 OKS was considered a responder. We trained our QNN classifier on a randomly selected training subset of 113 patients to classify responders from non-responders (73 responders and 40 non-responders) in pain and function at one year. Outliers were hidden from the training dataset but not from the validation set. Results We tested our QNN classifier on a randomly selected test subset of 57 patients (34 responders, 23 non-responders) including outliers. The no information rate was 0.59. Our application correctly classified 28 responders out of 34 and 6 non-responders out of 23 (sensitivity = 0.82, specificity = 0.26, F1 Statistic = 0.71). The positive and negative likelihood ratios were 1.11 and 0.68, respectively. The diagnostic odds ratio was 2. Conclusions Preliminary results on a small validation dataset showed that QML applied to data-driven clinical decisions for the personalized treatment of advanced knee osteoarthritis is a promising technology to reduce computational complexity and improve prognostic performance. Our results need further research validation with larger, real-world unstructured datasets, as well as clinical validation with an artificial intelligence clinical trial to test model efficacy, safety, clinical significance, and relevance at a public health level.",
      "authors": "Heidari Nima; Olgiati Stefano; Meloni Davide; Slevin Mark; Noorani Ali; Pirovano Federico; Azamfirei Leonard",
      "year": "2024",
      "journal": "Cureus",
      "doi": "10.7759/cureus.52093",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38213940/",
      "mesh_terms": "",
      "keywords": "biologic therapies; joint preservation; osteoarthritis knee; personalised precision medicine; quantum machine learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC10782883"
    },
    {
      "pmid": "29483870",
      "title": "Bayesian Optimization for Neuroimaging Pre-processing in Brain Age Classification and Prediction.",
      "abstract": "Neuroimaging-based age prediction using machine learning is proposed as a biomarker of brain aging, relating to cognitive performance, health outcomes and progression of neurodegenerative disease. However, even leading age-prediction algorithms contain measurement error, motivating efforts to improve experimental pipelines. T1-weighted MRI is commonly used for age prediction, and the pre-processing of these scans involves normalization to a common template and resampling to a common voxel size, followed by spatial smoothing. Resampling parameters are often selected arbitrarily. Here, we sought to improve brain-age prediction accuracy by optimizing resampling parameters using Bayesian optimization. Using data on N = 2003 healthy individuals (aged 16-90 years) we trained support vector machines to (i) distinguish between young (<22 years) and old (>50 years) brains (classification) and (ii) predict chronological age (regression). We also evaluated generalisability of the age-regression model to an independent dataset (CamCAN, N = 648, aged 18-88 years). Bayesian optimization was used to identify optimal voxel size and smoothing kernel size for each task. This procedure adaptively samples the parameter space to evaluate accuracy across a range of possible parameters, using independent sub-samples to iteratively assess different parameter combinations to arrive at optimal values. When distinguishing between young and old brains a classification accuracy of 88.1% was achieved, (optimal voxel size = 11.5 mm3, smoothing kernel = 2.3 mm). For predicting chronological age, a mean absolute error (MAE) of 5.08 years was achieved, (optimal voxel size = 3.73 mm3, smoothing kernel = 3.68 mm). This was compared to performance using default values of 1.5 mm3 and 4mm respectively, resulting in MAE = 5.48 years, though this 7.3% improvement was not statistically significant. When assessing generalisability, best performance was achieved when applying the entire Bayesian optimization framework to the new dataset, out-performing the parameters optimized for the initial training dataset. Our study outlines the proof-of-principle that neuroimaging models for brain-age prediction can use Bayesian optimization to derive case-specific pre-processing parameters. Our results suggest that different pre-processing parameters are selected when optimization is conducted in specific contexts. This potentially motivates use of optimization techniques at many different points during the experimental process, which may improve statistical sensitivity and reduce opportunities for experimenter-led bias.",
      "authors": "Lancaster Jenessa; Lorenz Romy; Leech Rob; Cole James H",
      "year": "2018",
      "journal": "Frontiers in aging neuroscience",
      "doi": "10.3389/fnagi.2018.00028",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29483870/",
      "mesh_terms": "",
      "keywords": "Bayesian optimization; T1-MRI; brain aging; machine learning; pre-processing",
      "pub_types": "Journal Article",
      "pmcid": "PMC5816033"
    },
    {
      "pmid": "33550542",
      "title": "Utility estimations of health states of older Australian women with atrial fibrillation using SF-6D.",
      "abstract": "PURPOSE: To estimate SF-6D utility scores for older women with atrial fibrillation (AF); calculate and compare mean utility scores for women with AF with various demographic, health behaviours, and clinical characteristics; and develop a multivariable regression model to determine factors associated with SF-6D utility scores. METHODS: This study evaluated N = 1432 women diagnosed with AF from 2000 to 2015 of the old cohort (born 1921-26) of the Australian Longitudinal Study on Women's Health (ALSWH) who remained alive for at least 12 months post first recorded AF diagnosis. Self-reported data on demographics, health behaviours, health conditions, and SF-36 were obtained from the ALSWH surveys, corresponding to within three years of the date of the first record of AF diagnosis. Linked Pharmaceutical Benefits Scheme (PBS) data determined the use of oral anticoagulants and comorbid conditions, included in CHA2DS2-VA (Congestive heart failure, Hypertension, Age \u2265 75 years, Diabetes, Stroke or TIA, Vascular disease and Age 65-74 years) score calculation, were assessed using state-based hospital admissions data. Utility scores were calculated for every woman from their SF-36 responses using the SF-6D algorithm with Australian population norms. Mean utility scores were then calculated for women with various demographic, health behaviours, and clinical characteristics. Ordinary Least Square (OLS) regression modelling was performed to determine factors associated with these utility scores. Two different scenarios were used for the analysis: (1) complete-case, for women with complete data on all the SF-36 items required to estimate SF-6D (N = 584 women), and (2) Multiple Imputation (MI) for missing data, applied to missing values on SF-36 items (N = 1432 women). MI scenario was included to gauge the potential bias when using complete data only. RESULTS: The mean health utility was estimated to be 0.638 \u00b1 0.119 for the complete dataset and 0.642 \u00b1 0.120 for the dataset where missing values were handled using MI. Using the MI technique, living in regional and remote areas ([Formula: see text]) and the use of oral anticoagulants ([Formula: see text] were positively associated with health utility compared to living in major cities and no use of anticoagulants, respectively. Difficulty to manage on available income [Formula: see text], no/low physical activity [Formula: see text], disability [Formula: see text], history of stroke ([Formula: see text] and history of arthritis [Formula: see text] were negatively associated with health utility. CONCLUSION: This study presents health utility estimates for older women with AF. These estimates can be used in future clinical and economic research. The study also highlights better health utilities for women living in regional and remote areas, which requires further exploration.",
      "authors": "Abbas Shazia S; Majeed Tazeen; Weaver Natasha; Nair Balakrishnan R; Forder Peta M; Byles Julie E",
      "year": "2021",
      "journal": "Quality of life research : an international journal of quality of life aspects of treatment, care and rehabilitation",
      "doi": "10.1007/s11136-020-02748-3",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33550542/",
      "mesh_terms": "Aged; Atrial Fibrillation; Australia; Female; Humans; Longitudinal Studies; Quality of Life; Surveys and Questionnaires; Women's Health",
      "keywords": "Atrial fibrillation; Health utilities; Linked data; Multiple imputations; Older women; Quality of life",
      "pub_types": "Journal Article",
      "pmcid": "1071947"
    },
    {
      "pmid": "32216801",
      "title": "Using gridded population and quadtree sampling units to support survey sample design in low-income settings.",
      "abstract": "BACKGROUND: Household surveys are the main source of demographic, health and socio-economic data in low- and middle-income countries (LMICs). To conduct such a survey, census population information mapped into enumeration areas (EAs) typically serves a sampling frame from which to generate a random sample. However, the use of census information to generate this sample frame can be problematic as in many LMIC contexts, such data are often outdated or incomplete, potentially introducing coverage issues into the sample frame. Increasingly, where census data are outdated or unavailable, modelled population datasets in the gridded form are being used to create household survey sampling frames. METHODS: Previously this process was done by either sampling from a set of the uniform grid cells (UGC) which are then manually subdivided to achieve the desired population size, or by sampling very small grid cells then aggregating cells into larger units to achieve a minimum population per survey cluster. The former approach is time and resource-intensive as well as results in substantial heterogeneity in the output sampling units, while the latter can complicate the calculation of unbiased sampling weights. Using the context of Somalia, which has not had a full census since 1987, we implemented a quadtree algorithm for the first time to create a population sampling frame. The approach uses gridded population estimates and it is based on the idea of a quadtree decomposition in which an area successively subdivided into four equal size quadrants, until the content of each quadrant is homogenous. RESULTS: The quadtree approach used here produced much more homogeneous sampling units than the UGC (1\u2009\u00d7\u20091 km and 3\u2009\u00d7\u20093 km) approach. At the national and pre-war regional scale, the standard deviation and coefficient of variation, as indications of homogeneity, were calculated for the output sampling units using quadtree and UGC 1\u2009\u00d7\u20091 km and 3\u2009\u00d7\u20093 km approaches to create the sampling frame and the results showed outstanding performance for quadtree approach. CONCLUSION: Our approach reduces the manual burden of manually subdividing UGC into highly populated areas, while allowing for correct calculation of sampling weights. The algorithm produces a relatively homogenous population counts within the sampling units, reducing the variation in the weights and improving the precision of the resulting estimates. Furthermore, a protocol of creating approximately equal-sized blocks and using tablets for randomized selection of a household in each block mitigated potential selection bias by enumerators. The approach shows labour, time and cost-saving and points to the potential use in wider contexts.",
      "authors": "Qader Sarchil Hama; Lefebvre Veronique; Tatem Andrew J; Pape Utz; Jochem Warren; Himelein Kristen; Ninneman Amy; Wolburg Philip; Nunez-Chaim Gonzalo; Bengtsson Linus; Bird Tomas",
      "year": "2020",
      "journal": "International journal of health geographics",
      "doi": "10.1186/s12942-020-00205-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32216801/",
      "mesh_terms": "Censuses; Family Characteristics; Health Surveys; Humans; Income; Population Density; Poverty; Research Design",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7099787"
    },
    {
      "pmid": "24987523",
      "title": "Automation of workplace lifting hazard assessment for musculoskeletal injury prevention.",
      "abstract": "OBJECTIVES: Existing methods for practically evaluating musculoskeletal exposures such as posture and repetition in workplace settings have limitations. We aimed to automate the estimation of parameters in the revised United States National Institute for Occupational Safety and Health (NIOSH) lifting equation, a standard manual observational tool used to evaluate back injury risk related to lifting in workplace settings, using depth camera (Microsoft Kinect) and skeleton algorithm technology. METHODS: A large dataset (approximately 22,000 frames, derived from six subjects) of simultaneous lifting and other motions recorded in a laboratory setting using the Kinect (Microsoft Corporation, Redmond, Washington, United States) and a standard optical motion capture system (Qualysis, Qualysis Motion Capture Systems, Qualysis AB, Sweden) was assembled. Error-correction regression models were developed to improve the accuracy of NIOSH lifting equation parameters estimated from the Kinect skeleton. Kinect-Qualysis errors were modelled using gradient boosted regression trees with a Huber loss function. Models were trained on data from all but one subject and tested on the excluded subject. Finally, models were tested on three lifting trials performed by subjects not involved in the generation of the model-building dataset. RESULTS: Error-correction appears to produce estimates for NIOSH lifting equation parameters that are more accurate than those derived from the Microsoft Kinect algorithm alone. Our error-correction models substantially decreased the variance of parameter errors. In general, the Kinect underestimated parameters, and modelling reduced this bias, particularly for more biased estimates. Use of the raw Kinect skeleton model tended to result in falsely high safe recommended weight limits of loads, whereas error-corrected models gave more conservative, protective estimates. CONCLUSIONS: Our results suggest that it may be possible to produce reasonable estimates of posture and temporal elements of tasks such as task frequency in an automated fashion, although these findings should be confirmed in a larger study. Further work is needed to incorporate force assessments and address workplace feasibility challenges. We anticipate that this approach could ultimately be used to perform large-scale musculoskeletal exposure assessment not only for research but also to provide real-time feedback to workers and employers during work method improvement activities and employee training.",
      "authors": "Spector June T; Lieblich Max; Bao Stephen; McQuade Kevin; Hughes Margaret",
      "year": "2014",
      "journal": "Annals of occupational and environmental medicine",
      "doi": "10.1186/2052-4374-26-15",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24987523/",
      "mesh_terms": "",
      "keywords": "Back injury; Back pain; Depth camera; Ergonomics; Microsoft Kinect; Musculoskeletal hazard assessment; NIOSH lifting equation; Prevention; Work-related musculoskeletal disorders",
      "pub_types": "Journal Article",
      "pmcid": "PMC4076760"
    },
    {
      "pmid": "40499254",
      "title": "Smart farming with AI: Enhancing anemia detection in small ruminants.",
      "abstract": "Accurate classification of FAMACHA\u00a9 scores is essential for assessing anemia in small ruminants and optimizing parasite management strategies in livestock agriculture. The FAMACHA\u00a9 system categorizes anemia severity on a scale from 1 to 5, where scores 1 and 2 indicate healthy animals, score 3 represents a borderline condition, and scores 4 and 5 indicate severe anemia. In this study, a dataset of 4700 images of the lower eye conjunctiva of young male goats was collected weekly over six months using a Samsung A54 smartphone. Traditional FAMACHA\u00a9 assessment methods rely on subjective visual examination, which is labor-intensive and susceptible to observer bias. To address this limitation, this study implemented machine learning algorithms to automate FAMACHA\u00a9 classification, leveraging Support Vector Machine (SVM), Backpropagation Neural Network (BPNN), and Convolutional Neural Network (CNN) models. A comparative analysis of these models was conducted using precision, recall, F1-score, and accuracy metrics. The CNN model demonstrated the highest classification accuracy (97.8\u202f%), outperforming both BPNN and SVM. The SVM model achieved a mean accuracy of 84.6\u202f%, with strong performance in severe anemia detection, but limitations in intermediate classes. The overall accuracy of 84\u202f% attained by the BPNN model provided a balanced tradeoff between precision and recall. The CNN model's superior performance was attributed to its ability to learn spatial and contextual patterns from images, ensuring robust classification across all FAMACHA\u00a9 categories. These findings underscore CNN's potential as a reliable, scalable solution for automated anemia detection in livestock, facilitating early intervention and improving herd health management. The study also highlights the need for future research to explore ensemble learning approaches and integration with mobile applications for real-time deployment for both commercial and resource-limited livestock producers.",
      "authors": "Siddique Aftab; Khan Sophia; Terrill Thomas H; Mahaptra Ajit K; Panda Sudhanshu S; Morgan Eric R; Pech-Cervantes Andres A; Randall Reginald; Singh Anurag; Batchu Phaneendra; Gurrapu Priyanka; van Wyk Jan A",
      "year": "2025",
      "journal": "Veterinary parasitology",
      "doi": "10.1016/j.vetpar.2025.110525",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40499254/",
      "mesh_terms": "Animals; Goats; Anemia; Goat Diseases; Male; Neural Networks, Computer; Support Vector Machine; Machine Learning; Conjunctiva",
      "keywords": "Backpropagation neural network; FAMACHA\u00a9 images; Parasite management; Support vector machines",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40501115",
      "title": "Analysis of influenza-like illness trends in Saudi Arabia: a comparative study of statistical and deep learning techniques.",
      "abstract": "BACKGROUND: To develop and evaluate forecasting models using the Holt-Winters statistical approach and the long short-term memory (LSTM) deep learning method for weekly seasonal influenza-like illness (ILI) incidences in Saudi Arabia. The study compares model performance and assesses the predictive value added by incorporating region-specific exogenous variables within Middle Eastern epidemiological modeling. METHODS: This study compared the performance of Holt-Winters and LSTM models in forecasting weekly ILI cases in Saudi Arabia, using data collected from 2017 to 2022. Time series analysis integrated exogenous variables including climatic conditions and population mobility trends. The Holt-Winters model employed both additive and multiplicative seasonal components. Model performance was evaluated using root mean squared error (RMSE), mean absolute percentage error, and R2. RESULTS: The best-performing model, LSTM with exogenous variables, achieved an RMSE of 28.55, mean absolute error (MAE) of 0.14, R2 of 0.96, and percent bias (PBIAS) of +2.1%, indicating negligible systematic error. The LSTM model without exogenous variables demonstrated slightly lower accuracy (RMSE of 34.07, MAE of 0.18, R2 of 0.93, PBIAS of +5.8%), indicating strong predictive capability but less precision in determining peak ILI cases. The Holt-Winters model effectively captured seasonal and long-term trends, but showed a moderate performance with an RMSE of 82.57, MAE of 0.38, R2 of 0.58, and a high PBIAS of +14.2%, revealing significant unexplained variability during periods of high incidence fluctuation. CONCLUSION: This study highlights the respective strengths and limitations of statistical and machine learning approaches for ILI forecasting.",
      "authors": "Guma Fathelrhman El",
      "year": "2025",
      "journal": "Osong public health and research perspectives",
      "doi": "10.24171/j.phrp.2025.0080",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40501115/",
      "mesh_terms": "",
      "keywords": "Forecasting; Influenza, human; Neural networks, computer; Public health",
      "pub_types": "Journal Article",
      "pmcid": "PMC12245528"
    },
    {
      "pmid": "40415467",
      "title": "Artificial intelligence vs human clinicians: a comparative analysis of complex medical query handling across the USA and Australia.",
      "abstract": "PURPOSE: This study sought to explore the practical application and effectiveness of AI-generated responses in healthcare and compared these with human clinician responses to complex medical queries in the USA and Australia. The study identifies strengths and limitations of AI in clinical settings and offers insights into its potential to enhance healthcare delivery. DESIGN/METHODOLOGY/APPROACH: A comparative analysis used a dataset of 7,165 medical queries to assess AI-generated responses versus human clinicians on accuracy, professionalism and real-time performance using machine learning algorithms and various tests. The study evaluated AI and human responses across the diverse healthcare systems of the United States and Australia, broadening the findings' applicability. FINDINGS: The results show that AI-generated responses were generally more accurate and professional than human responses, suggesting potential benefits like increased efficiency, lower costs and enhanced patient satisfaction. However, significant concerns such as AI's lack of emotional depth, data bias and the risk of displacing human clinicians must be addressed to fully utilize AI in clinical settings. ORIGINALITY/VALUE: This study contributes to the ongoing discourse on AI in healthcare by empirically testing AI's capability to handle complex medical queries compared to human clinicians. It provides a comprehensive analysis that not only underscores AI's potential to transform healthcare practices but also highlights critical areas where further refinement is necessary. The comparative analysis between two major healthcare systems adds to its originality, offering a nuanced understanding of AI's role in global health contexts.",
      "authors": "Graham Christian M",
      "year": "2025",
      "journal": "Journal of health organization and management",
      "doi": "10.1108/JHOM-02-2025-0100",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40415467/",
      "mesh_terms": "Australia; United States; Artificial Intelligence; Humans",
      "keywords": "AI challenges in healthcare; AI-Generated responses; Artificial intelligence; Clinical decision making; Comparative analysis; Healthcare efficiency; Healthcare systems comparison; Human clinician performance; Medical query handling",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": ""
    },
    {
      "pmid": "32985908",
      "title": "Machine-Learning Models for Multicenter Prostate Cancer Treatment Plans.",
      "abstract": "Clinical factors, including T-stage, Gleason score, and baseline prostate-specific antigen, are used to stratify patients with prostate cancer (PCa) into risk groups. This provides prognostic information for a heterogeneous disease such as PCa and guides treatment selection. In this article, we hypothesize that nonclinical factors may also impact treatment selection and their adherence to treatment guidelines. A total of 552 patients with intermediate- and high-risk PCa treated with definitive radiation with or without androgen deprivation therapy (ADT) between 2010 and 2017 were identified from 34 medical centers within the Veterans Health Administration. Medical charts were manually reviewed, and details regarding each patient's clinical history and treatment were extracted. Support Vector Machine and Random forest-based classification was used to identify clinical and nonclinical predictors of adherence to the treatment guidelines from the National Comprehensive Cancer Network (NCCN). We created models for predicting both initial treatment intent and treatment alterations. Our results demonstrate that besides clinical factors, the center in which the patient was treated (nonclinical factor) played a significant role in adherence to NCCN guidelines. Furthermore, the treatment center served as an important predictor to decide on whether or not to prescribe ADT; however, it was not associated with ADT duration and weakly associated with treatment alterations. Such center-bias motivates further investigation on details of center-specific barriers to both NCCN guideline adherence and on oncological outcomes. In addition, we demonstrate that publicly available data sets, for example, that from Surveillance, Epidemiology, and End Results (SEERs), may not be well equipped to build such predictive models on treatment plans.",
      "authors": "Syed Khajamoinuddin; Sleeman William; Soni Payal; Hagan Michael; Palta Jatinder; Kapoor Rishabh; Ghosh Preetam",
      "year": "2021",
      "journal": "Journal of computational biology : a journal of computational molecular cell biology",
      "doi": "10.1089/cmb.2020.0188",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32985908/",
      "mesh_terms": "Androgen Antagonists; Decision Support Systems, Clinical; Humans; Male; Models, Theoretical; Neoplasm Grading; Neoplasm Staging; Practice Guidelines as Topic; Prognosis; Prostatic Neoplasms; Radiotherapy; SEER Program; Support Vector Machine; Treatment Outcome; United States; Veterans Health Services",
      "keywords": "SEER; SVM; androgen deprivation therapy; localized prostate cancer; radiation therapy; random forests",
      "pub_types": "Journal Article; Multicenter Study; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "32028323",
      "title": "Validation of Questionnaire-based Case Definitions for Chronic Obstructive Pulmonary Disease.",
      "abstract": "BACKGROUND: Various questionnaire-based definitions of chronic obstructive pulmonary disease (COPD) have been applied using the US representative National Health and Nutrition Examination Survey (NHANES), but few have been validated against objective lung function data. We validated two prior definitions that incorporated self-reported physician diagnosis, respiratory symptoms, and/or smoking. We also validated a new definition that we developed empirically using gradient boosting, an ensemble machine learning method. METHODS: Data came from 7,996 individuals 40-79 years who participated in NHANES 2007-2012 and underwent spirometry. We considered participants \"true\" COPD cases if their ratio of postbronchodilator forced expiratory volume in 1 second to forced vital capacity was below 0.7 or the lower limit of normal. We stratified all analyses by smoking history. We developed a gradient boosting model for smokers only; predictors assessed (25 total) included sociodemographics, inhalant exposures, clinical variables, and respiratory symptoms. RESULTS: The spirometry-based COPD prevalence was 26% for smokers and 8% for never smokers. Among smokers, using questionnaire-based definitions resulted in a COPD prevalence ranging from 11% to 16%, sensitivity ranging from 18% to 35%, and specificity ranging from 88% to 92%. The new definition classified participants based on age, bronchodilator use, body mass index (BMI), smoking pack-years, and occupational organic dust exposure, and resulted in the highest sensitivity (35%) and specificity (92%) among smokers. Among never smokers, the COPD prevalence ranged from 4% to 5%, and we attained good specificity (96%) at the expense of sensitivity (9-10%). CONCLUSION: Our results can be used to parametrize misclassification assumptions for quantitative bias analysis when pulmonary function data are unavailable.",
      "authors": "Feinstein Lydia; Wilkerson Jesse; Salo Paivi M; MacNell Nathaniel; Bridge Matthew F; Fessler Michael B; Thorne Peter S; Mendy Angelico; Cohn Richard D; Curry Matthew D; Zeldin Darryl C",
      "year": "2020",
      "journal": "Epidemiology (Cambridge, Mass.)",
      "doi": "10.1097/EDE.0000000000001176",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32028323/",
      "mesh_terms": "Adult; Aged; Female; Forced Expiratory Volume; Humans; Male; Middle Aged; Nutrition Surveys; Prevalence; Pulmonary Disease, Chronic Obstructive; Reproducibility of Results; Spirometry; Vital Capacity",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, N.I.H., Intramural",
      "pmcid": "PMC7138734"
    },
    {
      "pmid": "33109457",
      "title": "Development and Validation of a Prediction Model of Prescription Tranquilizer Misuse Based on a Nationally Representative United States Sample.",
      "abstract": "BACKGROUND: Prescription tranquilizer misuse is a risky behavior associated with fatal drug poisonings. Although various predictors have been examined, there is no published prediction model for tranquilizer misuse. This study develops and internally validates a tranquilizer misuse prediction model based primarily on drug histories of participants in a national cross-sectional survey. Predictors also include psychiatric, behavioral and demographic variables. METHODS: We analyzed data from 471,097 individuals aged 14-to-29-years in the United States, as sampled by the National Survey of Drug Use and Health, 2004-2018, an annual cross-sectional survey. We encoded 21 predictors with known or likely onset prior to tranquilizer misuse initiation, (e.g., early onset of cannabis use). With this dataset, we trained a neural network and regularized logistic regression model. While the assessment for tranquilizer misuse changed slightly in 2015, by pooling all years of survey data, predictions are robust to this source of variation. RESULTS: 1.44% of the pooled sample, 2004-2018, recently initiated tranquilizer misuse (unweighted estimate). On held-out test data (n = 43,714), logistic regression and the neural network performed equally well, with an area under the receiver operating characteristic curve (AUC) of \u223c0.83 on the primary model, containing 12 variables known to occur before tranquilizer misuse. CONCLUSION: Built for case prediction rather than case detection, this model restricted predictors to those with known timing prior to initiation of tranquilizer misuse. Yet its performance supersedes commonly accepted criteria for clinical prediction models (AUC > 0.80). Future work should incorporate survey analysis weights into the prediction model to minimize possible bias.",
      "authors": "Thompson C L; Alcover Karl; Yip Sarah W",
      "year": "2021",
      "journal": "Drug and alcohol dependence",
      "doi": "10.1016/j.drugalcdep.2020.108344",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33109457/",
      "mesh_terms": "Adolescent; Adult; Aged; Cross-Sectional Studies; Drug-Related Side Effects and Adverse Reactions; Female; Humans; Hypnotics and Sedatives; Logistic Models; Male; Middle Aged; Prescription Drug Misuse; Prescriptions; Risk-Taking; Substance-Related Disorders; Surveys and Questionnaires; Tranquilizing Agents; United States; Young Adult",
      "keywords": "Benzodiazepines; Drug Dependence; Extra-Medical; Machine Learning; Muscle Relaxants; Nonmedical Use; Xanax",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural; Research Support, U.S. Gov't, P.H.S.; Validation Study",
      "pmcid": ""
    },
    {
      "pmid": "39454187",
      "title": "Studies of Artificial Intelligence/Machine Learning Registered on ClinicalTrials.gov: Cross-Sectional Study With Temporal Trends, 2010-2023.",
      "abstract": "BACKGROUND: The rapid growth of research in artificial intelligence (AI) and machine learning (ML) continues. However, it is unclear whether this growth reflects an increase in desirable study attributes or merely perpetuates the same issues previously raised in the literature. OBJECTIVE: This study aims to evaluate temporal trends in AI/ML studies over time and identify variations that are not apparent from aggregated totals at a single point in time. METHODS: We identified AI/ML studies registered on ClinicalTrials.gov with start dates between January 1, 2010, and December 31, 2023. Studies were included if AI/ML-specific terms appeared in the official title, detailed description, brief summary, intervention, primary outcome, or sponsors' keywords. Studies registered as systematic reviews and meta-analyses were excluded. We reported trends in AI/ML studies over time, along with study characteristics that were fast-growing and those that remained unchanged during 2010-2023. RESULTS: Of 3106 AI/ML studies, only 7.6% (n=235) were regulated by the US Food and Drug Administration. The most common study characteristics were randomized (56.2%; 670/1193; interventional) and prospective (58.9%; 1126/1913; observational) designs; a focus on diagnosis (28.2%; 335/1190) and treatment (24.4%; 290/1190); hospital/clinic (44.2%; 1373/3106) or academic (28%; 869/3106) sponsorship; and neoplasm (12.9%; 420/3245), nervous system (12.2%; 395/3245), cardiovascular (11.1%; 356/3245) or pathological conditions (10%; 325/3245; multiple counts per study possible). Enrollment data were skewed to the right: maximum 13,977,257; mean 16,962 (SD 288,155); median 255 (IQR 80-1000). The most common size category was 101-1000 (44.8%; 1372/3061; excluding withdrawn or missing), but large studies (n>1000) represented 24.1% (738/3061) of all studies: 29% (551/1898) of observational studies and 16.1% (187/1163) of trials. Study locations were predominantly in high-income countries (75.3%; 2340/3106), followed by upper-middle-income (21.7%; 675/3106), lower-middle-income (2.8%; 88/3106), and low-income countries (0.1%; 3/3106). The fastest-growing characteristics over time were high-income countries (location); Europe, Asia, and North America (location); diagnosis and treatment (primary purpose); hospital/clinic and academia (lead sponsor); randomized and prospective designs; and the 1-100 and 101-1000 size categories. Only 5.6% (47/842) of completed studies had results available on ClinicalTrials.gov, and this pattern persisted. Over time, there was an increase in not only the number of newly initiated studies, but also the number of completed studies without posted results. CONCLUSIONS: Much of the rapid growth in AI/ML studies comes from high-income countries in high-resource settings, albeit with a modest increase in upper-middle-income countries (mostly China). Lower-middle-income or low-income countries remain poorly represented. The increase in randomized or prospective designs, along with 738 large studies (n>1000), mostly ongoing, may indicate that enough studies are shifting from an in silico evaluation stage toward a prospective comparative evaluation stage. However, the ongoing limited availability of basic results on ClinicalTrials.gov contrasts with this field's rapid advancements and the public registry's role in reducing publication and outcome reporting biases.",
      "authors": "Maru Shoko; Matthias Michael D; Kuwatsuru Ryohei; Simpson Ross J",
      "year": "2024",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/57750",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39454187/",
      "mesh_terms": "Artificial Intelligence; Machine Learning; Cross-Sectional Studies; Humans; United States; Registries",
      "keywords": "ClinicalTrials.gov; artificial intelligence; cross-sectional study; data-source disparities; deep learning; health care; health disparities; machine learning; publication bias; registry; trends",
      "pub_types": "Journal Article",
      "pmcid": "PMC11549584"
    },
    {
      "pmid": "36971840",
      "title": "Complementary and Integrative Health Approaches and Pain Care Quality in the Veterans Health Administration Primary Care Setting: A Quasi-Experimental Analysis.",
      "abstract": "Background: Complementary and integrative health (CIH) approaches have been recommended in national and international clinical guidelines for chronic pain management. We set out to determine whether exposure to CIH approaches is associated with pain care quality (PCQ) in the Veterans Health Administration (VHA) primary care setting. Methods: We followed a cohort of 62,721 Veterans with newly diagnosed musculoskeletal disorders between October 2016 and September 2017 over 1-year. PCQ scores were derived from primary care progress notes using natural language processing. CIH exposure was defined as documentation of acupuncture, chiropractic or massage therapies by providers. Propensity scores (PSs) were used to match one control for each Veteran with CIH exposure. Generalized estimating equations were used to examine associations between CIH exposure and PCQ scores, accounting for potential selection and confounding bias. Results: CIH was documented for 14,114 (22.5%) Veterans over 16,015 primary care clinic visits during the follow-up period. The CIH exposure group and the 1:1 PS-matched control group achieved superior balance on all measured baseline covariates, with standardized differences ranging from 0.000 to 0.045. CIH exposure was associated with an adjusted rate ratio (aRR) of 1.147 (95% confidence interval [CI]: 1.142, 1.151) on PCQ total score (mean: 8.36). Sensitivity analyses using an alternative PCQ scoring algorithm (aRR: 1.155; 95% CI: 1.150-1.160) and redefining CIH exposure by chiropractic alone (aRR: 1.118; 95% CI: 1.110-1.126) derived consistent results. Discussion: Our data suggest that incorporating CIH approaches may reflect higher overall quality of care for patients with musculoskeletal pain seen in primary care settings, supporting VHA initiatives and the Declaration of Astana to build comprehensive, sustainable primary care capacity for pain management. Future investigation is warranted to better understand whether and to what degree the observed association may reflect the therapeutic benefits patients actually received or other factors such as empowering provider-patient education and communication about these approaches.",
      "authors": "Han Ling; Luther Stephen L; Finch Dezon K; Dobscha Steven K; Skanderson Melissa; Bathulapalli Harini; Fodeh Samah J; Hahm Bridget; Bouayad Lina; Lee Allison; Goulet Joseph L; Brandt Cynthia A; Kerns Robert D",
      "year": "2023",
      "journal": "Journal of integrative and complementary medicine",
      "doi": "10.1089/jicm.2022.0686",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36971840/",
      "mesh_terms": "Humans; Veterans Health; Chronic Pain; Complementary Therapies; Quality of Health Care; Primary Health Care",
      "keywords": "VHA primary care; complementary and integrative health approaches (CIH); musculoskeletal disorders (MSD); natural language processing (NLP); pain care quality (PCQ); propensity score (PS)",
      "pub_types": "Journal Article",
      "pmcid": "PMC10280173"
    },
    {
      "pmid": "41066621",
      "title": "Social Media Discussions About Robotic Total Knee Arthroplasty: Cross-Sectional Analysis.",
      "abstract": "BACKGROUND: The advent of robotic total knee arthroplasty (TKA) in the field of orthopedics has caused much discussion on social media. As social media grows, its platforms are becoming an increasingly popular medium for health care-related discussions. OBJECTIVE: This study aimed to better understand the current public discussion about robotic TKA on social media. We aimed to characterize these discussions by analyzing their contributors, the general sentiment, the temporal trends, and the content. METHODS: A comprehensive search of the Twitter database for academic research was performed from inception (March 2006) to April 1, 2023, to identify all tweets related to robotic TKA. General data regarding the tweets and the accounts were retrieved. ChatGPT-4o (OpenAI) was used to categorize the post's content and the accounts into different categories developed via iterative testing. The content was categorized using a rule-based classification algorithm developed using Python to assign categories based on keyword presence, phrase matching, and syntactic patterns. Regarding the accounts, an automated keyword-based rule engine was implemented in Python to classify accounts based on the account's name and description. We used a lexicon-based natural language processing Python library, via ChatGPT-4o, to assign a sentiment to the tweets and conducted subgroup sentiment analysis. RESULTS: A total of 2000 tweets were retrieved for analysis. Account analysis revealed that the most prevalent account categories were \"medical professionals\" (619/2000, 31.0%), \"patients and community\" (274/2000, 13.7%), and \"media and publications\" (268/2000, 13.4%). Content analysis revealed that the most prevalent tweet themes were \"technology and innovation\" (550/2000, 27.5%), \"advertising and promotion\" (176/2000, 8.8%), and \"research and data\" (172/2000, 8.6%). Sentiment analysis showed that 61.6% (1231/2000) of the tweets had a positive sentiment, while 9.2% (183/2000) were neutral, and 29.3% (586/2000) had a negative sentiment. Accounts categorized as \"institutions\" had the highest prevalence of positive sentiment (165/229, 72.1%), while accounts categorized as \"media and publications\" had the highest prevalence of negative sentiment (88/268, 32.8%). The number of tweets relating to robotic TKA has been steadily rising since 2016, with a peak incidence of 402 (20.1%) tweets published in 2022. CONCLUSIONS: The increased number of tweets with a positive sentiment suggests a positive outlook toward robotic TKA. Institutions had the highest prevalence of positive sentiment, suggesting a possible bias toward positive reporting of robotic TKA, likely for commercial reasons. Media and publications had the highest prevalence of negative sentiment, which may represent skepticism and bias toward negative reporting on robotic technologies in health care. Medical professionals contributed significantly to the discussion about robotic TKA, while patient involvement was relatively small. The number of tweets relating to robotic TKA has been steadily growing since 2016, which indicates that robotic TKA has been gaining in popularity over recent years.",
      "authors": "Desgagn\u00e9 Charles; Levett Jordan J; Elkaim Lior M; Antoniou John",
      "year": "2025",
      "journal": "JMIR infodemiology",
      "doi": "10.2196/69883",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41066621/",
      "mesh_terms": "Humans; Social Media; Arthroplasty, Replacement, Knee; Cross-Sectional Studies; Robotic Surgical Procedures",
      "keywords": "arthroplasty; clinician; knee replacement; patient; researcher; robotic; robotic surgery; social media; twitter",
      "pub_types": "Journal Article",
      "pmcid": "PMC12510438"
    },
    {
      "pmid": "28645212",
      "title": "Google Searches for \"Cheap Cigarettes\" Spike at Tax Increases: Evidence from an Algorithm to Detect Spikes in Time Series Data.",
      "abstract": "INTRODUCTION: Online cigarette dealers have lower prices than brick-and-mortar retailers and advertise tax-free status.1-8 Previous studies show smokers search out these online alternatives at the time of a cigarette tax increase.9,10 However, these studies rely upon researchers' decision to consider a specific date and preclude the possibility that researchers focus on the wrong date. The purpose of this study is to introduce an unbiased methodology to the field of observing search patterns and to use this methodology to determine whether smokers search Google for \"cheap cigarettes\" at cigarette tax increases and, if so, whether the increased level of searches persists. METHODS: Publicly available data from Google Trends is used to observe standardized search volumes for the term, \"cheap cigarettes\". Seasonal Hybrid Extreme Studentized Deviate and E-Divisive with Means tests were performed to observe spikes and mean level shifts in search volume. RESULTS: Of the twelve cigarette tax increases studied, ten showed spikes in searches for \"cheap cigarettes\" within two weeks of the tax increase. However, the mean level shifts did not occur for any cigarette tax increase. CONCLUSION: Searches for \"cheap cigarettes\" spike around the time of a cigarette tax increase, but the mean level of searches does not shift in response to a tax increase. The SHESD and EDM tests are unbiased methodologies that can be used to identify spikes and mean level shifts in time series data without an a priori date to be studied. SHESD and EDM affirm spikes in interest are related to tax increases. IMPLICATIONS: \u2022 Applies improved statistical techniques (SHESD and EDM) to Google search data related to cigarettes, reducing bias and increasing power \u2022 Contributes to the body of evidence that state and federal tax increases are associated with spikes in searches for cheap cigarettes and may be good dates for increased online health messaging related to tobacco.",
      "authors": "Caputi Theodore L",
      "year": "2018",
      "journal": "Nicotine & tobacco research : official journal of the Society for Research on Nicotine and Tobacco",
      "doi": "10.1093/ntr/ntx143",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28645212/",
      "mesh_terms": "Algorithms; Commerce; Data Analysis; Humans; Internet; Interrupted Time Series Analysis; Taxes; Tobacco Products",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "23745785",
      "title": "Robotic radiosurgery for the treatment of 1-3 brain metastases: a pragmatic application of cost-benefit analysis using willingness-to-pay.",
      "abstract": "With the emergence of radiosurgery as a new radiotherapeutic technique, health care decision makers are required to incorporate community need, cost and patient preferences when allocating radiosurgery resources. Conventional patient utility measures would not reflect short term preferences and would therefore not inform decision makers when allocating radiosurgery treatment units. The goal of this article is to demonstrate the feasibility of cost-benefit analysis to elicit the yearly net monetary benefit of robotic radiosurgery. To calculate the yearly incremental cost of robotic radiosurgery as compared to fixed gantry radiosurgery we used direct local cost data. We assumed a standard 10 year replacement and 5% amortization rate. Decision boards summarizing the clinical scenario of brain metastases and the difference between robotic and fixed gantry radiosurgery in terms of immobilization, comfort and treatment time were then presented to a sample of 18 participants. Participants who preferred robotic radiosurgery were randomly assigned to either a low ($1) or high ($5) starting point taxation based willingness-to-pay algorithm. The yearly incremental cost of providing robotic radiosurgery was $99,177 CAD. The mean community yearly willingness-to-pay for robotic radiosurgery was $2,300,000 CAD, p = 0.03. The calculated yearly net societal benefit for robotic radiosurgery was $2,200,823 CAD. Among participants who preferred robotic radiosurgery there was no evidence of starting point bias, p = 0.8. We have shown through this pilot study that it is feasible to perform cost-benefit analysis to evaluate new technologies in Radiation Oncology. Cost-benefit analysis offers an analytic method to evaluate local preferences and provide accountability when allocating limited healthcare resources.",
      "authors": "Greenspoon Jeffrey Noah; Whitton Anthony; Whelan Timothy; Sharieff Waseem; Wright James; Sussman Jonathan; Gafni Amiram",
      "year": "2013",
      "journal": "Technology in cancer research & treatment",
      "doi": "10.7785/tcrt.2012.500344",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23745785/",
      "mesh_terms": "Brain Neoplasms; Cost-Benefit Analysis; Humans; Insurance, Health, Reimbursement; Ontario; Radiosurgery; Robotics; Surgery, Computer-Assisted",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "15741805",
      "title": "Usefulness of lyophilized calibration plasmas for International Normalized Ratio determination with the bovine combined thromboplastin (Thrombotest): results of a collaborative study.",
      "abstract": "The logical solution to account for the influence of coagulometers on the International Sensitivity Index (ISI) is local calibration with freeze-dried plasmas. However, because of their unpredictable behavior these plasmas must be validated before large-scale implementation. We report on a collaborative exercise designed to evaluate the suitability of a set of such plasmas used with Thrombotest in combination with a coagulometer provided by the manufacturer to be used with that reagent. This was a two-step study. First, one lot of reagent was calibrated against the international standard OBT/79 in two expert laboratories. The calibrated lot was then used as an intermediate standard to calibrate two additional lots of the same reagent in four field laboratories where the ISI was determined for both plasma and native blood. The International Normalized Ratio (INR) for the patient plasmas tested in each laboratory were calculated using two algorithms: the World Health Organization-recommended ISI mode (gold standard), and the simplified calibration plasma mode. In the latter, the INR was derived from the local calibration curve constructed by plotting the certified INR versus local coagulation times obtained with calibration plasmas. The between-algorithm INR differences indicate that this set of calibration plasmas may be employed for local INR calibration of the investigated reagent/instrument combination, especially when plasma is used for INR determination where the average INR (range) difference is 5% (3-13%) or 2% (3-8%) according to whether the INRs to calibration plasmas were assigned by the manufacturer or by the two expert laboratories. A slight but measurable difference of the INR may be predicted [9% (6-20%) or 6% (8-15%)] if this set of calibration plasmas is used for local calibration when native blood is employed for INR determination. Whether this bias is of practical significance is to be determined.",
      "authors": "Chantarangkul Veena; Frontoni Rita; Gresele Paolo; Oca Gaetana; Paniccia Rita; Pellegrini Lucio; Tripodi Armando",
      "year": "2005",
      "journal": "Blood coagulation & fibrinolysis : an international journal in haemostasis and thrombosis",
      "doi": "10.1097/01.mbc.0000161571.04883.6c",
      "url": "https://pubmed.ncbi.nlm.nih.gov/15741805/",
      "mesh_terms": "Animals; Cattle; Humans; International Normalized Ratio; Reference Standards; Thromboplastin",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39376943",
      "title": "Integrating tabular data through image conversion for enhanced diagnosis: A novel intelligent decision support system for stratifying obstructive sleep apnoea patients using convolutional neural networks.",
      "abstract": "OBJECTIVE: High-dimensional databases make it difficult to apply traditional learning algorithms to biomedical applications. Recent developments in computer technology have introduced deep learning (DL) as a potential solution to these difficulties. This study presents a novel intelligent decision support system based on a novel interpretation of data formalisation from tabular data in DL techniques. Once defined, it is used to diagnose the severity of obstructive sleep apnoea, distinguishing between moderate to severe and mild/no cases. METHODS: The study uses a complete database extract from electronic health records of 2472 patients, including anthropometric data, habits, medications, comorbidities, and patient-reported symptoms. The novelty of this methodology lies in the initial processing of the patients' data, which is formalised into images. These images are then used as input to train a convolutional neural network (CNN), which acts as the inference engine of the system. RESULTS: The initial tests of the system were performed on a set of 247 samples from the Pulmonary Department of the \u00c1lvaro Cunqueiro Hospital in Vigo (Galicia, Spain), with an AUC value of \u2248 0.8. CONCLUSIONS: This study demonstrates the benefits of an intelligent decision support system based on a novel data formalisation approach that allows the use of advanced DL techniques starting from tabular data. In this way, the ability of CNNs to recognise complex patterns using visual elements such as gradients and contrasts can be exploited. This approach effectively addresses the challenges of analysing large amounts of tabular data and reduces common problems such as bias and variance, resulting in improved diagnostic accuracy.",
      "authors": "Casal-Guisande Manuel; Fern\u00e1ndez-Villar Alberto; Mosteiro-A\u00f1\u00f3n Mar; Comesa\u00f1a-Campos Alberto; Cerqueiro-Peque\u00f1o Jorge; Torres-Dur\u00e1n Mar\u00eda",
      "year": "2024",
      "journal": "Digital health",
      "doi": "10.1177/20552076241272632",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39376943/",
      "mesh_terms": "",
      "keywords": "Diagnosis; artificial intelligence; convolutional neural networks; decision support systems; deep learning; design; intelligent systems; medical algorithm; obstructive sleep apnoea",
      "pub_types": "Journal Article",
      "pmcid": "PMC11457234"
    },
    {
      "pmid": "35328163",
      "title": "Post-Acquisition Hyperpolarized 29Silicon Magnetic Resonance Image Processing for Visualization of Colorectal Lesions Using a User-Friendly Graphical Interface.",
      "abstract": "Medical imaging devices often use automated processing that creates and displays a self-normalized image. When improperly executed, normalization can misrepresent information or result in an inaccurate analysis. In the case of diagnostic imaging, a false positive in the absence of disease, or a negative finding when disease is present, can produce a detrimental experience for the patient and diminish their health prospects and prognosis. In many clinical settings, a medical technical specialist is trained to operate an imaging device without sufficient background information or understanding of the fundamental theory and processes involved in image creation and signal processing. Here, we describe a user-friendly image processing algorithm that mitigates user bias and allows for true signal to be distinguished from background. For proof-of-principle, we used antibody-targeted molecular imaging of colorectal cancer (CRC) in a mouse model, expressing human MUC1 at tumor sites. Lesion detection was performed using targeted magnetic resonance imaging (MRI) of hyperpolarized silicon particles. Resulting images containing high background and artifacts were then subjected to individualized image post-processing and comparative analysis. Post-acquisition image processing allowed for co-registration of the targeted silicon signal with the anatomical proton magnetic resonance (MR) image. This new methodology allows users to calibrate a set of images, acquired with MRI, and reliably locate CRC tumors in the lower gastrointestinal tract of living mice. The method is expected to be generally useful for distinguishing true signal from background for other cancer types, improving the reliability of diagnostic MRI.",
      "authors": "McCowan Caitlin V; Salmon Duncan; Hu Jingzhe; Pudakalakatti Shivanand; Whiting Nicholas; Davis Jennifer S; Carson Daniel D; Zacharias Niki M; Bhattacharya Pratip K; Farach-Carson Mary C",
      "year": "2022",
      "journal": "Diagnostics (Basel, Switzerland)",
      "doi": "10.3390/diagnostics12030610",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35328163/",
      "mesh_terms": "",
      "keywords": "GUI; MRI; colorectal cancer; diagnostic imaging; hyperpolarization; image processing; silicon particles",
      "pub_types": "Journal Article",
      "pmcid": "PMC8947341"
    },
    {
      "pmid": "33011384",
      "title": "Development, content validation, and reliability of the Assessment of Real-World Observational Studies (ArRoWS) critical appraisal tool.",
      "abstract": "PURPOSE: The objective was to develop and test a pragmatic critical appraisal tool, the Assessment of Real-World Observational Studies (ArRoWS), to quickly and easily assess the quality of real-world evidence studies using electronic health records. METHODS: The initial ArRoWS tool was developed by identifying items frequently found in existing validated assessment instruments and adapting these items to specifically assess real-world evidence studies. The tool was revised based on recommendations from an expert panel of 14 senior academic individuals specializing in epidemiology and content validity was measured. During March 2018-January 2019, 47 large, observational studies related to cardiometabolic medicine were identified through a search algorithm and assessed by three pairs of raters using the ArRoWS tool. RESULTS: The final version of the ArRoWS had 16 items including nine core items and seven study design-specific items with item-specific content validity indexes ranging from 0.64 to 1.00. The scale-level content validity index of the ArRoWS appraisal tool was 0.91. When the ArRoWS tool was pilot tested, the observed agreement between assessor pairs on whether the study provided high-quality real-world evidence was 85.7%, 68.8%, and 58.8%. The prevalence adjusted bias-adjusted kappa for the assessor pairs was 0.71, 0.38, and 0.18. CONCLUSION: The ArRoWS is a simple tool to standardize the assessment of real-world evidence studies.",
      "authors": "Coles Briana; Tyrer Freya; Hussein Humaira; Dhalwani Nafeesa; Khunti Kamlesh",
      "year": "2021",
      "journal": "Annals of epidemiology",
      "doi": "10.1016/j.annepidem.2020.09.014",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33011384/",
      "mesh_terms": "Bias; Humans; Observational Studies as Topic; Reproducibility of Results; Research Design",
      "keywords": "Appraisal tool; Assessment tool; Cardiometabolic medicine; Electronic databases; Observational study; Real-world evidence",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "40018053",
      "title": "Automated CT image prescription of the gallbladder using deep learning: Development, evaluation, and health promotion.",
      "abstract": "AIM: Most previous research on AI-based image diagnosis of acute cholecystitis (AC) has utilized ultrasound images. While these studies have shown promising outcomes, the results were based on still images captured by physicians, introducing inevitable selection bias. This study aims to develop a fully automated system for precise gallbladder detection among various abdominal structures, aiding clinicians in the rapid assessment of AC requiring cholecystectomy. METHODS: The dataset comprised images from 250 AC patients and 270 control participants. The VGG-16 architecture was employed for gallbladder recognition. Post-processing techniques such as the flood fill algorithm and centroid calculation were integrated into the model. U-Net was utilized for segmentation and features extraction. All models were combined to develop a fully automated AC detection system. RESULTS: The gallbladder identification accuracy among various abdominal organs was 95.3%, with the model effectively filtering out CT images lacking a gallbladder. In diagnosing AC, the model was tested on 120 cases, achieving an accuracy of 92.5%, sensitivity of 90.4%, and specificity of 94.1%. After integrating all components, the ensemble model achieved an overall accuracy of 86.7%. The automated process required 0.029 seconds of computation time per CT slice and 3.59 seconds per complete CT set. CONCLUSIONS: The proposed system achieves promising performance in the automatic detection and diagnosis of gallbladder conditions in patients requiring cholecystectomy, with robust accuracy and computational efficiency. With further clinical validation, this computer-assisted system could serve as an auxiliary tool in identifying patients requiring emergency surgery.",
      "authors": "Yang Chien-Yi; Kao Hao-Lun; Chen Yu Cheng; Kuo Chung-Feng; Liu Chieh Hsing; Liu Shao-Cheng",
      "year": "2025",
      "journal": "Acute medicine & surgery",
      "doi": "10.1002/ams2.70049",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40018053/",
      "mesh_terms": "",
      "keywords": "Acute cholecystitis; CT; artificial intelligence; cholecystectomy; deep learning",
      "pub_types": "Journal Article",
      "pmcid": "PMC11865635"
    },
    {
      "pmid": "38590103",
      "title": "Advancing unanchored simulated treatment comparisons: A novel implementation and simulation study.",
      "abstract": "Population-adjusted indirect comparisons, developed in the 2010s, enable comparisons between two treatments in different studies by balancing patient characteristics in the case where individual patient-level data (IPD) are available for only one study. Health technology assessment (HTA) bodies increasingly rely on these methods to inform funding decisions, typically using unanchored indirect comparisons (i.e., without a common comparator), due to the need to evaluate comparative efficacy and safety for single-arm trials. Unanchored matching-adjusted indirect comparison (MAIC) and unanchored simulated treatment comparison (STC) are currently the only two approaches available for population-adjusted indirect comparisons based on single-arm trials. However, there is a notable underutilisation of unanchored STC in HTA, largely due to a lack of understanding of its implementation. We therefore develop a novel way to implement unanchored STC by incorporating standardisation/marginalisation and the NORmal To Anything (NORTA) algorithm for sampling covariates. This methodology aims to derive a suitable marginal treatment effect without aggregation bias for HTA evaluations. We use a non-parametric bootstrap and propose separately calculating the standard error for the IPD study and the comparator study to ensure the appropriate quantification of the uncertainty associated with the estimated treatment effect. The performance of our proposed unanchored STC approach is evaluated through a comprehensive simulation study focused on binary outcomes. Our findings demonstrate that the proposed approach is asymptotically unbiased. We argue that unanchored STC should be considered when conducting unanchored indirect comparisons with single-arm studies, presenting a robust approach for HTA decision-making.",
      "authors": "Ren Shijie; Ren Sa; Welton Nicky J; Strong Mark",
      "year": "2024",
      "journal": "Research synthesis methods",
      "doi": "10.1002/jrsm.1718",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38590103/",
      "mesh_terms": "Humans; Computer Simulation; Algorithms; Technology Assessment, Biomedical; Research Design; Models, Statistical; Treatment Outcome; Reproducibility of Results; Bias; Data Interpretation, Statistical",
      "keywords": "indirect treatment comparison; marginal treatment effect; population adjustment; unanchored simulated treatment comparison",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": ""
    },
    {
      "pmid": "18695650",
      "title": "Causal models for estimating the effects of weight gain on mortality.",
      "abstract": "Suppose, in contrast to the fact, in 1950, we had put the cohort of 18-year-old non-smoking American men on a stringent mandatory diet that guaranteed that no one would ever weigh more than their baseline weight established at the age of 18 years. How would the counterfactual mortality of these 18 year olds have compared to their actual observed mortality through 2007? We describe in detail how this counterfactual contrast could be estimated from longitudinal epidemiologic data similar to that stored in the electronic medical records of a large health maintenance organization (HMO) by applying g-estimation to a novel of structural nested model (SNM). Our analytic approach differs from any alternative approach in that, in the absence of model misspecification, it can successfully adjust for (i) measured time-varying confounders such as exercise, hypertension and diabetes that are simultaneously intermediate variables on the causal pathway from weight gain to death and determinants of future weight gain, (ii) unmeasured confounding by undiagnosed preclinical disease (that is, reverse causation) that can cause both poor weight gain and premature mortality (provided an upper bound can be specified for the maximum length of time a subject may suffer from a subclinical illness severe enough to affect his weight without the illness becomes clinically manifest) and (iii) the presence of particular identifiable subgroups, such as those suffering from serious renal, liver, pulmonary and/or cardiac disease, in whom confounding by unmeasured prognostic factors is so severe as to render useless any attempt at direct analytic adjustment. However, (ii) and (iii) limit the ability to empirically test whether the SNM is misspecified. The other two g-methods--the parametric g-computation algorithm and inverse probability of treatment weighted estimation of marginal structural models--can adjust for potential bias due to (i) but not due to (ii) or (iii).",
      "authors": "Robins J M",
      "year": "2008",
      "journal": "International journal of obesity (2005)",
      "doi": "10.1038/ijo.2008.83",
      "url": "https://pubmed.ncbi.nlm.nih.gov/18695650/",
      "mesh_terms": "Adolescent; Bias; Body Mass Index; Humans; Longitudinal Studies; Male; Models, Statistical; Mortality; Weight Gain",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38971193",
      "title": "Identifying influencing factors of metabolic syndrome in patients with major depressive disorder: A real-world study with Bayesian network modeling.",
      "abstract": "BACKGROUND: The bidirectional relationships between metabolic syndrome (MetS) and major depressive disorder (MDD) were discovered, but the influencing factors of the comorbidity were barely investigated. We aimed to fully explore the factors and their associations with MetS in MDD patients. METHODS: The data were retrieved from the electronic medical records of a tertiary psychiatric hospital in Beijing from 2016 to 2021. The influencing factors were firstly explored by univariate analysis and multivariate logistic regressions. The propensity score matching was used to reduce the selection bias of participants. Then, the Bayesian networks (BNs) with hill-climbing algorithm and maximum likelihood estimation were preformed to explore the relationships between influencing factors with MetS in MDD patients. RESULTS: Totally, 4126 eligible subjects were included in the data analysis. The proportion rate of MetS was 32.6\u00a0% (95\u00a0% CI: 31.2\u00a0%-34.1\u00a0%). The multivariate logistic regression suggested that recurrent depression, uric acid, duration of depression, marriage, education, number of hospitalizations were significantly associated with MetS. In the BNs, number of hospitalizations and uric acid were directly connected with MetS. Recurrent depression and family history psychiatric diseases were indirectly connected with MetS. The conditional probability of MetS in MDD patients with family history of psychiatric diseases, recurrent depression and two or more times of hospitalizations was 37.6\u00a0%. CONCLUSION: Using the BNs, we found that number of hospitalizations, recurrent depression and family history of psychiatric diseases contributed to the probability of MetS, which could help to make health strategies for specific MDD patients.",
      "authors": "Qi Han; Liu Rui; Dong Cheng-Cheng; Zhu Xue-Quan; Feng Yuan; Wang Hai-Ning; Li Lei; Chen Fei; Wang Gang; Yan Fang",
      "year": "2024",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2024.07.004",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38971193/",
      "mesh_terms": "Humans; Major Depressive Disorder; Metabolic Syndrome; Female; Male; Bayes Theorem; Middle Aged; Adult; Comorbidity; Risk Factors; China; Logistic Models; Hospitalization; Uric Acid; Propensity Score",
      "keywords": "Bayesian network; Influencing factors; Major depressive disorder; Metabolic syndrome; Real-world data",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "23795223",
      "title": "A novel approach to improve health status measurement in observational claims-based studies of cancer treatment and outcomes.",
      "abstract": "OBJECTIVES: To develop and provide initial validation for amultivariate, claims-based prediction model for disability status (DS), a proxymeasure of performance status (PS), among older adults. The model was designed to augment information on health status at the point of cancer diagnosis in studies using insurance claims to examine cancer treatment and outcomes. MATERIALS AND METHODS: We used data from the 2001\u20132005 Medicare Current Beneficiary Survey (MCBS), with observations randomly split into estimation and validation subsamples. We developed an algorithm linking self-reported functional status measures to a DS scale, a proxy for the Eastern Cooperative Oncology Group (ECOG) PS scale. The DS measure was dichotomized to focus on good [ECOG 0\u20132] versus poor [ECOG 3\u20134] PS. We identified potential claims-based predictors, and estimated multivariate logistic regression models, with poor DS as the dependent measure, using a stepwise approach to select the optimal model. Construct validity was tested by determining whether the predicted DS measure generated by the model was a significant predictor of survival within a validation sample from the MCBS. RESULTS AND CONCLUSION: One-tenth of the beneficiaries met the definition for poor DS. The base model yielded high sensitivity (0.79) and specificity (0.92); positive predictive value=48.3% and negative predictive value=97.8%, c-statistic=0.92 and good model calibration. Adjusted poor claims-based DS was associated with an increased hazard of death (HR=3.53, 95% CI 3.18, 3.92). The ability to assess DS should improve covariate control and reduce indication bias in observational studies of cancer treatment and outcomes based on insurance claims.",
      "authors": "Davidoff Amy J; Zuckerman Ilene H; Pandya Naimish; Hendrick Franklin; Ke Xuehua; Hurria Arti; Lichtman Stuart M; Hussain Arif; Weiner Jonathan P; Edelman Martin J",
      "year": "2013",
      "journal": "Journal of geriatric oncology",
      "doi": "10.1016/j.jgo.2012.12.005",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23795223/",
      "mesh_terms": "Aged; Aged, 80 and over; Algorithms; Disability Evaluation; Female; Health Status; Health Surveys; Humans; Insurance Claim Review; Male; Medicare; Multivariate Analysis; Neoplasms; Predictive Value of Tests; Proportional Hazards Models; Sensitivity and Specificity; United States",
      "keywords": "",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC3685201"
    },
    {
      "pmid": "40125370",
      "title": "A Patient-Centered Forensic Nursing Model of Care for Victims of Law Enforcement Violence.",
      "abstract": "BACKGROUND: The manuscript examines the nature, manifestations, and potential causes of law enforcement violence as well the need for a model of care for victims. Specifically, it explores development of a preliminary forensic nursing model of care. The questions posed over the course of development of the model follow (1) What are the challenges to developing a rudimentary forensic nursing model of care for victims of law enforcement violence? (2) What are the tenets to be utilized in developing the model? (3) What additional recommendations are to be considered in refining and expanding the model? KEY CONCEPT: A review of the literature in forensic nursing found a gap in care for victims of law enforcement violence. To address the gap given the lack of research, a preliminary model of care was developed based on key constructs from the following established models: (1) Theory of Abolition, (2) Critical Race Theory, (3) Levels of Racism, (4) Intersectionality, (5) Social Determinants of Health, (6) Emancipatory Praxis - Theory of Forensic Nursing, (7) Trauma-Informed Model of Care, and (8) Patient-Centered Model of Care. IMPLICATIONS FOR PRACTICE: The preliminary model developed adheres to the International Council of Nurses guidelines, which emphasize the nurse's duty to care without judgment or bias. Protocols established must be followed precisely to mitigate potential conflicts of interest in care of the victim. A practical application algorithm was developed based on care provided to other victims of violence. CONCLUSION: The model developed was focused on forensic nursing care. There is a need for further refinement involving an interdisciplinary approach. There is also a need for additional research as it relates to forensic nursing's role in caring for victims of law enforcement violence.",
      "authors": "Anderson Maija; Callari-Robinson Jacqueline; Glembocki Margaret; Louden Elizabeth",
      "year": "2024",
      "journal": "Health equity",
      "doi": "10.1089/heq.2023.0270",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40125370/",
      "mesh_terms": "",
      "keywords": "emancipatory nursing praxis; forensic nursing; forensic nursing model of care; intersectionality; law enforcement violence; levels of racism; nursing; patient-centered model of care; police brutality; social determinants of health; trauma-informed care; victims",
      "pub_types": "Journal Article",
      "pmcid": "PMC11464873"
    },
    {
      "pmid": "38273776",
      "title": "Placental Abruption and Cardiovascular Event Risk (PACER): Design, data linkage, and preliminary findings.",
      "abstract": "BACKGROUND: Obstetrical complications impact the health of mothers and offspring along the life course, resulting in an increased burden of chronic diseases. One specific complication is abruption, a life-threatening condition with consequences for cardiovascular health that remains poorly studied. OBJECTIVES: To describe the design and data linkage algorithms for the Placental Abruption and Cardiovascular Event Risk (PACER) cohort. POPULATION: All subjects who delivered in New Jersey, USA, between 1993 and 2020. DESIGN: Retrospective, population-based, birth cohort study. METHODS: We linked the vital records data of foetal deaths and live births to delivery and all subsequent hospitalisations along the life course for birthing persons and newborns. The linkage was based on a probabilistic record-matching algorithm. PRELIMINARY RESULTS: Over the 28\u2009years of follow-up, we identified 1,877,824 birthing persons with 3,093,241 deliveries (1.1%, n =\u200933,058 abruption prevalence). The linkage rates for live births-hospitalisations and foetal deaths-hospitalisations were 92.4% (n =\u20092,842,012) and 70.7% (n =\u200913,796), respectively, for the maternal cohort. The corresponding linkage rate for the live births-hospitalisations for the offspring cohort was 70.3% (n =\u20092,160,736). The median (interquartile range) follow-up for the maternal and offspring cohorts was 15.4 (8.1, 22.4) and 14.4 (7.4, 21.0) years, respectively. We will undertake multiple imputations for missing data and develop inverse probability weights to account for selection bias owing to unlinked records. CONCLUSIONS: Pregnancy offers a unique window to study chronic diseases along the life course and efforts to identify the aetiology of abruption may provide important insights into the causes of future CVD. This project presents an unprecedented opportunity to understand how abruption may predispose women and their offspring to develop CVD complications and chronic conditions later in life.",
      "authors": "Ananth Cande V; Lee Rachel; Valeri Linda; Ross Zev; Graham Hillary L; Khan Shama P; Cabrera Javier; Rosen Todd; Kostis William J",
      "year": "2024",
      "journal": "Paediatric and perinatal epidemiology",
      "doi": "10.1111/ppe.13039",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38273776/",
      "mesh_terms": "Pregnancy; Female; Infant, Newborn; Humans; Abruptio Placentae; Cohort Studies; Retrospective Studies; Placenta; Risk Factors; Pregnancy Complications, Cardiovascular; Fetal Death; Chronic Disease",
      "keywords": "cardiovascular disease; heart disease; hospitalisation; life course; linkage; mortality; placental abruption; preterm delivery; recurrence; sib\u2010pair analysis; stroke",
      "pub_types": "Journal Article",
      "pmcid": "PMC10978269"
    },
    {
      "pmid": "28369691",
      "title": "Adapting the Vulnerable Elders Survey-13 to Predict Mortality Using Responses to the Medicare Health Outcomes Survey.",
      "abstract": "OBJECTIVES: To use items from the Medicare Health Outcomes Survey (HOS) to adapt or validate a simple method for identifying community-dwelling older adults at greater risk of death and to extend the method to identify a very high-risk group. DESIGN: Analysis of longitudinal data. SETTING: National sample of beneficiaries from Medicare Advantage plans with 500 or more enrollees. PARTICIPANTS: Medicare beneficiaries aged 65 and older responding to 2009 baseline and 2011 follow-up HOS (N\u00a0=\u00a0238,687). MEASUREMENTS: Bivariate and multivariate analyses of the HOS; adaptation and validation of a previously validated Vulnerable Elders Survey-13 (VES-13) scoring system that uses age and self-reported function to predict mortality. RESULTS: A modified predictive model, that uses substitutes for several items in the previously validated VES-13, predicted 2-year mortality; 10.6% of those scoring 3 or more, and 2.4% of those scoring less than 3 died within 2\u00a0years (relative risk of death 4.4, similar to 4.2 for the original VES-13 sample), and 15.5% of those scoring 7 or more died within 2\u00a0years (relative risk of death (relative to scores <3) of 6.5). Sixteen percent of HOS beneficiaries were missing some data; 2-year mortality for those with missing items was 9.5%, versus 7.1% for those with no missing items (P\u00a0<\u00a0.001). Imputation of median values for missing VES-13 items results in valid predictions of mortality for those with partially missing data. CONCLUSION: The VES-13 algorithm is robust to substitution of functional items and can be used to identify very high-risk older adults. Multiple imputation of missing items reduces loss-to-follow-up bias and increases sample size.",
      "authors": "Beckett Megan K; Elliott Marc N; Ritenour Douglas; Giordano Laura A; Grace Susan C; Malinoff Rochelle; Saliba Debra",
      "year": "2017",
      "journal": "Journal of the American Geriatrics Society",
      "doi": "10.1111/jgs.14734",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28369691/",
      "mesh_terms": "Aged; Frail Elderly; Health Surveys; Humans; Independent Living; Longitudinal Studies; Medicare; Mortality; Self Report; United States; Vulnerable Populations",
      "keywords": "Vulnerable Elders Survey; frail; mortality; risk; screening tool",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "17904038",
      "title": "Validity of a retrospective National Institutes of Health Stroke Scale scoring methodology in patients with severe stroke.",
      "abstract": "OBJECTIVE: Quantifying stroke severity is essential for interpreting outcomes in stroke studies; severity impacts outcomes. Because outcome studies often enroll patients some time after stroke and there is little standardization of the history and physical examination, objective measurement of stroke severity is limited. A method for retrospectively scoring the National Institutes of Health Stroke Scale (NIHSS) based on history and physical examination has been proposed, but has yet to be validated in patients with higher NIHSS score. We evaluate the validity of this scoring method across the spectrum of the NIHSS scores. METHODS: The retrospective scoring algorithm was applied to history and physical examinations documented for 58 patients with ischemic stroke presenting to any of 17 regional acute care facilities who had a NIHSS score recorded by a stroke team physician. The retrospective NIHSS score was obtained by standardized chart review. Linear regression was used to estimate scale-dependent and scale-independent bias. Limits of agreement quantify deviation of the retrospective NIHSS score from the prospective NIHSS score. RESULTS: Mean (SD) age at stroke was 66 (14) years; 27 (46.6%) patients were men, and 38 (65.5%) were white. The mean (SD) prospective NIHSS score was 13.6 (7.8); the mean (SD) retrospective NIHSS score was 13.7 (7.8). There were 23 (40%) prospective NIHSS scores above 15, and 13 scores (22%) above 20. The linear regression constant was 0.290 (95% confidence interval -0.107, 0.687); the slope was 0.987 (95% confidence interval 0.962, 1.013). The R(2) for the model was 0.991. Limits of agreement were -1.35 and 1.59. CONCLUSION: The retrospective NIHSS appears valid across the entire spectrum of scores.",
      "authors": "Lindsell Christopher J; Alwell Kathleen; Moomaw Charles J; Kleindorfer Dawn O; Woo Daniel; Flaherty Matthew L; Air Ellen L; Schneider Alexander T; Ewing Irene; Broderick Joseph P; Tsevat Joel; Kissela Brett M",
      "year": "2005",
      "journal": "Journal of stroke and cerebrovascular diseases : the official journal of National Stroke Association",
      "doi": "10.1016/j.jstrokecerebrovasdis.2005.08.004",
      "url": "https://pubmed.ncbi.nlm.nih.gov/17904038/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "35032694",
      "title": "Elevated Basal Serum Tryptase: Disease Distribution and Variability in a Regional Health System.",
      "abstract": "BACKGROUND: Hereditary-alpha tryptasemia (H\u03b1T) is the most common etiology for elevated basal serum tryptase (BST). However, the utility of tryptase genotyping of individuals with elevated BST in general clinical practice remains undefined. Moreover, studies showing associations between elevated BST and chronic kidney disease (CKD), myelodysplastic syndrome (MDS), rheumatoid arthritis, or eosinophilic esophagitis did not include tryptase genotyping. OBJECTIVE: To determine the utility of tryptase genotyping among individuals with moderate elevations in BST at a regional health system. METHODS: Clinical and laboratory data from 109 subjects with basal tryptase values of 7.5 ng/mL or greater who were tested for H\u03b1T or had a disorder previously linked to elevated BST were collected retrospectively by chart review. RESULTS: Fifty-eight subjects had elevated BST defined as 11.5 ng/mL or greater. H\u03b1T was found in 63.8% (n\u00a0= 37), 12.1% (n\u00a0= 7) had CKD, and 20.7% (n\u00a0= 12) had clonal myeloid disorders. A total of 6.9% (n\u00a0= 4) with elevated BST had negative testing for H\u03b1T, CKD, and myeloid neoplasms. Two subjects with CKD, 1 subject with MDS, and 1 with myeloid hypereosinophilic syndrome had negative testing for H\u03b1T. Among subjects with elevated BST and more than 1 tryptase measurement, 41.5% (n\u00a0= 22) had BST variability that exceeded the 20% plus 2 formula. Increased BST variability was found in subjects with H\u03b1T, all forms of mastocytosis, CKD, MDS, and those with no associated diagnosis. CONCLUSIONS: H\u03b1T, CKD, and clonal myeloid disorders or a combination of the 3 constitute approximately 90% of individuals with elevated BST in clinical practice. Myeloid neoplasms were over-represented in this cohort relative to population prevalence data suggesting tryptase measurement selection bias by clinicians or higher prevalence. Elevated BST is associated with increased tryptase variability, regardless of etiology.",
      "authors": "Waters Aubri M; Park Hyun J; Weskamp Andrew L; Mateja Allyson; Kachur Megan E; Lyons Jonathan J; Rosen Benjamin J; Boggs Nathan A",
      "year": "2022",
      "journal": "The journal of allergy and clinical immunology. In practice",
      "doi": "10.1016/j.jaip.2021.12.031",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35032694/",
      "mesh_terms": "Humans; Mast Cells; Mastocytosis; Myelodysplastic Syndromes; Renal Insufficiency, Chronic; Retrospective Studies; Tryptases",
      "keywords": "Biomarkers; Chronic kidney disease; Disease distribution; Elevated basal tryptase algorithm; Hereditary-alpha tryptasemia; Mastocytosis; Myeloid neoplasms; Tryptase; Variability",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC9273808"
    },
    {
      "pmid": "35539568",
      "title": "Chemometric modeling of larvicidal activity of plant derived compounds against zika virus vector Aedes aegypti: application of ETA indices.",
      "abstract": "Dengue, zika and chikungunya have severe public health concerns in several countries. Human modification of the natural environment continues to create habitats in which mosquitoes, vectors of a wide variety of human and animal pathogens, thrive, which can bring about an enormous negative impact on public health if not controlled properly. Quantitative structure-activity relationship (QSAR) modeling has been applied in this work with the aim of exploring features contributing to promising larvicidal properties against the vector Aedes aegypti (Diptera: Culicidae). A dataset of 61 plant derived compounds reported in previous literature was used in this present study. A genetic algorithm (GA) was used for QSAR model development employing the \"Double Cross Validation\" (DCV) tool available at http://teqip.jdvu.ac.in/QSAR_Tools/. The DCV tool removes any bias in descriptor selection from a fixed composition of a training set and often provides an optimum solution in terms of predictivity. Simple topological descriptors, the \"Extended Topochemical Atom\" (ETA) indices developed by the present authors' group, were used for model development. These descriptors do not require pretreatment of molecular structures by conformational analysis or energy minimization before model development, thus saving computational time and resources. They also avoid ambiguities with respect to the existence of compounds in various conformational states leading to the loss of predictive capability in QSAR models. A number of models were generated from GA, and further, the descriptors appearing in the best model obtained from GA were subjected to partial least squares (PLS) regression to obtain the final robust model. The developed model was validated extensively using different validation metrics to check the reliability and predictivity of the model for enhancing confidence in QSAR predictions. Based on the insights obtained from the PLS model, we can conclude that the presence of hydrogen bond acceptor atoms, the presence of multiple bonds as well as sufficient lipophilicity and a limited polar surface area play crucial roles in regulating the activity of the compounds.",
      "authors": "De Priyanka; Aher Rahul B; Roy Kunal",
      "year": "2018",
      "journal": "RSC advances",
      "doi": "10.1039/c7ra13159c",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35539568/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC9077860"
    },
    {
      "pmid": "36076307",
      "title": "Validating and automating learning of cardiometabolic polygenic risk scores from direct-to-consumer genetic and phenotypic data: implications for scaling precision health research.",
      "abstract": "INTRODUCTION: A major challenge to enabling precision health at a global scale is the bias between those who enroll in state sponsored genomic research and those suffering from chronic disease. More than 30 million people have been genotyped by direct-to-consumer (DTC) companies such as 23andMe, Ancestry DNA, and MyHeritage, providing a potential mechanism for democratizing access to medical interventions and thus catalyzing improvements in patient outcomes as the cost of data acquisition drops. However, much of these data are sequestered in the initial provider network, without the ability for the scientific community to either access or validate. Here, we present a novel geno-pheno platform that integrates heterogeneous data sources and applies learnings to common chronic disease conditions including Type 2 diabetes (T2D) and hypertension. METHODS: We collected genotyped data from a novel DTC platform where participants upload their genotype data files and were invited to answer general health questionnaires regarding cardiometabolic traits over a period of 6\u00a0months. Quality control, imputation, and genome-wide association studies were performed on this dataset, and polygenic risk scores were built in a case-control setting using the BASIL algorithm. RESULTS: We collected data on N\u2009=\u20094,550 (389 cases / 4,161 controls) who reported being affected or previously affected for T2D and N\u2009=\u20094,528 (1,027 cases / 3,501 controls) for hypertension. We identified 164 out of 272 variants showing identical effect direction to previously reported genome-significant findings in Europeans. Performance metric of the PRS models was AUC\u2009=\u20090.68, which is comparable to previously published PRS models obtained with larger datasets including clinical biomarkers. DISCUSSION: DTC platforms have the potential of inverting research models of genome sequencing and phenotypic data acquisition. Quality control (QC) mechanisms proved to successfully enable traditional GWAS and PRS analyses. The direct participation of individuals has shown the potential to generate rich datasets enabling the creation of PRS cardiometabolic models. More importantly, federated learning of PRS from reuse of DTC data provides a mechanism for scaling precision health care delivery beyond the small number of countries who can afford to finance these efforts directly. CONCLUSIONS: The genetics of T2D and hypertension have been studied extensively in controlled datasets, and various polygenic risk scores (PRS) have been developed. We developed predictive tools for both phenotypes trained with heterogeneous genotypic and phenotypic data generated outside of the clinical environment and show that our methods can recapitulate prior findings with fidelity. From these observations, we conclude that it is possible to leverage DTC genetic repositories to identify individuals at risk of debilitating diseases based on their unique genetic landscape so that informed, timely clinical interventions can be incorporated.",
      "authors": "Lopez-Pineda Arturo; Vernekar Manvi; Moreno-Grau Sonia; Rojas-Mu\u00f1oz Agustin; Moatamed Babak; Lee Ming Ta Michael; Nava-Aguilar Marco A; Gonzalez-Arroyo Gilberto; Numakura Kensuke; Matsuda Yuta; Ioannidis Alexander; Katsanis Nicholas; Takano Tomohiro; Bustamante Carlos D",
      "year": "2022",
      "journal": "Human genomics",
      "doi": "10.1186/s40246-022-00406-y",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36076307/",
      "mesh_terms": "Cardiovascular Diseases; Diabetes Mellitus, Type 2; Genetic Predisposition to Disease; Genome-Wide Association Study; Humans; Hypertension; Multifactorial Inheritance; Phenotype; Precision Medicine; Risk Factors",
      "keywords": "Ancestry; Genome-wide association study; Hypertension; Polygenic risk score; Type 2 diabetes mellitus",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC9452874"
    },
    {
      "pmid": "38942593",
      "title": "Large language model-driven sentiment analysis for facilitating fibromyalgia diagnosis.",
      "abstract": "BACKGROUND: Fibromyalgia (FM) is a complex disorder with widespread pain and emotional distress, posing diagnostic challenges. FM patients show altered cognitive and emotional processing, with a preferential allocation of attention to pain-related information. This attentional bias towards pain cues can impair cognitive functions such as inhibitory control, affecting patients' ability to manage and express emotions. Sentiment analysis using large language models (LLMs) can provide insights by detecting nuances in pain expression. This study investigated whether open-source LLM-driven sentiment analysis could aid FM diagnosis. METHODS: 40 patients with FM, according to the 2016 American College of Rheumatology Criteria and 40 non-FM chronic pain controls referred to rheumatology clinics, were enrolled. Transcribed responses to questions on pain and sleep were machine translated to English and analysed by the LLM Mistral-7B-Instruct-v0.2 using prompt engineering targeting FM-associated language nuances for pain expression ('prompt-engineered') or an approach without this targeting ('ablated'). Accuracy, precision, recall, specificity and area under the receiver operating characteristic curve (AUROC) were calculated using rheumatologist diagnosis as ground truth. RESULTS: The prompt-engineered approach demonstrated accuracy of 0.87, precision of 0.92, recall of 0.84, specificity of 0.82 and AUROC of 0.86 for distinguishing FM. In comparison, the ablated approach had an accuracy of 0.76, precision of 0.75, recall of 0.77, specificity of 0.75 and AUROC of 0.76. The accuracy was superior to the ablated approach (McNemar's test p<0.001). CONCLUSION: This proof-of-concept study suggests LLM-driven sentiment analysis, especially with prompt engineering, may facilitate FM diagnosis by detecting subtle differences in pain expression. Further validation is warranted, particularly the inclusion of secondary FM patients.",
      "authors": "Venerito Vincenzo; Iannone Florenzo",
      "year": "2024",
      "journal": "RMD open",
      "doi": "10.1136/rmdopen-2024-004367",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38942593/",
      "mesh_terms": "Humans; Fibromyalgia; Female; Middle Aged; Male; Adult; ROC Curve; Natural Language Processing; Language; Emotions; Aged; Chronic Pain",
      "keywords": "Fibromyalgia; Machine Learning; Outcome Assessment, Health Care",
      "pub_types": "Journal Article",
      "pmcid": "PMC11227845"
    },
    {
      "pmid": "39484070",
      "title": "Prediction of COVID-19 in-hospital mortality in older patients using artificial intelligence: a multicenter study.",
      "abstract": "BACKGROUND: Once the pandemic ended, SARS-CoV-2 became endemic, with flare-up phases. COVID-19 disease can still have a significant clinical impact, especially in older patients with multimorbidity and frailty. OBJECTIVE: This study aims at evaluating the main characteristics associated to in-hospital mortality among data routinely collected upon admission to identify older patients at higher risk of death. METHODS: The present study used data from Gerocovid-acute wards, an observational multicenter retrospective-prospective study conducted in geriatric and internal medicine wards in subjects \u226560\u00a0years old during the COVID-19 pandemic. Seventy-one routinely collected variables, including demographic data, living arrangements, smoking habits, pre-COVID-19 mobility, chronic diseases, and clinical and laboratory parameters were integrated into a web-based machine learning platform (Just Add Data Bio) to identify factors with the highest prognostic relevance. The use of artificial intelligence allowed us to avoid variable selection bias, to test a large number of models and to perform an internal validation. RESULTS: The dataset was split into training and test sets, based on a 70:30 ratio and matching on age, sex, and proportion of events; 3,520 models were set out to train. The three predictive algorithms (optimized for performance, interpretability, or aggressive feature selection) converged on the same model, including 12 variables: pre-COVID-19 mobility, World Health Organization disease severity, age, heart rate, arterial blood gases bicarbonate and oxygen saturation, serum potassium, systolic blood pressure, blood glucose, aspartate aminotransferase, PaO2/FiO2 ratio and derived neutrophil-to-lymphocyte ratio. CONCLUSION: Beyond variables reflecting the severity of COVID-19 disease failure, pre-morbid mobility level was the strongest factor associated with in-hospital mortality reflecting the importance of functional status as a synthetic measure of health in older adults, while the association between derived neutrophil-to-lymphocyte ratio and mortality, confirms the fundamental role played by neutrophils in SARS-CoV-2 disease.",
      "authors": "Fedecostante Massimiliano; Sabbatinelli Jacopo; Dell'Aquila Giuseppina; Salvi Fabio; Bonfigli Anna Rita; Volpato Stefano; Trevisan Caterina; Fumagalli Stefano; Monzani Fabio; Antonelli Incalzi Raffaele; Olivieri Fabiola; Cherubini Antonio",
      "year": "2024",
      "journal": "Frontiers in aging",
      "doi": "10.3389/fragi.2024.1473632",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39484070/",
      "mesh_terms": "",
      "keywords": "COVID-19; artificial intelligence; in-hospital mortality; mobility; neutrophil-to-limphocyte ratio",
      "pub_types": "Journal Article",
      "pmcid": "PMC11525005"
    },
    {
      "pmid": "37245005",
      "title": "Cluster analysis of angiotensin biomarkers to identify antihypertensive drug treatment in population studies.",
      "abstract": "BACKGROUND: The recent progress in molecular biology generates an increasing interest in investigating molecular biomarkers as markers of response to treatments. The present work is motivated by a study, where the objective was to explore the potential of the molecular biomarkers of renin-angiotensin-aldosterone system (RAAS) to identify the undertaken antihypertensive treatments in the general population. Population-based studies offer an opportunity to assess the effectiveness of treatments in real-world scenarios. However, lack of quality documentation, especially when electronic health record linkage is unavailable, leads to inaccurate reporting and classification bias. METHOD: We present a machine learning clustering technique to determine the potential of measured RAAS biomarkers for the identification of undertaken treatments in the general population. The biomarkers were simultaneously determined through a novel mass-spectrometry analysis in 800 participants of the Cooperative Health Research In South Tyrol (CHRIS) study with documented antihypertensive treatments. We assessed the agreement, sensitivity and specificity of the resulting clusters against known treatment types. Through the lasso penalized regression, we identified clinical characteristics associated with the biomarkers, accounting for the effects of cluster and treatment classifications. RESULTS: We identified three well-separated clusters: cluster 1 (n\u2009=\u2009444) preferentially including individuals not receiving RAAS-targeting drugs; cluster 2 (n\u2009=\u2009235) identifying angiotensin type 1 receptor blockers (ARB) users (weighted kappa \u03baw\u2009=\u200974%; sensitivity\u2009=\u200973%; specificity\u2009=\u200983%); and cluster 3 (n\u2009=\u2009121) well discriminating angiotensin-converting enzyme inhibitors (ACEi) users (\u03baw\u2009=\u200981%; sensitivity\u2009=\u200955%; specificity\u2009=\u200990%). Individuals in clusters 2 and 3 had higher frequency of diabetes as well as higher fasting glucose and BMI levels. Age, sex and kidney function were strong predictors of the RAAS biomarkers independently of the cluster structure. CONCLUSIONS: Unsupervised clustering of angiotensin-based biomarkers is a viable technique to identify individuals on specific antihypertensive treatments, pointing to a potential application of the biomarkers as useful clinical diagnostic tools even outside of a controlled clinical setting.",
      "authors": "Arisido Maeregu Woldeyes; Foco Luisa; Shoemaker Robin; Melotti Roberto; Delles Christian; G\u00f6gele Martin; Barolo Stefano; Baron Stephanie; Azizi Michel; Dominiczak Anna F; Zennaro Maria-Christina; P Pramstaller Peter; Poglitsch Marko; Pattaro Cristian",
      "year": "2023",
      "journal": "BMC medical research methodology",
      "doi": "10.1186/s12874-023-01930-8",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37245005/",
      "mesh_terms": "Humans; Antihypertensive Agents; Angiotensins; Angiotensin-Converting Enzyme Inhibitors; Angiotensin Receptor Antagonists; Cluster Analysis; Biomarkers",
      "keywords": "Aldosterone; Angiotensin; Antihypertensive drugs; Cluster analysis; Lasso regression; \u00a0CHRIS study",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10224304"
    },
    {
      "pmid": "37329981",
      "title": "Predictors of Human Milk Feeding and Direct Breastfeeding for Infants with Single Ventricle Congenital Heart Disease: Machine Learning Analysis of the National Pediatric Cardiology Quality Improvement Collaborative Registry.",
      "abstract": "OBJECTIVE: To identify factors that support or limit human milk (HM) feeding and direct breastfeeding (BF) for infants with single ventricle congenital heart disease at neonatal stage 1 palliation (S1P) discharge and at stage 2 palliation (S2P) (\u223c4-6\u00a0months old). STUDY DESIGN: Analysis of the National Pediatric Cardiology Quality Improvement Collaborative (NPC-QIC) registry (2016-2021; 67 sites). Primary outcomes were any HM, exclusive HM, and any direct BF at S1P discharge and at S2P. The main analysis involved multiple phases of elastic net logistic regression on imputed data to identify important predictors. RESULTS: For 1944 infants, the strongest predictor domain areas included preoperative feeding, demographics/social determinants of health, feeding route, clinical course, and site. Significant findings included: preoperative BF was associated with any HM at S1P discharge (OR\u00a0=\u00a02.02, 95% CI\u00a0=\u00a01.74-3.44) and any BF at S2P (OR = 2.29, 95% CI = 1.38-3.80); private/self-insurance was associated with any HM at S1P discharge (OR = 1.91, 95% CI = 1.58-2.47); and Black/African-American infants had lower odds of any HM at S1P discharge (OR = 0.54, 95% CI = 0.38-0.65) and at S2P (0.57, 0.30-0.86). Adjusted odds of HM/BF practices varied among NPC-QIC sites. CONCLUSIONS: Preoperative feeding practices predict later HM and BF for infants with single ventricle congenital heart disease; therefore, family-centered interventions focused on HM/BF during the S1P preoperative time are needed. These interventions should include evidence-based strategies to address implicit bias and seek to minimize disparities related to social determinants of health. Future research is needed to identify supportive practices common to high-performing NPC-QIC sites.",
      "authors": "Elgersma Kristin M; Wolfson Julian; Fulkerson Jayne A; Georgieff Michael K; Looman Wendy S; Spatz Diane L; Shah Kavisha M; Uzark Karen; McKechnie Anne Chevalier",
      "year": "2023",
      "journal": "The Journal of pediatrics",
      "doi": "10.1016/j.jpeds.2023.113562",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37329981/",
      "mesh_terms": "Infant, Newborn; Child; Female; Infant; Humans; Breast Feeding; Milk, Human; Quality Improvement; Heart Defects, Congenital; Univentricular Heart; Registries; Cardiology",
      "keywords": "breast feeding; congenital; heart defects; human; hypoplastic left heart syndrome; milk; nutrition",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10527750"
    },
    {
      "pmid": "38876484",
      "title": "Large Language Models Versus Expert Clinicians in Crisis Prediction Among Telemental Health Patients: Comparative Study.",
      "abstract": "BACKGROUND: Due to recent advances in artificial intelligence, large language models (LLMs) have emerged as a powerful tool for a variety of language-related tasks, including sentiment analysis, and summarization of provider-patient interactions. However, there is limited research on these models in the area of crisis prediction. OBJECTIVE: This study aimed to evaluate the performance of LLMs, specifically OpenAI's generative pretrained transformer 4 (GPT-4), in predicting current and future mental health crisis episodes using patient-provided information at intake among users of a national telemental health platform. METHODS: Deidentified patient-provided data were pulled from specific intake questions of the Brightside telehealth platform, including the chief complaint, for 140 patients who indicated suicidal ideation (SI), and another 120 patients who later indicated SI with a plan during the course of treatment. Similar data were pulled for 200 randomly selected patients, treated during the same time period, who never endorsed SI. In total, 6 senior Brightside clinicians (3 psychologists and 3 psychiatrists) were shown patients' self-reported chief complaint and self-reported suicide attempt history but were blinded to the future course of treatment and other reported symptoms, including SI. They were asked a simple yes or no question regarding their prediction of endorsement of SI with plan, along with their confidence level about the prediction. GPT-4 was provided with similar information and asked to answer the same questions, enabling us to directly compare the performance of artificial intelligence and clinicians. RESULTS: Overall, the clinicians' average precision (0.7) was higher than that of GPT-4 (0.6) in identifying the SI with plan at intake (n=140) versus no SI (n=200) when using the chief complaint alone, while sensitivity was higher for the GPT-4 (0.62) than the clinicians' average (0.53). The addition of suicide attempt history increased the clinicians' average sensitivity (0.59) and precision (0.77) while increasing the GPT-4 sensitivity (0.59) but decreasing the GPT-4 precision (0.54). Performance decreased comparatively when predicting future SI with plan (n=120) versus no SI (n=200) with a chief complaint only for the clinicians (average sensitivity=0.4; average precision=0.59) and the GPT-4 (sensitivity=0.46; precision=0.48). The addition of suicide attempt history increased performance comparatively for the clinicians (average sensitivity=0.46; average precision=0.69) and the GPT-4 (sensitivity=0.74; precision=0.48). CONCLUSIONS: GPT-4, with a simple prompt design, produced results on some metrics that approached those of a trained clinician. Additional work must be done before such a model can be piloted in a clinical setting. The model should undergo safety checks for bias, given evidence that LLMs can perpetuate the biases of the underlying data on which they are trained. We believe that LLMs hold promise for augmenting the identification of higher-risk patients at intake and potentially delivering more timely care to patients.",
      "authors": "Lee Christine; Mohebbi Matthew; O'Callaghan Erin; Winsberg Mir\u00e8ne",
      "year": "2024",
      "journal": "JMIR mental health",
      "doi": "10.2196/58129",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38876484/",
      "mesh_terms": "Humans; Telemedicine; Suicidal Ideation; Male; Female; Adult; Middle Aged; Artificial Intelligence; Suicide, Attempted; Mental Health Teletherapy",
      "keywords": "AI; GPT-4; LLM; OpenAI; PHQ-9; Patient Health Questionnaire-9; artificial intelligence; clinical setting; clinician; clinicians; crisis; digital health; digital mental health; e-health; generative pretrained transformer 4; language model; large language model; machine learning; medication; mental disorder; mental health; patient information; psychiatrist; psychiatrists; psychiatry; psychologist; psychologists; self-reported; suicidal; suicidal ideation; suicide; suicide attempt; tele health; tele-mental health; telehealth; telemental health; treatment",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": "PMC11329850"
    },
    {
      "pmid": "32734165",
      "title": "Estimating real-world performance of a predictive model: a case-study in predicting mortality.",
      "abstract": "OBJECTIVE: One primary consideration when developing predictive models is downstream effects on future model performance. We conduct experiments to quantify the effects of experimental design choices, namely cohort selection and internal validation methods, on (estimated) real-world model performance. MATERIALS AND METHODS: Four years of hospitalizations are used to develop a 1-year mortality prediction model (composite of death or initiation of hospice care). Two common methods to select appropriate patient visits from their encounter history (backwards-from-outcome and forwards-from-admission) are combined with 2 testing cohorts (random and temporal validation). Two models are trained under otherwise identical conditions, and their performances compared. Operating thresholds are selected in each test set and applied to a \"real-world\" cohort of labeled admissions from another, unused year. RESULTS: Backwards-from-outcome cohort selection retains 25% of candidate admissions (n\u2009=\u200923\u00a0579), whereas forwards-from-admission selection includes many more (n\u2009=\u200992\u00a0148). Both selection methods produce similar performances when applied to a random test set. However, when applied to the temporally defined \"real-world\" set, forwards-from-admission yields higher areas under the ROC and precision recall curves (88.3% and 56.5% vs. 83.2% and 41.6%). DISCUSSION: A backwards-from-outcome experiment manipulates raw training data, simplifying the experiment. This manipulated data no longer resembles real-world data, resulting in optimistic estimates of test set performance, especially at high precision. In contrast, a forwards-from-admission experiment with a temporally separated test set consistently and conservatively estimates real-world performance. CONCLUSION: Experimental design choices impose bias upon selected cohorts. A forwards-from-admission experiment, validated temporally, can conservatively estimate real-world performance. LAY SUMMARY: The routine care of patients stands to benefit greatly from assistive technologies, including data-driven risk assessment. Already, many different machine learning and artificial intelligence applications are being developed from complex electronic health record data. To overcome challenges that arise from such data, researchers often start with simple experimental approaches to test their work. One key component is how patients (and their healthcare visits) are selected for the study from the pool of all patients seen. Another is how the group of patients used to create the risk estimator differs from the group used to evaluate how well it works. These choices complicate how the experimental setting compares to the real-world application to patients. For example, different selection approaches that depend on each patient's future outcome can simplify the experiment but are impractical upon implementation as these data are unavailable. We show that this kind of \"backwards\" experiment optimistically estimates how well the model performs. Instead, our results advocate for experiments that select patients in a \"forwards\" manner and \"temporal\" validation that approximates training on past data and implementing on future data. More robust results help gauge the clinical utility of recent works and aid decision-making before implementation into practice.",
      "authors": "Major Vincent J; Jethani Neil; Aphinyanaphongs Yindalon",
      "year": "2020",
      "journal": "JAMIA open",
      "doi": "10.1093/jamiaopen/ooaa008",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32734165/",
      "mesh_terms": "",
      "keywords": "data science; experimental design; machine learning; mortality; reproducibility of results",
      "pub_types": "Journal Article",
      "pmcid": "PMC7382635"
    },
    {
      "pmid": "6725529",
      "title": "Intensified rates of venous sampling unmask the presence of spontaneous, high-frequency pulsations of luteinizing hormone in man.",
      "abstract": "To test the validity of venous sampling rates that are generally used to characterize pulsatile LH release in man (e.g. sampling every 15-20 min), we characterized apparent LH pulse frequency in blood withdrawn variously at 20- or 4-min intervals in 19 men, at 2-min intervals in 14 men, and at 1-min intervals in 6 men. In an effort to minimize detection bias, significant LH pulses were evaluated objectively using a computerized pulse-detection algorithm, which tended to maximize recognition of true-positive LH pulses, and minimize false-positive and false-negative pulses. Under these conditions, intensified rates of venous sampling at 4-, 2-, and 1-min intervals exposed approximately 3.6, 4.9, and 13.7-fold more LH pulses, respectively, than could be discerned at a 20-min sampling frequency. In addition, more rapid rates of venous sampling disclosed a previously unobserved pattern of LH pulses, in which higher frequency, lower amplitude LH pulsations were interposed among low frequency, high amplitude LH peaks. Quantitatively, LH pulses unmasked by intensified rates of venous sampling exhibited significantly lower pulse amplitudes, expressed either as a fractional (%) or absolute (mIU/ml) increment, than pulses identified at 20-min intervals. In conclusion, we demonstrated that intensified rates of venous sampling unmask a significant number of otherwise unrecognized LH pulses in the circulation of normal men. Moreover, because generally employed sampling rates overlooked these more rapid physiological fluctuations in LH concentrations, patterns of both high and low frequency LH pulsations must now be characterized in various states of health and disease using more rapid sampling paradigms.",
      "authors": "Veldhuis J D; Evans W S; Rogol A D; Drake C R; Thorner M O; Merriam G R; Johnson M L",
      "year": "1984",
      "journal": "The Journal of clinical endocrinology and metabolism",
      "doi": "10.1210/jcem-59-1-96",
      "url": "https://pubmed.ncbi.nlm.nih.gov/6725529/",
      "mesh_terms": "Adult; Blood Specimen Collection; Humans; Luteinizing Hormone; Male; Radioimmunoassay; Time Factors; Veins",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, P.H.S.",
      "pmcid": ""
    },
    {
      "pmid": "30507228",
      "title": "Towards personalized, brain-based behavioral intervention for transdiagnostic anxiety: Transient neural responses to negative images predict outcomes following a targeted computer-based intervention.",
      "abstract": "OBJECTIVE: Clinical anxiety is prevalent, highly comorbid with other conditions, and associated with significant medical morbidity, disability, and public health burden. Excessive attentional deployment toward threat is a transdiagnostic dimension of anxiety seen at both initial and sustained stages of threat processing. However, group-level observations of these phenomena mask considerable within-group heterogeneity that has been linked to treatment outcomes, suggesting that a transdiagnostic, individual differences approach may capture critical, clinically relevant information. METHOD: Seventy clinically anxious individuals were randomized to receive 8 sessions of attention bias modification (ABM; n = 41 included in analysis), a computer-based mechanistic intervention that specifically targets initial stages of threat processing, or a sham control (n = 21). Participants completed a mixed block/event-related functional MRI task optimized to discriminate transient from sustained neural responses to threat. RESULTS: Larger transient responses across a wide range of cognitive-affective regions (e.g., ventrolateral prefrontal cortex, anterior cingulate cortex, amygdala) predicted better clinical outcomes following ABM, in both a priori anatomical regions and whole-brain analyses; sustained responses did not. A spatial pattern recognition algorithm using transient threat responses successfully discriminated the top quartile of ABM responders with 68% accuracy. CONCLUSIONS: Neural alterations occurring on the relatively transient timescale that is specifically targeted by ABM predict favorable clinical outcomes. Results inform how to expand on the initial promise of neurocognitive treatments like ABM by fine-tuning their clinical indications (e.g., through personalized mechanistic intervention relevant across diagnoses) and by increasing the range of mechanisms that can be targeted (e.g., through synergistic treatment combinations and/or novel neurocognitive training protocols designed to tackle identified predictors of nonresponse). (PsycINFO Database Record (c) 2018 APA, all rights reserved).",
      "authors": "Price Rebecca B; Cummings Logan; Gilchrist Danielle; Graur Simona; Banihashemi Layla; Kuo Susan S; Siegle Greg J",
      "year": "2018",
      "journal": "Journal of consulting and clinical psychology",
      "doi": "10.1037/ccp0000309",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30507228/",
      "mesh_terms": "Adult; Anxiety Disorders; Attention; Behavior Therapy; Brain; Female; Humans; Individuality; Magnetic Resonance Imaging; Male; Predictive Value of Tests; Therapy, Computer-Assisted; Treatment Outcome",
      "keywords": "",
      "pub_types": "Journal Article; Randomized Controlled Trial",
      "pmcid": "PMC6287282"
    },
    {
      "pmid": "24155771",
      "title": "Diagnostic Accuracy of the Primary Care Screener for Affective Disorder (PC-SAD) in Primary Care.",
      "abstract": "BACKGROUND: Depression goes often unrecognised and untreated in non-psychiatric medical settings. Screening has recently gained acceptance as a first step towards improving depression recognition and management. The Primary Care Screener for Affective Disorders (PC-SAD) is a self-administered questionnaire to screen for Major Depressive Disorder (MDD) and Dysthymic Disorder (Dys) which has a sophisticated scoring algorithm that confers several advantages. This study tested its performance against a 'gold standard' diagnostic interview in primary care. METHODS: A total of 416 adults attending 13 urban general internal medicine primary care practices completed the PC-SAD. Of 409 who returned a valid PC-SAD, all those scoring positive (N=151) and a random sample (N=106) of those scoring negative were selected for a 3-month telephone follow-up assessment including the administration of the Structured Clinical Interview for DSM-IV-TR Axis I Disorders (SCID-I) by a psychiatrist who was masked to PC-SAD results. RESULTS: Most selected patients (N=212) took part in the follow-up assessment. After adjustment for partial verification bias the sensitivity, specificity, positive and negative predictive value for MDD were 90%, 83%, 51%, and 98%. For Dys, the corresponding figures were 78%, 79%, 8%, and 88%. CONCLUSIONS: While some study limitations suggest caution in interpreting our results, this study corroborated the diagnostic validity of the PC-SAD, although the low PPV may limit its usefulness with regard to Dys. Given its good psychometric properties and the short average administration time, the PC-SAD might be the screening instrument of choice in settings where the technology for computer automated scoring is available.",
      "authors": "Picardi Angelo; Adler D A; Rogers W H; Lega I; Zerella M P; Matteucci G; Tarsitani L; Caredda M; Gigantesco A; Biondi M",
      "year": "2013",
      "journal": "Clinical practice and epidemiology in mental health : CP & EMH",
      "doi": "10.2174/1745017901309010164",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24155771/",
      "mesh_terms": "",
      "keywords": "Depression; Diagnosis; Primary care; Public health.",
      "pub_types": "Journal Article",
      "pmcid": "PMC3804886"
    },
    {
      "pmid": "34740876",
      "title": "Evaluation of a contactless neonatal physiological monitor in Nairobi, Kenya.",
      "abstract": "BACKGROUND: Globally, 2.5\u2009million neonates died in 2018, accounting for 46% of under-5 deaths. Multiparameter continuous physiological monitoring (MCPM) of neonates allows for early detection and treatment of life-threatening health problems. However, neonatal monitoring technology is largely unavailable in low-resource settings. METHODS: In four evaluation rounds, we prospectively compared the accuracy of the EarlySense under-mattress device to the Masimo Rad-97 pulse CO-oximeter with capnography reference device for heart rate (HR) and respiratory rate (RR) measurements in neonates in Kenya. EarlySense algorithm optimisations were made between evaluation rounds. In each evaluation round, we compared 200 randomly selected epochs of data using Bland-Altman plots and generated Clarke error grids with zones of 20% to aid in clinical interpretation. RESULTS: Between 9 July 2019 and 8 January 2020, we collected 280 hours of MCPM data from 76 enrolled neonates. At the final evaluation round, the EarlySense MCPM device demonstrated a bias of -0.8 beats/minute for HR and 1.6 breaths/minute for RR, and normalised spread between the 95% upper and lower limits of agreement of 6.2% for HR and 27.3% for RR. Agreement between the two MCPM devices met the a priori-defined threshold of 30%. The Clarke error grids showed that all observations for HR and 197/200 for RR were within a 20% difference. CONCLUSION: Our research indicates that there is acceptable agreement between the EarlySense and Masimo MCPM devices in the context of large within-subject variability; however, further studies establishing cost-effectiveness and clinical effectiveness are needed before large-scale implementation of the EarlySense MCPM device in neonates. TRIAL REGISTRATION NUMBER: NCT03920761.",
      "authors": "Wang Dee; Macharia William M; Ochieng Roseline; Chomba Dorothy; Hadida Yifat S; Karasik Roman; Dunsmuir Dustin; Coleman Jesse; Zhou Guohai; Ginsburg Amy Sarah; Ansermino J Mark",
      "year": "2022",
      "journal": "Archives of disease in childhood",
      "doi": "10.1136/archdischild-2021-322344",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34740876/",
      "mesh_terms": "Heart Rate; Humans; Infant, Newborn; Kenya; Monitoring, Physiologic; Oximetry; Respiratory Rate",
      "keywords": "intensive care units; neonatal; neonatology; technology",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Observational Study",
      "pmcid": "PMC9125375"
    },
    {
      "pmid": "33109650",
      "title": "Linkage of maternity hospital episode statistics birth records to birth registration and notification records for births in England 2005-2006: quality assurance of linkage.",
      "abstract": "OBJECTIVES: The objectives of this study were to describe the methods used to assess the quality of linkage between records of babies' birth registration and hospital birth records, and to evaluate the potential bias that may be introduced because of these methods. DESIGN/SETTING: Data from the civil registration and the notification of births previously linked by the Office for National Statistics (ONS) had been further linked to birth records from the Hospital Episode Statistics (HES) for babies born in England. We developed a deterministic, six-stage algorithm to assess the quality of this linkage. PARTICIPANTS: All 1\u2009170\u2009790 live, singleton births, occurring in National Health Service hospitals in England between 1 January 2005 and 31 December 2006. PRIMARY OUTCOME MEASURE: The primary outcome was the number of successful links between ONS birth records and HES birth records. Rates of successful linkage were calculated for the cohort and the characteristics associated with unsuccessful linkage were identified. RESULTS: Approximately 92% (1 074 572) of the birth registration records were successfully linked with a HES birth record. Data quality and completeness were somewhat poorer in HES birth records compared with linked birth registration and birth notification records. The quality assurance algorithms identified 1456 incorrect linkages (<1%). Compared with the linked dataset, birth records were more likely to be unlinked if babies were of white ethnic origin; born to unmarried mothers; born in East England, London, North West England or the West Midlands; or born in March. CONCLUSIONS: It is possible to link administrative datasets to create large cohorts, allowing researchers to explore important questions about exposures and childhood outcomes. Missing data, coding errors and inconsistencies mean it is important that the quality of linkage is assessed prior to analysis.",
      "authors": "Coathup Victoria; Macfarlane Alison; Quigley Maria",
      "year": "2020",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2020-037885",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33109650/",
      "mesh_terms": "Birth Certificates; Child; England; Female; Hospitals, Maternity; Humans; London; Medical Record Linkage; Pregnancy; State Medicine",
      "keywords": "births; data-linkage; hospital episode statistics; hospital records",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7592278"
    },
    {
      "pmid": "30053683",
      "title": "Occupational factors associated with major depressive disorder: A Brazilian population-based study.",
      "abstract": "BACKGROUND: There have been very few studies exploring the occupational risk factors for major depressive disorder (MDD) in the working populations in Latin America. The aim of this study was to explore the associations between a large set of occupational factors and MDD in the Brazilian working population. METHODS: The study was based on the cross-sectional data from the Brazilian National Health Survey, 2013. 60,202 people were interviewed (response rate: 91.9%). Among them, 36,442 were working, 19,450 men and 16,992 women. MDD was measured using the diagnostic algorithm (DSM-IV criteria) of the PHQ-9. Occupational factors included job characteristics, working time factors, psychosocial work stressors and physico-chemical exposures. Logistic regression models were performed and adjusted for sociodemographic factors. All analyses were conducted using weighted and stratified data by gender. RESULTS: The following occupational factors were associated with a higher risk of MDD: working part time (\u226420\u00a0h a week) and stress at work for both genders, workplace violence, intense physical activity, exposure to noise and chemicals among women, and prolonged exposure to sun among men. Associations of stress and violence at work with MDD were particularly strong. LIMITATIONS: Cross-sectional study design, healthy worker effect and reporting bias may have impacted the results. CONCLUSIONS: This study, one of the first studies among the Brazilian working population, showed that psychosocial work stressors were the strongest risk factors for MDD. Physico-chemical exposures deserve more attention in association with MDD. Prevention policies oriented toward the work environment may help to prevent depression at the workplace.",
      "authors": "Oenning N\u00e1gila Soares Xavier; Ziegelmann Patr\u00edcia Klarmann; Goulart B\u00e1rbara Niegia Garcia de; Niedhammer Isabelle",
      "year": "2018",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2018.07.022",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30053683/",
      "mesh_terms": "Adult; Brazil; Cross-Sectional Studies; Major Depressive Disorder; Employment; Female; Health Surveys; Humans; Logistic Models; Male; Middle Aged; Occupational Diseases; Occupational Stress; Risk Factors; Workplace",
      "keywords": "Depression; Occupational exposures; Work stress; Workers; Working population; Workplace violence",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "37294742",
      "title": "Public interest trends for Covid-19 and alignment with the disease trajectory: A time-series analysis of national-level data.",
      "abstract": "Data from web search engines have become a valuable adjunct in epidemiology and public health, specifically during epidemics. We aimed to explore the concordance of web search popularity for Covid-19 across 6 Western nations (United Kingdom, United States, France, Italy, Spain and Germany) and how timeline changes align with the pandemic waves, Covid-19 mortality, and incident case trajectories. We used the Google Trends tool for web-search popularity, and \"Our World in Data\" on Covid-19 reported cases, deaths, and administrative responses (measured by stringency index) to analyze country-level data. The Google Trends tool provides spatiotemporal data, scaled to a range of <1 (lowest relative popularity) to 100 (highest relative popularity), for the selected search terms, timeframe, and region. We used \"coronavirus\" and \"covid\" as search terms and set the timeframe up to November 12, 2022. We obtained multiple consecutive samples using the same terms to validate against sampling bias. We consolidated national-level incident cases and deaths weekly and transformed them to a range between 0 to 100 through the min-max normalization algorithm. We calculated the concordance of relative popularity rankings between regions, using the non-parametric Kendall's W, which maps concordance between 0 (lack of agreement) to 1 (perfect match). We used a dynamic time-warping algorithm to explore the similarity between Covid-19 relative popularity, mortality, and incident case trajectories. This methodology can recognize the similarity of shapes between time-series through a distance optimization process. The peak popularity was recorded on March 2020, to be followed by a decline below 20% in the subsequent three months and a long-standing period of variation around that level. At the end of 2021, public interest spiked shortly to fade away to a low level of around 10%. This pattern was highly concordant across the six regions (Kendal's W 0.88, p< .001). In dynamic time warping analysis, national-level public interest yielded a high similarity with the Covid-19 mortality trajectory (Similarity indices range 0.60-0.79). Instead, public interest was less similar with incident cases (0.50-0.76) and stringency index trajectories (0.33-0.64). We demonstrated that public interest is better intertwined with population mortality, rather than incident case trajectory and administrative responses. As the public interest in Covid-19 gradually subsides, these observations could help predict future public interest in pandemic events.",
      "authors": "Ziakas Panayiotis D; Mylonakis Eleftherios",
      "year": "2023",
      "journal": "PLOS digital health",
      "doi": "10.1371/journal.pdig.0000271",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37294742/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC10255932"
    },
    {
      "pmid": "16528423",
      "title": "A comparison of portable XRF and ICP-OES analysis for lead on air filter samples from a lead ore concentrator mill and a lead-acid battery recycler.",
      "abstract": "Personal and area samples for airborne lead were taken at a lead mine concentrator mill, and at a lead-acid battery recycler. Lead is mined as its sulfidic ore, galena, which is often associated with zinc and silver. The ore typically is concentrated, and partially separated, on site by crushing and differential froth flotation of the ore minerals before being sent to a primary smelter. Besides lead, zinc and iron are also present in the airborne dusts, together with insignificant levels of copper and silver, and, in one area, manganese. The disposal of used lead-acid batteries presents environmental issues, and is also a waste of recoverable materials. Recycling operations allow for the recovery of lead, which can then be sold back to battery manufacturers to form a closed loop. At the recycling facility lead is the chief airborne metal, together with minor antimony and tin, but several other metals are generally present in much smaller quantities, including copper, chromium, manganese and cadmium. Samplers used in these studies included the closed-face 37 mm filter cassette (the current US standard method for lead sampling), the 37 mm GSP or \"cone\" sampler, the 25 mm Institute of Occupational Medicine (IOM) inhalable sampler, the 25 mm Button sampler, and the open-face 25 mm cassette. Mixed cellulose-ester filters were used in all samplers. The filters were analyzed after sampling for their content of the various metals, particularly lead, that could be analyzed by the specific portable X-ray fluorescence (XRF) analyzer under study, and then were extracted with acid and analyzed by inductively coupled plasma optical emission spectroscopy (ICP-OES). The 25 mm filters were analyzed using a single XRF reading, while three readings on different parts of the filter were taken from the 37 mm filters. For lead at the mine concentrate mill, all five samplers gave good correlations (r2 > 0.96) between the two analytical methods over the entire range of found lead mass, which encompassed the permissible exposure limit of 150 mg m(-3) enforced in the USA by the Mine Safety and Health Administration (MSHA). Linear regression on the results from most samplers gave almost 1 ratio 1 correlations without additional correction, indicating an absence of matrix effects from the presence of iron and zinc in the samples. An approximately 10% negative bias was found for the slope of the Button sampler regression, in line with other studies, but it did not significantly affect the accuracy as all XRF results from this sampler were within 20% of the corresponding ICP values. As in previous studies, the best results were obtained with the GSP sampler using the average of three readings, with all XRF results within 20% of the corresponding ICP values and a slope close to 1 (0.99). Greater than 95% of XRF results were within 20% of the corresponding ICP values for the closed-face 37 mm cassette using the OSHA algorithm, and the IOM sampler using a sample area of 3.46 cm2. As in previous studies, considerable material was found on the interior walls of all samplers that possess an internal surface for deposition, at approximately the same proportion for all samplers. At the lead-acid battery recycler all five samplers in their optimal configurations gave good correlations (r2 > 0.92) between the two analytical methods over the entire range of found lead mass, which included the permissible exposure limit enforced in the USA by the Occupational Safety and Health Administration (OSHA). Linear regression on the results from most samplers gave almost 1 ratio 1 correlations (except for the Button sampler), indicating an absence of matrix effects from the presence of the smaller quantities of the other metals in the samples. A negative bias was found for the slope of the button sampler regression, in line with other studies. Even though very high concentrations of lead were encountered (up to almost 6 mg m(-3)) no saturation of the detector was observed. Most samplers performed well, with >90% of XRF results within +/- 25% of the corresponding ICP results for the optimum configurations. The OSHA algorithm for the CFC worked best without including the back-up pad with the filter.",
      "authors": "Harper Martin; Pacolay Bruce; Hintz Patrick; Andrew Michael E",
      "year": "2006",
      "journal": "Journal of environmental monitoring : JEM",
      "doi": "10.1039/b518075a",
      "url": "https://pubmed.ncbi.nlm.nih.gov/16528423/",
      "mesh_terms": "Air Pollutants, Occupational; Conservation of Natural Resources; Electric Power Supplies; Environmental Monitoring; Filtration; Humans; Inhalation Exposure; Lead; Metallurgy; Occupational Exposure; Spectrometry, X-Ray Emission; Spectrophotometry, Atomic",
      "keywords": "",
      "pub_types": "Comparative Study; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "24974384",
      "title": "Human brain lesion-deficit inference remapped.",
      "abstract": "Our knowledge of the anatomical organization of the human brain in health and disease draws heavily on the study of patients with focal brain lesions. Historically the first method of mapping brain function, it is still potentially the most powerful, establishing the necessity of any putative neural substrate for a given function or deficit. Great inferential power, however, carries a crucial vulnerability: without stronger alternatives any consistent error cannot be easily detected. A hitherto unexamined source of such error is the structure of the high-dimensional distribution of patterns of focal damage, especially in ischaemic injury-the commonest aetiology in lesion-deficit studies-where the anatomy is naturally shaped by the architecture of the vascular tree. This distribution is so complex that analysis of lesion data sets of conventional size cannot illuminate its structure, leaving us in the dark about the presence or absence of such error. To examine this crucial question we assembled the largest known set of focal brain lesions (n = 581), derived from unselected patients with acute ischaemic injury (mean age = 62.3 years, standard deviation = 17.8, male:female ratio = 0.547), visualized with diffusion-weighted magnetic resonance imaging, and processed with validated automated lesion segmentation routines. High-dimensional analysis of this data revealed a hidden bias within the multivariate patterns of damage that will consistently distort lesion-deficit maps, displacing inferred critical regions from their true locations, in a manner opaque to replication. Quantifying the size of this mislocalization demonstrates that past lesion-deficit relationships estimated with conventional inferential methodology are likely to be significantly displaced, by a magnitude dependent on the unknown underlying lesion-deficit relationship itself. Past studies therefore cannot be retrospectively corrected, except by new knowledge that would render them redundant. Positively, we show that novel machine learning techniques employing high-dimensional inference can nonetheless accurately converge on the true locus. We conclude that current inferences about human brain function and deficits based on lesion mapping must be re-evaluated with methodology that adequately captures the high-dimensional structure of lesion data.",
      "authors": "Mah Yee-Haur; Husain Masud; Rees Geraint; Nachev Parashkev",
      "year": "2014",
      "journal": "Brain : a journal of neurology",
      "doi": "10.1093/brain/awu164",
      "url": "https://pubmed.ncbi.nlm.nih.gov/24974384/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Brain; Brain Mapping; Female; Humans; Imaging, Three-Dimensional; Male; Middle Aged",
      "keywords": "focal brain injury; ischaemic brain injury; lesion-deficit inference",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC4132645"
    },
    {
      "pmid": "41464234",
      "title": "A Multi-Stage Hybrid Learning Model with Advanced Feature Fusion for Enhanced Prostate Cancer Classification.",
      "abstract": "Background: Cancer poses a significant health risk to humans, with prostate cancer (PCa) being the second most common and deadly form among men, following lung cancer. Each year, it affects over a million individuals and presents substantial diagnostic challenges due to variations in tissue appearance and imaging quality. In recent decades, various techniques utilizing Magnetic Resonance Imaging (MRI) have been developed for identifying and classifying PCa. Accurate classification in MRI typically requires the integration of complementary feature types, such as deep semantic representations from Convolutional Neural Networks (CNNs) and handcrafted descriptors like Histogram of Oriented Gradients (HOG). Therefore, a more robust and discriminative feature integration strategy is crucial for enhancing computer-aided diagnosis performance. Objectives: This study aims to develop a multi-stage hybrid learning model that combines deep and handcrafted features, investigates various feature reduction and classification techniques, and improves diagnostic accuracy for prostate cancer using magnetic resonance imaging. Methods: The proposed framework integrates deep features extracted from convolutional architectures with handcrafted texture descriptors to capture both semantic and structural information. Multiple dimensionality reduction methods, including singular value decomposition (SVD), were evaluated to optimize the fused feature space. Several machine learning (ML) classifiers were benchmarked to identify the most effective diagnostic configuration. The overall framework was validated using k-fold cross-validation to ensure reliability and minimize evaluation bias. Results: Experimental results on the Transverse Plane Prostate (TPP) dataset for binary classification tasks showed that the hybrid model significantly outperformed individual deep or handcrafted approaches, achieving superior accuracy of 99.74%, specificity of 99.87%, precision of 99.87%, sensitivity of 99.61%, and F1-score of 99.74%. Conclusions: By combining complementary feature extraction, dimensionality reduction, and optimized classification, the proposed model offers a reliable and generalizable solution for prostate cancer diagnosis and demonstrates strong potential for integration into intelligent clinical decision-support systems.",
      "authors": "Abd El-Ghany Sameh; Abd El-Aziz A A",
      "year": "2025",
      "journal": "Diagnostics (Basel, Switzerland)",
      "doi": "10.3390/diagnostics15243235",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41464234/",
      "mesh_terms": "",
      "keywords": "deep learning; histogram of oriented gradients; magnetic resonance imaging; prostate cancer; singular value decomposition; support vector machines; transverse plane prostate dataset",
      "pub_types": "Journal Article",
      "pmcid": "PMC12731423"
    },
    {
      "pmid": "40874067",
      "title": "Clinical decision support for pharmacologic management of treatment-resistant depression with augmented large language models.",
      "abstract": "BACKGROUND: We evaluated whether a large language model could assist in selecting psychopharmacological treatments for adults with treatment-resistant depression. METHODS: We generated 20 clinical vignettes reflecting treatment-resistant depression among adults based on distributions drawn from electronic health records. Each vignette was evaluated by 2 expert psychopharmacologists to determine and rank the 5 best next-step pharmacologic interventions, as well as contraindicated or poor next-step treatments. Vignettes were then presented in random order, permuting gender and race, to a large language model (Qwen 2.5:7B), augmented with a synopsis of published treatment guidelines. Model output was compared to expert rankings, as well as to those of a convenience sample of community clinicians and an additional group of expert clinicians. RESULTS: The augmented model prioritized the expert-designated optimal choice for 114/320 vignettes (35.6\u202f%, 95\u202f% CI 30.6\u202f%-41.0\u202f%; Cohen's kappa = 0.34, 95\u202f% CI 0.28-0.39). There were no vignettes for which any of the model choices were among the poor or contraindicated treatments. Results were not meaningfully different when gender or race of the vignette was permuted to examine risk for bias. A sample of community clinicians identified the optimal treatment choice for 12/91 vignettes (13.2\u202f%, 95\u202f% CI: 7.7-21.6\u202f%; Cohen's kappa = 0.10, 95\u202f% CI 0.03-0.18), while an additional group of expert psychopharmacologists identified optimal treatment for 9/140 (6.4\u202f%, 95\u202f%CI: 3.4-11.8\u202f%; Cohen's kappa = 0.03, 95\u202f% CI 0.01-0.08). CONCLUSION: An augmented language model demonstrated moderate agreement with expert recommendations and avoided contraindicated treatments, suggesting potential as a tool for supporting complex psychopharmacologic decision-making in treatment-resistant depression.",
      "authors": "Perlis Roy H; Verhaak Pilar F; Goldberg Joseph; Cusin Cristina; Ostacher Michael; Malhi Gin S; Zarate Carlos A; Shelton Richard C; Iosifescu Dan V; Tohen Mauricio; Jha Manish Kumar; Sajatovic Martha; Berk Michael",
      "year": "2025",
      "journal": "Journal of mood and anxiety disorders",
      "doi": "10.1016/j.xjmad.2025.100142",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40874067/",
      "mesh_terms": "",
      "keywords": "Artificial intelligence; Expert consensus; Machine learning; Major depression; Psychopharmacology",
      "pub_types": "Journal Article",
      "pmcid": "PMC12378943"
    },
    {
      "pmid": "31053071",
      "title": "Look me in the eye: evaluating the accuracy of smartphone-based eye tracking for potential application in autism spectrum disorder research.",
      "abstract": "BACKGROUND: Avoidance to look others in the eye is a characteristic symptom of Autism Spectrum Disorders (ASD), and it has been hypothesised that quantitative monitoring of gaze patterns could be useful to objectively evaluate treatments. However, tools to measure gaze behaviour on a regular basis at a manageable cost are missing. In this paper, we investigated whether a smartphone-based tool could address this problem. Specifically, we assessed the accuracy with which the phone-based, state-of-the-art eye-tracking algorithm iTracker can distinguish between gaze towards the eyes and the mouth of a face displayed on the smartphone screen. This might allow mobile, longitudinal monitoring of gaze aversion behaviour in ASD patients in the future. RESULTS: We simulated a smartphone application in which subjects were shown an image on the screen and their gaze was analysed using iTracker. We evaluated the accuracy of our set-up across three tasks in a cohort of 17 healthy volunteers. In the first two tasks, subjects were shown different-sized images of a face and asked to alternate their gaze focus between the eyes and the mouth. In the last task, participants were asked to trace out a circle on the screen with their eyes. We confirm that iTracker can recapitulate the true gaze patterns, and capture relative position of gaze correctly, even on a different phone system to what it was trained on. Subject-specific bias can be corrected using an error model informed from the calibration data. We compare two calibration methods and observe that a linear model performs better than a previously proposed support vector regression-based method. CONCLUSIONS: Under controlled conditions it is possible to reliably distinguish between gaze towards the eyes and the mouth with a smartphone-based set-up. However, future research will be required to improve the robustness of the system to roll angle of the phone and distance between the user and the screen to allow deployment in a home setting. We conclude that a smartphone-based gaze-monitoring tool provides promising opportunities for more quantitative monitoring of ASD.",
      "authors": "Strobl Maximilian A R; Lipsmeier Florian; Demenescu Liliana R; Gossens Christian; Lindemann Michael; De Vos Maarten",
      "year": "2019",
      "journal": "Biomedical engineering online",
      "doi": "10.1186/s12938-019-0670-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31053071/",
      "mesh_terms": "Adult; Autism Spectrum Disorder; Eye Movements; Female; Humans; Male; Smartphone; Young Adult",
      "keywords": "Biomedical monitoring; Gaze tracking; Mental disorders; m-Health",
      "pub_types": "Evaluation Study; Journal Article",
      "pmcid": "PMC6499948"
    },
    {
      "pmid": "25545577",
      "title": "Textual analysis of internal medicine residency personal statements: themes and gender differences.",
      "abstract": "CONTEXT: Applicants to US residency training programmes are required to submit a personal statement, the content of which is flexible but often requires them to describe their career goals and aspirations. Despite their importance, no systematic research has explored common themes and gender differences inherent to these statements. OBJECTIVES: This study was conducted to analyse US applicants' Electronic Residency Application Service (ERAS) personal statements using two automated textual analysis programs, and to assess for common themes and gender-associated differences. METHODS: A retrospective cohort study of 2138 personal statements (containing 1,485,255 words) from candidates from 377 national and international medical schools applying to US internal medicine (IM) residency programmes through ERAS was conducted. A mathematical analysis of text segments using a recursive algorithm was performed; two different specifications of the text segments were used to conduct an internal validation. RESULTS: Five statistically significant thematic classes were identified through independent review by the researchers. These were best defined as referring to: the appeal of the residency programme; memorable patients; health care as public policy; research and academia, and family inspiration. Some themes were common to all applications. However, important gender-specific differences were identified. Notably, men were more likely to describe personal attributes and to self-promote, whereas women more frequently expressed the communicative and team-based aspects of doctoring. The results were externally validated using a second software program. Although these data comprise part of the national pool, they represent applicants to a single specialty at a single institution. CONCLUSIONS: By applying textual analysis to material derived from a national cohort, we identified common narrative themes in the personal statements of future US physicians, noting differences between men and women. Together, these data provide novel insight into the dominant discourse of doctoring in this generation of students applying for further training in US IM residency programmes, and depict a diverse group of applicants with multiple motivations, desires and goals. Furthermore, differences seen between men and women add to the growing understanding of bias in medical education. Training programmes may benefit by adapting curricula to foster such diverse interests.",
      "authors": "Osman Nora Y; Schonhardt-Bailey Cheryl; Walling Jessica L; Katz Joel T; Alexander Erik K",
      "year": "2015",
      "journal": "Medical education",
      "doi": "10.1111/medu.12487",
      "url": "https://pubmed.ncbi.nlm.nih.gov/25545577/",
      "mesh_terms": "Boston; Female; Humans; Internal Medicine; Internship and Residency; Male; Motivation; Personal Narratives as Topic; Retrospective Studies; School Admission Criteria; Sex Factors; Statistics as Topic; Writing",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38093998",
      "title": "LodgeNet: an automated framework for precise detection and classification of wheat lodging severity levels in precision farming.",
      "abstract": "Wheat lodging is a serious problem affecting grain yield, plant health, and grain quality. Addressing the lodging issue in wheat is a desirable task in breeding programs. Precise detection of lodging levels during wheat screening can aid in selecting lines with resistance to lodging. Traditional approaches to phenotype lodging rely on manual data collection from field plots, which are slow and laborious, and can introduce errors and bias. This paper presents a framework called 'LodgeNet,' that facilitates wheat lodging detection. Using Unmanned Aerial Vehicles (UAVs) and Deep Learning (DL), LodgeNet improves traditional methods of detecting lodging with more precision and efficiency. Using a dataset of 2000 multi-spectral images of wheat plots, we have developed a novel image registration technique that aligns the different bands of multi-spectral images. This approach allows the creation of comprehensive RGB images, enhancing the detection and classification of wheat lodging. We have employed advanced image enhancement techniques to improve image quality, highlighting the important features of wheat lodging detection. We combined three color enhancement transformations into two presets for image refinement. The first preset, 'Haze & Gamma Adjustment,' minimize atmospheric haze and adjusts the gamma, while the second, 'Stretching Contrast Limits,' extends the contrast of the RGB image by calculating and applying the upper and lower limits of each band. LodgeNet, which relies on the state-of-the-art YOLOv8 deep learning algorithm, could detect and classify wheat lodging severity levels ranging from no lodging (Class 1) to severe lodging (Class 9). The results show the mean Average Precision (mAP) of 0.952% @0.5 and 0.641% @0.50-0.95 in classifying wheat lodging severity levels. LodgeNet promises an efficient and automated high-throughput solution for real-time crop monitoring of wheat lodging severity levels in the field.",
      "authors": "Ali Nisar; Mohammed Ahmed; Bais Abdul; Sangha Jatinder S; Ruan Yuefeng; Cuthbert Richard D",
      "year": "2023",
      "journal": "Frontiers in plant science",
      "doi": "10.3389/fpls.2023.1255961",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38093998/",
      "mesh_terms": "",
      "keywords": "Unmanned Aerial Vehicle; classification; deep learning; multi-spectral imaging; wheat lodging",
      "pub_types": "Journal Article",
      "pmcid": "PMC10718648"
    },
    {
      "pmid": "36359118",
      "title": "Rumen Microbial Predictors for Short-Chain Fatty Acid Levels and the Grass-Fed Regimen in Angus Cattle.",
      "abstract": "The health benefits of grass-fed beef are well documented. However, the rumen microbiome features in beef steers raised in a grass-fed regimen have yet to be identified. This study examined the rumen microbiome profile in the feeding regimes. Our findings show that the rumen microbiome of the grass-fed cattle demonstrated greater species diversity and harbored significantly higher microbial alpha diversity, including multiple species richness and evenness indices, than the grain-fed cattle. Global network analysis unveiled that grass-fed cattle's rumen microbial interaction networks had higher modularity, suggesting a more resilient and stable microbial community under this feeding regimen. Using the analysis of compositions of microbiomes with a bias correction (ANCOM-BC) algorithm, the abundance of multiple unclassified genera, such as those belonging to Planctomycetes, LD1-PB3, SR1, Lachnospira, and Sutterella, were significantly enriched in the rumen of grass-fed steers. Sutterella was also the critical genus able to distinguish the two feeding regimens by Random Forest. A rumen microbial predictor consisting of an unclassified genus in the candidate division SR1 (numerator) and an unclassified genus in the order Bacteroidales (denominator) accurately distinguished the two feeding schemes. Multiple microbial signatures or balances strongly correlated with various levels of SCFA in the rumen. For example, a balance represented by the log abundance ratio of Sutterella to Desulfovibrio was strongly associated with acetate-to-propionate proportions in the rumen (R2 = 0.87), which could be developed as a valuable biomarker for optimizing milk fat yield and cattle growth. Therefore, our findings provided novel insights into microbial interactions in the rumen under different feed schemes and their ecophysiological implications. These findings will help to develop rumen manipulation strategies to improve feed conversion ratios and average daily weight gains for grass- or pasture-fed cattle production.",
      "authors": "Liu Jianan; Bai Ying; Liu Fang; Kohn Richard A; Tadesse Daniel A; Sarria Saul; Li Robert W; Song Jiuzhou",
      "year": "2022",
      "journal": "Animals : an open access journal from MDPI",
      "doi": "10.3390/ani12212995",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36359118/",
      "mesh_terms": "",
      "keywords": "Angus cattle; grain-fed beef; grass-fed beef; microbiome; rumen; short-chain fatty acids",
      "pub_types": "Journal Article",
      "pmcid": "PMC9656057"
    },
    {
      "pmid": "36699647",
      "title": "A New Drug Safety Signal Detection and Triage System Integrating Sequence Symmetry Analysis and Tree-Based Scan Statistics with Longitudinal Data.",
      "abstract": "PURPOSE: Development and evaluation of a drug-safety signal detection system integrating data-mining tools in longitudinal data is essential. This study aimed to construct a new triage system using longitudinal data for drug-safety signal detection, integrating data-mining tools, and evaluate adaptability of such system. PATIENTS AND METHODS: Based on relevant guidelines and structural frameworks in Taiwan's pharmacovigilance system, we constructed a triage system integrating sequence symmetry analysis (SSA) and tree-based scan statistics (TreeScan) as data-mining tools for detecting safety signals. We conducted an exploratory analysis utilizing Taiwan's National Health Insurance Database and selecting two drug classes (sodium-glucose co-transporter-2 inhibitors (SGLT2i) and non-fluorinated quinolones (NFQ)) as chronic and episodic treatment respectively, as examples to test feasibility of the system. RESULTS: Under the proposed system, either cohort-based or self-controlled mining with SSA and TreeScan was selected, based on whether the screened drug had an appropriate comparator. All detected alerts were further classified as known adverse drug reactions (ADRs), events related to other causes or potential signals from the triage algorithm, building on existing drug labels and clinical judgement. Exploratory analysis revealed greater numbers of signals for NFQ with a relatively low proportion of known ADRs; most were related to indication, patient characteristics or bias. No safety signals were found. By contrast, most SGLT2i signals were known ADRs or events related to patient characteristics. Four were potential signals warranting further investigation. CONCLUSION: The proposed system facilitated active and systematic screening to detect and classify potential safety signals. Countries with real-world longitudinal data could adopt it to streamline drug-safety surveillance.",
      "authors": "Hsieh Miyuki Hsing-Chun; Liang Hsun-Yin; Tsai Chih-Ying; Tseng Yu-Ting; Chao Pi-Hui; Huang Wei-I; Chen Wen-Wen; Lin Swu-Jane; Lai Edward Chia-Cheng",
      "year": "2023",
      "journal": "Clinical epidemiology",
      "doi": "10.2147/CLEP.S395922",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36699647/",
      "mesh_terms": "",
      "keywords": "drug safety; sequence symmetry analysis; signal detection; tree-based scan statistics; triage",
      "pub_types": "Journal Article",
      "pmcid": "PMC9868282"
    },
    {
      "pmid": "37962931",
      "title": "Predicting Obsessive-Compulsive Disorder Events in Children and Adolescents in the Wild using a Wearable Biosensor (Wrist Angel): Protocol for the Analysis Plan of a Nonrandomized Pilot Study.",
      "abstract": "BACKGROUND: Physiological signals such as heart rate and electrodermal activity can provide insight into an individual's mental state, which are invaluable information for mental health care. Using recordings of physiological signals from wearable devices in the wild can facilitate objective monitoring of symptom severity and evaluation of treatment progress. OBJECTIVE: We designed a study to evaluate the feasibility of predicting obsessive-compulsive disorder (OCD) events from physiological signals recorded using wrist-worn devices in the wild. Here, we present an analysis plan for the study to document our a priori hypotheses and increase the robustness of the findings of our planned study. METHODS: In total, 18 children and adolescents aged between 8 and 16 years were included in this study. Nine outpatients with an OCD diagnosis were recruited from a child and adolescent mental health center. Nine youths without a psychiatric diagnosis were recruited from the catchment area. Patients completed a clinical interview to assess OCD severity, types of OCD, and number of OCD symptoms in the clinic. Participants wore a biosensor on their wrist for up to 8 weeks in their everyday lives. Patients were asked to press an event tag button on the biosensor when they were stressed by OCD symptoms. Participants without a psychiatric diagnosis were asked to press this button whenever they felt really scared. Before and after the 8-week observation period, participants wore the biosensor under controlled conditions of rest and stress in the clinic. Features are extracted from 4 different physiological signals within sliding windows to predict the distress event logged by participants during data collection. We will test the prediction models within participants across time and multiple participants. Model selection and estimation using 2-layer cross-validation are outlined for both scenarios. RESULTS: Participants were included between December 2021 and December 2022. Participants included 10 female and 8 male participants with an even sex distribution between groups. Patients were aged between 10 and 16 years, and adolescents without a psychiatric diagnosis were between the ages of 8 and 16 years. Most patients had moderate to moderate to severe OCD, except for 1 patient with mild OCD. CONCLUSIONS: The strength of the planned study is the investigation of predictions of OCD events in the wild. Major challenges of the study are the inherent noise of in-the-wild data and the lack of contextual knowledge associated with the recorded signals. This preregistered analysis plan discusses in detail how we plan to address these challenges and may help reduce interpretation bias of the upcoming results. If the obtained results from this study are promising, we will be closer to automated detection of OCD events outside of clinical experiments. This is an important tool for the assessment and treatment of OCD in youth. TRIAL REGISTRATION: ClinicalTrials.gov NCT05064527; https://clinicaltrials.gov/study/NCT05064527. INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): DERR1-10.2196/48571.",
      "authors": "Olesen Kristoffer Vinther; L\u00f8nfeldt Nicole Nadine; Das Sneha; Pagsberg Anne Katrine; Clemmensen Line Katrine Harder",
      "year": "2023",
      "journal": "JMIR research protocols",
      "doi": "10.2196/48571",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37962931/",
      "mesh_terms": "",
      "keywords": "AI; Empatica E4; OCD; adolescents; artificial intelligence; children; machine learning; mental health; mental health care; monitoring; obsessive compulsive disorder; obsessive-compulsive disorder; physiological signal; prediction; teens; wearable",
      "pub_types": "Journal Article",
      "pmcid": "PMC10685277"
    },
    {
      "pmid": "41409680",
      "title": "Ocrelizumab versus Natalizumab in Relapsing-Remitting Multiple Sclerosis: A Registry-Linked Electronic Health Records Study.",
      "abstract": "BACKGROUND: Ocrelizumab and natalizumab are commonly prescribed high-effectiveness disease-modifying therapies (DMTs) for relapsing-remitting multiple sclerosis (RRMS). However, no randomized clinical trial and few real-world studies have directly compared their effectiveness in reducing disability progression. Subtype classification and disability status are critical for multiple sclerosis (MS) research, but these data are often missing in electronic health records (EHRs), limiting robust real-world evidence generation. OBJECTIVE: To compare the effectiveness of ocrelizumab and natalizumab in two-year rater-assessed disability progression among RRMS patients using longitudinal registry-linked EHR data. DESIGN: Retrospective cohort study. SETTING: A large healthcare system that includes both academic and community practices. PARTICIPANTS: Patients diagnosed with MS who initiated ocrelizumab or natalizumab between 2012 and 2020, with at least 6-month EHR data before treatment initiation and no prior exposure to other high-effectiveness DMTs. EXPOSURES: Treatment with ocrelizumab vs natalizumab. MEASUREMENTS: We developed an ensemble machine learning model to impute RRMS subtype and disability outcomes using structured and narrative EHR data. The primary outcome was moderate/severe rater-assessed disability at 2 years (observed or imputed Expanded Disability Status Scale [EDSS]\u22654) after treatment initiation. We estimated the average treatment effects using semi-supervised doubly robust approach with comprehensive confounder adjustment and calibration to mitigate imputation bias. Covariates included standard demographic and clinical features such as baseline disability as well as knowledge graph-selected features. Sensitivity analyses used observed EDSS scores in registry-derived RRMS patients. Exploratory analyses included rituximab, another B-cell-depleting therapy, with adjustments for differences in patient profiles. RESULTS: Among RRMS patients, those treated with ocrelizumab (n=543) had a significantly lower two-year risk of moderate/severe disability compared with those treated with natalizumab (n=205) based on imputed outcomes (risk difference, -5.87%; 95% CI: -11.28% to -0.46%; p=0.033) after confounder adjustment. Sensitivity analyses yielded consistent findings using imputed or observed EDSS outcomes in registry-derived RRMS patients. CONCLUSION AND RELEVANCE: In this real-world comparative effectiveness study using a novel semi-supervised doubly-robust framework, ocrelizumab was associated with a lower risk of disability progression than natalizumab among RRMS patients. This approach provides a roadmap for generating robust large-scale real-world evidence in settings of missing key inclusion features and outcomes.",
      "authors": "Huang Feiqing; Zhu Wen; Hou Jue; Morini Sweet Sara; Han Yunqing; Wen Jun; Liao Katherine P; Cai Tianrun; Chitnis Tanuja; Bourgeois Florence; Xia Zongqi; Cai Tianxi",
      "year": "2025",
      "journal": "medRxiv : the preprint server for health sciences",
      "doi": "10.64898/2025.12.01.25341331",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41409680/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article; Preprint",
      "pmcid": "PMC12706613"
    },
    {
      "pmid": "38630732",
      "title": "A protocol for remote collection of skeletal muscle mass via D3-creatine dilution in community-dwelling postmenopausal women from the Women's Health Initiative.",
      "abstract": "BACKGROUND: There is emerging evidence that cancer and its treatments may accelerate the normal aging process, increasing the magnitude and rate of decline in functional capacity. This accelerated aging process is hypothesized to hasten the occurrence of common adverse age-related outcomes in cancer survivors, including loss of muscle mass and decrease in physical function. However, there is no data describing age-related loss of muscle mass and its relation to physical function in the long-term in cancer survivors. METHODS: This study protocol describes the use of a novel method of muscle mass measurement, D3-creatine dilution method (D3Cr), in a large sample (n~6000) of community dwelling postmenopausal women from the Women's Health Initiative (WHI). D3Cr will be used to obtain a direct measure of muscle mass remotely. Participants will be drawn from two sub-cohorts embedded within the WHI that have recently completed an in-home visit. Cancer survivors will be drawn from the Life and Longevity After Cancer (LILAC) cohort, and cancer-free controls will be drawn from the WHI Long Life Study 2. The overall objective of this study is to examine the antecedents and consequences of low muscle mass in cancer survivors. The study aims are to: 1) create age-standardized muscle mass percentile curves and z-scores to characterize the distribution of D3- muscle mass in cancer survivors and non-cancer controls, 2) compare muscle mass, physical function, and functional decline in cancer survivors and non- cancer controls, and 3) use machine learning approaches to generate multivariate risk-prediction algorithms to detect low muscle mass. DISCUSSION: The D3Cr method will transform our ability to measure muscle mass in large-scale epidemiologic research. This study is an opportunity to advance our understanding of a key source of morbidity among older and long-term female cancer survivors. This project will fill knowledge gaps, including the antecedents and consequences of low muscle mass, and use innovative methods to overcome common sources of bias in cancer research. The results of this study will be used to develop interventions to mitigate the harmful effects of low muscle mass in older adults and promote healthy survivorship in cancer survivors in the old (>65) and oldest-old (>85) age groups.",
      "authors": "Banack Hailey R; Wactawski-Wende Jean; Ochs-Balcom Heather M; Feliciano Elizabeth M Cespedes; Caan Bette; Lee Catherine; Anderson Garnet; Shankaran Mahalakshmi; Evans William J",
      "year": "2024",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0300140",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38630732/",
      "mesh_terms": "Humans; Female; Aged; Aged, 80 and over; Creatine; Independent Living; Postmenopause; Neoplasms; Muscle, Skeletal; Women's Health",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11023459"
    },
    {
      "pmid": "39417708",
      "title": "Long-term exposure to PM2.5 and mortality: a national health insurance cohort study.",
      "abstract": "BACKGROUND: Previous studies with large data have been widely reported that exposure to fine particulate matter (PM2.5) is associated with all-cause mortality; however, most of these studies adopted ecological time-series designs or have included limited study areas or individuals residing in well-monitored urban areas. However, nationwide cohort studies including cause-specific mortalities with different age groups were sparse. Therefore, this study examined the association between PM2.5 and cause-specific mortality in South Korea using the nationwide cohort. METHODS: A longitudinal cohort with 187\u00a0917 National Health Insurance Service-National Sample Cohort participants aged 50-79\u2009years in enrolment between 2002 and 2019 was used. Annual average PM2.5 was collected from a machine learning-based ensemble model (a test R2 = 0.87) as an exposure. We performed a time-varying Cox regression model to examine the association between long-term PM2.5 exposure and mortality. To reduce the potential estimation bias, we adopted generalized propensity score weighting method. RESULTS: The association with long-term PM2.5 (2-year moving average) was prominent in mortalities related to diabetes mellitus [hazard ratio (HR): 1.03 (95% CI: 1.01, 1.06)], circulatory diseases [HR: 1.02 (95% CI: 1.00, 1.03)] and cancer [HR: 1.01 (95% CI: 1.00, 1.02)]. Meanwhile, circulatory-related mortalities were associated with a longer PM2.5 exposure period (1 or 2-year lags), whereas respiratory-related mortalities were associated with current-year PM2.5 exposure. In addition, the association with PM2.5 was more evident in people aged 50-64\u2009years than in people aged 65-79\u2009years, especially in heart failure-related deaths. CONCLUSIONS: This study identified the hypothesis that long-term exposure to PM2.5 is associated with mortality, and the association might be different by causes of death. Our result highlights a novel vulnerable population: the middle-aged population with risk factors related to heart failure.",
      "authors": "Moon Jeongmin; Kim Ejin; Jang Hyemin; Song Insung; Kwon Dohoon; Kang Cinoo; Oh Jieun; Park Jinah; Kim Ayoung; Choi Moonjung; Cha Yaerin; Kim Ho; Lee Whanhee",
      "year": "2024",
      "journal": "International journal of epidemiology",
      "doi": "10.1093/ije/dyae140",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39417708/",
      "mesh_terms": "Humans; Particulate Matter; Male; Female; Aged; Middle Aged; Republic of Korea; Environmental Exposure; Longitudinal Studies; Air Pollution; Air Pollutants; Cardiovascular Diseases; National Health Programs; Proportional Hazards Models; Cause of Death; Mortality; Cohort Studies; Neoplasms; Diabetes Mellitus",
      "keywords": "Particulate matter; cohort study; generalized propensity score method; long-term exposure; mortality",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40708322",
      "title": "Prevalence, combination patterns, and quality of life factors of multimorbidity among older adults in southern China based on the health ecological model.",
      "abstract": "BACKGROUND: Multimorbidity is increasingly prevalent among older adults and poses significant challenges to health and well-being. This study applied a health ecological model to investigate the prevalence, determinants, and common disease patterns of multimorbidity, as well as the factors associated with quality of life (QoL) among older adults in southern China. METHODS: A cross-sectional survey was conducted among 2404 individuals aged 60 years and older using a multi-stage random sampling method. Quality of life was assessed using the EQ-5D-5L scale. Multimorbidity was defined as the presence of two or more chronic conditions. The Apriori algorithm identified common multimorbidity combinations. Factors influencing multimorbidity were analysed using univariate and multivariate logistic regression based on a health ecological model. Tobit regression was used to assess associated factors of QoL among patients with multimorbidity. RESULTS: The prevalence of multimorbidity was 44.3%. Hypertension featured prominently in disease clusters, with 'hypertension\u2009+\u2009hyperlipidemia' as the top two-disease combination. Risk factors for multimorbidity included QoL, age, body mass index (BMI), exercise, sleep quality, social participation, education level, per capita monthly household income, and region. The number of chronic diseases was negatively associated with QoL. Factors significantly influencing QoL included age(\u226580, \u03b2\u2009=\u2009-0.087, P\u2009<\u20090.001), number of chronic diseases(>3 diseases, \u03b2\u2009=\u2009-0.029, P\u2009=\u20090.012), fresh fruit intake (occasionally: \u03b2\u2009=\u20090.052; often: \u03b2\u2009=\u20090.064, all P\u2009<\u20090.005), dietary balance (always: \u03b2\u2009=\u20090.078, P\u2009=\u20090.007), exercise frequency (1-3 days: \u03b2\u2009=\u2009-0.039; >3 days: \u03b2\u2009=\u20090.024, all P\u2009<\u20090.005), sleep quality (better: \u03b2\u2009=\u2009-0.034; worse: \u03b2\u2009=\u2009-0.070; very bad: \u03b2\u2009=\u2009-0.161; all P\u2009<\u20090.005), social participation (\u03b2\u2009=\u20090.034; P\u2009=\u20090.006), education level (primary school: \u03b2\u2009=\u20090.028, P\u2009=\u20090.028; college/higher vocational school: \u03b2\u2009=\u20090.083, P\u2009=\u20090.010), and region (western: \u03b2\u2009=\u20090.083; northern: \u03b2\u2009=\u20090.064; eastern: \u03b2\u2009=\u20090.132; all P\u2009<\u20090.001). CONCLUSIONS: Multimorbidity among older adults in southern China is associated with demographic, behavioral, interpersonal, socioeconomic, and regional factors. Therefore, it is recommended to implement differentiated insurance reimbursement, reinforce county-level resource allocation, integrate community services via the World Health Organization's (WHO) Integrated Care for Older People (ICOPE) framework, and promote individual lifestyle measures. Given the reliance on self-reported cross-sectional data, the findings are constrained by limited causal inference and possible recall bias. Longitudinal studies are needed to validate and refine the conclusions.",
      "authors": "Long Chunxiao; Huang Jiaqi; Liu Di; Liu Can; Wu Mengting; Wu Haiyang; Deng Jun; Zhang Yinjuan; Shi Lei; Cui Yanze",
      "year": "2025",
      "journal": "Journal of global health",
      "doi": "10.7189/jogh.15.04215",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40708322/",
      "mesh_terms": "Humans; China; Aged; Quality of Life; Multimorbidity; Male; Female; Middle Aged; Cross-Sectional Studies; Prevalence; Aged, 80 and over; Risk Factors; Chronic Disease",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12290435"
    },
    {
      "pmid": "41343793",
      "title": "Automated Speech Analysis for Screening and Monitoring Bipolar Depression: Machine Learning Model Development and Interpretation Study.",
      "abstract": "BACKGROUND: Depressive episodes in bipolar disorder are frequent, prolonged, and contribute substantially to functional impairment and reduced quality of life. Therefore, early and objective detection of bipolar depression is critical for timely intervention and improved outcomes. Multimodal speech analyses hold promise for capturing psychomotor, cognitive, and affective changes associated with bipolar depression. OBJECTIVE: This study aims to develop between- and within-person classifiers to screen for bipolar depression and monitor longitudinal changes to detect depressive recurrence in patients with bipolar disorder. A secondary objective was to compare the predictive performance across speech modalities. METHODS: We collected 304 voice audio recordings obtained during semistructured interviews with 92 patients diagnosed with bipolar disorder over a 1-year period. Depression severity was assessed using the Hamilton Depression Rating Scale. Acoustic features were extracted using the openSMILE toolkit, and linguistic features were extracted using the Linguistic Inquiry and Word Count frameworks following automatic speech recognition and machine translation. Mixed-effects multivariate linear regression evaluated the associations between speech markers and Hamilton Depression Rating Scale scores adjusting for demographic variables, diagnosis, and feature-specific covariates. Extreme gradient boosting and light gradient boosting were used as base learners. We developed a between-person classifier to detect moderate to severe depression and a within-person classifier to detect recurrence. Hyperparameter tuning and 95% CI estimation were performed using a bootstrap bias-corrected cross-validation (k=5) approach combined with a grid search. Feature contributions were interpreted using Shapley additive explanations. RESULTS: Patients with depression showed reduced energy modulation, prolonged monotony, and more frequent use of words related to death and negative emotions. The between-person classifier combining acoustic and linguistic features detected moderate to severe depression with an area under the curve of 0.76 compared to 0.54 for the demographic model. The within-person classifier based on speech features detected depression recurrence with an area under the curve of 0.70 compared to 0.55 for the demographic model. CONCLUSIONS: Between- and within-person comparisons of speech markers can be leveraged in detecting and monitoring bipolar depression. We demonstrate the feasibility of applying Linguistic Inquiry and Word Count-based psycholinguistic analysis to machine-transcribed and translated speech, supporting the replicability of this approach across languages. Automated multimodal voice analysis can be integrated into digital health platforms, providing a scalable and effective approach for accessing mental health monitoring and care.",
      "authors": "Min Sooyeon; Yeum Tae-Sung; Shin Daun; Rhee Sang Jin; Lee Hyunju; Lee Han-Sung; Park Seongmin; Lee Jihwa; Ahn Yong Min",
      "year": "2025",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/79093",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41343793/",
      "mesh_terms": "Humans; Bipolar Disorder; Machine Learning; Female; Male; Adult; Middle Aged; Speech; Mass Screening",
      "keywords": "AI; artificial intelligence; bipolar disorder; depression; natural language processing; speech modalities; voice analysis",
      "pub_types": "Journal Article",
      "pmcid": "PMC12715464"
    },
    {
      "pmid": "40842783",
      "title": "Advancing Accuracy in Non-invasive Hemoglobin Estimation: A Comparative Clinical Study of the Performance of the Non-invasive Anemia Detection App (NiADA).",
      "abstract": "BACKGROUND: Anemia remains a significant global health burden, particularly in low-\u00a0and middle-income countries. Traditional hemoglobin screening methods are invasive, resource-intensive, and often impractical for large-scale or repeated population-level screening. The Non-invasive Anemia Detection App (NiADA, Monere AI Private Limited, Kolkata, West Bengal, India) provides a smartphone-based, artificial intelligence (AI)-powered alternative for estimating hemoglobin levels using images of the lower palpebral conjunctiva. OBJECTIVE: This study aims to evaluate the improvement in accuracy and clinical utility of NiADA version 3 compared to NiADA version 2 in estimating hemoglobin levels and detecting anemia across diverse demographic subgroups in a tertiary care setting. MATERIALS AND METHODS: This study was conducted at NRS Medical College and Hospital, Kolkata, India, from December 2024 to January 2025. A total of 2,476 participants (ages 2-90 years) were enrolled. Trained personnel captured partial facial images, focusing on the lower eyelid, using Android smartphones running NiADA version\u00a03. The algorithm subsequently extracted the lower palpebral conjunctiva and surrounding scleral regions for automated analysis. Images underwent preprocessing and were analyzed in real time by the AI model. Venous blood samples were collected immediately after image capture\u00a0in standard ethylenediamine tetraacetic acid anticoagulant tubes, and hemoglobin levels were measured using an automated hematology analyzer. Regression and classification performance were evaluated using Bland-Altman analysis, mean bias, Lin's concordance correlation coefficient (CCC), and confusion matrices. Subgroup analyses were performed for adult males, adult females, and children. RESULTS: NiADA exhibited strong agreement with laboratory-measured hemoglobin levels across all demographic subgroups, with Pearson correlation coefficients ranging from 0.81 to 0.86, Lin's CCC\u00a0between 0.80 and 0.87, and R\u00b2 values spanning 0.73 to 0.76. The mean bias remained within \u00b10.27 g/dL across cohorts. Bland-Altman analysis showed that over 95% of predictions fell within the limits of agreement for children (-2.07 to 2.46 g/dL), females (-2.48 to 2.64 g/dL), and males (-2.51 to 3.05 g/dL). In anemia classification, NiADA achieved the highest accuracy in adult females (88.7%), followed by children (84.4%) and adult males (81.2%). Sensitivity remained consistently high across all groups (\u226588%), while specificity ranged from 71.8% to 76.1%. CONCLUSIONS: NiADA version 3 demonstrates strong accuracy and reliability as a non-invasive hemoglobin estimation tool, with performance comparable to that of conventional point-of-care devices. Its smartphone-based, consumable-free workflow makes it particularly well-suited for large-scale screening and longitudinal monitoring in both clinical and community settings. These results support NiADA's integration into public health initiatives targeting anemia surveillance and prevention.",
      "authors": "Banerjee Krishanu; Dolai Tuphan Kanti; Sharma Abhishek; Chernukha Ivan; Das Debjeet; Sharma Vipul; Nandi Mou",
      "year": "2025",
      "journal": "Cureus",
      "doi": "10.7759/cureus.88435",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40842783/",
      "mesh_terms": "",
      "keywords": "anemia; artificial intelligence; hemoglobin monitoring; image processing; non-invasive; smart phone app",
      "pub_types": "Journal Article",
      "pmcid": "PMC12367197"
    },
    {
      "pmid": "19582980",
      "title": "A clinical decision support system using multilayer perceptron neural network to assess well being in diabetes.",
      "abstract": "BACKGROUND: Diabetes mellitus is an increasingly common life-style disorder whose management outcomes are measured in symptomatic, biochemical as well as psychological areas. Well being as an outcome of treatment is being increasingly recognized as a crucial component of treatment. There is little published literature on psychosocial outcomes and the factors influencing them. Therefore we have developed a neural network system which is trained to predict the well being in diabetes, using data generated in real life. MATERIAL AND METHODS: We developed a Multi Layer Perceptron Neural Network model, which had been trained by back propagation algorithm. Data was used from a cohort of 241 individuals with diabetes. We used age, gender, weight, fasting plasma glucose as a set of inputs and predicted measures of well-being (depression, anxiety, energy and positive well-being). RESULTS: It was observed that female patients report significantly higher levels of depression than their male counter parts. Some slight high or no significant differences are observed between males and female patients with regard to the number of persons with whom they share their anxieties and fears regarding diabetes. There is not much difference has been observed in energy levels of both males and females. Also, Males have higher pwb value when compared with the female counterparts. Also, this may be due to women tend to react more emotionally to disease and hence experience more difficulty in coping with it. The present sample of women being predominantly house wives may be worrying more about their health and its problems. Also, it is observed that, gender differences are significant with regard to total general well-being. With five inputs (age, sex, weight, fasting plasma glucose, bias), four outputs are four (depression, anxiety, energy and positive well-being) the momentum rate was 0.9, the learning rate 0.7, using a sample of 50. the maximum individual error is 0.001 when the number of iterations were 500, number of hidden layers is 1 and the number of units in the hidden layer are 6, the normalized system error was 470.57. With input samples of 100, 150 and 200, keeping the other variables constant, the normalized system error was 419.61, 359.67 and 332.32 respectively. Similar values are found for the normalized system error when the number of units in the hidden layer have been increased to 7, 8 and 9 respectively. With two hidden layers, and with each hidden layer containing 6,7 ,8, 9, 10, 11 units for the samples 50, 100, 150, and 200, the same values of normalized system error was found. Women having weight between 40 kgs and 85kgs had higher levels of depression than men who had weight between 39kgs and 102 kgs. CONCLUSION: We have developed a prototype neural network model to predict the psychosocial well-being in diabetes, when biological or biographical variables are given as inputs. When greater data was fed to the system, the normalized system error can be reduced.",
      "authors": "Narasingarao M R; Manda R; Sridhar G R; Madhu K; Rao A A",
      "year": "2009",
      "journal": "The Journal of the Association of Physicians of India",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/19582980/",
      "mesh_terms": "Cohort Studies; Decision Support Systems, Clinical; Decision Support Techniques; Diabetes Mellitus; Female; Health Status; Humans; Male; Neural Networks, Computer; Predictive Value of Tests; Quality of Life",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40804403",
      "title": "Epidemiology, disease burden and costs of Duchenne muscular dystrophy in Germany: an observational, retrospective health claims data analysis.",
      "abstract": "BACKGROUND: Duchenne muscular dystrophy (DMD) is a rare genetic disorder that primarily\u00a0affects males. Beginning in childhood, patients experience ambulatory loss, heart failure and need ventilation. Disease management has improved, however, DMD remains debilitating, and has no cure. The rarity of the disease makes research difficult, and German prevalence data are lacking. Cost and resource utilization estimations are based on small sample sizes or self-reported data, limiting generalizability and adds the potential for recall bias. With a retrospective study on a healthcare claims database, we adapted algorithms to identify DMD patients and categorized them by disease stages 1-4 (early ambulatory, late ambulatory, early non-ambulatory, late non-ambulatory) with increasing disease progression. We analyzed annual prevalence, burden of disease, healthcare resource utilization and direct medical care costs, by time under observation (patient year). RESULTS: From 2016 to 2021, we identified 134 patients for which we could determine a disease stage and determined an extrapolated prevalence of DMD in Germany between 14.85 (95%CI 12.17, 17.95) and 18.91 (95%CI 15.70, 22.61) per 100,000 males under 40\u00a0years of age. Most patients we identified met DMD stage 4 group criteria (47.01%), followed by stage 3 (37.31%), stage 2 (33.58%) and only 4.48% in stage 1. The average age increased with progressing disease, from 4.27\u00a0years in stage 1, to 11.43, 18.86 and 23.21 in stage groups 2, 3 and 4, respectively. In the stage 2 group, diagnosis codes reflecting mobility support and orthopedic surgical interventions (15.56% of the group) were documented. In the stage 3 group, decubitus prevention was documented, increasing to around half of patients in the stage 4 group. Total direct mean healthcare costs per patient year increased substantially with disease severity group, from \u20ac2,180.73 (SD 16,258.90) in stage 1; \u20ac13,599.83 (SD 33,756.07) in stage 2; \u20ac14,472.08 (SD 27,245.78) in stage 3 and finally \u20ac41,888.70 (SD 117,718.13) in stage 4. Especially in stage groups 3 and 4, medical aids accounted for about half of total costs. CONCLUSIONS: We present an algorithm on which further research can be based, and provide a current picture of epidemiology, burden of disease and healthcare utilization and direct costs of DMD in Germany.",
      "authors": "Diesing Joanna; Kirschner Janbernd; Pechmann Astrid; K\u00f6nig J\u00f6rg; Kunk Leonie; Garcia Tarcyane Barata; Schwedhelm Carolina; Militzer-Horstmann Carsta; H\u00e4nsel Ivonne; Kisser Agnes",
      "year": "2025",
      "journal": "Orphanet journal of rare diseases",
      "doi": "10.1186/s13023-025-03906-x",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40804403/",
      "mesh_terms": "Humans; Muscular Dystrophy, Duchenne; Germany; Retrospective Studies; Male; Cost of Illness; Adolescent; Adult; Child; Young Adult; Health Care Costs; Child, Preschool; Prevalence",
      "keywords": "Algorithm; Costs; Disease stages; Duchenne muscular dystrophy; Epidemiology; Germany; Healthcare resource utilization; Prevalence; Real-world data",
      "pub_types": "Journal Article; Observational Study",
      "pmcid": "PMC12351880"
    },
    {
      "pmid": "41491540",
      "title": "A 3-tier information fusioned framework featuring explainable deep active optimized CRNet for accurate heart disease prediction.",
      "abstract": "BACKGROUND: Heart disease remains a leading cause of global morbidity and mortality, emphasizing the need for early and accurate prediction. Traditional models, however, often struggle with high class imbalance, limited accuracy, inadequate hyperparameter tuning, reliance on sparsely labeled data, and poor interpretability. METHODS: To address these limitations, we introduce a novel 3-tier information fusioned framework integrating Oversampling Using the Propensity Score (OUPS), ConvRecurrentNet (CRNet), an optimized CRNet, and CRNet enhanced with Uncertainty-Based Sampling (UBS). Initially, the highly imbalanced heart disease health indicator dataset is balanced using OUPS while preserving the underlying data distribution. In the first tier, we develop a new deep model; CRNet which combines gated units to capture temporal dependencies and convolutional layers for efficient spatial feature extraction. The second tier leverages the grasshopper optimization algorithm to optimize CRNet configuration and classification performance through hyperparameter tuning. At the third tier, we use an active learning based UBS to address the problem of sparse labeled data selecting the most informative samples for effective CRNet model learning. Model performance and generalizability are assessed through 10-fold cross validation and one-way analysis of variance. Interpretability is ensured using explainable artificial intelligence (AI) methods, local interpretable model-agnostic explanations and shapley additive explanations. RESULTS: Improvements are observed across all performance metrics: 3.45%, 5.75%, and 8.05% in accuracy, 3.45%, 6.90%, and 12.64% in precision, 4.65%, 5.81%, and 4.65% in recall, 4.65%, 6.98%, and 15.12% in F1-score, 1.04%, 2.08%, and 3.13% in receiver operating characteristic-area under the curve, 8.00%, 9.33%, and 17.33% in Matthews correlation coefficient, 12.16%, 13.51%, and 18.92% in Cohen\u2019s Kappa, and log loss reduction of 23.64%, 29.45%, and 45.82% across CRNet, optimized CRNet, and CRNet with UBS, respectively. CONCLUSION: The proposed 3-tier fusion framework enhances heart disease prediction by balancing data, optimizing parameters, and applying active learning to address labeled data scarcity. Explainable AI further improves transparency and supports real-world clinical adoption.",
      "authors": "Javed Aymin; Javaid Nadeem; Shafiq Muhammad; Choi Jin-Ghoo; Alrajeh Nabil",
      "year": "2026",
      "journal": "Journal of translational medicine",
      "doi": "10.1186/s12967-025-07292-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41491540/",
      "mesh_terms": "",
      "keywords": "Grasshopper optimization algorithm; Heart disease; K-fold cross validation; Local interpretable model-agnostic explanation; One-way analysis of variance; Over-sampling using the propensity score; Shapley additive explanations; Uncertainty-based sampling",
      "pub_types": "Journal Article",
      "pmcid": "PMC12777283"
    },
    {
      "pmid": "40605770",
      "title": "Limitations of Binary Classification for Long-Horizon Diagnosis Prediction and Advantages of a Discrete-Time Time-to-Event Approach: Empirical Analysis.",
      "abstract": "BACKGROUND: A major challenge in using electronic health records (EHR) is the inconsistency of patient follow-up, resulting in right-censored outcomes. This becomes particularly problematic in long-horizon event predictions, such as autism and attention-deficit/hyperactivity disorder (ADHD) diagnoses, where a significant number of patients are lost to follow-up before the outcome can be observed. Consequently, fully supervised methods such as binary classification (BC), which are trained to predict observed diagnoses, are substantially affected by the probability of sufficient follow-up, leading to biased results. OBJECTIVE: This empirical analysis aims to characterize BC's inherent limitations for long-horizon diagnosis prediction from EHR; and quantify the benefits of a specific time-to-event (TTE) approach, the discrete-time neural network (DTNN). METHODS: Records within the Duke University Health System EHR were analyzed, extracting features such as ICD-10 (International Classification of Diseases, Tenth Revision) diagnosis codes, medications, laboratories, and procedures. We compared a DTNN to 3 BC approaches and a deep Cox proportional hazards model across 4 clinical conditions to examine distributional patterns across various subgroups. Time-varying area under the receiving operating characteristic curve (AUCt) and time-varying average precision (APt) were our primary evaluation metrics. RESULTS: TTE models consistently had comparable or higher AUCt and APt than BC for all conditions. At clinically relevant operating time points, the area under the receiving operating characteristic curve (AUC) values for DTNNYOB\u22642020 (year-of-birth) and DCPHYOB\u22642020 (deep Cox proportional hazard) were 0.70 (95% CI 0.66-0.77) and 0.72 (95% CI 0.66-0.78) at t=5 for autism, 0.72 (95% CI 0.65-0.76) and 0.68 (95% CI 0.62-0.74) at t=7 for ADHD, 0.72 (95% CI 0.70-0.75) and 0.71 (95% CI 0.69-0.74) at t=1 for recurrent otitis media, and 0.74 (95% CI 0.68-0.82) and 0.71 (95% CI 0.63-0.77) at t=1 for food allergy, compared to 0.6 (95% CI 0.55-0.66), 0.47 (95% CI 0.40-0.54), 0.73 (95% CI 0.70-0.75), and 0.77 (95% CI 0.71-0.82) for BCYOB\u22642020, respectively. The probabilities predicted by BC models were positively correlated with censoring times, particularly for autism and ADHD prediction. Filtering strategies based on YOB or length of follow-up only partially corrected these biases. In subgroup analyses, only DTNN predicted diagnosis probabilities that accurately reflect actual clinical prevalence and temporal trends. CONCLUSIONS: BC models substantially underpredicted diagnosis likelihood and inappropriately assigned lower probability scores to individuals with earlier censoring. Common filtering strategies did not adequately address this limitation. TTE approaches, particularly DTNN, effectively mitigated bias from the censoring distribution, resulting in superior discrimination and calibration performance and more accurate prediction of clinical prevalence. Machine learning practitioners should recognize the limitations of BC for long-horizon diagnosis prediction and adopt TTE approaches. The DTNN in particular is well-suited to mitigate the effects of right-censoring and maximize prediction performance in this setting.",
      "authors": "Loh De Rong; Hill Elliot D; Liu Nan; Dawson Geraldine; Engelhard Matthew M",
      "year": "2025",
      "journal": "JMIR AI",
      "doi": "10.2196/62985",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40605770/",
      "mesh_terms": "",
      "keywords": "artificial intelligence; deep learning; distributional shifts; early detection; electronic health records; machine learning; practical models; predictive models; right-censoring; survival analysis",
      "pub_types": "Journal Article",
      "pmcid": "PMC12223692"
    },
    {
      "pmid": "41258169",
      "title": "Analytical and clinical validation of step counting method in people living with amyotrophic lateral sclerosis.",
      "abstract": "Accelerometer-based digital measures offer a scalable and low-burden means of quantifying physical function, but existing processing algorithms may not quantify pathological gait correctly. In people living with amyotrophic lateral sclerosis (ALS), where gait patterns are slow, variable, and asymmetric, validated tools to quantify mobility are urgently needed. We proposed a step-counting algorithm designed for ankle-worn accelerometers that leverage wavelet-based decomposition to quantify heel strikes under heterogeneous gait patterns. We validated this method using five datasets comprising healthy individuals and those with ALS in controlled and semi-controlled activities, and we performed clinical validation in a free-living cohort of 305 people with ALS. We tested our method for accuracy in detecting steps and recognizing walking activity. Reference labels used for analytical validation were obtained from annotated studies or video-based ground truth. Step counting accuracy was assessed using Bland-Altman analysis while clinical validity was evaluated by comparing step counts to gross motor functioning on the ALS Functional Rating Scale-Revised (ALSFRS-R). Walking recognition was robust across walking conditions and body types; sensitivity ranged from 0.94 to 0.98, and specificity exceeded 0.95 across all evaluated datasets. The mean step counting bias was minimal (e.g., 0.44 steps), and the 95% limits of agreement were narrow (LoA\u2009=\u2009[-5.90, 5.40]) relative to reference standards, including video-annotated ground truth. Clinical validation indicated substantial differences between groups with various levels of gait impairment, e.g., participants who reported \"walks with assist\" on the ALSFRS-R accumulated a mean of 1283 (95% CI 1063, 1503) steps/day, while those reporting \"normal\" walking covered 3984 (95% CI 3537, 4432) steps/day. Our study covered analytical and clinical validation of a step-counting method developed for ankle-worn accelerometers and demonstrated its applicability to pathological gait. The method provides accurate quantification of walking activity in controlled and free-living environments, supporting its use as a digital endpoint in ALS research.",
      "authors": "Straczkiewicz Marcin; Burke Katherine M; Carney Kendall T; Calcagno Narghes; Mandepudi Sravan; Premasiri Alan; Vieira Fernando G; Berry James D",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-24664-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41258169/",
      "mesh_terms": "Humans; Amyotrophic Lateral Sclerosis; Male; Female; Middle Aged; Walking; Gait; Accelerometry; Algorithms; Aged; Adult; Reproducibility of Results",
      "keywords": "ALSFRS-R; Assistive device; Digital Health Technologies; Gait; Motor neuron disease",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC12630758"
    },
    {
      "pmid": "40953056",
      "title": "Re-evaluating malarial retinopathy to improve its diagnostic accuracy in paediatric cerebral malaria: A retrospective study.",
      "abstract": "BACKGROUND: Previous work has identified that malarial retinopathy has diagnostic value in paediatric cerebral malaria (CM). To improve our understanding of malarial retinopathy as a predictor of cerebral parasite sequestration in paediatric CM we reviewed data from the Blantyre autopsy study, to test the hypothesis that malarial retinopathy is an accurate predictor of cerebral parasite sequestration in an autopsy cohort. METHODS AND FINDINGS: We performed a retrospective analysis of data collected from a consecutive series of patients presenting to the Pediatric Research Ward at Queen Elizabeth Central Hospital in Blantyre, Malawi between 1996 and 2010. We determined the diagnostic accuracy of malarial retinopathy as a predictor of cerebral parasite sequestration in a cohort of children with fatal CM. Of 84 children included in the study, 65 met the World Health Organization clinical diagnostic criteria for CM during life. Eighteen (28%) of 65 did not have evidence of cerebral parasite sequestration at autopsy and 17 had an alternative cause of death. Malarial retinopathy had a sensitivity of 89.4% (95% CI [77.6%, 95.6%]) and specificity of 73.0% (95% CI [57.2%, 84.8%]) to predict cerebral parasite sequestration. In a subset of patients with graded retinal assessments, this was improved to 94.3% (95% CI [81.7%, 98.7%]) and 88.0% (95% CI [70.4%, 96.2%]) by reclassifying patients in whom the only retinal sign was 1-5 haemorrhages in a single eye as retinopathy negative. This study is limited by its retrospective nature and the inherent selection bias associated with autopsy studies. CONCLUSIONS: Malarial retinopathy remains the most specific point-of-care test for CM in endemic areas. Its specificity may be improved, without sacrificing sensitivity, by reclassifying patients in whom the only retinal sign is fewer than 5 haemorrhages in a single eye as malarial retinopathy negative. A management algorithm is proposed for integration of malarial retinopathy into clinical care in both well-resourced and resource-limited environments.",
      "authors": "Wilson Kyle J; Muiruri Liomba Alice; Seydel Karl B; Banda Owen K; Moxon Christopher A; MacCormick Ian J C; Harding Simon P; Beare Nicholas A V; Taylor Terrie E",
      "year": "2025",
      "journal": "PLoS medicine",
      "doi": "10.1371/journal.pmed.1004727",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40953056/",
      "mesh_terms": "Humans; Malaria, Cerebral; Retrospective Studies; Child, Preschool; Male; Female; Infant; Child; Retinal Diseases; Malawi; Autopsy; Sensitivity and Specificity",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12445540"
    },
    {
      "pmid": "37637889",
      "title": "Identification of sources of DIF using covariates in patient-reported outcome measures: a simulation study comparing two approaches based on Rasch family models.",
      "abstract": "When analyzing patient-reported outcome (PRO) data, sources of differential item functioning (DIF) can be multiple and there may be more than one covariate of interest. Hence, it could be of great interest to disentangle their effects. Yet, in the literature on PRO measures, there are many studies where DIF detection is applied separately and independently for each covariate under examination. With such an approach, the covariates under investigation are not introduced together in the analysis, preventing from simultaneously studying their potential DIF effects on the questionnaire items. One issue, among others, is that it may lead to the detection of false-positive effects when covariates are correlated. To overcome this issue, we developed two new algorithms (namely ROSALI-DIF FORWARD and ROSALI-DIF BACKWARD). Our aim was to obtain an iterative item-by-item DIF detection method based on Rasch family models that enable to adjust group comparisons for DIF in presence of two binary covariates. Both algorithms were evaluated through a simulation study under various conditions aiming to be representative of health research contexts. The performance of the algorithms was assessed using: (i) the rates of false and correct detection of DIF, (ii) the DIF size and form recovery, and (iii) the bias in the latent variable level estimation. We compared the performance of the ROSALI-DIF algorithms to the one of another approach based on likelihood penalization. For both algorithms, the rate of false detection of DIF was close to 5%. The DIF size and form influenced the rates of correct detection of DIF. Rates of correct detection was higher with increasing DIF size. Besides, the algorithm fairly identified homogeneous differences in the item threshold parameters, but had more difficulties identifying non-homogeneous differences. Over all, the ROSALI-DIF algorithms performed better than the penalized likelihood approach. Integrating several covariates during the DIF detection process may allow a better assessment and understanding of DIF. This study provides valuable insights regarding the performance of different approaches that could be undertaken to fulfill this aim.",
      "authors": "Dubuy Yseulys; Hardouin Jean-Benoit; Blanchin Myriam; S\u00e9bille V\u00e9ronique",
      "year": "2023",
      "journal": "Frontiers in psychology",
      "doi": "10.3389/fpsyg.2023.1191107",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37637889/",
      "mesh_terms": "",
      "keywords": "LASSO; Rasch measurement theory (RMT); differential item functioning (DIF); measurement invariance (MI); patient-reported outcome (PRO); regularization",
      "pub_types": "Journal Article",
      "pmcid": "PMC10448192"
    },
    {
      "pmid": "32881112",
      "title": "Validating the eHealth Literacy Scale in Rural Adolescents.",
      "abstract": "PURPOSE: Given that the recent eHealth literacy literature supports the properties of the 3-factor eHealth literacy scale (eHEALS) model in samples with millennials, adults, and older adults, the appropriate next step is to establish whether the model can be reproduced in a rural adolescent sample. The purpose of this study was to evaluate the recent 3-factor model by Paige and associates with a sample of seventh-grade students. METHODS: This cross-sectional study included a subsample of students (n = 146) from 3 school districts in Appalachian Kentucky. We used confirmatory factor analysis (CFA) procedures and small sample model fit guidelines to evaluate our model, and the 1-sample bootstrap algorithm with bias-corrected and accelerated 95% confidence intervals to estimate associations among eHEALS and health and technology variables. FINDINGS: A total of 137 students, or 61% of enrolled seventh-grade students, completed the study. CFA results showed eHEALS 3-factor loadings-information awareness, information seeking, and information engagement-were high (\u22650.63) and statistically significant. We observed evidence of a good model fit (root mean square error of approximation [RMSEA] = 0.07, standardized root mean square residual [SRMR] = 0.03, comparative fit index [CFI] = 0.99) and results are comparable with Paige and associates' model fit (RMSEA = 0.06, SRMR = 0.08, CFI = 0.98). Correlations showed that students with more access to technology were associated with higher information seeking (r = 0.31) and higher information engagement (r = 0.23). eHealth literacy scores did not differ by level of rurality or gender. CONCLUSIONS: The 3-factor eHEALS is a reliable and valid instrument in assessing eHealth literacy in a group of rural seventh graders from Appalachian Kentucky.",
      "authors": "Giger Jarod T; Barnhart Sheila; Feltner Fran; Slone Melissa; Lawler Michael J; Windsor Leah; Windsor Alistair",
      "year": "2021",
      "journal": "The Journal of rural health : official journal of the American Rural Health Association and the National Rural Health Care Association",
      "doi": "10.1111/jrh.12509",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32881112/",
      "mesh_terms": "Adolescent; Aged; Cross-Sectional Studies; Health Literacy; Humans; Reproducibility of Results; Students; Surveys and Questionnaires; Telemedicine",
      "keywords": "confirmatory factor analysis; eHEALS; eHealth literacy scale; rural adolescents; technology use",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32871911",
      "title": "Unicondylar knee arthroplasty versus total knee arthroplasty in adults with isolated medial osteoarthritis: A matched study protocol.",
      "abstract": "BACKGROUND: The choice between unicondylar knee arthroplasty (UKA) and total knee arthroplasty (TKA) is likely to have long-term implications for patient-reported health outcomes. However, high-quality studies that compare the outcomes of TKA and UKA and their effects are still lacking in the literature. Thus, the aim of the present study was to compare the UKA and TKA techniques with regard to functional outcomes and perioperative complications in patients who had isolated medial osteoarthritis. METHODS: This was a retrospective, single-center, matched-controlled study performed with approval of our hospital (Kunshan hospital of Traditional Chinese Medicine affiliated to Nanjing University of Traditional Chinese Medicine), with the ethics number KZY2020-37. To reduce the effect of selection bias and potential confounding in this observational study, a 1:1 matching algorithm was applied. The groups were split by sex, age to within 6 years, and body mass index within 5\u200akg/m. Thus, we retrospectively reviewed the records of 240 consecutively enrolled patients who underwent UKA and 240 patients who underwent TKA from January 2013 to June 2015 from the database of our institution. Written informed consent was obtained from all subjects participating in the trial. Clinical outcomes included range of motion, Short Form 12 score, new Knee Society Score, Western Ontario and McMaster Universities Arthritis Index, and the complications. The outcome measures were evaluated by a physiotherapist and were assessed preoperatively and postoperatively at 6 months and 2 years. The mean follow-up time was 3 years. CONCLUSION: We hypothesized that there was no significant difference between the 2 groups in terms of postoperative outcomes. TRIAL REGISTRATION: Our study was registered in Research Registry (researchregistry5828).",
      "authors": "Yin Zifei; Qian Pingkang; Wu Xiaofeng; Gao Feng; Xu Feng",
      "year": "2020",
      "journal": "Medicine",
      "doi": "10.1097/MD.0000000000021868",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32871911/",
      "mesh_terms": "Adolescent; Adult; Aged; Aged, 80 and over; Arthroplasty, Replacement, Knee; China; Female; Humans; Male; Matched-Pair Analysis; Middle Aged; Observational Studies as Topic; Osteoarthritis, Knee; Patient Reported Outcome Measures; Range of Motion, Articular; Research Design; Retrospective Studies; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC7458234"
    },
    {
      "pmid": "31272232",
      "title": "Suicidal and self-harm presentations to Emergency Departments: The challenges of identification through diagnostic codes and presenting complaints.",
      "abstract": "BACKGROUND: The accuracy of data on suicide-related presentations to Emergency Departments (EDs) has implications for the provision of care and policy development, yet research on its validity is scarce. OBJECTIVE: To test the reliability of allocation of ICD-10 codes assigned to suicide and self-related presentations to EDs in Queensland, Australia. METHOD: All presentations due to suicide attempts, non-suicidal self-injury (NSSI) and suicidal ideation between 1 July 2017 and 31 December 2017 were reviewed. The number of presentations identified through relevant ICD-10-AM codes and presenting complaints in the Emergency Department Information System were compared to those identified through an application of an evolutionary algorithm and medical record review (gold standard). RESULTS: A total of 2540 relevant presentations were identified through the gold standard methodology. Great heterogeneity of ICD-10-AM codes and presenting complaints was observed for suicide attempts (40 diagnostic codes and 27 presenting complaints), NSSI (27 and 16, respectively) and suicidal ideation (38 and 34, respectively). Relevant ICD codes applied as primary or secondary diagnosis had very low sensitivity in detecting cases of suicide attempts (18.7%), NSSI (38.5%) and suicidal ideation (42.3%). A combination of ICD-10-AM code and a relevant presenting complaint increased specificity, however substantially reduced specificity and positive predictive values for all types of presentations. ED data showed bias in detecting higher percentages of suicide attempts by Indigenous persons (10.1% vs. 6.9%) or by cutting (28.1% vs. 10.3%), and NSSI by female presenters (76.4% vs. 67.4%). CONCLUSION: Suicidal and self-harm presentations are grossly under-enumerated in ED datasets and should be used with caution until a more standardised approach to their formulation and recording is implemented.",
      "authors": "Sveticic Jerneja; Stapelberg Nicholas Cj; Turner Kathryn",
      "year": "2020",
      "journal": "Health information management : journal of the Health Information Management Association of Australia",
      "doi": "10.1177/1833358319857188",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31272232/",
      "mesh_terms": "Adult; Algorithms; Clinical Coding; Data Accuracy; Emergency Service, Hospital; Female; Humans; International Classification of Diseases; Male; Queensland; Reproducibility of Results; Self-Injurious Behavior; Suicidal Ideation; Suicide, Attempted",
      "keywords": "ICD-10-AM; NSSI; clinical coding; data quality; depression; health information management; hospital information systems; non-suicidal self-injury; self-harm; self-injurious behavior; suicidal ideation; suicide; suicide attempted",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41224483",
      "title": "Computerised adaptive testing across the paranoia continuum.",
      "abstract": "BACKGROUND: To drive improvement in clinical services, an important innovation will be to regularly assess patients' psychotic experiences in order to guide, monitor and, when needed, alter treatment provision. The great heterogeneity in presentations of psychosis means that a comprehensive assessment battery is impractical. A plausible solution is computerised adaptive testing (CAT), which uses real-time computation to present the most informative questions to an individual. Fewer questions are needed to reach similar precision as a full questionnaire. OBJECTIVE: We tested the potential of a CAT for paranoia to halve the number of items that need to be presented. METHODS: We used the established item response theory psychometric properties of the 10-item Revised Green et al Paranoid Thoughts Scale (Persecution) to run CAT simulations in four datasets in which participants had completed the full scale: a representative survey of 10 382 UK adults; a clinical trial with 319 patients with psychosis; a cohort study of 836 National Health Service (NHS) male patients with psychosis; and a clinical trial with 89 patients with persecutory delusions. The CAT algorithm used the graded response model and the test was concluded when the SE of estimation dropped below 0.3 or five items had been answered. FINDINGS: On average, the CAT administered 4.2, 4.0, 4.2 and 4.0 items to each person in the four datasets. The correlations between the CAT score and the full-scale paranoia score were 0.95, 0.94, 0.94 and 0.87. Minimal systematic error in paranoia estimation occurred (mean bias scores=-0.01, -0.06, -0.07 to -0.10). Estimation was the least precise for people at the boundary of normal and elevated levels of paranoia. CONCLUSIONS: In datasets with people across the whole paranoia continuum, accurate estimates of paranoia can be provided by a CAT with fewer than half the items of the full scale. Tailored testing may work well with people with psychosis. CLINICAL IMPLICATIONS: CAT may be a way to implement informative measurement-based care in psychosis services.",
      "authors": "Freeman Daniel; Lambe Sin\u00e9ad; Waite Felicity; Rosebrock Laina; Morrison Anthony; Chapman Kate; Dudley Robert; Common Stephanie; Jones Julia; Kabir Thomas; Beckley Ariane; Westgate Verity; Rouse Natalie; Loe Bao Sheng",
      "year": "2025",
      "journal": "BMJ mental health",
      "doi": "10.1136/bmjment-2025-302099",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41224483/",
      "mesh_terms": "Humans; Paranoid Disorders; Male; Adult; Psychometrics; Diagnosis, Computer-Assisted; Middle Aged; Female; Psychotic Disorders; Young Adult; Psychiatric Status Rating Scales",
      "keywords": "Paranoid Disorders; Psychological Tests; Psychotic Disorders; Schizophrenia",
      "pub_types": "Journal Article",
      "pmcid": "PMC12612754"
    },
    {
      "pmid": "38542766",
      "title": "The Effectiveness of Artificial Intelligence in Assisting Mothers with Assessing Infant Stool Consistency in a Breastfeeding Cohort Study in China.",
      "abstract": "Breastfeeding is widely recognized as the gold standard for infant nutrition, benefitting infants' gastrointestinal tracts. Stool analysis helps in understanding pediatric gastrointestinal health, but the effectiveness of automated fecal consistency evaluation by parents of breastfeeding infants has not been investigated. Photographs of one-month-old infants' feces on diapers were taken via a smartphone app and independently categorized by Artificial Intelligence (AI), parents, and researchers. The accuracy of the evaluations of the AI and the parents was assessed and compared. The factors contributing to assessment bias and app user characteristics were also explored. A total of 98 mother-infant pairs contributed 905 fecal images, 94.0% of which were identified as loose feces. AI and standard scores agreed in 95.8% of cases, demonstrating good agreement (intraclass correlation coefficient (ICC) = 0.782, Kendall's coefficient of concordance W (Kendall's W) = 0.840, Kendall's tau = 0.690), whereas only 66.9% of parental scores agreed with standard scores, demonstrating low agreement (ICC = 0.070, Kendall's W = 0.523, Kendall's tau = 0.058). The more often a mother had one or more of the following characteristics, unemployment, education level of junior college or below, cesarean section, and risk for postpartum depression (PPD), the more her appraisal tended to be inaccurate (p < 0.05). Each point increase in the Edinburgh Postnatal Depression Scale (EPDS) score increased the deviation by 0.023 points (p < 0.05), which was significant only in employed or cesarean section mothers (p < 0.05). An AI-based stool evaluation service has the potential to assist mothers in assessing infant stool consistency by providing an accurate, automated, and objective assessment, thereby helping to monitor and ensure the well-being of infants.",
      "authors": "Wu Jieshu; Dong Linjing; Sun Yating; Zhao Xianfeng; Gan Junai; Wang Zhixu",
      "year": "2024",
      "journal": "Nutrients",
      "doi": "10.3390/nu16060855",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38542766/",
      "mesh_terms": "Humans; Infant; Child; Female; Pregnancy; Mothers; Breast Feeding; Cohort Studies; Artificial Intelligence; Cesarean Section; China",
      "keywords": "CNN algorithm; breastfed infants; postpartum depression status; stool consistency",
      "pub_types": "Journal Article",
      "pmcid": "PMC10975400"
    },
    {
      "pmid": "25431630",
      "title": "Traffic-related pollution and asthma prevalence in children. Quantification of associations with nitrogen dioxide.",
      "abstract": "Ambient nitrogen dioxide is a widely available measure of traffic-related air pollution and is inconsistently associated with the prevalence of asthma symptoms in children. The use of this relationship to evaluate the health impact of policies affecting traffic management and traffic emissions is limited by the lack of a concentration-response function based on systematic review and meta-analysis of relevant studies. Using systematic methods, we identified papers containing quantitative estimates for nitrogen dioxide and the 12\u00a0month period prevalence of asthma symptoms in children in which the exposure contrast was within-community and dominated by traffic pollution. One estimate was selected from each study according to an a priori algorithm. Odds ratios were standardised to 10\u00a0\u03bcg/m3 and summary estimates were obtained using random- and fixed-effects estimates. Eighteen studies were identified. Concentrations of nitrogen dioxide were estimated for the home address (12) and/or school (8) using a range of methods; land use regression (6), study monitors (6), dispersion modelling (4) and interpolation (2). Fourteen studies showed positive associations but only two associations were statistically significant at the 5\u00a0% level. There was moderate heterogeneity (I2\u2009=\u200932.8\u00a0%) and the random-effects estimate for the odds ratio was 1.06 (95\u00a0% CI 1.00 to 1.11). There was no evidence of small study bias. Individual studies tended to have only weak positive associations between nitrogen dioxide and asthma prevalence but the summary estimate bordered on statistical significance at the 5\u00a0% level. Although small, the potential impact on asthma prevalence could be considerable because of the high level of baseline prevalence in many cities. Whether the association is causal or indicates the effects of a correlated pollutant or other confounders, the estimate obtained by the meta-analysis would be appropriate for estimating impacts of traffic pollution on asthma prevalence.",
      "authors": "Favarato Graziella; Anderson H Ross; Atkinson Richard; Fuller Gary; Mills Inga; Walton Heather",
      "year": "2014",
      "journal": "Air quality, atmosphere, & health",
      "doi": "10.1007/s11869-014-0265-8",
      "url": "https://pubmed.ncbi.nlm.nih.gov/25431630/",
      "mesh_terms": "",
      "keywords": "Air Pollution; Asthma prevalence; Meta-analysis; Review; Traffic",
      "pub_types": "Journal Article",
      "pmcid": "PMC4239711"
    },
    {
      "pmid": "34980049",
      "title": "Variability of respiratory rate measurements in neonates- every minute counts.",
      "abstract": "BACKGROUND: Respiratory rate is difficult to measure, especially in neonates who have an irregular breathing pattern. The World Health Organisation recommends a one-minute count, but there is limited data to support this length of observation. We sought to evaluate agreement between the respiratory rate (RR) derived from capnography in neonates, over 15\u2009s, 30\u2009s, 120\u2009s and 300\u2009s, against the recommended 60\u2009s. METHODS: Neonates at two hospitals in Nairobi were recruited and had capnograph waveforms recorded using the Masimo Rad 97. A single high quality 5\u2009min epoch was randomly chosen from each subject. For each selected epoch, the mean RR was calculated using a breath-detection algorithm applied to the waveform. The RR in the first 60\u2009s was compared to the mean RR measured over the first 15\u2009s, 30\u2009s, 120\u2009s, full 300\u2009s, and last 60\u2009s. We calculated bias and limits of agreement for each comparison and used Bland-Altman plots for visual comparisons. RESULTS: A total of 306 capnographs were analysed from individual subjects. The subjects had a median gestation age of 39\u2009weeks with slightly more females (52.3%) than males (47.7%). The majority of the population were term neonates (70.1%) with 39 (12.8%) having a primary respiratory pathology. There was poor agreement between all the comparisons based on the limits of agreement [confidence interval], ranging between 11.9 [-\u20096.79 to 6.23] breaths per minute in the one versus 2 min comparison, and 34.7 [-\u200917.59 to 20.53] breaths per minute in the first versus last minute comparison. Worsening agreement was observed in plots with higher RRs. CONCLUSIONS: Neonates have high variability of RR, even over a short period of time. A slight degradation in the agreement is noted over periods shorter than 1 min. However, this is smaller than observations done 3 min apart in the same subject. Longer periods of observation also reduce agreement. For device developers, precise synchronization is needed when comparing devices to reduce the impact of RR variation. For clinicians, where possible, continuous or repeated monitoring of neonates would be preferable to one time RR measurements.",
      "authors": "Njeru Catherine Muthoni; Ansermino J Mark; Macharia William M; Dunsmuir Dustin T",
      "year": "2022",
      "journal": "BMC pediatrics",
      "doi": "10.1186/s12887-021-03087-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34980049/",
      "mesh_terms": "Capnography; Female; Humans; Infant; Infant, Newborn; Kenya; Male; Respiratory Rate; Time Factors",
      "keywords": "Neonates; Respiratory rate measurement; Variability",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8722355"
    },
    {
      "pmid": "28017360",
      "title": "Estimation of daily PM10 concentrations in Italy (2006-2012) using finely resolved satellite data, land use variables and meteorology.",
      "abstract": "Health effects of air pollution, especially particulate matter (PM), have been widely investigated. However, most of the studies rely on few monitors located in urban areas for short-term assessments, or land use/dispersion modelling for long-term evaluations, again mostly in cities. Recently, the availability of finely resolved satellite data provides an opportunity to estimate daily concentrations of air pollutants over wide spatio-temporal domains. Italy lacks a robust and validated high resolution spatio-temporally resolved model of particulate matter. The complex topography and the air mixture from both natural and anthropogenic sources are great challenges difficult to be addressed. We combined finely resolved data on Aerosol Optical Depth (AOD) from the Multi-Angle Implementation of Atmospheric Correction (MAIAC) algorithm, ground-level PM10 measurements, land-use variables and meteorological parameters into a four-stage mixed model framework to derive estimates of daily PM10 concentrations at 1-km2 grid over Italy, for the years 2006-2012. We checked performance of our models by applying 10-fold cross-validation (CV) for each year. Our models displayed good fitting, with mean CV-R2=0.65 and little bias (average slope of predicted VS observed PM10=0.99). Out-of-sample predictions were more accurate in Northern Italy (Po valley) and large conurbations (e.g. Rome), for background monitoring stations, and in the winter season. Resulting concentration maps showed highest average PM10 levels in specific areas (Po river valley, main industrial and metropolitan areas) with decreasing trends over time. Our daily predictions of PM10 concentrations across the whole Italy will allow, for the first time, estimation of long-term and short-term effects of air pollution nationwide, even in areas lacking monitoring data.",
      "authors": "Stafoggia Massimo; Schwartz Joel; Badaloni Chiara; Bellander Tom; Alessandrini Ester; Cattani Giorgio; De' Donato Francesca; Gaeta Alessandra; Leone Gianluca; Lyapustin Alexei; Sorek-Hamer Meytar; de Hoogh Kees; Di Qian; Forastiere Francesco; Kloog Itai",
      "year": "2017",
      "journal": "Environment international",
      "doi": "10.1016/j.envint.2016.11.024",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28017360/",
      "mesh_terms": "Air Pollutants; Air Pollution; Environmental Exposure; Environmental Monitoring; Humans; Italy; Meteorological Concepts; Particulate Matter; Rural Population; Seasons; Spacecraft; Urban Population",
      "keywords": "Aerosol Optical Depth; Air pollution; Epidemiology; Exposure assessment; Particulate matter; Satellite",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "16297792",
      "title": "Prediction of cyclosporine blood levels in heart transplantation patients using a pharmacokinetic model identified by evolutionary algorithms.",
      "abstract": "BACKGROUND: Artificial intelligence (AI)-based computation methods have been recently shown to be applicable in several clinical diagnostic fields. The purpose of this study was to introduce a novel AI method called evolutionary algorithms (EAs) to clinical predictions. The technique was used to create a pharmacokinetic model for the prediction of whole blood levels of cyclosporine (CyA). METHODS: One hundred one adult cardiac transplant recipients were randomly selected and included in this study. All patients had been receiving oral cyclosporine twice daily, and the trough levels in whole blood were measured by monoclonal-specific radioimmunoassay. An evolutionary algorithm (EA)-based software tool was trained with pre- and post-operative variables from 64 patients. The results of this process were then tested on data sets from 37 patients. RESULTS: The mean value of the predicted CyA level throughout the measurement period for the test data was 175 +/- 27 ng/ml, which compared well with the mean observed CyA level of 180 +/- 31 ng/ml. The system bias expressed as the mean percent error (MPE) for the training and test data sets were 7.1 +/- 5.4% (0.1% to 26.7%) and 8.0 +/- 6.7% (0.8% to 28.8%), respectively. The prediction accuracy ranged from 80% to 90%. The correlation coefficient between predicted and observed CyA concentration for the training data were 0.93 (p < 0.001) and for the test data were 0.85 (p < 0.001), respectively. CONCLUSIONS: The results of this study suggest that the use of evolutionary algorithms to identify pharmacokinetic models yields accurate prediction of cyclosporine whole blood levels in heart transplant recipients. This and other similar technologies should be considered as future clinical tools to reduce costs in our health systems.",
      "authors": "Hoda M Raschid; Grimm Michael; Laufer Guenther",
      "year": "2005",
      "journal": "The Journal of heart and lung transplantation : the official publication of the International Society for Heart Transplantation",
      "doi": "10.1016/j.healun.2005.02.021",
      "url": "https://pubmed.ncbi.nlm.nih.gov/16297792/",
      "mesh_terms": "Adult; Aged; Algorithms; Artificial Intelligence; Cyclosporine; Female; Heart Transplantation; Humans; Male; Middle Aged; Predictive Value of Tests; Transcription, Genetic",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38079535",
      "title": "Single-lead electrocardiogram Artificial Intelligence model with risk factors detects atrial fibrillation during sinus rhythm.",
      "abstract": "AIMS: Guidelines recommend opportunistic screening for atrial fibrillation (AF), using a 30\u2005s single-lead electrocardiogram (ECG) recorded by a wearable device. Since many patients have paroxysmal AF, identification of patients at high risk presenting with sinus rhythm (SR) may increase the yield of subsequent long-term cardiac monitoring. The aim is to evaluate an AI-algorithm trained on 10\u2005s single-lead ECG with or without risk factors to predict AF. METHODS AND RESULTS: This retrospective study used 13 479 ECGs from AF patients in SR around the time of diagnosis and 53 916 age- and sex-matched control ECGs, augmented with 17 risk factors extracted from electronic health records. AI models were trained and compared using 1- or 12-lead ECGs, with or without risk factors. Model bias was evaluated by age- and sex-stratification of results. Random forest models identified the most relevant risk factors. The single-lead model achieved an area under the curve of 0.74, which increased to 0.76 by adding six risk factors (95% confidence interval: 0.74-0.79). This model matched the performance of a 12-lead model. Results are stable for both sexes, over ages ranging from 40 to 90 years. Out of 17 clinical variables, 6 were sufficient for optimal accuracy of the model: hypertension, heart failure, valvular disease, history of myocardial infarction, age, and sex. CONCLUSION: An AI model using a single-lead SR ECG and six risk factors can identify patients with concurrent AF with similar accuracy as a 12-lead ECG-AI model. An age- and sex-matched data set leads to an unbiased model with consistent predictions across age groups.",
      "authors": "Dupulthys Stijn; Dujardin Karl; Ann\u00e9 Wim; Pollet Peter; Vanhaverbeke Maarten; McAuliffe David; Lammertyn Pieter-Jan; Berteloot Louise; Mertens Nathalie; De Jaeger Peter",
      "year": "2024",
      "journal": "Europace : European pacing, arrhythmias, and cardiac electrophysiology : journal of the working groups on cardiac pacing, arrhythmias, and cardiac cellular electrophysiology of the European Society of Cardiology",
      "doi": "10.1093/europace/euad354",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38079535/",
      "mesh_terms": "Male; Female; Humans; Atrial Fibrillation; Artificial Intelligence; Retrospective Studies; Electrocardiography; Risk Factors",
      "keywords": "Artificial intelligence; Atrial fibrillation; Screening; Single-lead ECG; Sinus rhythm",
      "pub_types": "Journal Article",
      "pmcid": "PMC10872711"
    },
    {
      "pmid": "35811720",
      "title": "Clinical Validation of Automated Corrected QT-Interval Measurements From a Single Lead Electrocardiogram Using a Novel Smartwatch.",
      "abstract": "INTRODUCTION: The Withings Scanwatch (Withings SA, Issy les Moulineaux, France) offers automated analysis of the QTc. We aimed to compare automated QTc-measurements using a single lead ECG of a novel smartwatch (Withings Scanwatch, SW-ECG) with manual-measured QTc from a nearly simultaneously recorded 12-lead ECG. METHODS: We enrolled consecutive patients referred to a tertiary hospital for cardiac workup in a prospective, observational study. The QT-interval of the 12-lead ECG was manually interpreted by two blinded, independent cardiologists through the tangent-method. Bazett's formula was used to calculate QTc. Results were compared using the Bland-Altman method. RESULTS: A total of 317 patients (48% female, mean age 63 \u00b1 17 years) were enrolled. HR-, QRS-, and QT-intervals were automatically calculated by the SW in 295 (93%), 249 (79%), and 177 patients (56%), respectively. Diagnostic accuracy of SW-ECG for detection of QTc-intervals \u2265 460 ms (women) and \u2265 440 ms (men) as quantified by the area under the curve was 0.91 and 0.89. The Bland-Altman analysis resulted in a bias of 6.6 ms [95% limit of agreement (LoA) -59 to 72 ms] comparing automated QTc-measurements (SW-ECG) with manual QTc-measurement (12-lead ECG). In 12 patients (6.9%) the difference between the two measurements was greater than the LoA. CONCLUSION: In this clinical validation of a direct-to-consumer smartwatch we found fair to good agreement between automated-SW-ECG QTc-measurements and manual 12-lead-QTc measurements. The SW-ECG was able to automatically calculate QTc-intervals in one half of all assessed patients. Our work shows, that the automated algorithm of the SW-ECG needs improvement to be useful in a clinical setting.",
      "authors": "Mannhart Diego; Hennings Elisa; Lischer Mirko; Vernier Claudius; Du Fay de Lavallaz Jeanne; Knecht Sven; Schaer Beat; Osswald Stefan; K\u00fchne Michael; Sticherling Christian; Badertscher Patrick",
      "year": "2022",
      "journal": "Frontiers in cardiovascular medicine",
      "doi": "10.3389/fcvm.2022.906079",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35811720/",
      "mesh_terms": "",
      "keywords": "QTc; artificial intelligence; digital health; intelligent ECG; remote patient monitoring (RPM); single-lead ECG; smartwatch",
      "pub_types": "Journal Article",
      "pmcid": "PMC9259864"
    },
    {
      "pmid": "39732668",
      "title": "The aluminum standard: using generative Artificial Intelligence tools to synthesize and annotate non-structured patient data.",
      "abstract": "BACKGROUND: Medical narratives are fundamental to the correct identification of a patient's health condition. This is not only because it describes the patient's situation. It also contains relevant information about the patient's context and health state evolution. Narratives are usually vague and cannot be categorized easily. On the other hand, once the patient's situation is correctly identified based on a narrative, it is then possible to map the patient's situation into precise classification schemas and ontologies that are machine-readable. To this end, language models can be trained to read and extract elements from these narratives. However, the main problem is the lack of data for model identification and model training in languages other than English. First, gold standard annotations are usually not available due to the high level of data protection for patient data. Second, gold standard annotations (if available) are difficult to access. Alternative available data, like MIMIC (Sci Data 3:1, 2016) is written in English and for specific patient conditions like intensive care. Thus, when model training is required for other types of patients, like oncology (and not intensive care), this could lead to bias. To facilitate clinical narrative model training, a method for creating high-quality synthetic narratives is needed. METHOD: We devised workflows based on generative AI methods to synthesize narratives in the German language to avoid the disclosure of patient's health data. Since we required highly realistic narratives, we generated prompts, written with high-quality medical terminology, asking for clinical narratives containing both a main and co-disease. The frequency of distribution of both the main and co-disease was extracted from the hospital's structured data, such that the synthetic narratives reflect the disease distribution among the patient's cohort. In order to validate the quality of the synthetic narratives, we annotated them to train a Named Entity Recognition (NER) algorithm. According to our assumptions, the validation of this system implies that the synthesized data used for its training are of acceptable quality. RESULT: We report precision, recall and F1 score for the NER model while also considering metrics that take into account both exact and partial entity matches. Trained models are cautious, with a precision up to 0.8 for Entity Type match metric and a F1 score of 0.3. CONCLUSION: Despite its inherent limitations, this technology has the potential to allow data interoperability by using encoded diseases across languages and regions without compromising data safety. Additionally, it facilitates the synthesis of unstructured patient data. In this way, the identification and training of models can be accelerated. We believe that this method may be able to generate discharge letters for any combination of main and co-diseases, which will significantly reduce the amount of time spent writing these letters by healthcare professionals.",
      "authors": "Diaz Ochoa Juan G; Mustafa Faizan E; Weil Felix; Wang Yi; Kama Kudret; Knott Markus",
      "year": "2024",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-024-02825-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39732668/",
      "mesh_terms": "Humans; Artificial Intelligence; Natural Language Processing; Narration",
      "keywords": "Generative AI; Language models; Non-english Language models; Synthetic data; Synthetic narratives",
      "pub_types": "Journal Article",
      "pmcid": "PMC11681671"
    },
    {
      "pmid": "41408068",
      "title": "Quality and accuracy of scoliosis-related short videos on TikTok reviewed in China in August 2025.",
      "abstract": "Scoliosis is a common spinal disorder that affects 2-4% of adolescents worldwide. With the rise of short-video platforms like TikTok, they have increasingly played a significant role in health information dissemination. However, the quality and accuracy of scoliosis-related video content on these platforms have not been thoroughly studied. The objective of this study was to assess the accuracy and quality of scoliosis-related videos on TikTok. Using a cross-sectional design and a newly created TikTok account with cleared cache to minimize bias, we retrieved the platform's top 100 scoliosis-related short videos via its default sorting algorithm on August 17, 2025. Two independent reviewers with backgrounds in orthopedic surgery and health-information assessment extracted basic data and evaluated each video's quality and accuracy with the Global Quality Score (GQS, 1-5), modified DISCERN (0-5), and JAMA (0-4). Bivariate associations used Spearman's rank correlation; multivariable associations used a proportional-odds ordinal logistic model with GQS as the outcome. A total of 95 videos were included in the analysis. 5 videos were excluded due to language mismatch, redundancy, or commercial content. Video duration was median 60\u00a0s (IQR 45-87). The median number of views was 8109 (IQR 2112-33,856). Professional individuals accounted for 63.8% of the uploaded videos, while non-professional individuals contributed 33.0%. The median GQS for professional videos was 3, while for non-professional videos it was 2. The video content primarily focused on treatment (68.1%), with less emphasis on diagnosis (16%) and prevention (8.5%). The videos exhibited moderate overall quality, with median scores of 3 for GQS and mDISCERN, and 2 for JAMA, with IQRs of 2-4, 2-3, and 1-2, respectively. Videos uploaded by professional individuals had higher quality and accuracy scores. Fans correlated with mDISCERN and JAMA scores (r\u2009=\u20090.241, P\u2009=\u20090.017 and r\u2009=\u20090.275, P\u2009=\u20090.005, respectively). In the multivariable model, collections (OR\u2009=\u20094.287, 95% CI 1.313-13.989) and duration (OR\u2009=\u20092.664, 95% CI 1.370-5.182) were associated with higher GQS, whereas patient as the uploader identity (OR\u2009=\u20090.064, 95% CI 0.007-0.621) and prognosis content (OR\u2009=\u20090.052, 95% CI 0.005-0.555) were associated with lower GQS. The quality and accuracy of scoliosis-related short videos on TikTok are generally low, with lower quality and accuracy scores for non-professionals.. The main problems are lack of professional review, misleading information, and emphasis on treatment rather than prevention. It is recommended that the public exercise caution when browsing health information on short-video platforms, and that medical professionals provide higher-quality educational content. This study provides a basis for the regulation and optimization of health information on short-video platforms.",
      "authors": "Zhou Qinxin; Shen Jianzeng; Cao Dongdong; Yu Weijie; Chen Jixin",
      "year": "2025",
      "journal": "Scientific reports",
      "doi": "10.1038/s41598-025-27684-5",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41408068/",
      "mesh_terms": "Scoliosis; Humans; Video Recording; China; Cross-Sectional Studies; Adolescent; Information Dissemination",
      "keywords": "Accuracy; Quality; Scoliosis; Short videos; TikTok",
      "pub_types": "Journal Article",
      "pmcid": "PMC12711883"
    },
    {
      "pmid": "36857960",
      "title": "Sex-specific equations to estimate body composition: Derivation and validation of diagnostic prediction models using UK Biobank.",
      "abstract": "BACKGROUND & AIMS: Body mass index and waist circumference are simple measures of obesity. However, they do not distinguish between visceral and subcutaneous fat, or muscle, potentially leading to biased relationships between individual body composition parameters and adverse health outcomes. The purpose of this study was to develop and validate prediction models for volumetric adipose and muscle. METHODS: Based on cross-sectional data of 18,457, 18,260, and 17,052 White adults from the UK Biobank, we developed sex-specific equations to estimate visceral adipose tissue (VAT), abdominal subcutaneous adipose tissue (ASAT), and total thigh fat-free muscle (FFM) volumes, respectively. Volumetric magnetic resonance imaging served as the reference. We used the least absolute shrinkage and selection operator and the extreme gradient boosting methods separately to fit three sequential models, the inputs of which included demographics and anthropometrics and, in some, bioelectrical impedance analysis parameters. We applied comprehensive metrics to assess model performance in the temporal validation set. RESULTS: The equations that included more predictors generally performed better. Accuracy of the equations was moderate for VAT (percentage of estimates that differed <30% from the measured values, 70 to 78 in males, 64 to 69 in females) and good for ASAT (85 to 91 in males, 90 to 95 in females) and FFM (99 to 100 in both sexes). All the equations appeared precise (interquartile range of the difference, 0.89 to 1.76\u00a0L for VAT, 1.16 to 1.61\u00a0L for ASAT, 0.81 to 1.39\u00a0L for FFM). Bias of all the equations was negligible (-0.17 to 0.05\u00a0L for VAT,\u00a0-0.10 to 0.12\u00a0L for ASAT,\u00a0-0.07 to 0.09\u00a0L for FFM). The equations achieved superior cardiometabolic correlations compared with body mass index and waist circumference. CONCLUSIONS: The developed equations to estimate VAT, ASAT, and FFM volumes achieved moderate to good performance. They may be cost-effective tools to revisit the implications of diverse body components.",
      "authors": "Lu Yueqi; Shan Ying; Dai Liang; Jiang Xiaosen; Song Congying; Chen Bangwei; Zhang Jingwen; Li Jing; Zhang Yue; Xu Junjie; Li Tao; Xiong Zuying; Bai Yong; Huang Xiaoyan",
      "year": "2023",
      "journal": "Clinical nutrition (Edinburgh, Scotland)",
      "doi": "10.1016/j.clnu.2023.02.005",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36857960/",
      "mesh_terms": "Adult; Male; Female; Humans; Cross-Sectional Studies; Biological Specimen Banks; Body Composition; Obesity; Body Mass Index; Subcutaneous Fat, Abdominal; United Kingdom",
      "keywords": "Abdominal subcutaneous adipose tissue; Machine learning; Prediction model; Total thigh fat-free muscle; Visceral adipose tissue; Volumetric magnetic resonance imaging",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "32405246",
      "title": "Ensemble averaging based assessment of spatiotemporal variations in ambient PM2.5 concentrations over Delhi, India, during 2010-2016.",
      "abstract": "Elevated levels of ambient air pollution has been implicated as a major risk factor for morbidities and premature mortality in India, with particularly high concentrations of particulate matter in the Indo-Gangetic plain. High resolution spatiotemporal estimates of such exposures are critical to assess health effects at an individual level. This article retrospectively assesses daily average PM2.5 exposure at 1 km \u00d7 1 km grids in Delhi, India from 2010-2016, using multiple data sources and ensemble averaging approaches. We used a multi-stage modeling exercise involving satellite data, land use variables, reanalysis based meteorological variables and population density. A calibration regression was used to model PM2.5: PM10 to counter the sparsity of ground monitoring data. The relationship between PM2.5 and its spatiotemporal predictors was modeled using six learners; generalized additive models, elastic net, support vector regressions, random forests, neural networks and extreme gradient boosting. Subsequently, these predictions were combined under a generalized additive model framework using a tensor product based spatial smoothing. Overall cross-validated prediction accuracy of the model was 80% over the study period with high spatial model accuracy and predicted annual average concentrations ranging from 87 to 138 \u03bcg/m3. Annual average root mean squared errors for the ensemble averaged predictions were in the range 39.7-62.7 \u03bcg/m3 with prediction bias ranging between 4.6-11.2 \u03bcg/m3. In addition, tree based learners such as random forests and extreme gradient boosting outperformed other algorithms. Our findings indicate important seasonal and geographical differences in particulate matter concentrations within Delhi over a significant period of time, with meteorological and land use features that discriminate most and least polluted regions. This exposure assessment can be used to estimate dose response relationships more accurately over a wide range of particulate matter concentrations.",
      "authors": "Mandal Siddhartha; Madhipatla Kishore K; Guttikunda Sarath; Kloog Itai; Prabhakaran Dorairaj; Schwartz Joel D",
      "year": "2020",
      "journal": "Atmospheric environment (Oxford, England : 1994)",
      "doi": "10.1016/j.atmosenv.2020.117309",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32405246/",
      "mesh_terms": "",
      "keywords": "Hybrid models; Machine learning; Particulate matter; Pollution exposure; Satellite observations",
      "pub_types": "Journal Article",
      "pmcid": "PMC7219795"
    },
    {
      "pmid": "41004181",
      "title": "Benefit-Risk Reporting for FDA-Cleared Artificial Intelligence-Enabled Medical Devices.",
      "abstract": "IMPORTANCE: Devices enabled by artificial intelligence (AI) and machine learning (ML) are increasingly used in clinical settings, but there are concerns regarding benefit-risk assessment and surveillance by the US Food and Drug Administration (FDA). OBJECTIVE: To characterize pre- and postmarket efficacy, safety, and risk assessment reporting for FDA-cleared AI/ML devices. DESIGN AND SETTING: This was a cross-sectional study using linked data from FDA decision summaries and approvals databases, the FDA Manufacturer and User Facility Device Experience Database, and the FDA Medical Device Recalls Database for all AI/ML devices cleared by the FDA from September 1995 to July 2023. Data were analyzed from October to November 2024. MAIN OUTCOMES AND MEASURES: AI/ML reporting of study design, data availability, efficacy, safety, bias assessments, adverse events, device recalls, and risk classification. RESULTS: The analysis included data for all 691 AI/ML devices that received FDA clearance through 2023, with 254 (36.8%) cleared in or after 2021. Device summaries often failed to report study designs (323 [46.7%]), training sample size (368 [53.3%]), and/or demographic information (660 [95.5%]). Only 6 devices (1.6%) reported data from randomized clinical trials and 53 (7.7%) from prospective studies. Few premarket summaries contained data published in peer-reviewed journals (272 [39.4%]) or provided statistical or clinical performance, including sensitivity (166 [24.0%]), specificity (152 [22.0%]), and/or patient outcomes (3 [<1%]). Some devices reported safety assessments (195 [28.2%]), adherence to international safety standards (344 [49.8%]), and/or risks to health (42 [6.1%]). In all, 489 adverse events were reported involving 36 (5.2%) devices, including 458 malfunctions, 30 injuries, and 1 death. A total of 40 devices (5.8%) were recalled 113 times, primarily due to software issues. CONCLUSIONS AND RELEVANCE: This cross-sectional study suggests that despite increasing clearance of AI/ML devices, standardized efficacy, safety, and risk assessment by the FDA are lacking. Dedicated regulatory pathways and postmarket surveillance of AI/ML safety events may address these challenges.",
      "authors": "Lin John C; Jain Bhav; Iyer Jay M; Rola Ishan; Srinivasan Anusha R; Kang Chaerim; Patel Heta; Parikh Ravi B",
      "year": "2025",
      "journal": "JAMA health forum",
      "doi": "10.1001/jamahealthforum.2025.3351",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41004181/",
      "mesh_terms": "United States; United States Food and Drug Administration; Cross-Sectional Studies; Humans; Artificial Intelligence; Device Approval; Risk Assessment; Product Surveillance, Postmarketing; Machine Learning; Equipment and Supplies; Equipment Safety",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12475944"
    },
    {
      "pmid": "40742180",
      "title": "Metagenomic estimation of absolute bacterial biomass in the mammalian gut through host-derived read normalization.",
      "abstract": "Absolute bacterial biomass estimation in the human gut is crucial for understanding microbiome dynamics and host-microbe interactions. Current methods for quantifying bacterial biomass in stool, such as flow cytometry, quantitative polymerase chain reaction (qPCR), or spike-ins, can be labor-intensive, costly, and confounded by factors like water content, DNA extraction efficiency, PCR inhibitors, and other technical challenges that add bias and noise. We propose a simple, cost-effective approach that circumvents some of these technical challenges: directly estimating bacterial biomass from metagenomes using bacterial-to-host (B:H) read count ratios. We compared B:H ratios to the standard methods outlined above, demonstrating that B:H ratios are useful proxies for bacterial biomass in stool and possibly in other host-associated substrates. B:H ratios in stool were correlated with bacterial-to-diet (B:D) read count ratios, but B:D ratios exhibited a substantial number of outlier points. Host read depletion methods reduced the total number of human reads in a given sample, but B:H ratios were strongly correlated before and after host read depletion, indicating that host read depletion did not reduce the utility of B:H ratios. B:H ratios showed expected variation between health and disease states and were generally stable in healthy individuals over time. Finally, we showed how B:H and B:D ratios can be used to track antibiotic treatment response and recovery. B:H ratios offer a convenient alternative to other absolute biomass quantification methods, without the need for additional measurements, experimental design considerations, or machine learning, enabling robust absolute biomass estimates directly from stool metagenomic data.IMPORTANCEIn this study, we asked whether normalization by host reads alone was sufficient to estimate absolute bacterial biomass directly from stool metagenomic data, without the need for synthetic spike-ins, additional experimental biomass measurements, or training data. The approach assumes that the contribution of host DNA to stool is more constant or stable than biologically relevant fluctuations in bacterial biomass. We find that host read normalization is an effective method for detecting variation in gut bacterial biomass. Absolute bacterial biomass is a key metric that often gets left out of gut microbiome studies, and empowering researchers to include this measure more broadly in their metagenomic analyses should serve to improve our understanding of host-microbiota interactions.",
      "authors": "Tang Gechlang; Carr Alex V; Perez Crystal; Ramos Sarmiento Katherine; Levy Lisa; Lampe Johanna W; Diener Christian; Gibbons Sean M",
      "year": "2025",
      "journal": "mSystems",
      "doi": "10.1128/msystems.00984-25",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40742180/",
      "mesh_terms": "Humans; Gastrointestinal Microbiome; Metagenomics; Feces; Biomass; Bacteria; Metagenome; Animals; Host Microbial Interactions",
      "keywords": "absolute biomass; diet DNA; gut microbiome; host DNA; human microbiome; metagenomics",
      "pub_types": "Journal Article",
      "pmcid": "PMC12363224"
    },
    {
      "pmid": "37115602",
      "title": "Examining Twitter-Derived Negative Racial Sentiment as Indicators of Cultural Racism: Observational Associations With Preterm Birth and Low Birth Weight Among a Multiracial Sample of Mothers, 2011-2021.",
      "abstract": "BACKGROUND: Large racial and ethnic disparities in adverse birth outcomes persist. Increasing evidence points to the potential role of racism in creating and perpetuating these disparities. Valid measures of area-level racial attitudes and bias remain elusive, but capture an important and underexplored form of racism that may help explain these disparities. Cultural values and attitudes expressed through social media reflect and shape public norms and subsequent behaviors. Few studies have quantified attitudes toward different racial groups using social media with the aim of examining associations with birth outcomes. OBJECTIVE: We used Twitter data to measure state-level racial sentiments and investigate associations with preterm birth (PTB) and low birth weight (LBW) in a multiracial or ethnic sample of mothers in the United States. METHODS: A random 1% sample of publicly available tweets from January 1, 2011, to December 31, 2021, was collected using Twitter's Academic Application Programming Interface (N=56,400,097). Analyses were on English-language tweets from the United States that used one or more race-related keywords. We assessed the sentiment of each tweet using support vector machine, a supervised machine learning model. We used 5-fold cross-validation to assess model performance and achieved high accuracy for negative sentiment classification (91%) and a high F1 score (84%). For each year, the state-level racial sentiment was merged with birth data during that year (~3 million births per year). We estimated incidence ratios for LBW and PTB using log binomial regression models, among all mothers, Black mothers, racially minoritized mothers (Asian, Black, or Latina mothers), and White mothers. Models were controlled for individual-level maternal characteristics and state-level demographics. RESULTS: Mothers living in states in the highest tertile of negative racial sentiment for tweets referencing racial and ethnic minoritized groups had an 8% higher (95% CI 3%-13%) incidence of LBW and 5% higher (95% CI 0%-11%) incidence of PTB compared to mothers living in the lowest tertile. Negative racial sentiment referencing racially minoritized groups was associated with adverse birth outcomes in the total population, among minoritized mothers, and White mothers. Black mothers living in states in the highest tertile of negative Black sentiment had 6% (95% CI 1%-11%) and 7% (95% CI 2%-13%) higher incidence of LBW and PTB, respectively, compared to mothers living in the lowest tertile. Negative Latinx sentiment was associated with a 6% (95% CI 1%-11%) and 3% (95% CI 0%-6%) higher incidence of LBW and PTB among Latina mothers, respectively. CONCLUSIONS: Twitter-derived negative state-level racial sentiment toward racially minoritized groups was associated with a higher risk of adverse birth outcomes among the total population and racially minoritized groups. Policies and supports establishing an inclusive environment accepting of all races and cultures may decrease the overall risk of adverse birth outcomes and reduce racial birth outcome disparities.",
      "authors": "Nguyen Thu T; Merchant Junaid S; Criss Shaniece; Makres Katrina; Gowda Krishik N; Mane Heran; Yue Xiaohe; Hswen Yulin; Glymour M Maria; Nguyen Quynh C; Allen Amani M",
      "year": "2023",
      "journal": "Journal of medical Internet research",
      "doi": "10.2196/44990",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37115602/",
      "mesh_terms": "Female; Infant, Newborn; United States; Humans; Mothers; Premature Birth; Racism; Social Media; Infant, Low Birth Weight; Racial Groups; Pregnancy Complications; Attitude",
      "keywords": "birth outcomes; health disparities; machine learning, racial sentiment; social media",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10182466"
    },
    {
      "pmid": "36508006",
      "title": "Comparison of post-operative outcomes of large direct inguinal hernia repairs based on operative approach (open vs. laparoscopic vs. robotic) using the ACHQC (Abdominal Core Health Quality Collaborative) database.",
      "abstract": "PURPOSE: To compare clinical outcomes for open, laparoscopic, and robotic hernia repairs for direct, unilateral inguinal hernia repairs, with particular focus on 30-day morbidity surgical site infection (SSI); surgical site occurrence (SSO); SSI/SSO requiring procedural interventions (SSOPI), reoperation, and recurrence. METHODS: The Abdominal Core Health Quality Collaborative database was queried for patients undergoing elective, primary,\u2009>\u20093\u00a0cm medial, unilateral inguinal hernia repairs with an open (Lichtenstein), laparoscopic, or robotic operative approach. Preoperative demographics and patient characteristics, operative techniques, and outcomes were studied. A 1-to-1 propensity score matching algorithm was used for each operative approach pair to reduce selection bias. RESULTS: There were 848 operations included: 297 were open, 285 laparoscopic, and 266 robotic hernia repairs. There was no evidence of a difference in primary endpoints at 30\u00a0days including SSI, SSO, SSI/SSO requiring procedural interventions (SSOPI), reoperation, readmission, or recurrence for any of the operative approach pairs (open vs. robotic, open vs. laparoscopic, robotic vs. laparoscopic). For the open vs. laparoscopic groups, QoL score at 30 day was lower (better) for laparoscopic surgery compared to open surgery (OR 0.53 [0.31, 0.92], p\u2009=\u20090.03), but this difference did not hold at the 1-year survey (OR 1.37 [0.48, 3.92], p\u2009=\u20090.55). Similarly, patients who underwent robotic repair were more likely to have a higher (worse) 30-day QoL score (OR 2.01 [1.18, 3.42], p\u2009=\u20090.01), but no evidence of a difference at 1 year (OR 0.83 [0.3, 2.26] p\u2009=\u20090.71). CONCLUSIONS: Our study did not reveal significant post-operative outcomes between open, laparoscopic, and robotic approaches for large medial inguinal hernias. Surgeons should continue to tailor operative approach based on patient needs and their own surgical expertise.",
      "authors": "Varvoglis Dimitrios N; Sanchez-Casalongue Manuel; Olson Molly A; DeAngelo Noah; Garbarine Ian; Lipman Jeffrey; Farrell Timothy M; Overby David Wayne; Perez Arielle; Zhou Randal",
      "year": "2023",
      "journal": "Surgical endoscopy",
      "doi": "10.1007/s00464-022-09805-7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36508006/",
      "mesh_terms": "Humans; Hernia, Inguinal; Quality of Life; Robotic Surgical Procedures; Abdominal Core; Laparoscopy; Surgical Wound Infection",
      "keywords": "Americas hernia society quality collaborative; Laparoscopic inguinal hernia repair; Large direct hernias; Open inguinal hernia repair; Robotic inguinal hernia repair",
      "pub_types": "Journal Article",
      "pmcid": "1422707"
    },
    {
      "pmid": "40032018",
      "title": "Accuracy and precision of segmentation and quantification of wrist bone microarchitecture using photon-counting computed tomography ex vivo.",
      "abstract": "The quantification of bone microarchitecture provides insight into bone health and the effects of disease or treatment, and is therefore highly relevant clinical information. Nonetheless, in vivo quantification of bone microarchitecture is mostly limited to high-resolution peripheral quantitative CT (HR-pQCT). This is a small field of view CT modality of which the gantry size only allows scanning of distal radius and tibia. Photon-counting CT (PCCT) is a novel clinical full-body CT with improved image resolution and quality compared to other clinical CT modalities, yet data on its capabilities in quantifying bone microarchitecture are limited. The aim of this study was to quantify the accuracy of two methods for trabecular bone segmentation on PCCT images as compared to the segmentations on micro-CT (\u03bcCT) and to use these segmentations to quantify the accuracy and agreement of trabecular bone morphometry measurements as compared to \u03bcCT, as well as the short-term precision. This study analysed multimodal CT data, obtained from eight cadaveric forearms; the data includes two repeated PCCT scans, as well as a single HR-pQCT scan from the forearm, and \u03bcCT scans of all individual carpal bones. For each carpal bone, trabecular volumes of interest (VOI) were delineated on the \u03bcCT images, and the \u03bcCT reference segmentations and VOIs were resampled onto the PCCT and HR-pQCT images. HR-pQCT images were segmented with a global threshold of 320 mgHA/cm3; PCCT images were segmented with either an identical global threshold or with an adaptive thresholding algorithm. Trabecular bone-volume fraction (Tb.BV/TV), trabecular thickness (Tb.Th), trabecular number (Tb.N) and trabecular separation (Tb.Sp) were quantified for all segmented VOIs. Accuracy and agreement were calculated relative to \u03bcCT as the gold standard, short-term precision was calculated from the repeated PCCT scan. For PCCT, adaptive threshold segmentation had significantly increased sensitivity compared to global threshold segmentation, along with a lower variance in its sensitivity and specificity. Concerning the microarchitecture quantification, for global threshold segmentation of PCCT images, correlations with \u03bcCT were significant, except for Tb.Sp. Correlation coefficients of Tb.BV/TV and Tb.N were not significantly different from those between HR-pQCT and \u03bcCT. Adaptive threshold segmentation led to higher correlation coefficients between PCCT and \u03bcCT of Tb.Th, Tb.N and Tb.Sp, although correlations of Tb.N remained poor for both PCCT and HR-pQCT. Moreover, adaptive thresholding led to a constant bias of Tb.BV/TV, Tb.Th and Tb.Sp, unlike the bias of HR-pQCT which was proportionally increasing with the size of the measurement. Finally, adaptive threshold segmentation led to a higher short-term precision than global threshold segmentation, with a root-mean-squared coefficient of variation below 0.65\u00a0% for all parameters. We conclude that adaptive threshold segmentation is well-suited for the segmentation of PCCT images. Despite measurement error, our results indicate that these segmentations can be used for bone microarchitecture analyses of carpal bones with agreement and short-term precision comparable to HR-pQCT.",
      "authors": "Quintiens Jilmen; Manske Sarah L; Boyd Steven K; Coudyzer Walter; Bevers Melissa; Vereecke Evie; van den Bergh Joop; van Lenthe G Harry",
      "year": "2025",
      "journal": "Bone",
      "doi": "10.1016/j.bone.2025.117443",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40032018/",
      "mesh_terms": "Humans; X-Ray Microtomography; Photons; Wrist; Tomography, X-Ray Computed; Male; Female; Aged; Cancellous Bone; Middle Aged; Image Processing, Computer-Assisted",
      "keywords": "Agreement analysis; Bone microarchitecture; High-resolution peripheral quantitative CT; Photon-counting CT; Short-term precision",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39704775",
      "title": "Exploring pre-diagnosis hospital contacts in women with endometriosis using ICD-10: a Danish case-control study.",
      "abstract": "STUDY QUESTION: How does pre-diagnosis use of hospital care differentiate between women later diagnosed with endometriosis and age-matched controls without a diagnosis? SUMMARY ANSWER: Women with hospital-diagnosed endometriosis had more frequent hospital contacts in the 10\u2009years leading up to the diagnosis compared to women without a diagnosis of endometriosis, and the contacts were related to registered diagnoses in nearly all of the included ICD-10 chapters for the entire period. WHAT IS KNOWN ALREADY: Only a few studies have investigated the utilization of health care among women with endometriosis in the time before diagnosis, but current research shows that women with endometriosis have a higher utilization compared to women without diagnosed endometriosis. To our knowledge, no study has investigated the type of contact related to the higher utilization by using the ICD-10 diagnoses registered to the hospital contact. STUDY DESIGN, SIZE, DURATION: This study was conducted as a national Danish registry-based case-control study of 129\u00a0696 women. Cases were women with a first-time hospital-based diagnosis of endometriosis between 1 January 2000 and 31 December 2017. PARTICIPANTS/MATERIALS, SETTING, METHODS: Using density sampling, we identified 21\u00a0616 cases. Each case was matched on age at the date of diagnosis (index date) to five women without hospital-diagnosed endometriosis (n\u2009=\u2009108\u00a0080) at the time of matching. The utilization and registered ICD-10 diagnoses related to the hospital contact were included for the 10\u2009years before the index date. MAIN RESULTS AND THE ROLE OF CHANCE: The probability of having a high number of hospital contacts (six or more) was more common among women with endometriosis (68.6%) compared to women without endometriosis (55.7%) In general, women without endometriosis were more likely to have fewer than six contacts. The diagnoses registered to the contact among cases were related to a greater variety of ICD-10 chapters when compared to controls with the same number of contacts. For nearly all of the included ICD-10 chapters, women with endometriosis were more likely to have a diagnosis over the entire period compared to controls, with the only exception being in the chapter related to pregnancy. LIMITATIONS, REASONS FOR CAUTION: Our results are only applicable for women with hospital-based diagnosed endometriosis since we were not able to include women diagnosed at the general practitioner or private gynecologists. We were not able to make a causal interpretation, as we do not have information on the onset of symptoms of the included diseases. The association may be overestimated due to detection bias. However, a sensitivity analysis only changed the results slightly, indicating a low risk of this bias. WIDER IMPLICATIONS OF THE FINDINGS: This study is in accordance with previous studies on the subject, indicating that the utilization of health care prior to endometriosis is not necessarily restricted to endometriosis-related symptoms and that endometriosis can be associated with many other diseases. Future studies may explore hospital contacts and causes/diagnoses following the endometriosis diagnosis to further shed light on whether our results are due to a pattern of multiple pathologies or rather an expression of misdiagnoses among women with endometriosis before diagnosis. STUDY FUNDING/COMPETING INTEREST(S): This study is supported by grants from the project Finding Endometriosis using Machine Learning (FEMaLe/101017562), which has received funding from The European Union's Horizon 2020 research and innovation program and Helsefonden (21-B-0141). A.W.H. received grant funding from NIHR, CSO, Roche Diagnostics, and Wellbeing of Women. A.W.H.'s institution received consultation fees from Theramex, Joii, Gesynta, and Gedeon Richter. A.W.H.'s institution received honoraria for lectures from Theramex and Gedeon Richter. A.W.H. is listed as co-inventor on a patent application (UK Patent App No. 2217921.2, International Patent App No. PCT/GB2023/053076). P.T.K.S.'s institution (University of Edinburgh) received consultation fees from Gesynta Pharma AB and BenevolentAI Bio Ltd. P.T.K.S's institution (University of Edinburgh) declares a patent application (UK Patent Application No. 2310300.5. Androgens in diagnostic strategies for endometriosis). P.T.K.S. is a treasurer of the World Endometriosis Society, Fellowship in the Royal Society of Edinburgh, and a Scientific Advisor of the Royal College of Obstetrics and Gynaecology. TRIAL REGISTRATION NUMBER: N/A.",
      "authors": "Melgaard Anna; Vestergaard Claus H\u00f8strup; Kesmodel Ulrik Schi\u00f8ler; Ris\u00f8r Bettina Wulff; Forman Axel; Zondervan Krina T; Nath Mintu; Ayansina Dolapo; Saunders Philippa T K; Horne Andrew W; Saraswat Lucky; Rytter Dorte",
      "year": "2025",
      "journal": "Human reproduction (Oxford, England)",
      "doi": "10.1093/humrep/deae273",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39704775/",
      "mesh_terms": "Humans; Female; Endometriosis; Denmark; Case-Control Studies; Adult; International Classification of Diseases; Registries; Middle Aged; Young Adult; Hospitalization; Hospitals",
      "keywords": "case\u2013control study; comorbidity; diagnostic delay; endometriosis; health care utilization; women\u2019s health",
      "pub_types": "Journal Article",
      "pmcid": "PMC11788223"
    },
    {
      "pmid": "40981620",
      "title": "Leveraging Smart Bed Technology to Detect COVID-19 Symptoms: Case Study.",
      "abstract": "BACKGROUND: Pathophysiological responses to viral infections such as COVID-19 significantly affect sleep duration, sleep quality, and concomitant cardiorespiratory function. The widespread adoption of consumer smart bed technology presents a unique opportunity for unobtrusive, real-world, longitudinal monitoring of sleep and physiological signals, which may be valuable for infectious illness surveillance and early detection. During the COVID-19 pandemic, scalable and noninvasive methods for identifying subtle early symptoms in naturalistic settings became increasingly important. Existing digital health studies have largely relied on wearables or patient self-reports, with limited adherence and recall bias. In contrast, smart bed-derived signals enable high-frequency objective data capture with minimal user burden. OBJECTIVE: The aim of this study was to leverage objective, longitudinal biometric data captured using ballistocardiography signals from a consumer smart bed platform, along with predictive modeling, to detect and monitor COVID-19 symptoms at an individual level. METHODS: A retrospective cohort of 1725 US adults with sufficient longitudinal data and completed surveys reporting COVID-19 test outcomes was identified from users of a smart bed system. Smart bed ballistocardiography-derived metrics included nightly pulse rate, respiratory rate, total sleep time, sleep stages, and movement patterns. Participants served as their own controls, comparing reference (baseline) and symptomatic periods. A two-stage analytical pipeline was used: (1) a gradient-boosted decision-tree \"symptom detection model\" independently classified each sleep session as symptomatic or not, and (2) an \"illness-symptom progression model\" using a Gaussian Mixture Hidden Markov Model estimated the probability of symptomatic states across contiguous sleep sessions by leveraging the temporal relationship in the data. Statistical analyses evaluated within-subject changes, and the model's ability to discriminate illness windows was quantified using receiver operating characteristic metrics. RESULTS: Out of 122 participants who tested positive for COVID-19, symptoms were detected by the model in 104 cases. Across the cohort, the model captured significant deviations in sleep and cardiorespiratory metrics during symptomatic periods compared to baseline, with an area under the receiver operating characteristic curve of 0.80, indicating high discriminatory performance. Limitations included reliance on self-reported symptoms and test status, as well as the demographic makeup of the smart bed user base. CONCLUSIONS: Smart beds represent a valuable resource for passively collecting objective, longitudinal sleep and physiological data. The findings support the feasibility of using these data and machine learning models for real-time detection and tracking of COVID-19 and related illnesses. Future directions include model refinement, integration with other health signals, and applications for population-scale surveillance of emerging infectious diseases.",
      "authors": "Garcia-Molina Gary; Guzenko Dmytro; DeFranco Susan; Aloia Mark; Mills Rajasi; Mushtaq Faisal; Somers Virend K",
      "year": "2025",
      "journal": "JMIR AI",
      "doi": "10.2196/64018",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40981620/",
      "mesh_terms": "",
      "keywords": "COVID-19; disease progression; illness progression; sleep; symptom detection model",
      "pub_types": "Journal Article",
      "pmcid": "PMC12452045"
    },
    {
      "pmid": "36819954",
      "title": "ChatGPT Output Regarding Compulsory Vaccination and COVID-19 Vaccine Conspiracy: A Descriptive Study at the Outset of a Paradigm Shift in Online Search for Information.",
      "abstract": "BACKGROUND: Being on the verge of a revolutionary approach to gathering information, ChatGPT (an artificial intelligence (AI)-based language model developed by OpenAI, and capable of producing human-like text) could be the prime motive of a paradigm shift on how humans will acquire information. Despite the concerns related to the use of such a promising tool in relation to the future of the quality of education, this technology will soon be incorporated into web search engines mandating the need to evaluate the output of such a tool. Previous studies showed that dependence on some sources of online information (e.g., social media platforms) was associated with higher rates of vaccination hesitancy. Therefore, the aim of the current study was to describe the output of ChatGPT regarding coronavirus disease 2019 (COVID-19) vaccine conspiracy beliefs. and compulsory vaccination. METHODS: The current descriptive study was conducted on January 14, 2023 using the ChatGPT from OpenAI (OpenAI, L.L.C.,\u00a0San Francisco, CA, USA). The output was evaluated by two authors and the degree of agreement regarding the correctness, clarity, conciseness, and bias was evaluated using Cohen's kappa. RESULTS: The ChatGPT responses were dismissive of conspiratorial ideas about severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) origins labeling it as non-credible and lacking scientific evidence. Additionally, ChatGPT responses were totally against COVID-19 vaccine conspiracy statements. Regarding compulsory vaccination, ChatGPT responses were neutral citing the following as advantages of this strategy: protecting public health, maintaining herd immunity, reducing the spread of disease, cost-effectiveness, and legal obligation, and on the other hand, it cited the following as disadvantages of compulsory vaccination: ethical and legal concerns, mistrust and resistance, logistical challenges, and limited resources and knowledge. CONCLUSIONS: The current study showed that ChatGPT could be a source of information to challenge COVID-19 vaccine conspiracies. For compulsory vaccination, ChatGPT resonated with the divided opinion in the scientific community toward\u00a0such a strategy; nevertheless, it detailed the pros and cons of this approach. As it currently stands, the judicious use of ChatGPT could be utilized as a user-friendly source of COVID-19 vaccine information that could challenge conspiracy ideas with clear, concise, and non-biased content. However, ChatGPT content cannot be used as an alternative to the original reliable sources of vaccine information (e.g., the World Health Organization [WHO] and the Centers for Disease Control and Prevention [CDC]).",
      "authors": "Sallam Malik; Salim Nesreen A; Al-Tammemi Ala'a B; Barakat Muna; Fayyad Diaa; Hallit Souheil; Harapan Harapan; Hallit Rabih; Mahafzah Azmi",
      "year": "2023",
      "journal": "Cureus",
      "doi": "10.7759/cureus.35029",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36819954/",
      "mesh_terms": "",
      "keywords": "artificial intelligence in medicine; covid-19 vaccine; machine learning; mandatory vaccination; vaccine promotion",
      "pub_types": "Journal Article",
      "pmcid": "PMC9931398"
    },
    {
      "pmid": "40245931",
      "title": "Hemolytic Disease of the Fetus and Newborn in an Integrated Health Care System.",
      "abstract": "Hemolytic disease of the fetus and newborn (HDFN) is associated with significant infant morbidity and mortality. Characteristics of pregnancies impacted by HDFN are not well understood. Therefore, this study examines maternal and infant characteristics based on HDFN status in a large, integrated health care system in the United States.This was a population-based, retrospective cohort study of 464,711 pregnancies that received care at Kaiser Permanente Southern California (KPSC) hospitals from January 2008 to June 2022. HDFN cases were ascertained using a validated algorithm of structured and unstructured data elements. HDFN due to ABO alloimmunization alone was excluded. Adjusted odds ratios (aORs) derived from logistic regression were used to describe the association between maternal and infant characteristics and HDFN diagnosis as well as adverse perinatal outcomes. For rare events, Firth's bias-reduced logistic regression was applied.A total of 136 HDFN pregnancies with 138 HDFN births (live births\u2009=\u2009137; stillbirth\u2009=\u20091) were observed in the study. Of three twin pregnancies, all but one fetus had an HDFN diagnosis. HDFN diagnosis was associated with a maternal age of \u226535 years (aOR: 1.74; 95% confidence interval [CI]: 1.13-2.67), hypertension (2.07; 0.96-4.50), renal disease (3.43; 1.75-6.70), and multiparity (4.95; 2.73-8.95). Furthermore, HDFN diagnosis was associated with birth at 33 to 34 weeks (aOR: 5.72; 95% CI: 2.78-11.78) and 35 to 36 weeks (3.76; 2.38-5.94), and neonatal jaundice (3.11; 2.20-4.41). Birth weight \u22654,000\u2009g was associated with lower HDFN diagnosis odds than normal weight (2,500-3,999\u2009g; aOR: 0.36; 95% CI: 0.14-0.90). Hispanic race/ethnicity was associated with a lower HDFN diagnosis risk than non-Hispanic White (aOR: 0.63; 95% CI: 0.43-0.93).This study identified clinical and demographic factors linked with HDFN diagnosis, including specific maternal characteristics, medical/obstetrical factors, and neonatal factors, within a large, integrated health care system that can help inform management plans. \u00b7 Characteristics of HDFN are not well understood.. \u00b7 This study examined HDFN characteristics in the United States.. \u00b7 HDFN risk is linked to medical/obstetric factors.. \u00b7 Increased risk of prematurity associated with HDFN..",
      "authors": "Fassett Michael J; Khadka Nehaa; Xie Fagen; Shi Jiaxiao; Chiu Vicki Y; Im Theresa M; Kim Sunhea; Mensah Nana A; Park Daniella; Mao Carol; Molaei Matthew; Lin Iris; Getahun Darios",
      "year": "2025",
      "journal": "American journal of perinatology",
      "doi": "10.1055/a-2558-7891",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40245931/",
      "mesh_terms": "Humans; Female; Pregnancy; Infant, Newborn; Retrospective Studies; Adult; Erythroblastosis, Fetal; Delivery of Health Care, Integrated; California; Logistic Models; Maternal Age; Young Adult; Male",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12530894"
    },
    {
      "pmid": "37917123",
      "title": "Public Health Surveillance of Behavioral Cancer Risk Factors During the COVID-19 Pandemic: Sentiment and Emotion Analysis of Twitter Data.",
      "abstract": "BACKGROUND: The COVID-19 pandemic and its associated public health mitigation strategies have dramatically changed patterns of daily life activities worldwide, resulting in unintentional consequences on behavioral risk factors, including smoking, alcohol consumption, poor nutrition, and physical inactivity. The infodemic of social media data may provide novel opportunities for evaluating changes related to behavioral risk factors during the pandemic. OBJECTIVE: We explored the feasibility of conducting a sentiment and emotion analysis using Twitter data to evaluate behavioral cancer risk factors (physical inactivity, poor nutrition, alcohol consumption, and smoking) over time during the first year of the COVID-19 pandemic. METHODS: Tweets during 2020 relating to the COVID-19 pandemic and the 4 cancer risk factors were extracted from the George Washington University Libraries Dataverse. Tweets were defined and filtered using keywords to create 4 data sets. We trained and tested a machine learning classifier using a prelabeled Twitter data set. This was applied to determine the sentiment (positive, negative, or neutral) of each tweet. A natural language processing package was used to identify the emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, and trust) based on the words contained in the tweets. Sentiments and emotions for each of the risk factors were evaluated over time and analyzed to identify keywords that emerged. RESULTS: The sentiment analysis revealed that 56.69% (51,479/90,813) of the tweets about physical activity were positive, 16.4% (14,893/90,813) were negative, and 26.91% (24,441/90,813) were neutral. Similar patterns were observed for nutrition, where 55.44% (27,939/50,396), 15.78% (7950/50,396), and 28.79% (14,507/50,396) of the tweets were positive, negative, and neutral, respectively. For alcohol, the proportions of positive, negative, and neutral tweets were 46.85% (34,897/74,484), 22.9% (17,056/74,484), and 30.25% (22,531/74,484), respectively, and for smoking, they were 41.2% (11,628/28,220), 24.23% (6839/28,220), and 34.56% (9753/28,220), respectively. The sentiments were relatively stable over time. The emotion analysis suggests that the most common emotion expressed across physical activity and nutrition tweets was trust (69,495/320,741, 21.67% and 42,324/176,564, 23.97%, respectively); for alcohol, it was joy (49,147/273,128, 17.99%); and for smoking, it was fear (23,066/110,256, 20.92%). The emotions expressed remained relatively constant over the observed period. An analysis of the most frequent words tweeted revealed further insights into common themes expressed in relation to some of the risk factors and possible sources of bias. CONCLUSIONS: This analysis provided insight into behavioral cancer risk factors as expressed on Twitter during the first year of the COVID-19 pandemic. It was feasible to extract tweets relating to all 4 risk factors, and most tweets had a positive sentiment with varied emotions across the different data sets. Although these results can play a role in promoting public health, a deeper dive via qualitative analysis can be conducted to provide a contextual examination of each tweet.",
      "authors": "Christodoulakis Nicolette; Abdelkader Wael; Lokker Cynthia; Cotterchio Michelle; Griffith Lauren E; Vanderloo Leigh M; Anderson Laura N",
      "year": "2023",
      "journal": "JMIR formative research",
      "doi": "10.2196/46874",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37917123/",
      "mesh_terms": "",
      "keywords": "Twitter; alcohol; cancer risk factors; emotion analysis; physical inactivity; poor nutrition; sentiment analysis; smoking; social media",
      "pub_types": "Journal Article",
      "pmcid": "PMC10624214"
    },
    {
      "pmid": "34889753",
      "title": "Prediction Algorithms for Blood Pressure Based on Pulse Wave Velocity Using Health Checkup Data in Healthy Korean Men: Algorithm Development and Validation.",
      "abstract": "BACKGROUND: Pulse transit time and pulse wave velocity (PWV) are related to blood pressure (BP), and there were continuous attempts to use these to predict BP through wearable devices. However, previous studies were conducted on a small scale and could not confirm the relative importance of each variable in predicting BP. OBJECTIVE: This study aims to predict systolic blood pressure and diastolic blood pressure based on PWV and to evaluate the relative importance of each clinical variable used in BP prediction models. METHODS: This study was conducted on 1362 healthy men older than 18 years who visited the Samsung Medical Center. The systolic blood pressure and diastolic blood pressure were estimated using the multiple linear regression method. Models were divided into two groups based on age: younger than 60 years and 60 years or older; 200 seeds were repeated in consideration of partition bias. Mean of error, absolute error, and root mean square error were used as performance metrics. RESULTS: The model divided into two age groups (younger than 60 years and 60 years and older) performed better than the model without division. The performance difference between the model using only three variables (PWV, BMI, age) and the model using 17 variables was not significant. Our final model using PWV, BMI, and age met the criteria presented by the American Association for the Advancement of Medical Instrumentation. The prediction errors were within the range of about 9 to 12 mmHg that can occur with a gold standard mercury sphygmomanometer. CONCLUSIONS: Dividing age based on the age of 60 years showed better BP prediction performance, and it could show good performance even if only PWV, BMI, and age variables were included. Our final model with the minimal number of variables (PWB, BMI, age) would be efficient and feasible for predicting BP.",
      "authors": "Park Dohyun; Cho Soo Jin; Kim Kyunga; Woo Hyunki; Kim Jee Eun; Lee Jin-Young; Koh Janghyun; Lee JeanHyoung; Choi Jong Soo; Chang Dong Kyung; Choi Yoon-Ho; Chung Ji In; Cha Won Chul; Jeong Ok Soon; Jekal Se Yong; Kang Mira",
      "year": "2021",
      "journal": "JMIR medical informatics",
      "doi": "10.2196/29212",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34889753/",
      "mesh_terms": "",
      "keywords": "algorithms; blood pressure; medical informatics; prediction model; pulse transit time; pulse wave velocity; wearable devices",
      "pub_types": "Journal Article",
      "pmcid": "PMC8701706"
    },
    {
      "pmid": "30105374",
      "title": "Tumor Necrosis Factor Inhibitors and Cancer Recurrence in Swedish Patients With Rheumatoid Arthritis: A Nationwide Population-Based Cohort Study.",
      "abstract": "BACKGROUND: Use of tumor necrosis factor inhibitors (TNFi) in patients with a history of cancer remains a clinical dilemma. OBJECTIVE: To investigate whether TNFi treatment in rheumatoid arthritis (RA) is associated with increased risk for cancer recurrence. DESIGN: Population-based cohort study based on linkage of nationwide registers. SETTING: Sweden. PARTICIPANTS: Patients with RA who started TNFi treatment between 2001 and 2015, after being diagnosed with cancer, and matched patients with RA and a history of the same cancer who had never received biologics. MEASUREMENTS: The primary outcome was the first recurrence of cancer. Adjusted Cox proportional hazards models were used to estimate hazard ratios (HRs), taking into account time, cancer type, and whether the cancer was invasive or in situ (or tumor, node, metastasis [TNM] classification system stage in a subset of patients). RESULTS: Among 467 patients who started TNFi treatment (mean time after cancer diagnosis, 7.9 years), 42 had cancer recurrences (9.0%; mean follow-up, 5.3 years); among 2164 matched patients with the same cancer history, 155 had recurrences (7.2%; mean follow-up, 4.3 years) (HR, 1.06 [95% CI, 0.73 to 1.54). Hazard ratios were close to 1 in analyses of patient subsets matched on cancer stage or with similar time from index cancer diagnosis to the start of TNFi treatment, as well as in unmatched analyses. Several CIs had upper limits close to 2. LIMITATION: The outcome algorithm was partly nonvalidated, and channeling bias was possible if patients with a better index cancer prognosis were more likely to receive TNFi. CONCLUSION: The findings suggest that TNFi treatment is not associated with increased risk for cancer recurrence in patients with RA, although meaningful risk increases could not be ruled out completely. PRIMARY FUNDING SOURCE: ALF (an agreement in Stockholm County Council concerning medical education and research in health and medical care), the Swedish Cancer Society, the Swedish Foundation for Strategic Research, and the Swedish Research Council.",
      "authors": "Raaschou Pauline; S\u00f6derling Jonas; Turesson Carl; Askling Johan",
      "year": "2018",
      "journal": "Annals of internal medicine",
      "doi": "10.7326/M17-2812",
      "url": "https://pubmed.ncbi.nlm.nih.gov/30105374/",
      "mesh_terms": "Aged; Algorithms; Antirheumatic Agents; Arthritis, Rheumatoid; Female; Follow-Up Studies; Humans; Male; Middle Aged; Neoplasm Staging; Neoplasms; Neoplasms, Second Primary; Proportional Hazards Models; Recurrence; Risk Factors; Sweden; Tumor Necrosis Factor-alpha",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "32310142",
      "title": "Objective Characterization of Activity, Sleep, and Circadian Rhythm Patterns Using a Wrist-Worn Actigraphy Sensor: Insights Into Posttraumatic Stress Disorder.",
      "abstract": "BACKGROUND: Wearables have been gaining increasing momentum and have enormous potential to provide insights into daily life behaviors and longitudinal health monitoring. However, to date, there is still a lack of principled algorithmic framework to facilitate the analysis of actigraphy and objectively characterize day-by-day data patterns, particularly in cohorts with sleep problems. OBJECTIVE: This study aimed to propose a principled algorithmic framework for the assessment of activity, sleep, and circadian rhythm patterns in people with posttraumatic stress disorder (PTSD), a mental disorder with long-lasting distressing symptoms such as intrusive memories, avoidance behaviors, and sleep disturbance. In clinical practice, these symptoms are typically assessed using retrospective self-reports that are prone to recall bias. The aim of this study was to develop objective measures from patients' everyday lives, which could potentially considerably enhance the understanding of symptoms, behaviors, and treatment effects. METHODS: Using a wrist-worn sensor, we recorded actigraphy, light, and temperature data over 7 consecutive days from three groups: 42 people diagnosed with PTSD, 43 traumatized controls, and 30 nontraumatized controls. The participants also completed a daily sleep diary over 7 days and the standardized Pittsburgh Sleep Quality Index questionnaire. We developed a novel approach to automatically determine sleep onset and offset, which can also capture awakenings that are crucial for assessing sleep quality. Moreover, we introduced a new intuitive methodology facilitating actigraphy exploration and characterize day-by-day data across 49 activity, sleep, and circadian rhythm patterns. RESULTS: We demonstrate that the new sleep detection algorithm closely matches the sleep onset and offset against the participants' sleep diaries consistently outperforming an existing open-access widely used approach. Participants with PTSD exhibited considerably more fragmented sleep patterns (as indicated by greater nocturnal activity, including awakenings) and greater intraday variability compared with traumatized and nontraumatized control groups, showing statistically significant (P<.05) and strong associations (|R|>0.3). CONCLUSIONS: This study lays the foundation for objective assessment of activity, sleep, and circadian rhythm patterns using passively collected data from a wrist-worn sensor, facilitating large community studies to monitor longitudinally healthy and pathological cohorts under free-living conditions. These findings may be useful in clinical PTSD assessment and could inform therapy and monitoring of treatment effects.",
      "authors": "Tsanas Athanasios; Woodward Elizabeth; Ehlers Anke",
      "year": "2020",
      "journal": "JMIR mHealth and uHealth",
      "doi": "10.2196/14306",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32310142/",
      "mesh_terms": "Actigraphy; Adult; Circadian Rhythm; Female; Humans; Male; Retrospective Studies; Sleep; Stress Disorders, Post-Traumatic; Wrist; Young Adult",
      "keywords": "Geneactiv; actigraphy; posttraumatic stress disorder; sleep; wearable technology",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7199134"
    },
    {
      "pmid": "36792410",
      "title": "Improving lung cancer diagnosis with cancer, fungal, and imaging biomarkers.",
      "abstract": "OBJECTIVE: Indeterminate pulmonary nodules (IPNs) represent a significant diagnostic burden in health care. We aimed to compare a combination clinical prediction model (Mayo Clinic model), fungal (histoplasmosis serology), imaging (computed tomography [CT] radiomics), and cancer (high-sensitivity cytokeratin fraction 21; hsCYFRA 21-1) biomarker approach to a validated prediction model in diagnosing lung cancer. METHODS: A prospective specimen collection, retrospective blinded evaluation study was performed in 3 independent cohorts with 6- to 30-mm IPNs (n\u00a0=\u00a0281). Serum histoplasmosis immunoglobulin G and immunoglobulin M antibodies and hsCYFRA 21-1 levels were measured and a validated CT radiomic score was calculated. Multivariable logistic regression models were estimated with Mayo Clinic model variables, histoplasmosis antibody levels, CT radiomic score, and hsCYFRA 21-1. Diagnostic performance of the combination model was compared with that of the Mayo Clinic model. Bias-corrected clinical net reclassification index (cNRI) was used to estimate the clinical utility of a combination biomarker approach. RESULTS: A total of 281 patients were included (111 from a histoplasmosis-endemic region). The combination biomarker model including the Mayo Clinic model score, histoplasmosis antibody levels, radiomics, and hsCYFRA 21-1 level showed improved diagnostic accuracy for IPNs compared with the Mayo Clinic model alone with an area under the receiver operating characteristics curve of 0.80 (95% CI, 0.76-0.84) versus 0.72 (95% CI, 0.66-0.78). Use of this combination model correctly reclassified intermediate risk IPNs into low- or high-risk category (cNRI benign\u00a0=\u00a00.11 and cNRI malignant\u00a0=\u00a00.16). CONCLUSIONS: The addition of cancer, fungal, and imaging biomarkers improves the diagnostic accuracy for IPNs. Integrating a combination biomarker approach into the diagnostic algorithm of IPNs might decrease unnecessary invasive testing of benign nodules and reduce time to diagnosis for cancer.",
      "authors": "Marmor Hannah N; Kammer Michael N; Deppen Stephen A; Shipe Maren; Welty Valerie F; Patel Khushbu; Godfrey Caroline; Billatos Ehab; Herman James G; Wilson David O; Kussrow Amanda K; Bornhop Darryl J; Maldonado Fabien; Chen Heidi; Grogan Eric L",
      "year": "2023",
      "journal": "The Journal of thoracic and cardiovascular surgery",
      "doi": "10.1016/j.jtcvs.2022.12.014",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36792410/",
      "mesh_terms": "Humans; Histoplasmosis; Models, Statistical; Retrospective Studies; Prospective Studies; Prognosis; Lung Neoplasms; Multiple Pulmonary Nodules; Biomarkers",
      "keywords": "biomarker; cancer; nodule; pulmonary",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10287834"
    },
    {
      "pmid": "34260592",
      "title": "Prediction of anemia and estimation of hemoglobin concentration using a smartphone camera.",
      "abstract": "Anemia, defined as a low hemoglobin concentration, has a large impact on the health of the world's population. We describe the use of a ubiquitous device, the smartphone, to predict hemoglobin concentration and screen for anemia. This was a prospective convenience sample study conducted in Emergency Department (ED) patients of an academic teaching hospital. In an algorithm derivation phase, images of both conjunctiva were obtained from 142 patients in Phase 1 using a smartphone. A region of interest targeting the palpebral conjunctiva was selected from each image. Image-based parameters were extracted and used in stepwise regression analyses to develop a prediction model of estimated hemoglobin (HBc). In Phase 2, a validation model was constructed using data from 202 new ED patients. The final model based on all 344 patients was tested for accuracy in anemia and transfusion thresholds. Hemoglobin concentration ranged from 4.7 to 19.6 g/dL (mean 12.5). In Phase 1, there was a significant association between HBc and laboratory-predicted hemoglobin (HBl) slope = 1.07 (CI = 0.98-1.15), p<0.001. Accuracy, sensitivity, and specificity of HBc for predicting anemia was 82.9 [79.3, 86.4], 90.7 [87.0, 94.4], and 73.3 [67.1, 79.5], respectively. In Phase 2, accuracy, sensitivity and specificity decreased to 72.6 [71.4, 73.8], 72.8 [71, 74.6], and 72.5 [70.8, 74.1]. Accuracy for low (<7 g/dL) and high (<9 g/dL) transfusion thresholds was 94.4 [93.7, 95] and 86 [85, 86.9] respectively. Error trended with increasing HBl values (slope 0.27 [0.19, 0.36] and intercept -3.14 [-4.21, -2.07] (p<0.001) such that HBc tended to underestimate hemoglobin in higher ranges and overestimate in lower ranges. Higher quality images had a smaller bias trend than lower quality images. When separated by skin tone results were unaffected. A smartphone can be used in screening for anemia and transfusion thresholds. Improvements in image quality and computational corrections can further enhance estimates of hemoglobin.",
      "authors": "Suner Selim; Rayner James; Ozturan Ibrahim U; Hogan Geoffrey; Meehan Caroline P; Chambers Alison B; Baird Janette; Jay Gregory D",
      "year": "2021",
      "journal": "PloS one",
      "doi": "10.1371/journal.pone.0253495",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34260592/",
      "mesh_terms": "Adult; Aged; Aged, 80 and over; Algorithms; Anemia; Conjunctiva; Female; Hemoglobins; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Photography; Prospective Studies; Reproducibility of Results; Sensitivity and Specificity; Skin; Smartphone; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article; Observational Study; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC8279386"
    },
    {
      "pmid": "31299406",
      "title": "Association between epigenetic age acceleration and depressive symptoms in a prospective cohort study of urban-dwelling adults.",
      "abstract": "OBJECTIVE: This study tests associations of DNA methylation-based (DNAm) measures of epigenetic age acceleration (EAA) with cross-sectional and longitudinal depressive symptoms in an urban sample of middle-aged adults. METHODS: White and African-American adult participants in the Healthy Aging in Neighborhoods of Diversity across the Life Span study for whom DNA samples were analyzed (baseline age: 30-65 years) we included. We estimated three DNAm based EAA measures: (1) universal epigenetic age acceleration (AgeAccel); (2) intrinsic epigenetic age acceleration (IEAA); and (3) extrinsic epigenetic age acceleration (EEAA). Depressive symptoms were assessed using the 20-item Center for Epidemiological Studies-Depression scale total and sub-domain scores at baseline (2004-2009) and follow-up visits (2009-2013). Linear mixed-effects regression models were conducted, adjusting potentially confounding covariates, selection bias and multiple testing (N\u202f=\u202f329 participants, \u223c52% men, k\u202f=\u202f1.9 observations/participant, mean follow-up time\u223c4.7 years). RESULTS: None of the epigenetic age acceleration measures were associated with total depressive symptom scores at baseline or over time. IEAA - a measure of cellular epigenetic age acceleration irrespective of white blood cell composition - was cross-sectionally associated with decrement in \"positive affect\" in the total population (\u03b3011\u00b1\u00a0SE\u00a0=\u00a0-0.090\u202f\u00b1\u202f0.030, P\u202f=\u202f0.003, Cohen's D: -0.16) and among Whites (\u03b3011\u202f\u00b1\u202fSE\u202f=\u202f-0.135\u202f\u00b1\u00a00.048, P\u202f=\u202f0.005, Cohen's D: -0.23), after correction for multiple testing. Baseline \"positive affect\" was similarly associated with AgeAccel. LIMITATIONS: Limitations included small sample size, weak-moderate effects and measurement error. CONCLUSIONS: IEAA and AgeAccel, two measures of EAA using Horvath algorithm, were linked to a reduced \"positive affect\", overall and among Whites. Future studies are needed to replicate our findings and test bi-directional relationships.",
      "authors": "Beydoun May A; Hossain Sharmin; Chitrala Kumaraswamy Naidu; Tajuddin Salman M; Beydoun Hind A; Evans Michele K; Zonderman Alan B",
      "year": "2019",
      "journal": "Journal of affective disorders",
      "doi": "10.1016/j.jad.2019.06.032",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31299406/",
      "mesh_terms": "Adult; Aged; Aging; Cross-Sectional Studies; Depression; Epigenesis, Genetic; Female; Humans; Longevity; Male; Middle Aged; Prospective Studies; Urban Population",
      "keywords": "Adults; Depressive symptoms; Epigenetic Age acceleration; Health disparities",
      "pub_types": "Journal Article; Research Support, N.I.H., Intramural",
      "pmcid": "PMC6757325"
    },
    {
      "pmid": "26426030",
      "title": "Temporal and Spatial Simulation of Atmospheric Pollutant PM2.5 Changes and Risk Assessment of Population Exposure to Pollution Using Optimization Algorithms of the Back Propagation-Artificial Neural Network Model and GIS.",
      "abstract": "PM2.5 pollution has become of increasing public concern because of its relative importance and sensitivity to population health risks. Accurate predictions of PM2.5 pollution and population exposure risks are crucial to developing effective air pollution control strategies. We simulated and predicted the temporal and spatial changes of PM2.5 concentration and population exposure risks, by coupling optimization algorithms of the Back Propagation-Artificial Neural Network (BP-ANN) model and a geographical information system (GIS) in Xi'an, China, for 2013, 2020, and 2025. Results indicated that PM2.5 concentration was positively correlated with GDP, SO\u2082, and NO\u2082, while it was negatively correlated with population density, average temperature, precipitation, and wind speed. Principal component analysis of the PM2.5 concentration and its influencing factors' variables extracted four components that accounted for 86.39% of the total variance. Correlation coefficients of the Levenberg-Marquardt (trainlm) and elastic (trainrp) algorithms were more than 0.8, the index of agreement (IA) ranged from 0.541 to 0.863 and from 0.502 to 0.803 by trainrp and trainlm algorithms, respectively; mean bias error (MBE) and Root Mean Square Error (RMSE) indicated that the predicted values were very close to the observed values, and the accuracy of trainlm algorithm was better than the trainrp. Compared to 2013, temporal and spatial variation of PM2.5 concentration and risk of population exposure to pollution decreased in 2020 and 2025. The high-risk areas of population exposure to PM2.5 were mainly distributed in the northern region, where there is downtown traffic, abundant commercial activity, and more exhaust emissions. A moderate risk zone was located in the southern region associated with some industrial pollution sources, and there were mainly low-risk areas in the western and eastern regions, which are predominantly residential and educational areas.",
      "authors": "Zhang Ping; Hong Bo; He Liang; Cheng Fei; Zhao Peng; Wei Cailiang; Liu Yunhui",
      "year": "2015",
      "journal": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph121012171",
      "url": "https://pubmed.ncbi.nlm.nih.gov/26426030/",
      "mesh_terms": "Air Pollutants; Algorithms; China; Environmental Exposure; Environmental Monitoring; Environmental Policy; Health Policy; Humans; Models, Theoretical; Neural Networks, Computer; Particle Size; Particulate Matter; Public Policy; Risk Assessment",
      "keywords": "BP-ANN model; PM2.5; geographical information system; optimization algorithms; population exposure risk; simulation and prediction",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC4626962"
    },
    {
      "pmid": "36266938",
      "title": "Accuracy of blood pressure measurement across BMI categories using the OptiBP\u2122 mobile application.",
      "abstract": "PURPOSE: Obesity is a clear risk factor for hypertension. Blood pressure (BP) measurement in obese patients may be biased by cuff size and upper arm shape which may affect the accuracy of measurements. This study aimed to assess the accuracy of the OptiBP smartphone application for three different body mass index (BMI) categories (normal, overweight and obese). MATERIALS AND METHODS: Participants with a wide range of BP and BMI were recruited at Lausanne University Hospital's hypertension clinic in Switzerland. OptiBP estimated BP by recording an optical signal reflecting light from the participants' fingertips into a smartphone camera. Age, sex and BP distribution were collected to fulfil the AAMI/ESH/ISO universal standards. Both auscultatory BP references and OptiBP BP were measured and compared using the simultaneous opposite arms method, as described in the 81060-2:2018 ISO norm. Subgroup analyses were performed for each BMI category. RESULTS: We analyzed 414 recordings from 95 patients: 34 were overweight and 15 were obese. The OptiBP application had a performance acceptance rate of 82%. The mean and standard deviation (SD) differences between the optical BP estimations and the auscultatory reference rates (criterion 1) were respected in all subgroups: SBP mean value was 2.08 (SD 7.58); 1.32 (6.44); -2.29 (5.62) respectively in obese, overweight and normal weight subgroup. For criterion 2, which investigates the precision errors on an individual level, the threshold for systolic BP in the obese group was slightly above the requirement for this criterion. CONCLUSION: This study demonstrated that the OptiBP application is easily applicable to overweight and obese participants. Differences between the reference measure and the OptiBP estimation were within ISO limits (criterion 1). In obese participants, the SD of mean error was outside criterion 2 limits. Whether auscultatory measurement, due to arm morphology or the OptiBP is associated with increasing bias in obese still needs to be studied.",
      "authors": "Caillat Mary; Degott Jean; Wuerzner Arlene; Proen\u00e7ain Martin; Bonnier Guillaume; Knebel Jean-Fran\u00e7ois; Stoll Chlo\u00e9; Christen Urvan; Durgnat Virginie; Hofmann Gregory; Burnier Michel; Wuerzner Gr\u00e9goire; Schoettker Patrick",
      "year": "2022",
      "journal": "Blood pressure",
      "doi": "10.1080/08037051.2022.2132214",
      "url": "https://pubmed.ncbi.nlm.nih.gov/36266938/",
      "mesh_terms": "Humans; Blood Pressure; Body Mass Index; Mobile Applications; Overweight; Blood Pressure Determination; Hypertension; Obesity",
      "keywords": "Blood pressure; application; cuffless; obese; optical signal; overweight; smartphone",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40038110",
      "title": "Advancing trabecular bone score (TBS): clinical performance of TBS version 4.0 with direct correction for soft tissue thickness-the osteolaus study.",
      "abstract": "UNLABELLED: This study compared TBS v4.0, which uses DXA-derived tissue thickness corrections, with TBS v3, which adjusts using BMI. TBS v4.0 improved soft tissue adjustments and maintained fracture risk prediction equivalence with TBS v3, enhancing applicability across diverse body compositions/phenotypes. Direct tissue thickness adjustment increases TBS's utility in osteoporosis assessment and management. PURPOSE: This study aimed to compare trabecular bone score (TBS) version 4.0, which uses direct tissue thickness correction via DXA measurements, with TBS version 3, which adjusts for soft tissues using body mass index (BMI). The objective was to assess the performance of TBS v4.0 compared to v3, for bone health evaluation and fracture risk assessment across diverse body compositions. METHODS: Data from the OsteoLaus cohort were analyzed. Associations between TBS, BMI, DXA-measured tissue thickness, visceral fat (VFAT), and android fat were examined using regression and correlation analyses. Machine learning, including Random Forest (RF) and SHapley Additive exPlanations (SHAP), explored TBS changes between versions. Five-year fracture risk was assessed using FRAX adjustment, and logistic regression. RESULTS: TBS v3 correlated with BMI (r\u2009=\u20090.110, p\u2009<\u20090 .001), VFAT mass (r\u2009=\u2009\u2009-\u20090.162, p\u2009<\u20090 .001), and soft tissue thickness (r\u2009=\u2009\u2009-\u20090.165, p\u2009<\u20090.001). TBS v4.0 demonstrated weaker correlations with BMI (r\u2009=\u2009\u2009-\u20090.057, p\u2009>\u20090.999), VFAT Mass (r\u2009=\u2009\u2009-\u20090.067, p\u2009>\u20090.779), and soft tissue thickness (r\u2009=\u2009\u2009-\u20090.114, p\u2009=\u20090.019). Differences between TBS versions were investigated with SHapley Additive exPlanations (SHAP) and explained by BMI, tissue thickness, VFAT, and gynoid fat. Logistic regression and Delong's test revealed no significant differences in vertebral fracture prediction between the two TBS versions (p\u2009=\u20090.564). FRAX adjustments were highly consistent between versions (r\u2009=\u20090.994, p\u2009<\u20090.001), with no evidence of calibration bias (p\u2009=\u20090.241). CONCLUSION: TBS v4.0 enhances the adjustment for regional soft tissue effects and results suggest comparable vertebral fracture risk prediction to TBS v3. Explainable AI provided insights into the contributions of BMI, tissue thickness, visceral fat, and gynoid fat to the observed changes between TBS versions. Incorporating direct tissue thickness adjustment improves TBS applicability across diverse body sizes and compositions.",
      "authors": "Gatineau Guillaume; Hind Karen; Shevroja Enisa; Gonzalez-Rodriguez Elena; Lamy Olivier; Hans Didier",
      "year": "2025",
      "journal": "Osteoporosis international : a journal established as result of cooperation between the European Foundation for Osteoporosis and the National Osteoporosis Foundation of the USA",
      "doi": "10.1007/s00198-025-07421-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40038110/",
      "mesh_terms": "Humans; Cancellous Bone; Absorptiometry, Photon; Female; Osteoporotic Fractures; Middle Aged; Aged; Body Mass Index; Male; Bone Density; Risk Assessment; Body Composition; Osteoporosis; Intra-Abdominal Fat; Aged, 80 and over; Lumbar Vertebrae",
      "keywords": "Bone fragility; Bone microarchitecture; Fracture risk; Osteoporosis; Trabecular bone score",
      "pub_types": "Journal Article; Comparative Study",
      "pmcid": "PMC12064620"
    },
    {
      "pmid": "33448937",
      "title": "A Bayesian Network Decision Support Tool for Low Back Pain Using a RAND Appropriateness Procedure: Proposal and Internal Pilot Study.",
      "abstract": "BACKGROUND: Low back pain (LBP) is an increasingly burdensome condition for patients and health professionals alike, with consistent demonstration of increasing persistent pain and disability. Previous decision support tools for LBP management have focused on a subset of factors owing to time constraints and ease of use for the clinician. With the explosion of interest in machine learning tools and the commitment from Western governments to introduce this technology, there are opportunities to develop intelligent decision support tools. We will do this for LBP using a Bayesian network, which will entail constructing a clinical reasoning model elicited from experts. OBJECTIVE: This paper proposes a method for conducting a modified RAND appropriateness procedure to elicit the knowledge required to construct a Bayesian network from a group of domain experts in LBP, and reports the lessons learned from the internal pilot of the procedure. METHODS: We propose to recruit expert clinicians with a special interest in LBP from across a range of medical specialties, such as orthopedics, rheumatology, and sports medicine. The procedure will consist of four stages. Stage 1 is an online elicitation of variables to be considered by the model, followed by a face-to-face workshop. Stage 2 is an online elicitation of the structure of the model, followed by a face-to-face workshop. Stage 3 consists of an online phase to elicit probabilities to populate the Bayesian network. Stage 4 is a rudimentary validation of the Bayesian network. RESULTS: Ethical approval has been obtained from the Research Ethics Committee at Queen Mary University of London. An internal pilot of the procedure has been run with clinical colleagues from the research team. This showed that an alternating process of three remote activities and two in-person meetings was required to complete the elicitation without overburdening participants. Lessons learned have included the need for a bespoke online elicitation tool to run between face-to-face meetings and for careful operational definition of descriptive terms, even if widely clinically used. Further, tools are required to remotely deliver training about self-identification of various forms of cognitive bias and explain the underlying principles of a Bayesian network. The use of the internal pilot was recognized as being a methodological necessity. CONCLUSIONS: We have proposed a method to construct Bayesian networks that are representative of expert clinical reasoning for a musculoskeletal condition in this case. We have tested the method with an internal pilot to refine the process prior to deployment, which indicates the process can be successful. The internal pilot has also revealed the software support requirements for the elicitation process to model clinical reasoning for a range of conditions. INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): DERR1-10.2196/21804.",
      "authors": "Hill Adele; Joyner Christopher H; Keith-Jopp Chloe; Yet Barbaros; Tuncer Sakar Ceren; Marsh William; Morrissey Dylan",
      "year": "2021",
      "journal": "JMIR research protocols",
      "doi": "10.2196/21804",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33448937/",
      "mesh_terms": "",
      "keywords": "Bayesian methods; back pain; consensus; decision making",
      "pub_types": "Journal Article",
      "pmcid": "PMC7846442"
    },
    {
      "pmid": "39547565",
      "title": "Daily high-resolution surface PM2.5 estimation over Europe by ML-based downscaling of the CAMS regional forecast.",
      "abstract": "Fine particulate matter (PM2.5) is a key air quality indicator due to its adverse health impacts. Accurate PM2.5 assessment requires high-resolution (e.g., atleast 1\u00a0km) daily data, yet current methods face challenges in balancing accuracy, coverage, and resolution. Chemical transport models such as those from the Copernicus Atmosphere Monitoring Service (CAMS) offer continuous data but their relatively coarse resolution can introduce uncertainties. Here we present a synergistic Machine Learning (ML)-based approach called S-MESH (Satellite and ML-based Estimation of Surface air quality at High resolution) for estimating daily surface PM2.5 over Europe at 1\u00a0km spatial resolution and demonstrate its performance for the years 2021 and 2022. The approach enhances and downscales the CAMS regional ensemble 24\u00a0h PM2.5 forecast by training a stacked XGBoost model against station observations, effectively integrating satellite-derived data and modeled meteorological variables. Overall, against station observations, S-MESH (mean absolute error (MAE) of 3.54\u00a0\u03bcg/m3) shows higher accuracy than the CAMS forecast (MAE of 4.18\u00a0\u03bcg/m3) and is approaching the accuracy of the CAMS regional interim reanalysis (MAE of 3.21\u00a0\u03bcg/m3), while exhibiting a significantly reduced mean bias (MB of -0.3\u00a0\u03bcg/m3 vs. -1.5\u00a0\u03bcg/m3 for the reanalysis). At the same time, S-MESH requires substantially less computational resources and processing time. At concentrations >20\u00a0\u03bcg/m3, S-MESH outperforms the reanalysis (MB of -7.3\u00a0\u03bcg/m3 and -10.3\u00a0\u03bcg/m3 respectively), and reliably captures high pollution events in both space and time. In the eastern study area, where the reanalysis often underestimates, S-MESH better captures high levels of PM2.5 mostly from residential heating. S-MESH effectively tracks day-to-day variability, with a temporal relative absolute error of 5% (reanalysis 10%). Exhibiting good performance at high pollution events coupled with its high spatial resolution and rapid estimation speed, S-MESH can be highly relevant for air quality assessments where both resolution and timeliness are critical.",
      "authors": "Shetty Shobitha; Hamer Paul D; Stebel Kerstin; Kylling Arve; Hassani Amirhossein; Berntsen Terje Koren; Schneider Philipp",
      "year": "2025",
      "journal": "Environmental research",
      "doi": "10.1016/j.envres.2024.120363",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39547565/",
      "mesh_terms": "Particulate Matter; Europe; Environmental Monitoring; Air Pollutants; Air Pollution; Machine Learning; Forecasting",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "38754804",
      "title": "Intensity-Specific Physical Activity Measured by Accelerometer, Genetic Susceptibility, and the Risk of Kidney Stone Disease: Results From the UK Biobank.",
      "abstract": "RATIONALE & OBJECTIVE: Kidney stone disease (KSD), a significant health care problem within both developed and developing countries, has been associated with genetic risk factors. An association between physical activity and KSD risk also has been hypothesized, but studies have yielded inconsistent findings. This study investigated the association between the intensity of physical activity and the incidence of KSD accounting for genetic risk. STUDY DESIGN: Prospective cohort study. SETTING & PARTICIPANTS: A total of 80,473 participants from the UK Biobank Study. EXPOSURE: Physical activity levels, including total physical activity (TPA), moderate-to-vigorous intensity physical activity (MVPA), and light-intensity physical activity (LPA), were measured using accelerometers and quantified using a machine learning model. A polygenic risk score (PRS) for KSD was also constructed. OUTCOME: Individuals with KSD were identified using the International Classification of Diseases, Tenth Revision (ICD-10), and procedure codes for KSD surgery. ANALYTICAL APPROACH: A Fine and Gray survival model was used to estimate the associations of incident KSD with TPA, MVPA, LPA, and PRS (as categorical variables). Restricted cubic splines were used to examine potential nonlinear associations within the fully adjusted models. RESULTS: During an average follow-up of 6.19 years, 421 participants developed KSD. Participants in the highest quartiles of TPA, MVPA, and LPA had lower adjusted rates of KSD compared with those in the lowest quartiles: HR, 0.50 (95% CI, 0.44-0.56), 0.57 (95% CI, 0.51-0.64), and 0.66 (95% CI, 0.59-0.74), respectively. TPA, MVPA, and LPA were associated with a lower risk of KSD in participants with low and high genetic predisposition for KSD. LIMITATIONS: Selection bias as participants who provided accelerometry data may have been more adherent to health care. CONCLUSIONS: Physical activity was negatively associated with the risk of KSD, regardless of the genetic risk. Future large studies are warranted to confirm and explain the mechanisms underlying these associations. PLAIN-LANGUAGE SUMMARY: The association between the intensity of physical activity (PA) and the incidence of kidney stone disease (KSD) after accounting for genetic risk is unclear. We conducted a comprehensive prospective cohort study utilizing participants from the UK Biobank to assess the intensity of PA using accelerometers. Our study findings indicated that greater total PA, moderate-to-vigorous-intensity PA, and light-intensity PA were each associated with a lower risk of KSD irrespective of an individual's genetic risk. Our study informs the understanding of risk factors for KSD.",
      "authors": "Liu Yashu; Ku Po-Wen; Li Zhenhua; Yang Honghao; Zhang Tingjing; Chen Liangkai; Xia Yang; Bai Song",
      "year": "2024",
      "journal": "American journal of kidney diseases : the official journal of the National Kidney Foundation",
      "doi": "10.1053/j.ajkd.2024.03.022",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38754804/",
      "mesh_terms": "Humans; Kidney Calculi; Male; Female; United Kingdom; Accelerometry; Middle Aged; Prospective Studies; Exercise; Genetic Predisposition to Disease; Biological Specimen Banks; Aged; Risk Factors; Incidence; Adult; Cohort Studies; Risk Assessment; UK Biobank",
      "keywords": "Accelerometer; cohort study; genetic predisposition; kidney stone disease; physical activity",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "39625748",
      "title": "The University of California Study of Outcomes in Mothers and Infants (a Population-Based Research Resource): Retrospective Cohort Study.",
      "abstract": "BACKGROUND: Population-based databases are valuable for perinatal research. The California Department of Health Care Access and Information (HCAI) created a linked birth file covering the years 1991 through 2012. This file includes birth and fetal death certificate records linked to the hospital discharge records of the birthing person and infant. In 2019, the University of California Study of Outcomes in Mothers and Infants received approval to create similar linked birth files for births from 2011 onward, with 2 years of overlapping birth files to allow for linkage comparison. OBJECTIVE: This paper aims to describe the University of California Study of Outcomes in Mothers and Infants linkage methodology, examine the linkage quality, and discuss the benefits and limitations of the approach. METHODS: Live birth and fetal death certificates were linked to hospital discharge records for California infants between 2005 and 2020. The linkage algorithm includes variables such as birth hospital and date of birth, and linked record selection is made based on a \"link score.\" The complete file includes California Vital Statistics and HCAI hospital discharge records for the birthing person (1 y before delivery and 1 y after delivery) and infant (1 y after delivery). Linkage quality was assessed through a comparison of linked files and California Vital Statistics only. Comparisons were made to previous linked birth files created by the HCAI for 2011 and 2012. RESULTS: Of the 8,040,000 live births, 7,427,738 (92.38%) California Vital Statistics live birth records were linked to HCAI records for birthing people, 7,680,597 (95.53%) birth records were linked to HCAI records for the infant, and 7,285,346 (90.61%) California Vital Statistics birth records were linked to HCAI records for both the birthing person and the infant. The linkage rates were 92.44% (976,526/1,056,358) for Asian and 86.27% (28,601/33,151) for Hawaiian or Pacific Islander birthing people. Of the 44,212 fetal deaths, 33,355 (75.44%) had HCAI records linked to the birthing person. When assessing variables in both California Vital Statistics and hospital records, the percentage was greatest when using both sources: the rates of gestational diabetes were 4.52% (329,128/7,285,345) in the California Vital Statistics records, 8.2% (597,534/7,285,345) in the HCAI records, and 9.34% (680,757/7,285,345) when using both data sources. CONCLUSIONS: We demonstrate that the linkage strategy used for this data platform is similar in linkage rate and linkage quality to the previous linked birth files created by the HCAI. The linkage provides higher rates of crucial variables, such as diabetes, compared to birth certificate records alone, although selection bias from the linkage must be considered. This platform has been used independently to examine health outcomes, has been linked to environmental datasets and residential data, and has been used to obtain and examine maternal serum and newborn blood spots.",
      "authors": "Baer Rebecca J; Bandoli Gretchen; Jelliffe-Pawlowski Laura; Chambers Christina D",
      "year": "2024",
      "journal": "JMIR public health and surveillance",
      "doi": "10.2196/59844",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39625748/",
      "mesh_terms": "Humans; California; Retrospective Studies; Female; Infant, Newborn; Pregnancy; Cohort Studies; Birth Certificates; Medical Record Linkage; Infant; Universities; Mothers; Adult",
      "keywords": "California; administrative data; adverse outcome; birth certificate; birth defects; birth outcome; children; data collection; disparities; hospital discharge; infant outcome; linkage; policy; pregnancy; pregnancy outcome; prenatal; preterm birth; vital statistics",
      "pub_types": "Journal Article",
      "pmcid": "PMC11653030"
    },
    {
      "pmid": "39868692",
      "title": "Concurrent Validity and Reliability of In-Person and Supervised Remote STEADI Fall Risk Assessment in Community-Dwelling Older Adults.",
      "abstract": "BACKGROUND AND PURPOSE: Physical therapists play a vital role in preventing and managing falls in older adults. With advancements in digital health and technology, community fall prevention programs need to adopt valid and reliable telehealth-based assessments. The purpose of this study was to evaluate the validity and reliability of the telehealth-based timed up and go (TUG) test, 30-second chair stand test (30s-CST), and four-stage (4-stage) balance test as functional components of the Stopping Elderly Accidents, Deaths, and Injuries (STEADI) fall risk assessment. METHODS: This cross-sectional study was conducted using a convenience sample of community-dwelling older adults. The TUG, 30s-CST, and 4-stage balance test were administered in random order in 1 session in the participant's own environment. Performance was scored concurrently by an in-person and synchronous telehealth rater. The video recordings of the performances were scored by an asynchronous telehealth rater on days 1 and 30 for inter- and intra-rater reliability. Additionally, participants performed the TUG test twice, using the distance measured by the participant and the distance measured by the in-person rater. To establish the validity of telehealth-based STEADI fall risk assessments, the Intraclass Correlation Coefficient (ICC), Pearson correlation coefficient, and 95% limits of agreement were derived. Inter- and intra-rater reliability were established by calculating ICC using a 2-way mixed model. Bland-Altman plots were created for nonsignificant proportional bias tests. RESULTS AND DISCUSSION: Thirty community-dwelling older adults participated. Based on the STEADI algorithm, 13 participants were classified as having a moderate fall risk. A comparison of in-person and synchronous telehealth ratings showed excellent ICCs (0.97-0.99) and relationships (r\u00a0=\u00a00.94-0.98). Bland-Altman plots were created for all tests except for the 30s-CST (t\u00a0=\u00a0-2.168, P =\u00a0.04). All tests had good to excellent inter-rater reliability (ICC\u00a0=\u00a00.84-1.00) and intra-rater reliability (0.77-1.00). No adverse events were reported. CONCLUSION: This study suggests that telehealth-administered functional tests in the STEADI fall risk assessment are valid and reliable when technology, environment, camera view, and angle are optimally managed.",
      "authors": "Jasper Amie; Karim Rania; Vitente Arvie C; Rafael Carmina Minnie; Tayag Eleazar; Uy Samuel John M; Baloy Rodiel K; Lazaro Rolando",
      "year": "2025",
      "journal": "Journal of geriatric physical therapy (2001)",
      "doi": "10.1519/JPT.0000000000000446",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39868692/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "32983235",
      "title": "Predicting secondary organic aerosol phase state and viscosity and its effect on multiphase chemistry in a regional-scale air quality model.",
      "abstract": "Atmospheric aerosols are a significant public health hazard and have substantial impacts on the climate. Secondary organic aerosols (SOAs) have been shown to phase separate into a highly viscous organic outer layer surrounding an aqueous core. This phase separation can decrease the partitioning of semi-volatile and low-volatile species to the organic phase and alter the extent of acid-catalyzed reactions in the aqueous core. A new algorithm that can determine SOA phase separation based on their glass transition temperature (T g), oxygen to carbon (O : C) ratio and organic mass to sulfate ratio, and meteorological conditions was implemented into the Community Multiscale Air Quality Modeling (CMAQ) system version 5.2.1 and was used to simulate the conditions in the continental United States for the summer of 2013. SOA formed at the ground/surface level was predicted to be phase separated with core-shell morphology, i.e., aqueous inorganic core surrounded by organic coating 65.4 % of the time during the 2013 Southern Oxidant and Aerosol Study (SOAS) on average in the isoprene-rich southeastern United States. Our estimate is in proximity to the previously reported ~ 70 % in literature. The phase states of organic coatings switched between semi-solid and liquid states, depending on the environmental conditions. The semi-solid shell occurring with lower aerosol liquid water content (western United States and at higher altitudes) has a viscosity that was predicted to be 102-1012 Pa s, which resulted in organic mass being decreased due to diffusion limitation. Organic aerosol was primarily liquid where aerosol liquid water was dominant (eastern United States and at the surface), with a viscosity < 102 Pa s. Phase separation while in a liquid phase state, i.e., liquid-liquid phase separation (LLPS), also reduces reactive uptake rates relative to homogeneous internally mixed liquid morphology but was lower than aerosols with a thick viscous organic shell. The sensitivity cases performed with different phase-separation parameterization and dissolution rate of isoprene epoxydiol (IEPOX) into the particle phase in CMAQ can have varying impact on fine particulate matter (PM2.5) organic mass, in terms of bias and error compared to field data collected during the 2013 SOAS. This highlights the need to better constrain the parameters that govern phase state and morphology of SOA, as well as expand mechanistic representation of multiphase chemistry for non-IEPOX SOA formation in models aided by novel experimental insights.",
      "authors": "Schmedding Ryan; Rasool Quazi Z; Zhang Yue; Pye Havala O T; Zhang Haofei; Chen Yuzhi; Surratt Jason D; Lopez-Hilfiker Felipe D; Thornton Joel A; Goldstein Allen H; Vizuete William",
      "year": "2020",
      "journal": "Atmospheric chemistry and physics",
      "doi": "10.5194/acp-20-8201-2020",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32983235/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC7510956"
    },
    {
      "pmid": "28583104",
      "title": "Development and validation of a claims-based measure as an indicator for disease status in patients with multiple sclerosis treated with disease-modifying drugs.",
      "abstract": "BACKGROUND: Administrative healthcare claims data provide a mechanism for assessing and monitoring multiple sclerosis (MS) disease status across large, clinically representative \"real-world\" populations. The estimation of MS disease status using administrative claims can be a challenge, however, due to a lack of detailed clinical information. Retrospective claims analyses in MS have traditionally used rates of MS relapses to approximate disease status. Healthcare costs may be alternate, broader claims-based indicators of disease activity because costs reflect multiple facets of care of patients with MS, and there is a strong correlation between quality of life of patients with MS and costs of the disease. This study developed, tested, and validated a healthcare cost-based measure to serve as an indicator of overall disease status in patients with MS treated with disease-modifying drugs (DMDs) utilizing administrative claims. METHODS: Using IMS Health Real World Data Adjudicated Claims - US data (January 2006-June 2013), a negative binomial regression predicted annual all-cause medical costs. Coefficients reaching statistical significance (p\u00a0<\u00a00.05) and increasing costs by \u22655% were selected for inclusion into an MS-specific severity score (scale of 0 to 100). Components of the score included rehabilitation services, altered mental state, pain, disability, stiffness, balance disorder, urinary incontinence, numbness, malaise/fatigue, and infections. Coefficient weights represented each predictor's contribution. The predictive model was derived using 50% of a random sample and tested/validated using the remaining 50%. RESULTS: Average overall predicted annual total medical cost was $11,134 (development sample, n\u00a0=\u00a011,384, vs. $10,528 actual) and $11,303 (validation sample, n\u00a0=\u00a011,385, vs. $10,620 actual). The model had consistent bias (approximately +$600 or +6% of actual costs) for both samples. In the validation sample, mean MS disease status scores were 0.24, 8.95, and 21.77 for low, medium, and high tertiles, respectively. Mean costs were most accurately predicted among less severe patients ($5243 predicted vs. $5233 actual cost for lowest tertile). CONCLUSION: The algorithm developed in this study provides an initial step to helping understand and potentially predict cost changes for a commercially insured MS population.",
      "authors": "Munsell Michael; Frean Molly; Menzin Joseph; Phillips Amy L",
      "year": "2017",
      "journal": "BMC neurology",
      "doi": "10.1186/s12883-017-0887-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/28583104/",
      "mesh_terms": "Adolescent; Adult; Databases as Topic; Delivery of Health Care; Health Care Costs; Humans; Middle Aged; Multiple Sclerosis; Quality of Life; Recurrence; Retrospective Studies; Young Adult",
      "keywords": "Costs; Disease status measure; Multiple sclerosis; Retrospective database; Validation",
      "pub_types": "Journal Article; Validation Study",
      "pmcid": "PMC5460356"
    },
    {
      "pmid": "41509167",
      "title": "Condylar Bone Quality in Growing Children Is Associated With Genetic Polymorphisms in Genes Involved in Calcium and Phosphate Maintenance.",
      "abstract": "Single nucleotide polymorphisms (SNPs) play a crucial role in regulating vitamin D, parathyroid hormone (PTH), and calcitonin concentrations, which are involved in bone health. Some reports suggested that fractal analysis is useful in the morphometric analysis of the mandible trabecular bone in panoramic radiographs. Therefore, we investigated if SNPs in genes that influence vitamin D, calcitonin, and PTH levels are involved in condylar bone quality during the active growing phase of the mandible. Fractal dimension was obtained from the condyle region of interest (ROI) using panoramic radiographs and used to measure the complexity and the microarchitecture of the bone. Fractal dimension using the box-counting algorithm was then calculated. In order to avoid information bias, a script to automate the commands in the software ImageJ was generated to ensure consistency and minimize the potential for human error during the data analysis process. SNPs in vitamin D receptor (VDR), cytochrome P450 family 27 subfamily B member 1 (CYP27B1), cytochrome P450 family 24 subfamily A member 1 (CYP24A1), vitamin D binding protein (VDBP), SEC23 homolog A (SEC23A), calcitonin receptor (CALCR), and parathyroid hormone (PTH) were analyzed. DNA extracted from saliva was used for genotyping analysis of VDR (rs7975232, rs2228570, and rs1544410), CYP27B1 (rs4646536), CYP24A1 (rs927650), VDBP (rs4588), SEC23A (rs8018720), CALCR (rs1801197), and PTH (rs6256, rs307247, and rs694). A statistical analysis was performed with an alpha error tolerance of 5%. A total of 100 children were included; 50 (50%) were boys and the age ranged from 5 to 14 years old. Fractal dimensions were compared among genotypes. The GT (mean = 1.20 and standard\u2009error = 0.03, p = 0.024) and TT genotypes (mean = 1.16 and standard\u2009error = 0.06, p = 0.047) in the gene VDBP (rs4588) presented lower fractal dimension. The GG genotype in SEC23A (rs8018720) (mean = 1.34 and standard\u2009error = 0.03, p = 0.011) and the TC genotype in PTH (rs694) showed an increased fractal dimension (mean = 1.29 and standard\u2009error = 0.03, p = 0.020). In conclusion, SNPs in VDBP, SEC23A, and PTH encoding genes are associated with mandibular condylar trabecular bone structure in children.",
      "authors": "K\u00fcchler Erika Calvano; Reis Caio Luiz Bitencourt; Fonseca-Souza Gabriela; Hemming Daniel; Baratto-Filho Flares; de Araujo Cristiano Miranda; Beisel-Memmert Svenja; Feltrin-Souza Juliana; Meger Michelle Nascimento; Cavalcante-Le\u00e3o Bianca Lopes",
      "year": "2026",
      "journal": "BioMed research international",
      "doi": "10.1155/bmri/9337029",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41509167/",
      "mesh_terms": "Humans; Polymorphism, Single Nucleotide; Child; Male; Female; Calcium; Parathyroid Hormone; Phosphates; Receptors, Calcitriol; Adolescent; Mandible",
      "keywords": "fractal dimension analysis; mandibular condyle; panoramic radiography; vitamin D receptor",
      "pub_types": "Journal Article",
      "pmcid": "PMC12776005"
    },
    {
      "pmid": "37495389",
      "title": "Implications of rapid population growth on survey design and HIV estimates in the Rakai Community Cohort Study (RCCS), Uganda.",
      "abstract": "OBJECTIVE: Since rapid population growth challenges longitudinal population-based HIV cohorts in Africa to maintain coverage of their target populations, this study evaluated whether the exclusion of some residents due to growing population size biases key HIV metrics like prevalence and population-level viremia. DESIGN, SETTING AND PARTICIPANTS: Data were obtained from the Rakai Community Cohort Study (RCCS) in south central Uganda, an open population-based cohort which began excluding some residents of newly constructed household structures within its surveillance boundaries in 2008. The study includes adults aged 15-49 years who were censused from 2019 to 2020. MEASURES: We fit ensemble machine learning models to RCCS census and survey data to predict HIV seroprevalence and viremia (prevalence of those with viral load >1000 copies/mL) in the excluded population and evaluated whether their inclusion would change overall estimates. RESULTS: Of the 24\u2009729 census-eligible residents, 2920 (12%) residents were excluded from the RCCS because they were living in new households. The predicted seroprevalence for these excluded residents was 10.8% (95% CI: 9.6% to 11.8%)-somewhat lower than 11.7% (95% CI: 11.2% to 12.3%) in the observed sample. Predicted seroprevalence for younger excluded residents aged 15-24 years was 4.9% (95% CI: 3.6% to 6.1%)-significantly higher than that in the observed sample for the same age group (2.6% (95% CI: 2.2% to 3.1%)), while predicted seroprevalence for older excluded residents aged 25-49 years was 15.0% (95% CI: 13.3% to 16.4%)-significantly lower than their counterparts in the observed sample (17.2% (95% CI: 16.4% to 18.1%)). Over all ages, the predicted prevalence of viremia in excluded residents (3.7% (95% CI: 3.0% to 4.5%)) was significantly higher than that in the observed sample (1.7% (95% CI: 1.5% to 1.9%)), resulting in a higher overall population-level viremia estimate of 2.1% (95% CI: 1.8% to 2.4%). CONCLUSIONS: Exclusion of residents in new households may modestly bias HIV viremia estimates and some age-specific seroprevalence estimates in the RCCS. Overall, HIV seroprevalence estimates were not significantly affected.",
      "authors": "Khalifa Aleya; Ssekubugu Robert; Lessler Justin; Wawer Maria; Santelli John S; Hoffman Susie; Nalugoda Fred; Lutalo Tom; Ndyanabo Anthony; Ssekasanvu Joseph; Kigozi Godfrey; Kagaayi Joseph; Chang Larry W; Grabowski Mary Kathryn",
      "year": "2023",
      "journal": "BMJ open",
      "doi": "10.1136/bmjopen-2022-071108",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37495389/",
      "mesh_terms": "Adult; Humans; Cohort Studies; HIV Infections; Uganda; Seroepidemiologic Studies; Population Growth; Viremia; Prevalence",
      "keywords": "HIV & AIDS; demography; epidemiologic studies; epidemiology; public health; statistics & research methods",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC10373715"
    },
    {
      "pmid": "34477126",
      "title": "Heterogeneity by global and textural feature analysis in F-18 FP-CIT brain PET images for diagnosis of Parkinson's disease.",
      "abstract": "BACKGROUND: The quantification of heterogeneity for the striatum and whole brain with F-18 FP-CIT PET images will be useful for diagnosis. The index obtained from texture analysis on PET images is related to pathological change that the neuronal loss of the nigrostriatal tract is heterogeneous according to the disease state. The aim of this study is to evaluate various heterogeneity indices of F-18 FP-CIT PET images in the diagnosis of Parkinson's disease (PD) patients and to access the diagnostic accuracy of the indices using machine learning (ML). METHODS: This retrospective study included F-18 FP-CIT PET images of 31 PD and 31 age-matched health controls (HC). The volume of interest was delineated according to iso-contour lines around standardized uptake value (SUV) 3.0\u200ag/ml for each region of the striatum by PMod 3.603. One hundred eight heterogeneity indices were calculated using CGITA to find indices from which the PD and HC were classified using statistical significance. PD group was classified by constructing a 2-dimensional or 3-dimensional phase space quantifier using these heterogeneity indices. We used 71 heterogeneity indices to classify PD from HC using ML for dimensional reduction. RESULTS: The heterogeneity indices for classifying PD from HC were size-zone variability, contrast, inverse difference-moment, and homogeneity in the order of low P value. Three-dimensional quantifiers composed of normalized-contrast, code-similarity, and contrast were more clearly classified than 2-dimensional ones. After 71-dimensional reduction using PCA, classification was possible by logistic regression with 91.3% accuracy. The 2 groups were classified with an accuracy of 85.5% using the support vector machine and 88.4% using the random forest. The classification accuracy using the eXtreme Gradient Boosting was 95.7%, and feature importance was highest in order of SUV bias-corrected kurtosis, size-zone-variability, intensity-variability, and high-intensity-zone-variability. CONCLUSION: It was confirmed that PD patients is more clearly classified than the conventional 2-dimensional quantifier by introducing a 3-dimensional phase space quantifier. We observed that ML can be used to classify the 2 groups in an easy and explanatory manner. For the discrimination of the disease, 24 heterogeneity indices were found to be statistically useful, and the major cut-off values of 3 heterogeneity indices were size-zone variability (1906.44), intensity variability (129.21), and high intensity zone emphasis (800.29).",
      "authors": "Yoon Hyun Jin; Cho Kook; Kim Woong Gon; Jeong Young-Jin; Jeong Ji-Eun; Kang Do-Young",
      "year": "2021",
      "journal": "Medicine",
      "doi": "10.1097/MD.0000000000026961",
      "url": "https://pubmed.ncbi.nlm.nih.gov/34477126/",
      "mesh_terms": "Aged; Female; Fluorodeoxyglucose F18; Humans; Male; Middle Aged; Neuroimaging; Parkinson Disease; Positron-Emission Tomography; Retrospective Studies",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC8415938"
    },
    {
      "pmid": "38041041",
      "title": "AI and semantic ontology for personalized activity eCoaching in healthy lifestyle recommendations: a meta-heuristic approach.",
      "abstract": "BACKGROUND: Automated coaches (eCoach) can help people lead a healthy lifestyle (e.g., reduction of sedentary bouts) with continuous health status monitoring and personalized recommendation generation with artificial intelligence (AI). Semantic ontology can play a crucial role in knowledge representation, data integration, and information retrieval. METHODS: This study proposes a semantic ontology model to annotate the AI predictions, forecasting outcomes, and personal preferences to conceptualize a personalized recommendation generation model with a hybrid approach. This study considers a mixed activity projection method that takes individual activity insights from the univariate time-series prediction and ensemble multi-class classification approaches. We have introduced a way to improve the prediction result with a residual error minimization (REM) technique and make it meaningful in recommendation presentation with a Na\u00efve-based interval prediction approach. We have integrated the activity prediction results in an ontology for semantic interpretation. A SPARQL query protocol and RDF Query Language (SPARQL) have generated personalized recommendations in an understandable format. Moreover, we have evaluated the performance of the time-series prediction and classification models against standard metrics on both imbalanced and balanced public PMData and private MOX2-5 activity datasets. We have used Adaptive Synthetic (ADASYN) to generate synthetic data from the minority classes to avoid bias. The activity datasets were collected from healthy adults (n\u2009=\u200916 for public datasets; n\u2009=\u200915 for private datasets). The standard ensemble algorithms have been used to investigate the possibility of classifying daily physical activity levels into the following activity classes: sedentary (0), low active (1), active (2), highly active (3), and rigorous active (4). The daily step count, low physical activity (LPA), medium physical activity (MPA), and vigorous physical activity (VPA) serve as input for the classification models. Subsequently, we re-verify the classifiers on the private MOX2-5 dataset. The performance of the ontology has been assessed with reasoning and SPARQL query execution time. Additionally, we have verified our ontology for effective recommendation generation. RESULTS: We have tested several standard AI algorithms and selected the best-performing model with optimized configuration for our use case by empirical testing. We have found that the autoregression model with the REM method outperforms the autoregression model without the REM method for both datasets. Gradient Boost (GB) classifier outperforms other classifiers with a mean accuracy score of 98.00%, and 99.00% for imbalanced PMData and MOX2-5 datasets, respectively, and 98.30%, and 99.80% for balanced PMData and MOX2-5 datasets, respectively. Hermit reasoner performs better than other ontology reasoners under defined settings. Our proposed algorithm shows a direction to combine the AI prediction forecasting results in an ontology to generate personalized activity recommendations in eCoaching. CONCLUSION: The proposed method combining step-prediction, activity-level classification techniques, and personal preference information with semantic rules is an asset for generating personalized recommendations.",
      "authors": "Chatterjee Ayan; Pahari Nibedita; Prinz Andreas; Riegler Michael",
      "year": "2023",
      "journal": "BMC medical informatics and decision making",
      "doi": "10.1186/s12911-023-02364-4",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38041041/",
      "mesh_terms": "Humans; Artificial Intelligence; Heuristics; Semantics; Algorithms; Information Storage and Retrieval",
      "keywords": "Autoregression; Ensemble; Interval prediction; Ontology; Personalized recommendation; Physical activity; Residual error minimization; Time-series; eCoach",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC10693173"
    },
    {
      "pmid": "29565955",
      "title": "Chronic Pelvic Pain: Neurogenic or Non-Neurogenic? Warm Detection Threshold Testing Supports a Diagnosis of Pudendal Neuropathy.",
      "abstract": "BACKGROUND: Chronic pelvic pain (CPP) in men is rarely considered to have a neurogenic (neuropathic) basis. Separation of neurogenic from non-neurogenic pain is possible using clinical examination and neurophysiologic tests. A definite diagnosis of neuropathic pain can be made. OBJECTIVES: We aim to demonstrate that definite pudendal neuropathic abnormalities can be supported by a quantitative sensory test (QST) called the warm temperature threshold detection (WDT) test in men with CPP. STUDY DESIGN: This is a retrospective review of 25 consecutive, unrecruited men evaluated in a private clinical practice beginning on January 1, 2010. The techniques of examination and neurophysiological testing have been standard since 2003. SETTING: A private practice that is a referral center because of its focus on CPP of a neuropathic basis. METHODS: Pinprick sensation was evaluated at 6 sites in the pudendal nerve territory (3 branches on each side). A WDT was performed at each nerve branch using a Physitemp NTE-2C Thermoprobe and Controller. This used a stepping algorithm from a neutral baseline of 31.5\u00b0C. Quantitative and subjective \"qualitative responses\" were recorded. Our preferred symptom score to evaluate pain level at consultation is the National Institutes of Health Chronic Prostatitis Symptom Index (NIH-CPSI). The results become the benchmark for comparison of responses following future treatments (not discussed). When possible, microscopy was used to evaluate prostate secretions for inflammatory prostatitis except in 2 men with CPP who had undergone previous radical prostatectomy for cancer. Observations were made of the skin in the pudendal territory. Our specific evaluation for neuropathy also sought evidence of multiple additional neuropathic pelvic pain generators. RESULTS: The WDT was abnormal in all men (88% quantitative), and pinprick sensation was abnormal in 92% of the men. The combination of tests provided a diagnosis of pudendal neuropathy in all patients, resulting in an accurate and timely explanation of the neurogenic basis of their CPP symptoms. The NIH-CPSI scores ranged from 10 to 35 (median 25). Four of 15 men had inflammatory prostatitis in addition to pudendal neuropathy. LIMITATIONS: There is selection bias because the men were either self-referred, suspecting their diagnosis from internet searches, or were referred by physicians who were aware of the focus of this clinical practice. The warm temperature testing used established normal values for the men. The NIH-CPSI does not evaluate sexual or bowel symptoms. Sensitivity or specificity values for the tests could not be obtained. CONCLUSIONS: A possible neuropathic basis for CPP in men can be suspected from symptoms and history of activities. A probable diagnosis of neuropathy can be determined using a pinprick sensory evaluation in the pudendal territory. A definite diagnosis of pudendal neuropathy can be made using WDT. The combination of these 2 examinations demonstrated pudendal neuropathy in 100% of this cohort.The institutional review board deemed this study met criteria for exemption. KEY WORDS: Chronic pelvic pain, pudendal neuropathy, quantitative sensory testing, warm temperature detection threshold test, neuropathic pelvic pain, definite diagnosis of neuropathy, chronic prostatitis.",
      "authors": "Antolak Stanley J; Antolak Christopher M",
      "year": "2018",
      "journal": "Pain physician",
      "doi": "",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29565955/",
      "mesh_terms": "Adult; Aged; Chronic Disease; Chronic Pain; Humans; Male; Middle Aged; Neurologic Examination; Pain Measurement; Pelvic Pain; Pudendal Nerve; Pudendal Neuralgia; Retrospective Studies",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "41091469",
      "title": "Glucose-Lowering Medication Classes and Cardiovascular Outcomes in Patients With Type 2 Diabetes.",
      "abstract": "IMPORTANCE: Major adverse cardiovascular events (MACEs) are primary causes of morbidity and mortality in adults with type 2 diabetes (T2D), yet few head-to-head randomized trials have compared the effects of glucose-lowering medications on MACEs, and most observational analyses are limited by inadequate bias adjustment methods. OBJECTIVE: To compare the effectiveness of sustained exposure to 4 classes of glucose-lowering medications (sulfonylureas, dipeptidyl peptidase-4 inhibitors [DPP4is], sodium-glucose cotransporter-2 inhibitors [SGLT2is], and glucagon-like peptide-1 receptor agonists [GLP-1RAs]) on MACEs in US adults with T2D using modern causal methods combined with machine learning. DESIGN, SETTING, AND PARTICIPANTS: This comparative effectiveness study included adults with T2D who were members of 6 large US health care delivery systems and initiated treatment with 1 of 4 medication classes (sulfonylureas, DPP4is, SGLT2is, and GLP-1RAs) between January 1, 2014, and December 31, 2021. Data analysis was conducted from May 1 to December 31, 2024. EXPOSURE: New use of a sulfonylurea, DPP4i, SGLT2i, or GLP-1RA based on filled prescriptions. MAIN OUTCOMES AND MEASURES: The primary outcome was MACEs defined as nonfatal myocardial infarction, nonfatal stroke, or cardiovascular death. Analyses were conducted using targeted learning within a trial emulation framework. Heterogeneity of treatment effects was assessed for prespecified subgroups. RESULTS: This study included 296 676 adults. The cohort for emulating a 4-arm trial included a subset of 241 981 adults (mean [SD] age, 57.2 [12.9] years; 54.3% male) with T2D. In adjusted analyses, 2.5-year MACE risk was lowest in patients with sustained exposure to GLP-1RAs, followed by SGLT2is , sulfonylureas, and DPP4is. Comparing DPP4is with sulfonylureas and SGLT2is with GLP-1RAs, the 2.5-year cumulative risk difference was 1.9% (95% CI, 1.1%-2.7%) and 1.5% (1.1%-1.9%), respectively. Risk differences in patients with vs without atherosclerotic cardiovascular disease (ASCVD) were similar in direction but typically much smaller for patients without ASCVD. Evidence of a benefit of GLP-1RAs over SGLT2is was most pronounced in patients with baseline ASCVD or heart failure (HF), age 65 years or older, or low to moderate kidney impairment but was not found in patients younger than 50 years. CONCLUSIONS AND RELEVANCE: In this study, MACE risk varied significantly by medication class, with most protection achieved with sustained treatment with GLP-1RAs followed by SGLT2is, sulfonylureas, and DPP4is. The magnitude of benefit of GLP-1RAs over SGLT2is depended on baseline age, ASCVD, HF, and kidney impairment. These results, along with consideration of cost, availability, and collateral clinical benefits, may inform treatment decisions for adults with T2D.",
      "authors": "Neugebauer Romain; An Jaejin; Dombrowski Sarah Krahe; Oshiro Caryn; Cassidy-Bushrow Andrea; Gilliam Lisa; Simonson Gregg; Karter Andrew J; Bergenstal Richard; Finertie Holly; Yassin Maher M; Knowlton Greg; Lin Sharon R; Dyer Wendy; Pimentel Noel; Izadian Keanu; Schmittdiel Julie; Thomas Tainayah W; Hooker Stephanie A; Nolan Margaret B; Wright Eric; Aurora Lindsey; Rodriguez Luis A; Kaur Jasleen; Adams Alyce S; van der Laan Mark J; O'Connor Patrick J",
      "year": "2025",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2025.36100",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41091469/",
      "mesh_terms": "Humans; Diabetes Mellitus, Type 2; Male; Female; Middle Aged; Hypoglycemic Agents; Cardiovascular Diseases; Dipeptidyl-Peptidase IV Inhibitors; Sodium-Glucose Transporter 2 Inhibitors; Aged; Sulfonylurea Compounds; Glucagon-Like Peptide-1 Receptor Agonists; Comparative Effectiveness Research; United States",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12529185"
    },
    {
      "pmid": "32791199",
      "title": "Protocol for a national probability survey using home specimen collection methods to assess prevalence and incidence of SARS-CoV-2 infection and antibody response.",
      "abstract": "PURPOSE: The U.S. response to the SARS-CoV-2 epidemic has been hampered by early and ongoing delays in testing for infection; without data on where infections were occurring and the magnitude of the epidemic, early public health responses were not data-driven. Understanding the prevalence of SARS-CoV-2 infections and immune response is critical to developing and implementing effective public health responses. Most serological surveys have been limited to localities that opted to conduct them and/or were based on convenience samples. Moreover, results of antibody testing might be subject to high false positive rates in the setting of low prevalence of immune response and imperfect test specificity. METHODS: We will conduct a national serosurvey for SARS-CoV-2 PCR positivity and immune experience. A probability sample of U.S. addresses will be mailed invitations and kits for the self-collection of anterior nares swab and finger prick dried blood spot specimens. Within each sampled household, one adult 18\u00a0years or older will be randomly selected and asked to complete a questionnaire and to collect and return biological specimens to a central laboratory. Nasal swab specimens will be tested for SARS-CoV-2 RNA by RNA PCR; dried blood spot specimens will be tested for antibodies to SARS-CoV-2 (i.e., immune experience) by enzyme-linked immunoassays. Positive screening tests for antibodies will be confirmed by a second antibody test with different antigenic basis to improve predictive value of positive (PPV) antibody test results. All persons returning specimens in the baseline phase will be enrolled into a follow-up cohort and mailed additional specimen collection kits 3\u00a0months after baseline. A subset of 10% of selected households will be invited to participate in full household testing, with tests offered for all household members aged \u22653\u00a0years. The main study outcomes will be period prevalence of infection with SARS-CoV-2 and immune experience, and incidence of SARS-CoV-2 infection and antibody responses. RESULTS: Power calculations indicate that a national sample of 4000 households will facilitate estimation of national SARS-CoV-2 infection and antibody prevalence with acceptably narrow 95% confidence intervals across several possible scenarios of prevalence levels. Oversampling in up to seven populous states will allow for prevalence estimation among subpopulations. Our 2-stage algorithm for antibody testing produces acceptable PPV at prevalence levels \u22651.0%. Including oversamples in states, we expect to receive data from as many as 9156 participants in 7495 U.S. households. CONCLUSIONS: In addition to providing robust estimates of prevalence of SARS-CoV-2 infection and immune experience, we anticipate this study will establish a replicable methodology for home-based SARS-CoV-2 testing surveys, address concerns about selection bias, and improve positive predictive value of serology results. Prevalence estimates of SARS-CoV-2 infection and immune experience produced by this study will greatly improve our understanding of the spectrum of COVID-19 disease, its current penetration in various demographic, geographic, and occupational groups, and inform the range of symptoms associated with infection. These data will inform resource needs for control of the ongoing epidemic and facilitate data-driven decisions for epidemic mitigation strategies.",
      "authors": "Siegler Aaron J; Sullivan Patrick S; Sanchez Travis; Lopman Ben; Fahimi Mansour; Sailey Charles; Frankel Martin; Rothenberg Richard; Kelley Colleen F; Bradley Heather",
      "year": "2020",
      "journal": "Annals of epidemiology",
      "doi": "10.1016/j.annepidem.2020.07.015",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32791199/",
      "mesh_terms": "Betacoronavirus; COVID-19; COVID-19 Testing; Clinical Laboratory Techniques; Clinical Trial Protocols as Topic; Coronavirus; Coronavirus Infections; Disease Outbreaks; Humans; Pandemics; Pneumonia, Viral; RNA, Viral; SARS-CoV-2",
      "keywords": "PCR testing; Probability sampling methods; SARS-CoV-2 infection; SARS-CoV-2 serology; Serology",
      "pub_types": "Journal Article; Research Support, N.I.H., Extramural",
      "pmcid": "PMC7417272"
    },
    {
      "pmid": "32452356",
      "title": "Fluoxetine to improve functional outcomes in patients after acute stroke: the FOCUS RCT.",
      "abstract": "BACKGROUND: Our Cochrane review of selective serotonin inhibitors for stroke recovery indicated that fluoxetine may improve functional recovery, but the trials were small and most were at high risk of bias. OBJECTIVES: The Fluoxetine Or Control Under Supervision (FOCUS) trial tested the hypothesis that fluoxetine improves recovery after stroke. DESIGN: The FOCUS trial was a pragmatic, multicentre, parallel-group, individually randomised, placebo-controlled trial. SETTING: This trial took place in 103 UK hospitals. PARTICIPANTS: Patients were eligible if they were aged \u2265\u200918 years, had a clinical stroke diagnosis, with focal neurological deficits, between 2 and 15 days after onset. INTERVENTIONS: Patients were randomly allocated 20\u2009mg of fluoxetine once per day or the matching placebo for 6 months via a web-based system using a minimisation algorithm. MAIN OUTCOME MEASURES: The primary outcome was the modified Rankin Scale at 6 months. Patients, carers, health-care staff and the trial team were masked to treatment allocation. Outcome was assessed at 6 and 12 months after randomisation. Patients were analysed by their treatment allocation as specified in a published statistical analysis plan. RESULTS: Between 10 September 2012 and 31 March 2017, we recruited 3127 patients, 1564 of whom were allocated fluoxetine and 1563 of whom were allocated placebo. The modified Rankin Scale score at 6 months was available for 1553 out of 1564 (99.3%) of those allocated fluoxetine and 1553 out of 1563 (99.4%) of those allocated placebo. The distribution across modified Rankin Scale categories at 6 months was similar in the two groups (common odds ratio adjusted for minimisation variables 0.951, 95% confidence interval 0.839 to 1.079; p\u2009=\u20090.439). Compared with placebo, patients who were allocated fluoxetine were less likely to develop a new episode of depression by 6 months [210 (13.0%) vs. 269 (16.9%), difference -3.78%, 95% confidence interval -1.26% to -6.30%; p\u2009=\u20090.003], but had more bone fractures [45 (2.9%) vs. 23 (1.5%), difference 1.41%, 95% confidence interval 0.38% to 2.43%; p\u2009=\u20090.007]. There were no statistically significant differences in any other recorded events at 6 or 12 months. Health economic analyses showed no differences between groups in health-related quality of life, hospital bed usage or health-care costs. LIMITATIONS: Some non-adherence to trial medication, lack of face-to-face assessment of neurological status at follow-up and lack of formal psychiatric diagnosis during follow-up. CONCLUSIONS: 20\u2009mg of fluoxetine daily for 6 months after acute stroke did not improve patients' functional outcome but decreased the occurrence of depression and increased the risk of fractures. These data inform decisions about using fluoxetine after stroke to improve functional outcome or to prevent or treat mood disorders. The Assessment oF FluoxetINe In sTroke recoverY (AFFINITY) (Australasia/Vietnam) and Efficacy oF Fluoxetine - a randomisEd Controlled Trial in Stroke (EFFECTS) (Sweden) trials recruited an additional 2780 patients and will report their results in 2020. These three trials have an almost identical protocol, which was collaboratively developed. Our planned individual patient data meta-analysis will provide more precise estimates of the effects of fluoxetine after stroke and indicate whether or not effects vary depending on patients' characteristics and health-care setting. TRIAL REGISTRATION: Current Controlled Trials ISRCTN83290762. FUNDING: This project was funded by the National Institute for Health Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 24, No. 22. See the NIHR Journals Library website for further project information. The Stroke Association (reference TSA 2011101) funded the start-up phase.",
      "authors": "Dennis Martin; Forbes John; Graham Catriona; Hackett Maree; Hankey Graeme J; House Allan; Lewis Stephanie; Lundstr\u00f6m Erik; Sandercock Peter; Mead Gillian",
      "year": "2020",
      "journal": "Health technology assessment (Winchester, England)",
      "doi": "10.3310/hta24220",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32452356/",
      "mesh_terms": "Adult; Female; Fluoxetine; Humans; Male; Middle Aged; Quality of Life; Recovery of Function; Selective Serotonin Reuptake Inhibitors; Stroke; Surveys and Questionnaires; United Kingdom",
      "keywords": "DECISION-MAKING; DEPRESSION; DEPRESSIVE DISORDER; FLUOXETINE; FRACTURES, BONE; HOSPITALS; HUMANS; MOOD DISORDERS; PHYSICAL RECOVERY; RANDOMISED TRIAL; STROKE; TREATMENT OUTCOME",
      "pub_types": "Journal Article; Multicenter Study; Pragmatic Clinical Trial; Randomized Controlled Trial; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7294394"
    },
    {
      "pmid": "35731078",
      "title": "IL-4/13 Blockade and sleep-related adverse drug reactions in over 37,000 Dupilumab reports from the World Health Organization Individual Case Safety reporting pharmacovigilance database (VigiBase\u2122): a big data and machine learning analysis.",
      "abstract": "OBJECTIVE: Atopic dermatitis displays a relevant sleep burden sustained by clinical (i.e., itch), psychological (i.e., inadequate coping strategies) and therapeutic (i.e., frequent loss of drug response) triggers. Dupilumab, the first biologic approved for atopic dermatitis, showed excellent effects on improving pruritus and sleep after only two weeks of treatment but, in some cases, may have paradoxical effects. The rate of sleep-related side-effects remains unknown. More specifically, adverse-drug reactions (ADRs) related to dupilumab have been investigated during the safety phase of randomized clinical trials or in small retrospective epidemiological surveys, but little is known about sleep-related ADRs in real-life settings. Therefore, we took advantage of a global large-scale pharmacovigilance database, carrying out a comprehensive data mining analysis to look at different sleep-related ADRs reported among patients under anti IL-4/13 therapy. MATERIALS AND METHODS: We analyzed individual case study reports (ICSRs) in VigiBaseTM, the World Health Organization (WHO) global pharmacovigilance database of ADRs collected by national drug authorities in > 140 countries (> 90% of the world population). We looked for patterns of potentially sleep-related ADRs and we applied a disproportionality analysis based on Bayesian Confidence Propagation Neural Network (BCPNN). A meta-analytical approach was used to synthesize the overall effect size of sleep-related ADRs potentially associated to Dupilumab administration. RESULTS: From inception up to March 9, 2021, 94,065 ADRs from 37,848 unique reports were included and analyzed in the present paper: 1,294 of them (1.4%) concerned sleep disturbances (n=27). Most of sleep-related complaints were generic sleep disorders (n=630), followed by insomnia (n=312), somnolence (n=81), lethargy (n=60), night sweats (n=30), middle insomnia (n=39), hypersomnia (n=25), poor-quality sleep (n=21), initial insomnia (n=17), sleep apnea syndrome (n=13), nightmares (n=11) and sleep deficit (n=11). Interestingly, restlessness and restless leg syndrome, nocturnal dyspnea, narcolepsy and bruxism were reported in 7, 6, 5, 4 and 3 cases, respectively. Only sleep deficit [OR 15.67 (95% CrI 8.61-28.51); IC 3.24 (95% CrI 2.26-3.97)], generic sleep disorder [OR 6.22 (95% CrI 5.74-6.73); IC 2.60 (95% CrI 2.48-2.71)], nocturnal dyspnea [OR 3.68 (95% CrI 1.53-8.87); IC 1.56 (95% CrI 0.03-2.56)] and middle insomnia [OR 1.87 (95% CrI 1.36-2.56); IC 0.88 (95% CrI 0.39-1.30)] achieved the statistical significance threshold. CONCLUSIONS: In this work, we identified over 37,000 unique case-reports of Dupilumab side-effects reported on the WHO pharmacovigilance database. We specifically categorized those related to sleep issues, which were 1,294. Our findings from large numbers of cases provide data supporting the clinical observations that Dupilumab is usually effective in improving sleep quality and sleep disturbances/impairments, given the lack of statistical significance of several sleep-related ADRs. Further work is needed to closely scrutinize the impact of Dupilumab on sleep, in terms of underlying mechanisms, and to better understand residual sleep disorders in patients with atopic dermatitis and other allergic diseases treated with Dupilumab. Thus, sleep monitoring may be helpful for dermatologists in managing atopic dermatitis patients treated with dupilumab. The limitations of spontaneous reporting systems including underreporting and reporting bias, heterogeneity of sources and impossibility to infer any causal relationship merit consideration and further research is needed.",
      "authors": "Alroobaea R; Rubaiee S; Hanbazazah A S; Jahrami H; Garbarino S; Damiani G; Wu J; Bragazzi N L",
      "year": "2022",
      "journal": "European review for medical and pharmacological sciences",
      "doi": "10.26355/eurrev_202206_28977",
      "url": "https://pubmed.ncbi.nlm.nih.gov/35731078/",
      "mesh_terms": "Adverse Drug Reaction Reporting Systems; Antibodies, Monoclonal, Humanized; Bayes Theorem; Big Data; Dermatitis, Atopic; Drug-Related Side Effects and Adverse Reactions; Dyspnea; Humans; Interleukin-4; Machine Learning; Pharmacovigilance; Retrospective Studies; Sleep; Sleep Initiation and Maintenance Disorders; Sleep Wake Disorders; World Health Organization",
      "keywords": "",
      "pub_types": "Case Reports; Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "40434773",
      "title": "Evaluating the Test-Negative Design for COVID-19 Vaccine Effectiveness Using Randomized Trial Data: A Secondary Cross-Protocol Analysis of 5 Randomized Clinical Trials.",
      "abstract": "IMPORTANCE: The test-negative design (TND) has been widely used to assess postmarketing COVID-19 vaccine effectiveness but requires further evaluation for this application. OBJECTIVE: To determine whether the TND reliably evaluates vaccine effectiveness against symptomatic COVID-19 using placebo-controlled vaccine efficacy randomized clinical trials (RCTs). DESIGN, SETTING, AND PARTICIPANTS: This secondary cross-protocol analysis constructed TND study datasets from study sites in 16 countries across 5 continents using the blinded phase cohorts of 5 harmonized phase 3 COVID-19 Prevention Network RCTs: COVE (Coronavirus Vaccine Efficacy and Safety), AZD1222, ENSEMBLE, PREVENT-19 (Prefusion Protein Subunit Vaccine Efficacy Novavax Trial COVID-19), and VAT00008. Participants included adults who received the intended number of doses, experienced COVID-19-like symptoms, and obtained SARS-CoV-2 testing. Start dates ranged from July 27, 2020, to October 19, 2021; data cutoff dates ranged from March 26, 2021, to March 15, 2022. Statistical analysis was performed from May 11, 2023, to February 25, 2025. INTERVENTIONS: Participants received vaccines consisting of messenger RNA-1273 (COVE; 2 doses 28 days apart), ChAdOx1 nCoV-19 (AZD1222; 2 doses 28 days apart), Ad26.COV2.S (ENSEMBLE; 1 dose), NVX-CoV2373 (PREVENT-19; 2 doses 21 days apart), CoV2 preS dTM-AS03 (VAT00008; D614) (2 doses 21 days apart), or CoV2 preS dTM-AS03 (D614 plus B.1.351) (VAT00008; 2 doses 21 days apart) or placebo. MAIN OUTCOMES AND MEASURES: Main outcomes were symptomatic COVID-19 according to each trial's primary efficacy definition and the Centers for Disease Control and Prevention definition. Vaccine effectiveness was estimated using targeted maximum likelihood estimation under a semiparametric logistic regression model and ordinary logistic regression. Noncase exchangeability, a core TND assumption for unbiased estimation, was also assessed by estimating vaccine efficacy against non-COVID-19 illness. RESULTS: Among the 12\u202f157 participants included in the analysis, mean (SD) age was 45 (15) years, 6414 were female (53%), 5858 were vaccinated (48%), 2835 experienced primary COVID-19 (23%), and 2992 experienced Centers for Disease Control and Prevention-defined COVID-19 (25%). TND vaccine effectiveness estimates were concordant with RCT vaccine efficacy estimates (concordance correlation coefficient,\u20090.86 [95% CI, 0.58-0.96] for both outcomes). The semiparametric method had 48% smaller variance estimates than ordinary logistic regression. Noncase exchangeability was generally supported with a median vaccine efficacy against non-COVID-19 illness of 7.7% (IQR, 2.7%-16.8%) across trial cohorts and most 95% CIs including 0. CONCLUSIONS AND RELEVANCE: In this cross-protocol analysis, the TND provided reliable inferences on COVID-19 vaccine effectiveness in health care-seeking populations for multiple vaccines and symptom definitions when confounding and selection bias were absent. A machine-learning approach for robust confounding control in postmarketing TND studies was also introduced.",
      "authors": "Andrews Leah I B; Halloran M Elizabeth; Neuzil Kathleen M; van der Laan Lars; Huang Yunda; Andriesen Jessica; Patel Mayur; Fisher Leigh H; Janes Holly; Rouphael Nadine; Walsh Stephen R; Theodore Deborah A; Tieu Hong-Van; Sobieszczyk Magdalena; El Sahly Hana M; Baden Lindsey R; Falsey Ann R; Campbell Thomas B; Kelley Colleen F; Healy Catherine Mary; Immergluck Lilly; Luft Benjamin; Hirsch Ian; de Bruyn Guy; Truyers Carla; Priddy Frances; Sumner Kelsey M; Flannery Brendan; Follmann Dean; Gilbert Peter B",
      "year": "2025",
      "journal": "JAMA network open",
      "doi": "10.1001/jamanetworkopen.2025.12763",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40434773/",
      "mesh_terms": "Humans; COVID-19 Vaccines; COVID-19; Vaccine Efficacy; Randomized Controlled Trials as Topic; SARS-CoV-2; Adult; Female; Male; Middle Aged; Research Design",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't; Research Support, N.I.H., Extramural",
      "pmcid": "PMC12120655"
    },
    {
      "pmid": "38872809",
      "title": "Improving Clinician Performance in Classifying EEG Patterns on the Ictal-Interictal Injury Continuum Using Interpretable Machine Learning.",
      "abstract": "BACKGROUND: In intensive care units (ICUs), critically ill patients are monitored with electroencephalography (EEG) to prevent serious brain injury. EEG monitoring is constrained by clinician availability, and EEG interpretation can be subjective and prone to interobserver variability. Automated deep-learning systems for EEG could reduce human bias and accelerate the diagnostic process. However, existing uninterpretable (black-box) deep-learning models are untrustworthy, difficult to troubleshoot, and lack accountability in real-world applications, leading to a lack of both trust and adoption by clinicians. METHODS: We developed an interpretable deep-learning system that accurately classifies six patterns of potentially harmful EEG activity - seizure, lateralized periodic discharges (LPDs), generalized periodic discharges (GPDs), lateralized rhythmic delta activity (LRDA), generalized rhythmic delta activity (GRDA), and other patterns - while providing faithful case-based explanations of its predictions. The model was trained on 50,697 total 50-second continuous EEG samples collected from 2711 patients in the ICU between July 2006 and March 2020 at Massachusetts General Hospital. EEG samples were labeled as one of the six EEG patterns by 124 domain experts and trained annotators. To evaluate the model, we asked eight medical professionals with relevant backgrounds to classify 100 EEG samples into the six pattern categories - once with and once without artificial intelligence (AI) assistance - and we assessed the assistive power of this interpretable system by comparing the diagnostic accuracy of the two methods. The model's discriminatory performance was evaluated with area under the receiver-operating characteristic curve (AUROC) and area under the precision-recall curve. The model's interpretability was measured with task-specific neighborhood agreement statistics that interrogated the similarities of samples and features. In a separate analysis, the latent space of the neural network was visualized by using dimension reduction techniques to examine whether the ictal-interictal injury continuum hypothesis, which asserts that seizures and seizure-like patterns of brain activity lie along a spectrum, is supported by data. RESULTS: The performance of all users significantly improved when provided with AI assistance. Mean user diagnostic accuracy improved from 47 to 71% (P<0.04). The model achieved AUROCs of 0.87, 0.93, 0.96, 0.92, 0.93, and 0.80 for the classes seizure, LPD, GPD, LRDA, GRDA, and other patterns, respectively. This performance was significantly higher than that of a corresponding uninterpretable black-box model (with P<0.0001). Videos traversing the ictal-interictal injury manifold from dimension reduction (a two-dimensional representation of the original high-dimensional feature space) give insight into the layout of EEG patterns within the network's latent space and illuminate relationships between EEG patterns that were previously hypothesized but had not yet been shown explicitly. These results indicate that the ictal-interictal injury continuum hypothesis is supported by data. CONCLUSIONS: Users showed significant pattern classification accuracy improvement with the assistance of this interpretable deep-learning model. The interpretable design facilitates effective human-AI collaboration; this system may improve diagnosis and patient care in clinical settings. The model may also provide a better understanding of how EEG patterns relate to each other along the ictal-interictal injury continuum. (Funded by the National Science Foundation, National Institutes of Health, and others.).",
      "authors": "Barnett Alina Jade; Guo Zhicheng; Jing Jin; Ge Wendong; Kaplan Peter W; Kong Wan Yee; Karakis Ioannis; Herlopian Aline; Jayagopal Lakshman Arcot; Taraschenko Olga; Selioutski Olga; Osman Gamaleldin; Goldenholz Daniel; Rudin Cynthia; Westover M Brandon",
      "year": "2024",
      "journal": "NEJM AI",
      "doi": "10.1056/aioa2300331",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38872809/",
      "mesh_terms": "",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC11175595"
    },
    {
      "pmid": "41310253",
      "title": "Optimizing Air Pollution Exposure Assessment with Application to Cognitive Function.",
      "abstract": "INTRODUCTION: Epidemiological studies often make use of exposure data that is collected in opportunistic and logistically convenient ways. And, while exposure assessment is fundamental to environmental epidemiology, little is known about what exposure assessment study designs are optimal for health inference. The objective of this project was to advance our understanding of the design of exposure assessment measurement campaigns and evaluate their impact on estimating the associations between long-term average air pollution exposure and cognitive function. This feeds into the broader goal of advancing understanding of air pollution exposure assessment design for application to epidemiological inference. METHODS: We leveraged data from the Adult Changes in Thought (ACT3) Air Pollution study (ACT-AP) to characterize exposures for over 5,000 participants from the ongoing ACT cohort. This is a population-based cohort of urban and suburban elderly individuals in the greater Puget Sound region drawn from Group Health Cooperative, now Kaiser Permanente, starting in 1994. Participants were routinely followed with routine biennial visits until dementia incidence, drop-out, or death. Extensive health, lifestyle, biological, and demographic data were also collected. The outcome measure used in this report is cognitive function at baseline based on the Cognitive Abilities Screening Instrument derived using Item Response Theory (CASI-IRT). The IRT transformation of the CASI score improves score accuracy, measures cognitive change with less bias, and accounts for missing test items. Health association analyses were based on 5,409 participants with both a valid CASI score and who had lived in the mobile monitoring region during at least 95% of the 5 years prior to baseline. We used 5-year average exposures that accounted for residential history. UNLABELLED: Exposure data came from two distinct exposure assessment campaigns carried out by the ACT-AP study: a campaign using low-cost sensors (2017+) that supplemented existing regulatory monitoring data for fine particles (PM2.5, 1978+) and nitrogen dioxide (NO2, 1996+), and a year-long multipollutant mobile monitoring campaign (2019-2020). The evaluation of the added value of low-cost sensor data relied on a combination of regulatory monitoring data and other high-quality data from research studies, calibrated 2-week low-cost sensor measurements from over 100 locations, which were mostly ACT cohort residences, and a snapshot campaign that measured NO2 using Ogawa samplers. Predictions were at a 2-week average time scale, used a suite of ~200 geographic covariates, and were obtained from a spatiotemporal model developed at the University of Washington. The Seattle mobile monitoring campaign collected a combination of stationary roadside and on-road measurements of ultrafine particles (UFPs, four instruments), black carbon (BC), NO2, carbon dioxide (CO2), and PM2.5. Visits were temporally balanced over 288 drive days such that all sites were visited during all seasons, days of the week, and most hours of the day (5 a.m. to 11 p.m.) approximately 29 times each. For the on-road measurements, we divided the driving route into 100-meter segments and assigned all measurements to the segment midpoint. Predictions used the same suite of geographic covariates in a spatial model fit using partial least squares (PLS) dimension reduction with universal kriging (UK-PLS) to capture the remaining spatial structure. We reported model performance metrics for both the spatial and spatiotemporal models as root mean squared error (RMSE) and mean squared error (MSE)-based R2. The reference observations for the spatiotemporal model were low-cost sensor measurements at home locations (with performance metrics averaged over their entire measurement period to approximate spatial contrasts), and for the spatial model, the reference observations were the all data long-term averages at stationary roadside locations. UNLABELLED: Using various approaches to sample data from these two exposure monitoring campaigns, we determined the impact on exposure prediction and estimates of health associations using two confounder models and 5-year average exposure predictions for cohort members at baseline developed from the alternative campaigns. For the low-cost sensor data, we evaluated temporally or spatially reduced subsets of low-cost sensors, as well as a comparison of the low-cost sensor versus snapshot campaigns for NO2. For the mobile monitoring data, we considered designs focused on the stationary roadside and on-road data separately. We reduced the stationary roadside data temporally by restricting seasons, times of day, or days of week for the campaign, while also considering a reduced number of visits using balanced sampling, as well as a set of unbalanced visit designs. We also reduced the on-road data spatially and temporally to assess the importance of spatially or temporally balanced data collection. In addition, we considered the impact of incorporating temporal adjustment to account for temporally unbalanced sampling, as well as plume adjustment to account for on-road sources. For each design, we evaluated prediction model performance using the all data stationary roadside observations (mobile campaign) or the measurements at homes (low-cost sensor campaign) as reference observations to ensure consistency in reported performance metrics. We also used long-term average exposures estimated from these alternative campaigns in health association analyses under two different confounder models that were adjusted by potentially confounding variables: Model 1 adjusted for age, calendar year, sex, and educational attainment; Model 2 included all Model 1 variables with the addition of race and socioeconomic status. Furthermore, using the stationary roadside data, we applied parametric and nonparametric bootstrap methods to account for Berkson-like and classical-like exposure measurement error for the UFP exposure in confounder model 1. UNLABELLED: In a separate methods-focused aim, we developed and applied advanced statistical methods using the stationary roadside mobile monitoring data. To evaluate possible improvements in exposure model performance, we applied tree-based machine learning algorithms that also account for residual spatial structure, and compared these to UK-PLS. This led to the development of a variable importance metric that uses a leave-one-out approach to evaluate the change in predictions across various user-specified quantiles. The variable importance metric produces covariate-specific averages that reflect how the predictions, on average, vary across different quantiles of each covariate. This serves as an intuitive measure of the contribution of this covariate to the predicted outcome. A key idea in this variable importance approach is to reuse the trained mean model across all locations and to refit the covariance model in a leave-one-out manner. In separate work to address dimension reduction for multipollutant prediction, we extended classical principal component analysis (PCA) and a recently developed predictive PCA approach to optimize performance by balancing the representativeness in classical PCA with the predictive ability of predictive PCA. We called the new method representative and predictive PCA, or RapPCA. UNLABELLED: Finally, we characterized the various exposure assessment campaigns in terms of the value of their information as quantified by cost. We calculated costs, focused predominantly on staff days of effort, for various exposure assessment designs and compared these to exposure model performance statistics. RESULTS: We found that air pollution exposure assessment design is critical for exposure prediction, and also impacts health inference. We showed that a mobile monitoring study with stationary roadside sampling that has at least 12 visits per location in a balanced and temporally unrestricted design optimizes exposure model performance while also limiting costs. Relative to weaker alternatives, a balanced and temporally unrestricted design has improved accuracy and reduced variability of health inferences, particularly for confounder model 1. To address temporal balance, it is important that the exposure sampling in mobile monitoring campaigns cover all days of the week, most hours of the day, and at least two seasons. The popular temporally restricted business-hours sampling design had the poorest performance, which was not improved by adjusting for the temporally unbalanced sampling approach. We found similar patterns using on-road data, though the findings were weaker overall. UNLABELLED: For the alternative exposure campaign that supplemented regulatory monitoring data with low-cost sensor data, while the exposure prediction model performances improved with the inclusion of the low-cost sensors, there was little notable impact on the health inferences, and the costs were steep. Given that the supplementary exposure assessment data were sparse relative to the existing regulatory monitoring data, and that the low-cost sensor data collection used a rotating approach due to the limited number of sensors (i.e., low-cost sensor measurements were not collected using a balanced design), it was much more challenging to develop deep insights from this exposure assessment approach. UNLABELLED: Finally, we found that leveraging spatial ensemble-learning methods for prediction did not improve exposure prediction model performances or alter health inferences. The new multipollutant dimension-reduction we developed, RapPCA, had the best predictive performance and also minimized the prediction error in comparison with both classical and predictive PCA. CONCLUSIONS: This project has shown that there should be greater attention to the design of the exposure data collection campaigns used in epidemiological inference. Based on the multiple investigations conducted, many of which focused on UFPs, we found that exposure predictions with better performance statistics resulted in health association estimates that were generally more consistent with those obtained using the \"best\" exposure model predictions (the model with all data included), although the pattern of health estimates was often less conclusive than the pattern of prediction model performances. Furthermore, we found that it is possible to design air pollution exposure assessment studies that achieve good exposure prediction model performance while controlling their relative cost. UNLABELLED: We developed strong recommendations for mobile monitoring campaign design, thanks to the well-designed and comprehensive Seattle mobile monitoring campaign. Insights from supplementing regulatory monitoring data with low-cost sensor data were less compelling, driven predominantly by a data structure with sparse and temporally unbalanced supplementary data that may not have been sufficiently comprehensive to demonstrate the impacts of alternative designs. Broadly speaking, better exposure assessment design leads to better exposure prediction model performance, which in turn can benefit estimates of health associations. UNLABELLED: We did not find that leveraging advanced statistical methods (specifically, spatial ensemble-learning methods for prediction) improved exposure prediction model performances. This finding is not consistent with the conclusions reached by other investigators, and may have been due to the already sophisticated UK-PLS approach we used by default, and in particular its application in conjunction with the large number of covariates that we considered in the PLS model, such that the contribution of any single covariate was approximately linear. In other words, it is reasonable to believe that in the presence of the large set of covariates we considered, each can contribute an approximately linear association with the pollutant being modeled, such that the potential added value of the spatial Random Forest approach is not observed in the model fit. Other settings with a smaller number of possible covariates available may lead to different conclusions and suggest greater added value of the application of a spatial Random Forest approach. UNLABELLED: We based our approach on leveraging the extensive air pollution exposure assessment and outcome data available from the ACT-AP study. Thus, we sampled from the existing air pollution data to evaluate exposure assessment designs that were subsets of those data. Then, conditional on each of these designs, we evaluated subsequent health inferences, which focused on cognitive function at baseline using the CASI-IRT outcome. The magnitude and uncertainty of these health association estimates were dependent upon the associations evident in the ACT cohort, and the insights we were able to develop are conditional on the strengths and weaknesses of these data. Specifically, while we observed some larger impacts on health association estimates of more poorly performing exposure models relative to the complete all data exposure model, such as the business-hours design from a mobile monitoring campaign, many of the differences were small and did not deviate meaningfully from the health association estimate obtained from the \"best\" exposure model. The degree of impact on the epidemiological inference depended on the magnitude of the health association estimate from the \"best\" exposure model and the width of its confidence interval. Future investigations should replicate and expand upon these findings in other settings, including application to new cohorts and exposure assessment data, as well as in simulation studies, which provide an alternative approach to using real-world data to evaluate a constellation of exposure models. However, while knowledge of the assumed underlying truth is an important strength of simulation studies, it is challenging to capture real-world complexity meaningfully in simulation studies. UNLABELLED: Our foray into applying advanced machine-learning methods to improve exposure predictions produced the surprising result that our default UK-PLS approach for spatial prediction produced similar performance metrics to spatial ensemble-learning methods. Future evaluations that assess smaller subsets of exposure covariates will allow determination of the relative exposure model performance benefits of UK-PLS versus spatial ensemble-learning methods, and provide insights into the possible reason that our conclusions differ from others in the literature.",
      "authors": "Sheppard L; Blanco M N; Kim S-Y; Doubleday A; Cheng S; Zuidema C; Bi J; Gassett A; Shojaie A; Szpiro A A",
      "year": "2025",
      "journal": "Research report (Health Effects Institute)",
      "doi": "10.1002/wics.51",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41310253/",
      "mesh_terms": "Humans; Male; Female; Aged; Air Pollution; Environmental Exposure; Cognition; Air Pollutants; Aged, 80 and over; Cohort Studies; Middle Aged; Particulate Matter",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": "PMC12660182"
    },
    {
      "pmid": "32079557",
      "title": "Varenicline versus nicotine replacement therapy for long-term smoking cessation: an observational study using the Clinical Practice Research Datalink.",
      "abstract": "BACKGROUND: Smoking is the leading avoidable cause of illness and premature mortality. The first-line treatments for smoking cessation are nicotine replacement therapy and varenicline. Meta-analyses of experimental studies have shown that participants allocated to the varenicline group were 1.57 times (95% confidence interval 1.29 to 1.91 times) as likely to be abstinent 6 months after treatment as those allocated to the nicotine replacement therapy group. However, there is limited evidence about the effectiveness of varenicline when prescribed in primary care. We investigated the effectiveness and rate of adverse events of these medicines in the general population. OBJECTIVE: To estimate the effect of prescribing varenicline on smoking cessation rates and health outcomes. DATA SOURCES: Clinical Practice Research Datalink. METHODS: We conducted an observational cohort study using electronic medical records from the Clinical Practice Research Datalink. We extracted data on all patients who were prescribed varenicline or nicotine replacement therapy after 1 September 2006 who were aged \u2265\u200918 years. We investigated the effects of varenicline on smoking cessation, all-cause mortality and cause-specific mortality and hospitalisation for: (1) chronic lung disease, (2) lung cancer, (3) coronary heart disease, (4) pneumonia, (5) cerebrovascular disease, (6) diabetes, and (7) external causes; primary care diagnosis of myocardial infarction, chronic obstructive pulmonary disease, depression, or prescription for anxiety; weight in kg; general practitioner and hospital attendance. Our primary outcome was smoking cessation 2 years after the first prescription. We investigated the baseline differences between patients prescribed varenicline and patients prescribed nicotine replacement therapy. We report results using multivariable-adjusted, propensity score and instrumental variable regression. Finally, we developed methods to assess the relative bias of the different statistical methods we used. RESULTS: People prescribed varenicline were healthier at baseline than those prescribed nicotine replacement therapy in almost all characteristics, which highlighted the potential for residual confounding. Our instrumental variable analysis results found little evidence that patients prescribed varenicline had lower mortality 2 years after their first prescription (risk difference 0.67, 95% confidence interval -0.11 to 1.46) than those prescribed nicotine replacement therapy. They had similar rates of all-cause hospitalisation, incident primary care diagnoses of myocardial infarction and chronic obstructive pulmonary disease. People prescribed varenicline subsequently attended primary care less frequently. Patients prescribed varenicline were more likely (odds ratio 1.46, 95% confidence interval 1.42 to 1.50) to be abstinent 6 months after treatment than those prescribed nicotine replacement therapy when estimated using multivariable-adjusted for baseline covariates. Patients from more deprived areas were less likely to be prescribed varenicline. However, varenicline had similar effectiveness for these groups. CONCLUSION: Patients prescribed varenicline in primary care were more likely to quit smoking than those prescribed nicotine replacement therapy, but there was little evidence that they had lower rates of mortality or morbidity in the 4 years following the first prescription. There was little evidence of heterogeneity in effectiveness across the population. FUTURE WORK: Future research should investigate the decline in prescribing of smoking cessation products; develop an optimal treatment algorithm for smoking cessation; use methods for using instruments with survival outcomes; and develop methods for comparing multivariable-adjusted and instrumental variable estimates. LIMITATIONS: Not all of our code lists were validated, body mass index and Index of Multiple Deprivation had missing values, our results may suffer from residual confounding, and we had no information on treatment adherence. TRIAL REGISTRATION: This trial is registered as NCT02681848. FUNDING: This project was funded by the National Institute for Health Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 24, No. 9. See the NIHR Journals Library website for further project information.",
      "authors": "Davies Neil M; Taylor Amy E; Taylor Gemma Mj; Itani Taha; Jones Tim; Martin Richard M; Munaf\u00f2 Marcus R; Windmeijer Frank; Thomas Kyla H",
      "year": "2020",
      "journal": "Health technology assessment (Winchester, England)",
      "doi": "10.3310/hta24090",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32079557/",
      "mesh_terms": "Adult; Cohort Studies; Electronic Health Records; Female; Humans; Male; Mortality; Pulmonary Disease, Chronic Obstructive; Smoking Cessation; Smoking Cessation Agents; Tobacco Use Cessation Devices; Varenicline",
      "keywords": "CPRD; ELECTRONIC MEDICAL RECORDS; NICOTINE REPLACEMENT PRODUCTS; SMOKING CESSATION; VARENICLINE",
      "pub_types": "Journal Article; Observational Study; Research Support, Non-U.S. Gov't",
      "pmcid": "PMC7061271"
    },
    {
      "pmid": "27504637",
      "title": "Uptake of Home-Based HIV Testing, Linkage to Care, and Community Attitudes about ART in Rural KwaZulu-Natal, South Africa: Descriptive Results from the First Phase of the ANRS 12249 TasP Cluster-Randomised Trial.",
      "abstract": "BACKGROUND: The 2015 WHO recommendation of antiretroviral therapy (ART) for all immediately following HIV diagnosis is partially based on the anticipated impact on HIV incidence in the surrounding population. We investigated this approach in a cluster-randomised trial in a high HIV prevalence setting in rural KwaZulu-Natal. We present findings from the first phase of the trial and report on uptake of home-based HIV testing, linkage to care, uptake of ART, and community attitudes about ART. METHODS AND FINDINGS: Between 9 March 2012 and 22 May 2014, five clusters in the intervention arm (immediate ART offered to all HIV-positive adults) and five clusters in the control arm (ART offered according to national guidelines, i.e., CD4 count \u2264 350 cells/\u03bcl) contributed to the first phase of the trial. Households were visited every 6 mo. Following informed consent and administration of a study questionnaire, each resident adult (\u226516 y) was asked for a finger-prick blood sample, which was used to estimate HIV prevalence, and offered a rapid HIV test using a serial HIV testing algorithm. All HIV-positive adults were referred to the trial clinic in their cluster. Those not linked to care 3 mo after identification were contacted by a linkage-to-care team. Study procedures were not blinded. In all, 12,894 adults were registered as eligible for participation (5,790 in intervention arm; 7,104 in control arm), of whom 9,927 (77.0%) were contacted at least once during household visits. HIV status was ever ascertained for a total of 8,233/9,927 (82.9%), including 2,569 ascertained as HIV-positive (942 tested HIV-positive and 1,627 reported a known HIV-positive status). Of the 1,177 HIV-positive individuals not previously in care and followed for at least 6 mo in the trial, 559 (47.5%) visited their cluster trial clinic within 6 mo. In the intervention arm, 89% (194/218) initiated ART within 3 mo of their first clinic visit. In the control arm, 42.3% (83/196) had a CD4 count \u2264 350 cells/\u03bcl at first visit, of whom 92.8% initiated ART within 3 mo. Regarding attitudes about ART, 93% (8,802/9,460) of participants agreed with the statement that they would want to start ART as soon as possible if HIV-positive. Estimated baseline HIV prevalence was 30.5% (2,028/6,656) (95% CI 25.0%, 37.0%). HIV prevalence, uptake of home-based HIV testing, linkage to care within 6 mo, and initiation of ART within 3 mo in those with CD4 count \u2264 350 cells/\u03bcl did not differ significantly between the intervention and control clusters. Selection bias related to noncontact could not be entirely excluded. CONCLUSIONS: Home-based HIV testing was well received in this rural population, although men were less easily contactable at home; immediate ART was acceptable, with good viral suppression and retention. However, only about half of HIV-positive people accessed care within 6 mo of being identified, with nearly two-thirds accessing care by 12 mo. The observed delay in linkage to care would limit the individual and public health ART benefits of universal testing and treatment in this population. TRIAL REGISTRATION: ClinicalTrials.gov NCT01509508.",
      "authors": "Iwuji Collins C; Orne-Gliemann Joanna; Larmarange Joseph; Okesola Nonhlanhla; Tanser Frank; Thiebaut Rodolphe; Rekacewicz Claire; Newell Marie-Louise; Dabis Francois",
      "year": "2016",
      "journal": "PLoS medicine",
      "doi": "10.1371/journal.pmed.1002107",
      "url": "https://pubmed.ncbi.nlm.nih.gov/27504637/",
      "mesh_terms": "AIDS Serodiagnosis; Adult; Anti-HIV Agents; Attitude to Health; Continuity of Patient Care; Female; HIV Infections; Humans; Male; Middle Aged; Rural Population; Self Care; Sexual Partners; South Africa; Young Adult",
      "keywords": "",
      "pub_types": "Journal Article; Randomized Controlled Trial",
      "pmcid": "PMC4978506"
    },
    {
      "pmid": "32639484",
      "title": "The effects of intensive speech treatment on intelligibility in Parkinson's disease: A randomised controlled trial.",
      "abstract": "BACKGROUND: More than 6,000,000 individuals worldwide are diagnosed with Parkinson's disease (PD). Nearly 90% develop speech signs that may substantially impair their speech intelligibility, resulting in losses in their communication and quality of life. Benefits of intensive speech treatment have been documented for a range of speech signs. However, the critical question of whether speech is more intelligible after treatment has not been investigated in a randomised controlled trial (RCT). We hypothesised that intensive speech treatment would improve speech intelligibility in PD. METHOD: Sixty-four patients with hypokinetic dysarthria secondary to PD participated in this single-centre, parallel arm, statistically-powered RCT. Reporting follows CONSORT guidelines for non-pharmacological treatment. Patients were recruited from US clinics and randomised using a statistician-derived minimisation algorithm, to intensive speech treatment (16 1-hour sessions/1 month) targeting voice (voice group) or targeting articulation (articulation group) or to an untreated group (no treatment group). Speech treatments were delivered by speech clinicians who specialised in treating patients with PD. Trial design minimised bias and supported equipoise. For intelligibility assessment, blinded listeners (n\u00a0=\u00a0117) orthographically transcribed 57 patients' recorded, self-generated narrative speech samples, randomly presented in multi-talker babble noise. Listeners were American-English speakers, ages 18-35 years, with normal hearing. The primary outcome was baseline (pre-treatment) to post-treatment change in transcription accuracy (TA), recognised as the most objective measure of intelligibility. TA was defined as the percentage of words transcribed correctly. Listeners, data collectors, and data managers were blinded to treatment conditions and groups. Reliability was evaluated using intraclass correlation coefficients and differences amongst groups were evaluated by mixed-effects models, in accordance with the intention-to-treat approach.This trial was registered with ClinicalTrials.gov Identifier: NCT00123084. FINDINGS: Between June 23, 2016 and August 14, 2017, blinded listeners transcribed baseline and post-treatment speech samples for intelligibility assessment of 57 patients in the voice (n\u00a0=\u00a019), articulation (n\u00a0=\u00a019) and no treatment (n\u00a0=\u00a019) groups. Between-group differences (d) in changes from baseline to post-treatment in TA indicated significantly greater increases following treatment targeting voice than treatment targeting articulation (d\u00a0=\u00a026\u00b72%, 95% CI 1\u00b75\u00a0-\u00a051\u00b70; p\u00a0=\u00a00\u00b704; ES=1\u00b70). Differences between TA changes in the treatment targeting voice and in the no treatment group were significant (d\u00a0=\u00a042\u00b78%, 95% CI 22\u00b74\u00a0-\u00a063\u00b72; p\u00a0=\u00a00\u00b70002; ES=1\u00b78). Differences between TA changes in the treatment targeting articulation and in the no treatment group were not significant (d\u00a0=\u00a016\u00b75%, 95% CI -6\u00b71\u00a0-\u00a039\u00b72; p\u00a0=\u00a00\u00b7147; ES=0\u00b79). INTERPRETATION: These findings provide the first RCT evidence that intensive speech treatment targeting voice improves speech intelligibility in PD. Thus, this evidence-based treatment may positively impact health-related quality of life for patients with PD globally when it is included in patient management.",
      "authors": "Levy Erika S; Moya-Gal\u00e9 Gemma; Chang Young Hwa M; Freeman Katherine; Forrest Karen; Brin Mitchell F; Ramig Lorraine A",
      "year": "2020",
      "journal": "EClinicalMedicine",
      "doi": "10.1016/j.eclinm.2020.100429",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32639484/",
      "mesh_terms": "",
      "keywords": "Dysarthria; Intelligibility; Parkinson's disease; RCT; Speech treatment",
      "pub_types": "Journal Article",
      "pmcid": "PMC7327886"
    },
    {
      "pmid": "40245909",
      "title": "The spatiotemporal ecology of Oropouche virus across Latin America: a multidisciplinary, laboratory-based, modelling study.",
      "abstract": "BACKGROUND: Latin America has been experiencing an Oropouche virus (OROV) outbreak of unprecedented magnitude and spread since 2023-24 for unknown reasons. We aimed to identify risk predictors of and areas at risk for OROV transmission. METHODS: In this multidisciplinary, laboratory-based, modelling study, we retrospectively tested anonymised serum samples collected between 2001 and 2022 for studies on virus epidemiology and medical diagnostics in Bolivia, Brazil, Colombia, Costa Rica, Ecuador, and Peru with nucleoprotein-based commercial ELISAs for OROV-specific IgG and IgM antibodies. Serum samples positive for IgG from different ecological regions and sampling years were tested against Guaroa virus and two OROV glycoprotein reassortants (Iquitos virus and Madre de Dios virus) via plaque reduction neutralisation testing (PRNT) to validate IgG ELISA specificity and support antigenic cartography. Three OROV strains were included in the neutralisation testing, a Cuban OROV isolate from the 2023-24 outbreak, a contemporary Peruvian OROV isolate taken from a patient in 2020, and a historical OROV isolate from Brazil. We analysed the serological data alongside age, sex, cohort, and geographical residence data for the serum samples; reported OROV incidence data; and vector occurrence data to explore OROV transmission in ecologically different regions of Latin America. We used the MaxEnt machine learning methodology to spatially analyse and predict OROV infection risk across Latin America, fitting one model with presence-absence serological data (seropositive results were recorded as presence and seronegative results were recorded as absence) and one model with presence-only, reported incidence data from 2024. We computed marginal dependency plots, variable contribution, and permutation metrics to analyse the impact of socioecological predictors and fitted a generalised linear mixed-effects model with logit link and binary error structure to analyse the potential effects of age, sex, or cohort type bias and interactions between age or sex and cohort type in our serological data. We conducted antigenic cartography and evolutionary characterisations of all available genomic sequences for all three OROV genome segments from the National Center for Biotechnology Information, including branch-specific selection pressure analysis and the construction of OROV phylogenetic trees. FINDINGS: In total, 9420 serum samples were included in this study, representing 76 provinces in the six Latin American countries previously mentioned. The sex distribution across the combined cohorts was 48% female (4237 of 8910 samples with available data) and 52% male (4673 of 8910 samples) and the mean age was 29\u00b75 years (range 0-95 years). The samples were collected from census-based cohorts, cohorts of healthy individuals, and cohorts of febrile patients receiving routine health care. The average OROV IgG antibody detection rate was 6\u00b73% (95% CI 5\u00b78-6\u00b78), with substantial regional heterogeneity. The presence-absence, serology-based model predicted high-risk areas for OROV transmission in the Amazon River basin, around the coastal and southern areas of Brazil, and in parts of central America and the Caribbean islands, consistent with case data from the 2023-24 outbreak reported by the Pan American Health Organization. Areas with a high predicted risk of OROV transmission with the serology-based model showed a statistically significant positive correlation with state-level incidence rates per 100\u2009000 people in 2024 (generalised linear model, p=0\u00b70003). The area under the curve estimates were 0\u00b779 (95% CI 0\u00b778-0\u00b780) for the serology-based model and 0\u00b766 (95% CI 0\u00b765-0\u00b766) for the presence-only incidence-based model. Longitudinal diagnostic testing of serum samples from cohorts of febrile patients suggested constant circulation of OROV in endemic regions at varying intensity. Climate variables accounted for more than 60% of variable contribution in both the serology-based and incidence-based models. Antigenic cartography, evolutionary analyses, and in-vitro growth comparisons showed clear differentiation between OROV and its glycoprotein reassortants, but not between the three different OROV strains. PRNT titres of OROV-neutralising serum samples were strongly correlated between all three tested OROV isolates (r>0\u00b783; p<0\u00b70001) but were not correlated with the two glycoprotein reassortants. INTERPRETATION: Our data suggest that climatic factors are major drivers of OROV spread and were potentially exacerbated during 2024 by extreme weather events. OROV glycoprotein reassortants, but not individual OROV strains, probably have distinct antigenicity. Preparedness for OROV outbreaks requires enhanced diagnostics, surveillance, and vector control in current and future endemic areas, which could all be informed by the risk predictions presented in this Article. FUNDING: European Union. TRANSLATIONS: For the Spanish and Portuguese translations of the abstract see Supplementary Materials section.",
      "authors": "Fischer Carlo; Fr\u00fchauf Anna; Inchauste Lucia; Cassiano Murilo Henrique Anzolini; Ramirez Heriberto Ar\u00e9valo; Barth\u00e9l\u00e9my Karine; Machicado Lissete Bautista; Bozza Fernando Augusto; Brites Carlos; Cabada Miguel Mauricio; S\u00e1nchez C\u00e9sar A Cabezas; Rodr\u00edguez Angie Cervantes; de Lamballerie Xavier; de Los Milagros Peralta Delgado Roxana; de Oliveira-Filho Edmilson F; Domenech de Cell\u00e8s Mathieu; Franco-Mu\u00f1oz Carlos; Mendoza Mar\u00eda Paquita Garc\u00eda; Nogueira Miladi Gatty; G\u00e9lvez-Ram\u00edrez Rosa-Margarita; Gonzalez Manuel Gonzalez; Gotuzzo Eduardo; Kramer-Schadt Stephanie; Kuivanen Suvi; Laiton-Donato Katherine; Lozano-Parra Anyela; M\u00e1laga-Trillo Edward; Alva Dora Valencia Manos; Miss\u00e9 Doroth\u00e9e; Moreira-Soto Andres; Souza Thiago Moreno; Mozo Karen; Netto Eduardo Martins; Olk Nadine; Diaz Johanna Maribel Pachamora; Jorge C\u00e9lia Pedroso; Astudillo Ana Micsuco P\u00e9rez; Piche-Ovares Marta; Priet Stephane; Rinc\u00f3n-Orozco Bladimiro; Romero-Z\u00fa\u00f1iga Juan Jos\u00e9; Cisneros Silvia Paola Salgado; St\u00f6cker Andreas; Ugalde Juan Carlos Villalobos; Centeno Luis Angel Villar; Wenzler-Meya Moritz; Zevallos Juan Carlos; Drexler Jan Felix",
      "year": "2025",
      "journal": "The Lancet. Infectious diseases",
      "doi": "10.1016/S1473-3099(25)00110-0",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40245909/",
      "mesh_terms": "Humans; Latin America; Antibodies, Viral; Bunyaviridae Infections; Retrospective Studies; Male; Female; Orthobunyavirus; Immunoglobulin G; Disease Outbreaks; Adult; Spatio-Temporal Analysis; Immunoglobulin M; Middle Aged; Young Adult; Enzyme-Linked Immunosorbent Assay; Adolescent; Seroepidemiologic Studies; Child; Aged",
      "keywords": "",
      "pub_types": "Journal Article",
      "pmcid": ""
    },
    {
      "pmid": "29523194",
      "title": "Incidence and risk factors of neonatal infections in a rural Bangladeshi population: a community-based prospective study.",
      "abstract": "BACKGROUND: Infections cause about one fifth of the estimated 2.7 million annual neonatal deaths worldwide. Population-based data on burden and risk factors of neonatal infections are lacking in developing countries, which are required for the appropriate design of effective preventive and therapeutic interventions in resource-poor settings. METHODS: We used data from a community-based cluster-randomized trial conducted to evaluate the impact of two umbilical cord cleansing regimens with chlorhexidine solution on neonatal mortality and morbidity in a rural area of Sylhet District in Bangladesh. Newborns were assessed four times in the first 9\u00a0days of life by trained community health workers (CHWs) using a WHO IMCI-like clinical algorithm. Cumulative incidence of the first episode of infections in the first 9\u00a0days of life was estimated using survival analysis technique accounting for survival bias and competing risk of death before the occurrence of infection. A multivariable generalized estimating equation log-binomial regression model was used to identify factors independently associated with infections. RESULTS: Between 2007 and 2009, 30,267 newborns who received at least one postnatal assessment visit by a CHW within the first 9\u00a0days of life were included in this study. Cumulative incidence of infections in the first 9\u00a0days of life was 14.5% (95% CI 14.1-14.9%). Significant risk factors included previous child death in the family [RR 1.10 (95% CI 1.02-1.19)]; overcrowding [RR 1.14 (95% CI 1.04-1.25)]; home delivery [RR 1.86 (95% CI 1.58-2.19)]; unclean cord care [RR 1.15 (95% CI 1.03-1.28)]; multiple births [RR 1.34 (95% CI 1.15-1.56)]; low birth weight [reference: \u2265\u20092500\u00a0g, RR (95% CI) for <\u20091500, 1500-1999, and 2000-2499\u00a0g were 4.69 (4.01-5.48), 2.15 (1.92-2.42), and 1.15 (1.07-1.25) respectively]; and birth asphyxia [RR 1.65 (1.51-1.81)]. Higher pregnancy order lowered the risk of infections in the study population [compared to first pregnancy, RR (95% CI) for second, third, and \u2265 fourth pregnancy babies were 0.93 (0.85-1.02), 0.88 (0.79-0.97), and 0.79 (0.71-0.87), respectively]. CONCLUSION: Neonatal infections and associated deaths can be reduced by identifying and following up high-risk mothers and newborns and promoting facility delivery and clean cord care in resource-poor countries like Bangladesh where the burden of clinically ascertained neonatal infections is high. Further research is needed to measure the burden of infections in the entire neonatal period, particularly in the second fortnight and its association with essential newborn care. TRIAL REGISTRATION: NCT00434408 . Registered February 9, 2007.",
      "authors": "Mitra Dipak K; Mullany Luke C; Harrison Meagan; Mannan Ishtiaq; Shah Rashed; Begum Nazma; Moin Mamun Ibne; El Arifeen Shams; Baqui Abdullah H",
      "year": "2018",
      "journal": "Journal of health, population, and nutrition",
      "doi": "10.1186/s41043-018-0136-2",
      "url": "https://pubmed.ncbi.nlm.nih.gov/29523194/",
      "mesh_terms": "Adolescent; Adult; Bangladesh; Birth Order; Birth Weight; Chlorhexidine; Female; Home Childbirth; Humans; Incidence; Infant; Infant Health; Infant Mortality; Infant, Newborn; Infections; Male; Perinatal Death; Postnatal Care; Pregnancy; Prospective Studies; Risk Factors; Rural Population; Umbilical Cord; Young Adult",
      "keywords": "Bangladesh; Neonatal infections; Prospective study; Risk factors",
      "pub_types": "Journal Article; Randomized Controlled Trial; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.",
      "pmcid": "PMC5845215"
    },
    {
      "pmid": "33036834",
      "title": "The future of Cochrane Neonatal.",
      "abstract": "Cochrane Neonatal was first established in 1993, as one of the original review groups of the Cochrane Collaboration. In fact, the origins of Cochrane Neonatal precede the establishment of the collaboration. In the 1980's, the National Perinatal Epidemiology Unit at Oxford, led by Dr. Iain Chalmers, established the \"Oxford Database of Perinatal Trials\" (ODPT), a register of virtually all randomized controlled trials in perinatal medicine to provide a resource for reviews of the safety and efficacy of interventions used in perinatal care and to foster cooperative and coordinated research efforts in the perinatal field [1]. An effort that was clearly ahead of its time, ODPT comprised four main elements: a register of published reports of trials; a register of unpublished trials; a register of ongoing and planned trials; and data derived from pooled overviews (meta-analyses) of trials. This core effort grew into the creation of the seminal books, \"Effective Care in Pregnancy and Childbirth\" as well as \"Effective Care of the Newborn Infant\" [2,3]. As these efforts in perinatal medicine grew, Iain Chalmers thought well beyond perinatal medicine into the creation of a worldwide collaboration that became Cochrane [4]. The mission of the Cochrane Collaboration is to promote evidence-informed health decision-making by producing high-quality, relevant, accessible systematic reviews and other synthesized research evidence (www.cochrane.org). Cochrane Neonatal has continued to be one of the most productive review groups, publishing between 25 tpo to 40 new or updated systematic reviews each year. The impact factor has been steadily increasing over four years and now rivals most of the elite journals in pediatric medicine. Cochrane Neonatal has been a worldwide effort. Currently, there are 404 reviews involving 1206 authors from 52 countries. What has Cochrane done for babies? Reviews from Cochrane Neonatal have informed guidelines and recommendations worldwide. From January 2018 through June 2020, 77 international guidelines cited 221 Cochrane Neonatal reviews. These recommendations have included recommendations of the use of postnatal steroids, inhaled nitric oxide, feeding guidelines for preterm infants and other core aspects of neonatal practice. In addition, Cochrane Reviews has been the impetus for important research, including the large-scale trial of prophylactic indomethacin therapy, a variety of trials of postnatal steroids, trials of emollient ointment and probiotic trials [6]. While justifiably proud of these accomplishments, one needs to examine the future contribution of Cochrane Neonatal to the neonatal community. The future of Cochrane Neonatal is inexorably linked to the future of neonatal research. Obviously, there is no synthesis of trials data if, as a community, we fail to provide the core substrate for that research. As we look at the current trials' environment, fewer randomized controlled trial related to neonates are being published in recent years. A simple search of PubMed, limiting the search to \"neonates\" and \"randomized controlled trials\" shows that in the year 2000, 321 randomized controlled trials were published. These peaked five years ago, in 2015, with close to 900 trials being published. However, in 2018, only 791 studies are identified. Does this decrease represent a meaningful change in the neonatal research environment? Quite possibly. There are shifting missions of clinical neonatology at academic medical institutions, at least in the United States, with a focus on business aspects as well as other important competing clinical activities. Quality improvement has taken over as one of the major activities at both private and academic neonatal practices. Clearly, this is a needed improvement. All units at levels need to be dedicated to improving the outcomes of the sick and fragile population we care for. However, this need not be at the expense of formal clinical trials. It is understandable that this approach would be taken. Newer interventions frequently relate to complex systems of care and not the simple single interventions. Even trials that might traditionally have been done as randomized controlled trials, such as the introduction of a new mode of ventilation, are in reality complex challenges to the ability of institutions to create systems to adapt to these new technologies. Cost of doing trials has always been a barrier. The challenging regulatory and ethical environment contributes to these problems as well [7]. Despite these barriers, how does the research agenda of the neonatal community move forward in the 21st Century? We need to reassess how we create and disseminate our research findings. Innovative trial designs will allow us to address complex issues that we may not have tackled with conventional trials. Adaptive designs may allow us to look at potentially life-saving therapies in a way that feel more efficient and more ethical [8]. Clarifying issues such as the use of inhaled nitric oxide in preterm infants would be greatly served if we even knew whether or not there are hypoxemic preterm infant who would benefit from this therapy [9]. Current trials do not suggest so, yet current practice tells us that a significant number of these babies will receive inhaled nitric oxide [10-13]. Adaptive design, such as those done with trials of extracorporeal membrane oxygenation (ECMO), would allow us to quickly assess whether, in fact, these therapies are life-saving and allow us to consider whether or not further trials are needed [14,15]. Our understanding that many interventions involve entire systems approaches does not relegate us only to doing quality improvement work. Cluster designs may allow us to test more complex interventions that have usually been under the purview of quality improvement [16-18]. Cluster trials are well suited for such investigations and can be done with the least interruption to ongoing care. Ultimately, quality improvement is the application of the best evidence available (evidence-based medicine is \"what to do\" and evidence-based practice is \"how to do\"). [19,20]. Nascent efforts, such as the statement on \"embedding necessary research into culture and health\" (the ENRICH statement) call for the conduct of large, efficient pragmatic trials to evaluate neonatal outcomes, as in part called for in the ALPHA Collaboration [21,22]. This statement envisions an international system to identify important research questions by consulting regularly with all stakeholders, including patients, public health professionals, researchers, providers, policy makers, regulators, funders of industry. The ENRICH statement envisions a pathway to enable individuals, educational institutions, hospitals and health-care facilities to confirm their status as research-friendly by integrating an understanding of trials, other research and critical thinking and to teaching learning and culture, as well as an engagement with funders, professional organizations and regulatory bodies and other stake holders to raise awareness of the value of efficient international research to reduce barriers to large international pragmatic trials and other collaborative studies. In the future, if trials are to be done on this scale or trials are prospectively designed to be analyzed together, core outcome measures must be identified and standardized. That clinical trials supply estimates of outcomes that are relevant to patients and their families is critical. In addition, current neonatal research evaluates many different outcomes using multiple measures. A given measure can have multiple widely used definitions. Bronchopulmonary dysplasia (or chronic lung disease just to add to the confusion) quickly comes to mind [23,24]. The use of multiple definitions when attempting to measure the same outcome prevents synthesis of trial results and meta-analysis and hinders efforts to refine our estimates of effects. Towards that end, Webbe and colleagues have set out to develop a core outcome set for neonatal research [25]. Key stakeholders in the neonatal community reviewed multiple outcomes reported in neonatal trials and qualitative studies. Based on consensus, key outcome measures were identified, including survival, sepsis, necrotizing enterocolitis, brain injury on imaging, retinopathy or prematurity, gross motor ability, general cognitive ability, quality of life, adverse events, visual impairment or blindness, hearing impairment or deafness, chronic lung disease/bronchopulmonary dysplasia. Trials registration has to be a continued focus of the neonatal community. Trials registration allows for systematic reviewers to understand whether or not reporting bias has occurred [26]. It also allows for transparent incorporation of these core outcome measures. Ultimately, trials registration should include public reporting of all of these core outcomes and, in the future, access to data on an individual level such that more sophisticated individual patient data meta-analysis could occur. Lastly, there is no reason to see clinical trials and quality improvement as separate or exclusive activities. In fact, in the first NICQ Collaborative, conducted by Vermont Oxford Network, participation in a trial of postnatal steroids was considered part of the quality improvement best practices as opposed to simply choosing an as-of-yet unproven approach to use of this potent drug [27]. What role will Cochrane Neonatal play as we move forward in the 21st Century? As the neonatal community moves forward with its' research agenda, Cochrane Neonatal must not only follow but also lead with innovative approaches to synthesizing research findings. Cochrane Neonatal must continue to work closely with guideline developers. The relationship between systematic review production and guideline development is clearly outlined in reports from the Institute of Medicine [28,29]. Both are essential to guideline development; the systematic review group culling the evidence for the benefits and harms of a given intervention and the guideline group addressing the contextual issues of cost, feasibility, implementation and the values and preferences of individuals and societies. Most national and international guidelines groups now routinely use systematic reviews as the evidence basis for their guidelines and recommendations. Examples of the partnership between Cochrane Neonatal and international guideline development can be seen in our support of the World Health Organization (WHO) guidelines on the use of vitamin A or the soon to be published recommendations from the International Liaison Committee on Resuscitation (ILCOR) on cord management in preterm and term infants [30]. In the future, we need to collaborate early in the guideline development process so that the reviews are fit for purpose and meet the needs of the guideline developers and the end users. Towards this end, all Cochrane Neonatal reviews now contain GRADE assessments of the key clinical findings reported in the systematic review [31]. Addition of these assessments addresses the critical issue of our confidence in the findings. We are most confident in evidence provided by randomized controlled trials but this assessment can be can be downgraded if the studies that reported on the outcome in question had a high risk of bias, indirectness, inconsistency of results, or imprecision, or where there is evidence of reporting bias. Information provided by GRADE assessments is seen as critical in the process of moving from the evidence to formal recommendations [32]. We need to explore complex reviews, such as network (NMA) or multiple treatment comparison (MCT) meta-analyses, to address issues not formally addressed in clinical trials [33]. In conditions where there are multiple effective interventions, it is rare for all possible interventions to have been tested against each other [34]. A solution could be provided by network meta-analysis, which allows for comparing all treatments with each other, even if randomized controlled trials are not available for some treatment comparisons [34]. Network meta-analysis uses both direct (head-to-head) randomized clinical trial (RCT) evidence as well as indirect evidence from RCTs to compare the relative effectiveness of all included interventions [35]. However, Mills and colleagues note that the methodological quality of MTCs may be difficult for clinicians to interpret because the number of interventions evaluated may be large and the methodological approaches may be complex [35]. Cochrane Neonatal must take a role in both the creation of such analyses and the education of the neonatal community regarding the pitfalls of such an approach. The availability of individual patient data will make more sophisticated analyses more available to the community. Although the current crop of individual patient data meta-analyses (including the reviews of elective high frequency ventilation, inhaled nitric oxide and oxygen targets) have not differed substantially from the findings of the trials level reviews (suggesting that, in fact, sick neonates are more alike that unalike), there still will be a large role for individual patient data meta-analysis, at least to end the unfound conclusions that these therapies are effective in various subgroups (be it issues of sex, disease severity, or clinical setting) [36-39]. Future trials should take a lesson from the NeOProM Collaborative [37,39]. Given the difficulty in generating significant sample size and creating funding in any single environment, trials with similar protocols should be conducted in a variety of healthcare settings with an eye towards both study level and individual patient level meta-analysis at the conclusion of those trials, allowing for broader contribution to the trials data, more rapid accrual of sample size, and more precise results. We need to educate the neonatal community regarding the use and abuse of diagnostic tests. Diagnostic tests are a critical component of healthcare but also contribute greatly to the cost of medical care worldwide. These costs include the cost of the tests themselves and the costs of misdiagnosis and treatment of individuals who will not benefit from those treatments. Clinicians may have a limited understanding of diagnostic test accuracy, the ability of a diagnostic test to distinguish between patients with and without the disease or target condition [41,42]. Efforts such as Choosing Wisely have tried to identify these deficiencies [40]. As Cochrane has increased the general literacy of both the medical and general population regarding the interpretation of the results of interventions on various diseases, so should Cochrane move forward and improve the understanding of diagnostic testing. We need to become more efficient at creating and maintaining our reviews. The time spent to produce systematic reviews is far too great. In average, it takes between 2\u00bd to 6\u00bd\u00a0years to produce a systematic review, requiring intense time input for highly trained and expensive experts. Innovations in the ways in which we produce systematic reviews can make the review process more efficient by outsourcing some of the tasks or crowdsourcing to machine learning. We need to let the crowd and machine learning innovations help us sort the massive amounts of information needed to conduct systematic reviews. It can also allow for \"live\" updating of critical reviews where the research landscape is quickly changing [43]. Lastly, Cochrane Neonatal must focus more on users of the reviews and not necessarily authors of the reviews. Current Cochrane programming speaks of Cochrane training with an eye towards developing the skills of individuals who will conduct systematic reviews. While this is clearly needed and laudable, the fact of the matter is that most of the community will be \"users\" of the reviews. Individuals who need to understand how to use and interpret the findings of systematic reviews. These review users include clinicians, guideline developers, policy makers and families. Incorporation of GRADE guidelines has been a huge step in adding transparency to the level of uncertainty we have in our findings. From a family's perspective, we need to overcome the environment of mistrust or misunderstanding of scientific evidence and how we convey what we know, and our uncertainty about what we know, to parents and families.",
      "authors": "Soll Roger F; Ovelman Colleen; McGuire William",
      "year": "2020",
      "journal": "Early human development",
      "doi": "10.1016/j.earlhumdev.2020.105191",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33036834/",
      "mesh_terms": "Humans; Infant, Newborn; Neonatology; Perinatology; Practice Guidelines as Topic; Randomized Controlled Trials as Topic; Review Literature as Topic",
      "keywords": "",
      "pub_types": "Journal Article; Research Support, Non-U.S. Gov't",
      "pmcid": ""
    },
    {
      "pmid": "41426978",
      "title": "Parental and cell-division origin analysis to reduce false-positives in mosaic embryos for preimplantation genetic testing.",
      "abstract": "STUDY QUESTION: Can parental and cell-division origin analysis identify the false-positive chromosomal aberrations in mosaic embryos detected during preimplantation genetic testing for aneuploidy (PGT-A)? SUMMARY ANSWER: Parental origin analysis reclassified over half of mosaic embryos as euploid to reduce diagnostic uncertainty, and cell-division origin analysis effectively differentiated mitotic from meiotic errors to guide evidence-based mosaic embryo transfer. WHAT IS KNOWN ALREADY: Mosaic embryos pose significant challenges in PGT-A, with reported detection rates varying widely (2-35.6%) due to biological and technical factors, but current methods lack reliable approaches to distinguish true mosaicism from technical artifacts. Decisions regarding mosaic embryo transfer remain conservative and hampered by inadequate understanding of the origins of errors (mitotic vs meiotic) and limited data on long-term neonatal outcomes. STUDY DESIGN SIZE DURATION: In this retrospective study, we analyzed 9062 PGT-A results and 8645 amniocentesis samples from 2021 to 2024 to investigate the difference in mosaicism rates between PGT treatment and prenatal diagnosis. An analysis of parental and cell-division origins was performed on 1221 consecutive results from PGT-A and PGT for monogenic disorders (PGT-M) from 259 patients across 304 treatment cycles in 2024. Multi-site re-biopsies of 36 donated embryos and the clinical outcomes of 19 mosaic embryo transfers were analyzed in 2024 and 2025. PARTICIPANTS/MATERIALS SETTING METHODS: An innovative algorithm, termed parental haplotype trace (PH-trace), was developed to identify the genetic origin of chromosomal aberrations for mosaic verification. Briefly, biallelic homozygous single-nucleotide polymorphisms (SNPs) in the parental genome exhibit equal allelic frequencies in euploid embryos. When chromosomal aberrations occur, these SNPs show an allelic bias toward either the maternal or paternal genome. We defined the ratio of maternal-biased SNPs to paternal-biased SNPs as the uneven score to quantitatively assess the parental origin of chromosomal aberrations. Receiver operating characteristic (ROC) curve analysis based on uneven scores from euploid and aneuploid embryos was used to determine critical thresholds for identifying false-positive mosaic embryos. Additionally, heterozygous SNPs in the parental genome were used to determine the cell-division origin of chromosomal aberrations. To validate our findings, we performed multi-site re-biopsies of aneuploid and mosaic embryos. MAIN RESULTS AND THE ROLE OF CHANCE: The prevalence of mosaicism differed significantly between PGT-A and prenatal diagnosis (12.2% vs 0.9%, P\u2009<\u20090.001). Parental origin analysis based on PH-trace reclassified 52.6% of mosaic embryos as euploid and increased the overall rate of usable embryos by 8.6%. Mitotic errors accounted for the majority of true mosaic cases, providing critical guidance for embryo transfer prioritization. Re-biopsy validation of donated embryos revealed that 94.1% of predicted false-positive copy-number variations (CNVs) were not detected in subsequent samples, whereas 71.4% of parental-biased CNVs were repeatedly detected. Among mosaic embryos resulting in live births, 66.7% were false-positive, and 22.2% originated from mitotic errors. LIMITATIONS REASONS FOR CAUTION: Our two-tiered analytical approach relies on a sufficient number of informative SNPs in parental and embryonic genomes (e.g. over 30 informative SNPs per chromosomal aberration). Additionally, the clinical implications of this method require further validation through long-term follow-up studies. WIDER IMPLICATIONS OF THE FINDINGS: This study presents an effective strategy to identify false-positive mosaic embryos, thereby improving embryo utilization in clinical treatment. By elucidating the cell-division origin of mosaicism, our findings provide embryologists with evidence-based criteria for prioritizing embryo transfers. Furthermore, this approach may reduce the number of IVF cycles and associated costs for patients with limited euploid embryo availability. STUDY FUNDING/COMPETING INTERESTS: This work was supported by the National Natural Science Foundation of China (82371728), the Chongqing's Mid-young Medical Elite Talent Project (YXGD202555), the Key Projects of the Collaborative Medical Research between Science and Health Commission of Chongqing (2026ZDXM004), the Chongqing Municipal Technological Innovation and Application Development Special Project (CSTB2022TIAD-KPX0146), and the Chongqing Nature Science Foundation (CSTB2023NSCQ-MSX0443). The authors have no competing interests to declare. TRIAL REGISTRATION NUMBER: N/A.",
      "authors": "Zhang Qi; Liu Guicen; Xiang Yezhou; Zou Yangyun; Chen Yulin; Xia Yingying; Xiong Shun; Fu Tao; Wang Jiang; Jiang Yan; Xiong Jiaojiao; Zhang Xiaodong; Lu Sijia; Liu Dongyun; Huang Guoning; Lin Tingting",
      "year": "2025",
      "journal": "Human reproduction open",
      "doi": "10.1093/hropen/hoaf075",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41426978/",
      "mesh_terms": "",
      "keywords": "cell-division origin; false-positives; mosaicism; parental origin; uneven score",
      "pub_types": "Journal Article",
      "pmcid": "PMC12714397"
    },
    {
      "pmid": "41157311",
      "title": "Mineral Metabolism Assays, Central DXA, and Fracture Risk Probabilities in Menopausal Patients with Non-Functional Adrenal Tumors with/Without Mild Autonomous Cortisol Secretion: Does the Presence of Unilateral Versus Bilateral Tumors Matter?",
      "abstract": "INTRODUCTION/BACKGROUND: Most adrenal incidentalomas (AIs) are non-functioning adrenal tumors (NFATs) without clinically overt hormonal hypersecretion; one-third show subtle endocrine over-activity and mild autonomous cortisol secretion (MACS). One out of ten NFATs involves not a unilateral (UTs), but bilateral tumors (BTs). Bone health, as opposed to cardio-metabolic complications, is less studied in NFAs/MACS, particularly in BTs. Hence, we aimed to analyze (blood) mineral metabolism assays (MMAs), including bone turnover markers (BTMs), central Dual-Energy X-ray Absorptiometry (DXA), and 10-year fracture risk estimation (FRAX/FRAXplus) in menopausal patients with UTs vs. BTs. METHODS: This was a retrospective, single-center study. The inclusion criteria were women aged \u226550 y and CT-based AI detection. The exclusion criteria were medication against osteoporosis, malignancies, bone metabolic disorders, and cs-1mg-DST >5 \u00b5g/dL. RESULTS: The cohort [N = 129; mean age: 62.39 \u00b1 7.9 y; and y since menopause (YSM): 13.7 \u00b1 8] included UT (62.22%) and BT (31.78%) groups with a similar age, YSM, type 2 diabetes rate (35.23% vs. 36.59%), arterial hypertension (73.6% vs. 75.5%), BMI, fasting glycemia, and glycated hemoglobin A1c (p > 0.5 for each). The borderline significance for morning cortisol was higher in UTs vs. BTs [median (interquartile interval): 13.9 (11.16, 15.00) vs. 10.10 (8.88, 12.95) \u00b5g/dL; p = 0.05] and the MACS-positive rate (24.45% vs. 36.59%; p = 0.051). The largest tumor diameter was similar (2.26 \u00b1 0.97 vs. 2.51 \u00b1 0.87 cm; p = 0.175), as was cs-1mg-DST [1.27 (1.01, 1.95) vs. 1.52 (0.92, 2.78) \u00b5g/dL; p = 0.357]. MMAs, BTMs, and DXA-BMD/T scores were similar in the UT vs. BT groups. The most prevalent DXA categories were osteopenia (50.82%) and normal (41.38%). The rate of DXA bone impairment (osteoporosis + osteopenia) was 72.13% vs. 58.62%. A generally low prevalence of fragility fractures was found (3.88%; N = 5, 3/2 between the groups). Out of the 25.58% (N = 33) females who were found to be MACS-positive, 54.55% were in the UT group and 45.45% were in the BT group. Age, YSM, the rate of analyzed comorbidities, BMI, biochemical parameters, DXA/BMDs, and FRAX/FRAXplus (lumbar BMD adjustment)-based probabilities were similar between the UT and BT groups, regarding MACS-positive vs. MACS-negative groups. Diabetic patients were all MACS-positive. A higher PTH level in the MACS-positive UT vs. MACS-positive BT groups (36.32 \u00b1 9.21 vs. 51.65 \u00b1 9.58 pg/mL; p = 0.01) was found, with the mean 25-hydroxyvitamin D showing mild deficiency (24.21 \u00b1 12.73 vs. 26.16 \u00b1 9.89 ng/mL; p = 0.694). In UTs, the largest tumor diameter statistically significantly correlated with baseline ACTH (r = -0.391; p < 0.001) and cs-1mg-DST (r = 0.306; p < 0.001), while in BTs, the largest diameter of the two tumors showed a positive correlation with cs-1mg-DST (r = 0.309; p = 0.012). CONCLUSIONS: The findings from this real-life setting (similar age, YSM, and diabetes and MACS-positive rates) could help us to better understand the bone features in UTs vs. BTs, noting that ACTH/cs-1mg-DST measurements showed no difference. The study population was associated with a generally low fracture prevalence and 10-year fracture risk probabilities, which might act as a bias in this distinct clinical exploration. Whether a multifactorial algorithm is needed to provide a 360-degree perspective of the bone health assessment in these patients remains an open matter. So far, starting from the current guidelines, a patient-centered approach is mandatory. To our best knowledge, this study adds to the limited number of prior studies regarding bone impairment in bilateral tumors.",
      "authors": "Trandafir Alexandra-Ioana; Carsote Mara; Costachescu Mihai; Sima Oana-Claudia; Florescu Alexandru-Florin",
      "year": "2025",
      "journal": "Life (Basel, Switzerland)",
      "doi": "10.3390/life15101639",
      "url": "https://pubmed.ncbi.nlm.nih.gov/41157311/",
      "mesh_terms": "",
      "keywords": "ACTH; CT; cortisol; dexamethasone; endocrine; fracture; hormone; incidentaloma; osteopenia; osteoporosis",
      "pub_types": "Journal Article",
      "pmcid": "PMC12565219"
    },
    {
      "pmid": "32493460",
      "title": "A short, animated video to improve good COVID-19 hygiene practices: a structured summary of a study protocol for a randomized controlled trial.",
      "abstract": "OBJECTIVES: Entertainment-education (E-E) media can improve behavioral intent toward health-related practices. In the era of COVID-19, millions of people can be reached by E-E media without requiring any physical contact. We have designed a short, wordless, animated video about COVID-19 hygiene practices-such as social distancing and frequent hand washing-that can be rapidly distributed through social media channels to a global audience. The E-E video's effectiveness, however, remains unclear. The study aims to achieve the following objectives. To: 1.Quantify people's interest in watching a short, animated video about COVID-19 hygiene (abbreviated to CoVideo).2.Establish the CoVideo's effectiveness in increasing behavioural intent toward COVID-19 hygiene.3.Establish the CoVideo's effectiveness in improving COVID-19 hygiene knowledge. TRIAL DESIGN: The present study is a multi-site, parallel group, randomized controlled trial (RCT) comparing the effectiveness of the CoVideo against an attention placebo control (APC) video or no video. The trial has an intervention arm (CoVideo), placebo arm (APC), and control arm (no video). Nested in each trial arm is a list experiment and questionnaire survey, with the following ordering. Arm 1: the CoVideo, list experiment, and questionnaire survey. Arm 2: the APC video, list experiment, questionnaire survey, and CoVideo. Arm 3: the list experiment, questionnaire survey, and CoVideo. For each list experiment, participants will be randomized to a control or treatment group. The control group will receive a list of five items and the treatment group will receive the same five items plus one item about COVID-19 hygiene. We will use the list experiment to reduce response bias associated with socially desirable answers to COVID-19 questions. The questionnaire survey will include items about the participant's age, sex, country of residence, highest education, and knowledge of COVID-19 spread. After completing the list experiment and questionnaire survey, participants in Arms 2 and 3 will receive the CoVideo to ensure post-trial access to treatment. PARTICIPANTS: This will be an online study setting. We will use Prolific Academic (ProA: https://www.prolific.co) to recruit participants and host our study on the Gorilla\u2122 platform (www.gorilla.sc). To be eligible, participants must be between the age of 18 and 59 years (male, female, or other) and have current residence in the United States, the United Kingdom, Germany, Spain, Mexico, or France. Participants will be excluded from the study if they cannot speak English, German, French, or Spanish (since the instructions and survey questions will be available in these 4 languages only). INTERVENTION AND COMPARATOR: The intervention is an E-E video about COVID-19 hygiene (CoVideo). Developed by our co-author (MA) for Stanford Medicine, the CoVideo is animated with sound effects, and has no words, speech, or text. The CoVideo shows how the novel coronavirus is spread (airborne, physical contact) and summarizes the public's response to the COVID-19 outbreak. Key components of the CoVideo are the promotion of five hygiene practices: i) social distancing and avoiding group gatherings, ii) frequently washing hands with soap and water or sanitizer, iii) cleaning surfaces at home (e.g., kitchen counters), iv) not sharing eating utensils, and v) avoidance of stockpiling essential goods (such as toilet paper and face masks). The CoVideo, which was designed for universal reach and optimized for release on social media channels, can be viewed at https://www.youtube.com/watch?v=rAj38E7vrS8. The comparators are an APC video (Arm 2) or no video (Arm 3). The APC video is similar in style to the CoVideo; it is also animated with a duration of 2.30 minutes, has sound effects but no words, speech, or text. The video message is about how small choices become actions, which become habits, which become a way of life. It is available at https://www.youtube.com/watch?v=_HEnohs6yYw. Each list experiment will have a control list as the comparator. The control list is needed to measure the prevalence of behavioral intent toward COVID-19 hygiene. MAIN OUTCOMES: This study will measure primary and secondary outcomes related to COVID-19 hygiene. By hygiene, we mean the adoption of behaviors or practices that reduce the chances of being infected or spreading COVID-19. As our primary outcome, we will measure changes in behavioral intent toward five hygiene practices: social distancing, washing hands, cleaning household surfaces, not sharing eating utensils, and not stockpiling essential goods. As a secondary outcome, we will measure knowledge about behaviors that can prevent the spread of COVID-19. RANDOMIZATION: Using a web-based randomization algorithm, Gorilla will randomly allocate participants to the intervention (CoVideo), placebo (APC), or control (no video) arm (sequence generation) at a 1:1:1 ratio. Within each trial arm, Gorilla will randomly allocate participants at a 1:1 ratio to the control or treatment group. Items in the lists will be randomly ordered to avoid order effects. The presentation order of the list experiments will also be randomized. BLINDING: Because ProA handles the interaction between the study investigators and participants, the participants will be completely anonymous to the study investigators. The outcome measures will be self-reported and submitted anonymously. All persons in the study team will be blinded to the group allocation. NUMBERS TO BE RANDOMIZED: The Gorilla algorithm will randomize 6,700 participants to each trial arm, giving a total sample size of 20,100. TRIAL STATUS: The protocol version number is 1.0 and the date is 18 May 2020. Recruitment is expected to end by 22 June 2020. Thus far, the study investigators have recruited 2,500 participants on ProA. Of these participants, 800 have completed the study on the Gorilla platform. TRIAL REGISTRATION: The study and its outcomes were registered at the German Clinical Trials Register (www.drks.de) on May 12th, 2020, protocol number: #DRKS00021582. The study was registered before any data was collected. FULL PROTOCOL: The full protocol is attached as an additional file, accessible from the Trials website (Additional file 1). In the interest in expediting dissemination of this material, the familiar formatting has been eliminated; this Letter serves as a summary of the key elements of the full protocol.",
      "authors": "Vandormael Alain; Adam Maya; Greuel Merlin; B\u00e4rnighausen Till",
      "year": "2020",
      "journal": "Trials",
      "doi": "10.1186/s13063-020-04449-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/32493460/",
      "mesh_terms": "Adolescent; Adult; Female; Humans; Male; Middle Aged; Young Adult; Betacoronavirus; Coronavirus Infections; COVID-19; Europe; Hand Disinfection; Health Behavior; Health Communication; Health Education; Health Knowledge, Attitudes, Practice; Multicenter Studies as Topic; Pandemics; Pneumonia, Viral; Public Opinion; Randomized Controlled Trials as Topic; SARS-CoV-2; Surveys and Questionnaires; United States; Video Recording",
      "keywords": "COVID-19; behavioral intent; entertainment-education; knowledge; list experiment; protocol; randomised controlled trial",
      "pub_types": "Clinical Trial Protocol; Letter",
      "pmcid": "PMC7267760"
    },
    {
      "pmid": "33419461",
      "title": "Effectiveness and cost-effectiveness of four different strategies for SARS-CoV-2 surveillance in the general population (CoV-Surv Study): a structured summary of a study protocol for a cluster-randomised, two-factorial controlled trial.",
      "abstract": "OBJECTIVES: In this cluster-randomised controlled study (CoV-Surv Study), four different \"active\" SARS-CoV-2 testing strategies for general population surveillance are evaluated for their effectiveness in determining and predicting the prevalence of SARS-CoV-2 infections in a given population. In addition, the costs and cost-effectiveness of the four surveillance strategies will be assessed. Further, this trial is supplemented by a qualitative component to determine the acceptability of each strategy. Findings will inform the choice of the most effective, acceptable and affordable strategy for SARS-CoV-2 surveillance, with the most effective and cost-effective strategy becoming part of the local public health department's current routine health surveillance activities. Investigating its everyday performance will allow us to examine the strategy's applicability to real time prevalence prediction and the usefulness of the resulting information for local policy makers to implement countermeasures that effectively prevent future nationwide lockdowns. The authors would like to emphasize the importance and relevance of this study and its expected findings in the context of population-based disease surveillance, especially in respect to the current SARS-CoV-2 pandemic. In Germany, but also in many other countries, COVID-19 surveillance has so far largely relied on passive surveillance strategies that identify individuals with clinical symptoms, monitor those cases who then tested positive for the virus, followed by tracing of individuals in close contact to those positive cases. To achieve higher effectiveness in population surveillance and to reliably predict the course of an outbreak, screening and monitoring of infected individuals without major symptoms (about 40% of the population) will be necessary. While current testing capacities are also used to identify such asymptomatic cases, this rather passive approach is not suitable in generating reliable population-based estimates of the prevalence of asymptomatic carriers to allow any dependable predictions on the course of the pandemic. To better control and manage the SARS-CoV-2 pandemic, current strategies therefore need to be complemented by an active surveillance of the wider population, i.e. routinely conducted testing and monitoring activities to identify and isolate infected individuals regardless of their clinical symptoms. Such active surveillance strategies will enable more effective prevention of the spread of the virus as they can generate more precise population-based parameters during a pandemic. This essential information will be required in order to determine the best strategic and targeted short-term countermeasures to limit infection spread locally. TRIAL DESIGN: This trial implements a cluster-randomised, two-factorial controlled, prospective, interventional, single-blinded design with four study arms, each representing a different SARS-CoV-2 testing and surveillance strategy. PARTICIPANTS: Eligible are individuals age 7 years or older living in Germany's Rhein-Neckar Region who consent to provide a saliva sample (all four arms) after completion of a brief questionnaire (two arms only). For the qualitative component, different samples of study participants and non-participants (i.e. eligible for study, but refuse to participate) will be identified for additional interviews. For these interviews, only individuals age 18 years or older are eligible. INTERVENTION AND COMPARATOR: Of the four surveillance strategies to be assessed and compared, Strategy A1 is considered the gold standard for prevalence estimation and used to determine bias in other arms. To determine the cost-effectiveness, each strategy is compared to status quo, defined as the currently practiced passive surveillance approach. Strategy A1: Individuals (one per household) receive information and study material by mail with instructions on how to produce a saliva sample and how to return the sample by mail. Once received by the laboratory, the sample is tested for SARS-CoV-2 using Reverse Transcription Loop-mediated Isothermal Amplification (RT-LAMP). Strategy A2: Individuals (one per household) receive information and study material by mail with instructions on how to produce their own as well as saliva samples from each household member and how to return these samples by mail. Once received by the laboratory, the samples are tested for SARS-CoV-2 using RT-LAMP. Strategy B1: Individuals (one per household) receive information by mail on how to complete a brief pre-screening questionnaire which asks about COVID-19 related clinical symptoms and risk exposures. Only individuals whose pre-screening score crosses a defined threshold, will then receive additional study material by mail with instructions on how to produce a saliva sample and how to return the sample by mail. Once received by the laboratory, the saliva sample is tested for SARS-CoV-2 using RT-LAMP. Strategy B2: Individuals (one per household) receive information by mail on how to complete a brief pre-screening questionnaire which asks about COVID-19 related clinical symptoms. Only individuals whose pre-screening score crosses a defined threshold, will then receive additional study material by mail with instructions how to produce their own as well as saliva samples from each household member and how to return these samples by mail. Once received by the laboratory, the samples are tested for SARS-CoV-2 using RT-LAMP. In each strategy, RT-LAMP positive samples are additionally analyzed with qPCR in order to minimize the number of false positives. MAIN OUTCOMES: The identification of the one best strategy will be determined by a set of parameters. Primary outcomes include costs per correctly screened person, costs per positive case, positive detection rate, and precision of positive detection rate. Secondary outcomes include participation rate, costs per asymptomatic case, prevalence estimates, number of asymptomatic cases per study arm, ratio of symptomatic to asymptomatic cases per study arm, participant satisfaction. Additional study components (not part of the trial) include cost effectiveness of each of the four surveillance strategies compared to passive monitoring (i.e. status quo), development of a prognostic model to predict hospital utilization caused by SARS-CoV-2, time from test shipment to test application and time from test shipment to test result, and perception and preferences of the persons to be tested with regard to test strategies. RANDOMISATION: Samples are drawn in three batches of three continuous weeks. Randomisation follows a two-stage process. First, a total of 220 sampling points have been allocated to the three different batches. To obtain an integer solution, the Cox-algorithm for controlled rounding has been used. Afterwards, sample points have been drawn separately per batch, following a probability proportional to size (PPS) random sample. Second, for each cluster the same number of residential addresses is randomly sampled from the municipal registries (self-weighted sample of individuals). The 28,125 addresses drawn per municipality are then randomly allocated to the four study arms A1, A2, B1, and B2 in the ratio 5 to 2.5 to 14 to 7 based on the expected response rates in each arm and the sensitivity and specificity of the pre-screening tool as applied in strategy B1 and B2. Based on the assumptions, this allocation should yield 2500 saliva samples in each strategy. Although a municipality can be sampled by multiple batches and the overall number of addresses per municipality might vary, the number of addresses contacted in each arm is kept constant. BLINDING (MASKING): The design is single-blinded, meaning the staff conducting the SARS-CoV-2 tests are unaware of the study arm assignment of each single participant and test sample. SAMPLE SIZES: Total sample size for the trial is 10,000 saliva samples equally allocated to the four study arms (i.e. 2,500 participants per arm). For the qualitative component, up to 60 in-depth interviews will be conducted with about 30 study participants (up to 15 in each arm A and B) and 30 participation refusers (up to 15 in each arm A and B) purposefully selected from the quantitative study sample to represent a variety of gender and ages to explore experiences with admission or rejection of study participation. Up to 25 asymptomatic SARS-CoV-2 positive study participants will be purposefully selected to explore the way in which asymptomatic men and women diagnosed with SARS-CoV-2 give meaning to their diagnosis and to the dialectic between feeling concurrently healthy and yet also being at risk for transmitting COVID-19. In addition, 100 randomly selected study participants will be included to explore participants' perspective on testing processes and implementation. TRIAL STATUS: Final protocol version is \"Surveillance_Studienprotokoll_03Nov2020_v1_2\" from November 3, 2020. Recruitment started November 18, 2020 and is expected to end by or before December 31, 2020. TRIAL REGISTRATION: The trial is currently being registered with the German Clinical Trials Register (Deutsches Register Klinischer Studien), DRKS00023271 ( https://www.drks.de/drks_web/navigate.do?navigationId=trial . HTML&TRIAL_ID=DRKS00023271). Retrospectively registered 30 November 2020. FULL PROTOCOL: The full protocol is attached as an additional file, accessible from the Trials website (Additional file 1). In the interest in expediting dissemination of this material, the familiar formatting has been eliminated; this Letter serves as a summary of the key elements of the full protocol.",
      "authors": "Deckert Andreas; Anders Simon; de Allegri Manuela; Nguyen Hoa Thi; Souares Aur\u00e9lia; McMahon Shannon; Boerner Kathleen; Meurer Matthias; Herbst Konrad; Sand Matthias; Koeppel Lisa; Siems Tobias; Brugnara Lucia; Brenner Stephan; Burk Robin; Lou Dan; Kirrmaier Daniel; Duan Yuanqiang; Ovchinnikova Svetlana; Marx Michael; Kr\u00e4usslich Hans Georg; Knop Michael; B\u00e4rnighausen Till; Denkinger Claudia",
      "year": "2021",
      "journal": "Trials",
      "doi": "10.1186/s13063-020-04982-z",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33419461/",
      "mesh_terms": "COVID-19; COVID-19 Nucleic Acid Testing; Cost-Benefit Analysis; Female; Germany; Health Care Costs; Humans; Male; Molecular Diagnostic Techniques; Nucleic Acid Amplification Techniques; Population Surveillance; Predictive Value of Tests; Prevalence; Randomized Controlled Trials as Topic; Reproducibility of Results; SARS-CoV-2; Saliva; Single-Blind Method; Surveys and Questionnaires",
      "keywords": "COVID-19; cluster-randomised controlled trial; cost-effectiveness; implementation; pandemic; population-based surveillance; protocol",
      "pub_types": "Clinical Trial Protocol; Letter",
      "pmcid": "PMC7791150"
    },
    {
      "pmid": "33849629",
      "title": "A randomized, double-blind, placebo-controlled phase III clinical trial to evaluate the efficacy and safety of SARS-CoV-2 vaccine (inactivated, Vero cell): a structured summary of a study protocol for a randomised controlled trial.",
      "abstract": "OBJECTIVES: The primary objective is to evaluate the efficacy of an inactivated and aluminium hydroxide adsorbed SARS-CoV-2 vaccine (Sinovac, China) in voluntary participants after 14 days of the second dose against RT-PCR confirmed symptomatic COVID-19 cases. The secondary objectives include evaluating the efficacy after at least one dose of the vaccine against RT-PCR confirmed symptomatic COVID-19 cases; the efficacy of two doses of the vaccine on the rates of hospitalization and death; the safety of the vaccine including adverse reactions up to one year after the 2nd dose of vaccination; and the immunogenicity of the vaccine and its duration up to 120 days. TRIAL DESIGN: This is a phase III, randomized, double-blind, placebo-controlled case driven clinical trial to assess the efficacy and safety of the vaccine. The study is planned to be carried out within two separate cohorts in voluntary participants aged between 18-59 years old. The first cohort includes healthcare professionals actively working in healthcare units, who are assumed to have higher risk of acquiring COVID-19, and the second cohort includes other immunocompetent subjects in the same age group, who are at a regular risk for COVID-19 disease. In Cohort 1, healthcare professionals will be randomized to receive two intramuscular doses of investigational product or the placebo in a 1:1 ratio and they will be monitored for 12 months by active surveillance of COVID-19. In Cohort 2, immunocompetent subjects will be randomized to receive vaccine or the placebo in a 2:1 ratio. PARTICIPANTS: Healthcare professionals of both genders, including medical doctors, nurses, cleaners, hospital technicians, and administrative personnel who work in any department of a healthcare unit and immunocompetent individuals of both genders are included. Pregnant (confirmed by positive beta-hCG test) and breastfeeding women as well as those intending to become pregnant within three months after vaccination are excluded. Other exclusion criteria include history of COVID-19 test positivity (PCR or immunoglobulin test results), any form of immunosuppressive therapy including corticosteroids within 6 months, history of bleeding disorders, asplenia, and administration of any form of immunoglobulins or blood products within 3 months. Exclusion criteria for the second dose include any serious adverse events related with the vaccine, anaphylaxis or hypersensitivity after vaccination, or any confirmed or suspected autoimmune or immunosuppressive disease (including HIV infection). Participants are only included after signing the voluntary informed consent form, ensuring cooperation in visits, undergoing screening for evaluation, and conforming to all the inclusion and exclusion criteria. All clinical sites are located in Turkey. INTERVENTION AND COMPARATOR: The vaccine was manufactured by Sinovac Research & Development Co., Ltd. It is a preparation made from a novel coronavirus (strain CZ02) grown in the kidney cell cultures (Vero Cell) of the African green monkey and contains inactivated SARS-CoV-2 virus, aluminium hydroxide, disodium hydrogen phosphate, sodium dihydrogen phosphate, and sodium chloride. A dose of 0.5 mL contains 600 SU of SARS-CoV-2 virus antigen. The placebo contains aluminium hydroxide, disodium hydrogen phosphate, sodium dihydrogen phosphate, and sodium chloride (0.5mL/dose). Scheduled visits and additional unscheduled weekly visits will be performed for the first 13 weeks and neutralizing antibody test, IgG test, T-Cell activation test, pregnancy test, and RT-PCR tests along with total antibody test will be performed. Adverse events and serious adverse events during the follow-up will be recorded on diary cards. Diary cards will collect information on the timing and severity of COVID-19 symptoms and solicited adverse events recorded by the subjects during one-year follow-up period. All serious adverse events will be managed and necessary treatment will be ensured according to the local regulations. All serious adverse events following vaccination will be reported to the ethics committee, the Ministry of Health, and the study sponsor within 24 hours of detection. MAIN OUTCOMES: The primary efficacy endpoint is the incidence of symptomatic cases of COVID-19 disease confirmed by RT-PCR two weeks after the second dose of vaccination. Secondary efficacy endpoints are the incidence of hospitalization/mortality rates among one or two dose regimens, duration of immunogenicity rates up to 120 days, the seroconversion rate, the seropositivity rate, neutralizing antibody titer, and IgG levels 14 days after each dose of vaccination. The primary safety endpoint is the severity and frequency of local and systemic adverse reactions during the period of one week after vaccination. The study would be terminated if more than 15% of the subjects have grade \u22653 adverse events related to vaccination including local reactions. RANDOMISATION: Eligible subjects will be randomized at their Study Day 0 to two study groups using an Interactive Web Response System (IWRS; developed by Omega CRO, Ankara, Turkey) in both risk groups. The IWRS system customizes the randomization algorithm. After enrolment in the study, each participant will be randomly assigned to either of the two treatment arms at a ratio of 1:1 in the high-risk group and at a ratio of 2:1 in the normal risk group. Each enrolled participant will be assigned to a code and will receive the treatment labelled with the code. BLINDING (MASKING): The trial is a double-blind study to avoid introducing bias. The blinding may be broken by the investigator in the event of a medical emergency in which knowledge of the identity of the study vaccine is critical for management of the subject's immediate treatment. The Data and Safety Monitoring Board is to be contacted in case of breaking the blinding for a study object. The blood samples will be taken from both placebo and vaccinated groups, in order not to break the blinding. NUMBERS TO BE RANDOMISED (SAMPLE SIZE): The study is planned to be carried out with two separate cohorts. The Cohort 1 includes healthcare professionals working in healthcare units and the Cohort 2 consists of immunocompetent subjects having normal risk for COVID-19 disease. The Cohort 2 will be initiated after the evaluation of the interim safety report of the Cohort 1 by the Data and Safety Monitoring Board. Both cohorts will be followed-up via RT-PCR to confirm symptomatic COVID-19 cases. If the clinical efficacy of the vaccine is shown in the Cohort 1 or 2, the subjects randomized into the placebo arm will also be vaccinated. In the Cohort 1, 588 subjects should be included in both arms with the assumption that the risk of infection with COVID-19 will be 5% for the placebo arm and 2% for the vaccine arm in the high-risk group. Considering 10% of drop-out rate and 5% of seropositivity or PCR positivity at baseline, 680 subjects should be screened at both arms of the Cohort 1. Group sample sizes of 7545 SARS-CoV-2 vaccine and 3773 placebo suits at a two-sided 95% confidence interval for the difference in population proportions with a width equal to 1.0%, when the estimated incidence rate for vaccinated group is 1.0% and the estimated incidence rate for placebo group is 2.0%. Drop-out rate is assumed to be 10% and seropositivity or PCR positivity at baseline is assumed to be 5%; accordingly, 13000 participants are needed to be enrolled totally in both cohorts. The remaining 11640 subjects will be screened in the Cohort 2 and eligible subjects will be randomized at a ratio of 2:1. TRIAL STATUS: Protocol version 6.0 - 15 October 2020. Recruitment started on 15.09.2020 and is expected to end on February 2022. TRIAL REGISTRATION: ClinicalTrials.gov, NCT04582344 . Registered 8 October 2020 FULL PROTOCOL: The full protocol of the trial is attached as an additional file, accessible from the Trials website (Additional file 1). In the interest in expediting dissemination of this material, the familiar formatting has been eliminated; this Letter serves as a summary of the key elements of the full protocol.",
      "authors": "Akova Murat; Unal Serhat",
      "year": "2021",
      "journal": "Trials",
      "doi": "10.1186/s13063-021-05180-1",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33849629/",
      "mesh_terms": "Animals; COVID-19; COVID-19 Vaccines; China; Chlorocebus aethiops; Clinical Trials, Phase III as Topic; Double-Blind Method; Female; Humans; Male; Pregnancy; Randomized Controlled Trials as Topic; SARS-CoV-2; Treatment Outcome; Vero Cells",
      "keywords": "COVID-19; Turkey; double blind; inactivated vaccines; phase III clinical trial; protocol; randomised placebo controlled trial; vaccine",
      "pub_types": "Clinical Trial Protocol; Letter",
      "pmcid": "PMC8042350"
    }
  ]
}