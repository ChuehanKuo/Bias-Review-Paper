{
  "included": [
    {
      "openalex_id": "https://openalex.org/W4393864308",
      "doi": "10.1109/jbhi.2024.3384848",
      "title": "De-Biased Disentanglement Learning for Pulmonary Embolism Survival Prediction on Multimodal Data",
      "abstract": "Health disparities among marginalized populations with lower socioeconomic status significantly impact the fairness and effectiveness of healthcare delivery. The increasing integration of artificial intelligence (AI) into healthcare presents an opportunity to address these inequalities, provided that AI models are free from bias. This paper aims to address the bias challenges by population disparities within healthcare systems, existing in the presentation of and development of algorithms, leading to inequitable medical implementation for conditions such as pulmonary embolism (PE) prognosis. In this study, we explore the diverse bias in healthcare systems, which highlights the demand for a holistic framework to reducing bias by complementary aggregation. By leveraging de-biasing deep survival prediction models, we propose a framework that disentangles identifiable information from images, text reports, and clinical variables to mitigate potential biases within multimodal datasets. Our study offers several advantages over traditional clinical-based survival prediction methods, including richer survival-related characteristics and bias-complementary predicted results. By improving the robustness of survival analysis through this framework, we aim to benefit patients, clinicians, and researchers by enhancing fairness and accuracy in healthcare AI systems.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Zhusi Zhong et al.",
      "keywords": "Computer science; Pulmonary embolism; Artificial intelligence; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3384848",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "Clinical Prediction Model; Survival Analysis",
      "health_domain": "Pulmonology",
      "bias_axes": "Gender/Sex; Age; Socioeconomic Status",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Both",
      "approach_method": "Representation Learning",
      "clinical_setting": "Public Health/Population",
      "key_findings": "Our study offers several advantages over traditional clinical-based survival prediction methods, including richer survival-related characteristics and bias-complementary predicted results. By improving the robustness of survival analysis through this framework, we aim to benefit patients, clinicians, and researchers by enhancing fairness and accuracy in healthcare AI systems."
    },
    {
      "openalex_id": "https://openalex.org/W4393372034",
      "doi": "10.1109/access.2024.3383841",
      "title": "Fairness Meets Cross-Domain Learning: A Benchmark of Models and Metrics",
      "abstract": "Deep learning-based recognition systems are deployed at scale for real-world applications that inevitably involve our social life. Although of great support when making complex decisions, they might capture spurious data correlations and leverage sensitive attributes (e.g., age, gender, ethnicity). How to factor out this information while maintaining high performance is a problem with several open questions, many of which are shared with those of the domain adaptation and generalization literature which aims at avoiding visual domain biases. In this work, we propose an in-depth study of the relationship between cross-domain learning (CD) and model fairness, by experimentally evaluating 14 CD approaches together with 3 state-of-the-art fairness algorithms on 5 datasets of faces and medical images spanning several demographic groups. We consider attribute classification and landmark detection tasks: the latter is introduced here for the first time in the fairness literature, showing how keypoint localization may be affected by sensitive attribute biases. To assess the analyzed methods, we adopt widely used evaluation metrics while also presenting their limits with a detailed review. Moreover, we propose a new Harmonic Fairness (HF) score that can ease unfairness mitigation model comparisons. Overall, our work shows how CD approaches can outperform state-of-the-art fairness algorithms and defines a framework with dataset and metrics as well as a code suite to pave the way for a more systematic analysis of fairness problems in computer vision (Code available at: <uri>https://github.com/iurada/fairness_crossdomain</uri>).",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Leonardo Iurada et al.",
      "keywords": "Computer science; Leverage (statistics); Machine learning; Artificial intelligence; Benchmark (surveying); Spurious relationship; Domain (mathematical analysis); Domain adaptation; Code (set theory); Landmark; Suite; Source lines of code; Software; Classifier (UML)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3383841",
      "cited_by_count": 1,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "Deep Learning; Computer Vision/Imaging AI",
      "health_domain": "General Healthcare",
      "bias_axes": "Race/Ethnicity; Gender/Sex; Age",
      "lifecycle_stage": "Model Evaluation; Deployment",
      "assessment_or_mitigation": "Both",
      "approach_method": "Transfer Learning",
      "clinical_setting": "Not specified",
      "key_findings": "Moreover, we propose a new Harmonic Fairness (HF) score that can ease unfairness mitigation model comparisons. Overall, our work shows how CD approaches can outperform state-of-the-art fairness algorithms and defines a framework with dataset and metrics as well as a code suite to pave the way for a more systematic analysis of fairness problems in computer vision (Code available at: <uri>https://github.com/iurada/fairness_crossdomain</uri>)."
    },
    {
      "openalex_id": "https://openalex.org/W4390692459",
      "doi": "10.1109/jbhi.2024.3352513",
      "title": "Identifying Biases in a Multicenter MRI Database for Parkinson's Disease Classification: Is the Disease Classifier a Secret Site Classifier?",
      "abstract": "Sharing multicenter imaging datasets can be advantageous to increase data diversity and size but may lead to spurious correlations between site-related biological and non-biological image features and target labels, which machine learning (ML) models may exploit as shortcuts. To date, studies analyzing how and if deep learning models may use such effects as a shortcut are scarce. Thus, the aim of this work was to investigate if site-related effects are encoded in the feature space of an established deep learning model designed for Parkinson's disease (PD) classification based on T1-weighted MRI datasets. Therefore, all layers of the PD classifier were frozen, except for the last layer of the network, which was replaced by a linear layer that was exclusively re-trained to predict three potential bias types (biological sex, scanner type, and originating site). Our findings based on a large database consisting of 1880 MRI scans collected across 41 centers show that the feature space of the established PD model (74% accuracy) can be used to classify sex (75% accuracy), scanner type (79% accuracy), and site location (71% accuracy) with high accuracies despite this information never being explicitly provided to the PD model during original training. Overall, the results of this study suggest that trained image-based classifiers may use unwanted shortcuts that are not meaningful for the actual clinical task at hand. This finding may explain why many image-based deep learning models do not perform well when applied to data from centers not contributing to the training set.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Raissa Souza et al.",
      "keywords": "Artificial intelligence; Computer science; Classifier (UML); Pattern recognition (psychology); Machine learning; Deep learning; Spurious relationship; Contextual image classification; Feature vector; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3352513",
      "cited_by_count": 20,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Empirical Study",
      "ai_ml_method": "Deep Learning",
      "health_domain": "Radiology/Medical Imaging",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Diverse/Representative Data",
      "clinical_setting": "Not specified",
      "key_findings": "Overall, the results of this study suggest that trained image-based classifiers may use unwanted shortcuts that are not meaningful for the actual clinical task at hand. This finding may explain why many image-based deep learning models do not perform well when applied to data from centers not contributing to the training set."
    },
    {
      "openalex_id": "https://openalex.org/W4390738750",
      "doi": "10.1109/access.2024.3353056",
      "title": "Reducing Bias in Sentiment Analysis Models Through Causal Mediation Analysis and Targeted Counterfactual Training",
      "abstract": "Large language models provide high-accuracy solutions in many natural language processing tasks. In particular, they are used as word embeddings in sentiment analysis models. However, these models pick up on and amplify biases and social stereotypes in the data. Causality theory has recently driven the development of effective algorithms to evaluate and mitigate these biases. Causal mediation was used to detect biases, while counterfactual training was proposed to mitigate bias. In both cases, counterfactual sentences are created by changing an attribute, such as the gender of a noun, for which no change in the model output is expected. Biases are detected and eventually corrected each time the model behavior differs between the original and the counterfactual sentence. We propose a new method for de-biasing sentiment analysis models that leverages the causal mediation analysis to identify the parts of the model primarily responsible for the bias and apply targeted counterfactual training for model de-biasing. We validated the methodology by fine-tuning the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model for sentiment prediction. We trained two sentiment analysis models using the Stanford Sentiment Treebank dataset and the Amazon Product Reviews, respectively, and we evaluated the fairness and prediction performances using the Equity Evaluation Corpus. We illustrated the causal patterns in the network and showed that our method achieves both high fairness and more accurate sentiment analysis than the state-of-the-art approach. Contrary to state-of-the-art models, we achieved a noticeable improvement in gender fairness without hindering sentiment prediction accuracy.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Yifei Da et al.",
      "keywords": "Counterfactual thinking; Computer science; Sentiment analysis; Artificial intelligence; Sentence; Natural language processing; Machine learning; Causal inference; Treebank; Econometrics; Psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3353056",
      "cited_by_count": 9,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Methodology",
      "ai_ml_method": "NLP/LLM",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age; Language",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Counterfactual Fairness; Representation Learning; Transfer Learning",
      "clinical_setting": "ICU",
      "key_findings": "We illustrated the causal patterns in the network and showed that our method achieves both high fairness and more accurate sentiment analysis than the state-of-the-art approach. Contrary to state-of-the-art models, we achieved a noticeable improvement in gender fairness without hindering sentiment prediction accuracy."
    },
    {
      "openalex_id": "https://openalex.org/W4391528444",
      "doi": "10.1109/jbhi.2023.3348249",
      "title": "Guest Editorial Achieving Health Equity Through AI for Diagnosis and Treatment and Patient Monitoring",
      "abstract": "Health equity is a fundamental principle that aims to ensure that all individuals, regardless of their background or circumstances, have equal access to quality healthcare. Unfortunately, significant health disparities persist globally, with marginalized and disadvantaged groups often being at a disadvantage in terms of access to diagnostics and treatments. Artificial intelligence (AI) is emerging as a powerful tool to combat these inequalities and improve health equity.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Habib Hamam",
      "keywords": "Disadvantaged; Equity (law); Disadvantage; Health equity; Health care; Inequality; Computer science; Public relations; Medicine; Business; Economic growth; Political science; Artificial intelligence; Economics",
      "mesh_terms": "",
      "pub_types": "editorial",
      "url": "https://doi.org/10.1109/jbhi.2023.3348249",
      "cited_by_count": 2,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Commentary/Editorial",
      "ai_ml_method": "Not specified",
      "health_domain": "General Healthcare",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Deployment",
      "assessment_or_mitigation": "Not specified",
      "approach_method": "Not specified",
      "clinical_setting": "Not specified",
      "key_findings": "Unfortunately, significant health disparities persist globally, with marginalized and disadvantaged groups often being at a disadvantage in terms of access to diagnostics and treatments. Artificial intelligence (AI) is emerging as a powerful tool to combat these inequalities and improve health equity."
    },
    {
      "openalex_id": "https://openalex.org/W4313554955",
      "doi": "10.1109/tmi.2023.3234450",
      "title": "Proportionally Fair Hospital Collaborations in Federated Learning of Histopathology Images",
      "abstract": "Medical centers and healthcare providers have concerns and hence restrictions around sharing data with external collaborators. Federated learning, as a privacy-preserving method, involves learning a site-independent model without having direct access to patient-sensitive data in a distributed collaborative fashion. The federated approach relies on decentralized data distribution from various hospitals and clinics. The collaboratively learned global model is supposed to have acceptable performance for the individual sites. However, existing methods focus on minimizing the average of the aggregated loss functions, leading to a biased model that performs perfectly for some hospitals while exhibiting undesirable performance for other sites. In this paper, we improve model \"fairness\" among participating hospitals by proposing a novel federated learning scheme called Proportionally Fair Federated Learning, short Prop-FFL. Prop-FFL is based on a novel optimization objective function to decrease the performance variations among participating hospitals. This function encourages a fair model, providing us with more uniform performance across participating hospitals. We validate the proposed Prop-FFL on two histopathology datasets as well as two general datasets to shed light on its inherent capabilities. The experimental results suggest promising performance in terms of learning speed, accuracy, and fairness.",
      "year": "2023",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "S. Maryam Hosseini et al.",
      "keywords": "Federated learning; Computer science; Artificial intelligence; Function (biology); Scheme (mathematics); Machine learning; Data sharing; Health care; Data modeling; Database; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2023.3234450",
      "cited_by_count": 47,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Empirical Study",
      "ai_ml_method": "Federated Learning",
      "health_domain": "Pathology",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Not specified",
      "approach_method": "Federated Learning",
      "clinical_setting": "Hospital/Inpatient; Laboratory/Pathology",
      "key_findings": "We validate the proposed Prop-FFL on two histopathology datasets as well as two general datasets to shed light on its inherent capabilities. The experimental results suggest promising performance in terms of learning speed, accuracy, and fairness."
    },
    {
      "openalex_id": "https://openalex.org/W4379985152",
      "doi": "10.1109/access.2023.3284458",
      "title": "Blood Pressure Estimation From Photoplethysmography by Considering Intra- and Inter-Subject Variabilities: Guidelines for a Fair Assessment",
      "abstract": "Cardiovascular diseases are the leading causes of death, and blood pressure (BP) monitoring is essential for prevention, diagnosis, assessment, and treatment. Photoplethysmography (PPG) is a low-cost opto-electronic technique for BP measurement that allows the acquisition of a modulated light signal highly correlated with BP. There are several reports of methods to estimate BP from PPG with impressive results; in this study, we demonstrate that the previous results are excessively optimistic because of their train/test split configuration. To manage this limitation, we considered intra- and inter-subject data arrangements and demonstrated how they affect the results of feature-based BP estimation algorithms (i.e., XGBoost, LightGBM, and CatBoost) and signal-based algorithms (i.e., Residual U-Net, ResNet-18, and ResNet-LSTM). Inter-subject configuration performance is inferior to intra-subject configuration performance, regardless of the model. We also showed that, using only demographic attributes (i.e., age, sex, weight, and subject index number), a regression model achieved results comparable to those obtained in an intra-subject scenario.Although limited to a public clinical database, our findings suggest that algorithms that use an intra-subject setting without a calibration strategy may be learning to identify patients and not predict BP.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Thiago Bulh\u00f5es da Silva Costa et al.",
      "keywords": "Photoplethysmogram; Computer science; Residual; Artificial intelligence; Calibration; Feature (linguistics); SIGNAL (programming language); Subject (documents); Machine learning; Blood pressure; Regression; Data mining; Pattern recognition (psychology); Statistics; Medicine; Algorithm; Mathematics; Internal medicine; Telecommunications; Wireless",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3284458",
      "cited_by_count": 12,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Guideline/Policy",
      "ai_ml_method": "Deep Learning; XGBoost/Gradient Boosting; Regression",
      "health_domain": "Cardiology",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Model Development/Training; Deployment",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Calibration",
      "clinical_setting": "Not specified",
      "key_findings": "Inter-subject configuration performance is inferior to intra-subject configuration performance, regardless of the model. We also showed that, using only demographic attributes (i.e., age, sex, weight, and subject index number), a regression model achieved results comparable to those obtained in an intra-subject scenario.Although limited to a public clinical database, our findings suggest that algorithms that use an intra-subject setting without a calibration strategy may be learning to identify ..."
    },
    {
      "openalex_id": "https://openalex.org/W4382138564",
      "doi": "10.1109/access.2023.3289320",
      "title": "Assessing Bias in Skin Lesion Classifiers With Contemporary Deep Learning and Post-Hoc Explainability Techniques",
      "abstract": "As Artificial Intelligence (AI) is increasingly utilized in dermatology, ensuring fairness in the development of Machine Learning models is crucial, particularly in skin lesion classification, where decisions can significantly impact people&#x2019;s lives. This study investigates the presence of biases between different Fitzpatrick Skin Types in baseline pretrained models and evaluates various training techniques to mitigate these disparities. An unsupervised skin transformer is developed to adjust an image&#x2019;s Fitzpatrick Skin Type (FST), and joint regularization and synthetic image blending methods are employed to address bias concerns. Additionally, eXplainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), are utilized to identify any underlying reasons for bias in the models. The results indicate that joint regularization and synthetic blending methods enhance the area under the curve performance and fairness. Meanwhile, XAI was found to be a valuable tool for fine-tuning Deep Learning models and uncovering problems. These findings can aid in developing accurate and unbiased skin lesion classification models, promoting equitable healthcare, and improving patient outcomes.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Adam Corbin et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Skin lesion; Regularization (linguistics); Deep learning; Pattern recognition (psychology); Medicine; Dermatology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3289320",
      "cited_by_count": 11,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Empirical Study",
      "ai_ml_method": "Deep Learning; NLP/LLM; Clustering",
      "health_domain": "Dermatology; ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Model Development/Training",
      "assessment_or_mitigation": "Both",
      "approach_method": "Transfer Learning; Explainability/Interpretability; Regularization",
      "clinical_setting": "ICU",
      "key_findings": "Meanwhile, XAI was found to be a valuable tool for fine-tuning Deep Learning models and uncovering problems. These findings can aid in developing accurate and unbiased skin lesion classification models, promoting equitable healthcare, and improving patient outcomes."
    },
    {
      "openalex_id": "https://openalex.org/W4360597056",
      "doi": "10.1109/access.2023.3260639",
      "title": "Integrating Fairness in the Software Design Process: An Interview Study With HCI and ML Experts",
      "abstract": "The term Fairness is used in the field of Machine Learning to refer to a suite of evaluation techniques, measures, and process adjustments focused on the reduction of bias in statistical models. With many different potential definitions and methodologies for implementing fairness, some contradictory in goal or incompatible in approach, there are challenges in the selection of the most appropriate definition(s) to meet the ethical expectations society or end users may have for a model. This is further confounded by the potentially complex engineering challenges in applying the selected definition. The goal of designing and developing a fair system requires interdisciplinary collaboration between user experience researchers, focused on the socio-technical challenges of application usage and adoption, and data scientists and machine learning software developers, directly involved in the technical engineering and optimisation of such models. How these two groups interact and how their areas of specialisation can support and influence the other when developing fair AI is unknown. This leaves open questions about how these stakeholders view fairness, how it can be operationalised in their current work, and what are the obstacles/opportunities for improving the treatment of fairness in practice. In order to answer these questions, 18 subject matter experts from the fields of human-computer interaction (HCI) or Machine Learning (ML) were interviewed about their experience with fairness, their perception of current fairness adoption, and the challenges they would anticipate in a set of example scenarios. This work identifies some of the current challenges to developing fair artificial intelligence (AI). In dealing with these challenges, we propose approaches that include expanding the responsibilities of HCI and ML specialists, and identifying areas where joint responsibility is required.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Seamus Ryan et al.",
      "keywords": "Computer science; Process (computing); Field (mathematics); Suite; Set (abstract data type); Perception; Work (physics); Artificial intelligence; Subject-matter expert; Knowledge management; Management science; Expert system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3260639",
      "cited_by_count": 12,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "Not specified",
      "health_domain": "General Healthcare",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "Not specified",
      "key_findings": "This work identifies some of the current challenges to developing fair artificial intelligence (AI). In dealing with these challenges, we propose approaches that include expanding the responsibilities of HCI and ML specialists, and identifying areas where joint responsibility is required."
    },
    {
      "openalex_id": "https://openalex.org/W4385324819",
      "doi": "10.1109/tgrs.2023.3299234",
      "title": "Performance Comparison of Bias-Corrected Satellite Precipitation Products by Various Deep Learning Schemes",
      "abstract": "Precipitation observations from a ground-based gauge provide a reliable data source for hydrological and climatological studies. However, these data are sparse in many regions of the world, particularly the Mekong River Basin (MRB). Satellite-based precipitation products (SPPs) are the sole data source available with worldwide coverage. Despite this, there is a mismatch between SPPs and gauge-based observations, and the correct procedures should be utilized to minimize systematic bias in SPPs. This study aimed to benchmark the efficacy of four state-of-the-art bias-correcting deep learning models (DLMs) for the tropical rainfall measuring mission-based precipitation product named TRMM_3B42 (hereafter TRMM) over the entire MRB. These models were designed mainly based on convolutional neural network (CNN) and encoder\u2013decoder (ENDE) architectures, including ConvENDE, ConvUNET, ConvINCE, and ConvLSTM. The bias-corrected dataset by DLMs was then confirmed against the gauge-based dataset (Asian precipitation-highly resolved observational data integration toward evaluation of water resources, APHRODITE). From the results obtained, all four DLMs effectively minimized the bias of the TRMM product. Among them, ConvENDE and ConvUNET had a higher consistency and performance level compared to ConvINCE and ConvLSTM. Additionally, the complexity of DLMs did not enhance their efficiency, as is the case with ConvINCE and ConvLSTM, despite using many computing resources. Given the observed data shortage for the MRB since 2016, the application of DLMs, such as ConvENDE and ConvUNET, can serve to improve the reliability of existing rainfall datasets and provide valuable input for various research purposes in the MRB.",
      "year": "2023",
      "journal": "IEEE Transactions on Geoscience and Remote Sensing",
      "authors": "Xuan-Hien Le et al.",
      "keywords": "Computer science; Benchmark (surveying); Precipitation; Rain gauge; Deep learning; Satellite; Environmental science; Convolutional neural network; Global Precipitation Measurement; Data mining; Artificial intelligence; Meteorology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tgrs.2023.3299234",
      "cited_by_count": 11,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Empirical Study",
      "ai_ml_method": "Deep Learning; Neural Network",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Age; Geographic",
      "lifecycle_stage": "Data Collection; Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "ICU",
      "key_findings": "Additionally, the complexity of DLMs did not enhance their efficiency, as is the case with ConvINCE and ConvLSTM, despite using many computing resources. Given the observed data shortage for the MRB since 2016, the application of DLMs, such as ConvENDE and ConvUNET, can serve to improve the reliability of existing rainfall datasets and provide valuable input for various research purposes in the MRB."
    },
    {
      "openalex_id": "https://openalex.org/W4319781656",
      "doi": "10.1109/ojemb.2023.3243190",
      "title": "Computational Simulation of Virtual Patients Reduces Dataset Bias and Improves Machine Learning-Based Detection of ARDS from Noisy Heterogeneous ICU Datasets",
      "abstract": "<i>Goal:</i> Machine learning (ML) technologies that leverage large-scale patient data are promising tools predicting disease evolution in individual patients. However, the limited generalizability of ML models developed on single-center datasets, and their unproven performance in real-world settings, remain significant constraints to their widespread adoption in clinical practice. One approach to tackle this issue is to base learning on large multi-center datasets. However, such heterogeneous datasets can introduce further biases driven by data origin, as data structures and patient cohorts may differ between hospitals. <i>Methods:</i> In this paper, we demonstrate how mechanistic virtual patient (VP) modeling can be used to capture specific features of patients' states and dynamics, while reducing biases introduced by heterogeneous datasets. We show how VP modeling can be used for data augmentation through identification of individualized model parameters approximating disease states of patients with suspected acute respiratory distress syndrome (ARDS) from observational data of mixed origin. We compare the results of an unsupervised learning method (clustering) in two cases: where the learning is based on original patient data and on data derived in the matching procedure of the VP model to real patient data. <i>Results:</i> More robust cluster configurations were observed in clustering using the model-derived data. VP model-based clustering also reduced biases introduced by the inclusion of data from different hospitals and was able to discover an additional cluster with significant ARDS enrichment. <i>Conclusions:</i> Our results indicate that mechanistic VP modeling can be used to significantly reduce biases introduced by learning from heterogeneous datasets and to allow improved discovery of patient cohorts driven exclusively by medical conditions.",
      "year": "2023",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Konstantin Sharafutdinov et al.",
      "keywords": "Generalizability theory; Leverage (statistics); Computer science; Machine learning; Artificial intelligence; Data center; Scale (ratio); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2023.3243190",
      "cited_by_count": 9,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Empirical Study",
      "ai_ml_method": "Clustering",
      "health_domain": "ICU/Critical Care; Pulmonology",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Data Preprocessing; Deployment",
      "assessment_or_mitigation": "Both",
      "approach_method": "Data Augmentation",
      "clinical_setting": "Hospital/Inpatient; ICU",
      "key_findings": "Conclusions:</i> Our results indicate that mechanistic VP modeling can be used to significantly reduce biases introduced by learning from heterogeneous datasets and to allow improved discovery of patient cohorts driven exclusively by medical conditions."
    },
    {
      "openalex_id": "https://openalex.org/W4387623816",
      "doi": "10.1109/tkde.2023.3321738",
      "title": "PATNet: Propensity-Adjusted Temporal Network for Joint Imputation and Prediction Using Binary EHRs With Observation Bias",
      "abstract": "Predictive analysis of electronic health records (EHR) is a fundamental task that could provide actionable insights to help clinicians improve the efficiency and quality of care. EHR are commonly recorded in binary format and contain inevitable missing data. The nature of missingness may vary by patients, clinical features, and time, which incurs observation bias. It is essential to account for the binary missingness and observation bias or the predictive performance could be substantially compromised. In this paper, we develop a propensity-adjusted temporal network (PATNet) to conduct data imputation and predictive analysis simultaneously. PATNet contains three subnetworks: 1) an imputation subnetwork that generates the initial imputation based on historical observations, 2) a propensity subnetwork that infers the patient-, feature-, and time-dependent propensity scores, and 3) a prediction subnetwork that produces the missing-informative prediction using the propensity-adjusted imputations and the missing probabilities. To allow the propensity scores to be inferred from data, we use the expectation-maximization (EM) algorithm to learn the imputation and propensity subnetworks and incorporate a low-rank constraint via PARAFAC2 approximation. Extensive evaluation using the MIMIC-III and eICU datasets demonstrates that PATNet outperforms the state-of-the-art methods in terms of binary data imputation, disease progression modeling, and mortality prediction tasks.",
      "year": "2023",
      "journal": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "Kejing Yin et al.",
      "keywords": "Imputation (statistics); Missing data; Computer science; Subnetwork; Propensity score matching; Data mining; Artificial intelligence; Statistics; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tkde.2023.3321738",
      "cited_by_count": 9,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Methodology",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care; EHR/Health Informatics",
      "bias_axes": "Gender/Sex",
      "lifecycle_stage": "Data Preprocessing; Model Evaluation",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Not specified",
      "clinical_setting": "ICU",
      "key_findings": "To allow the propensity scores to be inferred from data, we use the expectation-maximization (EM) algorithm to learn the imputation and propensity subnetworks and incorporate a low-rank constraint via PARAFAC2 approximation. Extensive evaluation using the MIMIC-III and eICU datasets demonstrates that PATNet outperforms the state-of-the-art methods in terms of binary data imputation, disease progression modeling, and mortality prediction tasks."
    },
    {
      "openalex_id": "https://openalex.org/W4312726348",
      "doi": "10.1109/access.2022.3232561",
      "title": "UNet Deep Learning Architecture for Segmentation of Vascular and Non-Vascular Images: A Microscopic Look at UNet Components Buffered With Pruning, Explainable Artificial Intelligence, and Bias",
      "abstract": "Biomedical image segmentation (BIS) task is challenging due to the variations in organ types, position, shape, size, scale, orientation, and image contrast. Conventional methods lack accurate and automated designs. Artificial intelligence (AI)-based UNet has recently dominated BIS. This is the first review of its kind that microscopically addressed UNet types by complexity, stratification of UNet by its components, addressing UNet in vascular vs. non-vascular framework, the key to segmentation challenge vs. UNet-based architecture, and finally interfacing the three facets of AI, the pruning, the explainable AI (XAI), and the AI-bias. PRISMA was used to select 267 UNet-based studies. Five classes were identified and labeled as conventional UNet, superior UNet, attention-channel UNet, hybrid UNet, and ensemble UNet. We discovered 81 variations of UNet by considering six kinds of components, namely encoder, decoder, skip connection, bridge network, loss function, and their combination. Vascular vs. non-vascular UNet architecture was compared. AP(ai)Bias 2.0-UNet was identified in these UNet classes based on (i) attributes of UNet architecture and its performance, (ii) explainable AI (XAI), and, (iii) pruning (compression). Five bias methods such as (i) ranking, (ii) radial, (iii) regional area, (iv) PROBAST, and (v) ROBINS-I were applied and compared using a Venn diagram. Vascular and non-vascular UNet systems dominated with sUNet classes with attention. Most of the studies suffered from a low interest in XAI and pruning strategies. None of the UNet models qualified to be bias-free. There is a need to move from paper-to-practice paradigms for clinical evaluation and settings.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Jasjit S. Suri et al.",
      "keywords": "Computer science; Pruning; Segmentation; Artificial intelligence; Ranking (information retrieval); Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3232561",
      "cited_by_count": 73,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Systematic Review",
      "ai_ml_method": "Deep Learning; Ensemble Methods; Computer Vision/Imaging AI; Generative AI",
      "health_domain": "General Healthcare",
      "bias_axes": "Gender/Sex; Age; Geographic",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Both",
      "approach_method": "Explainability/Interpretability; Ensemble Methods",
      "clinical_setting": "Not specified",
      "key_findings": "None of the UNet models qualified to be bias-free. There is a need to move from paper-to-practice paradigms for clinical evaluation and settings."
    },
    {
      "openalex_id": "https://openalex.org/W4312449667",
      "doi": "10.1109/access.2022.3218715",
      "title": "An Adversarial Perspective on Accuracy, Robustness, Fairness, and Privacy: Multilateral-Tradeoffs in Trustworthy ML",
      "abstract": "Model accuracy is the traditional metric employed in machine learning (ML) applications. However, privacy, fairness, and robustness guarantees are crucial as ML algorithms increasingly pervade our lives and play central roles in socially important systems. These four desiderata constitute the pillars of Trustworthy ML (TML) and may mutually inhibit or reinforce each other. It is necessary to understand and clearly delineate the trade-offs among these desiderata in the presence of adversarial attacks. However, threat models for the desiderata are different and the defenses introduced for each leads to further trade-offs in a multilateral adversarial setting (i.e., a setting attacking several pillars simultaneously). The first half of the paper reviews the state of the art in TML research, articulates known multilateral trade-offs, and identifies open problems and challenges in the presence of an adversary that may take advantage of such multilateral trade-offs. The fundamental shortcomings of statistical association-based TML are discussed, to motivate the use of causal methods to achieve TML. The second half of the paper, in turn, advocates the use of causal modeling in TML. Evidence is collected from across the literature that causal ML is well-suited to provide a unified approach to TML. Causal discovery and causal representation learning are introduced as essential stages of causal modeling, and a new threat model for causal ML is introduced to quantify the vulnerabilities introduced through the use of causal methods. The paper concludes with pointers to possible next steps in the development of a causal TML pipeline.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Alex Gittens et al.",
      "keywords": "Adversarial system; Computer science; Robustness (evolution); Trustworthiness; Adversary; Metric (unit); Perspective (graphical); Artificial intelligence; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3218715",
      "cited_by_count": 9,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Commentary/Editorial",
      "ai_ml_method": "Not specified",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Representation Learning",
      "clinical_setting": "ICU",
      "key_findings": "Causal discovery and causal representation learning are introduced as essential stages of causal modeling, and a new threat model for causal ML is introduced to quantify the vulnerabilities introduced through the use of causal methods. The paper concludes with pointers to possible next steps in the development of a causal TML pipeline."
    },
    {
      "openalex_id": "https://openalex.org/W4311897690",
      "doi": "10.1109/tts.2022.3211073",
      "title": "Individuality and Fairness in Public Health Surveillance Technology: A Survey of User Perceptions in Contact Tracing Apps",
      "abstract": "Machine learning algorithms are playing an increasingly important role in public health measures, accelerated by the Covid-19 pandemic. It is therefore vital that machine learning algorithms are applied in ways that are generally considered fair. However, the question of how to define fairness in a public health context is still an open one. In this study, we investigated people\u2019s attitudes towards two ways of defining fairness in the context of Covid-19 contact tracing apps. In the first, \u2018high-individuality\u2019 approach, the likelihood of an algorithm asking a person to self-isolate would depend on the person\u2019s individual characteristics, such as their risk of spreading the virus through regular contacts. In the second \u2018low individuality\u2019 approach, these individual characteristics would not be used to come to a decision. For each approach, participants rated its fairness, overall quality, and their privacy concerns, and answered questions about basic psychological need satisfaction. Participants rated the high-individuality approach as fairer and better overall compared to the low-individuality approach, despite having greater privacy concerns. Further, we found a strong correlation between the participants\u2019 fairness perceptions and their overall impression of the tracking tool. Together, these findings suggest that people prefer individualised approaches in some contexts and perceive them as fairer. However, policy makers should consider the privacy trade-off of employing such measures.",
      "year": "2022",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Ellen Hohma et al.",
      "keywords": "Perception; Context (archaeology); Internet privacy; Psychology; Social psychology; Contact tracing; Quality (philosophy); Public health; Coronavirus disease 2019 (COVID-19); Computer science; Applied psychology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2022.3211073",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Survey/Qualitative",
      "ai_ml_method": "Not specified",
      "health_domain": "Pulmonology; Public Health",
      "bias_axes": "Not specified",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Not specified",
      "clinical_setting": "Public Health/Population",
      "key_findings": "Together, these findings suggest that people prefer individualised approaches in some contexts and perceive them as fairer. However, policy makers should consider the privacy trade-off of employing such measures."
    },
    {
      "openalex_id": "https://openalex.org/W4285176431",
      "doi": "10.1109/tim.2022.3174270",
      "title": "Five Strategies for Bias Estimation in Artificial Intelligence-based Hybrid Deep Learning for Acute Respiratory Distress Syndrome COVID-19 Lung Infected Patients using AP(ai)Bias 2.0: A Systematic Review",
      "abstract": "Coronavirus 2019 (COVID-19) has led to a global pandemic infecting 224 million people and has caused 4.6 million deaths. Nearly 80 Artificial Intelligence (AI) articles have been published on COVID-19 diagnosis. The first systematic review on the Deep Learning (DL)-based paradigm for COVID-19 diagnosis was recently published by Suri et al. [IEEE J Biomed Health Inform. 2021]. The above study used AtheroPoint\u2019s \u201cAP(ai)Bias 1.0\u201d using 10 AI attributes in the DL framework. The proposed study uses \u201cAP(ai)Bias 2.0\u201d as part of the three quantitative paradigms for Risk-of-Bias quantification by using the best 40 dedicated Hybrid DL (HDL) studies and utilizing 39 AI attributes. In the first method, the radial-bias map (RBM) was computed for each AI study, followed by the computation of bias value. In the second method, the regional-bias area (RBA) was computed by the area difference between the best and the worst AI performing attributes. In the third method, ranking-bias score (RBS) was computed, where AI-based cumulative scores were computed for all the 40 studies. These studies were ranked, and the cutoff was determined, categorizing the HDL studies into three bins: low, moderate, and high. Using the Venn diagram, these three quantitative methods were benchmarked against the two qualitative non-randomized-based AI trial methods (ROBINS-I and PROBAST). Using the analytically derived moderate-high and low-moderate cutoff of 2.9 and 3.6, respectively, we observed 40%, 27.5%, 17.5%, 10%, and 20% of studies were low-biased for RBM, RBA, RBS, ROBINS-I, and PROBAST, respectively. We present an eight-point recommendation for AP(ai)Bias 2.0 minimization.",
      "year": "2022",
      "journal": "IEEE Transactions on Instrumentation and Measurement",
      "authors": "Jasjit S. Suri et al.",
      "keywords": "Artificial intelligence; Machine learning; Cutoff; Coronavirus disease 2019 (COVID-19); Deep learning; Receiver operating characteristic; Statistics; Computer science; Medicine; Mathematics; Internal medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tim.2022.3174270",
      "cited_by_count": 37,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Systematic Review",
      "ai_ml_method": "Deep Learning",
      "health_domain": "Pulmonology",
      "bias_axes": "Gender/Sex; Geographic",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Threshold Adjustment",
      "clinical_setting": "Not specified",
      "key_findings": "Using the analytically derived moderate-high and low-moderate cutoff of 2.9 and 3.6, respectively, we observed 40%, 27.5%, 17.5%, 10%, and 20% of studies were low-biased for RBM, RBA, RBS, ROBINS-I, and PROBAST, respectively. We present an eight-point recommendation for AP(ai)Bias 2.0 minimization."
    },
    {
      "openalex_id": "https://openalex.org/W4285506641",
      "doi": "10.1109/tcbb.2022.3191392",
      "title": "Explainable Drug Repurposing Approach From Biased Random Walks",
      "abstract": "Drug repurposing is a highly active research area, aiming at finding novel uses for drugs that have been previously developed for other therapeutic purposes. Despite the flourishing of methodologies, success is still partial, and different approaches offer, each, peculiar advantages. In this composite landscape, we present a novel methodology focusing on an efficient mathematical procedure based on gene similarity scores and biased random walks which rely on robust drug-gene-disease association data sets. The recommendation mechanism is further unveiled by means of the Markov chain underlying the random walk process, hence providing explainability about how findings are suggested. Performances evaluation and the analysis of a case study on rheumatoid arthritis show that our approach is accurate in providing useful recommendations and is computationally efficient, compared to the state of the art of drug repurposing approaches.",
      "year": "2022",
      "journal": "IEEE/ACM Transactions on Computational Biology and Bioinformatics",
      "authors": "Filippo Castiglione et al.",
      "keywords": "Drug repositioning; Computer science; Random walk; Artificial intelligence; Drug; Mathematics; Biology; Statistics; Pharmacology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcbb.2022.3191392",
      "cited_by_count": 8,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Guideline/Policy",
      "ai_ml_method": "Not specified",
      "health_domain": "Drug Discovery/Pharmacology",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Explainability/Interpretability",
      "clinical_setting": "Not specified",
      "key_findings": "The recommendation mechanism is further unveiled by means of the Markov chain underlying the random walk process, hence providing explainability about how findings are suggested. Performances evaluation and the analysis of a case study on rheumatoid arthritis show that our approach is accurate in providing useful recommendations and is computationally efficient, compared to the state of the art of drug repurposing approaches."
    },
    {
      "openalex_id": "https://openalex.org/W3138994570",
      "doi": "10.1109/mts.2021.3056282",
      "title": "From Artificial Intelligence Bias to Inequality in the Time of COVID-19",
      "abstract": "As secretary general of the United Nations, Antonio Guterres said during the 2020 Nelson Mandela Annual Lecture, \"COVID-19 has been likened to an X-ray, revealing fractures in the fragile skeleton of the societies we have built.\" Without a doubt, the COVID-19 pandemic has exposed and exacerbated existing global inequalities. Whether at the local, national, or international scale, the gap between the privileged and the vulnerable is growing wider, resulting in a broad increase in inequality across all dimensions of society. The disease has strained health systems, social support programs, and the economy as a whole, drawing an ever-widening distinction between those with access to treatment, services, and job opportunities and those without. Global lockdown restrictions have led to increases in childcare and housework responsibilities, and most of the burden has fallen on women, further increasing existing gender inequality [1], [2]. Indigenous populations worldwide find themselves more vulnerable to infection, many times with less access to health services or hygiene measures and limited updated scientific information about the virus and measures that can be taken to mitigate it [3]. Inequality has also pervaded the education sector, with only a subset of students able to attend safe in-person schooling or access online education when needed.",
      "year": "2021",
      "journal": "IEEE Technology and Society Magazine",
      "authors": "Miguel Luengo-Oroz et al.",
      "keywords": "Inequality; Social inequality; Coronavirus disease 2019 (COVID-19); Pandemic; Economic growth; Indigenous; Development economics; Political science; Demographic economics; Economics; Medicine; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mts.2021.3056282",
      "cited_by_count": 39,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Empirical Study",
      "ai_ml_method": "Not specified",
      "health_domain": "Radiology/Medical Imaging; Pediatrics; Pulmonology; Infectious Disease",
      "bias_axes": "Race/Ethnicity; Gender/Sex",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "Public Health/Population",
      "key_findings": "Indigenous populations worldwide find themselves more vulnerable to infection, many times with less access to health services or hygiene measures and limited updated scientific information about the virus and measures that can be taken to mitigate it [3]. Inequality has also pervaded the education sector, with only a subset of students able to attend safe in-person schooling or access online education when needed."
    },
    {
      "openalex_id": "https://openalex.org/W3206242500",
      "doi": "10.1109/jbhi.2021.3119325",
      "title": "Mix-and-Interpolate: A Training Strategy to Deal With Source-Biased Medical Data",
      "abstract": "Till March 31st, 2021, the coronavirus disease 2019 (COVID-19) had reportedly infected more than 127 million people and caused over 2.5 million deaths worldwide. Timely diagnosis of COVID-19 is crucial for management of individual patients as well as containment of the highly contagious disease. Having realized the clinical value of non-contrast chest computed tomography (CT) for diagnosis of COVID-19, deep learning (DL) based automated methods have been proposed to aid the radiologists in reading the huge quantities of CT exams as a result of the pandemic. In this work, we address an overlooked problem for training deep convolutional neural networks for COVID-19 classification using real-world multi-source data, namely, the data source bias problem. The data source bias problem refers to the situation in which certain sources of data comprise only a single class of data, and training with such source-biased data may make the DL models learn to distinguish data sources instead of COVID-19. To overcome this problem, we propose MIx-aNd-Interpolate (MINI), a conceptually simple, easy-to-implement, efficient yet effective training strategy. The proposed MINI approach generates volumes of the absent class by combining the samples collected from different hospitals, which enlarges the sample space of the original source-biased dataset. Experimental results on a large collection of real patient data (1,221 COVID-19 and 1,520 negative CT images, and the latter consisting of 786 community acquired pneumonia and 734 non-pneumonia) from eight hospitals and health institutions show that: 1) MINI can improve COVID-19 classification performance upon the baseline (which does not deal with the source bias), and 2) MINI is superior to competing methods in terms of the extent of improvement.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Yuexiang Li et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Coronavirus disease 2019 (COVID-19); Class (philosophy); Sample (material); Machine learning; Data mining; Medicine; Disease; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3119325",
      "cited_by_count": 3,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Methodology",
      "ai_ml_method": "Deep Learning; Neural Network",
      "health_domain": "Pathology; Pulmonology",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Data Collection; Deployment",
      "assessment_or_mitigation": "Mitigation",
      "approach_method": "Not specified",
      "clinical_setting": "Hospital/Inpatient; Public Health/Population",
      "key_findings": "The proposed MINI approach generates volumes of the absent class by combining the samples collected from different hospitals, which enlarges the sample space of the original source-biased dataset. Experimental results on a large collection of real patient data (1,221 COVID-19 and 1,520 negative CT images, and the latter consisting of 786 community acquired pneumonia and 734 non-pneumonia) from eight hospitals and health institutions show that: 1) MINI can improve COVID-19 classification performa..."
    },
    {
      "openalex_id": "https://openalex.org/W3004599123",
      "doi": "10.1109/access.2020.2971656",
      "title": "HybridEEGNet: A Convolutional Neural Network for EEG Feature Learning and Depression Discrimination",
      "abstract": "Electroencephalogram (EEG) measurement, being an appropriate approach to understanding the underlying mechanisms of the major depressive disorder (MDD), is used to discriminate between depressive and normal control. With the advancement of deep learning methods, many studies have designed deep learning models to improve the classification accuracy of depression discrimination. However, few of them have focused on designing a convolutional filter to learn features according to EEG activity characteristics. In this study, a novel convolutional neural network named HybridEEGNet that is composed of two parallel lines is proposed to learn the synchronous and regional EEG features, and further differentiate normal controls from medicated and unmedicated MDD patients. A ten-fold cross validation method is used to train and test the model. The results show that HybridEEGNet achieves a sensitivity of 68.78%, a specificity of 84.45%, and an accuracy of 79.08% in three-category classification. The result of EEG feature analysis indicates that the differences of spatial distributions and amplitude ranges in the alpha rhythm (especially at approximately 10 Hz) among three categories might be distinctive attributes for depression discrimination.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Zhijiang Wan et al.",
      "keywords": "Electroencephalography; Convolutional neural network; Artificial intelligence; Pattern recognition (psychology); Computer science; Feature (linguistics); Deep learning; Speech recognition; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2971656",
      "cited_by_count": 65,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Empirical Study",
      "ai_ml_method": "Deep Learning; Neural Network",
      "health_domain": "Mental Health/Psychiatry",
      "bias_axes": "Gender/Sex; Geographic",
      "lifecycle_stage": "Model Evaluation",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Not specified",
      "clinical_setting": "Not specified",
      "key_findings": "The results show that HybridEEGNet achieves a sensitivity of 68.78%, a specificity of 84.45%, and an accuracy of 79.08% in three-category classification. The result of EEG feature analysis indicates that the differences of spatial distributions and amplitude ranges in the alpha rhythm (especially at approximately 10 Hz) among three categories might be distinctive attributes for depression discrimination."
    },
    {
      "openalex_id": "https://openalex.org/W3097496686",
      "doi": "10.1109/access.2020.3035714",
      "title": "Towards Fairness-Aware Disaster Informatics: an Interdisciplinary Perspective",
      "abstract": "Collection of information from crowdsourced and traditional sensing techniques during a disaster offers opportunities to exploit this new data source to enhance situational awareness, relief, and rescue coordination, and impact assessment. The evolution of disaster/crisis informatics affords the capability to process multi-modal data and to implement analytics in support of disaster management tasks. Little is known, however, about fairness in disaster informatics and the extent to which this issue affects disaster response. Often ignored is whether existing data analytics approaches reflect the impact of communities with equality, especially the underserved communities (i.e., minorities, the elderly, and the poor). We argue that disaster informatics has not systematically identified fairness issues, and such gaps may cause issues in decision making for and coordination of disaster response and relief. Furthermore, the isolating siloed nature of the domains of fairness, machine learning, and disaster informatics prevents interchange between these pursuits. This paper bridges the knowledge gap by evaluating potential fairness issues in disaster informatics tasks based on existing disaster informatics approaches and fairness assessment criteria. Specifically, we identify potential fairness issues in disaster event detection and impact assessment tasks. We review existing approaches that address potential fairness issues by modifying the data, analytics, and outputs. Finally, this paper proposes an overarching fairness-aware disaster informatics framework to structure the workflow of mitigating fairness issues. This paper not only unveils both the ignored and essential aspects of fairness issues in disaster informatics approaches but also bridges the silos which prevent the understanding of fairness between disaster informatics researchers and machine-learning researchers.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Yang Yang et al.",
      "keywords": "Informatics; Computer science; Situation awareness; Analytics; Data science; Engineering informatics; Knowledge management; Emergency management; Health informatics; Process management; Risk analysis (engineering); Computer security; Business; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3035714",
      "cited_by_count": 20,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Commentary/Editorial",
      "ai_ml_method": "Not specified",
      "health_domain": "EHR/Health Informatics",
      "bias_axes": "Gender/Sex; Age",
      "lifecycle_stage": "Data Collection",
      "assessment_or_mitigation": "Both",
      "approach_method": "Not specified",
      "clinical_setting": "Safety-Net/Underserved",
      "key_findings": "Finally, this paper proposes an overarching fairness-aware disaster informatics framework to structure the workflow of mitigating fairness issues. This paper not only unveils both the ignored and essential aspects of fairness issues in disaster informatics approaches but also bridges the silos which prevent the understanding of fairness between disaster informatics researchers and machine-learning researchers."
    },
    {
      "openalex_id": "https://openalex.org/W2998095564",
      "doi": "10.1109/access.2020.2981912",
      "title": "Bias Remediation in Driver Drowsiness Detection Systems Using Generative Adversarial Networks",
      "abstract": "Datasets are crucial when training a deep neural network. When datasets are unrepresentative, trained models are prone to bias because they are unable to generalise to real world settings. This is particularly problematic for models trained in specific cultural contexts, which may not represent a wide range of races, and thus fail to generalise. This is a particular challenge for Driver drowsiness detection, where many publicly available datasets are unrepresentative as they cover only certain ethnicity groups. Traditional augmentation methods are unable to improve a model's performance when tested on other groups with different facial attributes, and it is often challenging to build new, more representative datasets. In this paper, we introduce a novel framework that boosts the performance of detection of drowsiness for different ethnicity groups. Our framework improves Convolutional Neural Network (CNN) trained for prediction by using Generative Adversarial networks (GAN) for targeted data augmentation based on a population bias visualisation strategy that groups faces with similar facial attributes and highlights where the model is failing. A sampling method selects faces where the model is not performing well, which are used to fine-tune the CNN. Experiments show the efficacy of our approach in improving driver drowsiness detection for under represented ethnicity groups. Here, models trained on publicly available datasets are compared with a model trained using the proposed data augmentation strategy. Although developed in the context of driver drowsiness detection, the proposed framework is not limited to the driver drowsiness detection task, but can be applied to other applications.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mkhuseli Ngxande et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Convolutional neural network; Context (archaeology); Generative adversarial network; Advanced driver assistance systems; Face (sociological concept); Generative grammar; Deep learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2020.2981912",
      "cited_by_count": 2,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Framework/Toolkit",
      "ai_ml_method": "Deep Learning; Neural Network; Generative AI",
      "health_domain": "ICU/Critical Care",
      "bias_axes": "Race/Ethnicity; Gender/Sex",
      "lifecycle_stage": "Data Collection; Data Preprocessing",
      "assessment_or_mitigation": "Assessment",
      "approach_method": "Data Augmentation; Transfer Learning; Diverse/Representative Data",
      "clinical_setting": "ICU; Public Health/Population",
      "key_findings": "Here, models trained on publicly available datasets are compared with a model trained using the proposed data augmentation strategy. Although developed in the context of driver drowsiness detection, the proposed framework is not limited to the driver drowsiness detection task, but can be applied to other applications."
    },
    {
      "openalex_id": "https://openalex.org/W2915988983",
      "doi": "10.1109/access.2019.2900022",
      "title": "Algorithmic Bias in Clinical Populations\u2014Evaluating and Improving Facial Analysis Technology in Older Adults With Dementia",
      "abstract": "The need for the automated facial expression analysis arises in various clinical settings involving mental and physical health assessment of older adults. However, the effect of age (young versus old) and ability (healthy versus physical or cognitive impairment) on the performance of available methods has not yet been investigated. In this paper, we demonstrate a bias affecting the performance of common facial landmark detection and expression recognition algorithms on the faces of older adults with dementia. We also investigate the ways of mitigating this bias via the addition of representative training examples. Results show that landmark placement is less accurate when tested on the faces of individuals with dementia as compared to older adults who are cognitively healthy. Retraining or fine-tuning the methods with images of older adults' faces improves the performance significantly, but the gap between older adults with versus without dementia persists. As the interest in using facial analysis methods in clinical applications grows, results of this study: 1) highlight the limitations of the existing models when applied to clinical populations and 2) shed light on methods of addressing these limitations as well as the need to develop algorithms designed to be fair with respect to variables such as age and ability.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Babak Taati et al.",
      "keywords": "Dementia; Retraining; Landmark; Facial expression; Cognition; Computer science; Psychology; Physical medicine and rehabilitation; Artificial intelligence; Cognitive psychology; Medicine; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2900022",
      "cited_by_count": 71,
      "include": true,
      "screen_reason": "Included",
      "ft_status": "No full text available \u2014 passed through",
      "ft_reason": "IEEE: full text paywalled",
      "study_type": "Empirical Study",
      "ai_ml_method": "Not specified",
      "health_domain": "Mental Health/Psychiatry; Neurology",
      "bias_axes": "Gender/Sex; Age; Disability",
      "lifecycle_stage": "Not specified",
      "assessment_or_mitigation": "Both",
      "approach_method": "Transfer Learning",
      "clinical_setting": "Public Health/Population",
      "key_findings": "Retraining or fine-tuning the methods with images of older adults' faces improves the performance significantly, but the gap between older adults with versus without dementia persists. As the interest in using facial analysis methods in clinical applications grows, results of this study: 1) highlight the limitations of the existing models when applied to clinical populations and 2) shed light on methods of addressing these limitations as well as the need to develop algorithms designed to be fair..."
    }
  ],
  "ta_excluded": [
    {
      "openalex_id": "https://openalex.org/W2958089299",
      "doi": "10.1109/tnnls.2020.3027314",
      "title": "A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI",
      "abstract": "Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide \"obviously\" interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.",
      "year": "2020",
      "journal": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Erico Tjoa et al.",
      "keywords": "Croatian; Linguistics; Philosophy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnnls.2020.3027314",
      "cited_by_count": 1931,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3132191748",
      "doi": "10.1109/jproc.2021.3060483",
      "title": "Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications",
      "abstract": "With the broader and highly successful usage of machine learning in industry\\nand the sciences, there has been a growing demand for Explainable AI.\\nInterpretability and explanation methods for gaining a better understanding\\nabout the problem solving abilities and strategies of nonlinear Machine\\nLearning, in particular, deep neural networks, are therefore receiving\\nincreased attention. In this work we aim to (1) provide a timely overview of\\nthis active emerging field, with a focus on 'post-hoc' explanations, and\\nexplain its theoretical foundations, (2) put interpretability algorithms to a\\ntest both from a theory and comparative evaluation perspective using extensive\\nsimulations, (3) outline best practice aspects i.e. how to best include\\ninterpretation methods into the standard usage of machine learning and (4)\\ndemonstrate successful usage of explainable AI in a representative selection of\\napplication scenarios. Finally, we discuss challenges and possible future\\ndirections of this exciting foundational field of machine learning.\\n",
      "year": "2021",
      "journal": "Proceedings of the IEEE",
      "authors": "Wojciech Samek et al.",
      "keywords": "Interpretability; Artificial intelligence; Computer science; Machine learning; Field (mathematics); Perspective (graphical); Artificial neural network; Interpretation (philosophy); Deep neural networks; Selection (genetic algorithm); Deep learning; Management science; Data science; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jproc.2021.3060483",
      "cited_by_count": 1187,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3030790048",
      "doi": "10.1109/jbhi.2020.2991043",
      "title": "AI in Medical Imaging Informatics: Current Challenges and Future Directions",
      "abstract": "This paper reviews state-of-the-art research solutions across the spectrum of medical imaging informatics, discusses clinical translation, and provides future directions for advancing clinical practice. More specifically, it summarizes advances in medical imaging acquisition technologies for different modalities, highlighting the necessity for efficient medical data management strategies in the context of AI in big healthcare data analytics. It then provides a synopsis of contemporary and emerging algorithmic methods for disease classification and organ/ tissue segmentation, focusing on AI and deep learning architectures that have already become the de facto approach. The clinical benefits of in-silico modelling advances linked with evolving 3D reconstruction and visualization applications are further documented. Concluding, integrative analytics approaches driven by associate research branches highlighted in this study promise to revolutionize imaging informatics as known today across the healthcare continuum for both radiology and digital pathology applications. The latter, is projected to enable informed, more accurate diagnosis, timely prognosis, and effective treatment planning, underpinning precision medicine.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Andreas S. Panayides et al.",
      "keywords": "Data science; Computer science; Big data; Health informatics; Informatics; Medical imaging; Health care; Context (archaeology); Modalities; Analytics; Precision medicine; Translational research informatics; Artificial intelligence; Medicine; Engineering informatics; Data mining; Pathology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2020.2991043",
      "cited_by_count": 609,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3046653923",
      "doi": "10.1109/access.2020.3013541",
      "title": "Federated Learning: A Survey on Enabling Technologies, Protocols, and Applications",
      "abstract": "This paper provides a comprehensive study of Federated Learning (FL) with an emphasis on enabling software and hardware platforms, protocols, real-life applications and use-cases. FL can be applicable to multiple domains but applying it to different industries has its own set of obstacles. FL is known as collaborative learning, where algorithm(s) get trained across multiple devices or servers with decentralized data samples without having to exchange the actual data. This approach is radically different from other more established techniques such as getting the data samples uploaded to servers or having data in some form of distributed infrastructure. FL on the other hand generates more robust models without sharing data, leading to privacy-preserved solutions with higher security and access privileges to data. This paper starts by providing an overview of FL. Then, it gives an overview of technical details that pertain to FL enabling technologies, protocols, and applications. Compared to other survey papers in the field, our objective is to provide a more thorough summary of the most relevant protocols, platforms, and real-life use-cases of FL to enable data scientists to build better privacy-preserving solutions for industries in critical need of FL. We also provide an overview of key challenges presented in the recent literature and provide a summary of related research work. Moreover, we explore both the challenges and advantages of FL and present detailed service use-cases to illustrate how different architectures and protocols that use FL can fit together to deliver desired results.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammed Aledhari et al.",
      "keywords": "Computer science; Upload; Server; Field (mathematics); Key (lock); Data science; Data exchange; Set (abstract data type); Data sharing; Service (business); Software; World Wide Web; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3013541",
      "cited_by_count": 668,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3135588948",
      "doi": "10.1109/jproc.2021.3058954",
      "title": "Toward Causal Representation Learning",
      "abstract": "The two fields of machine learning and graphical causality arose and are developed separately. However, there is, now, cross-pollination and increasing interest in both fields to benefit from the advances of the other. In this article, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, that is, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.",
      "year": "2021",
      "journal": "Proceedings of the IEEE",
      "authors": "Bernhard Sch\u00f6lkopf et al.",
      "keywords": "Representation (politics); Computer science; Artificial intelligence; Cognitive psychology; Psychology; Cognitive science; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2021.3058954",
      "cited_by_count": 909,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2907683311",
      "doi": "10.1109/access.2018.2890507",
      "title": "Blockchain for AI: Review and Open Research Challenges",
      "abstract": "Recently, artificial intelligence (AI) and blockchain have become two of the most trending and disruptive technologies. Blockchain technology has the ability to automate payment in cryptocurrency and to provide access to a shared ledger of data, transactions, and logs in a decentralized, secure, and trusted manner. Also with smart contracts, blockchain has the ability to govern interactions among participants with no intermediary or a trusted third party. AI, on the other hand, offers intelligence and decision-making capabilities for machines similar to humans. In this paper, we present a detailed survey on blockchain applications for AI. We review the literature, tabulate, and summarize the emerging blockchain applications, platforms, and protocols specifically targeting AI area. We also identify and discuss open research challenges of utilizing blockchain technologies for AI.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Khaled Salah et al.",
      "keywords": "Blockchain; Cryptocurrency; Computer science; Distributed ledger; Smart contract; Computer security; Payment; Open research; Data science; Big data; World Wide Web; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2890507",
      "cited_by_count": 951,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391855109",
      "doi": "10.1109/access.2024.3365742",
      "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
      "abstract": "Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mohaimenul Azam Khan Raiaan et al.",
      "keywords": "Computer science; Open research; Data science; Natural language processing; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3365742",
      "cited_by_count": 536,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394828356",
      "doi": "10.1109/access.2024.3389497",
      "title": "GPT (Generative Pre-Trained Transformer)\u2014 A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions",
      "abstract": "The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Gokul Yenduri et al.",
      "keywords": "Computer science; Transformer; Architecture; Natural language understanding; Emerging technologies; Natural language; Generative grammar; Artificial intelligence; Risk analysis (engineering); Engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3389497",
      "cited_by_count": 450,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3044482460",
      "doi": "10.1109/access.2020.3010511",
      "title": "HDPM: An Effective Heart Disease Prediction Model for a Clinical Decision Support System",
      "abstract": "Heart disease, one of the major causes of mortality worldwide, can be mitigated by early heart disease diagnosis. A clinical decision support system (CDSS) can be used to diagnose the subjects' heart disease status earlier. This study proposes an effective heart disease prediction model (HDPM) for a CDSS which consists of Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to detect and eliminate the outliers, a hybrid Synthetic Minority Over-sampling Technique-Edited Nearest Neighbor (SMOTE-ENN) to balance the training data distribution and XGBoost to predict heart disease. Two publicly available datasets (Statlog and Cleveland) were used to build the model and compare the results with those of other models (naive bayes (NB), logistic regression (LR), multilayer perceptron (MLP), support vector machine (SVM), decision tree (DT), and random forest (RF)) and of previous study results. The results revealed that the proposed model outperformed other models and previous study results by achieving accuracies of 95.90% and 98.40% for Statlog and Cleveland datasets, respectively. In addition, we designed and developed the prototype of the Heart Disease CDSS (HDCDSS) to help doctors/clinicians diagnose the patients'/subjects' heart disease status based on their current condition. Therefore, early treatment could be conducted to prevent the deaths caused by late heart disease diagnosis.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Norma Latif Fitriyani et al.",
      "keywords": "Computer science; Decision support system; Disease; Artificial intelligence; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3010511",
      "cited_by_count": 351,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295854586",
      "doi": "10.1109/access.2022.3204051",
      "title": "Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research",
      "abstract": "This survey presents a comprehensive review of current literature on\\nExplainable Artificial Intelligence (XAI) methods for cyber security\\napplications. Due to the rapid development of Internet-connected systems and\\nArtificial Intelligence in recent years, Artificial Intelligence including\\nMachine Learning (ML) and Deep Learning (DL) has been widely utilized in the\\nfields of cyber security including intrusion detection, malware detection, and\\nspam filtering. However, although Artificial Intelligence-based approaches for\\nthe detection and defense of cyber attacks and threats are more advanced and\\nefficient compared to the conventional signature-based and rule-based cyber\\nsecurity strategies, most ML-based techniques and DL-based techniques are\\ndeployed in the black-box manner, meaning that security experts and customers\\nare unable to explain how such procedures reach particular conclusions. The\\ndeficiencies of transparency and interpretability of existing Artificial\\nIntelligence techniques would decrease human users' confidence in the models\\nutilized for the defense against cyber attacks, especially in current\\nsituations where cyber attacks become increasingly diverse and complicated.\\nTherefore, it is essential to apply XAI in the establishment of cyber security\\nmodels to create more explainable models while maintaining high accuracy and\\nallowing human users to comprehend, trust, and manage the next generation of\\ncyber defense mechanisms. Although there are papers reviewing Artificial\\nIntelligence applications in cyber security areas and the vast literature on\\napplying XAI in many fields including healthcare, financial services, and\\ncriminal justice, the surprising fact is that there are currently no survey\\nresearch articles that concentrate on XAI applications in cyber security.\\n",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Zhibo Zhang et al.",
      "keywords": "Computer science; Computer security; State (computer science); Artificial intelligence; Data science; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3204051",
      "cited_by_count": 324,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3007204236",
      "doi": "10.1109/tts.2020.2974991",
      "title": "Responsible AI\u2014Two Frameworks for Ethical Design Practice",
      "abstract": "In 2019, the IEEE launched the P7000 standards projects intended to address ethical issues in the design of autonomous and intelligent systems. This move came amidst a growing public concern over the unintended consequences of artificial intelligence (AI), compounded by the lack of an anticipatory process for attending to ethical impact within professional practice. However, the difficulty in moving from principles to practice presents a significant challenge to the implementation of ethical guidelines. Herein, we describe two complementary frameworks for integrating ethical analysis into engineering practice to help address this challenge. We then provide the outcomes of an ethical analysis informed by these frameworks, conducted within the specific context of internet- delivered therapy in digital mental health. We hope both the frameworks and analysis can provide tools and insights, not only for the context of digital healthcare, but for data-enabled and intelligent technology development more broadly.",
      "year": "2020",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Dorian Peters et al.",
      "keywords": "Engineering ethics; Context (archaeology); Unintended consequences; Process (computing); Mental health; Ethical issues; Knowledge management; Computer science; Psychology; Political science; Engineering; Psychotherapist",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2020.2974991",
      "cited_by_count": 264,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2049755262",
      "doi": "10.1109/jbhi.2014.2338351",
      "title": "Signal Quality Indices for the Electrocardiogram and Photoplethysmogram: Derivation and Applications to Wireless Monitoring",
      "abstract": "The identification of invalid data in recordings obtained using wearable sensors is of particular importance since data obtained from mobile patients is, in general, noisier than data obtained from nonmobile patients. In this paper, we present a signal quality index (SQI), which is intended to assess whether reliable heart rates (HRs) can be obtained from electrocardiogram (ECG) and photoplethysmogram (PPG) signals collected using wearable sensors. The algorithms were validated on manually labeled data. Sensitivities and specificities of 94% and 97% were achieved for the ECG and 91% and 95% for the PPG. Additionally, we propose two applications of the SQI. First, we demonstrate that, by using the SQI as a trigger for a power-saving strategy, it is possible to reduce the recording time by up to 94% for the ECG and 93% for the PPG with only minimal loss of valid vital-sign data. Second, we demonstrate how an SQI can be used to reduce the error in the estimation of respiratory rate (RR) from the PPG. The performance of the two applications was assessed on data collected from a clinical study on hospital patients who were able to walk unassisted.",
      "year": "2014",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Christina Orphanidou et al.",
      "keywords": "Photoplethysmogram; Computer science; Wearable computer; SIGNAL (programming language); Wireless; Remote patient monitoring; Artificial intelligence; Electrocardiography; Pattern recognition (psychology); Medicine; Telecommunications; Cardiology; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2014.2338351",
      "cited_by_count": 349,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2945801048",
      "doi": "10.1109/access.2019.2912036",
      "title": "Noise Reduction in ECG Signals Using Fully Convolutional Denoising Autoencoders",
      "abstract": "The electrocardiogram (ECG) is an efficient and noninvasive indicator for arrhythmia detection and prevention. In real-world scenarios, ECG signals are prone to be contaminated with various noises, which may lead to wrong interpretation. Therefore, significant attention has been paid on denoising of ECG for accurate diagnosis and analysis. A denoising autoencoder (DAE) can be applied to reconstruct the clean data from its noisy version. In this paper, a DAE using the fully convolutional network (FCN) is proposed for ECG signal denoising. Meanwhile, the proposed FCN-based DAE can perform compression with regard to the DAE architecture. The proposed approach is applied to ECG signals from the MIT-BIH Arrhythmia database and the added noise signals are obtained from the MIT-BIH Noise Stress Test database. The denoising performance is evaluated using the root-mean-square error (RMSE), percentage-root-mean-square difference (PRD), and improvement in signal-to-noise ratio (SNR<sub>imp</sub>). The results of the experiments conducted on noisy ECG signals of different levels of input SNR show that the FCN acquires better performance as compared to the deep fully connected neural network- and convolutional neural network-based denoising models. Moreover, the proposed FCN-based DAE reduces the size of the input ECG signals, where the compressed data is 32 times smaller than the original. The results of the study demonstrate the superiority of FCN in denoising, with lower RMSE and PRD, as well as higher SNR<sub>imp</sub>. According to the results, we believe that the proposed FCN-based DAE has a good application prospect in clinical practice.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Hsin-Tien Chiang et al.",
      "keywords": "Noise reduction; Pattern recognition (psychology); Computer science; Mean squared error; Noise (video); Convolutional neural network; Artificial intelligence; Autoencoder; Reduction (mathematics); SIGNAL (programming language); Signal-to-noise ratio (imaging); Artificial neural network; Speech recognition; Mathematics; Statistics; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2912036",
      "cited_by_count": 333,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2918478470",
      "doi": "10.1109/access.2019.2902501",
      "title": "Blockchain Applications \u2013 Usage in Different Domains",
      "abstract": "Originally conceived as a mechanism to enable a trustless cryptocurrency-Bitcoin, blockchain has since unbound itself from its original purpose as an increasing number of industries and stakeholders' eye the technology as an attractive alternative to solve existing business solutions as well as disrupt mature industries. This paper presents a systematic literature review of the blockchain technology, tracking its increase in popularity in relation to similar technologies, such as cryptocurrencies and Bitcoin. The objective of this paper is to identify the current standing of the blockchain technology within the literature while also identifying the major fields of study and areas of application for which blockchain offers a valuable solution. This paper finds that unique features to the blockchain, such as privacy, security, anonymity, decentralization, and immutability, provide valuable benefits to various fields and subjects. This paper also finds that exploring the application of blockchain has only begun with some limited studies in areas, such as the Internet of Things, energy, finance, healthcare, and government, that also stand to benefit disproportionately from its implementation.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Joe Abou Jaoude et al.",
      "keywords": "Blockchain; Cryptocurrency; Immutability; Popularity; Computer science; Decentralization; Computer security; Anonymity; Government (linguistics); Relation (database); The Internet; Data science; World Wide Web; Data mining; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2902501",
      "cited_by_count": 367,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2552408385",
      "doi": "10.1109/tbme.2016.2613124",
      "title": "Toward a Robust Estimation of Respiratory Rate From Pulse Oximeters",
      "abstract": "GOAL: Current methods for estimating respiratory rate (RR) from the photoplethysmogram (PPG) typically fail to distinguish between periods of high- and low-quality input data, and fail to perform well on independent \"validation\" datasets. The lack of robustness of existing methods directly results in a lack of penetration of such systems into clinical practice. The present work proposes an alternative method to improve the robustness of the estimation of RR from the PPG. METHODS: The proposed algorithm is based on the use of multiple autoregressive models of different orders for determining the dominant respiratory frequency in the three respiratory-induced variations (frequency, amplitude, and intensity) derived from the PPG. The algorithm was tested on two different datasets comprising 95 eight-minute PPG recordings (in total) acquired from both children and adults in different clinical settings, and its performance using two window sizes (32 and 64 seconds) was compared with that of existing methods in the literature. RESULTS: The proposed method achieved comparable accuracy to existing methods in the literature, with mean absolute errors (median, 25[Formula: see text]-75[Formula: see text] percentiles for a window size of 32 seconds) of 1.5 (0.3-3.3) and 4.0 (1.8-5.5) breaths per minute (for each dataset respectively), whilst providing RR estimates for a greater proportion of windows (over 90% of the input data are kept). CONCLUSION: Increased robustness of RR estimation by the proposed method was demonstrated. SIGNIFICANCE: This work demonstrates that the use of large publicly available datasets is essential for improving the robustness of wearable-monitoring algorithms for use in clinical practice.",
      "year": "2016",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Marco A. F. Pimentel et al.",
      "keywords": "Respiratory rate; Pulse rate; Computer science; Biomedical engineering; Medicine; Heart rate; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2016.2613124",
      "cited_by_count": 333,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3099128725",
      "doi": "10.1109/access.2020.3037474",
      "title": "Secure and Provenance Enhanced Internet of Health Things Framework: A Blockchain Managed Federated Learning Approach",
      "abstract": "Recent advancements in the Internet of Health Things (IoHT) have ushered in the wide adoption of IoT devices in our daily health management. For IoHT data to be acceptable by stakeholders, applications that incorporate the IoHT must have a provision for data provenance, in addition to the accuracy, security, integrity, and quality of data. To protect the privacy and security of IoHT data, federated learning (FL) and differential privacy (DP) have been proposed, where private IoHT data can be trained at the owner's premises. Recent advancements in hardware GPUs even allow the FL process within smartphone or edge devices having the IoHT attached to their edge nodes. Although some of the privacy concerns of IoHT data are addressed by FL, fully decentralized FL is still a challenge due to the lack of training capability at all federated nodes, the scarcity of high-quality training datasets, the provenance of training data, and the authentication required for each FL node. In this paper, we present a lightweight hybrid FL framework in which blockchain smart contracts manage the edge training plan, trust management, and authentication of participating federated nodes, the distribution of global or locally trained models, the reputation of edge nodes and their uploaded datasets or models. The framework also supports the full encryption of a dataset, the model training, and the inferencing process. Each federated edge node performs additive encryption, while the blockchain uses multiplicative encryption to aggregate the updated model parameters. To support the full privacy and anonymization of the IoHT data, the framework supports lightweight DP. This framework was tested with several deep learning applications designed for clinical trials with COVID-19 patients. We present here the detailed design, implementation, and test results, which demonstrate strong potential for wider adoption of IoHT-based health management in a secure way.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Md. Abdur Rahman et al.",
      "keywords": "Computer science; Encryption; Authentication (law); Computer security; Upload; Blockchain; Differential privacy; Information privacy; Data mining; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3037474",
      "cited_by_count": 264,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391974599",
      "doi": "10.1109/access.2024.3367715",
      "title": "Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations",
      "abstract": "Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Siva Sai et al.",
      "keywords": "Transformative learning; Generative grammar; Computer science; Health care; Data science; Artificial intelligence; Management science; Sociology; Engineering; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3367715",
      "cited_by_count": 179,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3003714166",
      "doi": "10.1109/access.2020.2969881",
      "title": "A Systematic Review of Blockchain in Healthcare: Frameworks, Prototypes, and Implementations",
      "abstract": "Blockchain, a form of distributed ledger technology has attracted the interests of stakeholders across several sectors including healthcare. Its' potential in the multi-stakeholder operated sector like health has been responsible for several investments, studies, and implementations. Electronic Health Records (EHR) systems traditionally used for the exchange of health information amongst healthcare stakeholders have been criticised for centralising power, failures and attack-points with exchange data custodians. EHRs have struggled in the face of multi-stakeholder and system requirements while adhering to security, privacy, ethical and other regulatory constraints. Blockchain is promising amongst others to address the many EHR challenges, primarily trustless and secure exchange of health information amongst stakeholders. Many blockchain-in-healthcare frameworks have been proposed; some prototyped and/or implemented. This study leveraged the PRISMA framework to systematically search and evaluate the different models proposed; prototyped and/or implemented. The bibliometric and functional distribution of all 143 articles from this study were presented. This study evaluated 61 articles that discussed either prototypes or pilot or implementations. The technical and architectural analysis of these 61 articles for privacy, security, cost, and performance were detailed. Blockchain was found to solve the trust, security and privacy constraints of traditional EHRs often at significant performance, storage and cost trade-offs.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Emeka Chukwu et al.",
      "keywords": "Blockchain; Implementation; Computer science; Stakeholder; Health care; Custodians; Computer security; Data exchange; Process management; Knowledge management; Business; Database; Software engineering; Public relations",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.2969881",
      "cited_by_count": 269,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4385059984",
      "doi": "10.1109/access.2023.3294569",
      "title": "A Review of Trustworthy and Explainable Artificial Intelligence (XAI)",
      "abstract": "The advancement of Artificial Intelligence (AI) technology has accelerated the development of several systems that are elicited from it. This boom has made the systems vulnerable to security attacks and allows considerable bias in order to handle errors in the system. This puts humans at risk and leaves machines, robots, and data defenseless. Trustworthy AI (TAI) guarantees human value and the environment. In this paper, we present a comprehensive review of the state-of-the-art on how to build a Trustworthy and eXplainable AI, taking into account that AI is a black box with little insight into its underlying structure. The paper also discusses various TAI components, their corresponding bias, and inclinations that make the system unreliable. The study also discusses the necessity for TAI in many verticals, including banking, healthcare, autonomous system, and IoT. We unite the ways of building trust in all fragmented areas of data protection, pricing, expense, reliability, assurance, and decision-making processes utilizing TAI in several diverse industries and to differing degrees. It also emphasizes the importance of transparent and post hoc explanation models in the construction of an eXplainable AI and lists the potential drawbacks and pitfalls of building eXplainable AI. Finally, the policies for developing TAI in the autonomous vehicle construction sectors are thoroughly examined and eclectic ways of building a reliable, interpretable, eXplainable, and Trustworthy AI systems are explained to guarantee safe autonomous vehicle systems.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Vinay Chamola et al.",
      "keywords": "Computer science; Trustworthiness; Boom; Order (exchange); Computer security; Robot; Risk analysis (engineering); Reliability (semiconductor); Artificial intelligence; Data science; Business; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3294569",
      "cited_by_count": 225,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386973901",
      "doi": "10.1109/jbhi.2023.3316750",
      "title": "Large AI Models in Health Informatics: Applications, Challenges, and the Future",
      "abstract": "Large AI models, or foundation models, are models recently emerging with massive scales both parameter-wise and data-wise, the magnitudes of which can reach beyond billions. Once pretrained, large AI models demonstrate impressive performance in various downstream tasks. A prime example is ChatGPT, whose capability has compelled people's imagination about the far-reaching influence that large AI models can have and their potential to transform different domains of our lives. In health informatics, the advent of large AI models has brought new paradigms for the design of methodologies. The scale of multi-modal data in the biomedical and health domain has been ever-expanding especially since the community embraced the era of deep learning, which provides the ground to develop, validate, and advance large AI models for breakthroughs in health-related areas. This article presents a comprehensive review of large AI models, from background to their applications. We identify seven key sectors in which large AI models are applicable and might have substantial influence, including: 1) bioinformatics; 2) medical diagnosis; 3) medical imaging; 4) medical informatics; 5) medical education; 6) public health; and 7) medical robotics. We examine their challenges, followed by a critical discussion about potential future directions and pitfalls of large AI models in transforming the field of health informatics.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Jianing Qiu et al.",
      "keywords": "Computer science; Health informatics; Informatics; Data science; Medicine; Public health; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jbhi.2023.3316750",
      "cited_by_count": 193,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3154435685",
      "doi": "10.1109/trpms.2021.3066428",
      "title": "On Interpretability of Artificial Neural Networks: A Survey",
      "abstract": "Deep learning as represented by the artificial deep neural networks (DNNs) has achieved great success recently in many important areas that deal with text, images, videos, graphs, and so on. However, the black-box nature of DNNs has become one of the primary obstacles for their wide adoption in mission-critical applications such as medical diagnosis and therapy. Because of the huge potentials of deep learning, increasing the interpretability of deep neural networks has recently attracted much research attention. In this paper, we propose a simple but comprehensive taxonomy for interpretability, systematically review recent studies in improving interpretability of neural networks, describe applications of interpretability in medicine, and discuss possible future research directions of interpretability, such as in relation to fuzzy logic and brain science.",
      "year": "2021",
      "journal": "IEEE Transactions on Radiation and Plasma Medical Sciences",
      "authors": "Fenglei Fan et al.",
      "keywords": "Interpretability; Artificial intelligence; Artificial neural network; Deep learning; Computer science; Black box; Machine learning; Deep neural networks; Relation (database); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/trpms.2021.3066428",
      "cited_by_count": 465,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3148438775",
      "doi": "10.1109/access.2021.3070212",
      "title": "A Review on Explainability in Multimodal Deep Neural Nets",
      "abstract": "Artificial Intelligence techniques powered by deep neural nets have achieved much success in several application domains, most significantly and notably in the Computer Vision applications and Natural Language Processing tasks. Surpassing human-level performance propelled the research in the applications where different modalities amongst language, vision, sensory, text play an important role in accurate predictions and identification. Several multimodal fusion methods employing deep learning models are proposed in the literature. Despite their outstanding performance, the complex, opaque and black-box nature of the deep neural nets limits their social acceptance and usability. This has given rise to the quest for model interpretability and explainability, more so in the complex tasks involving multimodal AI methods. This paper extensively reviews the present literature to present a comprehensive survey and commentary on the explainability in multimodal deep neural nets, especially for the vision and language tasks. Several topics on multimodal AI and its applications for generic domains have been covered in this paper, including the significance, datasets, fundamental building blocks of the methods and techniques, challenges, applications, and future trends in this domain",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Gargi Joshi et al.",
      "keywords": "Computer science; Artificial neural network; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3070212",
      "cited_by_count": 184,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391250546",
      "doi": "10.1109/tkde.2024.3352628",
      "title": "Vertical Federated Learning: Concepts, Advances, and Challenges",
      "abstract": "Vertical Federated Learning (VFL) is a federated learning setting where multiple parties with different features about the same set of users jointly train machine learning models without exposing their raw data or model parameters. Motivated by the rapid growth in VFL research and real-world applications, we provide a comprehensive review of the concept and algorithms of VFL, as well as current advances and challenges in various aspects, including effectiveness, efficiency, and privacy. We provide an exhaustive categorization for VFL settings and privacy-preserving protocols and comprehensively analyze the privacy attacks and defense strategies for each protocol. In the end, we propose a unified framework, termed VFLow, which considers the VFL problem under communication, computation, privacy, as well as effectiveness and fairness constraints. Finally, we review the most recent advances in industrial applications, highlighting open challenges and future directions for VFL. \u00a9 1989-2012 IEEE.",
      "year": "2024",
      "journal": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "Yang Liu et al.",
      "keywords": "Computer science; Categorization; Open research; Federated learning; Key (lock); Machine learning; Information privacy; Artificial intelligence; Set (abstract data type); Protocol (science); Raw data; Data science; Computer security; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tkde.2024.3352628",
      "cited_by_count": 248,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3203932036",
      "doi": "10.1109/access.2021.3118642",
      "title": "Federated Deep Learning for Cyber Security in the Internet of Things: Concepts, Applications, and Experimental Analysis",
      "abstract": "In this article, we present a comprehensive study with an experimental analysis of federated deep learning approaches for cyber security in the Internet of Things (IoT) applications. Specifically, we first provide a review of the federated learning-based security and privacy systems for several types of IoT applications, including, Industrial IoT, Edge Computing, Internet of Drones, Internet of Healthcare Things, Internet of Vehicles, etc. Second, the use of federated learning with blockchain and malware/intrusion detection systems for IoT applications is discussed. Then, we review the vulnerabilities in federated learning-based security and privacy systems. Finally, we provide an experimental analysis of federated deep learning with three deep learning approaches, namely, Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and Deep Neural Network (DNN). For each deep learning model, we study the performance of centralized and federated learning under three new real IoT traffic datasets, namely, the Bot-IoT dataset, the MQTTset dataset, and the TON_IoT dataset. The goal of this article is to provide important information on federated deep learning approaches with emerging technologies for cyber security. In addition, it demonstrates that federated deep learning approaches outperform the classic/centralized versions of machine learning (non-federated learning) in assuring the privacy of IoT device data and provide the higher accuracy in detecting attacks.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mohamed Amine Ferrag et al.",
      "keywords": "Computer science; The Internet; Computer security; Internet of Things; World Wide Web; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3118642",
      "cited_by_count": 291,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210840103",
      "doi": "10.1109/access.2022.3150093",
      "title": "Recent Trends in Underwater Visible Light Communication (UVLC) Systems",
      "abstract": "In recent years, underwater visible light communication (UVLC) has become a potential wireless carrier candidate for signal transmission in highly critical, unknown, and acrimonious water mediums such as oceans. Unfortunately, the oceans are the least explored reservoirs in oceanogeographical history. However, natural disasters have aroused significant interest in observing and monitoring oceanic environments for the last couple of decades. Therefore, UVLC has drawn attention as a reliable digital carrier and claims a futuristic optical media in the wireless communication domain. Counterparts of traditional communications, the green, clean, and safe UVLC support high capacity data-rate and bandwidth with minimal delay. Nevertheless, the deployment of UVLC is challenging rather than terrestrial basis communication over long ranges. In addition, UVLC systems have severe signal attenuation and strong turbulence channel conditions. Due to the fact that, this study provides an exhaustive and comprehensive survey of recent advancements in UVLC implementations to cope with the optical signal propagation issues. In this regard, a wide detailed summary and future perspectives of underwater optical signaling towards 5G and beyond (5GB) networks along with the current project schemes, channel impairments, various optical signal modulation techniques, underwater sensor network (UWSN) architectures with energy harvesting approaches, hybrid communication possibilities, and advancements of Internet of underwater things (IoUTs) are concluded in this research.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mohammad Furqan Ali et al.",
      "keywords": "Computer science; Underwater acoustic communication; Underwater; Telecommunications; Bandwidth (computing); Communications system; Wireless; Transmission (telecommunications); Optical communication; Optical wireless; SIGNAL (programming language); Software deployment; Channel (broadcasting); Data transmission; Electronic engineering; Computer network; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3150093",
      "cited_by_count": 219,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4285079306",
      "doi": "10.1109/jtehm.2022.3177710",
      "title": "Deep CNN-LSTM With Self-Attention Model for Human Activity Recognition Using Wearable Sensor",
      "abstract": "Human Activity Recognition (HAR) systems are devised for continuously observing human behavior - primarily in the fields of environmental compatibility, sports injury detection, senior care, rehabilitation, entertainment, and the surveillance in intelligent home settings. Inertial sensors, e.g., accelerometers, linear acceleration, and gyroscopes are frequently employed for this purpose, which are now compacted into smart devices, e.g., smartphones. Since the use of smartphones is so widespread now-a-days, activity data acquisition for the HAR systems is a pressing need. In this article, we have conducted the smartphone sensor-based raw data collection, namely <i>H-Activity</i>, using an Android-OS-based application for accelerometer, gyroscope, and linear acceleration. Furthermore, a hybrid deep learning model is proposed, coupling convolutional neural network and long-short term memory network (CNN-LSTM), empowered by the self-attention algorithm to enhance the predictive capabilities of the system. In addition to our collected dataset (<i>H-Activity</i>), the model has been evaluated with some benchmark datasets, e.g., MHEALTH, and UCI-HAR to demonstrate the comparative performance of our model. When compared to other models, the proposed model has an accuracy of 99.93% using our collected <i>H-Activity</i> data, and 98.76% and 93.11% using data from MHEALTH and UCI-HAR databases respectively, indicating its efficacy in recognizing human activity recognition. We hope that our developed model could be applicable in the clinical settings and collected data could be useful for further research.",
      "year": "2022",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Mst. Alema Khatun et al.",
      "keywords": "Accelerometer; Computer science; Activity recognition; Wearable computer; Convolutional neural network; Gyroscope; Artificial intelligence; mHealth; Deep learning; Machine learning; Android (operating system); Inertial measurement unit; Embedded system; Health care; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2022.3177710",
      "cited_by_count": 214,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3156205870",
      "doi": "10.1109/tts.2021.3066209",
      "title": "Z-Inspection<sup>\u00ae</sup>: A Process to Assess Trustworthy AI",
      "abstract": "The ethical and societal implications of artificial intelligence systems raise concerns. In this article, we outline a novel process based on applied ethics, namely, Z-Inspection \u00ae , to assess if an AI system is trustworthy. We use the definition of trustworthy AI given by the high-level European Commission's expert group on AI. Z-inspection \u00ae is a general inspection process that can be applied to a variety of domains where AI systems are used, such as business, healthcare, and public sector, among many others. To the best of our knowledge, Z-Inspection \u00ae is the first process to assess trustworthy AI in practice.",
      "year": "2021",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Roberto V. Zicari et al.",
      "keywords": "Trustworthiness; Process (computing); Artificial intelligence; Computer science; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2021.3066209",
      "cited_by_count": 111,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392172846",
      "doi": "10.1109/access.2024.3369912",
      "title": "Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond",
      "abstract": "In the past decade, the deployment of deep learning (Artificial Intelligence (AI)) methods has become pervasive across a spectrum of real-world applications, often in safety-critical contexts. This comprehensive research article rigorously investigates the ethical dimensions intricately linked to the rapid evolution of AI technologies, with a particular focus on the healthcare domain. Delving deeply, it explores a multitude of facets including transparency, adept data management, human oversight, educational imperatives, and international collaboration within the realm of AI advancement. Central to this article is the proposition of a conscientious AI framework, meticulously crafted to accentuate values of transparency, equity, answerability, and a human-centric orientation. The second contribution of the article is the in-depth and thorough discussion of the limitations inherent to AI systems. It astutely identifies potential biases and the intricate challenges of navigating multifaceted contexts. Lastly, the article unequivocally accentuates the pressing need for globally standardized AI ethics principles and frameworks. Simultaneously, it aptly illustrates the adaptability of the ethical framework proposed herein, positioned skillfully to surmount emergent challenges.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Sidra Nasir et al.",
      "keywords": "Health care; Computer science; Power (physics); Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3369912",
      "cited_by_count": 93,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3201854521",
      "doi": "10.1109/access.2021.3116481",
      "title": "Explainable Artificial Intelligence for Tabular Data: A Survey",
      "abstract": "Machine learning techniques are increasingly gaining attention due to their widespread use in various disciplines across academia and industry. Despite their tremendous success, many such techniques suffer from the &amp;#x201C;black-box&amp;#x201D; problem, which refers to situations where the data analyst is unable to explain why such techniques arrive at certain decisions. This problem has fuelled interest in Explainable Artificial Intelligence (XAI), which refers to techniques that can easily be interpreted by humans. Unfortunately, many of these techniques are not suitable for &lt;italic&gt;tabular data&lt;/italic&gt;, which is surprising given the importance and widespread use of tabular data in critical applications such as finance, healthcare, and criminal justice. Also surprising is the fact that, despite the vast literature on XAI, there are still no survey articles to date that focus on tabular data. Consequently, despite the existing survey articles that cover a wide range of XAI techniques, it remains challenging for researchers working on tabular data to go through all of these surveys and extract the techniques that are suitable for their analysis. Our article fills this gap by providing a comprehensive and up-to-date survey of the XAI techniques that are relevant to tabular data. Furthermore, we categorize the references covered in our survey, indicating the type of the model being explained, the approach being used to provide the explanation, and the XAI problem being addressed. Our article is the first to provide researchers with a map that helps them navigate the XAI literature in the context of tabular data.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Maria Sahakyan et al.",
      "keywords": "Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3116481",
      "cited_by_count": 117,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3013630101",
      "doi": "10.1109/access.2020.2983075",
      "title": "Attention Gate ResU-Net for Automatic MRI Brain Tumor Segmentation",
      "abstract": "Brain tumor segmentation technology plays a pivotal role in the process of diagnosis and treatment of MRI brain tumors. It helps doctors to locate and measure tumors, as well as develop treatment and rehabilitation strategies. Recently, MRI brain tumor segmentation methods based on U-Net architecture have become popular as they largely improve the segmentation accuracy by applying skip connection to combine high-level feature information and low-level feature information. Meanwhile, researchers have demonstrated that introducing attention mechanism into U-Net can enhance local feature expression and improve the performance of medical image segmentation. In this work, we aim to explore the effectiveness of a recent attention module called attention gate for brain tumor segmentation task, and a novel Attention Gate Residual U-Net model, i.e., AGResU-Net, is further presented. AGResU-Net integrates residual modules and attention gates with a primeval and single U-Net architecture, in which a series of attention gate units are added into the skip connection for highlighting salient feature information while disambiguating irrelevant and noisy feature responses. AGResU-Net not only extracts abundant semantic information to enhance the ability of feature learning, but also pays attention to the information of small-scale brain tumors. We extensively evaluate attention gate units on three authoritative MRI brain tumor benchmarks, i.e., BraTS 2017, BraTS 2018 and BraTS 2019. Experimental results illuminate that models with attention gate units, i.e., Attention Gate U-Net (AGU-Net) and AGResU-Net, outperform their baselines of U-Net and ResU-Net, respectively. In addition, AGResU-Net achieves competitive performance than the representative brain tumor segmentation methods.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jianxin Zhang et al.",
      "keywords": "Segmentation; Computer science; Feature (linguistics); Artificial intelligence; Net (polyhedron); Process (computing); Residual; Pattern recognition (psychology); Image segmentation; Machine learning; Algorithm; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2983075",
      "cited_by_count": 303,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205987779",
      "doi": "10.1109/tbcas.2021.3137646",
      "title": "ANNet: A Lightweight Neural Network for ECG Anomaly Detection in IoT Edge Sensors",
      "abstract": "In this paper, we propose a lightweight neural network for real-time electrocardiogram (ECG) anomaly detection and system level power reduction of wearable Internet of Things (IoT) Edge sensors. The proposed network utilizes a novel hybrid architecture consisting of Long Short Term Memory (LSTM) cells and Multi-Layer Perceptrons (MLP). The LSTM block takes a sequence of coefficients representing the morphology of ECG beats while the MLP input layer is fed with features derived from instantaneous heart rate. Simultaneous training of the blocks pushes the overall network to learn distinct features complementing each other for making decisions. The network was evaluated in terms of accuracy, computational complexity, and power consumption using data from the MIT-BIH arrhythmia database. To address the class imbalance in the dataset, we augmented the dataset using SMOTE algorithm for network training. The network achieved an average classification accuracy of 97% across several records in the database. Further, the network was mapped to a fixed point model, retrained in a bit accurate fixed-point environment to compensate for the quantization error, and ported to an ARM Cortex M4 based embedded platform. In laboratory testing, the overall system was successfully demonstrated, and a significant saving of \u2245 50% power was achieved by gating the wireless transmission using the classifier. Wireless transmission was enabled only to transmit the beats deemed anomalous by the classifier. The proposed technique compares favourably with current methods in terms of computational complexity and has the advantage of stand-alone operation in the edge node, without the need for always-on wireless connectivity making it ideal for IoT wearable devices.",
      "year": "2022",
      "journal": "IEEE Transactions on Biomedical Circuits and Systems",
      "authors": "Gawsalyan Sivapalan et al.",
      "keywords": "Computer science; Perceptron; Edge device; Artificial neural network; Anomaly detection; Artificial intelligence; Real-time computing; Quantization (signal processing); Pattern recognition (psychology); Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbcas.2021.3137646",
      "cited_by_count": 139,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388624604",
      "doi": "10.1109/tpami.2023.3331846",
      "title": "Towards Human-Centered Explainable AI: A Survey of User Studies for Model Explanations",
      "abstract": "Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how human-computer interaction (HCI) and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97 core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI.",
      "year": "2023",
      "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Yao Rong et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Data science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tpami.2023.3331846",
      "cited_by_count": 158,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380536977",
      "doi": "10.1109/access.2023.3285596",
      "title": "Artificial Intelligence and Biosensors in Healthcare and Its Clinical Relevance: A Review",
      "abstract": "Data generated from sources such as wearable sensors, medical imaging, personal health records, pathology records, and public health organizations have resulted in a massive information increase in the medical sciences over the last decade. Advances in computational hardware, such as cloud computing, Graphical Processing Units (GPUs), and Tensor Processing Units (TPUs), provide the means to utilize these data. Consequently, many Artificial Intelligence (AI)-based methods have been developed to infer from large healthcare data. Here, we present an overview of recent progress in artificial intelligence and biosensors in medical and life sciences. We discuss the role of machine learning in medical imaging, precision medicine, and biosensors for the Internet of Things (IoT). We review the most recent advancements in wearable biosensing technologies that use AI to assist in monitoring bodily electro-physiological and electro-chemical signals and disease diagnosis, demonstrating the trend towards personalized medicine with highly effective, inexpensive, and precise point-of-care treatment. Furthermore, an overview of the advances in computing technologies, such as accelerated artificial intelligence, edge computing, and federated learning for medical data, are also documented. Finally, we investigate challenges in data-driven AI approaches, the potential issues that biosensors and IoT-based healthcare generate, and the distribution shifts that occur among different data modalities, concluding with an overview of future prospects.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Rizwan Qureshi et al.",
      "keywords": "Computer science; Wearable computer; Health care; Big data; Cloud computing; Data science; Modalities; Artificial intelligence; Relevance (law); Wearable technology; Precision medicine; Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3285596",
      "cited_by_count": 134,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2100802110",
      "doi": "10.1109/jbhi.2013.2293059",
      "title": "Predictive Monitoring of Mobile Patients by Combining Clinical Observations With Data From Wearable Sensors",
      "abstract": "The majority of patients in the hospital are ambulatory and would benefit significantly from predictive and personalized monitoring systems. Such patients are well suited to having their physiological condition monitored using low-power, minimally intrusive wearable sensors. Despite data-collection systems now being manufactured commercially, allowing physiological data to be acquired from mobile patients, little work has been undertaken on the use of the resultant data in a principled manner for robust patient care, including predictive monitoring. Most current devices generate so many false-positive alerts that devices cannot be used for routine clinical practice. This paper explores principled machine learning approaches to interpreting large quantities of continuously acquired, multivariate physiological data, using wearable patient monitors, where the goal is to provide early warning of serious physiological determination, such that a degree of predictive care may be provided. We adopt a one-class support vector machine formulation, proposing a formulation for determining the free parameters of the model using partial area under the ROC curve, a method arising from the unique requirements of performing online analysis with data from patient-worn sensors. There are few clinical evaluations of machine learning techniques in the literature, so we present results from a study at the Oxford University Hospitals NHS Trust devised to investigate the large-scale clinical use of patient-worn sensors for predictive monitoring in a ward with a high incidence of patient mortality. We show that our system can combine routine manual observations made by clinical staff with the continuous data acquired from wearable sensors. Practical considerations and recommendations based on our experiences of this clinical study are discussed, in the context of a framework for personalized monitoring.",
      "year": "2014",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Lei Clifton et al.",
      "keywords": "Wearable computer; Computer science; Machine learning; Artificial intelligence; Wearable technology; Remote patient monitoring; Support vector machine; Data collection; Continuous monitoring; Predictive power; Mobile device; Data mining; Medicine; Embedded system; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jbhi.2013.2293059",
      "cited_by_count": 189,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4308167307",
      "doi": "10.1109/ojcoms.2022.3215676",
      "title": "Explainable AI Over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions",
      "abstract": "Explainable Artificial Intelligence (XAI) is transforming the field of\\nArtificial Intelligence (AI) by enhancing the trust of end-users in machines.\\nAs the number of connected devices keeps on growing, the Internet of Things\\n(IoT) market needs to be trustworthy for the end-users. However, existing\\nliterature still lacks a systematic and comprehensive survey work on the use of\\nXAI for IoT. To bridge this lacking, in this paper, we address the XAI\\nframeworks with a focus on their characteristics and support for IoT. We\\nillustrate the widely-used XAI services for IoT applications, such as security\\nenhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and\\nInternet of City Things (IoCT). We also suggest the implementation choice of\\nXAI models over IoT systems in these applications with appropriate examples and\\nsummarize the key inferences for future works. Moreover, we present the\\ncutting-edge development in edge XAI structures and the support of\\nsixth-generation (6G) communication services for IoT applications, along with\\nkey inferences. In a nutshell, this paper constitutes the first holistic\\ncompilation on the development of XAI-based frameworks tailored for the demands\\nof future IoT use cases.\\n",
      "year": "2022",
      "journal": "IEEE Open Journal of the Communications Society",
      "authors": "Senthil Kumar Jagatheesaperumal et al.",
      "keywords": "Internet of Things; State (computer science); Computer science; The Internet; World Wide Web; Data science; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcoms.2022.3215676",
      "cited_by_count": 136,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4283373300",
      "doi": "10.1109/jbhi.2022.3185673",
      "title": "Handling Privacy-Sensitive Medical Data With Federated Learning: Challenges and Future Directions",
      "abstract": "Recent medical applications are largely dominated by the application of Machine Learning (ML) models to assist expert decisions, leading to disruptive innovations in radiology, pathology, genomics, and hence modern healthcare systems in general. Despite the profitable usage of AI-based algorithms, these data-driven methods are facing issues such as the scarcity and privacy of user data, as well as the difficulty of institutions exchanging medical information. With insufficient data, ML is prevented from reaching its full potential, which is only possible if the database consists of the full spectrum of possible anatomies, pathologies, and input data types. To solve these issues, Federated Learning (FL) appeared as a valuable approach in the medical field, allowing patient data to stay where it is generated. Since an FL setting allows many clients to collaboratively train a model while keeping training data decentralized, it can protect privacy-sensitive medical data. However, FL is still unable to deliver all its promises and meets the more stringent requirements (e.g., latency, security) of a healthcare system based on multiple Internet of Medical Things (IoMT). For example, although no data are shared among the participants by definition in FL systems, some security risks are still present and can be considered as vulnerabilities from multiple aspects. This paper sheds light upon the emerging deployment of FL, provides a broad overview of current approaches and existing challenges, and outlines several directions of future work that are relevant to solving existing problems in federated healthcare, with a particular focus on security and privacy issues.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Ons Aouedi et al.",
      "keywords": "Computer science; Software deployment; Health care; Data science; Information privacy; Scarcity; Field (mathematics); Big data; Computer security; Internet privacy; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3185673",
      "cited_by_count": 122,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390831829",
      "doi": "10.1109/access.2024.3353461",
      "title": "Quantum Machine Learning Revolution in Healthcare: A Systematic Review of Emerging Perspectives and Applications",
      "abstract": "Quantum computing (QC) stands apart from traditional computing systems by employing revolutionary techniques for processing information. It leverages the power of quantum bits (qubits) and harnesses the unique properties exhibited by subatomic particles, such as superposition, entanglement, and interference. These quantum phenomena enable quantum computers to operate on an entirely different level, exponentially surpassing the computational capabilities of classical computers. By manipulating qubits and capitalising on their quantum states, QC holds the promise of solving complex problems that are currently intractable in the case of traditional computers. The potential impact of QC extends beyond its computational power and reaches into various critical sectors, including healthcare. Scientists and engineers are working diligently to overcome various challenges and limitations associated with QC technology. These include issues related to qubit stability, error correction, scalability, and noise reduction. In such a scenario, our proposed work provides a concise summary of the most recent state of the art based on articles published between 2018 and 2023 in the healthcare domain. Additionally, the approach follows the necessary guidelines for conducting a systematic literature review. This includes utilising research questions and evaluating the quality of the articles using specific metrics. Initially, a total of 2,038 records were acquired from multiple databases, with 468 duplicate records and 1,053 records unrelated to healthcare subsequently excluded. A further 258, 68, and 39 records were eliminated based on title, abstract, and full-text criteria, respectively. Ultimately, the remaining 49 articles were subject to evaluation, thus providing a brief overview of the recent literature and contributing to existing knowledge and comprehension of Quantum Machine Learning (QML) algorithms and their applications in the healthcare sector. This analysis establishes a foundational framework for forthcoming research and development at the intersection of QC and machine learning, ultimately paving the way for innovative approaches to addressing complex challenges within the healthcare domain.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ubaid Ullah et al.",
      "keywords": "Computer science; Qubit; Quantum computer; Scalability; Health care; Quantum entanglement; Data science; Quantum; Theoretical computer science; Computer engineering; Physics; Quantum mechanics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3353461",
      "cited_by_count": 131,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3207974842",
      "doi": "10.1109/access.2021.3119621",
      "title": "Machine Learning Techniques for Biomedical Natural Language Processing: A Comprehensive Review",
      "abstract": "The widespread use of electronic health records (EHR) systems in health care provides a large amount of real-world data, leading to new areas for clinical research. Natural language processing (NLP) techniques have been used as an artificial intelligence strategy to extract information from clinical narratives in electronic health records since they include a great amount of valuable clinical information. However, in a free-form text such as electronic health records, many clinical data are still hidden in a clinical narrative format. Therefore, the performance of biomedical NLP techniques is required to unlock the full potential of EHR data to convert a clinical narrative text automatically into structured clinical data. In this way, biomedical NLP applications can be used to direct clinical decisions, identify medical problems, and effectively postpone or avoid the occurrence of a disease. This review discusses the current literature on the secondary use of electronic health record data for clinical research on chronic diseases and addresses the potential, challenges, and applications of biomedical NLP techniques. We review some of the biomedical NLP methods and systems used over EHRs and give an overview of machine learning and deep learning methodologies used to process EHRs and improve the understanding of the patient&#x2019;s clinical records and the prediction of chronic diseases risk, providing a great chance to extract previously unknown clinical information. Moreover, this review summarizes the utilizing of Deep Learning and Machine Learning techniques in biomedical NLP tasks based on chronic diseases related EHR data. Finally, this review presents the future trends and challenges in the biomedical NLP.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Essam H. Houssein et al.",
      "keywords": "Artificial intelligence; Computer science; Deep learning; Machine learning; Health records; Data science; Health care; Medical record; Electronic health record; Narrative; Natural language processing; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3119621",
      "cited_by_count": 100,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3136653234",
      "doi": "10.1109/access.2021.3068178",
      "title": "Survey on Blockchain-Based Smart Contracts: Technical Aspects and Future Research",
      "abstract": "Internet of Things (IoT) is an emerging technology that makes people\u2019s lives smart by conquering a plethora of diverse application and service areas. In near future, the fifth-generation (5G) wireless networks provide the connectivity for this IoT ecosystem. It has been carefully designed to facilitate the exponential growth in the IoT field. Network slicing is one of the key technologies in the 5G architecture that has the ability to divide the physical network into multiple logical networks (i.e. slices) with different network characteristics. Therefore, network slicing is also a key enabler of realisation of IoT in 5G. Network slicing can satisfy the various networking demands by heterogeneous IoT applications via dedicated slices. In this survey, we present a comprehensive analysis of the exploitation of network slicing in IoT realisation. We discuss network slicing utilisation in different IoT application scenarios, along with the technical challenges that can be solved via network slicing. Furthermore, integration challenges and open research problems related to the network slicing in the IoT realisation are also discussed in this paper. Finally, we discuss the role of other emerging technologies and concepts, such as blockchain and Artificial Intelligence/Machine Learning(AI/ML) in network slicing and IoT integration",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Tharaka Hewa et al.",
      "keywords": "Blockchain; Smart contract; Cryptocurrency; Computer science; LEAPS; Context (archaeology); Computer security; Internet of Things; Decentralization; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3068178",
      "cited_by_count": 173,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206547830",
      "doi": "10.1109/access.2021.3137364",
      "title": "Reliable and Resilient AI and IoT-Based Personalised Healthcare Services: A Survey",
      "abstract": "Recent technological and economic developments have transformed the\\nhealthcare sector towards more personalized and IoT-based healthcare services.\\nThese services are realized through control and monitoring applications that\\nare typically developed using artificial intelligence/machine learning-based\\nalgorithms, which play a significant role in highlighting the efficiency of\\ntraditional healthcare systems. Current personalized healthcare services are\\ndedicated to a specific environment to support technological personalization.\\nHowever, they are unable to consider different interrelated health conditions,\\nleading to inappropriate diagnoses and affecting sustainability and the\\nlong-term health of patients. To this end, current Healthcare 5.0 technology\\nhas evolved that supersede previous healthcare technologies. The goal of\\nhealthcare 5.0 is to achieve an autonomous healthcare service, that takes into\\naccount the interdependent effect of different health conditions of a patient.\\nThis paper conducts a comprehensive survey on personalized healthcare services.\\nIn particular, we first present an overview of key requirements of\\ncomprehensive personalized healthcare services in modern healthcare Internet of\\nThings (HIoT), including the definition of personalization and an example use\\ncase scenario as a representative for modern HIoT. Second, we explored a\\nfundamental three-layer architecture for IoT-based healthcare systems using AI\\nand non-AI-based approaches, considering key requirements for CPHS followed by\\ntheir strengths and weaknesses in the frame of personalized healthcare\\nservices. Third, we highlighted different security threats against each layer\\nof IoT architecture along with the possible AI and non-AI-based solutions.\\nFinally, we propose a methodology to develop reliable, resilient, and\\npersonalized healthcare services that address the identified weaknesses of\\nexisting approaches.\\n",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Najma Taimoor et al.",
      "keywords": "Health care; Personalization; Computer science; Key (lock); Knowledge management; Service (business); Process management; Computer security; Business; World Wide Web; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3137364",
      "cited_by_count": 131,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3041235520",
      "doi": "10.1109/access.2020.3007939",
      "title": "Notice of Retraction: AI Techniques for COVID-19",
      "abstract": "Artificial Intelligence (AI) intent is to facilitate human limits. It is getting a standpoint on human administrations, filled by the growing availability of restorative clinical data and quick progression of insightful strategies. Motivated by the need to highlight the need for employing AI in battling the COVID-19 Crisis, this survey summarizes the current state of AI applications in clinical administrations while battling COVID-19. Furthermore, we highlight the application of Big Data while understanding this virus. We also overview various intelligence techniques and methods that can be applied to various types of medical information-based pandemic. We classify the existing AI techniques in clinical data analysis, including neural systems, classical SVM, and edge significant learning. Also, an emphasis has been made on regions that utilize AI-oriented cloud computing in combating various similar viruses to COVID-19. This survey study is an attempt to benefit medical practitioners and medical researchers in overpowering their faced difficulties while handling COVID-19 big data. The investigated techniques put forth advances in medical data analysis with an exactness of up to 90%. We further end up with a detailed discussion about how AI implementation can be a huge advantage in combating various similar viruses.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Adedoyin Ahmed Hussain et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3007939",
      "cited_by_count": 142,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387587504",
      "doi": "10.1109/rbme.2023.3324264",
      "title": "Integrating Multi-Omics Data With EHR for Precision Medicine Using Advanced Artificial Intelligence",
      "abstract": "With the recent advancement of novel biomedical technologies such as high-throughput sequencing and wearable devices, multi-modal biomedical data ranging from multi-omics molecular data to real-time continuous bio-signals are generated at an unprecedented speed and scale every day. For the first time, these multi-modal biomedical data are able to make precision medicine close to a reality. However, due to data volume and the complexity, making good use of these multi-modal biomedical data requires major effort. Researchers and clinicians are actively developing artificial intelligence (AI) approaches for data-driven knowledge discovery and causal inference using a variety of biomedical data modalities. These AI-based approaches have demonstrated promising results in various biomedical and healthcare applications. In this review paper, we summarize the state-of-the-art AI models for integrating multi-omics data and electronic health records (EHRs) for precision medicine. We discuss the challenges and opportunities in integrating multi-omics data with EHRs and future directions. We hope this review can inspire future research and developing in integrating multi-omics data with EHRs for precision medicine.",
      "year": "2023",
      "journal": "IEEE Reviews in Biomedical Engineering",
      "authors": "Tong Li et al.",
      "keywords": "Precision medicine; Computer science; Data science; Big data; Variety (cybernetics); Omics; Inference; Modalities; Artificial intelligence; Data mining; Bioinformatics; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/rbme.2023.3324264",
      "cited_by_count": 84,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3156033593",
      "doi": "10.1109/jiot.2021.3073904",
      "title": "Harnessing the Power of Smart and Connected Health to Tackle COVID-19: IoT, AI, Robotics, and Blockchain for a Better World",
      "abstract": "As COVID-19 hounds the world, the common cause of finding a swift solution to manage the pandemic has brought together researchers, institutions, governments, and society at large. The Internet of Things (IoT), artificial intelligence (AI)-including machine learning (ML) and Big Data analytics-as well as Robotics and Blockchain, are the four decisive areas of technological innovation that have been ingenuity harnessed to fight this pandemic and future ones. While these highly interrelated smart and connected health technologies cannot resolve the pandemic overnight and may not be the only answer to the crisis, they can provide greater insight into the disease and support frontline efforts to prevent and control the pandemic. This article provides a blend of discussions on the contribution of these digital technologies, propose several complementary and multidisciplinary techniques to combat COVID-19, offer opportunities for more holistic studies, and accelerate knowledge acquisition and scientific discoveries in pandemic research. First, four areas, where IoT can contribute are discussed, namely: 1) tracking and tracing; 2) remote patient monitoring (RPM) by wearable IoT (WIoT); 3) personal digital twins (PDTs); and 4) real-life use case: ICT/IoT solution in South Korea. Second, the role and novel applications of AI are explained, namely: 1) diagnosis and prognosis; 2) risk prediction; 3) vaccine and drug development; 4) research data set; 5) early warnings and alerts; 6) social control and fake news detection; and 7) communication and chatbot. Third, the main uses of robotics and drone technology are analyzed, including: 1) crowd surveillance; 2) public announcements; 3) screening and diagnosis; and 4) essential supply delivery. Finally, we discuss how distributed ledger technologies (DLTs), of which blockchain is a common example, can be combined with other technologies for tackling COVID-19.",
      "year": "2021",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Farshad Firouzi et al.",
      "keywords": "Computer science; Big data; Artificial intelligence; Robotics; Pandemic; Ingenuity; Digital health; Data science; Computer security; Coronavirus disease 2019 (COVID-19); Robot; Health care; Political science; Medicine; Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2021.3073904",
      "cited_by_count": 127,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293370646",
      "doi": "10.1109/access.2022.3201878",
      "title": "Systematic Review on AI-Blockchain Based E-Healthcare Records Management Systems",
      "abstract": "Electronic health records (EHRs) are digitally saved health records that provide information about a person&#x2019;s health. EHRs are generally shared among healthcare stakeholders, and thus are susceptible to power failures, data misuse, a lack of privacy, security, and an audit trail, among other problems. Blockchain, on the other hand, is a groundbreaking technology that provides a distributed and decentralized environment in which nodes in a list of networks can connect to each other without the need for a central authority. It has the potential to overcome the limits of EHR management and create a more secure, decentralized, and safer environment for exchanging EHR data. Further, blockchain is a distributed ledger on which data can be stored and shared in a cryptographically secure, validated, and mutually agreed-upon manner across all mining nodes. The blockchain stores data with a high level of integrity and robustness, and it cannot be altered. When smart contracts are used to make decisions and conduct analytics with machine-learning algorithms, the results may be trusted and unquestioned. However, Blockchain is not always indestructible and suffers from scalability and complexity issues that might render it inefficient. Combining AI and blockchain technology can handled some of the drawbacks of these two technical ecosystems effectively. AI algorithms rely on data or information to learn, analyze, and reach conclusions. The performance of AI algorithms is enhanced through the data obtained from a data repository or a reliable, secure, trustworthy, and credible platform. Researchers have identified three categories of blockchain-based potential solutions for the management of electronic health records: conceptual, prototype, and implemented. The purpose of this research work is to conduct a Systematic Literature Review (SLR) to identify and assess research articles that were either conceptual or implemented to manage EHRs using blockchain technology. The study conducts a comprehensive evaluation of the literature on blockchain technology and enhanced health record management systems utilizing artificial intelligence technologies. The study examined 189 research papers collected from various publication categories. The in-depth analysis focuses on the privacy, security, accessibility, and scalability of publications. The SLR has illustrated that blockchain technology has the potential to deliver decentralization, security, and privacy that are frequently lacking in traditional EHRs. Additionally, the outcomes of the extensive analysis inform future researchers about the type of blockchain to use in their research. Additionally, methods used in healthcare are summarized per application area while their pros and cons are highlighted. Finally, the emphasized taxonomy combines blockchain and artificial intelligence, which enables us to analyze possible blockchain and artificial intelligence applications in health records management systems. The article ends with a discussion on open issues for research and future directions.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Alaa Haddad et al.",
      "keywords": "Blockchain; Computer science; Scalability; Computer security; Audit trail; Audit; Data management; Data integrity; Health records; Health care; Data science; Data mining; Database; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3201878",
      "cited_by_count": 107,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387886075",
      "doi": "10.1109/access.2023.3326474",
      "title": "Exploring ChatGPT Capabilities and Limitations: A Survey",
      "abstract": "ChatGPT, a groundbreaking natural language processing technology released a few months ago, has attracted significant attention due to its remarkable capabilities. This AI milestone has urged researchers, industry, decision-makers, and governments to examine this technology, including its implications, threats, and benefits. Despite the short period since its release, several researchers have examined ChatGPT from different perspectives. This paper presents a comprehensive review of ChatGPT, highlighting its technical novelties compared to previous models and analyzing existing research from various perspectives. We followed a rigorous methodology to conduct a critical review of existing research on ChatGPT and developed a taxonomy for the different areas of study. Additionally, we identify future challenges and research trends associated with ChatGPT. Our paper is the first critical review of ChatGPT literature, providing valuable insights for practitioners and policymakers. This paper is a reference for researchers seeking to advance research on ChatGPT, including its applications and development.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Anis Koub\u00e2a et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326474",
      "cited_by_count": 78,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3128131898",
      "doi": "10.1109/tnnls.2021.3054746",
      "title": "Anam-Net: Anamorphic Depth Embedding-Based Lightweight CNN for Segmentation of Anomalies in COVID-19 Chest CT Images",
      "abstract": "Chest computed tomography (CT) imaging has become indispensable for staging and managing coronavirus disease 2019 (COVID-19), and current evaluation of anomalies/abnormalities associated with COVID-19 has been performed majorly by the visual score. The development of automated methods for quantifying COVID-19 abnormalities in these CT images is invaluable to clinicians. The hallmark of COVID-19 in chest CT images is the presence of ground-glass opacities in the lung region, which are tedious to segment manually. We propose anamorphic depth embedding-based lightweight CNN, called Anam-Net, to segment anomalies in COVID-19 chest CT images. The proposed Anam-Net has 7.8 times fewer parameters compared to the state-of-the-art UNet (or its variants), making it lightweight capable of providing inferences in mobile or resource constraint (point-of-care) platforms. The results from chest CT images (test cases) across different experiments showed that the proposed method could provide good Dice similarity scores for abnormal and normal regions in the lung. We have benchmarked Anam-Net with other state-of-the-art architectures, such as ENet, LEDNet, UNet++, SegNet, Attention UNet, and DeepLabV3+. The proposed Anam-Net was also deployed on embedded systems, such as Raspberry Pi 4, NVIDIA Jetson Xavier, and mobile-based Android application (CovSeg) embedded with Anam-Net to demonstrate its suitability for point-of-care platforms. The generated codes, models, and the mobile application are available for enthusiastic users at https://github.com/NaveenPaluru/Segmentation-COVID-19.",
      "year": "2021",
      "journal": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Naveen Paluru et al.",
      "keywords": "Coronavirus disease 2019 (COVID-19); Embedding; Artificial intelligence; Segmentation; Computer science; Pattern recognition (psychology); Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); 2019-20 coronavirus outbreak; Computer vision; Medicine; Internal medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnnls.2021.3054746",
      "cited_by_count": 179,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392405811",
      "doi": "10.1109/access.2024.3373195",
      "title": "Explainable Artificial Intelligence for Drug Discovery and Development: A Comprehensive Survey",
      "abstract": "The field of drug discovery has experienced a remarkable transformation with the advent of artificial intelligence (AI) and machine learning (ML) technologies. However, as these AI and ML models are becoming more complex, there is a growing need for transparency and interpretability of the models. Explainable Artificial Intelligence (XAI) is a novel approach that addresses this issue and provides a more interpretable understanding of the predictions made by machine learning models. In recent years, there has been an increasing interest in the application of XAI techniques to drug discovery. This review article provides a comprehensive overview of the current state-of-the-art in XAI for drug discovery, including various XAI methods, their application in drug discovery, and the challenges and limitations of XAI techniques in drug discovery. The article also covers the application of XAI in drug discovery, including target identification, compound design, and toxicity prediction. Furthermore, the article suggests potential future research directions for the application of XAI in drug discovery. This review article aims to provide a comprehensive understanding of the current state of XAI in drug discovery and its potential to transform the field.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Roohallah Alizadehsani et al.",
      "keywords": "Computer science; Drug discovery; Data science; Bioinformatics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3373195",
      "cited_by_count": 72,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390590855",
      "doi": "10.1109/access.2024.3349952",
      "title": "A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?",
      "abstract": "Text classification in natural language processing (NLP) is evolving rapidly, particularly with the surge in transformer-based models, including large language models (LLM). This paper presents an in-depth survey of text classification techniques across diverse benchmarks, addressing applications from sentiment analysis to chatbot-driven question-answering. Methodologically, it utilizes NLP-facilitated approaches such as co-citation and bibliographic coupling alongside traditional research techniques. Because new use cases continue to emerge in this dynamic field, the study proposes an expanded taxonomy of text classification applications, extending the focus beyond unimodal (text-only) inputs to explore the emerging field of multimodal classification. While offering a comprehensive review of text classification with LLMs, this review highlights novel questions that arise when approaching the task with transformers: It evaluates the use of multimodal data, including text, numeric, and columnar data, and discusses the evolution of text input lengths (tokens) for long text classification; it covers the historical development of transformer-based models, emphasizing recent advancements in LLMs; it evaluates model accuracy on 358 datasets across 20 applications, with results challenging the assumption that LLMs are universally superior, revealing unexpected findings related to accuracy, cost, and safety; and it explores issues related to cost and access as models become increasingly expensive. Finally, the survey discusses new social and ethical implications raised when using LLMs for text classification, including bias and copyright. Throughout, the review emphasizes the importance of a nuanced understanding of model performance and a holistic approach to deploying transformer-based models in real-world applications.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "John Fields et al.",
      "keywords": "Computer science; Transformer; Data science; Modal; Citation; Language model; Taxonomy (biology); Natural language processing; Artificial intelligence; Machine learning; Information retrieval; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3349952",
      "cited_by_count": 107,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4381250863",
      "doi": "10.1109/access.2023.3287195",
      "title": "A Survey of Privacy Risks and Mitigation Strategies in the Artificial Intelligence Life Cycle",
      "abstract": "Over the decades, Artificial Intelligence (AI) and machine learning has become a transformative solution in many sectors, services, and technology platforms in a wide range of applications, such as in smart healthcare, financial, political, and surveillance systems. In such applications, a large amount of data is generated about diverse aspects of our life. Although utilizing AI in real-world applications provides numerous opportunities for societies and industries, it raises concerns regarding data privacy. Data used in an AI system are cleaned, integrated, and processed throughout the AI life cycle. Each of these stages can introduce unique threats to individual&#x2019;s privacy and have an impact on ethical processing and protection of data. In this paper, we examine privacy risks in different phases of the AI life cycle and review the existing privacy-enhancing solutions. We introduce four different categories of privacy risk, including (i) risk of identification, (ii) risk of making an inaccurate decision, (iii) risk of non-transparency in AI systems, and (iv) risk of non-compliance with privacy regulations and best practices. We then examined the potential privacy risks in each AI life cycle phase, evaluated concerns, and reviewed privacy-enhancing technologies, requirements, and process solutions to countermeasure these risks. We also reviewed some of the existing privacy protection policies and the need for compliance with available privacy regulations in AI-based systems. The main contribution of this survey is examining privacy challenges and solutions, including technology, process, and privacy legislation in the entire AI life cycle. In each phase of the AI life cycle, open challenges have been identified.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sakib Shahriar et al.",
      "keywords": "Information privacy; Computer science; Privacy by Design; Transparency (behavior); Legislation; Transformative learning; Privacy software; Computer security; Privacy policy; Process (computing); Internet privacy; Risk analysis (engineering); Business; Law; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3287195",
      "cited_by_count": 87,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2904030287",
      "doi": "10.1109/access.2019.2910224",
      "title": "Patient-Centric Cellular Networks Optimization Using Big Data Analytics",
      "abstract": "Big data analytics is one of the state-of-the-art tools to optimize networks and transform them from merely being a blind tube that conveys data, into a cognitive, conscious, and self-optimizing entity that can intelligently adapt according to the needs of its users. This, in fact, can be regarded as one of the highest forthcoming priorities of future networks. In this paper, we propose a system for Out-Patient (OP) centric Long Term Evolution-Advanced (LTE-A) network optimization. Big data harvested from the OPs' medical records, along with current readings from their body sensors are processed and analyzed to predict the likelihood of a life-threatening medical condition, for instance, an imminent stroke. This prediction is used to ensure that the OP is assigned an optimal LTE-A Physical Resource Blocks (PRBs) to transmit their critical data to their healthcare provider with minimal delay. To the best of our knowledge, this is the first time big data analytics are utilized to optimize a cellular network in an OP-conscious manner. The PRBs assignment is optimized using Mixed Integer Linear Programming (MILP) and a real-time heuristic. Two approaches are proposed, the Weighted Sum Rate Maximization (WSRMax) approach and the Proportional Fairness (PF) approach. The approaches increased the OPs' average SINR by 26.6% and 40.5%, respectively. The WSRMax approach increased the system's total SINR to a level higher than that of the PF approach, however, the PF approach reported higher SINRs for the OPs, better fairness and a lower margin of error.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Mohammed S. Hadi et al.",
      "keywords": "Computer science; Big data; Heuristic; Analytics; Integer programming; Maximization; Linear programming; Data mining; Artificial intelligence; Mathematical optimization; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2910224",
      "cited_by_count": 77,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4361296995",
      "doi": "10.1109/tts.2023.3257627",
      "title": "Designing AI Using a Human-Centered Approach: Explainability and Accuracy Toward Trustworthiness",
      "abstract": "One of the major criticisms of Artificial Intelligence is its lack of explainability. A claim is made by many critics that without knowing how an AI may derive a result or come to a given conclusion, it is impossible to trust in its outcomes. This problem is especially concerning when AI-based systems and applications fail to perform their tasks successfully. In this Special Issue Editorial, we focus on two main areas, explainable AI (XAI) and accuracy, and how both dimensions are critical to building trustworthy systems. We review prominent XAI design themes, leading to a reframing of the design and development effort that highlights the significance of the human, thereby demonstrating the importance of human-centered AI (HCAI). The HCAI approach advocates for a range of deliberate design-related decisions, such as those pertaining to multi-stakeholder engagement and the dissolving of disciplinary boundaries. This enables the consideration and integration of deep interdisciplinary knowledge, as evidenced in our example of social cognitive approaches to AI design. This Editorial then presents a discussion on ways forward, underscoring the value of a balanced approach to assessing the opportunities, risks and responsibilities associated with AI design. We conclude by presenting papers in the Special Issue and their contribution, pointing to future research endeavors.",
      "year": "2023",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Jordan Richard Schoenherr et al.",
      "keywords": "Cognitive reframing; Stakeholder; Computer science; Discipline; Value (mathematics); Trustworthiness; Engineering ethics; Multidisciplinary approach; Data science; Knowledge management; Artificial intelligence; Management science; Sociology; Psychology; Engineering; Political science; Public relations; Social psychology; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2023.3257627",
      "cited_by_count": 71,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2947919073",
      "doi": "10.1109/access.2019.2919184",
      "title": "A Multi-Patient Data-Driven Approach to Blood Glucose Prediction",
      "abstract": "Continuous glucose monitoring systems (CGMSs) allow measuring the blood glycaemic value of a diabetic patient at a high sampling rate, producing a considerable amount of data. These data can be effectively used by machine learning techniques to infer future values of the glycaemic concentration, allowing the early prevention of dangerous hyperglycaemic or hypoglycaemic states and better optimization of the diabetic treatment. Most of the approaches in the literature learn a prediction model from the past samples of the same patient, which needs extensive calibrations and limits the usability of the system. In this paper, we investigate the prediction models trained on glucose signals of a large and heterogeneous cohort of patients and then applied to infer future glucose-level values on a completely new patient. To achieve this purpose, we designed and compared two different types of solutions that were proved successful in many time-series prediction problems based respectively, on non-linear autoregressive (NAR) neural network and on long short-term memory (LSTM) networks. These solutions were experimentally compared with three literature approaches, respectively, based on feed-forward neural networks (FNNs), autoregressive (AR) models, and recurrent neural networks (RNN). While the NAR obtained good prediction accuracy only for short-term predictions (i.e., with prediction horizon within 30 min), the LSTM obtained extremely good performance both for short- and long-term glucose-level inference (60 min and more), overcoming all the other methods in terms of correlation between the measured and the predicted glucose signal and in terms of clinical outcome.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Alessandro Aliberti et al.",
      "keywords": "Autoregressive model; Computer science; Artificial neural network; Recurrent neural network; Artificial intelligence; Machine learning; Inference; Time series; Continuous glucose monitoring; Term (time); Statistics; Diabetes mellitus; Mathematics; Type 1 diabetes; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2919184",
      "cited_by_count": 129,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3108118145",
      "doi": "10.1109/access.2020.3040166",
      "title": "Explainable Prediction of Acute Myocardial Infarction Using Machine Learning and Shapley Values",
      "abstract": "The early and accurate detection of the onset of acute myocardial infarction (AMI) is imperative for the timely provision of medical intervention and the reduction of its mortality rate. Machine learning techniques have demonstrated great potential in aiding disease diagnosis. In this paper, we present a framework to predict the onset of AMI using 713,447 extracted ECG samples and associated auxiliary data from the longitudinal and comprehensive ECG-ViEW II database, previously unexplored in the field of machine learning in healthcare. The framework is realized with two deep learning models, a convolutional neural network (CNN) and a recurrent neural network (RNN), and a decision-tree based model, XGBoost. Synthetic minority oversampling technique (SMOTE) was utilized to address class imbalance. High prediction accuracy of 89.9%, 84.6%, 97.5% and ROC curve areas of 90.7%, 82.9%, 96.5% have been achieved for the best CNN, RNN, and XGBoost models, respectively. Shapley values were utilized to identify the features that contributed most to the classification decision with XGBoost, demonstrating the high impact of auxiliary inputs such as age and sex. This paper demonstrates the promising application of explainable machine learning in the field of cardiovascular disease prediction.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Lujain Ibrahim et al.",
      "keywords": "Computer science; Myocardial infarction; Machine learning; Artificial intelligence; Cardiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3040166",
      "cited_by_count": 109,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392406184",
      "doi": "10.1109/access.2024.3373467",
      "title": "A Lesion-Based Diabetic Retinopathy Detection Through Hybrid Deep Learning Model",
      "abstract": "Diabetic retinopathy (DR) can be defined as visual impairment caused by prolonged diabetes affecting the blood vessels in the retina. Globally, it stands as the primary contributor to blindness, impacting approximately 191 million individuals. While prior research has addressed DR classification using retinal fundus images, existing methods often focus on isolated lesion detection, lacking a comprehensive framework for the simultaneous identification of all lesions. Previous studies concentrated on early-stage features like exudates, aneurysms, hemorrhages, and blood vessels, sidelining severe-stage lesions such as cotton wool spots, venous beading, very severe intraretinal microvascular abnormalities (IRMA), diffuse intraretinal hemorrhages, capillary degeneration, highly activated microglia, and retinal pigment epithelium (RPE) damage. In this study, a deep learning approach is proposed to classify DR fundus images by severity levels, utilizing GoogleNet and ResNet models based on adaptive particle swarm optimizer (APSO), for enhanced feature extraction. The extracted features from the hybrid model are further used with different machine learning models like random forest, support vector machine, decision tree, and linear regression models. Experimental results showcased the proposed hybrid framework outperforming advanced approaches with a remarkable 94&#x0025; accuracy on the benchmark dataset. This method demonstrates potential enhancements in precision, recall, accuracy, and F1 score for different DR severity levels.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ayesha Jabbar et al.",
      "keywords": "Diabetic retinopathy; Computer science; Artificial intelligence; Retinopathy; Lesion; Deep learning; Medicine; Diabetes mellitus; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3373467",
      "cited_by_count": 95,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3001584199",
      "doi": "10.1109/rbme.2020.3013489",
      "title": "Secure and Robust Machine Learning for Healthcare: A Survey",
      "abstract": "Recent years have witnessed widespread adoption of machine learning (ML)/deep learning (DL) techniques due to their superior performance for a variety of healthcare applications ranging from the prediction of cardiac arrest from one-dimensional heart signals to computer-aided diagnosis (CADx) using multi-dimensional medical images. Notwithstanding the impressive performance of ML/DL, there are still lingering doubts regarding the robustness of ML/DL in healthcare settings (which is traditionally considered quite challenging due to the myriad security and privacy issues involved), especially in light of recent results that have shown that ML/DL are vulnerable to adversarial attacks. In this paper, we present an overview of various application areas in healthcare that leverage such techniques from security and privacy point of view and present associated challenges. In addition, we present potential methods to ensure secure and privacy-preserving ML for healthcare applications. Finally, we provide insight into the current research challenges and promising directions for future research.",
      "year": "2020",
      "journal": "IEEE Reviews in Biomedical Engineering",
      "authors": "Adnan Qayyum et al.",
      "keywords": "Leverage (statistics); Adversarial system; Health care; Robustness (evolution); Computer science; Artificial intelligence; Machine learning; Healthcare system; Deep learning; Adversarial machine learning; Computer security; Data science; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/rbme.2020.3013489",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3196440773",
      "doi": "10.1109/tetc.2022.3171314",
      "title": "The Role of Explainability in Assuring Safety of Machine Learning in Healthcare",
      "abstract": "Established approaches to assuring safety-critical systems and software are difficult to apply to systems employing ML where there is no clear, pre-defined specification against which to assess validity. This problem is exacerbated by the \"opaque\" nature of ML where the learnt model is not amenable to human scrutiny. Explainable AI (XAI) methods have been proposed to tackle this issue by producing human-interpretable representations of ML models which can help users to gain confidence and build trust in the ML system. However, little work explicitly investigates the role of explainability for safety assurance in the context of ML development. This paper identifies ways in which XAI methods can contribute to safety assurance of ML-based systems. It then uses a concrete ML-based clinical decision support system, concerning weaning of patients from mechanical ventilation, to demonstrate how XAI methods can be employed to produce evidence to support safety assurance. The results are also represented in a safety argument to show where, and in what way, XAI methods can contribute to a safety case. Overall, we conclude that XAI methods have a valuable role in safety assurance of ML-based systems in healthcare but that they are not sufficient in themselves to assure safety.",
      "year": "2022",
      "journal": "IEEE Transactions on Emerging Topics in Computing",
      "authors": "Yan Jia et al.",
      "keywords": "Computer science; Health care; Patient safety; Computer security; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tetc.2022.3171314",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287739163",
      "doi": "10.1109/access.2022.3161132",
      "title": "Blockchain-Based Federated Learning in UAVs Beyond 5G Networks: A Solution Taxonomy and Future Directions",
      "abstract": "Recently, unmanned aerial vehicles (UAVs) have gained attention due to increased use-cases in healthcare, monitoring, surveillance, and logistics operations. UAVs mainly communicate with mobile base stations, ground stations (GS), or networked peer UAVs, known as UAV swarms. UAVs communicate with GS, or UAV swarms, over wireless channels to support mission-critical operations. Communication latency, bandwidth, and precision are of prime importance in such operations. With the rise of data-driven applications, fifth-generation (5G) networks would face bottlenecks to communicate at near-real-time, at low latency and improved coverage. Thus, researchers have shifted towards network designs that incorporate beyond 5G (B5G) networks for UAV designs. However, UAVs are resource-constrained, with limited power and battery, and thus centralized cloud-centric models are not suitable. Moreover, as exchanged data is through open channels, privacy and security issues exist. Federated learning (FL) allows data to be trained on local nodes, preserving privacy and improving network communication. However, sharing of local updates is required through a trusted consensus mechanism. Thus, blockchain (BC)-based FL schemes for UAVs allow trusted exchange of FL updates among UAV swarms and GS. To date, limited research has been carried out on the integration of BC and FL in UAV management. The proposed survey addresses the gap and presents a solution taxonomy of BC-based FL in UAVs for B5G networks due to the open problem. This paper presents a reference architecture and compares its potential benefits over traditional BC-based UAV networks. Open issues and challenges are discussed, with possible future directions. Finally, a logistics case study of BC-based FL-oriented UAVs in 6G networks is presented. The survey aims to aid researchers in developing potential UAV solutions with the key integrating principles over a diverse set of application verticals.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Deepti Saraswat et al.",
      "keywords": "Computer science; Base station; Computer network; Open research; Drone; Cloud computing; Latency (audio); Distributed computing; Architecture; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3161132",
      "cited_by_count": 97,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3110977802",
      "doi": "10.1109/jiot.2020.3044966",
      "title": "Disaster and Pandemic Management Using Machine Learning: A Survey",
      "abstract": "This article provides a literature review of state-of-the-art machine learning (ML) algorithms for disaster and pandemic management. Most nations are concerned about disasters and pandemics, which, in general, are highly unlikely events. To date, various technologies, such as IoT, object sensing, UAV, 5G, and cellular networks, smartphone-based system, and satellite-based systems have been used for disaster and pandemic management. ML algorithms can handle multidimensional, large volumes of data that occur naturally in environments related to disaster and pandemic management and are particularly well suited for important related tasks, such as recognition and classification. ML algorithms are useful for predicting disasters and assisting in disaster management tasks, such as determining crowd evacuation routes, analyzing social media posts, and handling the post-disaster situation. ML algorithms also find great application in pandemic management scenarios, such as predicting pandemics, monitoring pandemic spread, disease diagnosis, etc. This article first presents a tutorial on ML algorithms. It then presents a detailed review of several ML algorithms and how we can combine these algorithms with other technologies to address disaster and pandemic management. It also discusses various challenges, open issues and, directions for future research.",
      "year": "2020",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Vinay Chamola et al.",
      "keywords": "Computer science; Emergency management; Pandemic; Artificial intelligence; Data science; Machine learning; Computer security; Coronavirus disease 2019 (COVID-19); Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2020.3044966",
      "cited_by_count": 131,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388520297",
      "doi": "10.1109/rbme.2023.3331297",
      "title": "Artificial Intelligence and Machine Learning for Improving Glycemic Control in Diabetes: Best Practices, Pitfalls, and Opportunities",
      "abstract": "These consensus guidelines are designed to improve performance and translatability of new machine learning algorithms developed in the field of diabetes for engineers and data scientists.",
      "year": "2023",
      "journal": "IEEE Reviews in Biomedical Engineering",
      "authors": "Peter G. Jacobs et al.",
      "keywords": "Machine learning; Artificial intelligence; Interpretability; Computer science; Field (mathematics); Glycemic; Personalization; Diabetes mellitus; Medicine; World Wide Web; Mathematics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/rbme.2023.3331297",
      "cited_by_count": 86,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4352977741",
      "doi": "10.1109/access.2023.3260027",
      "title": "A Systematic Review on Federated Learning in Medical Image Analysis",
      "abstract": "Federated Learning (FL) obtained a lot of attention to the academic and industrial stakeholders from the beginning of its invention. The eye-catching feature of FL is handling data in a decentralized manner which creates a privacy preserving environment in Artificial Intelligence (AI) applications. As we know medical data includes marginal private information of patients which demands excessive data protection from disclosure to unexpected destinations. In this paper, we performed a Systematic Literature Review (SLR) of published research articles on FL based medical image analysis. Firstly, we have collected articles from different databases followed by PRISMA guidelines, then synthesized data from the selected articles, and finally we provided a comprehensive overview on the topic. In order to do that we extracted core information associated with the implementation of FL in medical imaging from the articles. In our findings we briefly presented characteristics of federated data and models, performance achieved by the models and exclusively results comparison with traditional ML models. In addition, we discussed the open issues and challenges of implementing FL and mentioned our recommendations for future direction of this particular research field. We believe this SLR has successfully summarized the state-of-the-art FL methods for medical image analysis using deep learning.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Md Fahimuzzman Sohan et al.",
      "keywords": "Computer science; Field (mathematics); Systematic review; Data science; Information retrieval; MEDLINE",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3260027",
      "cited_by_count": 80,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3155464240",
      "doi": "10.1109/access.2021.3072900",
      "title": "Efficient Automated Processing of the Unstructured Documents Using Artificial Intelligence: A Systematic Literature Review and Future Directions",
      "abstract": "The unstructured data impacts 95&#x0025; of the organizations and costs them millions of dollars annually. If managed well, it can significantly improve business productivity. The traditional information extraction techniques are limited in their functionality, but AI-based techniques can provide a better solution. A thorough investigation of AI-based techniques for automatic information extraction from unstructured documents is missing in the literature. The purpose of this Systematic Literature Review (SLR) is to recognize, and analyze research on the techniques used for automatic information extraction from unstructured documents and to provide directions for future research. The SLR guidelines proposed by Kitchenham and Charters were adhered to conduct a literature search on various databases between 2010 and 2020. We found that: 1. The existing information extraction techniques are template-based or rule-based, 2. The existing methods lack the capability to tackle complex document layouts in real-time situations such as invoices and purchase orders, 3. The datasets available publicly are task-specific and of low quality. Hence, there is a need to develop a new dataset that reflects real-world problems. Our SLR discovered that AI-based approaches have a strong potential to extract useful information from unstructured documents automatically. However, they face certain challenges in processing multiple layouts of the unstructured documents. Our SLR brings out conceptualization of a framework for construction of high-quality unstructured documents dataset with strong data validation techniques for automated information extraction. Our SLR also reveals a need for a close association between the businesses and researchers to handle various challenges of the unstructured data analysis.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Dipali Baviskar et al.",
      "keywords": "Computer science; Unstructured data; Information extraction; Task (project management); Data science; Information retrieval; Quality (philosophy); Business intelligence; Conceptualization; Data mining; Artificial intelligence; Big data",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3072900",
      "cited_by_count": 133,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3043220749",
      "doi": "10.1109/access.2020.3008733",
      "title": "A Bibliometric Analysis of Corona Pandemic in Social Sciences: A Review of Influential Aspects and Conceptual Structure",
      "abstract": "Corona pandemic has affected the whole world, and it is a highly researched area in biological sciences. As the current pandemic has affected countries socially and economically, the purpose of this bibliometric analysis is to provide a holistic review of the corona pandemic in the field of social sciences. This study aims to highlight significant, influential aspects, research streams, and themes. We have reviewed 395 journal articles related to coronavirus in the field of social sciences from 2003 to 2020. We have deployed 'biblioshiny' a web-interface of the 'bibliometrix 3.0' package of R-studio to conduct bibliometric analysis and visualization. In the field of social sciences, we have reported influential aspects of coronavirus literature. We have found that the 'Morbidity and Mortality Weekly Report' is the top journal. The core article of coronavirus literature is 'Guidelines for preventing health-care-associated pneumonia'. The most commonly used word, in titles, abstracts, author's keywords, and keywords plus, is 'SARS'. Top affiliation is 'The University of Hong Kong'. Hong Kong is a leading country based on citations, and the USA is on top based on total publications. We have used a conceptual framework to identify potential research streams and themes in coronavirus literature. Four research streams are found by deploying a co-occurrence network. These research streams are 'Social and economic effects of epidemic disease', 'Infectious disease calamities and control', 'Outbreak of COVID 19,' and 'Infectious diseases and the role of international organizations'. Finally, a thematic map is used to provide a holistic understanding by dividing significant themes into basic or transversal, emerging or declining, motor, highly developed, but isolated themes. These themes and subthemes have proposed future directions and critical areas of research.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Adeel Nasir et al.",
      "keywords": "Pandemic; Bibliometrics; Thematic analysis; Social network analysis; Conceptual framework; Field (mathematics); Social science; Sociology; Data science; Coronavirus disease 2019 (COVID-19); Infectious disease (medical specialty); Computer science; Disease; Library science; Medicine; Qualitative research",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3008733",
      "cited_by_count": 146,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390933379",
      "doi": "10.1109/access.2024.3354809",
      "title": "A Systematic Review of Graph Neural Network in Healthcare-Based Applications: Recent Advances, Trends, and Future Directions",
      "abstract": "Graph neural network (GNN) is a formidable deep learning framework that enables the analysis and modeling of intricate relationships present in data structured as graphs. In recent years, a burgeoning interest has arisen in exploiting the latent capabilities of GNN for healthcare-based applications, capitalizing on their aptitude for modeling complex relationships and unearthing profound insights from graph-structured data. However, to the best of our knowledge, no study has systemically reviewed the GNN studies conducted in the healthcare domain. This study has furnished an all-encompassing and erudite overview of the prevailing cutting-edge research on GNN in healthcare. Through analysis and assimilation of studies, current research trends, recurrent challenges, and promising future opportunities in GNN for healthcare applications have been identified. China emerged as the leading country to conduct GNN-based studies in the healthcare domain, followed by the USA, UK, and Turkey. Among various aspects of healthcare, disease prediction and drug discovery emerge as the most prominent areas of focus for GNN application, indicating the potential of GNN for advancing diagnostic and therapeutic approaches. This study proposed research questions regarding diverse aspects of GNN in the healthcare domain and addressed them through an in-depth analysis. This study can provide practitioners and researchers with profound insights into the current landscape of GNN applications in healthcare and can guide healthcare institutes, researchers, and governments by demonstrating the ways in which GNN can contribute to the development of effective and efficient healthcare systems.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Showmick Guha Paul et al.",
      "keywords": "Health care; Computer science; Data science; Domain (mathematical analysis); Knowledge management; Management science; Artificial intelligence; Engineering; Political science; Mathematics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3354809",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390533386",
      "doi": "10.1109/access.2023.3349379",
      "title": "A Systematic Literature Review of Digital Twin Research for Healthcare Systems: Research Trends, Gaps, and Realization Challenges",
      "abstract": "Using the PRISMA approach, we present the first systematic literature review of digital twin (DT) research in healthcare systems (HSs). This endeavor stems from the pressing need for a thorough analysis of this emerging yet fragmented research area, with the goal of consolidating knowledge to catalyze its growth. Our findings are structured around three research questions aimed at identifying: (i) current research trends, (ii) gaps, and (iii) realization challenges. Current trends indicate global interest and interdisciplinary collaborations to address complex HS challenges. However, existing research predominantly focuses on conceptualization; research on integration, verification, and implementation is nascent. Additionally, we document that a substantial body of papers mislabel their work, often disregarding modeling and twinning methods that are necessary elements of a DT. Furthermore, we provide a non-exhaustive classification of the literature based on two axes: &lt;italic&gt;the object&lt;/italic&gt; (i.e., product or process) and &lt;italic&gt;the context&lt;/italic&gt; (i.e., patient&amp;#x2019;s body, medical procedures, healthcare facilities, and public health). While this is a testament to the diversity of the field, it implies a specific pattern that could be reimagined. We also identify two gaps: (i) considering the human-in-the-loop nature of HSs with a focus on provider decision-making and (ii) implementation research. Lastly, we discuss two challenges for broad-scale implementation of DTs in HSs: improving virtual-to-physical connectivity and data-related issues. In conclusion, this study suggests that DT research could potentially help alleviate the acute shortcomings of HSs that are often manifested in the inability to concurrently improve the quality of care, provider wellbeing, and cost efficiency.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Md Doulotuzzaman Xames et al.",
      "keywords": "Conceptualization; Context (archaeology); Computer science; Data science; Health care; Systematic review; Digital library; Management science; MEDLINE; Artificial intelligence; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3349379",
      "cited_by_count": 87,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3101452063",
      "doi": "10.1109/access.2020.3037725",
      "title": "Closed-Loop Control of Anesthesia: Survey on Actual Trends, Challenges and Perspectives",
      "abstract": "Automation empowers self-sustainable adaptive processes and personalized services in many industries. The implementation of the integrated healthcare paradigm built on Health 4.0 is expected to transform any area in medicine due to the lightning-speed advances in control, robotics, artificial intelligence, sensors etc. The two objectives of this article, as addressed to different entities, are: i) to raise awareness throughout the anesthesiologists about the usefulness of integrating automation and data exchange in their clinical practice for providing increased attention to alarming situations, ii) to provide the actualized insights of drug-delivery research in order to create an opening horizon towards precision medicine with significantly improved human outcomes. This article presents a concise overview on the recent evolution of closed-loop anesthesia delivery control systems by means of control strategies, depth of anesthesia monitors, patient modelling, safety systems, and validation in clinical trials. For decades, anesthesia control has been in the midst of transformative changes, going from simple controllers to integrative strategies of two or more components, but not achieving yet the breakthrough of an integrated system. However, the scientific advances that happen at high speed need a modern review to identify the current technological gaps, societal implications, and implementation barriers. This article provides a good basis for control research in clinical anesthesia to endorse new challenges for intelligent systems towards individualized patient care. At this connection point of clinical and engineering frameworks through (semi-) automation, the following can be granted: patient safety, economical efficiency, and clinicians' efficacy.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mihaela Ghita et al.",
      "keywords": "Automation; Transformative learning; Control (management); Health care; Patient safety; Computer science; Robotics; Risk analysis (engineering); Medicine; Artificial intelligence; Engineering; Robot; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3037725",
      "cited_by_count": 100,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4294691653",
      "doi": "10.1109/access.2022.3204395",
      "title": "ADD-Net: An Effective Deep Learning Model for Early Detection of Alzheimer Disease in MRI Scans",
      "abstract": "Alzheimer&amp;#x2019;s Disease (AD) is a neurological brain disorder marked by dementia and neurological dysfunction that affects memory, behavioral patterns, and reasoning. Alzheimer&amp;#x2019;s disease is an incurable disease that primarily affects people over 40. Alzheimer&amp;#x2019;s disease is diagnosed through a manual evaluation of a patient&amp;#x2019;s MRI scan and neuro-psychological examinations. Deep Learning (DL), a type of Artificial Intelligence (AI), has pioneered new approaches to automate medical image diagnosis. This study aims to create a reliable and efficient system for classifying AD using MRI by applying the deep Convolutional Neural Network (CNN). In this paper, we propose a new CNN architecture for detecting AD with relatively few parameters, and the proposed solution is ideal for training a smaller dataset. This proposed model successfully distinguishes the early stages of Alzheimer&amp;#x2019;s disease and shows class activation maps as a heat map on the brain. The proposed Alzheimer&amp;#x2019;s Disease Detection Network (ADD-Net) is built from scratch to precisely classify the stages of AD by decreasing parameters and calculation costs. The Kaggle MRI image dataset has a significant class imbalance problem, and we exploited a synthetic oversampling technique to evenly distribute the image among the classes to prevent the problem of class imbalance. The proposed ADD-Net is extensively evaluated against DenseNet169, VGG19, and InceptionResNet V2 using precision, recall, F1-score, Area Under the Curve (AUC), and loss. The ADD-Net achieved the following values for evaluation metrics: 98.63&amp;#x0025;, 99.76&amp;#x0025;, 98.61&amp;#x0025;, 98.63&amp;#x0025;, 98.58&amp;#x0025;, and 0.0549&amp;#x0025; accuracy, AUC, F1-score, precision, recall, and loss, respectively. The simulation results show that the proposed ADD-Net outperforms other state-of-the-art models in all the evaluation metrics.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mian Muhammad Sadiq Fareed et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Convolutional neural network; Dementia; Disease; Neuroimaging; Neuropsychology; Contextual image classification; Machine learning; Recall; Alzheimer's disease; Pattern recognition (psychology); Neuroscience; Medicine; Pathology; Image (mathematics); Cognition; Psychology; Cognitive psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3204395",
      "cited_by_count": 85,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293428560",
      "doi": "10.1109/access.2022.3201876",
      "title": "Adoption of Federated Learning for Healthcare Informatics: Emerging Applications and Future Directions",
      "abstract": "The smart healthcare system has improved the patients quality of life (QoL), where the records are being analyzed remotely by distributed stakeholders. It requires a voluminous exchange of data for disease prediction via the open communication channel, i.e., the Internet to train artificial intelligence (AI) models efficiently and effectively. The open nature of communication channels puts data privacy at high risk and affects the model training of collected data at centralized servers. To overcome this, an emerging concept, i.e., federated learning (FL) is a viable solution. It performs training at client nodes and aggregates their results to train the global model. The concept of local training preserves the privacy, confidentiality, and integrity of the patient&#x2019;s data which contributes effectively to the training process. The applicability of FL in the healthcare domain has various advantages, but it has not been explored to its extent. The existing surveys majorly focused on the role of FL in diverse applications, but there exists no detailed or comprehensive survey on FL in healthcare informatics (HI). We present a relative comparison of recent surveys with the proposed survey. To strengthen healthcare data privacy and increase the QoL of patients, we proposed an FL-based layered healthcare informatics architecture along with the case study on FL-based electronic health records (FL-EHR). We discuss the emerging FL models, and present the statistical and security challenges in FL adoption in medical setups. Thus, the review presents useful insights for both academia and healthcare practitioners to investigate FL application in HI ecosystems.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Vishwa Amitkumar Patel et al.",
      "keywords": "Computer science; Health informatics; Health care; Informatics; Data science; Knowledge management; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3201876",
      "cited_by_count": 64,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2907301012",
      "doi": "10.1109/access.2018.2888816",
      "title": "GAN-Based Semi-Supervised Learning Approach for Clinical Decision Support in Health-IoT Platform",
      "abstract": "Las redes neuronales adversarias generativas adversarias (GANs), es un algoritmo de arquitectura de alto nivel que son parte del conjunto de la inteligencia artificial y del aprendizaje autom\u00e1tico. Las GANs son dos redes neuronales llamadas generador y discriminador, y estas dos redes neuronales compitan entre si creando as\u00ed una optimizaci\u00f3n de los resultados de alta calidad. Las GANs fueron propuestas por Goodfellow en el a\u00f1o 2014 que buscaba otro tipo de enfoque de modelado generativo basado en redes generadoras diferenciables, su amplia aplicaci\u00f3n en la tecnolog\u00eda no tiene l\u00edmites. Su objetivo de aplicaci\u00f3n aborda desde im\u00e1genes, textos, v\u00eddeos, sonidos entre otros. Adem\u00e1s, existen una gran variedad de arquitecturas GANs donde busca la optimizaci\u00f3n dado a su tarea de aprendizaje y desarrollo de aplicaci\u00f3n. El objetivo de trabajo de grado constituye en crear una red neuronal de alto nivel como las GANs para la creaci\u00f3n de informaci\u00f3n sint\u00e9tica por medio de ayuda del aprendizaje supervisado. Adem\u00e1s, se eval\u00faa con m\u00e9todos estad\u00edsticos multivariantes contrastar hipot\u00e9ticamente por igualdad de promedios y homogeneidad de varianzas entre la informaci\u00f3n real y la sint\u00e9tica. Estos m\u00e9todos cient\u00edficos estad\u00edsticos multivariados permiten que la informaci\u00f3n sint\u00e9tica generada por las GANs sea de alta calidad y permitan recrear cierta cantidad de informaci\u00f3n para realizar an\u00e1lisis a gran escala. Adem\u00e1s, la informaci\u00f3n real corresponde a un corresponsal no bancario de una ciudad en Colombia, por cuestiones de confidencialidad no se puede divulgar el nombre de la entidad bancaria y sus clientes. Se cuenta con informaci\u00f3n transaccional con 67244 registros y 7 variables. Con base a la informaci\u00f3n real del corresponsal no bancario se genera nueva informaci\u00f3n sint\u00e9tica por medio de las GANs, y contrastadas estad\u00edsticamente sus igualdades en promedios y varianzas. Dado a la informaci\u00f3n sint\u00e9tica para la identificar posibles casos de lavado de activos donde se quiere identificar patrones y caracter\u00edsticas inusuales para mitigar el lavado de activos. Sin embargo, esto constituye que la informaci\u00f3n que se genere no puede ser publicada dado a que la informaci\u00f3n que se est\u00e1 analizando es sint\u00e9tica, por lo tanto, no se puede realizar an\u00e1lisis descriptivos o inferenciales estad\u00edsticos de la poblaci\u00f3n.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yun Yang et al.",
      "keywords": "Computer science; Clinical decision support system; Internet of Things; Decision support system; Supervised learning; Artificial intelligence; Machine learning; World Wide Web; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2888816",
      "cited_by_count": 74,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382315317",
      "doi": "10.1109/access.2023.3275134",
      "title": "Deep Generative Models for Synthetic Data: A Survey",
      "abstract": "A growing interest in synthetic data has stimulated the development and advancement of a large variety of deep generative models for a wide range of applications. However, as this research has progressed, its streams have become more specialized and disconnected from one another. This is why models for synthesizing text data for natural language processing cannot readily be compared to models for synthesizing health records anymore. To mitigate this isolation, we propose a data-driven evaluation framework for generative models for synthetic sequential data, an important and challenging sub-category of synthetic data, based on five high-level criteria: representativeness, novelty, realism, diversity and coherence of a synthetic data-set relative to the original data-set regardless of the models&#x2019; internal structures. The criteria reflect requirements different domains impose on synthetic data and allow model users to assess the quality of synthetic data across models. In a critical review of generative models for sequential data, we examine and compare the importance of each performance criterion in numerous domains. We find that realism and coherence are more important for synthetic data natural language, speech and audio processing tasks. At the same time, novelty and representativeness are more important for healthcare and mobility data. We also find that measurement of representativeness is often accomplished using statistical metrics, realism by using human judgement, and novelty using privacy tests.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Peter Eigenschink et al.",
      "keywords": "Computer science; Synthetic data; Data modeling; Generative model; Representativeness heuristic; Novelty; Novelty detection; Artificial intelligence; Data set; Coherence (philosophical gambling strategy); Data quality; Data science; Machine learning; Data mining; Generative grammar; Database; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3275134",
      "cited_by_count": 74,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3161687493",
      "doi": "10.1109/access.2021.3081998",
      "title": "Exploring Sybil and Double-Spending Risks in Blockchain Systems",
      "abstract": "The first step to realise the true potential of blockchain systems is to explain the associated security risks and vulnerabilities. These risks and vulnerabilities, exploited by the threat agent to affect the valuable assets and services. In this work, we use a security risk management (SRM) domain model and develop a framework to explore two security risks &#x2013; <italic>Sybil</italic> and <italic>Double-spending</italic> &#x2013; that are observed and considered most concerning security risks within blockchain systems. The framework illustrates the protected assets or assets to secure, the classification of threats that the attacker can trigger using Sybil attack, the identification of threats that cause Double-spending, the vulnerabilities of identified threats, and their countermeasures. We evaluated a newly built framework by exploring Sybil and Double-spending risks in Ethereum-based healthcare applications. We also recognise the various other security and implementation challenges of blockchain that hinder the acceptance of blockchain-enabled solutions. Furthermore, we discuss the permissioned blockchain systems making an appearance in industry-level enterprises and how permissioned blockchain systems control these challenges. We conclude the paper and outline the future work that aims to build an ontology-based blockchain security reference model. The results of this work could help blockchain developers, practitioners, and other associated stakeholders to communicate about Sybil and Double-spending risks, what security countermeasures should be introduced, and what security and implementation challenges are emerging in blockchain systems.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mubashar Iqbal et al.",
      "keywords": "Blockchain; Sybil attack; Computer security; Computer science; Security controls; Identification (biology); Work (physics); Risk analysis (engineering); Business; Control (management)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3081998",
      "cited_by_count": 123,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391305431",
      "doi": "10.1109/ojcoms.2024.3349465",
      "title": "AI and 6G Into the Metaverse: Fundamentals, Challenges and Future Research Trends",
      "abstract": "Since Facebook was renamed Meta, a lot of attention, debate, and exploration have intensified about what the Metaverse is, how it works, and the possible ways to exploit it. It is anticipated that Metaverse will be a continuum of rapidly emerging technologies, usecases, capabilities, and experiences that will make it up for the next evolution of the Internet. Several researchers have already surveyed the literature on artificial intelligence (AI) and wireless communications in realizing the Metaverse. However, due to the rapid emergence and continuous evolution of technologies, there is a need for a comprehensive and in-depth survey of the role of AI, 6G, and the nexus of both in realizing the immersive experiences of Metaverse. Therefore, in this survey, we first introduce the background and ongoing progress in augmented reality (AR), virtual reality (VR), mixed reality (MR) and spatial computing, followed by the technical aspects of AI and 6G. Then, we survey the role of AI in the Metaverse by reviewing the state-of-the-art in deep learning, computer vision, and Edge AI to extract the requirements of 6G in Metaverse. Next, we investigate the promising services of B5G/6G towards Metaverse, followed by identifying the role of AI in 6G networks and 6G networks for AI in support of Metaverse applications, and the need for sustainability in Metaverse. Finally, we enlist the existing and potential applications, usecases, and projects to highlight the importance of progress in the Metaverse. Moreover, in order to provide potential research directions to researchers, we underline the challenges, research gaps, and lessons learned identified from the literature review of the aforementioned technologies.",
      "year": "2024",
      "journal": "IEEE Open Journal of the Communications Society",
      "authors": "Muhammad Zawish et al.",
      "keywords": "Metaverse; Computer science; Virtual reality; Exploit; Data science; Human\u2013computer interaction; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcoms.2024.3349465",
      "cited_by_count": 140,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387885883",
      "doi": "10.1109/access.2023.3326528",
      "title": "Vision Transformer Model for Predicting the Severity of Diabetic Retinopathy in Fundus Photography-Based Retina Images",
      "abstract": "Diabetic Retinopathy (DR) is a result of prolonged diabetes with poor blood sugar management. It causes vision problems and blindness due to the deformation of the human retina. Recently, DR has become a crucial medical problem that affects the health and life of people. Diagnosis of DR can be done manually by ophthalmologists, but this is cumbersome and time consuming especially in the current overloaded physician&#x2019;s environment. The early detection and prevention of DR, a severe complication of diabetes that can lead to blindness, require an automatic, accurate, and personalized machine learning-based method. Various deep learning algorithms, particularly convolutional neural networks (CNNs), have been investigated for detecting different stages of DR. Recently, transformers have proved their capabilities in natural language processing. Vision transformers (ViTs) are extensions of these models to capture long-range dependencies in images, which achieved better results than CNN models. However, ViT always needs huge datasets to learn properly, and this condition reduced its applicability in DR domain. Recently, a new real-world and large fundus image dataset called fine-grained annotated diabetic retinopathy (FGADR) has been released which supported the application of ViT in DR diagnosis domain. The literature has not explored FGADR to optimize ViT models. In this paper, we propose a novel ViT based deep learning pipeline for detecting the severity stages of DR based on fundus photography-based retina images. The model has been built using FGADR dataset. The model has been optimized using a new optimizer called AdamW to detect the global context of images. Because FGADR is an imbalanced dataset, we combine several techniques for handling this issue including the usage of F1-score as the optimization metric, data augmentation, class weights, label smoothing, and focal loss. Extensive experiments have been conducted to explore the role of ViT with different data balancing techniques to detect DR. In addition, the proposed model has been compared with the state-of-the-art CNN algorithms such as ResNet50, Incep-tionV3, and VGG19. The adopted model was able to capture the crucial features of retinal images to understand DR severity better. It achieved superior results compared to other CNN and baseline ViT models (i.e., 0.825, 0.825, 0.826, 0.964, 0.825, 0.825, and 0.956 for F1-score, accuracy, balanced accuracy, AUC, precision, recall, specificity, respectively). The results of the proposed ViT model were quite encouraging to be applied in real medical environment for assisting physicians to make accurate, personalized, and timely decisions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Waleed Nazih et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Diabetic retinopathy; Deep learning; Fundus photography; Fundus (uterus); Blindness; Computer vision; Machine learning; Diabetes mellitus; Optometry; Medicine; Ophthalmology; Visual acuity",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326528",
      "cited_by_count": 94,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210328027",
      "doi": "10.1109/access.2022.3146711",
      "title": "Exploration of EEG-Based Depression Biomarkers Identification Techniques and Their Applications: A Systematic Review",
      "abstract": "Depression is the most common mental illness, which has become the major cause of fear and suicidal mortality or tendencies. Currently, about 10&#x0025; of the world population has been suffering from depression. The classical approach for detecting depression relies on the clinical questionnaire, which depends on the patients&#x2019; responses as well as observing their behavioral activities. However, there is no established method to detect depression from EEG biomarkers. Therefore, exploration of EEG biomarkers for depression assessments is vital and has a great potential to improve our understanding and clinical interventions. In this study, we have conducted a systematic review of 52 research articles using the PRISMA-P systematic review protocol, where we analyzed their research methodologies and outcomes. We categorized the experimentations in these articles according to their physical and psychological aspects scaled by the commonly used clinical questionnaire-based assessments. This study finds that the negative stimuli are the better identification strategies for evaluating depression through EEG signals. From this exploration, researchers observed that the Neural Connectivity Analysis and Brain Topological Mapping have huge potentials for finding depression biomarkers, and it is evident that the right-side hemisphere and frontal and parietal-occipital cortex are distinct regions to detect depression using EEG signals. For this mechanism, researchers are using many signal processing and machine learning approaches. In the case of filtering, Independent Component Analysis (ICA) is commonly used to eliminate physiological and non-physiological artifacts. Among machine learning approaches, Convolutional Neural Network (CNN) and Support Vector Machine (SVM) showed better performance for classifying healthy and depressed brains. The authors hope, this study will create an opportunity to explore more in the future for EEG as diagnostic tool by analyzing brain functional connectivity for focusing on clinical interventions.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Antora Dev et al.",
      "keywords": "Electroencephalography; Depression (economics); Support vector machine; Identification (biology); Artificial intelligence; Population; Computer science; Convolutional neural network; Systematic review; Psychology; Machine learning; Clinical psychology; Medicine; Psychiatry; MEDLINE",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3146711",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3012024716",
      "doi": "10.1109/access.2020.2979256",
      "title": "Arrhythmia Recognition and Classification Using Combined Parametric and Visual Pattern Features of ECG Morphology",
      "abstract": "ECG is a non-invasive tool used to detect cardiac arrhythmias. Many arrhythmias classification solutions with various ECG features have been reported in literature. In this work, a new method combined with a novel morphological feature is proposed for accurate recognition and classification of arrhythmias. First, the events of the ECG signals are detected. Then, parametric features of ECG morphology, i.e., amplitude, interval and duration, are extracted from selected ECG regions. Next, a novel feature for analyzing QRS complex morphology changes as visual patterns as well as a new clustering-based feature extraction algorithm is proposed. Finally, the feature vectors are applied to three well-known classifiers (neural network, SVM, and KNN) for automatic diagnosis. The proposed method was assessed with all fifteen types of heartbeats as recommended by the Association for Advancement of Medical Instrumentation from the MIT-BIH arrhythmia database and achieved the best overall accuracy of 97.70% based on KNN, using the combined parametric and visual pattern features of ECG Morphology. The accuracies for the six main types - normal (N), left bundled branch blocks (L), right bundled branch blocks (R), premature ventricular contractions (V), atrial premature beats (A) and paced beats (P) are 97.79%, 99.50%, 99.59%, 97.69%, 89.70%, and 99.92%, respectively. Comparisons with peer works prove a marginal progress in automatic heart arrhythmia classification performance.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Hui Yang et al.",
      "keywords": "Pattern recognition (psychology); Computer science; Artificial intelligence; Parametric statistics; Morphology (biology); Mathematics; Geology; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2979256",
      "cited_by_count": 88,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394862853",
      "doi": "10.1109/ojcoms.2024.3386872",
      "title": "Explainable AI for 6G Use Cases: Technical Aspects and Research Challenges",
      "abstract": "Around 2020, 5G began its commercialization journey, and discussions about the next-generation networks (such as 6G) emerged. Researchers predict that 6G networks will have higher bandwidth, coverage, reliability, energy efficiency, and lower latency, and will be an integrated \u201chuman-centric\u201d network system powered by artificial intelligence (AI). This 6G network will lead to many real-time automated decisions, ranging from network resource allocation to collision avoidance for self-driving cars. However, there is a risk of losing control over decision-making due to the high-speed, data-intensive AI decision-making that may go beyond designers\u2019 and users\u2019 comprehension. To mitigate this risk, explainable AI (XAI) methods can be used to enhance the transparency of the black-box AI decision-making process. This paper surveys the application of XAI towards the upcoming 6G age, including 6G technologies (such as intelligent radio and zero-touch network management) and 6G use cases (such as industry 5.0). Additionally, the paper summarizes the lessons learned from recent attempts and outlines important research challenges in applying XAI for 6G use cases soon.",
      "year": "2024",
      "journal": "IEEE Open Journal of the Communications Society",
      "authors": "Shen Wang et al.",
      "keywords": "Computer science; Data science; Management science; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcoms.2024.3386872",
      "cited_by_count": 75,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3080571847",
      "doi": "10.1109/access.2020.3018995",
      "title": "A Graph Theory-Based Modeling of Functional Brain Connectivity Based on EEG: A Systematic Review in the Context of Neuroergonomics",
      "abstract": "Graph theory analysis, a mathematical approach, has been applied in brain connectivity studies to explore the organization of network patterns. The computation of graph theory metrics enables the characterization of the stationary behavior of electroencephalogram (EEG) signals that cannot be explained by simple linear methods. The main purpose of this study was to systematically review the graph theory applications for mapping the functional connectivity of the EEG data in neuroergonomics. Moreover, this article proposes a pipeline for constructing an unweighted functional brain network from EEG data using both source and sensor methods. Out of 57 articles, our results show that graph theory metrics used to characterize EEG data have attracted increasing attention since 2006, with the highest frequency of publications in 2018. Most studies have focused on cognitive tasks in comparison with motor tasks. The mean phase coherence method, based on the &#x201C;phase-locking value,&#x201D; was the most frequently used functional estimation technique in the reviewed studies. Furthermore, the unweighted functional brain network has received substantially more attention in the literature than the weighted network. The global clustering coefficient and characteristic path length were the most prevalent metrics for differentiating between global integration and local segregation, and the small-worldness property emerged as a compelling metric for the characterization of information processing. This review provides insight into the use of graph theory metrics to model functional brain connectivity in the context of neuroergonomics research.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Lina Ismail et al.",
      "keywords": "Computer science; Clustering coefficient; Graph theory; Electroencephalography; Graph; Artificial intelligence; Context (archaeology); Coherence (philosophical gambling strategy); Cluster analysis; Theoretical computer science; Machine learning; Mathematics; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3018995",
      "cited_by_count": 132,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4205103167",
      "doi": "10.1109/access.2022.3144765",
      "title": "A Multi-Dimensional Evaluation of Synthetic Data Generators",
      "abstract": "Synthetic datasets are gradually emerging as solutions for data sharing. Multiple synthetic data generators have been introduced in the last decade fueled by advancement in machine learning and by the increased demand for fast and inclusive data sharing, yet their utility is not well understood. Prior research tried to compare the utility of synthetic data generators using different evaluation metrics. These metrics have been found to generate conflicting conclusions making direct comparison of synthetic data generators very difficult. This paper identifies four criteria (or dimensions) for masked data evaluation by classifying available utility metrics into different categories based on the measure they attempt to preserve: attribute fidelity, bivariate fidelity, population fidelity, and application fidelity. A representative metric from each category is chosen based on popularity and consistency, and the four metrics are used to compare the overall utility of four recent data synthesizers across 19 datasets of different sizes and feature counts. The paper also examines correlations between the selected metrics in an attempt to streamline synthetic data utility.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Fida K. Dankar et al.",
      "keywords": "Fidelity; Computer science; Synthetic data; Consistency (knowledge bases); Data mining; Metric (unit); Bivariate analysis; Population; Raw data; Machine learning; Data consistency; Data sharing; Artificial intelligence; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3144765",
      "cited_by_count": 78,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391547640",
      "doi": "10.1109/access.2024.3362239",
      "title": "Empowering Healthcare With IoMT: Evolution, Machine Learning Integration, Security, and Interoperability Challenges",
      "abstract": "The Internet of Medical Things (IoMT) is the subset of the Internet of Things (IoT) that connects multiple medical devices, collect information/data from devices, and transmits and process data in real-time. IoMT is crucial for increasing electronic device accuracy, reliability, and productivity in the healthcare industry. IoMT has emerged as a next-generation bio-analytical tool that converges network-linked biomedical devices with relevant software applications for advancing human health. Adapting IoMT and associated technologies has fixed several problems using telemedicine, remote monitoring, sensors, robotics, etc. However, adopting IoMT technologies for a large population is challenging due to extensive data management, privacy, security, upgradation, scalability, etc. Although significant research has been carried out in this domain, identifying emerging trends and highlighting the technological advancement and challenges within IoMT is required for its success. Moreover, it will aid policymakers, scientists, healthcare practitioners, and researchers to measure the pertinence of IoMT in healthcare sectors more efficiently. This review discusses the evolution of IoMT, Machine Learning Integration, Security, and interoperability challenges of IoMT devices.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "G. R. Pradyumna et al.",
      "keywords": "Interoperability; Computer science; The Internet; Scalability; Health care; Telemedicine; Big data; Data science; World Wide Web; Computer security; Multimedia; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3362239",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323519388",
      "doi": "10.1109/access.2023.3249759",
      "title": "Assessing Inter-Annotator Agreement for Medical Image Segmentation",
      "abstract": "Artificial Intelligence (AI)-based medical computer vision algorithm training and evaluations depend on annotations and labeling. However, variability between expert annotators introduces noise in training data that can adversely impact the performance of AI algorithms. This study aims to assess, illustrate and interpret the inter-annotator agreement among multiple expert annotators when segmenting the same lesion(s)/abnormalities on medical images. We propose the use of three metrics for the qualitative and quantitative assessment of inter-annotator agreement: 1) use of a common agreement heatmap and a ranking agreement heatmap; 2) use of the extended Cohen's kappa and Fleiss' kappa coefficients for a quantitative evaluation and interpretation of inter-annotator reliability; and 3) use of the Simultaneous Truth and Performance Level Estimation (STAPLE) algorithm, as a parallel step, to generate ground truth for training AI models and compute Intersection over Union (IoU), sensitivity, and specificity to assess the inter-annotator reliability and variability. Experiments are performed on two datasets, namely cervical colposcopy images from 30 patients and chest X-ray images from 336 tuberculosis (TB) patients, to demonstrate the consistency of inter-annotator reliability assessment and the importance of combining different metrics to avoid bias assessment.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Feng Yang et al.",
      "keywords": "Computer science; Cohen's kappa; Artificial intelligence; Reliability (semiconductor); Agreement; Ground truth; Kappa; Segmentation; Pattern recognition (psychology); Intersection (aeronautics); Consistency (knowledge bases); Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3249759",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2793597870",
      "doi": "10.1109/access.2018.2816003",
      "title": "A Weakly-Supervised Framework for Interpretable Diabetic Retinopathy Detection on Retinal Images",
      "abstract": "Diabetic retinopathy (DR) detection is a critical retinal image analysis task in the context of early blindness prevention. Unfortunately, in order to train a model to accurately detect DR based on the presence of different retinal lesions, typically a dataset with medical expert's annotations at the pixel level is needed. In this paper, a new methodology based on the multiple instance learning (MIL) framework is developed in order to overcome this necessity by leveraging the implicit information present on annotations made at the image level. Contrary to previous MIL-based DR detection systems, the main contribution of the proposed technique is the joint optimization of the instance encoding and the image classification stages. In this way, more useful mid-level representations of pathological images can be obtained. The explainability of the model decisions is further enhanced by means of a new loss function enforcing appropriate instance and mid-level representations. The proposed technique achieves comparable or better results than other recently proposed methods, with 90% area under the receiver operating characteristic curve (AUC) on Messidor, 93% AUC on DR1, and 96% AUC on DR2, while improving the interpretability of the produced decisions.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Pedro Costa et al.",
      "keywords": "Diabetic retinopathy; Computer science; Retinal; Artificial intelligence; Pattern recognition (psychology); Retinopathy; Computer vision; Ophthalmology; Diabetes mellitus; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2816003",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392397338",
      "doi": "10.1109/access.2024.3372588",
      "title": "Pneumonia Detection Using Chest Radiographs With Novel EfficientNetV2L Model",
      "abstract": "Pneumonia is a potentially life-threatening infectious disease that is typically diagnosed through physical examinations and diagnostic imaging techniques such as chest X-rays, ultrasounds or lung biopsies. Accurate diagnosis is crucial as wrong diagnosis, inadequate treatment or lack of treatment can cause serious consequences for patients and may become fatal. The advancements in deep learning have significantly contributed to aiding medical experts in diagnosing pneumonia by assisting in their decision-making process. By leveraging deep learning models, healthcare professionals can enhance diagnostic accuracy and make informed treatment decisions for patients suspected of having pneumonia. In this study, six deep learning models including CNN, InceptionResNetV2, Xception, VGG16, ResNet50 and EfficientNetV2L are implemented and evaluated. The study also incorporates the Adam optimizer, which effectively adjusts the epoch for all the models. The models are trained on a dataset of 5856 chest X-ray images and show 87.78&#x0025;, 88.94&#x0025;, 90.7&#x0025;, 91.66&#x0025;, 87.98&#x0025; and 94.02&#x0025; accuracy for CNN, InceptionResNetV2, Xception, VGG16, ResNet50 and EfficientNetV2L, respectively. Notably, EfficientNetV2L demonstrates the highest accuracy and proves its robustness for pneumonia detection. These findings highlight the potential of deep learning models in accurately detecting and predicting pneumonia based on chest X-ray images, providing valuable support in clinical decision-making and improving patient treatment.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mudasir Ali et al.",
      "keywords": "Pneumonia; Radiography; Computer science; Radiology; Artificial intelligence; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3372588",
      "cited_by_count": 61,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386757860",
      "doi": "10.1109/tmi.2023.3313786",
      "title": "AIROGS: Artificial Intelligence for Robust Glaucoma Screening Challenge",
      "abstract": "The early detection of glaucoma is essential in preventing visual impairment. Artificial intelligence (AI) can be used to analyze color fundus photographs (CFPs) in a cost-effective manner, making glaucoma screening more accessible. While AI models for glaucoma screening from CFPs have shown promising results in laboratory settings, their performance decreases significantly in real-world scenarios due to the presence of out-of-distribution and low-quality images. To address this issue, we propose the Artificial Intelligence for Robust Glaucoma Screening (AIROGS) challenge. This challenge includes a large dataset of around 113,000 images from about 60,000 patients and 500 different screening centers, and encourages the development of algorithms that are robust to ungradable and unexpected input data. We evaluated solutions from 14 teams in this paper and found that the best teams performed similarly to a set of 20 expert ophthalmologists and optometrists. The highest-scoring team achieved an area under the receiver operating characteristic curve of 0.99 (95% CI: 0.98-0.99) for detecting ungradable images on-the-fly. Additionally, many of the algorithms showed robust performance when tested on three other publicly available datasets. These results demonstrate the feasibility of robust AI-enabled glaucoma screening.",
      "year": "2023",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Coen de Vente et al.",
      "keywords": "Glaucoma; Artificial intelligence; Computer science; Fundus (uterus); Machine learning; Set (abstract data type); Receiver operating characteristic; Computer vision; Pattern recognition (psychology); Medicine; Ophthalmology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2023.3313786",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285111878",
      "doi": "10.1109/access.2022.3176367",
      "title": "An Interpretable Deep Learning Classifier for Epileptic Seizure Prediction Using EEG Data",
      "abstract": "Deep learning has served pattern classification in many applications, with a performance which often well exceeds that of other machine learning paradigms. Yet, in general, deep learning has used computational architectures built, albeit partially, by ad hoc means, and its classification decisions are not necessarily interpretable in terms of knowledge relevant to the application it serves. This is often referred to as the black box problem, which in certain applications, such as epileptic seizure prediction, can be a serious impediment. The purpose of this study is to investigate an interpretable deep learning classifier for epileptic EEG-driven seizure prediction. This neural network is interpretable because its layers can be visualized and interpreted as a result of a novel architecture where the learned weights follow from signal processing computations such as frequency sub-band and spatial filters. Consequently, the extracted features are no longer abstract as they correspond to the features commonly used for decoding EEG data. In addition, the network uses layer-wise relevance propagation to reveal pertinent features which can further explain the computations leading to the decisions. In seizure prediction experiments using the CHB-MIT data set, the method produced classification results which improved on the state-of-the art, with first network layer filters corresponding to clinically relevant frequency bands, and the input channels in the brain location in which the seizure originates contributing most significantly to the network predictions.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Imene Jemal et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Electroencephalography; Epileptic seizure; Classifier (UML); Pattern recognition (psychology); Artificial neural network; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3176367",
      "cited_by_count": 75,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387831834",
      "doi": "10.1109/access.2023.3326258",
      "title": "Toward Trustworthy Metaverse: Advancements and Challenges",
      "abstract": "The Metaverse, a transformative digital realm, holds immense promise for reshaping industries and human interactions while potentially addressing global challenges and democratizing opportunities. However, it also introduces a spectrum of complexities that demand careful navigation. To establish trustworthiness within the Metaverse ecosystem, gaining a deep understanding of its applications, challenges, and existing solutions is imperative. In this comprehensive survey, we first delve into Metaverse applications, drawing insights from existing literature. Subsequently, we explore the diverse challenges the Metaverse presents, analyzing them through the lens of existing research. We then scrutinize the overall trustworthiness of the Metaverse environment and investigate existing solutions to previously identified challenges through a thorough review and analysis of pertinent literature. Lastly, we discussed future research directions aimed at fostering a trustworthy Metaverse environment. This comprehensive review can provide an overview of the Metaverse, its application domains, challenges, existing solutions and research directions for many multidisciplinary studies.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jamin Rahman Jim et al.",
      "keywords": "Metaverse; Computer science; Trustworthiness; Realm; Data science; Possible world; Human\u2013computer interaction; Epistemology; Virtual reality; Internet privacy; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326258",
      "cited_by_count": 52,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3134492315",
      "doi": "10.1109/trpms.2020.3030611",
      "title": "Application and Construction of Deep Learning Networks in Medical Imaging",
      "abstract": "Deep learning (DL) approaches are part of the machine learning (ML) subfield concerned with the development of computational models to train artificial intelligence systems. DL models are characterized by automatically extracting high-level features from the input data to learn the relationship between matching datasets. Thus, its implementation offers an advantage over common ML methods that often require the practitioner to have some domain knowledge of the input data to select the best latent representation. As a result of this advantage, DL has been successfully applied within the medical imaging field to address problems, such as disease classification and tumor segmentation for which it is difficult or impossible to determine which image features are relevant. Therefore, taking into consideration the positive impact of DL on the medical imaging field, this article reviews the key concepts associated with its evolution and implementation. The sections of this review summarize the milestones related to the development of the DL field, followed by a description of the elements of deep neural network and an overview of its application within the medical imaging field. Subsequently, the key steps necessary to implement a supervised DL application are defined, and associated limitations are discussed.",
      "year": "2020",
      "journal": "IEEE Transactions on Radiation and Plasma Medical Sciences",
      "authors": "Maribel Torres-Vel\u00e1zquez et al.",
      "keywords": "Deep learning; Field (mathematics); Computer science; Artificial intelligence; Key (lock); Machine learning; Domain (mathematical analysis); Representation (politics); Medical imaging; Segmentation; Artificial neural network; Matching (statistics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/trpms.2020.3030611",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3174222500",
      "doi": "10.1109/access.2021.3093469",
      "title": "Identification of Abnormal Movements in Infants: A Deep Neural Network for Body Part-Based Prediction of Cerebral Palsy",
      "abstract": "The early diagnosis of cerebral palsy is an area which has recently seen significant multi-disciplinary research. Diagnostic tools such as the General Movements Assessment (GMA), have produced some very promising results, however these manual methods can be laborious. The prospect of automating these processes is seen as key in advancing this field of study. In our previous works, we examined the viability of using pose-based features extracted from RGB video sequences to undertake classification of infant body movements based upon the GMA. In this paper, we propose a new deep learning framework for this classification task. We also propose a visualization framework which identifies body-parts with the greatest contribution towards a classification decision. The inclusion of a visualization framework is an important step towards automation as it helps make the decisions made by the machine learning framework interpretable. We directly compare the proposed framework's classification with several other methods from the literature using two independent datasets. Our experimental results show that the proposed method performs more consistently and more robustly than our previous pose-based techniques as well as other features from related works in this setting. We also find that our visualization framework helps provide greater interpretability, enhancing the likelihood of the adoption of these technologies within the medical domain.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Dimitrios Sakkos et al.",
      "keywords": "Interpretability; Computer science; Visualization; Artificial intelligence; Machine learning; Cerebral palsy; Identification (biology); Artificial neural network; Field (mathematics); Deep learning; Key (lock)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3093469",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288783441",
      "doi": "10.1109/tts.2022.3195114",
      "title": "Assessing Trustworthy AI in Times of COVID-19: Deep Learning for Predicting a Multiregional Score Conveying the Degree of Lung Compromise in COVID-19 Patients",
      "abstract": "This article's main contributions are twofold: 1) to demonstrate how to apply the general European Union's High-Level Expert Group's (EU HLEG) guidelines for trustworthy AI in practice for the domain of healthcare and 2) to investigate the research question of what does \"trustworthy AI\" mean at the time of the COVID-19 pandemic. To this end, we present the results of a post-hoc self-assessment to evaluate the trustworthiness of an AI system for predicting a multiregional score conveying the degree of lung compromise in COVID-19 patients, developed and verified by an interdisciplinary team with members from academia, public hospitals, and industry in time of pandemic. The AI system aims to help radiologists to estimate and communicate the severity of damage in a patient's lung from Chest X-rays. It has been experimentally deployed in the radiology department of the ASST Spedali Civili clinic in Brescia, Italy, since December 2020 during pandemic time. The methodology we have applied for our post-hoc assessment, called Z-Inspection\u00ae, uses sociotechnical scenarios to identify ethical, technical, and domain-specific issues in the use of the AI system in the context of the pandemic.",
      "year": "2022",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Himanshi Allahabadi et al.",
      "keywords": "Coronavirus disease 2019 (COVID-19); Trustworthiness; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); 2019-20 coronavirus outbreak; Degree (music); Compromise; Medicine; Computer science; Artificial intelligence; Internal medicine; Virology; Physics; Outbreak; Political science; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2022.3195114",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285134481",
      "doi": "10.1109/access.2022.3185129",
      "title": "Improving the Heart Disease Detection and Patients\u2019 Survival Using Supervised Infinite Feature Selection and Improved Weighted Random Forest",
      "abstract": "Heart disease is the leading cause of death worldwide. A Machine Learning (ML) system can detect heart disease in the early stages to mitigate mortality rates based on clinical data. However, the class imbalance and high dimensionality issues have been a persistent challenge in ML, preventing accurate predictive data analysis in many real-world applications, including heart disease detection. In this regard, this work proposes a new method to address these issues and improve the predict the presence of heart disease and patients&#x2019; survival, including supervised infinite feature selection (Inf-FS<sub>s</sub>) to find the most significant features and Improved Weighted Random Forest (IWRF) to predict heart disease, and Bayesian optimization to tune the new hyperparameters for IWRF. Two public datasets, including Statlog and heart disease clinical records, were used to develop and validate the proposed model. The proposed model is compared with other hybrid models to show its superiority using performance metrics like accuracy and f-measure to evaluate the models&#x2019; performance. The results have shown that the proposed Inf-FS<sub>s</sub>-IWRF achieved better results than other models in attaining higher accuracy and F-measure on both datasets. Additionally, a comparative study has been performed to compare with previous studies, where the proposed model outperformed the others by an accuracy improvement of 2.4&#x0025; and 4.6&#x0025; on both datasets, respectively.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Abdallah Abdellatif et al.",
      "keywords": "Random forest; Hyperparameter; Feature selection; Computer science; Machine learning; Artificial intelligence; Bayesian optimization; Heart disease; Dimensionality reduction; Feature (linguistics); Curse of dimensionality; Model selection; Naive Bayes classifier; Data mining; Support vector machine; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3185129",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4378976270",
      "doi": "10.1109/access.2023.3281832",
      "title": "Decentralized Learning in Healthcare: A Review of Emerging Techniques",
      "abstract": "Recent developments in deep learning have contributed to numerous success stories in healthcare. The performance of a deep learning model generally improves with the size of the training data. However, there are privacy, ownership, and regulatory issues that prevent combining medical data into traditional centralized storage. Decentralized learning approaches enable collaborative model training by distributing the learning process among several nodes or devices. Conceptually, decentralized learning builds on earlier work in distributed optimization, but the focus of this paper is on recent and emerging techniques such as Federated Learning (FL), Split Learning (SL), and hybrid Split-Federated Learning (SFL). With common, universal deep learning models and centralized aggregator servers, FL overcomes the difficulties of centralized training. Additionally, patient data remains at the local party, upholding the security and anonymity of the data. SL enables machine learning without directly accessing data on clients or end devices. It further enhances privacy in a decentralized setting and mitigates clients&#x2019; storage issues. In this survey, we first provide a contemporary survey of FL, SL, and SFL approaches. Second, we discuss their state-of-the-art applications in healthcare, particularly in medical image analysis. Third, we review these emerging decentralized learning approaches under challenging conditions such as statistical and system heterogeneity, privacy preservation, communication efficiency, fairness, etc. Then, we address existing approaches to tackle these challenges. We detail unique complications related to healthcare applications including data, privacy and security, and communication challenges. Finally, we outline potential areas for further research on emerging decentralized learning techniques in healthcare, including developing personalized models, reducing bias, incorporating hybrid non-IID features, hyperparameter tuning, developing sufficient incentive mechanisms, and incorporating domain expertise knowledge.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Chamani Shiranthika et al.",
      "keywords": "Computer science; Deep learning; Health care; Server; Big data; Artificial intelligence; Data science; Information privacy; Machine learning; Anonymity; Computer security; Data mining; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3281832",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293732086",
      "doi": "10.1109/access.2022.3202889",
      "title": "Ethically Responsible Machine Learning in Fintech",
      "abstract": "Rapid technological developments in the last decade have contributed to using machine learning (ML) in various economic sectors. Financial institutions have embraced technology and have applied ML algorithms in trading, portfolio management, and investment advising. Large-scale automation capabilities and cost savings make the ML algorithms attractive for personal and corporate finance applications. Using ML applications in finance raises ethical issues that need to be carefully examined. We engage a group of experts in finance and ethics to evaluate the relationship between ethical principles of finance and ML. The paper compares the experts&#x2019; findings with the results obtained using natural language processing (NLP) transformer models, given their ability to capture the semantic text similarity. The results reveal that the finance principles of integrity and fairness have the most significant relationships with ML ethics. The study includes a use case with SHapley Additive exPlanations (SHAP) and Microsoft Responsible AI Widgets explainability tools for error analysis and visualization of ML models. It analyzes credit card approval data and demonstrates that the explainability tools can address ethical issues in fintech, and improve transparency, thereby increasing the overall trustworthiness of ML models. The results show that both humans and machines could err in approving credit card requests despite using their best judgment based on the available information. Hence, human-machine collaboration could contribute to improved decision-making in finance. We propose a conceptual framework for addressing ethical challenges in fintech such as bias, discrimination, differential pricing, conflict of interest, and data protection.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Maryan Rizinski et al.",
      "keywords": "Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3202889",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389459160",
      "doi": "10.1109/access.2023.3340884",
      "title": "Ethical Frameworks for Machine Learning in Sensitive Healthcare Applications",
      "abstract": "The application of Machine Learning (ML) in healthcare has opened unprecedented avenues for predictive analytics, diagnostics, and personalized medicine. However, the sensitivity of healthcare data and the ethical dilemmas associated with automated decision-making necessitate a rigorous ethical framework. This review paper aims to provide a comprehensive overview of the existing ethical frameworks that guide ML in healthcare and evaluates their adequacy in ad-dressing ethical challenges. Specifically, this article offers an in-depth examination of prevailing ethical constructs that oversee healthcare ML, spotlighting pivotal concerns: data protection, in-formed assent, equity, and patient autonomy. Various analytical approaches including quantitative metrics, statistical methods for bias detection, and qualitative thematic analyses are applied to address these challenges. Insights are further enriched through case studies of Clinical Decision Support Systems, Remote Patient Monitoring, and Telemedicine Applications. Each case is evaluated against existing ethical frameworks to identify limitations and gaps. Based on our com-prehensive review and evaluation, we propose actionable recommendations for evolving ethical guidelines. The paper concludes by summarizing key findings and underscoring the urgent need for robust ethical frameworks to guide ML applications in sensitive healthcare environments. Future work should focus on the development and empirical validation of new ethical frameworks that can adapt to emerging technologies and ethical dilemmas in healthcare ML.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Haseeb Javed et al.",
      "keywords": "Health care; Autonomy; Thematic analysis; Ethical issues; Engineering ethics; Computer science; Data science; Beneficence; Knowledge management; Qualitative research; Political science; Sociology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3340884",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3016194608",
      "doi": "10.1109/tmi.2020.2993291",
      "title": "Deep Learning COVID-19 Features on CXR Using Limited Training Data Sets",
      "abstract": "Under the global pandemic of COVID-19, the use of artificial intelligence to analyze chest X-ray (CXR) image for COVID-19 diagnosis and patient triage is becoming important. Unfortunately, due to the emergent nature of the COVID-19 pandemic, a systematic collection of the CXR data set for deep neural network training is difficult. To address this problem, here we propose a patch-based convolutional neural network approach with a relatively small number of trainable parameters for COVID-19 diagnosis. The proposed method is inspired by our statistical analysis of the potential imaging biomarkers of the CXR radiographs. Experimental results show that our method achieves state-of-the-art performance and provides clinically interpretable saliency maps, which are useful for COVID-19 diagnosis and patient triage.",
      "year": "2020",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Yujin Oh et al.",
      "keywords": "Coronavirus disease 2019 (COVID-19); Triage; Convolutional neural network; Artificial intelligence; Computer science; Deep learning; Pandemic; Training set; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); 2019-20 coronavirus outbreak; Data set; Set (abstract data type); Artificial neural network; Machine learning; Pattern recognition (psychology); Data mining; Medicine; Medical emergency; Pathology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tmi.2020.2993291",
      "cited_by_count": 55,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3184562487",
      "doi": "10.1109/jstsp.2022.3142514",
      "title": "Project Achoo: A Practical Model and Application for COVID-19 Detection From Recordings of Breath, Voice, and Cough",
      "abstract": "The COVID-19 pandemic created significant interest and demand for infection detection and monitoring solutions. In this paper, we propose a machine learning method to quickly detect COVID-19 using audio recordings made on consumer devices. The approach combines signal processing and noise removal methods with an ensemble of fine-tuned deep learning networks and enables COVID detection on coughs. We have also developed and deployed a mobile application that uses a symptoms checker together with voice, breath, and cough signals to detect COVID-19 infection. The application showed robust performance on both openly sourced datasets and the noisy data collected during beta testing by the end users.",
      "year": "2022",
      "journal": "IEEE Journal of Selected Topics in Signal Processing",
      "authors": "Alexander Ponomarchuk et al.",
      "keywords": "Computer science; Coronavirus disease 2019 (COVID-19); Speech recognition; Artificial intelligence; Noise (video); Deep learning; Machine learning; Real-time computing; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstsp.2022.3142514",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3195963873",
      "doi": "10.1109/access.2021.3105485",
      "title": "An Efficient Slime Mould Algorithm Combined With K-Nearest Neighbor for Medical Classification Tasks",
      "abstract": "Growing science and medical technologies have produced a massive amount of knowledge on different scales of biological systems. By processing various amounts of medical data, these technologies will increase the quality of disease detection and enhance the usability of health information systems. The integration of machine learning in computer-based diagnostic systems facilitates the early detection of diseases, enabling more productive treatments and prolonged survival rates. The slime mould algorithm (SMA) may have drawbacks, such as being trapped in minimal local regions and having an unbalanced exploitation and exploration phase. To overcome these limitations, this paper proposes ISMA, an improved version of the slime mould algorithm (SMA) hybridized with the opposition-based learning (OBL) strategy based on the k-nearest neighbor (kNN) classifier for the classification approach. Opposition-based learning improves global exploratory ability while avoiding premature convergence. The experimental results revealed the superiority of the proposed ISMA&#x2013;kNN in various classification evaluation metrics, including accuracy, sensitivity, specificity, precision, F-score, G-mean, computational time, and feature selection (FS) size compared with the tunicate swarm algorithm (TSA), the marine predators algorithm (MPA), the chimp optimization algorithm (ChOA), the moth&#x2013;flame optimization (MFO) algorithm, the whale optimization algorithm (WOA), the sine cosine algorithm (SCA), and the original SMA algorithm. Performance tests were run on the same maximum number of function evaluations (FEs) on nine UCI benchmark disease data sets with different feature sizes.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Yaser M. Wazery et al.",
      "keywords": "Computer science; Algorithm; Artificial intelligence; Feature selection; Statistical classification; Classifier (UML); Benchmark (surveying); Machine learning; Optimization algorithm; Mathematics; Mathematical optimization",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3105485",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3127287554",
      "doi": "10.1109/access.2021.3052835",
      "title": "Diagnosing Coronavirus Disease 2019 (COVID-19): Efficient Harris Hawks-Inspired Fuzzy K-Nearest Neighbor Prediction Methods",
      "abstract": "This study is devoted to proposing a useful intelligent prediction model to distinguish the severity of COVID-19, to provide a more fair and reasonable reference for assisting clinical diagnostic decision-making. Based on patients' necessary information, pre-existing diseases, symptoms, immune indexes, and complications, this article proposes a prediction model using the Harris hawks optimization (HHO) to optimize the Fuzzy K-nearest neighbor (FKNN), which is called HHO-FKNN. This model is utilized to distinguish the severity of COVID-19. In HHO-FKNN, the purpose of introducing HHO is to optimize the FKNN's optimal parameters and feature subsets simultaneously. Also, based on actual COVID-19 data, we conducted a comparative experiment between HHO-FKNN and several well-known machine learning algorithms, which result shows that not only the proposed HHO-FKNN can obtain better classification performance and higher stability on the four indexes but also screen out the key features that distinguish severe COVID-19 from mild COVID-19. Therefore, we can conclude that the proposed HHO-FKNN model is expected to become a useful tool for COVID-19 prediction.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hua Ye et al.",
      "keywords": "Fuzzy logic; Coronavirus disease 2019 (COVID-19); Artificial intelligence; Computer science; Feature (linguistics); Data mining; Pattern recognition (psychology); Machine learning; Medicine; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3052835",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3204496322",
      "doi": "10.1109/access.2021.3115494",
      "title": "Augmented Intelligence: Surveys of Literature and Expert Opinion to Understand Relations Between Human Intelligence and Artificial Intelligence",
      "abstract": "Augmented intelligence (AuI) integrates human intelligence (HI) and artificial intelligence (AI) to harness their strengths and mitigate their weaknesses. The combination of HI and AI has seen to improve both human and machine capabilities, and achieve a better performance compared to separate HI and AI approaches. In this paper, we present a survey of literature to understand how AuI has been applied in the literature, including the roles of HI and AI, AI approaches, features, and applications. Due to the limited literature related to this topic, we also present a survey of expert opinion to answer four main questions to understand the experts&#x2019; implications of AuI, including: a) the definition of AuI and the significance of HI in AuI; b) the roles of HI in AuI; c) the current and future applications of AuI in research, industry, and public, as well as the advantages and shortcomings of AuI; and d) end users&#x2019; view of the application of AuI. We also present recommendations to improve AuI, and provide a comparison between the findings from the surveys of both literature and expert opinion. The discussion of this paper shows the promising potential of AuI compared to separate HI and AI approaches.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Kok\u2010Lim Alvin Yau et al.",
      "keywords": "Computer science; Human intelligence; Artificial intelligence; Data science; Expert opinion; Intelligence analysis",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3115494",
      "cited_by_count": 52,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3136885910",
      "doi": "10.1109/access.2021.3065576",
      "title": "Central Blood Pressure Estimation From Distal PPG Measurement Using Semiclassical Signal Analysis Features",
      "abstract": "Background and objective: Blood pressure (BP) is one of the crucial indicators that contains valuable medical information about cardiovascular activities. Developing photoplethysmography (PPG)-based cuffless BP estimation algorithms with enough robustness and accuracy is clinically useful in practice, due to its simplicity and noninvasiveness. In this paper, we have developed and tested two frameworks for arterial blood pressure (ABP) estimation at the central arteries using photoplethysmography and electrocardiogram. Methods: Supervised learning, as adapted by most studies regarding this topic, is introduced by comparing three machine learning algorithms. Features are extracted using semi-classical signal analysis (SCSA) tools. To further increase the accuracy of estimation, another BP estimation algorithm is presented. A single feed-forward neural network (FFNN) is utilized for BP regression with PPG features, which are extracted by SCSA and later used by FFNN as the network input. Both BP estimation algorithms perform robustly against MIMIC II database to guarantee statistical reliability. Results: We evaluated the performance against the Advancement of Medical Instrumentation (AAMI) and British Hypertension Society (BHS) standards, and we have compared the standard deviation (STD) of estimation error with current state of the arts. With the AAMI standard, the first method yields comparable performance against existing literature in the estimation of BP values. Regarding the BHS protocol, the second method achieves grade A in the estimation of BP values. Conclusion: We conclude that by using the PPG signal in combination with informative features from the Schr\u00f6dinger\u2019s spectrum, the BP can be non-invasively estimated in a reliable and accurate way. Furthermore, the proposed frameworks could potentially enable applications of cuffless estimation of the BP and development of mobile healthcare device.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Peihao Li et al.",
      "keywords": "Photoplethysmogram; Computer science; Robustness (evolution); Medical instrumentation; Artificial neural network; Artificial intelligence; Blood pressure; Pattern recognition (psychology); Standard deviation; Statistics; Medicine; Mathematics; Computer vision; Cardiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3065576",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3158705359",
      "doi": "10.1109/jiot.2021.3074952",
      "title": "Enhancing IoT Security via Cancelable HD-sEMG-Based Biometric Authentication Password, Encoded by Gesture",
      "abstract": "Enhancing information security via reliable user authentication in wireless body area network (WBAN)-based Internet of Things (IoT) applications has attracted increasing attention. The noncancelability of traditional biometrics (e.g. fingerprint) for user authentication increases the privacy disclosure risks once the biometric template is exposed, because users cannot volitionally create a new template. In this work, we propose a cancelable biometric modality based on high-density surface electromyogram (HD-sEMG) encoded by hand gesture password, for user authentication. HD-sEMG signals (256 channels) were acquired from the forearm muscles when users performed a prescribed gesture password, forming their biometric token. Thirty four alternative hand gestures in common daily use were studied. Moreover, to reduce the data acquisition and transmission burden in IoT devices, an automatically generated password-specific channel mask was employed to reduce the number of active channels. HD-sEMG biometrics were also robust with reduced sampling rate, further reducing power consumption. HD-sEMG biometrics achieved a low equal error rate (EER) of 0.0013 when impostors entered a wrong gesture password, as validated on 20 subjects. Even if impostors entered the correct gesture password, the HD-sEMG biometrics still achieved an EER of 0.0273. If the HD-sEMG biometric template was exposed, users could cancel it by simply changing it to a new gesture password, with an EER of 0.0013. To the best of our knowledge, this is the first study to employ HD-sEMG signals under common daily hand gestures as biometric tokens, with training and testing data acquired on different days.",
      "year": "2021",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Xinyu Jiang et al.",
      "keywords": "Password; Biometrics; Computer science; Gesture; Authentication (law); Word error rate; Speech recognition; Artificial intelligence; Pattern recognition (psychology); Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2021.3074952",
      "cited_by_count": 70,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4323022427",
      "doi": "10.1109/access.2023.3251105",
      "title": "AI-Based Epileptic Seizure Detection and Prediction in Internet of Healthcare Things: A Systematic Review",
      "abstract": "Epilepsy is a neurological condition affecting around 50 million individuals worldwide, reported by the World Health Organization. This is identified as a hypersensitive disease by clinical associations. The unique characteristics of Electroencephalography have proven to be stable and universal; therefore, researchers have a lot of credibilities. So, it is the most used test for Epileptic Seizure detection and prediction. This study examines the contributions that have so far been made utilizing Electroencephalography technology to detect, predict, and monitor Epileptic Seizures. We have reviewed around 56 research articles, and those papers are selected from different academic databases. The studies explored various approaches, including Machine Learning, Deep Learning, and the Internet of Things framework. A comprehensive discussion of different classification algorithms is analyzed, and their performances are explored. Furthermore, various open issues of the stated approach are discussed, and potential future works are addressed.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sobhana Jahan et al.",
      "keywords": "Epilepsy; Internet of Things; Computer science; Health care; The Internet; Epileptic seizure; Artificial intelligence; Internet privacy; World Wide Web; Psychiatry; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3251105",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3134091181",
      "doi": "10.1109/access.2021.3062493",
      "title": "DeepKneeExplainer: Explainable Knee Osteoarthritis Diagnosis From Radiographs and Magnetic Resonance Imaging",
      "abstract": "Osteoarthritis (OA) is a degenerative joint disease, which significantly affects middle-aged and elderly people. Although primarily identified via hyaline cartilage change based on medical images, technical bottlenecks like noise, artifacts, and modality impose an enormous challenge on high-precision, objective, and efficient early quantification of OA. Owing to recent advancements, approaches based on neural networks (DNNs) have shown outstanding success in this application domain. However, due to nested non-linear and complex structures, DNNs are mostly opaque and perceived as black-box methods, which raises numerous legal and ethical concerns. Moreover, these approaches do not have the ability to provide the reasoning behind diagnosis decisions in the way humans would do, which poses an additional risk in the clinical setting. In this paper, we propose a novel explainable method for knee OA diagnosis based on radiographs and magnetic resonance imaging (MRI), which we called DeepKneeExplainer. First, we comprehensively preprocess MRIs and radiographs through the deep-stacked transformation technique against possible noises and artifacts that could contain unseen images for domain generalization. Then, we extract the region of interests (ROIs) by employing U-Net architecture with ResNet backbone. To classify the cohorts, we train DenseNet and VGG architectures on the extracted ROIs. Finally, we highlight class-discriminating regions using gradient-guided class activation maps (Grad-CAM++) and layer-wise relevance propagation (LRP), followed by providing human-interpretable explanations of the predictions. Comprehensive experiments based on the multicenter osteoarthritis study (MOST) cohorts, our approach yields up to 91% classification accuracy, outperforming comparable state-of-the-art approaches. We hope that our results will encourage medical researchers and developers to adopt explainable methods and DNN-based analytic pipelines towards an increasing acceptance and adoption of AI-assisted applications in the clinical practice for improved knee OA diagnoses.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Md. Rezaul Karim et al.",
      "keywords": "Computer science; Artificial intelligence; Osteoarthritis; Magnetic resonance imaging; Convolutional neural network; Deep learning; Radiography; Domain (mathematical analysis); Generalization; Medical imaging; Pattern recognition (psychology); Machine learning; Medicine; Radiology; Pathology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3062493",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392157450",
      "doi": "10.1109/access.2024.3370238",
      "title": "Empowering Glioma Prognosis With Transparent Machine Learning and Interpretative Insights Using Explainable AI",
      "abstract": "The primary objective of this research is to create a reliable technique to determine whether a patient has glioma, a specific kind of brain tumour, by examining various diagnostic markers, using a variety of machine learning as well as deep learning approaches, and involving XAI (explainable artificial intelligence) methods. Through the integration of patient data, including medical records, genetic profiles, algorithms using machine learning have the ability to predict how each individual will react to different medical interventions. To guarantee regulatory compliance and inspire confidence in AI-driven healthcare solutions, XAI is incorporated. Machine learning methods employed in this study includes Random Forest, decision trees, logistic regression, KNN, Adaboost, SVM, Catboost, LGBM classifier, and Xgboost whereas the deep learning methods include ANN and CNN. Four alternative XAI strategies, including SHAP, Eli5, LIME, and QLattice algorithm, are employed to comprehend the predictions of the model. The Xgboost, a ML model achieved accuracy, precision, recall, f1 score, and AUC of 88&#x0025;, 82&#x0025;, 94&#x0025;, 88&#x0025;, and 92&#x0025;, respectively. The best characteristics according to XAI techniques are IDH1, Age at diagnosis, PIK3CA, ATRX, PTEN, CIC, EGFR and TP53. By applying data analytic techniques, the objective is to provide healthcare professionals with practical tool that enhances their capacity for decision-making, enhances resource management, and ultimately raises the bar for patient care. Medical experts can customise treatments and improve patient outcomes by taking into account patient&#x2019;s particular characteristics. XAI provides justifications to foster faith amongst patients and medical professionals who must rely on AI-assisted diagnosis and treatment recommendations.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Anisha Palkar et al.",
      "keywords": "Computer science; Glioma; Artificial intelligence; Natural language processing; Medicine; Cancer research",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3370238",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392543811",
      "doi": "10.1109/access.2024.3374650",
      "title": "Federated Learning Approach for Breast Cancer Detection Based on DCNN",
      "abstract": "Breast cancer stands as one of the predominant health challenges globally, affecting millions of women every year and necessitating early and accurate detection to optimize patient outcomes. Currently, while deep convolutional neural networks (DCNNs) have shown promise in breast cancer detection, their application is often hampered by privacy concerns associated with sharing patient data and the limitation of training on small, localized datasets. Addressing these challenges, this manuscript introduces an effective federated learning approach tailored for breast cancer detection, leveraging DCNNs across diverse and large datasets without compromising data privacy. Our experimental findings underscore significant advancements in detection accuracy of 98.9&#x0025; on three large scale datasets which are VINDR-MAMMO, CMMD, and INBREAST. Additionally, we tested the proposed federated learning performance, showcasing the potential of our approach as a robust and privacy-preserving solution for future breast cancer diagnostic strategies.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Hussain AlSalman et al.",
      "keywords": "Computer science; Breast cancer; Artificial intelligence; Machine learning; Cancer; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3374650",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390605203",
      "doi": "10.1109/tnsre.2024.3350074",
      "title": "Epileptic Seizure Detection Based on Path Signature and Bi-LSTM Network With Attention Mechanism",
      "abstract": "Automatic seizure detection using electroen-cephalogram (EEG) can significantly expedite the diagnosis of epilepsy, thereby facilitating prompt treatment and reducing the risk of future seizures and associated complications. While most existing EEG-based epilepsy detection studies employ deep learning models, they often ignore the chronological relationships between different EEG channels. To tackle this limitation, a novel automatic epilepsy detection method is proposed, which leverages path signature and Bidirectional Long Short-Term Memory (Bi-LSTM) neural network with an attention mechanism. The path signature algorithm is used to extract discriminative features for capturing the dynamic dependencies between different channels of EEG, while Bi-LSTM with attention further analyzes the inherent temporal dependencies hidden in EEG signal features. Our method is evaluated on two public EEG databases with different sizes (CHB-MIT and TUEP) and a private database from a local hospital. Two experimental settings are used, i.e., five-fold cross-validation and leave-one-out cross-validation. Experimental results show that our method achieves 99.09%, 95.60%, and 99.87% average accuracies on CHB-MIT, TUEP with 250Hz, and TUEP with 256Hz, respectively. On the private dataset, our method also achieves 99.40% average accuracy, which outperforms other methods. Furthermore, our method exhibits robustness in patients, as demonstrated by the evaluation results of cross-patient experiments.",
      "year": "2024",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Yixuan Tang et al.",
      "keywords": "Mechanism (biology); Signature (topology); Path (computing); Computer science; Epilepsy; Artificial intelligence; Neuroscience; Epileptic seizure; Pattern recognition (psychology); Psychology; Computer network; Physics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2024.3350074",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312720000",
      "doi": "10.1109/access.2022.3217683",
      "title": "A Tertiary Review on Blockchain and Sustainability With Focus on Sustainable Development Goals",
      "abstract": "Sustainable development is crucial to securing the future of humanity. Blockchain as a disruptive technology and a driver for social change has exhibited great potential to promote sustainable practices and help organizations and governments achieve the United Nations&#x2019; Sustainable Development Goals (SDGs). Existing literature reviews on blockchain and sustainability often focus only on topics related to a few SDGs. There is a need to consolidate existing results in terms of SDGs and provide a comprehensive overview of the impacts that blockchain technology may have on each SDG. This paper intends to bridge this gap, presenting a tertiary review based on 42 literature reviews, to investigate the relationship between blockchain and sustainability in light of SDGs. The method used is a consensus-based expert elicitation with thematic analysis. The findings include a novel and comprehensive mapping of impact-based interlinkage of blockchain and SDGs and a systematic overview of drivers and barriers to adopting blockchain for sustainability. The findings reveal that blockchain can have a positive impact on all 17 SDGs though some negative effects can occur and impede the achievement of certain objectives. 76 positive and 10 negative linkages between blockchain adoption and the 17 SDGs as well as 45 factors that drive or hinder blockchain adoption for the achievement of SDGs have been identified. Research gaps to overcome the barriers and enhance blockchain&#x2019;s positive impacts have also been identified. The findings may help managers in evaluating the applicability and tradeoffs, and policymakers in making supportive measures to facilitate sustainability using blockchain.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Shanshan Jiang et al.",
      "keywords": "Blockchain; Sustainability; Sustainable development; Focus (optics); Computer science; Process management; Business; Computer security; Political science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3217683",
      "cited_by_count": 55,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2794958817",
      "doi": "10.1109/tmi.2018.2878509",
      "title": "Learning-Based Quality Control for Cardiac MR Images",
      "abstract": "The effectiveness of a cardiovascular magnetic resonance (CMR) scan depends on the ability of the operator to correctly tune the acquisition parameters to the subject being scanned and on the potential occurrence of imaging artifacts, such as cardiac and respiratory motion. In the clinical practice, a quality control step is performed by visual assessment of the acquired images; however, this procedure is strongly operator-dependent, cumbersome, and sometimes incompatible with the time constraints in clinical settings and large-scale studies. We propose a fast, fully automated, and learning-based quality control pipeline for CMR images, specifically for short-axis image stacks. Our pipeline performs three important quality checks: 1) heart coverage estimation; 2) inter-slice motion detection; 3) image contrast estimation in the cardiac region. The pipeline uses a hybrid decision forest method-integrating both regression and structured classification models-to extract landmarks and probabilistic segmentation maps from both long- and short-axis images as a basis to perform the quality checks. The technique was tested on up to 3000 cases from the UK Biobank and on 100 cases from the UK Digital Heart Project and validated against manual annotations and visual inspections performed by expert interpreters. The results show the capability of the proposed pipeline to correctly detect incomplete or corrupted scans (e.g., on UK Biobank, sensitivity and specificity, respectively, 88% and 99% for heart coverage estimation and 85% and 95% for motion detection), allowing their exclusion from the analyzed dataset or the triggering of a new acquisition.",
      "year": "2018",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Giacomo Tarroni et al.",
      "keywords": "Artificial intelligence; Computer science; Computer vision; Segmentation; Pipeline (software); Image quality; Image segmentation; Probabilistic logic; Visual inspection; Pattern recognition (psychology); Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2018.2878509",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4320712900",
      "doi": "10.1109/access.2023.3244741",
      "title": "Generative Adversarial Networks for Anomaly Detection in Biomedical Imaging: A Study on Seven Medical Image Datasets",
      "abstract": "Anomaly detection (AD) is a challenging problem in computer vision. Particularly in the field of medical imaging, AD poses even more challenges due to a number of reasons, including insufficient availability of ground truth (annotated) data. In recent years, AD models based on generative adversarial networks (GANs) have made significant progress. However, their effectiveness in biomedical imaging remains underexplored. In this paper, we present an overview of using GANs for AD, as well as an investigation of state-of-the-art GAN-based AD methods for biomedical imaging and the challenges encountered in detail. We have also specifically investigated the advantages and limitations of AD methods on medical image datasets, conducting experiments using 3 AD methods on 7 medical imaging datasets from different modalities and organs/tissues. Given the highly different findings achieved across these experiments, we further analyzed the results from both data-centric and model-centric points of view. The results showed that none of the methods had a reliable performance for detecting abnormalities in medical images. Factors such as the number of training samples, the subtlety of the anomaly, and the dispersion of the anomaly in the images are among the phenomena that highly impact the performance of the AD models. The obtained results were highly variable (AUC: 0.475-0.991; Sensitivity: 0.17-0.98; Specificity: 0.14-0.97). In addition, we provide recommendations for the deployment of AD models in medical imaging and foresee important research directions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Marzieh Esmaeili et al.",
      "keywords": "Computer science; Anomaly detection; Medical imaging; Artificial intelligence; Modalities; Ground truth; Generative grammar; Field (mathematics); Anomaly (physics); Machine learning; Software deployment; Image (mathematics); Deep learning; Pattern recognition (psychology); Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3244741",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387092456",
      "doi": "10.1109/access.2023.3320042",
      "title": "Ensemble Multifeatured Deep Learning Models and Applications: A Survey",
      "abstract": "Ensemble multifeatured deep learning methodology has emerged as a powerful approach to overcome the limitations of single deep learning models in terms of generalization, robustness, and performance. This survey provides an extended review of ensemble multifeatured deep learning models, and their applications, challenges, and future directions. We explore potential applications of these models across various domains, including computer vision, medical imaging, natural language processing, and speech recognition. By combining the strengths of multiple models and features, ensemble multifeatured deep learning models have demonstrated improved performance and adaptability in diverse problem settings. We also discuss the challenges associated with these models, such as model interpretability, computational complexity, ensemble model selection, adversarial robustness, and personalized and federated learning. This survey highlights recent advancements in addressing these challenges and emphasizes the importance of continued research in tackling these issues to enable widespread adoption of ensemble multifeatured deep learning models. It provides an outlook on future research directions, focusing on the development of new algorithms, frameworks, and hardware architectures that can efficiently handle the large-scale computations required by these models. Moreover, it underlines the need for a better understanding of the trade-offs between model complexity, accuracy, and computational resources to optimize the design and deployment of ensemble multifeatured deep learning models.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Satheesh Abimannan et al.",
      "keywords": "Computer science; Artificial intelligence; Ensemble learning; Deep learning; Machine learning; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3320042",
      "cited_by_count": 63,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285230897",
      "doi": "10.1109/access.2022.3175219",
      "title": "Toward Privacy Preservation Using Clustering Based Anonymization: Recent Advances and Future Research Outlook",
      "abstract": "With the continuous increase in avenues of personal data generation, privacy protection has become a hot research topic resulting in various proposed mechanisms to address this social issue. The main technical solutions for guaranteeing a user&#x2019;s privacy are encryption, pseudonymization, anonymization, differential privacy (DP), and obfuscation. Despite the success of other solutions, anonymization has been widely used in commercial settings for privacy preservation because of its algorithmic simplicity and low computing overhead. It facilitates unconstrained analysis of published data that DP and the other latest techniques cannot offer, and it is a mainstream solution for responsible data science. In this paper, we present a comprehensive analysis of clustering-based anonymization mechanisms (CAMs) that have been recently proposed to preserve both privacy and utility in data publishing. We systematically categorize the existing CAMs based on heterogeneous types of data (tables, graphs, matrixes, etc.), and we present an up-to-date, extensive review of existing CAMs and the metrics used for their evaluation. We discuss the superiority and effectiveness of CAMs over traditional anonymization mechanisms. We highlight the significance of CAMs in different computing paradigms, such as social networks, the internet of things, cloud computing, AI, and location-based systems with regard to privacy preservation. Furthermore, we present various proposed representative CAMs that compromise individual privacy, rather than safeguarding it. Besides, this article provides an extended knowledge (e.g., key assertion(s), strengths, weaknesses, clustering methods used in the anonymization process, and &#x0025;age improvements in quantitative results) about each technique that provides a clear view of how much this topic has been investigated thus far, and what are the research gaps that seek pertinent solutions in the near future. Finally, we discuss the technical challenges of applying CAMs, and we suggest promising opportunities for future research. To the best of our knowledge, this is the first work to systematically cover current CAMs involving different data types and computing paradigms.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Abdul Majeed et al.",
      "keywords": "Computer science; Differential privacy; Data publishing; Data science; Information privacy; Cluster analysis; Encryption; Cloud computing; Obfuscation; Overhead (engineering); Data anonymization; Compromise; Privacy software; Computer security; Data mining; Machine learning; Publishing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3175219",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4379468209",
      "doi": "10.1109/jproc.2023.3275192",
      "title": "Facial Micro-Expressions: An Overview",
      "abstract": "Micro-expression (ME) is an involuntary, fleeting, and subtle facial expression. It may occur in high-stake situations when people attempt to conceal or suppress their true feelings. Therefore, MEs can provide essential clues to people's true feelings and have plenty of potential applications, such as national security, clinical diagnosis, and interrogations. In recent years, ME analysis has gained much attention in various fields due to its practical importance, especially automatic ME analysis in computer vision as MEs are difficult to process by naked eyes. In this survey, we provide a comprehensive review of ME development in the field of computer vision, from the ME studies in psychology and early attempts in computer vision to various computational ME analysis methods and future directions. Four main tasks in ME analysis are specifically discussed, including ME spotting, ME recognition, ME action unit detection, and ME generation in terms of the approaches, advance developments, and challenges. Through this survey, readers can understand MEs in both aspects of psychology and computer vision, and apprehend the future research direction in ME analysis.",
      "year": "2023",
      "journal": "Proceedings of the IEEE",
      "authors": "Guoying Zhao et al.",
      "keywords": "Feeling; Field (mathematics); Action (physics); Computer science; Expression (computer science); Facial expression; Process (computing); Face (sociological concept); Human\u2013computer interaction; Data science; Psychology; Cognitive science; Artificial intelligence; Social psychology; Sociology; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2023.3275192",
      "cited_by_count": 71,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395661563",
      "doi": "10.1109/access.2024.3394030",
      "title": "Enhancing Lung Cancer Classification and Prediction With Deep Learning and Multi-Omics Data",
      "abstract": "Lung adenocarcinoma (LUAD), a prevalent histological type of lung cancer and a subtype of non-small cell lung cancer (NSCLC) accounts for 45&#x2013;55&#x0025; of all lung cancer cases. Various factors, including environmental influences and genetics, have been identified as contributors to the initiation and progression of LUAD. Recent large-scale analyses have probed into RNASeq, miRNA, and DNA methylation alterations in LUAD. In this study, we devised an innovative deep-learning model for lung cancer detection by integrating markers from mRNA, miRNA, and DNA methylation. The initial phase involved meticulous data preparation, encompassing multiple steps, followed by a differential analysis aimed at identifying genes exhibiting differential expression across different lung cancer stages (Stages I, II, III, and IV). The DESeq2 technique was employed for RNASeq data, while the LIMMA package was utilized for miRNA and DNA methylation datasets during the differential analysis. Subsequently, integration of all prepared omics data types was achieved by selecting common samples, resulting in a consolidated dataset comprising 448 samples and 8228 features (genes). To streamline features, principal components analysis (PCA) was implemented, and the synthetic minority over-sampling technique (SMOTE) algorithm was applied to ensure class balance. The integrated and processed data were then input into the PCA-SMOTE-CNN model for the classification process. The deep learning model, specifically designed for classifying and predicting lung cancer using an integrated omics dataset, was evaluated using various metrics, including precision, recall, F1-score, and accuracy. Experimental results emphasized the superior predictive performance of the proposed model, attaining an accuracy, precision, recall, and F1-score of 0.97 each, surpassing recent competitive methods.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Tehnan I. A. Mohamed et al.",
      "keywords": "Computer science; Artificial intelligence; Lung cancer; Deep learning; Cancer; Machine learning; Medicine; Oncology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3394030",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3046023260",
      "doi": "10.1109/jbhi.2020.3012383",
      "title": "Introducing the GEV Activation Function for Highly Unbalanced Data to Develop COVID-19 Diagnostic Models",
      "abstract": "Fast and accurate diagnosis is essential for the efficient and effective control of the COVID-19 pandemic that is currently disrupting the whole world. Despite the prevalence of the COVID-19 outbreak, relatively few diagnostic images are openly available to develop automatic diagnosis algorithms. Traditional deep learning methods often struggle when data is highly unbalanced with many cases in one class and only a few cases in another; new methods must be developed to overcome this challenge. We propose a novel activation function based on the generalized extreme value (GEV) distribution from extreme value theory, which improves performance over the traditional sigmoid activation function when one class significantly outweighs the other. We demonstrate the proposed activation function on a publicly available dataset and externally validate on a dataset consisting of 1,909 healthy chest X-rays and 84 COVID-19 X-rays. The proposed method achieves an improved area under the receiver operating characteristic (DeLong's p-value < 0.05) compared to the sigmoid activation. Our method is also demonstrated on a dataset of healthy and pneumonia vs. COVID-19 X-rays and a set of computerized tomography images, achieving improved sensitivity. The proposed GEV activation function significantly improves upon the previously used sigmoid activation for binary classification. This new paradigm is expected to play a significant role in the fight against COVID-19 and other diseases, with relatively few training cases available.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Joshua Bridge et al.",
      "keywords": "Sigmoid function; Coronavirus disease 2019 (COVID-19); Computer science; Activation function; Binary classification; Function (biology); Artificial intelligence; Receiver operating characteristic; Set (abstract data type); Value (mathematics); Binary number; Class (philosophy); Data mining; Pattern recognition (psychology); Machine learning; Medicine; Support vector machine; Artificial neural network; Mathematics; Pathology; Arithmetic",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2020.3012383",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4383200203",
      "doi": "10.1109/access.2023.3292551",
      "title": "An End-to-End Deep Learning Framework for Real-Time Denoising of Heart Sounds for Cardiac Disease Detection in Unseen Noise",
      "abstract": "<p dir=\"ltr\">The heart sound signals captured via a digital stethoscope are often distorted by environmental and physiological noise, altering their salient and critical properties. The problem is exacerbated in crowded low-resource hospital settings with high noise levels which degrades the diagnostic performance. In this study, we present a novel deep encoder-decoder-based denoising architecture (LU-Net) to suppress ambient and internal lung sound noises. Training is done using a large benchmark PCG dataset mixed with physiological noise, i.e., breathing sounds. Two different noisy datasets were prepared for experimental evaluation by mixing unseen lung sounds and hospital ambient noises with the clean heart sound recordings. We also used the inherently noisy portion of the PASCAL heart sound dataset for evaluation. The proposed framework showed effective suppression of background noises in both unseen real-world data and synthetically generated noisy heart sound recordings, improving the signal-to-noise ratio (SNR) level by 5.575 dB on an average using only 1.32 M parameters. The proposed model outperforms the current state-of-the-art U-Net model with an average SNR improvement of 5.613 dB and 5.537 dB in the presence of lung sound and unseen hospital noise, respectively. LU-Net also outperformed the state-of-the-art Fully Convolutional Network (FCN) by 1.750 dB and 1.748 dB for lung sound and unseen hospital noise conditions, respectively. In addition, the proposed denoising method model improves classification accuracy by 38.93% in the noisy portion of the PASCAL heart sound dataset. The results presented in the paper indicate that our proposed architecture demonstrated a robust denoising performance on different datasets with diverse levels and characteristics of noise. The proposed deep learning-based PCG denoising approach is a pioneering study that can significantly improve the accuracy of computer-aided auscultation systems for detecting cardiac diseases in noisy, low-resource hospitals and underserved communities. <h2>Other Information</h2><p dir=\"ltr\">Published in: IEEE Access<br>License: <a href=\"http://creativecommons.org/licenses/by/4.0\" target=\"_blank\">http://creativecommons.org/licenses/by/4.0</a><br>See article on publisher's website: <a href=\"https://dx.doi.org/10.1109/access.2023.3292551\" target=\"_blank\">https://dx.doi.org/10.1109/access.2023.3292551</a>",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Shams Nafisa Ali et al.",
      "keywords": "Noise reduction; Computer science; Speech recognition; Noise (video); Deep learning; Artificial intelligence; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3292551",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285160408",
      "doi": "10.1109/access.2022.3177651",
      "title": "Texture Attention Network for Diabetic Retinopathy Classification",
      "abstract": "Diabetic Retinopathy (DR) is a disease caused by a high level of glucose in retina vessels. This malicious disease put millions of people around the world at risk for vision loss each year. Being a life-threatening disease, early diagnosis can be an effective step in the treatment and prevention of vision loss. To automate the early diagnosis process, computer-aided diagnosis methods are not only useful in detecting the diabetic signatures but also provide information regarding the diabetic grade for the optometrist to determine an appropriate treatment. Several deep classification models are proposed in the literature to solve the diabetic retinopathy classification task, however, these methods usually lack incorporate an attention mechanism to better encode the semantic dependency and highlight the most important region for boosting the model performance. To overcome these limitations, we propose to incorporate a style and content recalibration mechanism inside the deep neural network to adaptively scale the informative regions for diabetic retinopathy classification. In our proposed method, the input image passes through the encoder module to encode both high-level and semantic features. Next, by utilizing a content and style separation mechanism, we decompose the representational space into a style (e.g., texture features) and content (e.g., semantic and contextual features) representation. The texture attention module takes the style representation and applies a high-pass filter to highlight the texture information while the spatial normalization module uses a convolutional operation to determine the more informative region inside the retinopathy image to detect diabetic signs. Once the attention modules are applied to the representational features, the fusion module combines both features to form a normalized representation for the decoding path. The decoder module in our model performs both diabetic grading and healthy, non-healthy classification tasks. Our experiment on APTOS Kaggle dataset (accuracy 0.85) demonstrates a significant improvement compared to the literature work. This fact reveals the applicability of our method in a real-world scenario.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mohammad D. Alahmadi",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Diabetic retinopathy; Feature extraction; Pattern recognition (psychology); Normalization (sociology); Computer vision; Diabetes mellitus; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3177651",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390422072",
      "doi": "10.1109/jbhi.2023.3348334",
      "title": "Exploring Nutritional Influence on Blood Glucose Forecasting for Type 1 Diabetes Using Explainable AI",
      "abstract": "Type 1 diabetes mellitus (T1DM) is characterized by insulin deficiency and blood sugar control issues. The state-of-the-art solution is the artificial pancreas (AP), which integrates basal insulin delivery and glucose monitoring. However, APs are unable to manage postprandial glucose response (PGR) due to limited knowledge of its determinants, requiring additional information for accurate bolus delivery, such as estimated carbohydrate intake. This study aims to quantify the influence of various meal-related factors on predicting postprandial blood glucose levels (BGLs) at different time intervals (15 min, 60 min, and 120 min) after meals by using deep neural network (DNN) models. The prediction models incorporate preprandial blood glucose values, insulin dosage, and various meal-related nutritional factors such as intake of energy, carbohydrates, proteins, lipids, fatty acids, fibers, glycemic index, and glycemic load as input variables. The impact of input features was assessed by exploiting eXplainable Artificial Intelligence (XAI) methodologies, specifically SHapley Additive exPlanations (SHAP), which provide insights into each feature's contribution to the model predictions. By leveraging XAI methodologies, this study aims to enhance the interpretability and transparency of BGL prediction models and validate clinical literature hypotheses. The findings can aid in the development of decision-support tools for individuals with T1DM, facilitating PGR management and reducing the risks of adverse events. The improved understanding of PGR determinants may lead to advancements in AP technology and improve the overall quality of life for T1DM patients.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Giovanni Annuzzi et al.",
      "keywords": "Postprandial; Interpretability; Insulin; Glycemic; Glycemic index; Type 1 diabetes; Blood sugar; Medicine; Computer science; Diabetes mellitus; Artificial intelligence; Internal medicine; Endocrinology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3348334",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3047125043",
      "doi": "10.1109/jbhi.2021.3069169",
      "title": "COVID-19 in CXR: From Detection and Severity Scoring to Patient Disease Monitoring",
      "abstract": "This work estimates the severity of pneumonia in COVID-19 patients and reports the findings of a longitudinal study of disease progression. It presents a deep learning model for simultaneous detection and localization of pneumonia in chest Xray (CXR) images, which is shown to generalize to COVID-19 pneumonia. The localization maps are utilized to calculate a \"Pneumonia Ratio\" which indicates disease severity. The assessment of disease severity serves to build a temporal disease extent profile for hospitalized patients. To validate the model's applicability to the patient monitoring task, we developed a validation strategy which involves a synthesis of Digital Reconstructed Radiographs (DRRs - synthetic Xray) from serial CT scans; we then compared the disease progression profiles that were generated from the DRRs to those that were generated from CT volumes.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Maayan Frid-Adar et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3069169",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4383899644",
      "doi": "10.1109/access.2023.3294443",
      "title": "Redefining Retinal Lesion Segmentation: A Quantum Leap With DL-UNet Enhanced Auto Encoder-Decoder for Fundus Image Analysis",
      "abstract": "The first diagnosis of diabetic retinopathy (DR) must include lesion segmentation. As it takes a lot of time and effort to label lesions, automatic segmentation methods have to be created manually. The degree of the retina&#x2019;s degenerative lesions determines how severe diabetic retinopathy is. A major influence is on the early detection of illness and treatment of DR. To reliably identify the sites of related lesions and identify various abnormalities in retinal fundus pictures, deep learning algorithms are crucial. Additionally, utilizing patch-based analysis, a deep convolutional neural network is constructed. In this study, encoder-decoder neural networks along with channel-wise spatial Attention Mechanisms are proposed. The IDRiD dataset, which includes hard exudate segmentations, is used to train and evaluate the architecture. In this method, image patches are created using the sliding window technique. To determine the effectiveness of the recommended strategy, a thorough experiment was conducted on IDRiD. In order to predict the various sorts of lesions, the trained network analyses the picture patches and creates a probability map. This technique&#x2019;s efficacy and supremacy are confirmed by the expected accuracy of 99.94 &#x0025;. The findings of this experiment show significantly enhanced performance in terms of accuracy when compared to prior research on comparable tasks.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "B. Naveen Kumar et al.",
      "keywords": "Computer science; Artificial intelligence; Segmentation; Convolutional neural network; Fundus (uterus); Deep learning; Diabetic retinopathy; Image segmentation; Pattern recognition (psychology); Encoder; Computer vision; Sliding window protocol; Medicine; Window (computing); Ophthalmology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3294443",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3123479206",
      "doi": "10.1109/access.2021.3054613",
      "title": "Explainability Metrics of Deep Convolutional Networks for Photoplethysmography Quality Assessment",
      "abstract": "Photoplethysmography (PPG) is a noninvasive way to monitor various aspects of the circulatory system, and is becoming more and more widespread in biomedical processing. Recently, deep learning methods for analyzing PPG have also become prevalent, achieving state of the art results on heart rate estimation, atrial fibrillation detection, and motion artifact identification. Consequently, a need for interpretable deep learning has arisen within the field of biomedical signal processing. In this paper, we pioneer novel explanatory metrics which leverage domain-expert knowledge to validate a deep learning model. We visualize model attention over a whole testset using saliency methods and compare it to human expert annotations. Congruence, our first metric, measures the proportion of model attention within expert-annotated regions. Our second metric, Annotation Classification, measures how much of the expert annotations our deep learning model pays attention to. Finally, we apply our metrics to compare between a signal based model and an image based model for PPG signal quality classification. Both models are deep convolutional networks based on the ResNet architectures. We show that our signal-based one dimensional model acts in a more explainable manner than our image based model; on average 50.78% of the one dimensional model's attention are within expert annotations, whereas 36.03% of the two dimensional model's attention are within expert annotations. Similarly, when thresholding the one dimensional model attention, one can more accurately predict if each pixel of the PPG is annotated as artifactual by an expert. Through this testcase, we demonstrate how our metrics can provide a quantitative and dataset-wide analysis of how explainable the model is.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Oliver Zhang et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Leverage (statistics); Machine learning; Metric (unit); Photoplethysmogram; Pattern recognition (psychology); Computer vision; Filter (signal processing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3054613",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3082167223",
      "doi": "10.1109/taffc.2020.3021015",
      "title": "Ethics and Good Practice in Computational Paralinguistics",
      "abstract": "With the advent of 'heavy Artificial Intelligence' \u2013 big data, deep learning, and ubiquitous use of the internet, ethical considerations are widely dealt with in public discussions and governmental bodies. Within Computational Paralinguistics with its manifold topics and possible applications (modelling of long-term, medium-term, and short-term traits and states such as personality, emotion, or speech pathology), we have not yet seen that many contributions. In this article, we try to set the scene by (1) giving a short overview of ethics and privacy, (2) describing the field of Computational Paralinguistics, its history and exemplary use cases, as well as (de-)anonymisation and peculiarities of speech and text data, and (3) proposing rules for good practice in the field, such as choosing the right performance measure, and accounting for representativity and interpretability.",
      "year": "2020",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Anton Batliner et al.",
      "keywords": "Interpretability; Field (mathematics); Set (abstract data type); Big data; Computer science; Term (time); Data science; Personality; The Internet; Artificial intelligence; Psychology; World Wide Web; Data mining; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taffc.2020.3021015",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4221163971",
      "doi": "10.1109/tnnls.2022.3183864",
      "title": "Targeted-BEHRT: Deep Learning for Observational Causal Inference on Longitudinal Electronic Health Records",
      "abstract": "Observational causal inference is useful for decision-making in medicine when randomized clinical trials (RCTs) are infeasible or nongeneralizable. However, traditional approaches do not always deliver unconfounded causal conclusions in practice. The rise of \"doubly robust\" nonparametric tools coupled with the growth of deep learning for capturing rich representations of multimodal data offers a unique opportunity to develop and test such models for causal inference on comprehensive electronic health records (EHRs). In this article, we investigate causal modeling of an RCT-established causal association: the effect of classes of antihypertensive on incident cancer risk. We develop a transformer-based model, targeted bidirectional EHR transformer (T-BEHRT) coupled with doubly robust estimation to estimate average risk ratio (RR). We compare our model to benchmark statistical and deep learning models for causal inference in multiple experiments on semi-synthetic derivations of our dataset with various types and intensities of confounding. In order to further test the reliability of our approach, we test our model on situations of limited data. We find that our model provides more accurate estimates of relative risk [least sum absolute error (SAE) from ground truth] compared with benchmark estimations. Finally, our model provides an estimate of class-wise antihypertensive effect on cancer risk that is consistent with results derived from RCTs.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Shishir Rao et al.",
      "keywords": "Observational study; Causal inference; Health records; Inference; Electronic health record; Artificial intelligence; Psychology; Machine learning; Data science; Computer science; Medicine; Econometrics; Internal medicine; Mathematics; Health care; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnnls.2022.3183864",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295788789",
      "doi": "10.1109/access.2022.3206449",
      "title": "A Survey on Attention Mechanisms for Medical Applications: are we Moving Toward Better Algorithms?",
      "abstract": "The increasing popularity of attention mechanisms in deep learning algorithms for computer vision and natural language processing made these models attractive to other research domains. In healthcare, there is a strong need for tools that may improve the routines of the clinicians and the patients. Naturally, the use of attention-based algorithms for medical applications occurred smoothly. However, being healthcare a domain that depends on high-stake decisions, the scientific community must ponder if these high-performing algorithms fit the needs of medical applications. With this motto, this paper extensively reviews the use of attention mechanisms in machine learning methods (including Transformers) for several medical applications based on the types of tasks that may integrate several works pipelines of the medical domain. This work distinguishes itself from its predecessors by proposing a critical analysis of the claims and potentialities of attention mechanisms presented in the literature through an experimental case study on medical image classification with three different use cases. These experiments focus on the integrating process of attention mechanisms into established deep learning architectures, the analysis of their predictive power, and a visual assessment of their saliency maps generated by post-hoc explanation methods. This paper concludes with a critical analysis of the claims and potentialities presented in the literature about attention mechanisms and proposes future research lines in medical applications that may benefit from these frameworks.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Tiago Gon\u00e7alves et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Domain (mathematical analysis); Deep learning; Data science; Popularity; Process (computing); Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3206449",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3164720667",
      "doi": "10.1109/access.2021.3082423",
      "title": "A Sensitivity Analysis of Biophysiological Responses of Stress for Wearable Sensors in Connected Health",
      "abstract": "Stress is known as a silent killer that contributes to several life-threatening health conditions such as high blood pressure, heart disease, and diabetes. The current standard for stress evaluation is based on self-reported questionnaires and standardized stress scores. There is no gold standard to independently evaluate stress levels despite the availability of numerous biophysiological stress indicators. With an increasing interest in wearable health monitoring in recent years, several studies have explored the potential of various biophysiological indicators of stress for this purpose. However, there is no clear understanding of the relative sensitivity and specificity of these stress-related biophysiological indicators of stress in the literature. Hence this study aims to perform statistical analysis and classification modelling of biophysiological data gathered from healthy individuals, undergoing various induced emotional states, and to assess the relative sensitivity and specificity of common biophysiological indicators of stress. In this paper, several frequently used key indicators of stress, such as heart rate, respiratory rate, skin conductance, RR interval, heart rate variability in the electrocardiogram, and muscle activation measured by electromyography, are evaluated based on a detailed statistical analysis of the data gathered from an already existing, publicly available WESAD (Wearable Stress and Affect Detection) dataset. Respiratory rate and heart rate were the two best features for distinguishing between stressed and unstressed states.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Talha Iqbal et al.",
      "keywords": "Stress (linguistics); Respiratory rate; Heart rate; Heart rate variability; Computer science; Blood pressure; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3082423",
      "cited_by_count": 52,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3049505819",
      "doi": "10.1109/jbhi.2020.3016831",
      "title": "Blind Monaural Source Separation on Heart and Lung Sounds Based on Periodic-Coded Deep Autoencoder",
      "abstract": "Auscultation is the most efficient way to diagnose cardiovascular and respiratory diseases. To reach accurate diagnoses, a device must be able to recognize heart and lung sounds from various clinical situations. However, the recorded chest sounds are mixed by heart and lung sounds. Thus, effectively separating these two sounds is critical in the pre-processing stage. Recent advances in machine learning have progressed on monaural source separations, but most of the well-known techniques require paired mixed sounds and individual pure sounds for model training. As the preparation of pure heart and lung sounds is difficult, special designs must be considered to derive effective heart and lung sound separation techniques. In this study, we proposed a novel periodicity-coded deep auto-encoder (PC-DAE) approach to separate mixed heart-lung sounds in an unsupervised manner via the assumption of different periodicities between heart rate and respiration rate. The PC-DAE benefits from deep-learning-based models by extracting representative features and considers the periodicity of heart and lung sounds to carry out the separation. We evaluated PC-DAE on two datasets. The first one includes sounds from the Student Auscultation Manikin (SAM), and the second is prepared by recording chest sounds in real-world conditions. Experimental results indicate that PC-DAE outperforms several well-known separation works in terms of standardized evaluation metrics. Moreover, waveforms and spectrograms demonstrate the effectiveness of PC-DAE compared to existing approaches. It is also confirmed that by using the proposed PC-DAE as a pre-processing stage, the heart sound recognition accuracies can be notably boosted. The experimental results confirmed the effectiveness of PC-DAE and its potential to be used in clinical applications.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Kun-Hsi Tsai et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2020.3016831",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4294691681",
      "doi": "10.1109/access.2022.3204703",
      "title": "A Self-Contained STFT CNN for ECG Classification and Arrhythmia Detection at the Edge",
      "abstract": "Automated classification of Electrocardiogram (ECG) for arrhythmia monitoring is the core of cardiovascular disease diagnosis. Machine Learning (ML) is widely used for arrhythmia detection. The cloud-based inference is the prevailing deployment model of modern ML algorithms which does not always meet the availability and privacy requirements of ECG monitoring. Edge inference is an emerging alternative that addresses the concerns of latency, privacy, connectivity, and availability. However, edge deployment of ML models is challenging due to the demanding requirements of modern ML algorithms and the computation constraints of edge devices. In this work, we propose a lightweight self-contained short-time Fourier Transform (STFT) Convolutional Neural Network (CNN) model for ECG classification and arrhythmia detection in real-time at the edge. We provide a clear interpretation of the convolutional layer as a Finite Impulse Response (FIR) filter and exploit this interpretation to develop an STFT-based 1D convolutional (Conv1D) layer to extract the spectrogram of the input ECG signal. The Conv1D output feature maps are reshaped into a 2D heatmap image and fed to a 2D convolutional (Conv2D) neural network (CNN) for classification. The MIT-BIH arrhythmia database is used for model training and testing. Four model variants are trained and tested on a cloud machine and then optimized for edge computing on a raspberry-pi device. Weight quantization and pruning techniques are applied to optimize the developed models for edge inference. The proposed classifier can achieve up to 99.1&#x0025; classification accuracy and 95&#x0025; F1-score at the edge with a maximum model size of 90 KB, an average inference time of 9 ms, and a maximum memory usage of 12 MB. The achieved results of the proposed classifier enable its deployment on a wide range of edge devices for arrhythmia monitoring.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mohammed M. Farag",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Edge computing; Short-time Fourier transform; Pattern recognition (psychology); Feature extraction; Deep learning; Inference; Edge device; Feature (linguistics); Machine learning; Enhanced Data Rates for GSM Evolution; Cloud computing; Fourier transform",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3204703",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3148814392",
      "doi": "10.1109/access.2021.3069024",
      "title": "Targeted Ensemble Machine Classification Approach for Supporting IoT Enabled Skin Disease Detection",
      "abstract": "The fast development of the Internet of Things (IoT) changes our life in many areas, especially in the health domain. For example, remote disease diagnosis can be achieved more efficiently with advanced IoT-technologies which not only include hardware but also smart IoT data processing and learning algorithms, e.g. image-based disease classification. In this paper, we work in a specific area of skin condition classification. This research work aims to provide an implementable solution for IoT-led remote skin disease diagnosis applications. The research output can be concluded into three folders. The first folder is about dynamic AI model configuration supported IoT-Fog-Cloud remote diagnosis architecture with hardware examples. The second folder is the evaluation survey regarding the performances of machine learning models for skin disease detection. The evaluation contains a variety of data processing methods and their aggregations. The evaluation takes account of both training-testing and cross-testing validations on all seven conditions and individual condition. In addition, the HAM10000 dataset is picked for the evaluation process according to the suitability comparisons to other relevant datasets. In the evaluation, we discuss the earlier work of ANN, SVM and KNN models, but the evaluation process mainly focuses on six widely applied Deep Learning models of VGG16, Inception, Xception, MobileNet, ResNet50 and DenseNet161. The result shows that each of the top four models for the major seven skin conditions has better performance for the specific condition than others. Based on the evaluation discovery, the last folder proposes a novel classification approach of the Targeted Ensemble Machine Classify Model (TEMCM) to enable dynamically combining a suitable model in a two-phase detection process. The final evaluation result shows the proposed model can archive better performance.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hong Qing Yu et al.",
      "keywords": "Computer science; Machine learning; Cloud computing; Internet of Things; Process (computing); Artificial intelligence; Support vector machine; Domain (mathematical analysis); Contextual image classification; Architecture; Embedded system; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3069024",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3196024535",
      "doi": "10.1109/access.2021.3106120",
      "title": "A Survey on Skill Identification From Online Job Ads",
      "abstract": "A changing job market, influenced by different factors such as globalization and demographic growth, urges close monitoring. The digitization of the job market has given the opportunity to researchers to better understand job market needs as job postings/ads become more accessible. However, such postings are submitted in unstructured text and need further processing to identify the required skills. The aim of this survey is to review current research on skill identification from job ads and to discuss possible future research directions. In this study, we systematically reviewed 108 research articles on the topic. In particular, we evaluated and classified the prior work aiming to identify the skill bases used for analyzing job market needs; the type of extracted skills; the skill identification methods; the studied sector and the skill identification granularity. Then, we categorized the existent applications and goals of skill identification. Finally, we present key challenges and discuss recent trends.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Imane Khaouja et al.",
      "keywords": "Identification (biology); Computer science; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3106120",
      "cited_by_count": 82,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389332131",
      "doi": "10.1109/access.2023.3339635",
      "title": "Deep Learning-Based Dermatological Condition Detection: A Systematic Review With Recent Methods, Datasets, Challenges, and Future Directions",
      "abstract": "Dermatological conditions are a global health concern affecting all age groups. They encompass various skin issues such as rashes, moles, acne, blisters, hives, nodules, cysts, macules, and papules. Early diagnosis of dermatological conditions is crucial to prevent skin damage and chronic diseases. Recent advancements in artificial intelligence and medical image processing, particularly through deep learning, have significantly improved the precision and efficiency of dermatological disease detection by dermatologists. This paper thoroughly examines deep learning-based methods for detecting dermatological conditions from dermoscopic images. Specifically, it presents study of 22 methods that are used to detect dermatological conditions such as basal cell carcinoma, melanocytic nevus, seborrheic keratosis, psoriasis, benign keratosis, melanoma, acne, cold sore, warts, eczema, hives, shingles, scar, skin tag, inflammatory hyper pigment, cyst, dark circle, blackhead, burn and skin rash. It also covers clinical diagnostic methods for dermatological conditions and the need for computer-aided diagnosis. In this paper, we have also proposed the categorization of deep learning-based dermatological condition detection methods. Moreover, a comprehensive summary of these methods is presented. In addition, this paper summarizes the majority of the datasets available for computer-aided detection of dermatological conditions. Furthermore, it presents enormous challenges and potential future research directions. This survey informs researchers about the latest advancements in deep learning-based detection methods for dermatological conditions and allows dermatologists to stay updated on technological breakthroughs in this area.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Stephanie Noronha et al.",
      "keywords": "Dermatology; Seborrheic keratosis; Medicine; Acne; Dermatological diseases; Actinic keratosis; Deep learning; Artificial intelligence; Computer science; Basal cell; Pathology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3339635",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385222884",
      "doi": "10.1109/access.2023.3298371",
      "title": "Unleashing the Potential of Blockchain and Machine Learning: Insights and Emerging Trends From Bibliometric Analysis",
      "abstract": "Blockchain and machine learning (ML) has garnered growing interest as cutting-edge technologies that have witnessed tremendous strides in their respective domains. Blockchain technology provides a decentralized and immutable ledger, enabling secure and transparent transactions without intermediaries. Alternatively, ML is a sub-field of artificial intelligence (AI) that empowers systems to enhance their performance by learning from data. The integration of these data-driven paradigms holds the potential to reinforce data privacy and security, improve data analysis accuracy, and automate complex processes. The confluence of blockchain and ML has sparked increasing interest among scholars and researchers. Therefore, a bibliometric analysis is carried out to investigate the key focus areas, hotspots, potential prospects, and dynamical aspects of the field. This paper evaluates 700 manuscripts drawn from the Web of Science (WoS) core collection database, spanning from 2017 to 2022. The analysis is conducted using advanced bibliometric tools (e.g., Bibliometrix R, VOSviewer, and CiteSpace) to assess various aspects of the research area regarding publication productivity, influential articles, prolific authors, the productivity of academic countries and institutions, as well as the intellectual structure in terms of hot topics and emerging trends. The findings suggest that upcoming research should focus on blockchain technology, AI-powered 5G networks, industrial cyber-physical systems, IoT environments, and autonomous vehicles. This paper provides a valuable foundation for both academic scholars and practitioners as they contemplate future projects on the integration of blockchain and ML.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nouhaila El Akrami et al.",
      "keywords": "Blockchain; Computer science; Data science; Field (mathematics); Bibliometrics; Productivity; Big data; Knowledge management; World Wide Web; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3298371",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3215635203",
      "doi": "10.1109/access.2021.3130610",
      "title": "A Comprehensive Analysis of Privacy Protection Techniques Developed for COVID-19 Pandemic",
      "abstract": "Since the emergence of coronavirus disease&#x2013;2019 (COVID-19) outbreak, every country has implemented digital solutions in the form of mobile applications, web-based frameworks, and/or integrated platforms in which huge amounts of personal data are collected for various purposes (e.g., contact tracing, suspect search, and quarantine monitoring). These systems not only collect basic data about individuals but, in most cases, very sensitive data like their movements, spatio-temporal activities, travel history, visits to churches/clubs, purchases, and social interactions. While collection and utilization of person-specific data in different contexts is essential to limiting the spread of COVID-19, it increases the chances of privacy breaches and personal data misuse. Recently, many privacy protection techniques (PPTs) have been proposed based on the person-specific data included in different data types (e.g., tables, graphs, matrixes, barcodes, and geospatial data), and epidemic containment strategies (ECSs) (contact tracing, quarantine monitoring, symptom reports, etc.) in order to minimize privacy breaches and to permit only the intended uses of such personal data. In this paper, we present an extensive review of the PPTs that have been recently proposed to address the diverse privacy requirements/concerns stemming from the COVID-19 pandemic. We describe the heterogeneous types of data collected to control this pandemic, and the corresponding PPTs, as well as the paradigm shifts in personal data handling brought on by this pandemic. We systemically map the recently proposed PPTs into various ECSs and data lifecycle phases, and present an in-depth review of existing PPTs and evaluation metrics employed for analysis of their suitability. We describe various PPTs developed during the COVID-19 period that leverage emerging technologies, such as federated learning, blockchain, privacy by design, and swarm learning, to name a few. Furthermore, we discuss the challenges of preserving individual privacy during a pandemic, the role of privacy regulations/laws, and promising future research directions. With this article, our aim is to highlight the recent PPTs that have been specifically proposed for the COVID-19 arena, and point out research gaps for future developments in this regard.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Abdul Majeed et al.",
      "keywords": "Contact tracing; Computer science; Internet privacy; Pandemic; Coronavirus disease 2019 (COVID-19); Geospatial analysis; Data Protection Act 1998; Computer security; Information privacy; Data collection; Containment (computer programming); Data science; Geography; Infectious disease (medical specialty); Remote sensing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3130610",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377861896",
      "doi": "10.1109/tnnls.2023.3270027",
      "title": "Toward Explainable Affective Computing: A Review",
      "abstract": "Affective computing has an unprecedented potential to change the way humans interact with technology. While the last decades have witnessed vast progress in the field, multimodal affective computing systems are generally black box by design. As affective systems start to be deployed in real-world scenarios, such as education or healthcare, a shift of focus toward improved transparency and interpretability is needed. In this context, how do we explain the output of affective computing models? and how to do so without limiting predictive performance? In this article, we review affective computing work from an explainable AI (XAI) perspective, collecting and synthesizing relevant papers into three major XAI approaches: premodel (applied before training), in-model (applied during training), and postmodel (applied after training). We present and discuss the most fundamental challenges in the field, namely, how to relate explanations back to multimodal and time-dependent data, how to integrate context and inductive biases into explanations using mechanisms such as attention, generative modeling, or graph-based methods, and how to capture intramodal and cross-modal interactions in post hoc explanations. While explainable affective computing is still nascent, existing methods are promising, contributing not only toward improved transparency but, in many cases, surpassing state-of-the-art results. Based on these findings, we explore directions for future research and discuss the importance of data-driven XAI and explanation goals, and explainee needs definition, as well as causability or the extent to which a given method leads to human understanding.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Karina Corti\u00f1as-Lorenzo et al.",
      "keywords": "Computer science; Interpretability; Affective computing; Transparency (behavior); Data science; Field (mathematics); Context (archaeology); Generative grammar; Ubiquitous computing; Artificial intelligence; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tnnls.2023.3270027",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226128579",
      "doi": "10.1109/jsen.2022.3164057",
      "title": "On-Line Algorithms of Stride-Parameter Estimation for in-Shoe Motion-Sensor System",
      "abstract": "We propose two on-line algorithms for stride parameter estimation for an in-shoe motion-sensor system (IMS) system: one for on-line stride segmentation based on stable foot-flat detection using foot-sole angle and the other for a three-dimensional zero-velocity-update for accurate stride parameterization. We developed a small and lightweight IMS device, which consists of an inertial measurement unit, micro control unit, and peripheral electrical components, integrated with an insole so that it can be placed inside a shoe at the arch of the foot. Stride parameters, i.e., stride length, walking speed, foot height, circumduction, peak foot sole angle in the dorsiflexion and plantarflexion directions, and toe-in <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$/$ </tex-math></inline-formula> out angle, that characterize a user's foot motion are estimated. We recruited 30 healthy participants and evaluated the precision of our IMS system by comparing the stride parameters calculated with this system with those acquired from a motion-capture system. The results indicate the precision of the system in terms of the root mean square error for stride length of 0.069 m, walking speed of 0.094 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\text{m}/\\text{s}$ </tex-math></inline-formula> , foot height of 1.5 cm, circumduction of 1.0 cm, peak foot-sole angle in the dorsiflexion of 3.3 deg. and in the plantarflexion directions of 5.9 deg., and toe-in <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$/$ </tex-math></inline-formula> out angle of 2.5 deg. Our IMS system has good precision regarding all parameters and high reliability and promises to contribute to personal health and wellness services and solutions by serving as a powerful and practical tool for objective gait assessment in real-world contexts.",
      "year": "2022",
      "journal": "IEEE Sensors Journal",
      "authors": "Kenichiro Fukushi et al.",
      "keywords": "STRIDE; Algorithm; Gait; Foot (prosody); Inertial measurement unit; Mathematics; Accelerometer; Computer science; Simulation; Artificial intelligence; Physical medicine and rehabilitation",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2022.3164057",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385413436",
      "doi": "10.1109/access.2023.3299850",
      "title": "TS-CNN: A Three-Tier Self-Interpretable CNN for Multi-Region Medical Image Classification",
      "abstract": "Medical image classification is critical, where reliability and transparency are crucial for the safe and accurate diagnosis of diseases. Deep Convolutional Neural Networks (DCNNs) are widely used in medical image classification due to their high performance. However, they are often considered black-boxes because they offer little insight into decision-making. Therefore, improving the interpretability of DCNNs is crucial for their adoption in medical diagnoses. This paper proposes a novel three-tier self-interpretable DCNN (TS-CNN) architecture for multi-region medical image classification, which improves classification performance while being inherently interpretable. The proposed TS-CNN architecture is well-suited for medical images with multiple regions, such as images with scattered and randomly shaped lesions. The proposed architecture has three branches: a global branch that learns the relevant patterns from the raw input image; an attention branch that selects the important regions and discards the irrelevant parts for the local branch to learn; and a fusion branch that distills knowledge from both the global and local branches for classification. The proposed architecture is flexible in terms of the backbone CNNs used for classification and post-hoc interpretability methods used for attention capture. We demonstrate the flexibility and generalization of the architecture through a series of experiments involving multiple state-of-the-art CNN architectures such as DenseNet-121, Inception, Xception, and ResNet-50 as the global/local branches, each paired with GradCAM and Saliency maps as attention modules. The proposed architecture outperformed the backbone model in classification tasks on two datasets: a custom-made blob dataset and a publicly available skin lesion PAD-UFES-20 dataset, demonstrating its potential for improving accuracy in medical image classification tasks. The code related to this work can be found at: <uri>https://github.com/sikha2552/TS-CNN-A-Three-Tier-Self-Interpretable-CNN-for-Medical-Image-Classification-Empowered-with-Post-hoc.git</uri>.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "V A Ashwath et al.",
      "keywords": "Interpretability; Computer science; Convolutional neural network; Artificial intelligence; Pattern recognition (psychology); Contextual image classification; Medical diagnosis; Generalization; Architecture; Image (mathematics); Backbone network; Deep learning; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3299850",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365790409",
      "doi": "10.1109/access.2023.3266826",
      "title": "MCAD: A Machine Learning Based Cyberattacks Detector in Software-Defined Networking (SDN) for Healthcare Systems",
      "abstract": "The healthcare sector deals with sensitive and significant data that must be protected against illegitimate users. Software-defined networks (SDNs) are widely used in healthcare systems to ensure efficient resource utilization, security, optimal network control, and management. Despite such advantages, SDNs suffer from a major issue posed by a wide range of cyberattacks, due to the sensitivity of patients&#x2019; data. These attacks diminish the overall network performance, and can cause a network failure that might threaten human lives. Therefore, the main goal of our work is to propose a machine learning-based cyberattack detector (MCAD) for healthcare systems, by adapting a layer three (L3) learning switch application to collect normal and abnormal traffic, and then deploy MCAD on the Ryu controller. Our findings are beneficial for enhancing the security of healthcare applications by mitigating the impact of cyberattacks. This work covers the testing of MCAD using a wide spectrum of both ML algorithms and attacks, and provides a performance comparison for every pair of ML algorithms/attacks to illustrate the strengths and weaknesses of different algorithms against a specific attack. The MCAD shows impressive performance, achieving an F1-score of 0.9998 and of 0.9882 on normal and attack classes, respectively, which implies a high level of reliability. MCAD also achieved 5,709,692 samples per second on throughput, which reflects a high-performance real-time system with respect to complexity. Additionally, it showed a positive impact on the network KPIs by increasing the throughput by 609&#x0025;, and decreasing delay and jitter by 77&#x0025; and 23&#x0025;, respectively, compared to attack results.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Laila M. Halman et al.",
      "keywords": "Software-defined networking; Computer science; Software; Health care; Networking hardware; Computer network; Computer security; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3266826",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394711303",
      "doi": "10.1109/access.2024.3387702",
      "title": "A Framework for Interpretability in Machine Learning for Medical Imaging",
      "abstract": "Interpretability for machine learning models in medical imaging (MLMI) is an important direction of research. However, there is a general sense of murkiness in what interpretability means. Why does the need for interpretability in MLMI arise? What goals does one actually seek to address when interpretability is needed? To answer these questions, we identify a need to formalize the goals and elements of interpretability in MLMI. By reasoning about real-world tasks and goals common in both medical image analysis and its intersection with machine learning, we identify five core elements of interpretability: localization, visual recognizability, physical attribution, model transparency, and actionability. From this, we arrive at a framework for interpretability in MLMI, which serves as a step-by-step guide to approaching interpretability in this context. Overall, this paper formalizes interpretability needs in the context of medical imaging, and our applied perspective clarifies concrete MLMI-specific goals and considerations in order to guide method design and improve real-world usage. Our goal is to provide practical and didactic information for model designers and practitioners, inspire developers of models in the medical imaging field to reason more deeply about what interpretability is achieving, and suggest future directions of interpretability research.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Alan Q. Wang et al.",
      "keywords": "Interpretability; Computer science; Artificial intelligence; Medical imaging; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3387702",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382138597",
      "doi": "10.1109/access.2023.3289584",
      "title": "Heart Disease Prediction Using Novel Quine McCluskey Binary Classifier (QMBC)",
      "abstract": "Cardiovascular disease is the primary reason for mortality worldwide, responsible for around a third of all deaths. To assist medical professionals in quickly identifying and diagnosing patients, numerous machine learning and data mining techniques are utilized to predict the disease. Many researchers have developed various models to boost the efficiency of these predictions. Feature selection and extraction techniques are utilized to remove unnecessary features from the dataset, thereby reducing computation time and increasing the efficiency of the models. In this study, we introduce a new ensemble Quine McCluskey Binary Classifier (QMBC) technique for identifying patients diagnosed with some form of heart disease and those who are not diagnosed. The QMBC model utilizes an ensemble of seven models, including logistic regression, decision tree, random forest, K-nearest neighbour, naive bayes, support vector machine, and multilayer perceptron, and performs exceptionally well on binary class datasets. We employ feature selection and feature extraction techniques to accelerate the prediction process. We utilize Chi-Square and ANOVA approaches to identify the top 10 features and create a subset of the dataset. We then apply Principal Component Analysis to the subset to identify 9 prime components. We utilize an ensemble of all seven models and the Quine McCluskey technique to obtain the Minimum Boolean expression for the target feature. The results of the seven models ( x_0, x_1, x_2,\u22d6, x_6 ) are considered independent features, while the target attribute is dependent. We combine the projected outcomes of the seven ML models and the target feature to form a foaming dataset. We apply the ensemble model to the dataset, utilizing the Quine McCluskey minimum Boolean equation built with an 80:20 train-to-test ratio. Our proposed QMBC model surpasses all current state-of-the-art models and previously suggested methods put forward by various researchers.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ramdas Kapila et al.",
      "keywords": "Artificial intelligence; Computer science; Naive Bayes classifier; Feature selection; Machine learning; Random forest; Support vector machine; Classifier (UML); Pattern recognition (psychology); Perceptron; Data mining; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3289584",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210277770",
      "doi": "10.1109/access.2022.3148279",
      "title": "Comparison of Neural Language Modeling Pipelines for Outcome Prediction From Unstructured Medical Text Notes",
      "abstract": "Machine learning techniques and algorithm-based approaches are becoming more and more vital to support clinical decision-making. In the medical area, natural language processing (NLP) techniques have shown the ability to extract useful information from electronic health records. On the one hand, statistic, semantic, and contextualized word embedding-based models and on the other hand preprocessing approaches are the keys to a better representation of a document. Using narratives from the Intensive Care Unit, we elaborated a comparison of the most used methods and preprocessing approaches to tackle an outcome prediction problem and guide researchers into NLP pipelines in the medical area. We used real data from Medical Information Mart for Intensive Care-III (MIMIC-III). We selected all notes related to patients with pneumonia. We conducted a deep analysis on text preprocessing tasks producing three datasets: raw data with minor preprocessing, meticulous preprocessing, and extreme preprocessing filtering only medical-related terminologies using Named Entity Recognition algorithms. We then used these three sets in five models, of which two are based on the traditional noncontextual word embedding techniques and three use contextualized word embedding based on a transformer. We demonstrated that transformer-based models outperform other word embedding models and a profound preprocessing yielded an accuracy of 98.2 F1-score. These results show the highly competitive ability of NLP predictive models against other models that use medical data. With an appropriate NLP pipeline, the information contained in medical narratives can be used to draw up a patient profile, and admission notes can help to ascertain a mortality risk of a patient admitted to the Intensive Care Unit.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ch\u00e9rubin Mugisha et al.",
      "keywords": "Computer science; Artificial intelligence; Preprocessor; Word embedding; Natural language processing; Language model; Machine learning; Sentiment analysis; F1 score; Transformer; Embedding",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3148279",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4289913091",
      "doi": "10.1109/access.2022.3196917",
      "title": "The Robustness of Counterfactual Explanations Over Time",
      "abstract": "Counterfactual explanations are a prominent example of post-hoc interpretability methods in the explainable Artificial Intelligence (AI) research domain. Differently from other explanation methods, they offer the possibility to have recourse against unfavourable outcomes computed by machine learning models. However, in this paper we show that retraining machine learning models over time may invalidate the counterfactual explanations of their outcomes. We provide a formal definition of this phenomenon and we introduce a method, namely counterfactual data augmentation, to help improving the robustness of counterfactual explanations over time. We test our method in an empirical study where we simulate different model retraining scenarios. Our results show that counterfactual data augmentation improves the robustness of counterfactual explanations over time, therefore contributing to their use in real-world machine learning applications.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Andrea Ferrario et al.",
      "keywords": "Counterfactual thinking; Robustness (evolution); Interpretability; Computer science; Machine learning; Artificial intelligence; Retraining; Empirical research; Counterfactual conditional; Post hoc; Econometrics; Psychology; Mathematics; Economics; Statistics; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3196917",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3155751221",
      "doi": "10.1109/access.2021.3073086",
      "title": "An Early Detection of Asthma Using BOMLA Detector",
      "abstract": "\\n\\t\\t\\t\\t\\tAsthma is a chronic and airway-induced disease, causing the incidence of bronchus inflammation, breathlessness, wheezing, is drastically becoming life-threatening. Even in the worst cases, it may destroy the quality to lead. Therefore, early detection of asthma is urgently needed, and machine learning can help identify asthma accurately. In this paper, a novel machine learning framework, namely BOMLA ( B ayesian O ptimisation-based M achine L earning framework for A sthma) detector has been proposed to detect asthma. Ten classifiers have been utilized in the BOMLA detector, where Support Vector Classifier (SVC), Random Forest (RF), Gradient Boosting Classifier (GBC), eXtreme Gradient Boosting (XGB), and Artificial Neural Network (ANN) are state-of-the-art classifiers. In contrast, Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QLDA), Naive Bayes (NB), Decision Tree (DT), and K-Nearest Neighbor (KNN) are conventional popular classifiers. ADASYN algorithm has also been employed in the BOMLA detector to eradicate the issues created due to the imbalanced dataset. It has even been attempted to delineate how the ADASYN algorithm affects the classification performance. The highest accuracy (ACC) and Matthews&amp;rsquo;s correlation coefficient (MCC) for an Asthma dataset provide 94.35% and 88.97%, respectively, using BOMLA detector when SVC is adapted, and it has been increased to 96.52% and 93.04%, respectively, when ensemble technique is adapted. The one-way analysis of variance (ANOVA) has also been performed in the 10-fold cross-validation to measure the statistical significance. A decision support system has been built as a potential application of the proposed system to visualize the probable outcome of the patient. Finally, it is expected that the BOMLA detector will help patients in their early diagnosis of asthma.\\n\\t\\t\\t\\t",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Md. Abdul Awal et al.",
      "keywords": "Artificial intelligence; Machine learning; Computer science; Discriminant; Linear discriminant analysis; Random forest; Gradient boosting; Naive Bayes classifier; Classifier (UML); Support vector machine; Artificial neural network; Boosting (machine learning)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3073086",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4220701811",
      "doi": "10.1109/tcss.2022.3157522",
      "title": "Fundamentals of Computational Psychophysiology: Theory and Methodology",
      "abstract": "Welcome to the second issue of IEEE Transactions on Computational Social Systems (TCSS) in 2022. In this issue, we are going to present 25 regular articles. After the scanning the issue, I would like to share some of my opinions and perspectives on the fundamentals of computational psychophysiology: theory and methodology.",
      "year": "2022",
      "journal": "IEEE Transactions on Computational Social Systems",
      "authors": "Bin Hu et al.",
      "keywords": "Psychophysiology; Computer science; Computational model; Cognitive science; Management science; Data science; Artificial intelligence; Psychology; Engineering; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcss.2022.3157522",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4384028491",
      "doi": "10.1109/access.2023.3294542",
      "title": "Transfer Learning-Based Smart Features Engineering for Osteoarthritis Diagnosis From Knee X-Ray Images",
      "abstract": "Osteoarthritis is a deteriorating joint disease affecting millions worldwide. Osteoarthritis is a chronic condition that develops over time due to joint wear and tears. The degeneration of joint cartilage is the underlying cause of osteoarthritis, resulting in bone-to-bone contact and contributing to stiffness, discomfort, and restricted movement. People with osteoarthritis struggle to perform simple tasks such as walking, standing, or climbing stairs. Moreover, osteoarthritis can also cause psychological distress, including depression and anxiety, due to the chronic pain and disability associated with the condition. Improving the quality of life requires the development of efficient methods for early detection. Our study aims to create a model that can effectively diagnose osteoarthritis in knee X-ray images at an early stage. The advanced deep learning-based Convolutional Neural Network (CNN) and several machine learning-based techniques are applied in comparison. A novel transfer learning-based feature engineering technique CRK (CNN Random forest K-neighbors) is proposed to detect osteoarthritis with high performance. Using a 2D-CNN, the proposed CRK smartly extracts the spatial features from the X-ray images. The spatial features are input to the random forest and k-neighbors techniques, creating a probabilistic feature set. The probabilistic feature set is utilized to build the applied machine learning-based techniques. Extensive study experiments demonstrate that the proposed model outperformed with a 99&#x0025; accuracy score for predicting osteoarthritis. The performance of each applied model is validated using hyperparameter optimization and k-fold-based cross-validation. The proposed study has the potential to revolutionize the prediction of osteoarthritis from X-ray images with high-performance scores.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Amjad Rehman et al.",
      "keywords": "Osteoarthritis; Artificial intelligence; Computer science; Convolutional neural network; Transfer of learning; Feature (linguistics); Random forest; Machine learning; Hyperparameter; Deep learning; Support vector machine; Pattern recognition (psychology); Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3294542",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4292347945",
      "doi": "10.1109/jbhi.2022.3198440",
      "title": "Customized Federated Learning for Multi-Source Decentralized Medical Image Classification",
      "abstract": "The performance of deep networks for medical image analysis is often constrained by limited medical data, which is privacy-sensitive. Federated learning (FL) alleviates the constraint by allowing different institutions to collaboratively train a federated model without sharing data. However, the federated model is often suboptimal with respect to the characteristics of each client's local data. Instead of training a single global model, we propose Customized FL (CusFL), for which each client iteratively trains a client-specific/private model based on a federated global model aggregated from all private models trained in the immediate previous iteration. Two overarching strategies employed by CusFL lead to its superior performance: 1) the federated model is mainly for feature alignment and thus only consists of feature extraction layers; 2) the federated feature extractor is used to guide the training of each private model. In that way, CusFL allows each client to selectively learn useful knowledge from the federated model to improve its personalized model. We evaluated CusFL on multi-source medical image datasets for the identification of clinically significant prostate cancer and the classification of skin lesions.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Jeffry Wicaksana et al.",
      "keywords": "Computer science; Federated learning; Feature extraction; Feature (linguistics); Constraint (computer-aided design); Identification (biology); Image (mathematics); Artificial intelligence; Deep learning; Data mining; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3198440",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2912527195",
      "doi": "10.1109/tmi.2019.2897044",
      "title": "Robust Non-Rigid Motion Compensation of Free-Breathing Myocardial Perfusion MRI Data",
      "abstract": "Kinetic parameter values, such as myocardial perfusion, can be quantified from dynamic contrast-enhanced magnetic resonance imaging data using tracer-kinetic modeling. However, respiratory motion affects the accuracy of this process. Motion compensation of the image series is difficult due to the rapid local signal enhancement caused by the passing of the gadolinium-based contrast agent. This contrast enhancement invalidates the assumptions of the (global) cost functions traditionally used in intensity-based registrations. The algorithms are unable to distinguish whether the differences in signal intensity between frames are caused by the spatial motion artifacts or the local contrast enhancement. In order to address this problem, a fully automated motion compensation scheme is proposed, which consists of two stages. The first of which uses robust principal component analysis (PCA) to separate the local signal enhancement from the baseline signal, before a refinement stage which uses the traditional PCA to construct a synthetic reference series that is free from motion but preserves the signal enhancement. Validation is performed on 18 subjects acquired in free-breathing and 5 clinical subjects acquired with a breath-hold. The validation assesses the visual quality, the temporal smoothness of tissue curves, and the clinically relevant quantitative perfusion values. The expert observers score the visual quality increased by a mean of 1.58/5 after motion compensation and improvement over the previously published methods. The proposed motion compensation scheme also leads to the improved quantitative performance of motion compensated free-breathing image series [30% reduction in the coefficient of variation across quantitative perfusion maps and 53% reduction in temporal variations (p < 0.001)].",
      "year": "2019",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Cian M. Scannell et al.",
      "keywords": "Breathing; Motion compensation; Magnetic resonance imaging; Computer science; Computer vision; Motion (physics); Compensation (psychology); Biomedical engineering; Medicine; Artificial intelligence; Radiology; Anatomy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2019.2897044",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390204227",
      "doi": "10.1109/access.2023.3346764",
      "title": "Enhancing Computer-Aided Cervical Cancer Detection Using a Novel Fuzzy Rank-Based Fusion",
      "abstract": "Cervical cancer is a severe and pervasive disease that poses a significant health threat to women globally. The Pap smear test is an efficient and effective method for detecting cervical cancer in its early stages. However, manual screening is labor-intensive and requires expert cytologists, leading to potential delays and inconsistencies in diagnosis. Deep Learning-based Computer-Aided Diagnosis (CAD) has shown significant results and can ease the problem of manual screening. However, one single model is sometimes insufficient to capture the complex data pattern for accurate disease prediction. In this work, we develop an end-to-end architecture utilizing three pre-trained models for the initial cervical cancer prediction. To aggregate the outcomes of these models, we propose a novel fuzzy rank-based ensemble considering two non-linear functions for the final level prediction. Unlike simple fusion techniques, the proposed architecture provides the final predictions on the test samples by considering the base classifier\u2019s confidence in the predictions. To further enhance the classification capabilities of these models, we integrate advanced augmentation techniques such as CutOut, MixUp, and CutMix. The proposed model is evaluated on two benchmark datasets, SIPaKMeD and Mendeley LBC, using a 5-fold cross-validation approach. On the SIPaKMeD dataset, the proposed ensemble architecture achieves a classification accuracy of 97.18% and an F1 score of 97.16%. On the Mendeley LBC dataset, the accuracy reaches 99.22% with an F1 score of 99.19%. Experimental results demonstrate the proposed architecture\u2019s effectiveness and potential in cervical Pap smear image classification. This could aid medical professionals in making more informed treatment decisions, improving overall effectiveness in the testing process.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Pranab Sahoo et al.",
      "keywords": "Computer science; Artificial intelligence; Benchmark (surveying); Machine learning; Cervical cancer; Classifier (UML); Cross-validation; Fuzzy logic; Data mining; Pattern recognition (psychology); Cancer; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3346764",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380980908",
      "doi": "10.1109/access.2023.3275126",
      "title": "RadioPathomics: Multimodal Learning in Non-Small Cell Lung Cancer for Adaptive Radiotherapy",
      "abstract": "Current practice in cancer treatment collects multimodal data, such as radiology images, histopathology slides, genomics and clinical data. The importance of these data sources taken individually has fostered the recent rise of radiomics and pathomics, i.e., the extraction of quantitative features from radiology and histopathology images collected to predict clinical outcomes or guide clinical decisions using artificial intelligence algorithms. Nevertheless, how to combine them into a single multimodal framework is still an open issue. In this work, we develop a multimodal late fusion approach that combines hand-crafted features computed from radiomics, pathomics and clinical data to predict radiotherapy treatment outcomes for non-small-cell lung cancer patients. Within this context, we investigate eight different late fusion rules and two patient-wise aggregation rules leveraging the richness of information given by CT images, whole-slide scans and clinical data. The experiments in leave-one-patient-out cross-validation on an in-house cohort of 33 patients show that the proposed fusion-based multimodal paradigm, with an AUC equal to 90.9%, outperforms each unimodal approach, suggesting that data integration can advance precision medicine. The results also show that late fusion favourably compares against early fusion, another commonly used multimodal approach. As a further contribution, we explore the chance to use a deep learning framework against hand-crafted features. In our scenario characterised by different modalities and a limited amount of data, as it may happen in different areas of cancer research, the results show that the latter is still a viable and effective option for extracting relevant information with respect to the former.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Matteo Tortora et al.",
      "keywords": "Computer science; Artificial intelligence; Context (archaeology); Multimodal therapy; Machine learning; Radiomics; Deep learning; Medical physics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3275126",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390771634",
      "doi": "10.1109/access.2024.3351600",
      "title": "Split Federated Learning for 6G Enabled-Networks: Requirements, Challenges, and Future Directions",
      "abstract": "Sixth-generation (6G) networks anticipate intelligently supporting a wide range of smart services and innovative applications. Such a context urges a heavy usage of Machine Learning (ML) techniques, particularly Deep Learning (DL), to foster innovation and ease the deployment of intelligent network functions/operations, which are able to fulfill the various requirements of the envisioned 6G services. The revolution of 6G networks is driven by massive data availability, moving from centralized and big data towards small and distributed data. This trend has motivated the adoption of distributed and collaborative ML/DL techniques. Specifically, collaborative ML/DL consists of deploying a set of distributed agents that collaboratively train learning models without sharing their data, thus improving data privacy and reducing the time/communication overhead. This work provides a comprehensive study on how collaborative learning can be effectively deployed over 6G wireless networks. In particular, our study focuses on Split Federated Learning (SFL), a technique that recently emerged promising better performance compared with existing collaborative learning approaches. We first provide an overview of three emerging collaborative learning paradigms, including federated learning, split learning, and split federated learning, as well as of 6G networks along with their main vision and timeline of key developments. We then highlight the need for split federated learning towards the upcoming 6G networks in every aspect, including 6G technologies (e.g., intelligent physical layer, intelligent edge computing, zero-touch network management, intelligent resource management) and 6G use cases (e.g., smart grid 2.0, Industry 5.0, connected and autonomous systems). Furthermore, we review existing datasets along with frameworks that can help in implementing SFL for 6G networks. We finally identify key technical challenges, open issues, and future research directions related to SFL-enabled 6G networks.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Houda Hafi et al.",
      "keywords": "Computer science; Collaborative learning; Context (archaeology); Software deployment; Overhead (engineering); Distributed computing; Artificial intelligence; Knowledge management; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3351600",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3209138746",
      "doi": "10.1109/access.2021.3124163",
      "title": "Review: Privacy-Preservation in the Context of Natural Language Processing",
      "abstract": "Data privacy is one of the highly discussed issues in recent years as we encounter data breaches and privacy scandals often. This raises a lot of concerns about the ways the data is acquired and the potential information leaks. Especially in the field of Artificial Intelligence (AI), the widely using of AI models aggravates the vulnerability of user privacy because a considerable portion of user data that AI models used is represented in natural language. In the past few years, many researchers have proposed NLP-based methods to address these data privacy challenges. To the best of our knowledge, this is the first interdisciplinary review discussing privacy preservation in the context of NLP. In this paper, we present a comprehensive review of previous research conducted to gather techniques and challenges of building and testing privacy-preserving systems in the context of Natural Language Processing (NLP). We group the different works under four categories: 1) Data privacy in the medical domain, 2) Privacy preservation in the technology domain, 3) Analysis of privacy policies, and 4) Privacy leaks detection in the text representation. This review compares the contributions and pitfalls of the various privacy violation detection and prevention works done using NLP techniques to help guide a path ahead.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Darshini Mahendran et al.",
      "keywords": "Computer science; Context (archaeology); Information privacy; Internet privacy; Domain (mathematical analysis); Natural language; Data science; Privacy policy; Representation (politics); Privacy software; Privacy by Design; Computer security; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3124163",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288391511",
      "doi": "10.1109/access.2022.3194529",
      "title": "A Survey of Wound Image Analysis Using Deep Learning: Classification, Detection, and Segmentation",
      "abstract": "Wounds not only harm the physical and mental health of patients, but also introduce huge medical costs. Meanwhile, there is a shortage of physicians in some areas, and clinical examinations are sometimes unreliable in wound diagnosis. Reliable wound analysis is of great importance in its diagnosis, treatment, and care. Currently, deep learning has developed rapidly in the field of computer vision and medical imaging and has become the most commonly used technique in wound image analysis. This paper studies the current research on deep learning in the field of wound image analysis, including classification, detection, and segmentation. We first review the publicly available datasets from various research, and study the preprocessing methods used in wound image analysis. Second, various models used in different deep learning tasks (classification, detection, and segmentation) and their applications in different types of wounds (e.g., burns, diabetic foot ulcers, pressure ulcers) are investigated. Finally, we discuss the challenges in the field of wound image analysis using deep learning, and provide an outlook on the research and development prospects.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ruyi Zhang et al.",
      "keywords": "Deep learning; Artificial intelligence; Segmentation; Image segmentation; Computer science; Preprocessor; Field (mathematics); Economic shortage; Harm; Machine learning; Wound care; Pattern recognition (psychology); Computer vision; Medicine; Intensive care medicine; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3194529",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387996976",
      "doi": "10.1109/jbhi.2023.3327951",
      "title": "GenHPF: General Healthcare Predictive Framework for Multi-Task Multi-Source Learning",
      "abstract": "Despite the remarkable progress in the development of predictive models for healthcare, applying these algorithms on a large scale has been challenging. Algorithms trained on a particular task, based on specific data formats available in a set of medical records, tend to not generalize well to other tasks or databases in which the data fields may differ. To address this challenge, we propose General Healthcare Predictive Framework (GenHPF), which is applicable to any EHR with minimal preprocessing for multiple prediction tasks. GenHPF resolves heterogeneity in medical codes and schemas by converting EHRs into a hierarchical textual representation while incorporating as many features as possible. To evaluate the efficacy of GenHPF, we conduct multi-task learning experiments with single-source and multi-source settings, on three publicly available EHR datasets with different schemas for 12 clinically meaningful prediction tasks. Our framework significantly outperforms baseline models that utilize domain knowledge in multi-source learning, improving average AUROC by 1.2%P in pooled learning and 2.6%P in transfer learning while also showing comparable results when trained on a single EHR dataset. Furthermore, we demonstrate that self-supervised pretraining using multi-source datasets is effective when combined with GenHPF, resulting in a 0.6 pretraining. By eliminating the need for preprocessing and feature engineering, we believe that this work offers a solid framework for multi-task and multi-source learning that can be leveraged to speed up the scaling and usage of predictive algorithms in healthcare.<sup>1</sup>.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Kyunghoon Hur et al.",
      "keywords": "Computer science; Machine learning; Preprocessor; Artificial intelligence; Task (project management); Feature engineering; Transfer of learning; Multi-task learning; Supervised learning; Source code; Set (abstract data type); Data mining; Deep learning; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3327951",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2906111507",
      "doi": "10.1109/access.2018.2889350",
      "title": "Ensemble Learning of Multiple-View 3D-CNNs Model for Micro-Nodules Identification in CT Images",
      "abstract": "Numerous automatic systems of pulmonary nodules detection have been proposed, but very few of them have been consecrated to micro-nodules (diameter &#x003C; 3 mm) even though they are regarded as the earliest manifestations of lung cancer. Moreover, most available systems present high false positive rate resulting from their incapability of discriminating between micro-nodules and non-nodules. Thus, this paper proposes a system to differentiate between the micro-nodules and non-nodules in computed tomography (CT) images by an ensemble learning of multiple-view 3-D convolutional neural networks (3D-CNNs). A total of 34 494 volumetric image samples, including 13 179 micro-nodules and 21 315 non-nodules, are acquired from the 1010 CT scans of the LIDC/IDRI database. The pulmonary nodule candidates are cropped with five different sizes, including <inline-formula> <tex-math notation=\"LaTeX\">$20\\times 20\\times 3$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$16\\times 16\\times 3$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$12\\times 12\\times 3$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$8\\times 8\\times 3$ </tex-math></inline-formula>, and <inline-formula> <tex-math notation=\"LaTeX\">$4\\times 4\\times 3$ </tex-math></inline-formula>. Then, five distinct 3D-CNN models are built and implemented on one size of the nodule candidates. An extreme learning machine (ELM) network is utilized to integrate the five 3D-CNN outputs, yielding the final classification results. The performance of the proposed system is assessed in terms of accuracy, area under the curve (AUC), F-score, and sensitivity. It is found that the proposed system yields an accuracy, AUC, F-score, and sensitivity of 97.35&#x0025;, 0.98, 96.42&#x0025;, and 96.57&#x0025;, respectively. These performances are highly superior to those of 2D-CNNs, single 3D-CNN model, as well as those by the state-of-the-art methods implemented on the same dataset. For the ensemble method, ELM achieves better performance than the majority voting, averaging, AND operator, and autoencoder. The results demonstrate that developing an automatic system for discriminating between micro-nodules and non-nodules in CT images is feasible, which extends lung cancer studies to micro-nodules. The combination of multiple-view 3D-CNNs and ensemble learning contribute to excellent identification performance, and this strategy may help develop other reliable clinical-decision support systems.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Patrice Monkam et al.",
      "keywords": "Notation; Artificial intelligence; Nodule (geology); Mathematics; Algorithm; Computer science; Natural language processing; Biology; Arithmetic",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2889350",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392007319",
      "doi": "10.1109/access.2024.3368031",
      "title": "A Framework for Early Detection of Acute Lymphoblastic Leukemia and Its Subtypes From Peripheral Blood Smear Images Using Deep Ensemble Learning Technique",
      "abstract": "Acute lymphoblastic leukemia (ALL), one of the prevalent types of carcinogenic disease, has been seen a deadly illness exposing numerous patients across the world to potential threats of lives. It impacts both adults and children providing a narrow range of chances of being cured if diagnosed at a later stage. A definitive diagnosis often demands highly invasive diagnostic procedures thereby proving time-consuming and expensive. Peripheral Blood Smear (PBS) images have been playing a crucial role in the initial screening of ALL in suspected individuals. However, the nonspecific nature of ALL poses a substantial challenge in the analysis of these images thus leaving space for misdiagnosis. Aiming at contribute to the early diagnoses of this life-threatening disease, we put forward automated platform for screening the presence of ALL concerning its specific subtypes (benign, Early Pro-B, Pro-B and Pre-B) using PBS images. The proposed web based platform follows weighted ensemble learning technique using a Residual Convolutional Neural Network (ResNet-152) as the base learner to identify ALL from hematogone cases and then determine ALL subtypes. This is likely to save both diagnosis time and the efforts of clinicians and patients. Experimental results are obtained and comparative analysis among 7 well-known CNN Network architectures (AlexNet, VGGNet, Inception, ResNet-50, ResNet-18, Inception and DenseNet-121) is also performed that demonstrated that the proposed platform achieved comparatively high accuracy (99.95&#x0025;), precision (99.92&#x0025;), recall (99.92&#x0025;), F1-Score (99.90&#x0025;), sensitivity (99.92&#x0025;) and specificity (99.97&#x0025;). The promising results demonstrate that the proposed platform has the potential to be used as a reliable tool for early diagnosis of ALL and its sub-types. Furthermore, this provides references for pathologists and healthcare providers, aiding them in producing specific guidelines and more informed choices about patient and disease management.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Sajida Perveen et al.",
      "keywords": "Lymphoblastic Leukemia; Peripheral blood; Computer science; Artificial intelligence; Peripheral; Deep learning; Pattern recognition (psychology); Leukemia; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3368031",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3186462793",
      "doi": "10.1109/jbhi.2021.3098511",
      "title": "Practical Strategies for Extreme Missing Data Imputation in Dementia Diagnosis",
      "abstract": "Accurate computational models for clinical decision support systems require clean and reliable data but, in clinical practice, data are often incomplete. Hence, missing data could arise not only from training datasets but also test datasets which could consist of a single undiagnosed case, an individual. This work addresses the problem of extreme missingness in both training and test data by evaluating multiple imputation and classification workflows based on both diagnostic classification accuracy and computational cost. Extreme missingness is defined as having \u223c50% of the total data missing in more than half the data features. In particular, we focus on dementia diagnosis due to long time delays, high variability, high attrition rates and lack of practical data imputation strategies in its diagnostic pathway. We identified and replicated the extreme missingness structure of data from a real-world memory clinic on a larger open dataset, with the original complete data acting as ground truth. Overall, we found that computational cost, but not accuracy, varies widely for various imputation and classification approaches. Particularly, we found that iterative imputation on the training dataset combined with a reduced-feature classification model provides the best approach, in terms of speed and accuracy. Taken together, this work has elucidated important factors to be considered when developing a predictive model for a dementia diagnostic support system.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Niamh McCombe et al.",
      "keywords": "Missing data; Imputation (statistics); Computer science; Data mining; Ground truth; Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3098511",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3198163615",
      "doi": "10.1109/access.2021.3110904",
      "title": "Lung Segmentation-Based Pulmonary Disease Classification Using Deep Neural Networks",
      "abstract": "Interpreting chest x-ray (CXR) to find anomalies in the thoracic region is a tedious job and can consume an ample amount of radiologist&#x2019;s time when there are thousands of them to process. In such scenarios, the Computer-Aided Diagnostic (CAD) systems can help radiologists by doing the trivial processing and presenting the information in a meaningful way so that, the radiologist can make more accurate decisions by spending less amount of time and energy. This research study intends to propose a better, accurate, and efficient CNN based pulmonary disease diagnosis system using CXR images. In the proposed system, the capabilities of deep neural network architecture are exploited by proposing a custom CNN architecture with additional layers and modified hyperparameters to meet the required results. The input CXR is examined for healthy or infected at the surface level and the infected images are further processed for class level label classification. The lung region is segmented from the entire input CXR image to reduce the amount of noise and increase the processing efficiency by processing less overall information. The proposed model is evaluated on the benchmark split of the NIH chest x-ray dataset and achieves better segmentation and classification results when compared to the state of the art approaches.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Syeda Zainab Yousuf Zaidi et al.",
      "keywords": "Computer science; Artificial intelligence; Artificial neural network; Segmentation; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3110904",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285303086",
      "doi": "10.1109/access.2022.3175858",
      "title": "Polyp Segmentation of Colonoscopy Images by Exploring the Uncertain Areas",
      "abstract": "Colorectal cancer is one of the leading causes of death worldwide. Polyps are early symptoms of colorectal cancer and prone to malignant transformation. Polyp segmentation of colonoscopy images can help diagnosis. However, existing studies on polyp segmentation of colonoscopy images face two main difficulties: blurry polyp boundaries, close resemblances between polyps and surrounding tissues. The former may lead to partial segmentations, while the latter can result in false positive segmentations. This paper proposes a new polyp segmentation framework to tackle the two challenges. In this method, an uncertainty region based module called Uncertainty eXploration (UnX) is introduced to get the complete polyp region while eliminating the interferences from the backgrounds. Specifically, it refines the feature maps with ternary guidance masks by dividing the initial guidance maps into three types: foreground, background and uncertain region, so that the uncertain areas are highlighted for more foreground objects while the backgrounds are forcefully suppressed to avoid interferences of tissues in background. Taking UnX as side supervision to the transformer encoder based backbone stages, the proposed method can mine the boundary areas from the uncertainty regions gradually and obtain robust polyp segmentation finally. Moreover, a new module called Feature Enhancement (FeE) is also incorporated in the framework to enhance the discrimination for images with significant variation of sizes and shapes of polyps. FeE can supply multi-scale features to the global oriented transformer features. Experiments on five polyp segmentation benchmark datasets of colonoscopy images, Kvasir, CVC-ClinicDB, ETIS, CVC-ColonDB and CVC-300, show the superior performances of our proposed method. Especially, for ETIS, the most challenging among the five datasets, our method achieves 7.7% and 5.6% improvements in mDSC (mean Dice Similarity Coefficient) and mIoU (mean Intersection over Union) respectively in comparison with the state-of-the-arts methods.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Qingqing Guo et al.",
      "keywords": "Segmentation; Artificial intelligence; Computer science; Colonoscopy; Computer vision; Feature (linguistics); Pattern recognition (psychology); Image segmentation; Encoder; Benchmark (surveying); Colorectal cancer; Medicine; Cancer; Cartography; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3175858",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388676616",
      "doi": "10.1109/access.2023.3333229",
      "title": "Blockchain and Machine Learning in EHR Security: A Systematic Review",
      "abstract": "Background: The rapid development of modern technologies renders a convenient and efficient solution to implement Electronic Health Records (EHRs) systems. The rapid growth of healthcare data has a distinctive attribute of digital transformations. The big datasets of healthcare, their complexity and their dynamic nature have posed severe challenges associated with the analysis, pre-processing, privacy, security, storage, usability and data exchange. Material and Methods: We have performed the Systematic Literature Review (SLR) and followed the Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) methodology. SLR refers to the methodology that discovers, analyses and accesses recent research literature related to the subject field. The research papers were searched from academic repositories like IEEE, WOS, Scopus and PubMed for the previous five years on March 2023. Results: The designed search string provides 199 research articles in total. We filter the research articles based on inclusion-exclusion strategies and quality assessment metrics. Six main criteria for research inclusion-exclusion for SLR are formulated. These works of literature insight into 1) the issues associated with interoperability and security of EHRs by using the Blockchain (BC) technology, 2) different frameworks and tools to improve privacy and security in the healthcare domain, 3) the open issues of using BC technology in the electronic healthcare domain, 4) the standardized ways to store EHRs, 5) various ways to handle the big data using the BC systems and 6) the usage of Federated Learning (FL) to preserve the privacy of EHRs in the healthcare domain. We acquired 46 research articles based on the criteria (inclusion-exclusion) that investigate the above-mentioned issues. Conclusion: The SLR will serve as the state-of-the-art (SOTA) for future researchers in the field of BC in healthcare. Additionally, the paper provides insights to the new researchers to revolutionize the healthcare domain by adopting the latest digitalized technologies. The proposed study identified various reflections. It analyzed the architectural mechanism that supports the security and interoperability of EHRs. Secondly, the study described different tools and frameworks to improve the privacy and security of EHRs using the BC. Thirdly, the open issues of storing and preserving the EHRs using BC in the healthcare system were determined. Fourth, it analyzed and provided a detailed view of using standardized ways for storing and handling big data by using the BC system. Lastly, the usage of FL to preserve the privacy of EHRs was analyzed.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Umer Zukaib et al.",
      "keywords": "Computer science; Interoperability; Health care; Usability; Data science; Systematic review; Big data; Domain (mathematical analysis); Inclusion and exclusion criteria; World Wide Web; Data mining; MEDLINE; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3333229",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377861913",
      "doi": "10.1109/jproc.2023.3273517",
      "title": "Unlocking the Emotional World of Visual Media: An Overview of the Science, Research, and Impact of Understanding Emotion",
      "abstract": "The emergence of artificial emotional intelligence technology is revolutionizing the fields of computers and robotics, allowing for a new level of communication and understanding of human behavior that was once thought impossible. While recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy. This foundering stems from the absence of a universally accepted definition of \"emotion,\" coupled with the inherently subjective nature of emotions and their intricate nuances. In this article, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts. We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos. We then review the latest research and systems within the field, accentuating the most promising approaches. We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation. We contend that this represents a \"Holy Grail\" research problem in computing and delineate pivotal directions for future inquiry. Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts. Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field.",
      "year": "2023",
      "journal": "Proceedings of the IEEE",
      "authors": "James Z. Wang et al.",
      "keywords": "Field (mathematics); Multidisciplinary approach; Affective science; Psychology; Holy Grail; Cognitive science; Interdisciplinarity; Domain (mathematical analysis); Computer science; Cognitive psychology; Emotion classification; Sociology; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2023.3273517",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4213027218",
      "doi": "10.1109/ojemb.2022.3151233",
      "title": "Continuous Speech for Improved Learning Pathological Voice Disorders",
      "abstract": "<i>Goal:</i> Numerous studies had successfully differentiated normal and abnormal voice samples. Nevertheless, further classification had rarely been attempted. This study proposes a novel approach, using continuous Mandarin speech instead of a single vowel, to classify four common voice disorders (i.e. functional dysphonia, neoplasm, phonotrauma, and vocal palsy). <i>Methods:</i> In the proposed framework, acoustic signals are transformed into mel-frequency cepstral coefficients, and a bi-directional long-short term memory network (BiLSTM) is adopted to model the sequential features. The experiments were conducted on a large-scale database, wherein 1,045 continuous speech were collected by the speech clinic of a hospital from 2012 to 2019. <i>Results:</i> Experimental results demonstrated that the proposed framework yields significant accuracy and unweighted average recall improvements of 78.12-89.27% and 50.92-80.68%, respectively, compared with systems that use a single vowel. <i>Conclusions:</i> The results are consistent with other machine learning algorithms, including gated recurrent units, random forest, deep neural networks, and LSTM.The sensitivities for each disorder were also analyzed, and the model capabilities were visualized via principal component analysis. An alternative experiment based on a balanced dataset again confirms the advantages of using continuous speech for learning voice disorders.",
      "year": "2022",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Syu-Siang Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2022.3151233",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366549824",
      "doi": "10.1109/access.2023.3269027",
      "title": "Computer Vision-Based Assessment of Autistic Children: Analyzing Interactions, Emotions, Human Pose, and Life Skills",
      "abstract": "In this paper, the proposed work implements and tests the computer vision applications to perform the skill and emotion assessment of children with Autism Spectrum Disorder (ASD) by extracting various bio-behaviors, human activities, child-therapist interactions, and joint pose estimations from the recorded videos of interactive single- or two-person play-based intervention sessions. A comprehensive data set of 300 videos is amassed from ASD children engaged in social interaction, and three novel deep learning-based vision models are developed, which are explained as follows: (i) activity comprehension to analyze child-play partner interactions (activity comprehension model); (ii) an automatic joint attention recognition framework using head and hand pose; and (iii) emotion and facial expression recognition. The proposed models are also tested on children&#x2019;s real-world, 68 unseen videos captured from the clinic, and public datasets. The activity comprehension model has an overall accuracy of 72.32&#x0025;, the joint attention recognition models have an accuracy of 97&#x0025; for follow eye gaze and 93.4&#x0025; for hand pointing, and the facial expression recognition model has an overall accuracy of 95.1&#x0025;. The proposed models could extract behaviors of interest, events of activities, emotions, and social skills from free-play and intervention session videos of long duration and provide temporal plots for session monitoring and assessment, thus empowering clinicians with insightful data useful in diagnosis, assessment, treatment formulation, and monitoring ASD children with limited supervision.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Varun Ganjigunte Prakash et al.",
      "keywords": "Autism; Comprehension; Facial expression; Gaze; Joint attention; Set (abstract data type); Session (web analytics); Computer science; Autism spectrum disorder; Intervention (counseling); Eye tracking; Activity recognition; Artificial intelligence; Human\u2013computer interaction; Psychology; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3269027",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385756442",
      "doi": "10.1109/jsen.2023.3303436",
      "title": "Evaluating Multimodal Wearable Sensors for Quantifying Affective States and Depression With Neural Networks",
      "abstract": "With the increasing proliferation of embedded sensors in wearable devices, there is potential for modeling individual emotional and mental state variations. The popular measure for the quantification of emotions outlines the affective states of arousal and valences, with high and low being the discrete categories of interest. Recent works explore the discernability of digital behavior differences between groups with and without mental disorders. However, the interaction between physiological states and affective states within a predominantly depressive population remains to be studied with the aid of wearables. Despite the pervasiveness of emotional state inference through the tracking of ubiquitous physiological trackers such as heart rate, blood volume pulse, skin conductance, and motion, a dearth of work is noted in the exploration of physiological markers in single and multimodal settings. This work provides an extensive evaluation of a convolutional neural network with an attention mechanism ensembled with a random forest algorithm to effectively leverage multiple raw signal-to-image transformations as feature inputs to predict depression severity and affective state. The proposed models are assessed on the Daily Ambulatory Psychological and Physiological recording for Emotion Research (DAPPER) dataset, and achieve the sensitivity: specificity scores of 58.75%:45.59%, 62.34%:43.41%, 49.43%:51.70% for predicting depression, valence, and arousal with a mixture of uni- and bi- modality applying Continuous Wavelet Transforms and Short-time Fourier Transform to motion skin-conductance readings, respectively. This work is envisioned as a preliminary study to contribute towards the monitoring of affective states among a depressed population by utilizing low-frequency sensor recordings with the DAPPER dataset.",
      "year": "2023",
      "journal": "IEEE Sensors Journal",
      "authors": "Abdullah Ahmed et al.",
      "keywords": "Wearable computer; Convolutional neural network; Artificial intelligence; Population; Affective computing; Computer science; Arousal; Valence (chemistry); Machine learning; Psychology; Medicine; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2023.3303436",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3091534396",
      "doi": "10.1109/access.2020.3027535",
      "title": "In-Home Floor Based Sensor System-Smart Carpet- to Facilitate Healthy Aging in Place (AIP)",
      "abstract": "With the rapidly aging population, there is a need to detect elderly's activity, monitor their health, alert health care personnel, and provide real-time and long-term access to the generated sensor data. With the advances in sensor technologies, communication protocols, computing power, and cloud and edge services, it is now possible to build smart assistive living systems to improve people's lives. In this research, we present a Context-aware and private real-time reporting aging in place system. The proposed system, we call it smart carpet, consists of a sensor pad placed under a carpet; the electronics reads walking activity to provide an automated health monitoring and alert system. We extended the system's functionalities to improve its ability to detect falls, measure gait, and count the number of people traversing the carpet (socializing). In an urgent and time-sensitive situation, we need to provide a real-time notification. We propose a cooperative cloudlet model, where the sensors' data will be sent to the nearest Cloudlet for analysis and extracting real-time decisions in minimal delay. Results showed that our system could assist the elderly in detecting falls with 95% sensitivity and 85% specificity. Measuring and estimating their gait with a mean percentage error difference to GAITRite 1.43% in walking speed; hence, predicting a fall risk and counting people's plurality socializing with the elderly with an average accuracy of 100%. We evaluated our system's improvements in a controlled environment. We are looking forward to deploying the system in a nursing home (after the COVID -19 is over) for more data gathering and validations.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Fadi Muheidat et al.",
      "keywords": "Cloudlet; Computer science; Context (archaeology); Cloud computing; Real-time computing; Enhanced Data Rates for GSM Evolution; Edge computing; Population; Artificial intelligence; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3027535",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3016100956",
      "doi": "10.1109/trpms.2020.2986414",
      "title": "Micro-Networks for Robust MR-Guided Low Count PET Imaging",
      "abstract": "Noise suppression is particularly important in low count positron emission tomography (PET) imaging. Post-smoothing (PS) and regularization methods which aim to reduce noise also tend to reduce resolution and introduce bias. Alternatively, anatomical information from another modality such as magnetic resonance (MR) imaging can be used to improve image quality. Convolutional neural networks (CNNs) are particularly well suited to such joint image processing, but usually require large amounts of training data and have mostly been applied outside the field of medical imaging or focus on classification and segmentation, leaving PET image quality improvement relatively understudied. This article proposes the use of a relatively low-complexity CNN (micro-net) as a post-reconstruction MR-guided image processing step to reduce noise and reconstruction artefacts while also improving resolution in low count PET scans. The CNN is designed to be fully 3-D, robust to very limited amounts of training data, and to accept multiple inputs (including competitive denoising methods). Application of the proposed CNN on simulated low (30 M) count data (trained to produce standard (300 M) count reconstructions) results in a 36% lower normalized root mean squared error (NRMSE, calculated over ten realizations against the ground truth) compared to maximum-likelihood expectation maximization (MLEM) used in clinical practice. In contrast, a decrease of only 25% in NRMSE is obtained when an optimized (using knowledge of the ground truth) PS is performed. A 26% NRMSE decrease is obtained with both RM and optimized PS. Similar improvement is also observed for low count real patient datasets. Overfitting to training data is demonstrated to occur as the network size is increased. In an extreme case, a U-net (which produces better predictions for training data) is shown to completely fail on test data due to overfitting to this case of very limited training data. Meanwhile, the resultant images from the proposed CNN (which has low training data requirements) have lower noise, reduced ringing, and partial volume effects, as well as sharper edges and improved resolution compared to conventional MLEM.",
      "year": "2020",
      "journal": "IEEE Transactions on Radiation and Plasma Medical Sciences",
      "authors": "Casper da Costa\u2010Luis et al.",
      "keywords": "Artificial intelligence; Ground truth; Convolutional neural network; Computer science; Image quality; Smoothing; Expectation\u2013maximization algorithm; Positron emission tomography; Medical imaging; Pattern recognition (psychology); Noise reduction; Segmentation; Iterative reconstruction; Noise (video); Computer vision; Nuclear medicine; Mathematics; Image (mathematics); Medicine; Statistics; Maximum likelihood",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/trpms.2020.2986414",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3011744915",
      "doi": "10.1109/jsen.2020.2981334",
      "title": "Classification of Atrial Fibrillation and Acute Decompensated Heart Failure Using Smartphone Mechanocardiography: A Multilabel Learning Approach",
      "abstract": "Timely diagnosis of cardiovascular diseases (CVD) is crucial to prevent morbidity and mortality. Atrial fibrillation (AFib) and heart failure (HF) are two prevalent cardiac disorders that are associated with a high risk of morbidity and mortality, especially if they are concurrently present. Current approaches fail to screen many at-risk individuals who would benefit from preventive treatment; while others receive unnecessary interventions. An effective approach to the detection of CVDs is mechanocardiography (MCG) by which translational and rotational precordial chest movements are monitored. In this study, we collected MCG data from a study sample of 300 hospitalized cardiac patients using multidimensional built-in inertial sensors of a smartphone. Our main objective was to detect concurrent AFib and acute decompensated HF (ADHF) using smartphone MCG (or sMCG). To this end, we adopted a supervised machine learning classification using multi-label and hierarchical classification. Logistic regression, random forest, and extreme gradient boosting were used as candidate classifiers. The results of the analysis showed the area under the receiver operating characteristic curve values of 0.98 and 0.85 for AFib and ADHF, respectively. The highest percentages of positive and negative predictive values for AFib were 91.9 and 100; while for ADHF, they were 56.9 and 88.4 for the multi-label classification and 69.9 and 68.8 for the hierarchical classification, respectively. We conclude that using a single sMCG measurement, AFib can be detected accurately whereas ADHF can be detected with moderate certainty.",
      "year": "2020",
      "journal": "IEEE Sensors Journal",
      "authors": "Saeed Mehrang et al.",
      "keywords": "Acute decompensated heart failure; Atrial fibrillation; Medicine; Logistic regression; Heart failure; Receiver operating characteristic; Random forest; Internal medicine; Machine learning; Cardiology; Artificial intelligence; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2020.2981334",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2971613769",
      "doi": "10.1109/jbhi.2019.2939149",
      "title": "Exploratory Data Mining for Subgroup Cohort Discoveries and Prioritization",
      "abstract": "Finding small homogeneous subgroup cohorts in large heterogeneous populations is a critical process for hypothesis development in biomedical research. Concurrent computational approaches are still lacking in robust answers to the question \"what hypotheses are likely to be novel and to produce clinically relevant results with well thought-out study designs?\" We have developed a novel subgroup discovery method which employs a deep exploratory mining process to slice and dice thousands of potential subpopulations and prioritize potential cohorts based on their explainable contrast patterns and which may provide interventionable insights. We conducted computational experiments on both synthesized data and a clinical autism data set to assess performance quantitatively for coverage of pre-defined cohorts and qualitatively for novel knowledge discovery, respectively. We also conducted a scaling analysis using a distributed computing environment to suggest computational resource needs for when the subpopulation number increases. This work will provide a robust data-driven framework to automatically tailor potential interventions for precision health.",
      "year": "2019",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Danlu Liu et al.",
      "keywords": "Computer science; Prioritization; Resource (disambiguation); Exploratory data analysis; Data science; Set (abstract data type); Data mining; Process (computing); Machine learning; Artificial intelligence; Management science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2019.2939149",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2913996141",
      "doi": "10.1109/access.2019.2894530",
      "title": "Sparse Feature Learning With Label Information for Alzheimer\u2019s Disease Classification Based on Magnetic Resonance Imaging",
      "abstract": "Neuroimaging techniques have been used for automatic diagnosis and classification of Alzheimer's disease and mild cognitive impairment. How to select discriminant features from these data is the key that will affect the subsequent automatic diagnosis and classification performance. However, in the previous manifold regularized sparse regression models, the local neighborhood structure was constructed directly in the traditional Euclidean distance without fully utilizing the label information of the subjects, which leads to the selection of less discriminative features. In this paper, we propose a novel manifold regularized sparse regression model for learning discriminative features. Specifically, wefirst adopt l(2,1)-norm regularization to jointly select a relevant feature subset among the samples. Then, to select more discriminative features, a novel manifold regularization term is constructed via the relative distance adjusted by the label information, which can simultaneously maintain the compactness of the intra-class samples and the separability of inter-class samples. The proposed feature learning method is further carried out for both the binary classification and the multi-class classification. The experimental results on Alzheimer's Disease Neuroimaging Initiative database demonstrate the effectiveness of the proposed method, which can be utilized for the diagnosis of Alzheimer's disease and mild cognitive impairment.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Lina Xu et al.",
      "keywords": "Magnetic resonance imaging; Feature (linguistics); Computer science; Artificial intelligence; Pattern recognition (psychology); Medicine; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2894530",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293812151",
      "doi": "10.1109/access.2022.3195898",
      "title": "Deep Learning for Resource Management in Internet of Things Networks: A Bibliometric Analysis and Comprehensive Review",
      "abstract": "In this study, we conducted a bibliometric analysis and comprehensive review of the studies&#13;\\npublished between the period of 2012 and 2022 on resource management in internet of things (IoT)&#13;\\nnetworks using the Scopus database to determine the current state of research and gain insight into the&#13;\\nresearch challenges and opportunities in the field. The bibliometric analysis technique was employed to&#13;\\nbibliometrically analyze the published studies that were collected from the Scopus database and this helped&#13;\\nto discover the majority of research subjects in the field of resource management in IoT networks. Following&#13;\\nthis, we conducted a comprehensive review of the relevant studies to provide an insight into the recent&#13;\\nprogress and the research gaps in the field. According to the results of our bibliometric analysis and the&#13;\\ncomprehensive review, we discovered that resource management problems in IoT networks is still a growing&#13;\\nchallenge as a result of the limited available resources for operating IoT networks. Resource management&#13;\\nproblem is a critical research area due to the advantages of IoT in terms of collecting vital data that could be&#13;\\nused in analyzing and predicting human behavior as well as environmental conditions. Also, the results of&#13;\\nour bibliometric analysis and comprehensive review further revealed that research on the use of conventional&#13;\\nartificial intelligence techniques, such as optimization approaches and game theory approaches, for resource&#13;\\nmanagement are common, while research on the use of the modern artificial intelligence technique, like&#13;\\ndeep learning approaches, is less common. Therefore, this study aims to fill the research gap in the area of&#13;\\nresource management in IoT networks by introducing the use of deep learning approaches. Deep learning is a&#13;\\npowerful artificial intelligence method that is advantageous for obtaining low-complexity resource allocation&#13;\\nsolutions in a near real-time. Also, various open research issues that are associated with the use of deep&#13;\\nlearning approaches are highlighted as future research directions to enable the development of novel deep&#13;\\nlearning models for IoT networks.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Segun O. Olatinwo et al.",
      "keywords": "Computer science; Internet of Things; Resource management (computing); The Internet; Data science; Knowledge management; World Wide Web; Computer network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3195898",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4224315024",
      "doi": "10.1109/tcbb.2022.3173562",
      "title": "LitMC-BERT: Transformer-Based Multi-Label Classification of Biomedical Literature With An Application on COVID-19 Literature Curation",
      "abstract": "The rapid growth of biomedical literature poses a significant challenge for curation and interpretation. This has become more evident during the COVID-19 pandemic. LitCovid, a literature database of COVID-19 related papers in PubMed, has accumulated over 200,000 articles with millions of accesses. Approximately 10,000 new articles are added to LitCovid every month. A main curation task in LitCovid is topic annotation where an article is assigned with up to eight topics, e.g., Treatment and Diagnosis. The annotated topics have been widely used both in LitCovid (e.g., accounting for \u223c18% of total uses) and downstream studies such as network generation. However, it has been a primary curation bottleneck due to the nature of the task and the rapid literature growth. This study proposes LITMC-BERT, a transformer-based multi-label classification method in biomedical literature. It uses a shared transformer backbone for all the labels while also captures label-specific features and the correlations between label pairs. We compare LITMC-BERT with three baseline models on two datasets. Its micro-F1 and instance-based F1 are 5% and 4% higher than the current best results, respectively, and only requires \u223c18% of the inference time than the Binary BERT baseline. The related datasets and models are available via https://github.com/ncbi/ml-transformer.",
      "year": "2022",
      "journal": "IEEE/ACM Transactions on Computational Biology and Bioinformatics",
      "authors": "Qingyu Chen et al.",
      "keywords": "Computer science; Bottleneck; Transformer; Inference; Annotation; Coronavirus disease 2019 (COVID-19); Natural language processing; Baseline (sea); Artificial intelligence; Information retrieval; F1 score; Machine learning; Biology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcbb.2022.3173562",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4223519342",
      "doi": "10.1109/mc.2022.3149017",
      "title": "The Role of Data and Artificial Intelligence in Driving Diversity, Equity, and Inclusion",
      "abstract": "Data and artificial intelligence hold promise for promoting diversity, equity, and inclusion. However, limited data availability, the biased nature of available data, and a lack of resources need to be overcome.",
      "year": "2022",
      "journal": "Computer",
      "authors": "Preeti Chauhan et al.",
      "keywords": "Computer science; Diversity (politics); Inclusion (mineral); Equity (law); Artificial intelligence; Data science; Machine learning; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mc.2022.3149017",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3177707346",
      "doi": "10.1109/access.2021.3096188",
      "title": "Optimization of the Medical Service Consultation System Based on the Artificial Intelligence of the Internet of Things",
      "abstract": "Artificial intelligence-assisted diagnosis systems are developing rapidly, but doctors are currently less aware of artificial intelligence-assisted diagnosis systems. Understanding how to allow doctors to accept and use artificial intelligence medical assistant diagnosis system can promote the implementation of artificial intelligence medical assistant diagnosis system applications. Taking into account the current difficulties faced by the Internet of Things medical consultation services, this paper proposes a business operation model based on multi-party participation and sharing of medical consultation resources. We designed the information flow, overall logic and service implementation process of the service model, and completed the construction of the artificial intelligence medical service service model. We combine IoT technology to build a vital signs monitoring environment and clarify how to use IoT devices. In the error backpropagation algorithm, there is no significant difference in the contribution of different samples to the weight change, which makes the adjustment of network parameters not easily affected by difficult medical consultation samples, thereby weakening the effect of network medical consultation. In order to solve this problem, this article defines the degree to which the sample belongs to its correct category as the confidence of medical inquiry, and divides the training sample into a dangerous sample and a safe sample according to a dynamic threshold. Based on the difficulty of medical inquiry, an improved new learning algorithm is proposed. The algorithm penalizes the loss of dangerous samples, so that the convolutional neural network pays more attention to dangerous samples and can learn more effective information. Aiming at the eight physiological characteristics of data, this paper adjusts the structure of the convolutional neural network to make it take into account the richness of data characteristics and the dynamics of data changes over time. The realized CNN optimization algorithm model has improved the prediction effect, and the accuracy rate of medical consultation reaches 90.15&amp;#x0025;, which is better than other machine learning algorithms.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Yi Mao et al.",
      "keywords": "Computer science; Artificial intelligence; Service (business); Sample (material); The Internet; Artificial neural network; Process (computing); Backpropagation; Machine learning; Medical diagnosis; World Wide Web; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3096188",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3185965585",
      "doi": "10.1109/access.2021.3099806",
      "title": "A Study on an Application System for the Sustainable Development of Smart Healthcare in China",
      "abstract": "The purpose of this study is to explore ways to apply information technologies such as big data, Internet of things (IoT), mobile internet, and so on to the healthcare industry. By analyzing the impact path of such high-techs on healthcare, it intends to propose an application system for the sustainable development of so called &#x201C;smart healthcare&#x201D;. It identifies the influencing factors of smart healthcare from three different perspectives: society, economy and environment. It then constructs an indicator system containing 14 factors, and comprehensively analyzes the importance and dependence of the factors by using Fuzzy Decision-making Trial and Evaluation Laboratory (DEMATEL) and Interpretative Structural Modeling Method (ISM) based on a multi-level hierarchy model. Using the theoretical framework of scientific research methods, this paper reveals the hierarchical path of the sustainable development of the whole intelligent healthcare which starts from the social level, combines the social and economic levels to achieve the balanced development of benefits, and finally brings the benefits to the environmental level. Based on this finding, this paper develops a sustainable application system for intelligent medicine in three levels: government, enterprise and user. The development of the sustainable application system for smart healthcare can provide theoretical guidance for model application evaluation.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Xingqun Xue et al.",
      "keywords": "China; Sustainable development; Health care; Computer science; Healthcare system; Economic growth; Political science; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3099806",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4293371134",
      "doi": "10.1109/access.2022.3202008",
      "title": "BOFRF: A Novel Boosting-Based Federated Random Forest Algorithm on Horizontally Partitioned Data",
      "abstract": "The application of federated learning on ensemble methods is a common practice with the goal of increasing the predictive power of local models. However, although existing federated solutions utilizing ensemble methods can achieve this when the datasets of sites are balanced and of good quality, i.e., the local models are already above a certain accuracy threshold, they usually fail to provide the same level of improvement to the models of sites that have an unsuccessful classifier because of their poor quality or imbalanced data. To address this challenge, we propose a novel federated ensemble classification algorithm for horizontally partitioned data, namely Boosting-based Federated Random Forest (BOFRF), which not only increases the predictive power of all participating sites, but also provides significantly high improvement on the predictive power of sites having unsuccessful local models. We implement a federated version of random forest, which is a well-known bagging algorithm, by adapting the idea of boosting to it. We introduce a novel aggregation and weight calculation methodology that assigns weights to local classifiers based on their classification performance at each site without increasing the communication or computation cost. We evaluate the performance of our proposed algorithm in different federated environments that we set up by using four healthcare datasets. The empirical results show that BOFRF improves the predictive power of local random forest models in all cases. The advantage of BOFRF is that the level of improvement it provides for sites having unsuccessful local models is significantly high unlike existing solutions.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mert Gen\u00e7t\u00fcrk et al.",
      "keywords": "Random forest; Boosting (machine learning); Computer science; Ensemble learning; Computation; Machine learning; Classifier (UML); Data mining; Ensemble forecasting; Gradient boosting; Artificial intelligence; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3202008",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3107878263",
      "doi": "10.1109/access.2020.3041173",
      "title": "Facial Expression Rendering in Medical Training Simulators: Current Status and Future Directions",
      "abstract": "Recent technological advances in robotic sensing and actuation methods have prompted development of a range of new medical training simulators with multiple feedback modalities. Learning to interpret facial expressions of a patient during medical examinations or procedures has been one of the key focus areas in medical training. This article reviews facial expression rendering systems in medical training simulators that have been reported to date. Facial expression rendering approaches in other domains are also summarized to incorporate the knowledge from those works into developing systems for medical training simulators. Classifications and comparisons of medical training simulators with facial expression rendering are presented, and important design features, merits and limitations are outlined. Medical educators, students and developers are identified as the three key stakeholders involved with these systems and their considerations and needs are presented. Physical-virtual (hybrid) approaches provide multimodal feedback, present accurate facial expression rendering, and can simulate patients of different age, gender and ethnicity group; makes it more versatile than virtual and physical systems. The overall findings of this review and proposed future directions are beneficial to researchers interested in initiating or developing such facial expression rendering systems in medical training simulators.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Thilina Dulantha Lalitharatne et al.",
      "keywords": "Rendering (computer graphics); Computer science; Modalities; Facial expression; Human\u2013computer interaction; Multimedia; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3041173",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387145972",
      "doi": "10.1109/jbhi.2023.3320139",
      "title": "SHAPE: A Sample-Adaptive Hierarchical Prediction Network for Medication Recommendation",
      "abstract": "Effectively medication recommendation with complex multimorbidity conditions is a critical yet challenging task in healthcare. Most existing works predicted medications based on longitudinal records, which assumed the encoding format of intra-visit medical events are serialized and information transmitted patterns of learning longitudinal sequence data are stable. However, the following conditions may have been ignored: 1) A more compact encoder for intra-relationship in the intra-visit medical event is urgent; 2) Strategies for learning accurate representations of the variable longitudinal sequences of patients are different. In this article, we proposed a novel Sample-adaptive Hierarchical medicAtion Prediction nEtwork, termed SHAPE, to tackle the above challenges in the medication recommendation task. Specifically, we design a compact intra-visit set encoder to encode the relationship in the medical event for obtaining visit-level representation and then develop an inter-visit longitudinal encoder to learn the patient-level longitudinal representation efficiently. To endow the model with the capability of modeling the variable visit length, we introduce a soft curriculum learning method to assign the difficulty of each sample automatically by the visit length. Extensive experiments on a benchmark dataset verify the superiority of our model compared with several state-of-the-art baselines.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Sicen Liu et al.",
      "keywords": "Benchmark (surveying); Computer science; Encoder; Task (project management); ENCODE; Event (particle physics); Encoding (memory); Sample (material); Artificial intelligence; Representation (politics); Machine learning; Feature learning; Set (abstract data type); Variable (mathematics); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3320139",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394939130",
      "doi": "10.1109/ojcs.2024.3389462",
      "title": "Affective Computing and the Road to an Emotionally Intelligent Metaverse",
      "abstract": "The metaverse is currently undergoing a profound transformation, fundamentally reshaping our perception of reality. It has transcended its origins to become an expansion of human consciousness, seamlessly blending the physical and virtual worlds. Amidst this transformative evolution, numerous applications are striving to mould the metaverse into a digital counterpart capable of delivering immersive human-like experiences. These applications envisage a future where users effortlessly traverse between physical and digital dimensions. Taking a step forward, affective computing technologies can be utilised to identify users&#x0027; emotional cues and convey authentic emotions, enhancing genuine, meaningful, and context-aware interactions in the digital world. In this paper, we explore how integrating emotional intelligence can enhance the traditional metaverse, birthing an emotionally intelligent metaverse (EIM). Our work illuminates the multifaceted potential of EIM across diverse sectors, including healthcare, education, gaming, automotive, customer service, human resources, marketing, and urban metaverse cyberspace. Through our examination of these sectors, we uncover how infusing emotional intelligence enriches user interactions and experiences within the metaverse. Nonetheless, this transformative journey is riddled with challenges, and we address the obstacles hindering the realisation of EIM&#x0027;s full potential. By doing so, we lay the groundwork for future research endeavours aimed at further enhancing and refining the captivating journey into the world of EIM.",
      "year": "2024",
      "journal": "IEEE Open Journal of the Computer Society",
      "authors": "Farrukh Pervez et al.",
      "keywords": "Computer science; Human\u2013computer interaction; Metaverse; Intelligent transportation system; Psychology; Engineering; Transport engineering; Virtual reality",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcs.2024.3389462",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4394827054",
      "doi": "10.1109/access.2024.3388889",
      "title": "Synchronizing Object Detection: Applications, Advancements and Existing Challenges",
      "abstract": "From pivotal roles in autonomous vehicles, healthcare diagnostics, and surveillance systems to seamlessly integrating with augmented reality, object detection algorithms stand as the cornerstone in unraveling the complexities of the visual world. Tracing the trajectory from conventional region-based methods to the latest neural network architectures reveals a technological renaissance where algorithms metamorphose into digital artisans. However, this journey is not without hurdles, prompting researchers to grapple with real-time detection, robustness in varied environments, and interpretability amidst the intricacies of deep learning. The allure of addressing issues such as occlusions, scale variations, and fine-grained categorization propels exploration into uncharted territories, beckoning the scholarly community to contribute to an ongoing saga of innovation and discovery. This research offers a comprehensive panorama, encapsulating the applications reshaping our digital reality, the advancements pushing the boundaries of perception, and the open issues extending an invitation to the next generation of visionaries to explore uncharted frontiers within object detection.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Md. Tanzib Hosain et al.",
      "keywords": "Computer science; Data science; Panorama; Bespoke; Robustness (evolution); Interpretability; Deep learning; Artificial intelligence; Object detection; Architecture",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3388889",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226405060",
      "doi": "10.1109/access.2022.3165574",
      "title": "Skin Disease Analysis With Limited Data in Particular Rosacea: A Review and Recommended Framework",
      "abstract": "Recently, the rapid advancements in Deep Learning and Computer Vision technologies have introduced a new and exciting era in the field of skin disease analysis. However, there are certain challenges in the roadmap towards developing such technologies for real-life applications that must be investigated. This study considers one of the key challenges in data acquisition and computation, viz. data scarcity. Data scarcity is a central problem in acquiring medical images and applying machine learning techniques to train Convolutional Neural Networks for disease diagnosis. The main objective of this study is to explore the possible methods to deal with the data scarcity problem and to improve diagnosis with small datasets. The challenges in data acquisition for a few lamentably neglected skin conditions such as rosacea are an excellent instance to explore the possibilities of improving computer-aided skin disease diagnosis. With data scarcity in mind, the possible techniques explored and discussed include Generative Adversarial Networks, Meta-Learning, Few-Shot classification, and 3D face modelling. Furthermore, the existing studies are discussed based on skin conditions considered, data volume and implementation choices. Some future research directions are recommended.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Anwesha Mohanty et al.",
      "keywords": "Computer science; Scarcity; Rosacea; Convolutional neural network; Artificial intelligence; Field (mathematics); Machine learning; Data science; Deep learning; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3165574",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2972653183",
      "doi": "10.1109/access.2019.2960371",
      "title": "Reducing the Model Variance of a Rectal Cancer Segmentation Network",
      "abstract": "In preoperative imaging, the demarcation of rectal cancer with magnetic resonance images provides an important basis for cancer staging and treatment planning. Recently, deep learning has greatly improved the state-of-the-art method in automatic segmentation. However, limitations in data availability in the medical field can cause large variance and consequent overfitting to medical image segmentation networks. In this study, we propose methods to reduce the model variance of a rectal cancer segmentation network by adding a rectum segmentation task and performing data augmentation; the geometric correlation between the rectum and rectal cancer motivated the former approach. Moreover, we propose a method to perform a bias-variance analysis within an arbitrary region-of-interest (ROI) of a segmentation network, which we applied to assess the efficacy of our approaches in reducing model variance. As a result, adding a rectum segmentation task reduced the model variance of the rectal cancer segmentation network within tumor regions by a factor of 0.90; data augmentation further reduced the variance by a factor of 0.89. These approaches also reduced the training duration by a factor of 0.96 and a further factor of 0.78, respectively. Our approaches will improve the quality of rectal cancer staging by increasing the accuracy of its automatic demarcation and by providing rectum boundary information since rectal cancer staging requires the demarcation of both rectum and rectal cancer. Besides such clinical benefits, our method also enables segmentation networks to be assessed with bias-variance analysis within an arbitrary ROI, such as a cancerous region.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Joohyung Lee et al.",
      "keywords": "Segmentation; Computer science; Artificial intelligence; Rectum; Overfitting; Variance (accounting); Image segmentation; Pattern recognition (psychology); Medicine; Artificial neural network; Surgery",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2960371",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382998827",
      "doi": "10.1109/jproc.2023.3286445",
      "title": "Approaches, Applications, and Challenges in Physiological Emotion Recognition\u2014A Tutorial Overview",
      "abstract": "An automatic emotion recognition system can serve as a fundamental framework for various applications in daily life from monitoring emotional well-being to improving the quality of life through better emotion regulation. Understanding the process of emotion manifestation becomes crucial for building emotion recognition systems. An emotional experience results in changes not only in interpersonal behavior but also in physiological responses. Physiological signals are one of the most reliable means for recognizing emotions since individuals cannot consciously manipulate them for a long duration. These signals can be captured by medical-grade wearable devices, as well as commercial smart watches and smart bands. With the shift in research direction from laboratory to unrestricted daily life, commercial devices have been employed ubiquitously. However, this shift has introduced several challenges, such as low data quality, dependency on subjective self-reports, unlimited movement-related changes, and artifacts in physiological signals. This tutorial provides an overview of practical aspects of emotion recognition, such as experiment design, properties of different physiological modalities, existing datasets, suitable machine learning algorithms for physiological data, and several applications. It aims to provide the necessary psychological and physiological backgrounds through various emotion theories and the physiological manifestation of emotions, thereby laying a foundation for emotion recognition. Finally, the tutorial discusses open research directions and possible solutions.",
      "year": "2023",
      "journal": "Proceedings of the IEEE",
      "authors": "Yekta Said Can et al.",
      "keywords": "Modalities; Computer science; Process (computing); Emotion recognition; Human\u2013computer interaction; Wearable computer; Affective computing; Quality (philosophy); Cognitive psychology; Artificial intelligence; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2023.3286445",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205416091",
      "doi": "10.1109/access.2021.3136026",
      "title": "Tooth Numbering and Condition Recognition on Dental Panoramic Radiograph Images Using CNNs",
      "abstract": "Dentists and medical personnel strive to provide patients with prompt medical services. In the past, Dental Panoramic Radiograph (DPR) was often used to diagnose and understand the dental condition of patients. In recent years, many machine learning and deep learning methods have been applied to medical image recognition problems. Moreover, when combined with deep learning methods, data augmentation and image pre-processing methods can also give positive feedback. This study aims to combine data augmentation and data pre-processing methods with advanced deep learning methods to build an innovative and practical two-phase DPR recognition and classification method to assist dentists in diagnosis. It will help to improve the medical quality of dental services by speeding up and saving valuable physician manpower cost and time. Prior to the two-phase recognition based on several effective Convolutional Neural Networks (CNNs), the data augmentation and data pre-processing are processed. In the first phase of this method, the position and numbering of the tooth is automatically classified as one of 32 tooth positions from the DPR tooth images. In the second phase, the dental conditions are automatically recognized from the 6 dental conditions, including orthodontics, endodontic therapy, dental restoration, impaction, implant, and dental prosthesis. The experimental results showed that the trained network, without image pre-processing and augmentation, identified the dental position numbering with an accuracy of 90.93&#x0025;, and the dental condition with an accuracy of 93.33&#x0025;. After data augmentation, the accuracy of tooth numbering can be increased to 95.62&#x0025;, and the accuracy of dental condition can be increased to 98.33&#x0025;. This is a significant improvement when compared with past research.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Szu\u2010Yin Lin et al.",
      "keywords": "Numbering; Computer science; Artificial intelligence; Convolutional neural network; Impaction; Deep learning; Dentistry; Computer vision; Orthodontics; Medicine; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3136026",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4379985031",
      "doi": "10.1109/access.2023.3284682",
      "title": "Clinical Errors From Acronym Use in Electronic Health Record: A Review of NLP-Based Disambiguation Techniques",
      "abstract": "The adoption of Electronic Health Record (EHR) and other e-health infrastructures over the years has been characterized by an increase in medical errors. This is primarily a result of the widespread usage of medical acronyms and abbreviations with multiple possible senses (i.e., ambiguous acronyms). The advent of Artificial Intelligence (AI) technology, specifically Natural Language Processing (NLP), has presented a promising avenue for tackling the intricate issue of automatic sense resolution of acronyms. Notably, the application of Machine Learning (ML) techniques has proven to be highly effective in the development of systems aimed at this objective, garnering significant attention and interest within the research and industry domains in recent years. The significance of automating the resolution of medical acronym senses cannot be overstated, especially in the context of modern healthcare delivery with the widespread use of EHR. However, it is disheartening to note that comprehensive studies examining the global adoption of EHR, assessing the impact of acronym usage on medical errors within EHR systems, and reporting on the latest trends and advancements in ML-based NLP solutions for disambiguating medical acronyms remain severely limited. In this current study, we present a detailed overview on medical error, its origins, unintended effects, and EHR-related errors as a subclass of clinical error. Furthermore, this paper investigates the adoption of EHR systems in developed and developing nations, as well as the review concludes with an examination of various artificial intelligence techniques, particularly machine learning algorithms for medical acronym and abbreviation disambiguation in EHRs.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Temitope Ibrahim Amosa et al.",
      "keywords": "Acronym; Computer science; Artificial intelligence; Context (archaeology); Electronic health record; Data science; Natural language processing; Health care",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3284682",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386470319",
      "doi": "10.1109/tmi.2023.3312524",
      "title": "Clinically-Inspired Multi-Agent Transformers for Disease Trajectory Forecasting From Multimodal Data",
      "abstract": "Deep neural networks are often applied to medical images to automate the problem of medical diagnosis. However, a more clinically relevant question that practitioners usually face is how to predict the future trajectory of a disease. Current methods for prognosis or disease trajectory forecasting often require domain knowledge and are complicated to apply. In this paper, we formulate the prognosis prediction problem as a one-to-many prediction problem. Inspired by a clinical decision-making process with two agents-a radiologist and a general practitioner - we predict prognosis with two transformer-based components that share information with each other. The first transformer in this framework aims to analyze the imaging data, and the second one leverages its internal states as inputs, also fusing them with auxiliary clinical data. The temporal nature of the problem is modeled within the transformer states, allowing us to treat the forecasting problem as a multi-task classification, for which we propose a novel loss. We show the effectiveness of our approach in predicting the development of structural knee osteoarthritis changes and forecasting Alzheimer's disease clinical status directly from raw multi-modal data. The proposed method outperforms multiple state-of-the-art baselines with respect to performance and calibration, both of which are needed for real-world applications. An open-source implementation of our method is made publicly available at https://github.com/Oulu-IMEDS/CLIMATv2.",
      "year": "2023",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Huy Hoang Nguyen et al.",
      "keywords": "Computer science; Artificial intelligence; Transformer; Machine learning; Trajectory; Deep learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2023.3312524",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390603751",
      "doi": "10.1109/tse.2024.3350019",
      "title": "Test Input Prioritization for Machine Learning Classifiers",
      "abstract": "peer reviewed",
      "year": "2024",
      "journal": "IEEE Transactions on Software Engineering",
      "authors": "Xueqi Dang et al.",
      "keywords": "Computer science; Prioritization; Test (biology); Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tse.2024.3350019",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3129228121",
      "doi": "10.1109/jstqe.2021.3059532",
      "title": "Neuroblastoma Cells Classification Through Learning Approaches by Direct Analysis of Digital Holograms",
      "abstract": "The label-free single cell analysis by machine and Deep Learning, in combination with digital holography in transmission microscope configuration, is becoming a powerful framework exploited for phenotyping biological samples. Usually, quantitative phase images of cells are retrieved from the reconstructed complex diffraction patterns and used as inputs of a deep neural network. However, the phase retrieval process can be very time consuming and prone to errors. Here we address the classification of cells by using learning strategies with images coming directly from the raw recorded digital holograms, i.e. without any data processing or refocusing involved. Indeed, in the raw digital hologram the entire complex amplitude information of the sample is intrinsically embedded in the form of modulated fringes. We develop a training strategy, based on deep and feature based machine learning models, in order extract such information by skipping the classical reconstruction process for classifying different neuroblastoma cells. We provided an experimental validation by using the proposed strategy to classify two neuroblastoma cell lines.",
      "year": "2021",
      "journal": "IEEE Journal of Selected Topics in Quantum Electronics",
      "authors": "Mattia Delli Priscoli et al.",
      "keywords": "Computer science; Artificial intelligence; Holography; Digital holography; Deep learning; Artificial neural network; Pattern recognition (psychology); Process (computing); Feature (linguistics); Feature extraction; Machine learning; Optics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstqe.2021.3059532",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386275539",
      "doi": "10.1109/access.2023.3310400",
      "title": "Federated Learning in Computer Vision",
      "abstract": "Federated Learning (FL) has recently emerged as a novel machine learning paradigm allowing to preserve privacy and to account for the distributed nature of the learning process in many real-world settings. Computer vision tasks deal with huge datasets often with critical privacy issues, therefore many federated learning approaches have been presented to exploit its distributed and privacy-preserving nature. Firstly, this paper introduces the different FL settings used in computer vision and the main challenges that need to be tackled. Then, it provides a comprehensive overview of the different strategies used for FL in vision applications and presents several different approaches for image classification, object detection, semantic segmentation and for focused settings in face recognition and medical imaging. For the various approaches the considered FL setting, the employed data and methodologies and the achieved results are thoroughly discussed.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Donald Shenaj et al.",
      "keywords": "Computer science; Exploit; Process (computing); Artificial intelligence; Object detection; Machine learning; Segmentation; Cognitive neuroscience of visual object recognition; Object (grammar); Human\u2013computer interaction; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3310400",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2112167165",
      "doi": "10.1109/jtehm.2014.2297953",
      "title": "Accurate and Fully Automatic Hippocampus Segmentation Using Subject-Specific 3D Optimal Local Maps Into a Hybrid Active Contour Model",
      "abstract": "Assessing the structural integrity of the hippocampus (HC) is an essential step toward prevention, diagnosis, and follow-up of various brain disorders due to the implication of the structural changes of the HC in those disorders. In this respect, the development of automatic segmentation methods that can accurately, reliably, and reproducibly segment the HC has attracted considerable attention over the past decades. This paper presents an innovative 3-D fully automatic method to be used on top of the multiatlas concept for the HC segmentation. The method is based on a subject-specific set of 3-D optimal local maps (OLMs) that locally control the influence of each energy term of a hybrid active contour model (ACM). The complete set of the OLMs for a set of training images is defined simultaneously via an optimization scheme. At the same time, the optimal ACM parameters are also calculated. Therefore, heuristic parameter fine-tuning is not required. Training OLMs are subsequently combined, by applying an extended multiatlas concept, to produce the OLMs that are anatomically more suitable to the test image. The proposed algorithm was tested on three different and publicly available data sets. Its accuracy was compared with that of state-of-the-art methods demonstrating the efficacy and robustness of the proposed method.",
      "year": "2014",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Dimitrios Zarpalas et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Robustness (evolution); Active contour model; Set (abstract data type); Pattern recognition (psychology); Heuristic; Image segmentation",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2014.2297953",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4290993798",
      "doi": "10.1109/jbhi.2022.3198254",
      "title": "Dealing With Inaccurate Sensor Data in the Context of Mobile Crowdsensing and mHealth",
      "abstract": "The technological capabilities and ubiquity of smart mobile devices favor the combined utilization of Ecological Momentary Assessments (EMA) and Mobile Crowdsensing (MCS). In the healthcare domain, this combination particularly enables the collection of ecologically valid and longitudinal data. Furthermore, the context in which these data are collected can be captured through the use of smartphone sensors as well as externally connected sensors. The TrackYourTinnitus (TYT) mobile platform uses these concepts to collect the user's individual subjective perception of tinnitus as well as an objective environmental sound level. However, the sound level data in the TYT database are subject to several possible sensor errors and therefore do not allow a meaningful interpretation in terms of correlation with tinnitus symptoms. To this end, a data-centric approach based on Principal Component Analysis (PCA) is proposed in this paper to cleanse MCS mHealth data sets from erroneous sensor data. To further improve the approach, additional information (i.e., responses to the EMA questionnaire) is considered in the PCA and a prior check for constant values is performed. To demonstrate the practical feasibility of the approach, in addition to TYT data, where it is generally unknown which sensor measurements are actually erroneous, a simulation with generated data was designed and performed to evaluate the performance of the approach with different parameters based on different quality metrics. The results obtained show that the approach is able to detect an average of 29.02% of the errors, with an average false-positive rate of 14.11%, yielding an overall error reduction of 22.74%.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Robin Kraft et al.",
      "keywords": "Computer science; Crowdsensing; Context (archaeology); mHealth; Data mining; Data quality; Data collection; Principal component analysis; Accelerometer; Artificial intelligence; Machine learning; Data science; Statistics; Health care; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3198254",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3153158914",
      "doi": "10.1109/access.2021.3074550",
      "title": "Estimating Gestational Age From Maternal-Fetal Heart Rate Coupling Parameters",
      "abstract": "Maternal and fetal heartbeat couplings are evident throughout fetal development. Most of the published work, however, did not consider maternal physiological factors such as Heart Rate Variability (HRV), and did not investigate the interrelationships of maternal-fetal coupling parameters. The aims of this study are to investigate whether: 1) maternal-fetal Heart Rate (HR) coupling ( &#x03BB;-based) parameters are associated with fetal development, and 2) fetal gold standard Gestational Age (GA) can be estimated using maternal-fetal HR coupling and variability of various recording lengths. The study considered Electrocardiogram (ECG) signals from 60 healthy pregnant women with no records of fetal abnormalities. HRV and &#x03BB; parameters at various Maternal:Fetal coupling ratios were calculated, and stepwise regression was utilized to create generalized linear regression models considering various lengths of recorded signals (1 and 5 min) to produce a robust estimate of fetal age. Cross-validation performances were evaluated by the mean square root of the average of squared errors (mRMSE) between age values estimated by the proposed models and gold standard GA identified by Crown-Rump Length (CRL). Effect of Fetal Behavioral States (FBSes) on proposed models with different recording lengths was considered to examine the highly nonstationary nature of signals. We found that HR coupling strength for a specific ratio is not constant throughout gestation. Results showed that ratios of 2:3 and 2:4 were common between the proposed models. The value of &#x03BB;[2:3] was found to be positively correlated with GA, while &#x03BB;[2:4] had a negative correlation. Compared with gold standard GA identified by CRL, the proposed regression model resulted in mRMSE of 2.67 and 3.69 weeks for the recordings of 5 and 1 min, respectively. However, when FBS was considered, both models produced lower estimation errors. Fetal GA can be more reliably estimated by a multivariate model incorporating fetal and maternal HR coupling and HRV parameters using 5 min of ECG signals.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Maisam Wahbah et al.",
      "keywords": "Fetus; Gestational age; Obstetrics; Coupling (piping); Fetal heart rate; Medicine; Pregnancy; Materials science; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3074550",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3210552024",
      "doi": "10.1109/access.2021.3121092",
      "title": "Improving the Correctness of Medical Diagnostics Based on Machine Learning With Coloured Petri Nets",
      "abstract": "Advanced software and storage technologies have enabled medical facilities to record and store vast amounts of data about cancer patients. There is a strong demand for an accurate and interpretable method to perform cancer prognostic for effective treatment. Machine learning algorithms, undoubtedly, demonstrate a remarkable ability to recognize models and extract patterns from data to improve medical prognosis decision-making. But machine learning outcomes are prone to bias and inaccurate labelling. Therefore, to negate the impact of such errors in the prognostic decision-making process, the mechanism to correct such errors is in high demand. This article addresses this problem by proposing the use of Coloured Petri nets formalism to ensure the correctness of the machine learning based prognostic process. Use of formalism makes it possible to ensure that prognostic decisions are correct and understandable. Empirical results show that we have increased the accuracy of prognostic decisions by up to 90&#x0025;. This research supports improved prognostic decision-making for the effective treatment and identification of cancer patients.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Muhammad Nauman et al.",
      "keywords": "Correctness; Computer science; Petri net; Formalism (music); Machine learning; Artificial intelligence; Distributed computing; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3121092",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366463707",
      "doi": "10.1109/jbhi.2023.3268729",
      "title": "An Overview of Data Integration in Neuroscience With Focus on Alzheimer's Disease",
      "abstract": "This work represents the first attempt to provide an overview of how to face data integration as the result of a dialogue between neuroscientists and computer scientists. Indeed, data integration is fundamental for studying complex multifactorial diseases, such as the neurodegenerative diseases. This work aims at warning the readers of common pitfalls and critical issues in both medical and data science fields. In this context, we define a road map for data scientists when they first approach the issue of data integration in the biomedical domain, highlighting the challenges that inevitably emerge when dealing with heterogeneous, large-scale and noisy data and proposing possible solutions. Here, we discuss data collection and statistical analysis usually seen as parallel and independent processes, as cross-disciplinary activities. Finally, we provide an exemplary application of data integration to address Alzheimer's Disease (AD), which is the most common multifactorial form of dementia worldwide. We critically discuss the largest and most widely used datasets in AD, and demonstrate how the emergence of machine learning and deep learning methods has had a significant impact on disease's knowledge particularly in the perspective of an early AD diagnosis.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Rosanna Turrisi et al.",
      "keywords": "Data science; Computer science; Data integration; Context (archaeology); Perspective (graphical); Big data; Domain (mathematical analysis); Neuroinformatics; Dementia; Disease; Cognitive science; Artificial intelligence; Medicine; Psychology; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3268729",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390707173",
      "doi": "10.1109/tbme.2023.3348800",
      "title": "ZCHSound: Open-Source ZJU Paediatric Heart Sound Database With Congenital Heart Disease",
      "abstract": "This study has successfully established a large-scale, high-quality, rigorously standardized pediatric CHD sound database with precise disease diagnosis. This database not only provides important learning resources for clinical doctors in auscultation knowledge but also offers valuable data support for algorithm engineers in developing intelligent auscultation algorithms.",
      "year": "2024",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Weijie Jia et al.",
      "keywords": "Heart disease; Auscultation; Workload; Medical diagnosis; Computer science; Sound (geography); Medicine; Heart Auscultation; Database; Speech recognition; Electrocardiography; Cardiology; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2023.3348800",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313027435",
      "doi": "10.1109/access.2022.3210468",
      "title": "An Accurate and Explainable Deep Learning System Improves Interobserver Agreement in the Interpretation of Chest Radiograph",
      "abstract": "Interpretation of chest radiographs (CXR) is a difficult but essential task for detecting thoracic abnormalities. Recent artificial intelligence (AI) algorithms have achieved radiologist-level performance on various medical classification tasks. However, only a few studies addressed the localization of abnormal findings from CXR scans, which is essential in explaining the image-level classification to radiologists. Additionally, the actual impact of AI algorithms on the diagnostic performance of radiologists in clinical practice remains relatively unclear. To bridge these gaps, we developed an explainable deep learning system called VinDr-CXR that can classify a CXR scan into multiple thoracic diseases and, at the same time, localize most types of critical findings on the image. VinDr-CXR was trained on 51,485 CXR scans with radiologist-provided bounding box annotations. It demonstrated a comparable performance to experienced radiologists in classifying 6 common thoracic diseases on a retrospective validation set of 3,000 CXR scans, with a mean area under the receiver operating characteristic curve (AUROC) of 0.967 (95&#x0025; confidence interval [CI]: 0.958&#x2013;0.975). The VinDr-CXR was also externally validated in independent patient cohorts and showed its robustness. For the localization task with 14 types of lesions, our free-response receiver operating characteristic (FROC) analysis showed that the VinDr-CXR achieved a sensitivity of 80.2&#x0025; at the rate of 1.0 false-positive lesion identified per scan. A prospective study was also conducted to measure the clinical impact of the VinDr-CXR in assisting six experienced radiologists. The results indicated that the proposed system, when used as a diagnosis supporting tool, significantly improved the agreement between radiologists themselves with an increase of 1.5&#x0025; in mean Fleiss&#x2019; Kappa. We also observed that, after the radiologists consulted VinDr-CXR&#x2019;s suggestions, the agreement between each of them and the system was remarkably increased by 3.3&#x0025; in mean Cohen&#x2019;s Kappa. Altogether, our results highlight the potentials of the proposed deep learning system as an effective assistant to radiologists in clinical practice. Part of the dataset used for developing the VinDr-CXR system has been made publicly available at <uri>https://physionet.org/content/vindr-cxr/1.0.0/</uri>.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Hieu H. Pham et al.",
      "keywords": "Receiver operating characteristic; Radiography; Medicine; Cohen's kappa; Chest radiograph; Radiology; Artificial intelligence; Kappa; Medical imaging; Robustness (evolution); Computer science; Medical diagnosis; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3210468",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382138474",
      "doi": "10.1109/access.2023.3289397",
      "title": "Avoiding Shortcut-Learning by Mutual Information Minimization in Deep Learning-Based Image Processing",
      "abstract": "Deep learning models are increasingly being used in detecting patterns and correlations in medical imaging data such as magnetic resonance imaging. However, conventional methods are incapable of considering the real underlying causal relationships. In the presence of confounders, spurious correlations between data, imaging process, content, and output can occur that allow the network to learn shortcuts instead of the desired causal relationship. This effect is even more prominent in new environments or when using out-of-distribution data since the learning process is primarily focused on correlations and patterns within the data. Hence, wrong conclusions or false diagnoses can be obtained from such confounded models. In this paper, we propose a novel framework, denoted as Mutual Information Minimization Model (MIMM), that predicts the desired causal outcome while simultaneously reducing the influence of present spurious correlations. The input imaging data is encoded into a feature vector that is split into two components to predict the primary task and the presumed spuriously correlated factor separately. We hypothesize that learned mutual information between both feature vector components can be reduced to achieve independence, i.e., confounder-free task prediction. The proposed approach is investigated on five databases: two non-medical benchmark databases (Morpho-MNIST and Fashion-MNIST) to verify the hypothesis and three medical databases (German National Cohort, UK Biobank, and ADNI). The results show that our proposed framework serves as a solution to address the limitations of conventional deep learning models in medical image analysis. By explicitly considering and minimizing spurious correlations, it learns causal relationships which result in more accurate and reliable predictions. The novel contributions in this work are: 1) the separation of features into the prediction of the primary task and the spuriously correlated factor; 2) MIMM targets the preservation of invariance to counterfactuals, prevents shortcut learning, and enables confounder-free network training; and 3) the mutual information minimization addresses heterogeneous data cohorts as usually encountered in the medical domain.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Louisa Fay et al.",
      "keywords": "Computer science; Spurious relationship; MNIST database; Artificial intelligence; Machine learning; Mutual information; Feature (linguistics); Benchmark (surveying); Pattern recognition (psychology); Medical diagnosis; Multi-task learning; Feature learning; Deep learning; Data mining; Task (project management)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3289397",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388642353",
      "doi": "10.1109/access.2023.3332122",
      "title": "A Dimension Centric Proximate Attention Network and Swin Transformer for Age-Based Classification of Mild Cognitive Impairment From Brain MRI",
      "abstract": "The early identification and treatment of Mild Cognitive Impairment (MCI) play a crucial role in managing the risk of Alzheimer&#x2019;s disease (AD). However, current methods for categorizing progressive MCI and stable MCI based on brain MRI scans have proven insufficient due to the subtle nature of the features involved. This research aims to improve the effectiveness of MCI classification through the utilization of a Deep Learning (DL) network. The primary objective of this work is to improve the feature representation of brain MRI scans for more accurate classification. The proposed model is a hybrid MCI classification system that integrates three components: the Swin Transformer, the Dimension Centric Proximity Aware Attention Network (DCPAN), and the Age Deviation Factor (ADF). The proposed network achieves better classification results through a unique feature fusion approach that combines global, local, proximal features, and dimensional dependencies. It effectively combines fine-grained details with broader contextual information to extract discriminative features. Experimental results demonstrate the effectiveness of the proposed network, achieving an accuracy of 79.8&#x0025;, precision of 76.6&#x0025;, recall of 80.2&#x0025;, and an F1-score of 78.4&#x0025; when evaluated on the ADNI dataset.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "T. Illakiya et al.",
      "keywords": "Discriminative model; Computer science; Artificial intelligence; Recall; Cognitive impairment; Pattern recognition (psychology); Machine learning; Dimension (graph theory); Cognition; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3332122",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4378194781",
      "doi": "10.1109/access.2023.3280071",
      "title": "A Comprehensive Study of Human Factors, Sensory Principles, and Commercial Solutions for Future Human-Centered Working Operations in Industry 5.0",
      "abstract": "The purpose of this study is to explore the measurement of human factors in the workplace that can provide critical insights into workers&#x2019; well-being. Human factors refer to physical, cognitive, and psychological states that can impact the efficiency, effectiveness, and mental health of workers. The article identifies six human factors that are particularly crucial in today&#x2019;s workplaces: physical fatigue, attention, mental workload, stress, trust, and emotional state. Each of these factors alters the human physiological response in a unique way, affecting the human brain, cardiovascular, electrodermal, muscular, respiratory, and ocular reactions. This paper provides an overview of these human factors and their specific influence on psycho-physiological responses, along with suitable technologies to measure them in working environments and the currently available commercial solutions to do so. By understanding the importance of these human factors, employers can make informed decisions to create a better work environment that leads to improved worker well-being and productivity.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Erlantz Loizaga et al.",
      "keywords": "Workload; Cognition; Productivity; Work (physics); Computer science; Applied psychology; Psychology; Risk analysis (engineering); Business; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3280071",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4285213032",
      "doi": "10.1109/access.2022.3175816",
      "title": "Adversary-Aware Multimodal Neural Networks for Cancer Susceptibility Prediction From Multiomics Data",
      "abstract": "Artificial intelligence (AI) systems are increasingly used in health and personalized care. However, the adoption of data-driven approaches in many clinical settings has been hampered due to their inability to perform in a reliable and safe manner to leverage accurate and trustworthy diagnoses. A critical and challenging usage scenario for AI is aiding the treatment of cancerous conditions. Providing accurate diagnosis for cancer is a challenging problem in precision oncology. Although machine learning (ML)-based approaches are very effective at cancer susceptibility prediction and subsequent treatment recommendations, ML models can be vulnerable to adversarial attacks. Since adversarially weak models can lead to wrong clinical recommendations, such vulnerabilities is critical &amp;#x2013; especially when AI-guided systems are used to aid medical doctors. Therefore, it is indispensable that healthcare professionals employ trustworthy AI tools for predicting and assessing disease risks and progression. In this paper, we propose an &lt;italic&gt;adversary-aware multimodal convolutional autoencoder&lt;/italic&gt; (MCAE) model for cancer susceptibility prediction from multi-omics data consisting of copy number variations (CNVs), miRNA expression, and gene expression (GE). Based on different representational learning techniques, the MCAE model learns multimodal feature representations from multi-omics data, followed by classifying the patient cohorts into different cancer types on multimodal embedding space that exhibit similar characteristics in end-to-end setting. To make the &lt;italic&gt;MCAE&lt;/italic&gt; model robust to adversaries and to provide consistent diagnosis, we formulate &lt;italic&gt;robustness&lt;/italic&gt; as a property, such that predictions remain stable with regard to small variations in the input. We study different adversarial attacks scenarios and take both proactive and reactive measures (e.g., adversarial retraining and identification of adversarial inputs). Experiment results show that the &lt;italic&gt;MCAE&lt;/italic&gt; model based on &lt;italic&gt;latent representation concatenation&lt;/italic&gt; (LRC) exhibits high confidence at predicting cancer types, giving an average precision and Matthews correlation coefficient (MCC) scores of 0.9625 and 0.8453, respectively and shows higher robustness when compared with state-of-the-art approaches against different attack scenarios w.r.t. &lt;italic&gt;ERM&lt;/italic&gt; and &lt;italic&gt;CLEVER&lt;/italic&gt; scores. Overall, our study suggests that a well-fitted and adversarially robust model can provide consistent and reliable diagnosis for cancer.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Md. Rezaul Karim et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Autoencoder; DECIPHER; Robustness (evolution); Leverage (statistics); Convolutional neural network; Medical diagnosis; Deep learning; Adversarial system; Bioinformatics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3175816",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4318766061",
      "doi": "10.1109/access.2023.3241488",
      "title": "Personalized Federated Learning for In-Hospital Mortality Prediction of Multi-Center ICU",
      "abstract": "Federated learning (FL), as a paradigm for addressing challenges of machine learning (ML) to be applied in private distributed data provides a novel and promising scheme to promote ML in multiple independently distributed healthcare institutions. However, the non-IID and unbalanced nature of the data distribution can decrease its performance, even resulting in the institutions losing motivation to participate in its training. This paper explored the problem with an in-hospital mortality prediction task under an actual multi-center ICU electronic health record database that preserves the original non-IID and unbalanced data distribution. It first analyzed the reason for the performance degradation of baseline FL under this data scenario, and then proposed a personalized FL (PFL) approach named POLA to tackle the problem. POLA is a personalized one-shot and two-step FL method capable of generating high-performance personalized models for each independent participant. The proposed method, POLA was compared with two other PFL methods in experiments, and the results indicate that it not only effectively improves the prediction performance of FL but also significantly reduces the communication rounds. Moreover, its generality and extensibility also make it potential to be extended to other similar cross-silo FL application scenarios.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ting Deng et al.",
      "keywords": "Computer science; Generality; Task (project management); Artificial intelligence; Scheme (mathematics); Federated learning; Extensibility; Data center; Machine learning; Task analysis; Personalized learning; Computer network; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3241488",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3092310125",
      "doi": "10.1109/access.2020.3029429",
      "title": "Extreme Multi-Label ICD Classification: Sensitivity to Hospital Service and Time",
      "abstract": "This work deals with clinical text mining for automatic classification of Electronic Health Records (EHRs) with respect to the International Classification of Diseases (ICD). ICD is the international standard for the identification of diseases and health conditions in EHRs and the foundation for reporting health statistics. Machine learning-based techniques have proven robust to infer classification models from EHRs. Since each EHR tends to involve multiple diseases, multi-label classification is required. The concern in this work is the versatility of the models inferred and their ability to generalise in two ways: as time goes ahead and across hospital services or health specialties. Indeed, in this work, we show the capabilities of a Bidirectional Recurrent Neural Network (RNN) with GRU units and ELMo embeddings on two corpora (a corpus comprising a set of EHRs within the Basque Health System, namely Osakidetza, and the well-known MIMIC-III corpus). To delve into and assess the versatility of the models, we focus on their resilience across hospital admissions taken over two different years and also across six distinct hospital services. In addition, we paid attention to the classification performance to estimate ICD codes of different granularity (e.g. with or without essential modifiers). Our best results are 39.55&#x0025; and 47.28&#x0025; F-Score for the Osakidetza and MIMIC-III datasets respectively, with the original main label-sets. Regarding the models evaluated per specialty, the most remarkable results are 57.00&#x0025; and 72.74&#x0025; F-Score, in the Cardiology and Nephrology medical services respectively.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Alberto Blanco et al.",
      "keywords": "Computer science; Artificial intelligence; Identification (biology); Machine learning; Health records; Set (abstract data type); ICD-10; Recurrent neural network; Specialty; Resilience (materials science); Data mining; Artificial neural network; Natural language processing; Medicine; Health care; Family medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3029429",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388430320",
      "doi": "10.1109/access.2023.3330212",
      "title": "Identification of Ancient Chinese Medical Prescriptions and Case Data Analysis Under Artificial Intelligence GPT Algorithm: A Case Study of Song Dynasty Medical Literature",
      "abstract": "This work aims to use the chatGPT algorithm to analyze and summarize cases in medical literature of the Song Dynasty, understand the clinical practice experience of ancient Chinese medicine, and provide historical reference for the clinical application and research of modern Chinese medicine. Firstly, the application of Artificial Intelligence (AI) in medicine is explained through literature research. Secondly, the prescription recognition technology related to AI is introduced, and a method combining supervised learning and semi-supervised learning for prescription entity recognition is proposed. Combined with chatGPT technology, medical data mining is carried out to obtain information and knowledge of medical research in the Song Dynasty. chatGPT is applied to the identification of ancient Chinese medical prescriptions and the analysis of case data. The results show that: 1) machine classifier performs well in classifying different flavor compounds, effective and ineffective prescriptions can be distinguished, and the accuracy increases with the increase of samples; 2) data mining reveals the differences in disease stages, the primary and secondary contradictions in patients&#x2019; bodies, and the primary and secondary differences in drug use; 3) frequency statistics show that warm drugs account for 45.46&#x0025;, confirming that warm drugs are the main ones for treating phlegm. Therefore, it is recommended to use chatGPT as an auxiliary tool in medical-related analysis and combine it with professional medical knowledge and clinical practice for comprehensive judgment and decision-making. Ancient medical prescriptions can be better identified, and case data can be analyzed by combining chatGPT technology in AI. It can well support ancient medicine study and lay a solid foundation for developing modern medical information data warehouse.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mengfei Li et al.",
      "keywords": "Identification (biology); Computer science; Medical prescription; Algorithm; Algorithm design; Artificial intelligence; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3330212",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365790361",
      "doi": "10.1109/access.2023.3267050",
      "title": "Using Machine Learning to Establish the Concerns of Persons With HIV/AIDS During the COVID-19 Pandemic From Their Tweets",
      "abstract": "There are millions of People Living with HIV/AIDS (PLWHA) globally and over the years, addressing their concerns has been topical for many stakeholders. It is a well-known and established fact that PLWHA are at increased risk of victimization and stigmatization. Unfortunately, the world experienced an outbreak of the COVID-19 pandemic that has led to strict social measures in many states. Thus, it is the goal of this research to study the impact that the outbreak and its mitigation measures have had on the PLWHA. Specifically, we sought to highlight their concerns from sentiments expressed on social media based on posted tweets. By combining machine learning (ML) techniques such as textual mining and thematic analysis, we determined 14 major themes as factors that are worth exploring. In this work, we originally extracted 2,839,091 tweets related to HIV/AIDS posted from March 2020 to April 2022. After initially doing data cleaning and preprocessing, we performed topic modeling using the Latent Dirichlet Allocation (LDA) topic model to extract 25 topics that are made up of 30 keywords each. The topics were then narrowed into 14 themes. The paper details the negative, positive, and neutral sentiment polarities which we highlight as concerning. These sentiments were determined using the Valence Aware Dictionary and sEntiment Reasoner (VADER) Sentiment Analysis Library with a 90&#x0025; F1-score compared to TextBlob which showed a 53&#x0025; F1-score. The research findings highlight issues affecting PLWHA during and post-pandemic such as high cost of medical care, late diagnosis of HIV, limited access to medications, stigmatization and victimization, absence of testing kits in hospitals, and lack of urgency in the development of vaccines or cure for HIV.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Richard K. Lomotey et al.",
      "keywords": "Sentiment analysis; Latent Dirichlet allocation; Social media; Pandemic; Topic model; Thematic analysis; Artificial intelligence; Coronavirus disease 2019 (COVID-19); Computer science; Human immunodeficiency virus (HIV); Psychology; Natural language processing; Internet privacy; Machine learning; Medicine; Sociology; Family medicine; World Wide Web; Qualitative research; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3267050",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391097208",
      "doi": "10.1109/access.2024.3356584",
      "title": "Tracking ChatGPT Research: Insights From the Literature and the Web",
      "abstract": "This article presents a scientometric and literature analysis of current research on ChatGPT, a conversational AI technology developed by OpenAI. Using various databases, 103 relevant articles were retrieved and analyzed through scientometric, quantitative, and application-based approaches. A Google trend analysis and comparison with other generative AI and chatbot technologies were also carried out. The study provides insights into the distribution of ChatGPT publications across different countries and regions, the network of co-occurring keywords, authorship analysis, article typology, and publishing entities. The findings offer a comprehensive overview of the current state of ChatGPT research, highlighting key directions for future research. The study finds that ChatGPT has gained significant attention and interest in online platforms, particularly in technology, education, and healthcare, and highlights potential ethical and legal concerns related to its use. Its applications extend to several literary and text generation areas. We do note that the sample of extracted publications is lower than anticipated due to the niche area of investigation. The article is relevant to researchers, practitioners, and policymakers interested in the field of AI-powered language models, especially ChatGPT.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Omar Mubin et al.",
      "keywords": "Computer science; Data science; Field (mathematics); Typology; Sample (material); Generative grammar; Knowledge management; Artificial intelligence; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3356584",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387789797",
      "doi": "10.1109/access.2023.3326129",
      "title": "Early Mental Stress Detection Using Q-Learning Embedded Starling Murmuration Optimiser-Based Deep Learning Model",
      "abstract": "Stress affects individual of all ages as a regular part of life, but excessive and chronic stress can lead to physical and mental health problems, decreased productivity, and reduced quality of life. By identifying stress at an early stage, individuals can take steps to manage it effectively and improve their overall well-being. Feature selection is a critical aspect of early stress detection because it helps identify the most relevant and informative features that can differentiate between stressed and non-stressed individuals. This paper firstly proposes a variance based feature selection technique that uses q-learning embedded Starling Murmuration Optimiser (QLESMO) to choose relevant features from a publicly available dataset in which stresses experienced by nurses working during the Covid&#x2019;19 Pandemic is recorded using bio-signals and user surveys. Furthermore, a comparative study with other metaheuristic based feature selection techniques have been demonstrated. Next, to evaluate the efficacy of the proposed algorithm, 10 benchmark test functions have been used. The reduced feature subset is then classified through a 1D convolutional neural network (CNN) model (QLESMO-CNN) and is seen to perform well in terms of the evaluation metrics in comparison to other competitive algorithms. Finally, the proposed technique is compared with the State-of-the-Art methodologies present in literature. The experiments provide a strong basis to determine features that are most relevant for early mental stress classification using a hybrid model combining CNN, Reinforcement Learning and metaheuristic algorithms.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Syed Kumayl Raza Moosavi et al.",
      "keywords": "Computer science; Feature selection; Artificial intelligence; Machine learning; Benchmark (surveying); Convolutional neural network; Feature (linguistics); Reinforcement learning; Metaheuristic; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326129",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3148415692",
      "doi": "10.1109/access.2021.3071273",
      "title": "A Novel Approach for Heart Ventricular and Atrial Abnormalities Detection via an Ensemble Classification Algorithm Based on ECG Morphological Features",
      "abstract": "In this study, a new approach using a novel ensemble classification algorithm based on ECG morphological features is proposed for accurate detection of heart ventricular and atrial abnormalities. First, the raw ECG signal is preprocessed and the main character waves are detected. Second, a combination of ECG morphological features is proposed and extracted from the selected ECG segments. The proposed feature set contains morphological parameters, morphological visual pattern of QRS complex, and principle components of the third level and fourth level of a four-level Sym8 wavelet-decomposed ECG waveform. Next, a novel ensemble classification algorithm, with the key idea of integrating the knowledge acquired by several popular classification algorithms for this task into an ensemble system, is proposed so that the accuracy and robustness over various arrhythmia types could be improved. Finally, the features are applied to the proposed ensemble classification algorithm for abnormality detection. The proposed approach achieved an overall accuracy of 98.68&#x0025; when it was validated on fifteen heartbeat types from the MIT-BIH arrhythmia database (MITDB), according to the Association for Advancement of Medical Instrumentation (AAMI) standard. The classification accuracies of the six main types &#x2013; normal beat (N), right bundled branch blocks beat (R), left bundled branch blocks beat (L), atrial premature beat (A), premature ventricular contractions beat (V), and paced beat (P) are 98.75&#x0025;, 99.77&#x0025;, 99.70&#x0025;, 94.81&#x0025;, 98.57&#x0025;, and 99.94&#x0025;, respectively. The proposed approach proves a solid result in comparison with component classification algorithms as well as recent peer works.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hui Yang et al.",
      "keywords": "Beat (acoustics); Heartbeat; Pattern recognition (psychology); Computer science; Artificial intelligence; QRS complex; Statistical classification; Feature extraction; Robustness (evolution); Electrocardiography; Algorithm; Cardiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3071273",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395017521",
      "doi": "10.1109/access.2024.3392032",
      "title": "An Improved Robust Fuzzy Local Information K-Means Clustering Algorithm for Diabetic Retinopathy Detection",
      "abstract": "According to the International Diabetes Federation (IDF), roughly 33% of individuals affected by diabetes exhibit diagnoses encompassing diverse severity of diabetic retinopathy. In the year 2020, approximately 463 million adults within the age bracket of 20 to 79 were documented as diabetes sufferers on a global scale. Projections suggest a rise to 700 million by 2045. The proposed automated diabetic retinopathy detection methods aim to reduce the workload of ophthalmologists. The study presents the Robust Fuzzy Local Information K-Means Clustering algorithm, an advanced iteration of the classical K-means clustering approach, integrating localized information parameters tailored to individual clusters. Comparative analysis is conducted between the performance of Robust Fuzzy Local Information K-Means Clustering and Modified Fuzzy C Means clustering, which incorporates a median adjustment parameter to augment Fuzzy C Means for diabetic retinopathy detection. The results are evaluated on three datasets: IDRiD, Kaggle, and fundus images collected from Shiva Netralaya Center, India. Achieving a 94.4% accuracy rate and an average execution time of 17.11 seconds, the proposed algorithm aims to categorize a substantial volume of retinal images, thereby improving performance and meeting the crucial demand for prompt and precise diagnoses in diabetic retinopathy healthcare.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Huma Naz et al.",
      "keywords": "Diabetic retinopathy; Cluster analysis; Computer science; Fuzzy logic; Fuzzy clustering; Workload; Artificial intelligence; Medical diagnosis; Algorithm; Diabetes mellitus; Fundus (uterus); Medicine; Data mining; Pattern recognition (psychology); Ophthalmology; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3392032",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385820084",
      "doi": "10.1109/access.2023.3305270",
      "title": "ResDSda_U-Net: A Novel U-Net-Based Residual Network for Segmentation of Pulmonary Nodules in Lung CT Images",
      "abstract": "The timely detection and segmentation of pulmonary nodules in lung computed tomography (CT) images can aid in the early diagnosis and treatment of lung cancer. However, manual segmentation of pulmonary nodules by doctors is highly demanding in terms of operational requirements and efficiency. To effectively improve the pulmonary nodule segmentation, this paper proposes a novel neural network, called ResDSda_U-Net, based on the U-Net network with the following improvements: (1) combining a Depthwise Over-parameterized Convolutional layer (DO-Conv) with a simple parameter-free attention module (SimAM), in the form of a newly designed ResDS block; (2) incorporating a denser Dense Atrous Spatial Pyramid Pooling (DASPP) module, between the encoder and decoder, using modified dilated rates to extract multi-scale information more effectively; and (3) adding channel and spatial attention mechanisms to the decoder, in the form of newly designed Convolution and Channel Attention (CCA) and Convolution and Spatial Attention (CSA) blocks, to enhance global pixel attention, fully capture global contextual information, and enable the decoder to better eliminate differences between pixels. The conducted experiments demonstrate that the proposed ResDSda_U-Net network outperforms all existing U-Net based networks (according to all evaluation metrics used) and all considered state-of-the-art networks (according to half of the evaluation metrics), by achieving corresponding values of 86.65% for the Dice Similarity Coefficient (DSC), 76.73% for Intersection over Union (IoU), 86.30% for sensitivity, and 87.22% for precision.<br>",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zhanlin Ji et al.",
      "keywords": "Residual; Net (polyhedron); Lung; Computer science; Segmentation; Artificial intelligence; Medicine; Internal medicine; Mathematics; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3305270",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295934599",
      "doi": "10.1109/access.2022.3206963",
      "title": "Selective Feature Sets Based Fake News Detection for COVID-19 to Manage Infodemic",
      "abstract": "During the COVID-19 pandemic, the spread of fake news became easy due to the wide use of social media platforms. Considering the problematic consequences of fake news, efforts have been made for the timely detection of fake news using machine learning and deep learning models. Such works focus on model optimization and feature engineering and the extraction part is under-explored area. Therefore, the primary objective of this study is to investigate the impact of features to obtain high performance. For this purpose, this study analyzes the impact of different subset feature selection techniques on the performance of models for fake news detection. Principal component analysis and Chi-square are investigated for feature selection using machine learning and pre-trained deep learning models. Additionally, the influence of different preprocessing steps is also analyzed regarding fake news detection. Results obtained from comprehensive experiments reveal that the extra tree classifier outperforms with a 0.9474 accuracy when trained on the combination of term frequency-inverse document frequency and bag of words features. Models tend to yield poor results if no preprocessing or partial processing is carried out. Convolutional neural network, long short term memory network, residual neural network (ResNet), and InceptionV3 show marginally lower performance than the extra tree classifier. Results reveal that using subset features also helps to achieve robustness for machine learning models.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Manideep Narra et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Feature engineering; Feature selection; Feature extraction; Convolutional neural network; Preprocessor; Deep learning; Robustness (evolution); Data pre-processing; Classifier (UML); Feature learning; Artificial neural network; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3206963",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392667270",
      "doi": "10.1109/access.2024.3376254",
      "title": "EEG Datasets for Healthcare: A Scoping Review",
      "abstract": "The rapidly evolving landscape of artificial intelligence (AI) and machine learning has placed data at the forefront of healthcare innovation. Electroencephalography (EEG) has gained significant attention for its potential to revolutionize healthcare applications. However, the effective utilization of EEG data in advancing medical diagnoses and treatment hinges on the availability and quality of relevant datasets. In this context, we conducted a scoping review to explore the wealth of EEG datasets designed for healthcare applications. This review serves as a critical exploration of the current landscape, aiming to identify datasets related to healthcare conditions while assessing their reusability. Our findings highlight both the opportunities and limitations in the wealth of open access EEG datasets. Available. As AI increasingly relies on high-quality, well labelled data, barriers impeding the sharing and utilization of EEG data for healthcare (such as lack of comprehensive documentation or adherence to FAIR principles) must be addressed so as to leverage the potential of advanced deep learning models to unlock new possibilities for diagnosis and analysis of a wide array of medical conditions.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Caroline Peres da Silva et al.",
      "keywords": "Computer science; Electroencephalography; Health care; Data science; Artificial intelligence; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3376254",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312327417",
      "doi": "10.1109/access.2022.3227219",
      "title": "Differential Beat Accuracy for ECG Family Classification Using Machine Learning",
      "abstract": "Holter systems record the electrocardiogram (ECG), which is used to identify beat families according to their origin and severity. Many systems have been proposed using signal conditioning and machine learning (ML) classification algorithms for beat family recognition. However, the design stage of these systems does not always consider the impact that tuning the intermediate blocks has on the beat family classification and the overall accuracy. We propose to use a new index based on the confusion matrices and bootstrap resampling to summarize the global performance for all family beats, so-called differential beat accuracy (DBA), which is obtained as the total number of beats correctly classified in each class minus the total number of beats incorrectly classified. We addressed the sensitivity of the different subblocks when creating a simple beat family classifier consisting of signal preprocessing blocks and a simple k-Nearest Neighbors classifier. The MIT-BIH Arrhythmia database was used for this purpose, following existing literature on the field. We benchmarked two implementations, one for biclass classification (supraventricular vs. non-supraventricular origin) and another for multiclass beat labeling. The usual preprocessing stages were scrutinized with the DBA to evaluate their impact on the quality of the complete ML system, such as signal detrending and filtering, beat balancing, or inter-beat distance. With the support of the DBA, our methodology was able to detect significant differences in terms of some of the options in the algorithm design. For instance, balancing the number of beats in each class for training significantly improved the classification accuracy of the minority classes at 3.22&#x0025; for the multiclass dataset but not for the biclass dataset. Also, accuracy improved significantly by about 6&#x0025; for the biclass regrouping without data normalization, whereas overall accuracy improved significantly by about 7&#x0025; for the multiclass regrouping with data normalization. In addition, the analysis of the statistical dispersion of confusion matrices showed that this database should be considered with caution when training ML-based family classifiers. We can conclude that the proposed DBA can provide us with statistically principled criteria for designing ML-based classifiers and reducing their bias in strongly unbalanced beat family datasets.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Alba Vadillo-Valderrama et al.",
      "keywords": "Beat (acoustics); Computer science; Artificial intelligence; Preprocessor; Confusion matrix; Pattern recognition (psychology); Classifier (UML); Speech recognition; Multiclass classification; Machine learning; Support vector machine; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3227219",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387886028",
      "doi": "10.1109/access.2023.3326882",
      "title": "SAM-UNETR: Clinically Significant Prostate Cancer Segmentation Using Transfer Learning From Large Model",
      "abstract": "&lt;p&gt;Prostate cancer (PCa) is one of the leading causes of cancer-related mortality among men worldwide. Accurate and efficient segmentation of clinically significant prostate cancer (csPCa) regions from magnetic resonance imaging (MRI) plays a crucial role in diagnosis, treatment planning, and monitoring of the disease, however, this is a challenging task even for the specialized clinicians. This study presents SAM-UNETR, a novel model for segmenting csPCa regions from MRI images. SAM-UNETR combines a transformer-encoder from the Segment Anything Model (SAM), a versatile segmentation model trained on 11 million images, with a residual-convolution decoder inspired by UNETR. The model uses multiple image modalities and applies prostate zone segmentation, normalization, and data augmentation as preprocessing steps. The performance of SAM-UNETR is compared with three other models using the same strategy and preprocessing. The results show that SAM-UNETR achieves superior reliability and accuracy in csPCa segmentation, especially when using transfer learning for the image encoder. This demonstrates the adaptability of large-scale models for different tasks. SAM-UNETR attains a Dice Score of 0.467 and an AUROC of 0.77 for csPCa prediction.&lt;/p&gt;",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jes\u00fas Alejandro Alzate-Grisales et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Encoder; Preprocessor; Image segmentation; Transfer of learning; Prostate cancer; Magnetic resonance imaging; Pattern recognition (psychology); Medicine; Cancer; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326882",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3114135062",
      "doi": "10.1109/access.2020.3045772",
      "title": "A SWOT Analysis of Human- and Machine Learning- Based Embryo Assessment",
      "abstract": "Embryo assessment is the most critical step of an IVF cycle. Morphologic evaluation of embryonic development has been the conventional method of embryo selection for transfer. However, this evaluation is subjective due to the diversity of skills and experience of embryologists. Machine learning (ML)-based models have been implemented in many clinical applications and considered a promising solution for efficient and unbiased performance. Therefore, this paper performs the SWOT analysis on human- and ML-based embryo assessments, representing conventional and artificial intelligence-assisted medicines, respectively. After analyzing various perspectives of each approach, the appropriate strategies are proposed for gradually shifting from the conventional to the ML-based approach in embryo evaluation.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Huy Phuong Tran et al.",
      "keywords": "SWOT analysis; Computer science; Artificial intelligence; Machine learning; Embryo; Selection (genetic algorithm); Embryo transfer; Biology; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3045772",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395027924",
      "doi": "10.1109/access.2024.3392572",
      "title": "Bilevel Hyperparameter Optimization and Neural Architecture Search for Enhanced Breast Cancer Detection in Smart Hospitals Interconnected With Decentralized Federated Learning Environment",
      "abstract": "Breast cancer, a widespread malignancy predominantly affecting women aged 40 and above, presents a significant global health challenge with high mortality rates. The scarcity of medical data underscores the need for collaborative efforts among hospitals to enhance automated breast cancer detection. This research employs decentralized Federated Learning (FL) to facilitate cooperative learning across an interconnected smart hospital network, addressing data privacy, regulatory compliance, voluminous medical image data, and the necessity for distributed machine learning. Our innovative approach integrates Ant Colony Optimization (ACO) for hyperparameter fine-tuning and Neural Architecture Search (NAS) in a collaborative framework for smart hospitals linked with decentralized edge intelligent networks. This optimization strategy significantly improves the performance of our breast cancer detection system. Through a comprehensive experimental study (including diverse datasets), we classify Normal vs. Mass and Benign vs. Malignant regions in mammograms within a decentralized, federated collaborative learning environment. Empirical results consistently highlight the superiority of models trained using our method over individual hospital client-level training. Our method yielded significant improvements across evaluation measures: for Normal vs. Mass, achieving 92.6&#x0025; sensitivity, 93.0&#x0025; specificity, and 93.0&#x0025; accuracy; for Benign vs. Malignant, achieving 89.6&#x0025; sensitivity, 91.6&#x0025; specificity, and 89.7&#x0025; accuracy. Moreover, it has obtained a 6&#x0025; and 5&#x0025; increase in accuracy for Normal vs. Mass and Benign vs. Malignant cases, respectively, compared to the PSO-based HPO method. This evidence underscores the potential of collaborative approaches, emphasizing decentralized FL as a robust paradigm in medical research. The incorporation of ACO optimization reinforces the effectiveness of the proposed computer-aided diagnosis (CAD) system, marking a noteworthy advancement in the ongoing fight against breast cancer.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Salabat Khan et al.",
      "keywords": "Hyperparameter; Computer science; Bilevel optimization; Architecture; Breast cancer; Artificial intelligence; Machine learning; Cancer; Optimization problem; Medicine; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3392572",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312882971",
      "doi": "10.1109/access.2022.3230324",
      "title": "Improving Sepsis Prediction Performance Using Conditional Recurrent Adversarial Networks",
      "abstract": "In this paper, we devise a novel method involving deep neural networks (DNNs) that improves the early prediction of sepsis for patients admitted to the intensive care units (ICUs). It is assumed that the patient data sets are dramatically corrupted by missing information, which negatively impacts the detection of the onset of sepsis. We propose a generative learning framework to estimate the missing information in data. Our model involves Conditional Generative Adversarial Networks (GANs) utilizing Long Short-Term Memory (LSTM) networks as the generator and discriminator when conditioned on class labels. A deep LSTM network is also employed for prediction purposes. The prediction network is trained with an output of the conditional GAN and evaluated on an unseen test set to investigate the performance of the proposed model. Here, we show that the proposed framework not only identifies long-term temporal dependencies but also exploits the missing patterns. We present the performance results and compare them to other well-known techniques. For the 4-hour, 8-hour, and 12-hour prediction of sepsis, the proposed method attains area under the receiver operating characteristic (AUROC) of 94.49&#x0025;, 93.74&#x0025;, and 94.01&#x0025;, respectively. It is shown here that the improvement in imputation and prediction promises a highly effective method that can offer early detection of sepsis in high-risk patients.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Merve Apalak et al.",
      "keywords": "Discriminator; Computer science; Artificial intelligence; Artificial neural network; Machine learning; Deep learning; Missing data; Receiver operating characteristic; Generative adversarial network; Imputation (statistics); Recurrent neural network; Data mining; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3230324",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394896945",
      "doi": "10.1109/access.2024.3390186",
      "title": "Dual Attention Convolutional AutoEncoder for Diagnosis of Alzheimer\u2019s Disorder in Patients Using Neuroimaging and MRI Features",
      "abstract": "Alzheimer&#x2019;s disease is a neurodegenerative disease causing memory loss and brain protein accumulation. Early diagnosis is crucial for clinical trials and patient care. Magnetic resonance imaging (MRI) methods have improved diagnosis and prognosis, but doctors need to interpret images proficiently. Deep learning technology has shown potential in detecting Alzheimer&#x2019;s disease, but the disease progresses slower in early phases. A new dual-attention convolutional autoencoder model is presented, offering improved detection abilities and potential for real-time use in Alzheimer&#x2019;s disease diagnosis. The study utilized two datasets: the first ADNI dataset, which includes three classes (MCI, CN, and AD), and the second Alzheimer&#x2019;s Disease Neuroimaging Dataset, which includes two distinct classes (AD and MCI). We analyze the effectiveness of our proposed model by evaluating key performance metrics such as accuracy, precision, sensitivity, specificity, F1 score, and AUC score. In addition, we utilize cross-validation and mean absolute error to validate our model while also fine-tuning the parameters. Based on experimental data, the proposed model accurately detected Alzheimer&#x2019;s disease with an accuracy of 0.9902 &#x00B1; 0.0139. Based on the results, the proposed model demonstrates excellent performance compared to the existing methods described in the literature. The proposed mode achieves precision, sensitivity, and specificity of 0.9882 &#x00B1; 0.0587, 0.9898 &#x00B1; 0.0865, 0.9912 &#x00B1; 0.0872 respectively. The model achieved an AUC score of 0.9992 for MCI and 0.9919 for AD class. Furthermore, the proposed method can enhance the affordability of Alzheimer&#x2019;s disease diagnostics and increase the rate of early AD detection by facilitating remote healthcare.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Shaha Al\u2010Otaibi et al.",
      "keywords": "Autoencoder; Neuroimaging; Computer science; Artificial intelligence; Alzheimer's Disease Neuroimaging Initiative; Magnetic resonance imaging; Deep learning; Disease; Sensitivity (control systems); Alzheimer's disease; Convolutional neural network; Pattern recognition (psychology); Machine learning; Medicine; Pathology; Radiology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3390186",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4381250428",
      "doi": "10.1109/access.2023.3287788",
      "title": "Review and Analysis of Patients\u2019 Body Language From an Artificial Intelligence Perspective",
      "abstract": "Body language is a nonverbal communication process consisting of movements, postures, gestures, and expressions of the body or body parts. Body language expresses human feelings, thoughts, and intentions. It also reveals physical and psychological health conditions: abnormal activities inform peoples&#x2019; health conditions, facial expressions indicate their emotional states and abnormal body actions convey specific diseases&#x2019; external signs and symptoms. We can observe the importance of studying the body language of people with health conditions through many reports in literature written by healthcare (medical) and artificial intelligence researchers. This paper comprehensively reviews artificial intelligence-based articles that have studied patients&#x2019; body language. We also conduct different descriptive and exploratory examinations of the findings using data analysis techniques, which provide more authentic domain knowledge of abnormal activities, abnormal body actions, and more precise analysis of methodologies used in machine learning tasks for studying these abnormalities. The paper&#x2019;s results are essential for developing intelligent automated systems that accurately evaluate patients&#x2019; physical and psychological conditions, precisely identify external signs and symptoms of diseases, and adequately monitor patients&#x2019; health conditions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sherzod Turaev et al.",
      "keywords": "Body language; Gesture; Nonverbal communication; Feeling; Perspective (graphical); Computer science; Human body; Body of knowledge; Artificial intelligence; Psychology; Natural language processing; Cognitive psychology; Knowledge management; Communication; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3287788",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388819906",
      "doi": "10.1109/access.2023.3335196",
      "title": "Deep Representation Learning: Fundamentals, Technologies, Applications, and Open Challenges",
      "abstract": "Machine learning algorithms have had a profound impact on the field of computer science over the past few decades. The performance of these algorithms heavily depends on the representations derived from the data during the learning process. Successful learning processes aim to produce concise, discrete, meaningful representations that can be effectively applied to various tasks. Recent advancements in deep learning models have proven to be highly effective in capturing high-dimensional, non-linear, and multi-modal characteristics. In this work, we provide a comprehensive overview of the current state-of-the-art in deep representation learning and the principles and developments made in the process of representation learning. Our study encompasses both supervised and unsupervised methods, including popular techniques such as autoencoders, self-supervised methods, and deep neural networks. Furthermore, we explore a wide range of applications, including image recognition and natural language processing. In addition, we discuss recent trends, key issues, and open challenges in the field. This survey endeavors to make a significant contribution to the field of deep representation learning, fostering its understanding and facilitating further advancements.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Amirreza Payandeh et al.",
      "keywords": "Computer science; Deep learning; Artificial intelligence; Field (mathematics); Representation (politics); Machine learning; Process (computing); Feature learning; Data science; Unsupervised learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3335196",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3081613850",
      "doi": "10.1109/access.2020.3021310",
      "title": "A Machine Learning Framework for Pulse Detection During Out-of-Hospital Cardiac Arrest",
      "abstract": "The availability of an automatic pulse detection during out-of-hospital cardiac arrest (OHCA) would allow the rapid identification of cardiac arrest and the prompt detection of return of spontaneous circulation. The aim of this study was to develop a reliable pulse detection algorithm using the electrocardiogram (ECG) and thoracic impedance (TI), the signals available in most defibrilators. The dataset used in the study consisted of 1140 ECG and TI segments from 187 OHCA patients, whereof 792 were labelled as pulse-generating rhythm (PR) and 348 as pulseless electrical activity (PEA) by a pool of experts in OHCA. First, an adaptive filtering scheme was used to extract the impedance circulation component and its first derivative from the TI. Then, the wavelet decomposition of the ECG was carried out to obtain the different subband components and the denoised ECG. Pulse/no-pulse (PR/PEA) discrimination features were extracted from those signals and fed into a support vector machine (SVM) classifier that made the pulse/no-pulse decision. A quasi-stratified and patient wise nested cross validation procedure was used to select the best feature subset and to tune the SVM hyperparameters. This procedure was repeated 50 times to estimate the statistical distributions of the performance metrics of the method. The optimal solution consisted in a five feature classifier that yielded a mean (standard deviation) sensitivity, specificity, balanced accuracy and total accuracy of 92.4% (0.7), 93.0% (0.8), 92.7% (0.5) and 92.6% (0.5), respectively. When compared to available methods, our solution presented an improvement in balanced accuracy of at least 2.5 points. A reliable pulse detection algorithm for OHCA using the signals available in defibrillators was acomplished.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Erik Alonso et al.",
      "keywords": "Pattern recognition (psychology); Support vector machine; Computer science; Hyperparameter; Return of spontaneous circulation; Artificial intelligence; Standard deviation; Remote patient monitoring; Mathematics; Medicine; Cardiopulmonary resuscitation; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3021310",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4367665393",
      "doi": "10.1109/access.2023.3271635",
      "title": "Explainable Artificial Intelligence for Patient Safety: A Review of Application in Pharmacovigilance",
      "abstract": "Explainable AI (XAI) is a methodology that complements the black box of artificial intelligence, and its necessity has recently been highlighted in various fields. The purpose of this research is to identify studies in the field of pharmacovigilance using XAI. Though there have been many previous attempts to select papers, with a total of 781 papers being confirmed, only 25 of them manually met the selection criteria. This study presents an intuitive review of the potential of XAI technologies in the field of pharmacovigilance. In the included studies, clinical data, registry data, and knowledge data were used to investigate drug treatment, side effects, and interaction studies based on tree models, neural network models, and graph models. Finally, key challenges for several research issues for the use of XAI in pharmacovigilance were identified. Although artificial intelligence (AI) is actively used in drug surveillance and patient safety, gathering adverse drug reaction information, extracting drug-drug interactions, and predicting effects, XAI is not normally utilized. Therefore, the potential challenges involved in its use alongside future prospects should be continuously discussed.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Seunghee Lee et al.",
      "keywords": "Pharmacovigilance; Computer science; Field (mathematics); Drug reaction; Data science; Artificial intelligence; Drug; Medicine; Pharmacology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3271635",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226158806",
      "doi": "10.1109/access.2022.3168980",
      "title": "Notice of Removal: Automated Triaging Medical Referral for Otorhinolaryngology Using Data Mining and Machine Learning Techniques",
      "abstract": "Public hospitals receive and triage a large volume of medical referrals for otorhinolaryngology annually and it can be a challenge to derive knowledge from them as they are written in unstructured text and may be unavailable in electronic formats. Acquiring knowledge and insights from these referrals are important to public health management and policymakers. Triaging of general practitioner (GP) referrals for ear, nose, and throat (ENT) specialists is a manual process performed by experienced clinicians, but it is time-consuming. This paper proposes utilising machine learning and data mining to automate the process of referrals. In this study, an ensemble of machine learning algorithms to perform clinical text mining against the unstructured referral text in order to derive the relationship among the discovered medical terms was proposed and implemented. A set of comprehensive term sets\u2019 association rules which describe the entire referral dataset\u2019s characteristics was obtained from the association rule mining experiments. The neural network-based text classification model that can classify referrals with high accuracy was developed, tested and reported in this paper.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Chee Keong Wee et al.",
      "keywords": "Referral; Computer science; Triage; Otorhinolaryngology; Machine learning; Artificial intelligence; Notice; Association rule learning; Data mining; Medicine; Medical emergency; Family medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3168980",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312397225",
      "doi": "10.1109/access.2022.3211334",
      "title": "A Multi-Headed Transformer Approach for Predicting the Patient\u2019s Clinical Time-Series Variables From Charted Vital Signs",
      "abstract": "Deep learning has progressively been the spotlight of innovations that aim to leverage the clinical time-series data that are longitudinally recorded in the Electronic Health Records(EHR) to forecast the patient&#x2019;s survival and vital signs deterioration. However, their recording velocity, as well as their noisiness, hinder the proper adoption of the recently proposed benchmarks. The Recurrent Neural Networks (RNN) especially the Long-short Term Memory (LSTMs) have achieved better results in recent studies but they are hard to train and interpret and fail to properly capture the long-term dependencies. Moreover, the RNNs suffer greatly with clinical time series due to their sequential processing which cripples the prospect of parallel processing. Recently the Transformer approach was proposed for Natural Language Processing (NLP) tasks and achieved state-of-the-art results. Hence to tackle the drawbacks that are suffered by the RNNs we propose a clinical time series Multi-head Transformer (MHT), which is a transformer-based model that forecasts the patient&#x2019;s future time series variables using the vitals signs. To prove the generalization of the model we use the same model for other critical tasks that describe the Intensive Care Unit (ICU) patient&#x2019;s progression and the associated risks like the remaining Length Of Stay(LoS), the In-hospital Mortality as well as the 24 hours mortality. Our model achieves an Area Under The Curve-Receiver Operating Characteristics(AUC-ROC) of 0.98 and an Area Under the Curve, Precision-Recall (AUC-PR) of 0.424 for vital time series prediction, and an AUC-ROC of 0.875 in the mortality prediction. The model performs well for the frequently recorded variables like the Heart Rate (HR) and performs barely like the LSTM counterparts for the intermittently captured records such as the White Blood Count (WBC).",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Gaspard Harerimana et al.",
      "keywords": "Recurrent neural network; Computer science; Leverage (statistics); Artificial intelligence; Receiver operating characteristic; Vital signs; Transformer; Time series; Machine learning; Recurrence plot; Health records; Long short term memory; Deep learning; F1 score; Electronic health record; Artificial neural network; Medicine; Health care; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3211334",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3128675788",
      "doi": "10.1109/access.2021.3056724",
      "title": "Convolutional Neural Network Utilizing Error-Correcting Output Codes Support Vector Machine for Classification of Non-Severe Traumatic Brain Injury From Electroencephalogram Signal",
      "abstract": "A sudden blow or jolt to the human brain called traumatic brain injury (TBI) is one of the most common injuries recorded in the health insurance claim. Generally, computed tomography (CT) or magnetic resonance imaging (MRI) is required to identify the trauma's severity. Unfortunately, CT and MRI equipment are bulky, expensive, and not always available, limiting their use in TBI detection. Therefore, as an alternative, this study presents a novel classification architecture that can classify non-severe TBI patients from healthy subjects by using resting-state electroencephalogram (EEG) as the input. The proposed architecture employs a convolutional neural network (CNN), and error-correcting output codes support vector machine (ECOC-SVM) to perform automated feature extraction and multi-class classification. In this architecture, complex feature selection and extraction steps are avoided. The proposed architecture attained a high-performance classification accuracy of 99.76%, potentially being used as a classification approach to preventing healthcare insurance fraud. The proposed method is compared to existing studies in the literature. The outcome from the comparisons indicates that the proposed method has outperformed the benchmarked methods by presenting the highest classification accuracy and precision.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Chi Qin Lai et al.",
      "keywords": "Convolutional neural network; Computer science; Support vector machine; Feature extraction; Artificial intelligence; Pattern recognition (psychology); Traumatic brain injury; Electroencephalography; Feature selection; Feature (linguistics); Machine learning; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3056724",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312607194",
      "doi": "10.1109/jbhi.2022.3230663",
      "title": "Privacy-Aware Early Detection of COVID-19 Through Adversarial Training",
      "abstract": "Early detection of COVID-19 is an ongoing area of research that can help with triage, monitoring and general health assessment of potential patients and may reduce operational strain on hospitals that cope with the coronavirus pandemic. Different machine learning techniques have been used in the literature to detect potential cases of coronavirus using routine clinical data (blood tests, and vital signs measurements). Data breaches and information leakage when using these models can bring reputational damage and cause legal issues for hospitals. In spite of this, protecting healthcare models against leakage of potentially sensitive information is an understudied research area. In this study, two machine learning techniques that aim to predict a patient's COVID-19 status are examined. Using adversarial training, robust deep learning architectures are explored with the aim to protect attributes related to demographic information about the patients. The two models examined in this work are intended to preserve sensitive information against adversarial attacks and information leakage. In a series of experiments using datasets from the Oxford University Hospitals (OUH), Bedfordshire Hospitals NHS Foundation Trust (BH), University Hospitals Birmingham NHS Foundation Trust (UHB), and Portsmouth Hospitals University NHS Trust (PUH), two neural networks are trained and evaluated. These networks predict PCR test results using information from basic laboratory blood tests, and vital signs collected from a patient upon arrival to the hospital. The level of privacy each one of the models can provide is assessed and the efficacy and robustness of the proposed architectures are compared with a relevant baseline. One of the main contributions in this work is the particular focus on the development of effective COVID-19 detection models with built-in mechanisms in order to selectively protect sensitive attributes against adversarial attacks. The results on hold-out test set and external validation confirmed that there was no impact on the generalisibility of the model using adversarial learning.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Omid Rohanian et al.",
      "keywords": "Adversarial system; Triage; Computer science; Robustness (evolution); Artificial intelligence; Deep learning; Coronavirus disease 2019 (COVID-19); Health care; Pandemic; Computer security; Information leakage; Machine learning; Medical emergency; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3230663",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312230094",
      "doi": "10.1109/access.2022.3221750",
      "title": "Using Artificial Intelligence for COVID-19 Detection in Blood Exams: A Comparative Analysis",
      "abstract": "COVID-19 is an infectious disease that was declared a pandemic by the World Health Organization (WHO) in early March 2020. Since its early development, it has challenged health systems around the world. Although more than 12 billion vaccines have been administered, at the time of writing, it has more than 623 million confirmed cases and more than 6 million deaths reported to the WHO. These numbers continue to grow, soliciting further research efforts to reduce the impacts of such a pandemic. In particular, artificial intelligence techniques have shown great potential in supporting the early diagnosis, detection, and monitoring of COVID-19 infections from disparate data sources. In this work, we aim to make a contribution to this field by analyzing a high-dimensional dataset containing blood sample data from over forty thousand individuals recognized as infected or not with COVID-19. Encompassing a wide range of methods, including traditional machine learning algorithms, dimensionality reduction techniques, and deep learning strategies, our analysis investigates the performance of different classification models, showing that accurate detection of blood infections can be obtained. In particular, an F-score of 84% was achieved by the artificial neural network model we designed for this task, with a rate of 87% correct predictions on the positive class. Furthermore, our study shows that the dimensionality of the original data, i.e. the number of features involved, can be significantly reduced to gain efficiency without compromising the final prediction performance. These results pave the way for further research in this field, confirming that artificial intelligence techniques may play an important role in supporting medical decision-making.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Andrea Loddo et al.",
      "keywords": "Artificial intelligence; Coronavirus disease 2019 (COVID-19); Computer science; Machine learning; Artificial neural network; Pandemic; Deep learning; Field (mathematics); Dimensionality reduction; Curse of dimensionality; Task (project management); Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); Infectious disease (medical specialty); Data science; Disease; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3221750",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384787365",
      "doi": "10.1109/access.2023.3296456",
      "title": "Design and Development of an Efficient Risk Prediction Model for Cervical Cancer",
      "abstract": "Cervical cancer is a major public health concern, especially in low- and middle-income countries. Lifestyle choices to some extent have an effect on causing cervical cancer. Most cervical cancers are caused by the sexually transmitted infection caused by the Human Papillomavirus (HPV). However, only persistent HPV infections lead to progression to pre-cancer and cancer. The persistence of this infection is influenced by many factors namely, age, sexually transmitted infections, number of sexual partners, age at first sexual intercourse, number of deliveries, tobacco consumption, etc. Risk-based prediction algorithms help to stratify women with a high risk to develop cervical cancer and screen them on a priority basis. In this study, a model has been developed to predict the risk of cervical cancer based on one&#x2019;s lifestyle choices. Important features have been delineated using the Extreme Gradient Boosting (XGBoost) Classifier. After oversampling, the data is fed into the model for training and testing. The Gradient Boost model was chosen to arrive at an accurracy of 98.9&#x0025;. This model can be effective to associate risk factors with cervical cancer prediction which can help the in the effective prevention and management of cervical cancer.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "R. Hariprasad et al.",
      "keywords": "Cervical cancer; Medicine; Sexual intercourse; Oncology; Gynecology; Cancer; Internal medicine; Environmental health; Population",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3296456",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4214620436",
      "doi": "10.1109/access.2022.3153482",
      "title": "Multidimensional Population Health Modeling: A Data-Driven Multivariate Statistical Learning Approach",
      "abstract": "Population health is multidimensional in nature, having complex relationships with the various health determinants. However, most previous studies investigate a single dimension of population health using linear models, failing to capture the nonlinearity in the data and interdependence of multiple dimensions in health outcomes. In this paper, we propose a data-driven multivariate statistical learning approach to simultaneously model various aspects of population health&#x2014;characterizing the length and quality of life&#x2014;as a function of health behaviors, clinical care, socioeconomic factors, physical environment, and demographics. We also propose a novel percentile-based variable selection for multivariate regression, without compromising the model&#x2019;s generalization performance. We demonstrate the applicability of our proposed data-driven methodological framework using the New York State as a case study. Leveraging cross-validation techniques and statistical hypothesis tests, the results indicate that multivariate tree boosting method outperforms the traditionally-used univariate linear regression model and random forest in modeling multidimensional population health. The variable importance heat-map illustrates the relative influence of the key health determinants on the various dimensions of population health. Partial dependence plots are used to quantify the marginal effects and the nonlinear relationships between the health outcomes and health inputs. Our results show that teen birth rate is strongly associated with both length of life (e.g., child mortality) and quality of life (e.g., physically unhealthy days). Socioeconomic status is the key indicator to predict child and infant mortality. Our proposed framework can be used as a decision support tool for accurately assessing and predicting multivariate population health.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Zhiyuan Wei et al.",
      "keywords": "Multivariate statistics; Univariate; Computer science; Population; Decision tree; Population health; Statistics; Multivariate analysis; Econometrics; Machine learning; Mathematics; Medicine; Environmental health",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3153482",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3151081786",
      "doi": "10.1109/trpms.2021.3070656",
      "title": "External Validation of a Bayesian Network for Error Detection in Radiotherapy Plans",
      "abstract": "Artificial intelligence (AI) applications have recently been proposed to detect errors in radiotherapy plans. External validation of such systems is essential to assess their performance and safety before applying them to clinical practice. We collected data from 5238 patients treated at Maastro Clinic and introduced a range of common radiotherapy plan errors for the model to detect. We estimated the model's discrimination by calculating the area under the receiver-operating characteristic curve (AUC). We also assessed its clinical usefulness as an alert system that could reduce the need for manual checks by calculating the percentage of values flagged as errors and the positive predictive value (PPV) for a range of high sensitivities (95 %-99 %) and error prevalence. The AUC when considering all variables was 67.8% (95% CI, 65.6%-69.9%). The AUC varied widely for different types of errors (from 90.4% for table angle errors to 54.5% for planning tumor volume-PTV dose errors). The percentage of flagged values ranged from 84% to 90% for sensitivities between 95% and 99% and the PPV was only slightly higher than the prevalence of the errors. The model's performance in the external validation was significantly worse than that in its original setting (AUC of 68% versus 89%). Its usefulness as an alert system to reduce the need for manual checks is questionable due to the low PPV and high percentage of values flagged as potential errors to achieve a high sensitivity. We analyzed the apparent limitations of the model and we proposed actions to overcome them.",
      "year": "2021",
      "journal": "IEEE Transactions on Radiation and Plasma Medical Sciences",
      "authors": "Petros Kalendralis et al.",
      "keywords": "Receiver operating characteristic; Range (aeronautics); Statistics; Bayesian network; Computer science; Clinical Practice; Sensitivity (control systems); Predictive value; Medicine; Artificial intelligence; Machine learning; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/trpms.2021.3070656",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4360584637",
      "doi": "10.1109/access.2023.3260184",
      "title": "Bed Allocation Optimization Based on Survival Analysis, Treatment Trajectory and Costs Estimations",
      "abstract": "The intensive care units are a key element of patient flow, but due to high demand and an alternating rate of arriving patients, these units are often challenged by insufficient capacity, very high expenses, and in some cases, an unfair distribution of resources. Proper allocation of resources to match demand is, therefore, a vital task for many wards in these units. The patient bed assignment problem consists of managing in the best possible way a set of beds with equipment to be assigned to a particular type of patient. However, in real-world scenarios, constraints like a possible treatment trajectory are violated in most cases. In this paper, we present a new approach for solving patient bed assignment problems constrained by targets on survival function estimation, cost estimation, and possible treatment trajectory estimation for patients with cardiovascular diseases. For survival function estimations, we used the nave estimator and Kaplan-Meier, and for treatment effect estimations, we used logistic regression and T-learning. Estimations of the three components are used as weights in a genetic algorithm. This technique allows for the consideration of various constraints, which, unlike other techniques, allows for the selection of dominant solutions as solutions that satisfy dominant constraints. In addition, we demonstrate the robustness of our approach by testing the algorithms with multiple classes of patients, testing multiple sets of parameters, and comparing our results with several similar research studies showing the added value of working on this management axis in hospitals using the new approach to bed allocation.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Kaouter Karbouband et al.",
      "keywords": "Computer science; Estimator; Mathematical optimization; Robustness (evolution); Task (project management); Statistics; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3260184",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4322576603",
      "doi": "10.1109/mprv.2022.3218773",
      "title": "DDoD: Dual Denial of Decision Attacks on Human-AI Teams",
      "abstract": "Artificial intelligence (AI) systems have been increasingly used to make decision-making processes faster, more accurate, and more efficient. However, such systems are also at constant risk of being attacked. While the majority of attacks targeting AI-based applications aim to manipulate classifiers or training data and alter the output of an AI model, recently proposed sponge attacks against AI models aim to impede the classifier's execution by consuming substantial resources. In this work, we propose dual denial of decision (DDoD) attacks against collaborative human-AI teams. We discuss how such attacks aim to deplete both computational and human resources, and significantly impair decision-making capabilities. We describe DDoD on human and computational resources and present potential risk scenarios in a series of exemplary domains.",
      "year": "2023",
      "journal": "IEEE Pervasive Computing",
      "authors": "Benjamin Tag et al.",
      "keywords": "Computer science; Dual (grammatical number); Denial-of-service attack; Ubiquitous computing; Computer security; Denial; Artificial intelligence; Human\u2013computer interaction; World Wide Web; The Internet; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mprv.2022.3218773",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388543697",
      "doi": "10.1109/tem.2023.3326233",
      "title": "Unleashing Competitive Intelligence: News Mining Analysis on Technology Trends and Digital Health Driving Healthcare Innovation",
      "abstract": "In the rapidly evolving digital health landscape, technology plays a pivotal role in transforming the healthcare industry. With the exponential growth of data, uncovering valuable insights has become a daunting task. In today's data-driven world, healthcare businesses must leverage emerging technologies to stay informed about trends in their field. This research article presents a novel approach to deriving business insights in digital health enabled by technology, including artificial intelligence, and other cutting-edge advancements. We propose a methodology that utilizes news mining techniques and the global data on events, location, and tone database as the primary data source. By employing natural language processing, we developed a practical way of extracting relevant insights from vast amounts of public data. We implemented named-entity recognition (NER) enriched with the DBpedia knowledge base and relationship extraction. In addition, we leveraged graph analytics to identify and analyze the most significant concept relationships within the text corpus and their evolution in time. By integrating these advanced techniques, healthcare businesses can extract actionable insights from public datasets, empowering them to stay abreast of emerging trends and advancements in digital health, such as telehealth, precision medicine, or medical imaging.",
      "year": "2023",
      "journal": "IEEE Transactions on Engineering Management",
      "authors": "Enrique Ca\u00f1o-Mar\u00edn et al.",
      "keywords": "Data science; Big data; Computer science; Leverage (statistics); Health care; Competitive intelligence; Digital health; Analytics; Competitive advantage; Knowledge management; Artificial intelligence; Data mining; Business; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tem.2023.3326233",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386065457",
      "doi": "10.1109/access.2023.3307637",
      "title": "High-Reliability Non-Contact Photoplethysmography Imaging for Newborn Care by a Generative Artificial Intelligence",
      "abstract": "Long-term wiring on a newborn patient could be a disguise scene for parents. Unobtrusive and reliable monitoring without wiring can be a euphoric alternative for newborns and parents in obstetrics and gynecology (OB/GYN) incubation rooms. However, reliable and continuous non-contact surveillance in an incubation room is challenging. Therefore, a novel photoplethysmography imaging (PPGi) is developed specifically for baby skins through predictive adversarial adaptation and risk-sensitive generative synchronizer. Our artificial intelligence approach does not take blind guesses from input-output pairs. We apply an intelligent step to decouple the influence of fluctuated illumination through a generative algorithm of artificial intelligence. To boost skin detection performance, we capture those pixels with periodic variations and maximize the coherence of the extraction algorithm by the generative synchronizer. The periodic variations are matched by a synthesized pulse from the output PPGi signals through the control of a risk-sensitive filter to not over-compensate the illuminate variation. Based on the sensed pulsation, we synthesize the corresponding pulsation signals on the flight to identify the living skin in a spatiotemporal image sequence. We find that our skin classifier in risk-sensitive generative synchronizer effectively improves the quality of the resulting non-contact PPGi signal. Our algorithm produces substantial accuracy in the performance of PPGi reconstruction in the critical environment of newborn care. In the limited illustration of the incubation room, our non-contact PPGi can still achieve an average accuracy of 96.62&#x0025;.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Yenming J. Chen et al.",
      "keywords": "Computer science; Artificial intelligence; Photoplethysmogram; Computer vision; Pattern recognition (psychology); Filter (signal processing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3307637",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392309161",
      "doi": "10.1109/tmi.2024.3371948",
      "title": "Landmark Localization From Medical Images With Generative Distribution Prior",
      "abstract": "In medical image analysis, anatomical landmarks usually contain strong prior knowledge of their structural information. In this paper, we propose to promote medical landmark localization by modeling the underlying landmark distribution via normalizing flows. Specifically, we introduce the flow-based landmark distribution prior as a learnable objective function into a regression-based landmark localization framework. Moreover, we employ an integral operation to make the mapping from heatmaps to coordinates differentiable to further enhance heatmap-based localization with the learned distribution prior. Our proposed Normalizing Flow-based Distribution Prior (NFDP) employs a straightforward backbone and non-problem-tailored architecture (i.e., ResNet18), which delivers high-fidelity outputs across three X-ray-based landmark localization datasets. Remarkably, the proposed NFDP can do the job with minimal additional computational burden as the normalizing flows module is detached from the framework on inferencing. As compared to existing techniques, our proposed NFDP provides a superior balance between prediction accuracy and inference speed, making it a highly efficient and effective approach. The source code of this paper is available at https://github.com/jacksonhzx95/NFDP.",
      "year": "2024",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Zixun Huang et al.",
      "keywords": "Landmark; Artificial intelligence; Computer vision; Computer science; Medical imaging; Pattern recognition (psychology); Image registration; Image segmentation; Generative model; Generative grammar; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2024.3371948",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389161273",
      "doi": "10.1109/access.2023.3338191",
      "title": "Advancing ECG Biometrics Through Vision Transformers: A Confidence-Driven Approach",
      "abstract": "Over the past two decades, Electrocardiography (ECG) has gained significant momentum in the field of biometrics, offering a compelling alternative for person identity recognition based on physical/biological traits. Its inherent difficulty to be circumvent and its ability to enable liveness detection make it particularly appealing compared to other popular identifiers such as face, fingerprint, and iris. As a result, ECG has garnered attention from the computer vision community working on biometrics applications. We present a novel biometric method for personal recognition that leverages I-lead signals acquired off-the-person. Through fine-tuning a pre-trained Vision Transformer (ViT) model, we achieve remarkable results in recognizing individuals based on a single 2D image of their ECG recording obtained from as little as three heartbeats. Extensive evaluation on the CYBHi database, with enrollment and testing phases separated by a three-month time window, simulating a real-world, long-term identification scenario, demonstrates the robustness of our multiclass approach. Specifically, our system achieves a remarkable single sample-based identification accuracy of over 70&#x0025; with a pool of 63 individuals, along with an equal error rate of only 0.48&#x0025; in the 1-vs-1 authentication task. Additionally, we evaluated our approach on the very recent Heartprint database to assess the robustness of our approach with more subjects, larger separation time windows, and continuous training settings, obtaining again remarkable performance with respect to the state-of-the-art. While the promising capabilities of ECG-based biometrics are evident, given various security challenges, using such methods as standalone authentication could raise caution among users. To address this concern and enhance the system&#x2019;s dependability, we introduce a confidence-based rejection rule. Integrating this mechanism improves both identification and authentication performances, while it could also enable the system to detect out-of-database individuals.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Onorato d\u2019Angelis et al.",
      "keywords": "Biometrics; Computer science; Liveness; Robustness (evolution); Artificial intelligence; Fingerprint recognition; Machine learning; Iris recognition; Identifier; Facial recognition system; Computer vision; Feature extraction; Pattern recognition (psychology); Fingerprint (computing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3338191",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386025580",
      "doi": "10.1109/access.2023.3307138",
      "title": "Advances in Skeleton-Based Fall Detection in RGB Videos: From Handcrafted to Deep Learning Approaches",
      "abstract": "In the elderly population, falls are one of the leading causes of fatal and non-fatal injuries. Fall detection and early alarms play an important role in mitigating the negative effects of falls, especially given the growing proportion of the elderly population. Due to their non-intrusive nature, data availability, and low deployment costs, RGB videos have been used in many previous studies to detect falls. The RGB data, however, can be affected by background environment changes, resulting in non-recognition. To overcome these challenges, many researchers propose extracting skeleton data from RGB videos and using it for fall detection. Although there have been multiple surveys on fall detection, most of them focus on assessing fall detection systems using different kinds of sensors, and a comprehensive evaluation of skeleton-based fall detection in RGB videos is lacking. In this paper, we examine the most recent advances in skeleton-based fall detection in RGB videos, from handcrafted feature-based methods to advanced deep learning algorithms. Further, we present several skeleton-based fall detection techniques and their performance results on various benchmark datasets, along with challenges and future directions in this field.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Van-Ha Hoang et al.",
      "keywords": "Computer science; Artificial intelligence; RGB color model; Deep learning; Benchmark (surveying); Feature (linguistics); Population; Computer vision; Software deployment; Machine learning; Skeleton (computer programming); Cartography; Geography; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3307138",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312307828",
      "doi": "10.1109/access.2022.3211295",
      "title": "Clinically Relevant Sound-Based Features in COVID-19 Identification: Robustness Assessment With a Data-Centric Machine Learning Pipeline",
      "abstract": "As long as the COVID-19 pandemic is still active in most countries worldwide, rapid diagnostic continues to be crucial to mitigate the impact of seasonal infection waves. Commercialized rapid antigen self-tests proved they cannot handle the most demanding periods, lacking availability and leading to cost rises. Thus, developing a non-invasive, costless, and more decentralized technology capable of giving people feedback about the COVID-19 infection probability would fill these gaps. This paper explores a sound-based analysis of vocal and respiratory audio data to achieve that objective. This work presents a modular data-centric Machine Learning pipeline for COVID-19 identification from voice and respiratory audio samples. Signals are processed to extract and classify relevant segments that contain informative events, such as coughing or breathing. Temporal, amplitude, spectral, cepstral, and phonetic features are extracted from audio along with available metadata for COVID-19 identification. Audio augmentation and data balancing techniques are used to mitigate class disproportionality. The open-access Coswara and COVID-19 Sounds datasets were used to test the performance of the proposed architecture. Obtained sensitivity scores ranged from 60.00% to 80.00% in Coswara and from 51.43% to 77.14% in COVID-19 Sounds. Although previous works report higher accuracy on COVID-19 detection, this research focused on a data-centric approach by validating the quality of the samples, segmenting the speech events, and exploring interpretable features with physiological meaning. As the pandemic evolves, its lessons must endure, and pipelines such as the proposed one will help prepare new stages where quick and easy disease identification is essential.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Pedro Matias et al.",
      "keywords": "Computer science; Metadata; Robustness (evolution); Identification (biology); Speech recognition; Audio signal; Mel-frequency cepstrum; Machine learning; Artificial intelligence; Feature extraction; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3211295",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206455036",
      "doi": "10.1109/jbhi.2022.3140455",
      "title": "Personalized On-Device E-Health Analytics With Decentralized Block Coordinate Descent",
      "abstract": "Actuated by the growing attention to personal healthcare and the pandemic, the popularity of E-health is proliferating. Nowadays, enhancement on medical diagnosis via machine learning models has been highly effective in many aspects of e-health analytics. Nevertheless, in the classic cloud-based/centralized e-health paradigms, all the data will be centrally stored on the server to facilitate model training, which inevitably incurs privacy concerns and high time delay. Distributed solutions like Decentralized Stochastic Gradient Descent (D-SGD) are proposed to provide safe and timely diagnostic results based on personal devices. However, methods like D-SGD are subject to the gradient vanishing issue and usually proceed slowly at the early training stage, thereby impeding the effectiveness and efficiency of training. In addition, existing methods are prone to learning models that are biased towards users with dense data, compromising the fairness when providing E-health analytics for minority groups. In this paper, we propose a Decentralized Block Coordinate Descent (D-BCD) learning framework that can better optimize deep neural network-based models distributed on decentralized devices for E-health analytics. As a gradient-free optimization method, Block Coordinate Descent (BCD) mitigates the gradient vanishing issue and converges faster at the early stage compared with the conventional gradient-based optimization. To overcome the potential data scarcity issues for users' local data, we propose similarity-based model aggregation that allows each on-device model to leverage knowledge from similar neighbor models, so as to achieve both personalization and high accuracy for the learned models. Benchmarking experiments on three real-world datasets illustrate the effectiveness and practicality of our proposed D-BCD, where additional simulation study showcases the strong applicability of D-BCD in real-life E-health scenarios.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Guanhua Ye et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3140455",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206656789",
      "doi": "10.1109/jsen.2021.3138485",
      "title": "Foot-Healthcare Application Using Inertial Sensor: Estimating First Metatarsophalangeal Angle From Foot Motion During Walking",
      "abstract": "Our purpose was to demonstrate the possibility of providing foot-healthcare application by using an in-shoe motion sensor (IMS) through validating the feasibility of applying an IMS for measuring the first metatarsophalangeal angle (FMTPA), which is the most important parameter regarding the common foot problem hallux valgus. Methods: The IMS signals can represent foot motions when the mid-foot and hindfoot were modelled as a rigid body. FMTPAs can be estimated from the foot-motion signals measured using an IMS embedded beneath the foot arch near the calcaneus side using a machine-learning method. The foot-motion signals were collected from 50 participants with different FMTPAs. The true FMTPAs were assessed from digital photography. Correlation-based feature-selection processes (significance level <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${p} &lt; 0.05$ </tex-math></inline-formula> ) were used to search for the predictors from the foot-motion signals. Leave-one-subject-out cross-validation, root mean squared error, and intra-class coefficients were used for FMTPA-estimation model evaluation. Results: Eleven FMTPA-impacted gait-phase clusters, which were used to construct effective foot-motion predictors, were observed in all gait-cycle periods except terminal swing. The range of the foot motion in the sagittal and coronal planes significantly correlated with the FMTPA ( <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${p} &lt; 0.05$ </tex-math></inline-formula> ). Linear regression could be the best method for constructing an FMTPA estimation model with a root mean squared error and intra-class correlation coefficient of 4.2 degrees and 0.789, respectively. Conclusion: The results indicate the reliability of our FMTPA estimation model constructed from foot-motion signals and the possibility to providing foot-healthcare applications by using an IMS.",
      "year": "2021",
      "journal": "IEEE Sensors Journal",
      "authors": "Chenhui Huang et al.",
      "keywords": "Foot (prosody); Gait; Sagittal plane; Artificial intelligence; Motion (physics); Mathematics; Computer science; Computer vision; Medicine; Physical medicine and rehabilitation; Anatomy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2021.3138485",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389428503",
      "doi": "10.1109/access.2023.3340912",
      "title": "Attention 3D-CU-Net: Enhancing Kidney Tumor Segmentation Accuracy Through Selective Feature Emphasis",
      "abstract": "Kidney tumor segmentation from MR images became a pivotal research area in kidney cancer diagnosis and treatment planning. Accurate and efficient segmentation enables precise tumor localization, treatment planning, and monitoring of disease progression. Former studies have demonstrated the remarkable capability of the U-Net architecture in semantic segmentation of kidney tumors. A recent variant of the U-Net architecture, known as 3D-CU-Net, has been specifically designed with fully-connected dense skip connections to tackle the kidney tumor segmentation challenges related to network depth invariance, segmentation errors, and enforced feature fusion. While the 3D-CU-Net model demonstrated improved effectiveness in kidney tumor segmentation, it still exhibits significant limitations, including challenges in precise localization, fixed feature selection, image diversity, limited contextual information, and computational complexity. To address the limitations of the 3D-CU-Net model, this paper introduces the Attention 3D-CU-Net as a novel variant. The attention-based mechanism is seamlessly integrated with the 3D-CU-Net, prioritizing informative features to enhance segmentation accuracy by concentrating on selective regions. This innovative approach serves to significantly improve the model&#x2019;s performance, particularly in challenging cases. The proposed model is evaluated on the TCGA-KIRC dataset, a widely used benchmark for kidney tumor segmentation. In comparative experiments, we evaluated the results using metrics like IoU, DSC and accuracy. Our Attention 3D-CU-Net model outperforms the baseline 3D-CU-Net and U-Net with notably higher scores: IoU (0.92), DSC (0.94), and accuracy (0.96).",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sitanaboina S L Parvathi et al.",
      "keywords": "Computer science; Feature (linguistics); Segmentation; Artificial intelligence; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3340912",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386232149",
      "doi": "10.1109/access.2023.3309157",
      "title": "Threshold-Learned CNN for Multi-Label Text Classification of Electronic Health Records",
      "abstract": "Text data in the form of natural language is a valuable resource that contains domain-specific information applicable to various applications. An example are electronic health records (eHR) offering comprehensive insights into patients&#x2019; health histories, enabling knowledge extraction for clinical diagnosis and treatment. In this paper, we study multi-label text classification (MLTC) of eHR data by introducing two novel MLTC methods based on a threshold-learned convolutional neural network (CNN). We conduct comprehensive comparisons with other multi-label models and binary relevance (BR). Importantly, we do not only optimize the architecture of multi-label classifiers but also of the baseline BR model. As a result, our findings indicate that the adaptive-threshold CNN (AT-CNN) and implicit-threshold CNN (IT-CNN) provide a favorable approximation of a binary CNN (B-CNN) with the added benefit of improved runtime efficiency. The latter is crucial when the number of classes grows larger because the runtime of classifiers based on one-vs-rest mappings becomes increasingly prohibitive for such configurations.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zhen Yang et al.",
      "keywords": "Computer science; Convolutional neural network; Health records; Relevance (law); Binary number; Artificial intelligence; Domain (mathematical analysis); Binary classification; Electronic health record; Multi-label classification; Machine learning; Data mining; Pattern recognition (psychology); Support vector machine; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3309157",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3188425338",
      "doi": "10.1109/access.2021.3100686",
      "title": "Unsupervised Semantic Mapping for Healthcare Data Storage Schema",
      "abstract": "Data, information, and knowledge processing systems, in the domain of healthcare, are currently plagued by heterogeneity at various levels. Current solutions have focused on developing a standard-based, manual intervention mechanism, which requires a large number of human resources and necessitates the realignment of existing systems. State-of-the-art methodologies in the field of natural language processing and machine learning can help to partially automate this process, reducing the resource requirements and providing a relatively good multi-class-based classification algorithm. We present a novel methodology for bridging the gap between various healthcare data management solutions by leveraging the strength of transformer-based machine learning models, to create mappings between the data elements. Additionally, the annotated data, collected against five medical schemas and labeled by four annotators is made available for helping future researchers. Our results indicate, that for biased, dependent multi-class text classification, transformer-based models provide better results than linguistic and other classical models. In particular, the Robustly Optimized BERT Pretraining Approach (RoBERTa) provides the best schema matching performance by achieving a Cohen&#x2019;s kappa score of 0.47 and Matthews Correlation Coefficient (MCC) score of 0.48, with human-annotated data.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Fahad Ahmed Satti et al.",
      "keywords": "Computer science; Schema (genetic algorithms); Artificial intelligence; Transformer; Machine learning; Bridging (networking); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3100686",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366503836",
      "doi": "10.1109/access.2023.3268704",
      "title": "Failure to Achieve Domain Invariance With Domain Generalization Algorithms: An Analysis in Medical Imaging",
      "abstract": "One prominent issue in the application of deep learning is the failure to generalize to data that lies on a different distribution to the training data. While many methods have been proposed to address this, prior work has shown that when operating under the same conditions most algorithms perform almost equally. As such, more work needs to be done to validate past and future methods before they are put into important scenarios like medical imaging. Our work analyses eight domain generalization algorithms across four important medical imaging classification datasets along with three standard natural image classification problems to discover the differences in how these methods operate in these different contexts. We assess these algorithms in terms of generalization capability, domain invariance, and representational sensitivity. Through this, we show that despite the differences between domain and content variations between natural and medical imaging there is little deviation in the operation of each method between natural images and medical images. Additionally, we show that all tested algorithms retain significant amounts of domain-specific information in their feature representations despite explicit training to remove it. Thus, revealing the failure point of all these methods is a lack of class-discriminative features extracted from out-of-distribution data. While these results show that methods that work well on natural imaging work similarly in medical imaging, no method outperforms baseline methods, highlighting the continuing gap of achieving adequate domain generalization. Similarly, the results also question the efficacy of optimizing for domain invariant representations as a method for generalizing to unseen domains.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Steven Korevaar et al.",
      "keywords": "Discriminative model; Generalization; Computer science; Domain (mathematical analysis); Artificial intelligence; Algorithm; Medical imaging; Machine learning; Feature (linguistics); Invariant (physics); Pattern recognition (psychology); Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3268704",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3215613636",
      "doi": "10.1109/access.2021.3129105",
      "title": "Disease-Oriented Image Embedding With Pseudo-Scanner Standardization for Content-Based Image Retrieval on 3D Brain MRI",
      "abstract": "To build a robust and practical content-based image retrieval (CBIR) system applicable to clinical brain MRI databases, we propose a new framework, disease-oriented image embedding with pseudo-scanner standardization (DI-PSS). It consists of two core techniques: data harmonization to absorb differences caused by different scanning environments and an algorithm to generate low-dimensional embeddings suitable for disease classification. Until now, there have been very few studies aimed at CBIR of brain MRI. Even in the harmonization of scanners, which is an important prerequisite technique for CBIR, only a limited number of studies have been conducted on T1-weighted MRI, which has collected a vast amount of clinical data. Recently proposed methods need to correctly estimate the domain (i.e., dataset, scanner) of each data in advance to remove environment-dependent information from low-dimensional embedding, which is not an easy task. With DI-PSS, each brain image is pseudo-transformed into a brain image taken with a given reference scanner. Then, 3D convolutional autoencoders (3D-CAE) trained with deep metric learning generate low-dimensional embeddings that better reflect the characteristics of the disease. In this study, DI-PSS reduced the variability of distance in low-dimensional embedding between Alzheimer&#x2019;s disease (AD) and clinically normal (CN) patients, caused by differences in scanners and datasets, by 15.8-22.6&#x0025; and 18.0-29.9&#x0025;, respectively, compared to the baseline. This improved the ability of spectral clustering to classify AD and CN by 6.2&#x0025; in average accuracy and 10.7&#x0025; in macro-F1. Our method has the advantage of not requiring difficult domain prediction tasks in advance, and can effectively utilize the big data of T1-weighted MR images. Given the potential of the DI-PSS for harmonizing images scanned by MRI scanners that were not used to scan the training data, it is well suited for application to a large number of legacy MRIs captured in heterogeneous environments.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hayato Arai et al.",
      "keywords": "Computer science; Content-based image retrieval; Standardization; Scanner; Image retrieval; Artificial intelligence; Computer vision; Embedding; Image (mathematics); Brain disease; Disease; Pattern recognition (psychology); Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3129105",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386363006",
      "doi": "10.1109/access.2023.3311134",
      "title": "Toward Detecting and Addressing Corner Cases in Deep Learning Based Medical Image Segmentation",
      "abstract": "Translating machine learning research into clinical practice has several challenges. In this paper, we identify some critical issues in translating research to clinical practice in the context of medical image segmentation and propose strategies to systematically address these challenges. Specifically, we focus on cases where the model yields erroneous segmentation, which we define as corner cases. One of the standard metrics used for reporting the performance of medical image segmentation algorithms is the average Dice score across all patients. We have discovered that this aggregate reporting has the inherent drawback that the corner cases where the algorithm or model has erroneous performance or very low metrics go unnoticed. Due to this reporting, models that report superior performance could end up producing completely erroneous results, or even anatomically impossible results in a few challenging cases, albeit without being noticed.We have demonstrated how corner cases go unnoticed using the Magnetic Resonance (MR) cardiac image segmentation task of the Automated Cardiac Diagnosis Challenge (ACDC) challenge. To counter this drawback, we propose a framework that helps to identify and report corner cases. Further, we propose a novel balanced checkpointing scheme capable of finding a solution that has superior performance even on these corner cases. Our proposed scheme leads to an improvement of 44.6% for LV, 46.1% for RV and 38.1% for the Myocardium on our identified corner case in the ACDC segmentation challenge. Further, we establish the generalisability of our proposed framework by also demonstrating its applicability in the context of chest X-ray lung segmentation. This framework has broader applications across multiple deep learning tasks even beyond medical image segmentation.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Srividya Tirunellai Rajamani et al.",
      "keywords": "Segmentation; Generalizability theory; Computer science; Context (archaeology); Artificial intelligence; Image segmentation; Deep learning; Focus (optics); Medical imaging; Metric (unit); Machine learning; Pattern recognition (psychology); Computer vision; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3311134",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4321488423",
      "doi": "10.1109/tbme.2023.3247910",
      "title": "Video-Based Elevated Skin Temperature Detection",
      "abstract": "In this work, we propose a non-contact video-based approach that detects when an individual's skin temperature is elevated beyond the normal range. The detection of elevated skin temperature is critical as a diagnostic tool to infer the presence of an infection or an abnormal health condition. Detection of elevated skin temperature is typically achieved using contact thermometers or non-contact infrared-based sensors. The ubiquity of video data acquisition devices such as mobile phones and computers motivates the development of a binary classification approach, the Video-based TEMPerature (V-TEMP) to classify subjects with non-elevated/elevated skin temperature. We leverage the correlation between the skin temperature and the angular reflectance distribution of light, to empirically differentiate between skin at non-elevated temperature and skin at elevated temperature. We demonstrate the uniqueness of this correlation by 1) revealing the existence of a difference in the angular reflectance distribution of light from skin-like and non-skin like material and 2) exploring the consistency of the angular reflectance distribution of light in materials exhibiting optical properties similar to human skin. Finally, we demonstrate the robustness of V-TEMP by evaluating the efficacy of elevated skin temperature detection on subject videos recorded in 1) laboratory controlled environments and 2) outside-the-lab environments. V-TEMP is beneficial in two ways; 1) it is non-contact-based, reducing the possibility of infection due to contact and 2) it is scalable, given the ubiquity of video-recording devices.",
      "year": "2023",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Ananyananda Dasari et al.",
      "keywords": "Computer science; Computer vision; Skin temperature; Biomedical engineering; Artificial intelligence; Materials science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2023.3247910",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391892630",
      "doi": "10.1109/access.2024.3366801",
      "title": "This Intestine Does Not Exist: Multiscale Residual Variational Autoencoder for Realistic Wireless Capsule Endoscopy Image Generation",
      "abstract": "Medical image synthesis has emerged as a promising solution to address the limited availability of annotated medical data needed for training machine learning algorithms in the context of image-based Clinical Decision Support (CDS) systems. To this end, Generative Adversarial Networks (GANs) have been mainly applied to support the algorithm training process by generating synthetic images for data augmentation. However, in the field of Wireless Capsule Endoscopy (WCE), the limited content diversity and size of existing publicly available annotated datasets adversely affect both the training stability and synthesis performance of GANs. In this paper a novel Variational Autoencoder (VAE) architecture is proposed for WCE image synthesis, namely &#x2018;This Intestine Does not Exist&#x2019; (TIDE). This is the first VAE architecture comprising multiscale feature extraction convolutional blocks and residual connections. Its advantage is that it enables the generation of high-quality and diverse datasets even with a limited number of training images. Contrary to the current approaches, which are oriented towards the augmentation of the available datasets, this study demonstrates that using TIDE, real WCE datasets can be fully substituted by artificially generated ones, without compromising classification performance of CDS. It performs a spherical experimental evaluation study that covers both quantitative and qualitative aspects, including a user evaluation study performed by WCE specialists, which validate from a medical viewpoint that both the normal and abnormal WCE images synthesized by TIDE are sufficiently realistic. The quantitative results obtained by comparative experiments validate that the proposed architecture outperforms the state-of-the-art.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Dimitrios E. Diamantis et al.",
      "keywords": "Computer science; Autoencoder; Artificial intelligence; Context (archaeology); Capsule endoscopy; Residual; Stability (learning theory); Feature extraction; Process (computing); Deep learning; Pattern recognition (psychology); Machine learning; Data mining; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3366801",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2890007211",
      "doi": "10.1109/access.2019.2935416",
      "title": "Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization With Medical Applications",
      "abstract": "Medical applications challenge today's text categorization techniques by demanding both high accuracy and ease-of-interpretation. Although deep learning has provided a leap ahead in accuracy, this leap comes at the sacrifice of interpretability. To address this accuracy-interpretability challenge, we here introduce, for the first time, a text categorization approach that leverages the recently introduced Tsetlin Machine. In all brevity, we represent the terms of a text as propositional variables. From these, we capture categories using simple propositional formulae, such as: if \"rash\" and \"reaction\" and \"penicillin\" then Allergy. The Tsetlin Machine learns these formulae from a labelled text, utilizing conjunctive clauses to represent the particular facets of each category. Indeed, even the absence of terms (negated features) can be used for categorization purposes. Our empirical comparison with Na\u00efve Bayes, decision trees, linear support vector machines (SVMs), random forest, long short-term memory (LSTM) neural networks, and other techniques, is quite conclusive. The Tsetlin Machine either performs on par with or outperforms all of the evaluated methods on both the 20 Newsgroups and IMDb datasets, as well as on a non-public clinical dataset. On average, the Tsetlin Machine delivers the best recall and precision scores across the datasets. Finally, our GPU implementation of the Tsetlin Machine executes 5 to 15 times faster than the CPU implementation, depending on the dataset. We thus believe that our novel approach can have a significant impact on a wide range of text analysis applications, forming a promising starting point for deeper natural language understanding with the Tsetlin Machine.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Geir Thore Berge et al.",
      "keywords": "Interpretability; Artificial intelligence; Computer science; Machine learning; Support vector machine; Naive Bayes classifier; Categorization; Random forest; Natural language processing",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2019.2935416",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389776556",
      "doi": "10.1109/jiot.2023.3343462",
      "title": "ERUDITE: Human-in-the-Loop IoT for an Adaptive Personalized Learning System",
      "abstract": "Thanks to the rapid growth in wearable technologies and advancements in machine learning, monitoring complex human contexts becomes feasible, paving the way to develop human-in-the-loop IoT systems that naturally evolve to adapt to the human and environment state autonomously. Nevertheless, a central challenge in designing many of these IoT systems arises from the requirement to infer the human mental state, such as intention, stress, cognition load, or learning ability. While different human contexts can be inferred from the fusion of different sensor modalities that can correlate to a particular mental state, the human brain provides a richer sensor modality that gives us more insights into the required human context. This paper proposes ERUDITE, a human-in-the-loop IoT system for the learning environment that exploits recent wearable neurotechnology to decode brain signals. Through insights from concept learning theory, ERUDITE can infer the human state of learning and understand when human learning increases or declines. By quantifying human learning as an input sensory signal, ERUDITE can provide adequate personalized feedback to humans in a learning environment to enhance their learning experience. ERUDITE is evaluated across 15 participants and showed that by using the brain signals as a sensor modality to infer the human learning state and providing personalized adaptation to the learning environment, the participants' learning performance increased on average by 26%. Furthermore, to evaluate ERUDITE practicality and scalability, we showed that ERUDITE can be deployed on an edge-based prototype consuming 75 mW power on average with 100 MB memory footprint.",
      "year": "2023",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Mojtaba Taherisadr et al.",
      "keywords": "Computer science; Human-in-the-loop; Adaptive system; Artificial intelligence; Internet of Things; Loop (graph theory); Feedback loop; Distributed computing; Machine learning; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2023.3343462",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4289856655",
      "doi": "10.1109/tcss.2022.3191821",
      "title": "COVID-19\u2019s Impact on Mental Health\u2014The Hour of Computational Aid?",
      "abstract": "Welcome to the fourth issue of IEEE Transactions on Computational Social Systems (TCSS) in 2022. First, we have some exciting news to share. In late June, Clarivate updated the Impact Factor of all journals which are indexed by Web of Science. According to the Journal Citation Reports, the 2021 Journal Impact Factor of IEEE TCSS was 4.727. Many thanks to all for your great effort and support.",
      "year": "2022",
      "journal": "IEEE Transactions on Computational Social Systems",
      "authors": "Bj\u00f6rn W. Schuller et al.",
      "keywords": "Impact factor; Coronavirus disease 2019 (COVID-19); Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); 2019-20 coronavirus outbreak; Citation; Web of science; Computer science; Mental health; Data science; Library science; MEDLINE; Medicine; Political science; Psychiatry; Virology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcss.2022.3191821",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4384518975",
      "doi": "10.1109/access.2023.3296261",
      "title": "Transformers for Multi-Intent Classification and Slot Filling of Supreme Court Decisions Related to Sexual Violence Law",
      "abstract": "Sexual violence is a pervasive and complex issue that demands an immediate and comprehensive solution. The previous study titled &#x201C;LAW-U: Legal Guidance Through Artificial Intelligence Chatbot for Sexual Violence Victims and Survivors&#x201D; highlighted the crucial role of technology in addressing this problem. The current study aims to overcome limitations in the previous study by investigating the use of transformer-based models for multi-intent classification of Thai Supreme Court decision fragments related to Section 276 of the Thai Criminal Code. Utilizing various evaluation matrices, the study evaluates the effectiveness of transfer learning through transformer-based pre-trained language models against a Word2Vec-based support vector machine to detect criminal intents from decision fragments. The results demonstrate that transformer-based models, particularly XLM-RoBERTaBASE, outperform the Word2Vec-based support vector machine in multi-intent classification. The macro average F1-score of 0.77 and micro average F1-score of 0.78 achieved by the best-performing model indicates the effectiveness of pre-trained transformers with fine-tuning. The study also employs a t-SNE visualization to gain insights into the overlapping between criminal intents and the areas where misclassifications occur. The visualization reveals that misclassification occur between closely related or overlapping intents, especially when decision fragments have multiple intents. Overall, the study contributes to the field of legal technology by creating a model that can accurately classify criminal intents related to Section 276, which can be extrapolated to other sexual violence laws. The model will be used to train the updated version of LAW-U, specifically called LAW-U-RoBERTa, which will provide legal recommendations to sexual violence survivors and empower them to reaffirm their inherent rights through seeking justice. The study demonstrates the potential of artificial intelligence chatbots to support survivors of sexual violence and contribute to the fight against the pervasive problem of sexual violence.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "A. Munthuli et al.",
      "keywords": "Word2vec; Computer science; Supreme court; Artificial intelligence; Visualization; Transformer; Court decision; Support vector machine; Machine learning; Criminal code; Sexual violence; Criminal law; Law; Natural language processing; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3296261",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391020101",
      "doi": "10.1109/jbhi.2024.3355951",
      "title": "Attention Mechanisms in Clinical Text Classification: A Comparative Evaluation",
      "abstract": "Attention mechanisms are now a mainstay architecture in neural networks and improve the performance of biomedical text classification tasks. In particular, models that perform automated medical encoding of clinical documents make extensive use of the label-wise attention mechanism. A label-wise attention mechanism increases a model's discriminatory ability by using label-specific reference information. This information can either be implicitly learned during training or explicitly provided through embedded textual code descriptions or information on the code hierarchy; however, contemporary studies arbitrarily select the type of label-specific reference information. To address this shortcoming, we evaluated label-wise attention initialized with either implicit or explicit label-specific reference information against two common baseline methods-target-attention and text-encoder architecture-specific methods-to generate document embeddings across four text-encoder architectures-a convolutional neural network, two recurrent neural networks, and a transformer. We also present an extension of label-wise attention that can embed the information on the code hierarchy. We performed our experiments on the MIMIC III dataset, which is a standard dataset in the clinical text classification domain. Our experiments showed that using pretrained reference information and the hierarchical design helped improve classification performance. These performance improvements had less impact on larger datasets and label spaces across all text-encoder architectures. In our analysis, we used an attention mechanism's energy scores to explain the perceived differences in performance and interpretability between the text-encoder architectures and types of label-attention.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Christoph Metzner et al.",
      "keywords": "Computer science; Artificial intelligence; Natural language processing; Information retrieval",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3355951",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2904398209",
      "doi": "10.1109/access.2018.2887082",
      "title": "Towards a Hybrid Expert System Based on Sleep Event\u2019s Threshold Dependencies for Automated Personalized Sleep Staging by Combining Symbolic Fusion and Differential Evolution Algorithm",
      "abstract": "Identification of sleep stages is a fundamental step in clinical sleep analysis. Existing automatic sleep staging systems ignore two major issues: 1) Most of existing automatic sleep staging systems are using numerical classification methods without involving medical knowledge. These kinds of systems are not yet understood and accepted by physicians. 2) Individual variability sources are ignored. However, individual variability is observed in many aspects of sleep research (such as polysomnography recordings, sleep patterns, and sleep architecture). In this paper, a hybrid expert system is proposed to mimic the decision-making process of clinical sleep staging in accordance with the medical knowledge by using symbolic fusion. To formalize the medical guideline and knowledge, thresholds are used for translating the sleep events into symbols and the sleep event&#x2019;s threshold dependencies are analyzed for fully understanding the thresholds dependencies among different sleep stages and subjects. Meanwhile, the differential evolution algorithm is adopted to automate the setting-up of thresholds that are used in the symbolic fusion model and to provide personalized thresholds, which allows taking the individual variability into consideration. The robustness and clinical applicability of the proposed system are evaluated and demonstrated on a clinical dataset. The dataset is composed of 16 patients (nine males and seven females) and scored by physicians. Only 5&#x0025; of the dataset is used for the training process to obtain the personalized thresholds. Then, these personalized thresholds are passed to the classification process, and the overall accuracy on the identification of five sleep stages reaches 80.09&#x0025;. Using a small dataset for the training process, the proposed system not only drastically reduces the training set but also achieves favorable results compared with most of the existing works.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Chen Chen et al.",
      "keywords": "Computer science; Sleep (system call); Event (particle physics); Fusion; Algorithm; Artificial intelligence; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2887082",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392902351",
      "doi": "10.1109/access.2024.3377242",
      "title": "Multiple Imputation for Robust Cluster Analysis to Address Missingness in Medical Data",
      "abstract": "Cluster analysis has been applied to a wide range of problems as an exploratory tool to enhance knowledge discovery. Clustering aids disease subtyping, i.e. identifying homogeneous patient subgroups, in medical data. Missing data is a common problem in medical research and could bias clustering results if not properly handled. Yet, multiple imputation has been under-utilized to address missingness, when clustering medical data. Its limited integration in clustering of medical data, despite the known advantages and benefits of multiple imputation, could be attributed to many factors. This includes methodological complexity, difficulties in pooling results to obtain a consensus clustering, uncertainty regarding quality metrics, and a lack of accepted pipelines. A few studies have examined the feasibility of implementing multiple imputation for cluster analysis on simulated/small datasets. While these studies have begun to address how to pool imputed values and quantify uncertainty in clustering due to imputation, a need remains for a complete framework that integrates MI in the clustering of complex medical data and sophisticated cluster algorithms. We propose a cluster analysis framework that mitigates bias and addresses these limitations. It includes methods to pool multiple imputed datasets, create a consensus cluster solution by ensemble methods, and select an optimal number of clusters based on validity indices. It also estimates uncertainty about cluster membership attributable to the imputation and identifies features that characterize the derived clusters. The utility of this framework is illustrated by its application to a traumatic brain injury dataset with missing data. Our analysis revealed six multifaceted clusters that differed with respect to Glasgow Coma Score (GCS), mechanism of injury, sociodemographics, vitals, lab values, and radiological presentation. The most severe cluster consisted of single, relatively young patients injured by motor accident, with higher GCS severity scores. Comparative analysis with the miclust R package, along with statistical validation of cluster characterization, demonstrates its robust performance.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Arnold A. Harder et al.",
      "keywords": "Missing data; Computer science; Imputation (statistics); Cluster (spacecraft); Data mining; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3377242",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210401844",
      "doi": "10.23919/jsc.2021.0023",
      "title": "Algorithmic Silence: A Call to Decomputerize",
      "abstract": "Tech critics become technocrats when they overlook the daunting administrative density of a digital-first society. The author implores critics to reject structural dependencies on digital tools rather than naturalize their integration through critique and reform. At stake is the degree to which citizens must defer to unelected experts to navigate such density. Democracy dies in the darkness of sysadmin. The argument and a candidate solution proceed as follows. Since entropy is intrinsic to all physical systems, including digital systems, perfect automation is a fiction. Concealing this fiction, however, are five historical forces usually treated in isolation: ghost work, technical debt, intellectual debt, the labor of algorithmic critique, and various types of participatory labor. The author connects these topics to emphasize the systemic impositions of digital decision tools, which compound entangled genealogies of oppression and temporal attrition. In search of a harmonious balance between the use of \u201cAI\u201d tools and the non-digital decision systems they are meant to supplant, the author draws inspiration from an unexpected source: musical notation. Just as musical notes require silence to be operative, the author positions algorithmic silence\u2014the deliberate exclusion of highly abstract digital decision systems from human decision-making environments\u2014as a strategic corrective to the fiction of total automation. Facial recognition bans and the Right to Disconnect are recent examples of algorithmic silence as an active trend.",
      "year": "2021",
      "journal": "Journal of Social Computing",
      "authors": "Jonnie Penn",
      "keywords": "Silence; Sociology; Computer science; Oppression; Argument (complex analysis); Aesthetics; Technocracy; Law and economics; Epistemology; Law; Political science; Politics; Art; Philosophy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2021.0023",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386902909",
      "doi": "10.1109/access.2023.3317793",
      "title": "Comparison of Supervised Learning Algorithms for Quality Assessment of Wearable Electrocardiograms With Paroxysmal Atrial Fibrillation",
      "abstract": "Emerging wearable technology able to monitor electrocardiogram (ECG) continuously for long periods of time without disrupting the patient&#x2019;s daily life represents a great opportunity to improve suboptimal current diagnosis of paroxysmal atrial fibrillation (AF). However, its integration into clinical practice is still limited because the acquired ECG recording is often strongly contaminated by transient noise, thus leading to numerous false alarms of AF and requiring manual interpretation of extensive amounts of ECG data. To improve this situation, automated selection of ECG segments with sufficient quality for precise diagnosis has been widely proposed, and numerous algorithms for such ECG quality assessment can be found. Although most have reported successful performance on ECG signals acquired from healthy subjects, only a recent algorithm based on a well-known pre-trained convolutional neural network (CNN), such as AlexNet, has maintained a similar efficiency in the context of paroxysmal AF. Hence, having in mind the latest major advances in the development of neural networks, the main goal of this work was to compare the most recent pre-trained CNN models in terms of classification performance between high- and low-quality ECG excerpts and computational time. In global values, all reported a similar classification performance, which was significantly superior than the one provided by previous methods based on combining hand-crafted ECG features with conventional machine learning classifiers. Nonetheless, shallow networks (such as AlexNet) trended to detect better high-quality ECG excerpts and deep CNN models to identify better noisy ECG segments. The networks with a moderate depth of about 20 layers presented the best balanced performance on both groups of ECG excerpts. Indeed, GoogLeNet (with a depth of 22 layers) obtained very close values of sensitivity and specificity about 87&#x0025;. It also maintained a misclassification rate of AF episodes similar to AlexNet and an acceptable computation time, thus constituting the best alternative for quality assessment of wearable, long-term ECG recordings acquired from patients with paroxysmal AF.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "\u00c1lvaro Huerta Herr\u00e1iz et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Machine learning; Context (archaeology); Wearable computer; Paroxysmal atrial fibrillation; Deep learning; Artificial neural network; Atrial fibrillation; Noise (video); Pattern recognition (psychology); Medicine; Cardiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3317793",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3164264239",
      "doi": "10.1109/access.2021.3083668",
      "title": "Testing the Feasibility of a Multi-Model Fusion Method for Monitoring the Action of Rehabilitating Stroke Patients in Care Management",
      "abstract": "Post-stroke care encounters challenges, including high cost, lack of professionals, and insufficient rehabilitation state evaluation. Computer technology can alleviate these issues, as it allows health care professionals (HCP) to quantify the workload and thus enhance rehabilitation care quality. In this paper, a novel multi-model fusion method, terms as pose dual-stream network (PDSN), is devised, aiming to test the feasibility of monitoring the training actions of rehabilitating stroke patients in care management. In particular, this deep-learning-based algorithm combines human pose estimation and dual-stream networks in an innovative way. We utilize an improved OpenPose to estimate human pose from videos obtained by the low-cost monocular camera. In dual-stream networks, the spatial and motion streams are flexibly integrated. The spatial stream network combines the Gated Recurrent Unit (GRU) and attention mechanism to extract spatiotemporal data, while the motion stream network is composed of improved multi-layer 1D Convolutional Neural Networks (CNN), which enhanced by causal and dilated convolution skillfully. Additionally, an adaptive weight fusion strategy is used to fuse the two networks for the final action classification. Results show high accuracy on two public datasets and a dataset created by us, which validate the superiority and feasibility of our method.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Yao Tong et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Deep learning; Fuse (electrical); Machine learning; Workload; Motion (physics); Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3083668",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386766759",
      "doi": "10.1109/access.2023.3316019",
      "title": "Check It Before You Wreck It: A Guide to STAR-ML for Screening Machine Learning Reporting in Research",
      "abstract": "Machine learning (ML) is a technique that learns to detect patterns and trends in data. However, the quality of reporting ML in research is often suboptimal, leading to inaccurate conclusions and hindering progress in the field, especially if disseminated in literature reviews that provide researchers with an overview of a field, current knowledge gaps, and future directions. While various tools are available to assess the quality and risk-of-bias of studies, there is currently no generalized tool for assessing the reporting quality of ML in the literature. To address this, this study presents a new screening tool called STAR-ML (Screening Tool for Assessing Reporting of Machine Learning), accompanied by a guide to using it. A pilot scoping review looking at ML in chronic pain was used to investigate the tool. The time it took to screen papers and how the selection of the threshold affected the papers included were explored. The tool provides researchers with a reliable and systematic way to evaluate the quality of reporting of ML studies and to make informed decisions about the inclusion of studies in scoping or systematic reviews. In addition, this study provides recommendations for authors on how to choose the threshold for inclusion and use the tool proficiently. Lastly, the STAR-ML tool can serve as a checklist for researchers seeking to develop or implement ML techniques effectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ryan G. L. Koh et al.",
      "keywords": "Checklist; Computer science; Inclusion (mineral); Field (mathematics); Quality (philosophy); Systematic review; Data science; Artificial intelligence; Machine learning; MEDLINE; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3316019",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391242892",
      "doi": "10.1109/tcss.2024.3350958",
      "title": "Physiological Electrosignal Asynchronous Acquisition Technology: Insight and Perspectives",
      "abstract": "With great pride and enthusiasm, we present the inaugural edition of IEEE Transactions on Computational Social Systems (TCSS) for 2024. Reflecting on the year gone by, 2023 stands as a hallmark of academic excellence and prolific output, wherein our journal has successfully disseminated a substantial volume of scholarly work\u2014301 articles encompassing approximately 3600 pages, distributed across six distinct issues.",
      "year": "2024",
      "journal": "IEEE Transactions on Computational Social Systems",
      "authors": "Bin Hu et al.",
      "keywords": "Enthusiasm; Excellence; Asynchronous communication; Pride; Computer science; Data science; Work (physics); Engineering; Telecommunications; Political science; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcss.2024.3350958",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312837773",
      "doi": "10.1109/access.2022.3221409",
      "title": "A Path Dependent Approach for Characterizing the Legal Governance of Autonomous Systems",
      "abstract": "Autonomous systems promise significant improvements in many fields. These systems will be subject to legal governance requirements. The literature has largely focused on \u201cautonomous governance\u201d as a framework that is broadly applicable to autonomous devices regardless of the type of system (e.g., aviation or motor vehicles) at issue. While there are regulatory principles applicable to autonomous systems generally, an \u201cautonomy-focused\u201d approach is an inadequate lens to consider the governance of these systems. Rather, because autonomous systems are improvements of currently regulated complex systems, the regulation of autonomous elements will occur within those systems\u2019 preexisting regulatory framework. Accordingly, the nature of future autonomous regulation will likely depend on the preexisting features of that substantive system, rather than on an optimal approach divorced from that history, an attribute known in the social science literature as path dependency. In order to characterize diverse regulated systems with an eye toward assessing future autonomous developments, we develop a framework of regulatory approaches to identify specific features of the preexisting regulatory scheme for a given system. We then analyze that approach by examining three different regulatory regimes (aviation, motor vehicles, and medical devices), across two different continents, and consider how the same type of requirement, e.g., fail-safe systems, can lead to different types of regulations depending on the differing baseline framework.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Joseph E. Borson et al.",
      "keywords": "Corporate governance; Autonomy; Computer science; Autonomous system (mathematics); Aviation; Path (computing); Risk analysis (engineering); Artificial intelligence; Business; Law; Political science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3221409",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389891277",
      "doi": "10.1109/access.2023.3343845",
      "title": "Toward More Transparent and Accurate Cancer Diagnosis With an Unsupervised CAE Approach",
      "abstract": "[EN] According to the Global Cancer Observatory, 2020, breast cancer is the most prevalent\\ncancer type in both genders (11.7%), while prostate cancer is the second most common cancer type in\\nmen (14.1%). In digital pathology, Content-Based Medical Image Retrieval (CBMIR) is a powerful tool\\nfor improving cancer diagnosis by searching for similar histopathological Whole Slide Images (WSIs).\\nCBMIR empowers pathologists to explore similar patches to their query, enhancing diagnostic reliability and\\naccuracy. In this paper, a customized unsupervised Convolutional Auto Encoder (CAE) was developed in the\\nproposed Unsupervised CBMIR (UCBMIR) to replicate the traditional cancer diagnosis workflow, offering\\nthe potential to enhance diagnostic accuracy and efficiency by reducing pathologists\u00bf workload. Furthermore,\\nit provides a more transparent supporting tool for pathologists in cancer diagnosis. UCBMIR was evaluated\\nusing two widely used numerical techniques in CBMIR, visual techniques, and compared with a classifier.\\nValidation encompassed three data sets, including an external evaluation to demonstrate its effectiveness.\\nUCBMIR achieved 99% and 80% top 5 recalls on BreaKHis and SICAPv2 with the first evaluation\\ntechnique while using the second technique, it reached 91% and 70% precision for BreaKHis and SICAPv2,\\nrespectively. Moreover, UCBMIR displayed a strong capability to identify diverse patterns, yielding 81%\\naccuracy in the top 5 predictions on an external image from Arvaniti. The proposed unsupervised CBMIR\\ntool delivered 83% accuracy in retrieving images with the same cancer type.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zahra Tabatabaei et al.",
      "keywords": "Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3343845",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313015293",
      "doi": "10.1109/access.2022.3224055",
      "title": "Assisting in Diagnosis of Temporomandibular Disorders: A Deep Learning Approach",
      "abstract": "The etiology of Temporomandibular disorders (TMD) is still unclear, and its symptoms, signs, and progression are extremely complex. TMD requires early diagnosis and treatments, especially for combinations with other oral diseases. The research targets at developing an artificial neural network (ANN) model for predicting TMD based on clinical-collected data including clinical features, systematic medical condition, and psychosocial state. The popular data mining-based ANN was utilized to predict TMD with all 18 variables collected from patients as the input. The total dataset consists of 88 cases which were reviewed by Board-certificated orthodontists. 75&#x0025; (66) cases are randomly selected as the training dataset, while the remaining 25&#x0025; (22) cases are for test. Among the considered 88 cases, 58 (65.9&#x0025;) were with TMD, while the left 30 (34.1&#x0025;) without TMD. The numbers of male and female were 21 and 67, respectively, while the average age was 27.63 years. The calculated average sensitivity and specificity of ANN-based TMD risk predictions through 10-fold-cross-validation analysis were 92.31&#x0025; (95&#x0025; confidence interval (CI), 62.09&#x0025;-99.60&#x0025;) and 88.89&#x0025; (95&#x0025; CI, 50.67&#x0025;-99.42&#x0025;), respectively. Moreover, the accuracy rate of ANN was 90.91&#x0025; (95&#x0025; CI, 78.90&#x0025;-100.00&#x0025;). The results show the proposed ANN model could predict the TMD risks with a high accuracy rate, indicating the potential of machine learning in oral and maxillofacial diseases screening and diagnosis, which was further illustrated in a comparison with two doctors. This study can help dental care providers to find individuals&#x2019; risk of TMD by inputting patient&#x2019;s psychological factors, oral examinations, and systemic medical conditions to the developed artificial intelligence (AI) model.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Zou Wei et al.",
      "keywords": "Computer science; Deep learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3224055",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386431957",
      "doi": "10.1109/access.2023.3311752",
      "title": "Discovering Mathematical Patterns Behind HIV-1 Genetic Recombination: A New Methodology to Identify Viral Features",
      "abstract": "In this article, we introduce a novel methodology for characterizing viral genetic features: the Unified Methodology of recombinant virus Identification (UMI). Our methodology converts genomic sequences into spectrograms, applies transfer learning using a pre-trained Convolutional Neural Network (CNN), and employs interpretability tools to identify the genomic regions relevant for characterizing a viral sequence as recombinant. The UMI methodology does not necessitate multiple sequence alignment or manual adjustments. As a result, it operates much faster, has low computational demands, and is capable of handling substantial amounts of data. To validate this, we applied UMI to one extensively studied and documented case: HIV-1 genetic recombination. We worked with all identified HIV-1 complete sequences (13554 sequences up to 2020), searching for mathematical patterns, signatures, that characterize an HIV-1 sequence as recombinant. CNN&#x2019;s hit rate (test accuracy) is 94&#x0025;, with consistent and differentiated decision areas in each category. Using interpretability tools, we verified that the hot zones were similar for sequences of the same subtype and phylogenetic proximity. The leading areas for classifying a sequence as recombinant or non-recombinant are coincident with genomic regions that play a key role in genetic recombination processes. By applying UMI methodology we found that there is indeed a genome mathematical pattern that assesses an HIV-1 sequence as recombinant. In addition, we located its position. Considering expert knowledge, our results showed a substantial, robust and biologically-consistent hit rate. This type of solution can successfully guide the location and subsequent characterization of relevant areas, avoiding the heavy analysis of multiple sequence alignment and manual adjustments.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ana Guerrero-Tamayo et al.",
      "keywords": "Interpretability; Computational biology; Sequence (biology); Computer science; Genome; Recombinant DNA; Identification (biology); Artificial intelligence; Genetics; Convolutional neural network; Biology; Gene",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3311752",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4323767288",
      "doi": "10.1109/access.2023.3253933",
      "title": "Practical R-R Interval Editing for Heart Rate Variability Analysis Using Single-Channel Wearable ECG Devices",
      "abstract": "Recent innovations in wearable devices have expanded the usage opportunities of single-channel electrocardiography (ECG) recordings in a daily life environment and enabled a variety of indirect daily activity monitoring based on heart rate variability (HRV). In general, wearable ECGs rarely undergo visual inspection by medical experts and therefore may contain noise or artifacts. Although noise/artifact-induced changes in ECG waveforms are known to cause misdetection of the QRS complex (i.e., the most distinguishable ECG components comprised of Q wave, R wave, and S wave), its complete suppression might be technically impossible. Since misdetection occurs in the QRS complex unit, we propose reframing the traditional HRV analysis flow by subdividing the R-R interval (RRI) editing into four steps in accordance with the processing detail (i.e., identification and editing) and its target unit (i.e., QRS complex or RRI). In addition, as a dubious QRS complex identification method for practical use, we utilize the amplitude at the detected point assuming the use of a single-channel wearable ECG without a reference. Initial evaluations using pseudo/real ECG datasets including ECGs with noise/artifacts show that the proposed processing/unit-based subdivision is theoretically effective for improving HRV calculation accuracy, and that the dubious QRS complex identification method for practical use also maintains this effect. Our study starting from practical HRV analysis using single-channel wearable ECG devices encourages reexamining each step in HRV analysis through the interdisciplinary research of clinical medicine and engineering/informatics that reveals the relationship of every two adjacent steps from the perspective of theory and practice.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Kana Eguchi et al.",
      "keywords": "Computer science; QRS complex; Wearable computer; Artifact (error); Identification (biology); Noise (video); Artificial intelligence; Electrocardiography; Wearable technology; QT interval; Heart rate variability; Speech recognition; Pattern recognition (psychology); Heart rate; Medicine; Embedded system; Cardiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3253933",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386472890",
      "doi": "10.1109/access.2023.3312579",
      "title": "FeLebrities: A User-Centric Assessment of Federated Learning Frameworks",
      "abstract": "Federated Learning (FL) is a new paradigm aimed at solving data access problems. It provides a solution by moving the focus from sharing data to sharing models. The FL paradigm involves different entities (institutions) holding proprietary datasets that, contributing with each other to train a global Artificial Intelligence (AI) model using their own locally available data. Although several studies have proposed methods to distribute the computation or aggregate results, few efforts have been made to cover on how to implement FL pipelines. With the aim of accelerating the exploitation of FL frameworks, this paper proposes a survey of public tools that are currently available for building FL pipelines, an objective ranking based on the current state of user preferences, and an assessment of the growing trend of the tool&#x2019;s popularity over a one year time window, with measurements performed every six months. These measurements include objective metrics, like the number of &#x201C;Watch,&#x201D; &#x201C;Star&#x201D; and &#x201C;Follow&#x201D; available from software repositories as well as thirteen custom metrics grouped into three main categories: Usability, Portability, and Flexibility. Finally, a ranking of the maturity of the tools is derived based on the key aspects to consider when building a FL pipeline.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Walter Riviera et al.",
      "keywords": "Computer science; Software portability; Ranking (information retrieval); Usability; Flexibility (engineering); Pipeline (software); Popularity; Key (lock); Focus (optics); Interoperability; Pipeline transport; Data science; World Wide Web; Database; Artificial intelligence; Computer security; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312579",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2986358614",
      "doi": "10.1109/access.2020.2965955",
      "title": "Precision Medicine Informatics: Principles, Prospects, and Challenges",
      "abstract": "Precision Medicine (PM) is an emerging approach that appears with the impression of changing the existing paradigm of medical practice. Recent advances in technological innovations and genetics, and the growing availability of health data have set a new pace of the research and imposes a set of new requirements on different stakeholders. To date, some studies are available that discuss about different aspects of PM. Nevertheless, a holistic representation of those aspects deemed to confer the technological perspective, in relation to applications and challenges, is mostly ignored. In this context, this paper surveys advances in PM from informatics viewpoint and reviews the enabling tools and techniques in a categorized manner. In addition, the study discusses how other technological paradigms including big data, artificial intelligence, and internet of things can be exploited to advance the potentials of PM. Furthermore, the paper provides some guidelines for future research for seamless implementation and wide-scale deployment of PM based on identified open issues and associated challenges. To this end, the paper proposes an integrated holistic framework for PM motivating informatics researchers to design their relevant research works in an appropriate context.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Muhammad Afzal et al.",
      "keywords": "Data science; Context (archaeology); Pace; Computer science; Software deployment; Set (abstract data type); Health informatics; Big data; Informatics; Precision medicine; Perspective (graphical); Knowledge management; Management science; Engineering; Health care; Medicine; Artificial intelligence; Data mining; Software engineering; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2020.2965955",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3040693985",
      "doi": "10.1109/access.2020.3008000",
      "title": "Application of Deep Learning Algorithm in Feature Mining and Rapid Identification of Colorectal Image",
      "abstract": "Based on deep learning technology, this paper proposes a two-stage colorectal image feature mining and fast recognition model to achieve fully automatic medical image pathology discrimination. Drawing on the ideas of multi-factor Meta-regression analysis widely used in the medical field and the model aggregation framework based on Bayesian prior probability theory, a prognostic model of colorectal tumors suitable for various situations and scenarios is constructed. And using a combination of public data sets and real data sets, design two sets of experiments to verify these models from different angles. The algorithm was used to select one, four, and five related features from three sequences to construct three sets of prediction models. The application of the six algorithms failed to obtain a better predictive model (AUC value range 0.439 ~ 0.640). The algorithm (AUC value 0.750&#x00B1; 0.137) and the algorithm (AUC value 0.764&#x00B1; 0.128) can be used to obtain models with better predictive performance, and the four models are less effective (AUC value&lt;; 0.7). In the joint model, the algorithm (AUC value 0.742 &#x00B1; 0.101) and the algorithm (AUC value 0.718&#x00B1; 0.069) can also be used to obtain a model with better prediction performance. Image-based imaging histology tags can be used as a non-invasive auxiliary tool for preoperative evaluation of histological grading of CRAC, and are expected to be applied in clinical practice to assist in the development of individualized treatment plans.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mingchao Du et al.",
      "keywords": "Computer science; Artificial intelligence; Algorithm; Machine learning; Feature (linguistics); Grading (engineering); Pattern recognition (psychology); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3008000",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4367728434",
      "doi": "10.1109/access.2023.3272352",
      "title": "TAGU-Net: Transformer Convolution Hybrid-Based U-Net With Attention Gate for Atypical Meningioma Segmentation",
      "abstract": "Meningioma is derived from the cap cells that reside on the arachnoid membrane. The atypical meninges of Grade II, a classification established by the World Health Organization, are included in one of the grades of meningioma. It has been discovered that early surgical resection significantly reduces the recurrence rate and mortality of tumors. Accurate segmentation of magnetic resonance images of brain tumors is crucial for diagnosing and treating atypical meningiomas. However, the traditional automatic segmentation framework heavily relies on convolution. The convolution-based segmentation network has limitations such as the size of the convolution kernels, a restricted receptive field, and a lack of spatial aggregation ability. To overcome these limitations, this paper presents a novel hybrid architecture named TAGU-Net, which combines Transformer and convolution based on U-Net with an attention gate. The TAGU-Net architecture extracts features of different resolution feature scales using convolutional neural network and Transformer. This approach effectively captures the image&#x2019;s long-distance dependency and global characteristics in the encoder stage, relying on the global self-attention mechanism of the Transformer. Additionally, the inductive bias of the convolution neural network is combined to enhance the local modeling information and improve the model&#x2019;s overall modeling ability. In the decoder phase, the attention gate is introduced to adaptively learn the skip connection information and up-sampling information in the network. This information is weighted and fused to highlight important features and suppress irrelevant features. To obtain better model training and avoid the vanishing gradient, deep supervision technology is used in the training process. Supplementary loss is added in some stages to supervise the training and achieve the best effect of atypical meningioma segmentation. The proposed method is evaluated on both the private atypical meningioma dataset and the publicly available BraTs2018 dataset.TAGU-Net has achieved Dice Scores of 97.67&#x0025; and 97.62&#x0025; and Jaccard index of 96.35&#x0025; and 95.35&#x0025; on the private atypical meningioma dataset and BraTs2018 dataset respectively, which is a state-of-the-art segmentation result beyond existing methods. According to the research results, the TAGU-Net model significantly improves atypical meningioma segmentation and can effectively assist doctors in processing MRI images.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Hong Huang et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Convolutional neural network; Convolution (computer science); Transformer; Deep learning; Pattern recognition (psychology); Image segmentation; Encoder; Artificial neural network; Engineering; Voltage",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3272352",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3015061673",
      "doi": "10.1109/access.2020.2981119",
      "title": "Convolution Denoising Regularized Auto Encoder Stacked Method for Coronary Acute Syndrome in Internet of Medical Things Platform",
      "abstract": "Presently, Coronary Acute Syndrome (CAS) is a widespread and extreme heart disease which is considered as one of the major concerns for death in the world with long-term disability. For early intervention and care, the prediction of CAS clinical risk is more critical during analysis. A minimum number of manually selected dimensions of risk are used for current CAS risk assessment models and statistical variables are often dichotomized to optimize storage in the Internet of medical things platform(IoMT) on the Encoder layer during data analysis. This research develops a Convolution Denoising Regularized Auto Encoder Stacked Method (CDRAESM) to normalize CAS patient's medical risks from high volumes of patient records and the characteristics have been analyzed during prediction. In this research, a true medical dataset of 3,464 CAS samples is used for experimental analysis and numerical reliability has been analyzed in Area Characteristics Curve (ACC) with an Accuracy range of 96.77%. The results show that the current health risk prediction using CDRAESM achieves competitive concert than conventional models which prevails in practice. Further, the reconstructive learning strategy approach can extract informational risk from the CAS and the risk factors has been identified with existing knowledge of the clinical domain and include theories that might be confirmed by further medical research.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Zhongyu Wang et al.",
      "keywords": "Computer science; Convolution (computer science); Reliability (semiconductor); Noise reduction; Encoder; Medical record; Acute coronary syndrome; Artificial intelligence; Data mining; Machine learning; Medicine; Artificial neural network; Cardiology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2981119",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3012456184",
      "doi": "10.1109/access.2020.2992555",
      "title": "Patient-Centric HetNets Powered by Machine Learning and Big Data Analytics for 6G Networks",
      "abstract": "Having a cognitive and self-optimizing network that proactively adapts not only to channel conditions, but also according to its users needs can be one of the highest forthcoming priorities of future 6G Heterogeneous Networks (HetNets). In this paper, we introduce an interdisciplinary approach linking the concepts of e-healthcare, priority, big data analytics (BDA) and radio resource optimization in a multi-tier 5G network. We employ three machine learning (ML) algorithms, namely, naive Bayesian (NB) classifier, logistic regression (LR), and decision tree (DT), working as an ensemble system to analyze historical medical records of stroke out-patients (OPs) and readings from body-attached internet-of-things (IoT) sensors to predict the likelihood of an imminent stroke. We convert the stroke likelihood into a risk factor functioning as a priority in a mixed integer linear programming (MILP) optimization model. Hence, the task is to optimally allocate physical resource blocks (PRBs) to HetNet users while prioritizing OPs by granting them high gain PRBs according to the severity of their medical state. Thus, empowering the OPs to send their critical data to their healthcare provider with minimized delay. To that end, two optimization approaches are proposed, a weighted sum rate maximization (WSRMax) approach and a proportional fairness (PF) approach. The proposed approaches increased the OPs average signal to interference plus noise (SINR) by 57% and 95%, respectively. The WSRMax approach increased the system total SINR to a level higher than that of the PF approach, nevertheless, the PF approach yielded higher SINRs for the OPs, better fairness and a lower margin of error.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammed S. Hadi et al.",
      "keywords": "Computer science; Big data; Heterogeneous network; Resource allocation; Computer network; Wireless network; Wireless; Data mining",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2020.2992555",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387042388",
      "doi": "10.1109/access.2023.3319502",
      "title": "Enhancing Diagnosis Prediction in Healthcare With Knowledge-Based Recurrent Neural Networks",
      "abstract": "The objective of diagnosis prediction involves foreseeing the potential diseases/conditions according to analyzing patients&#x2019; historical Electronic Health Records (EHRs). The primary challenge in this task is to develop a predictive model that is both sturdy and accurate, while also being interpretable. The most advanced models usually take recurrent neural networks (RNNs) as backbones and then utilize other techniques, such as attention mechanisms, to address this challenge. However, the effectiveness of these models heavily relies on having ample EHR data. Consequently, when the data is insufficient, the performance of these models declines significantly. Recently, graph-based attention models have been proposed to mitigate the issues caused by insufficient data, although they do not fully capitalize on the knowledge present in medical ontologies. To address these problems, <underline>k</underline>nowledge-b<underline>a</underline>sed <underline>r</underline>ecurrent <underline>n</underline>eural networks (named KARNS) are introduced, which is an end-to-end, robust, and accurate deep learning-based architecture designed to predict patients&#x2019; future health information. KARNS explicitly leverages the high-level representations of medical codes within the medical ontologies to enhance the accuracy of predictions. Experimental outcomes demonstrate that the proposed KARNS outperforms existing approaches on three real-world medical datasets. It ensures robustness even with limited training data and learns disease representations that are interpretable.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Hua Shen",
      "keywords": "Computer science; Health care; Artificial neural network; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3319502",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389924870",
      "doi": "10.1109/jbhi.2023.3344187",
      "title": "Intelligent Electrocardiogram Acquisition Via Ubiquitous Photoplethysmography Monitoring",
      "abstract": "Recent advances in machine learning, particularly deep neural network architectures, have shown substantial promise in classifying and predicting cardiac abnormalities from electrocardiogram (ECG) data. Such data are rich in information content, typically in morphology and timing, due to the close correlation between cardiac function and the ECG. However, the ECG is usually not measured ubiquitously in a passive manner from consumer devices, and generally requires 'active' sampling whereby the user prompts a device to take an ECG measurement. Conversely, photoplethysmography (PPG) data are typically measured passively by consumer devices, and therefore available for long-period monitoring and suitable in duration for identifying transient cardiac events. However, classifying or predicting cardiac abnormalities from the PPG is very difficult, because it is a peripherally-measured signal. Hence, the use of the PPG for predictive inference is often limited to deriving physiological parameters (heart rate, breathing rate, etc.) or for obvious abnormalities in cardiac timing, such as atrial fibrillation/flutter (\"palpitations\"). This work aims to combine the best of both worlds: using continuously-monitored, near-ubiquitous PPG to identify periods of sufficient abnormality in the PPG such that prompting the user to take an ECG would be informative of cardiac risk. We propose a dual-convolutional-attention network (DCA-Net) to achieve this ECG-based PPG classification. With DCA-Net, we prove the plausibility of this concept on MIMIC Waveform Database with high performance level (AUROC 0.9 and AUPRC 0.7) and receive satisfactory result when testing the model on an independent dataset (AUROC 0.7 and AUPRC 0.6) which it is not perfectly-matched to the MIMIC dataset.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Zhangdaihong Liu et al.",
      "keywords": "Photoplethysmogram; Computer science; Artificial intelligence; Convolutional neural network; Deep learning; Electrocardiography; Pattern recognition (psychology); Cardiac arrhythmia; Machine learning; Atrial fibrillation; Cardiology; Medicine; Filter (signal processing); Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3344187",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391791444",
      "doi": "10.1109/access.2024.3365544",
      "title": "A Unified Approach Addressing Class Imbalance in Magnetic Resonance Image for Deep Learning Models",
      "abstract": "Medical image datasets, particularly those comprising Magnetic Resonance (MR) images, are essential for accurate diagnosis and treatment planning. However, these datasets often suffer from class imbalance, where certain classes of abnormalities have unequal representation. Models trained on imbalanced datasets can be biased towards the prominent class, leading to misclassification. Addressing class imbalance problems is crucial to developing robust deep-learning MR image analysis models. This research focuses on the class imbalance problem in MR image datasets and proposes a novel approach to enhance deep learning models. We have introduced a unified approach equipped with a selective attention mechanism, unified loss function, and progressive resizing. The selective attention strategy identifies prominent regions within the underlying image to find the feature maps, retaining only the relevant activations of the minority class. Fine-tuning of the multiple hyperparameters was achieved using a novel unified loss function that plays a vital role in enhancing the overwhelming error performance for minority classes and accuracy for common classes. To address the class imbalances phenomenon, we incorporate progressive resizing that can dynamically adjust the input image size as the model trains. This dynamic nature helps handle class imbalances and improve overall performance. The research evaluates the effectiveness of the proposed approach by embedding it into five state-of-the-art CNN models: UNet, FCN, RCNN, SegNet, and Deeplab-V3. For experimental purposes, we have selected five diverse MR image datasets, BUS2017, MICCAI 2015 head and neck, ATLAS, BRATS 2015, and Digital Database Thyroid Image (DDTI), to evaluate the performance of the proposed approach against state-of-the-art techniques. The assessment of the proposed approach reveals improved performance across all metrics for five different MR imaging datasets. DeepLab-V3 demonstrated the best performance, achieving IoU, DSC, Precision, and Recall scores of 0.893, 0.953, 0.943, and 0.944, respectively, on the BUS dataset. These scores indicate an improvement of 5&#x0025; in DSC, 6&#x0025; in IoU, 4&#x0025; in precision, and approximately 4&#x0025; in recall compared to the baseline. The most significant increases were observed in the ATLAS and LiTS MICCAI 2017 datasets, with a 5&#x0025; and 7&#x0025; increase in IoU and DSC over the baseline (DSC &#x003D; 0.628, DSC &#x003D; 0.695) for the ATLAS dataset and a 5&#x0025; and 9&#x0025; increase in IoU and DSC for the LiTS MICCAI 2017 dataset.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Lijuan Cui et al.",
      "keywords": "Computer science; Class (philosophy); Artificial intelligence; Magnetic resonance imaging; Image (mathematics); Deep learning; Computer vision; Radiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3365544",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387587686",
      "doi": "10.1109/access.2023.3324046",
      "title": "Companion Animal Disease Diagnostics Based on Literal-Aware Medical Knowledge Graph Representation Learning",
      "abstract": "Knowledge graph (KG) embedding has been used to benefit the diagnosis of animal diseases by analyzing electronic medical records (EMRs), such as notes and veterinary records. However, learning representations to capture entities and relations with literal information in KGs is challenging as the KGs show heterogeneous properties and various types of literal information. Meanwhile, the existing methods mostly aim to preserve graph structures surrounding target nodes without considering different types of literals, which could also carry significant information. In this paper, we propose a knowledge graph embedding model for the efficient diagnosis of animal diseases, which could learn various types of literal information and graph structure and fuse them into unified representations, namely LiteralKG. Specifically, we construct a knowledge graph that is built from EMRs along with literal information collected from various animal hospitals. We then fuse different types of entities and node feature information into unified vector representations through gate networks. Finally, we propose a self-supervised learning task to learn graph structure in pretext tasks and then towards various downstream tasks. Experimental results on link prediction tasks demonstrate that our model outperforms the baselines that consist of state-of-the-art models.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Van Thuy Hoang et al.",
      "keywords": "Computer science; Literal (mathematical logic); Graph; Artificial intelligence; Embedding; Theoretical computer science; Natural language processing; Machine learning; Information retrieval",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3324046",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390734058",
      "doi": "10.1109/access.2024.3351688",
      "title": "Optimizing Patient Recruitment for Clinical Trials: A Hybrid Classification Model and Game-Theoretic Approach for Strategic Interaction",
      "abstract": "This research is imperative due to the pressing need for improved patient recruitment in clinical trials, addressing challenges such as delays and high costs. By introducing a classification model and a game theoretic approach for clinical trial setting, we aim to boost trial efficiency, advance healthcare research, and enhance patient outcomes. This research is critical for revolutionizing recruitment strategies and accelerating medical progress. In this paper, we present a classification model that has been specifically designed to address this issue effectively. The proposed model employs an Autoencoder, augmented by a super classification model that merges Logistic Regression, Support Vector Machines, Random Forest Trees, and Decision Trees using a stacking classifier. The output of the super classifier is further processed by a meta classifier to obtain the final result. Notably, the model achieves a training accuracy of 99.576&#x0025; and a validation accuracy of 83.45&#x0025;, illustrating its robust classification performance and its potential to streamline patient recruitment, reducing delays and resource consumption. In addition to the classification model, this study formulates a three-layer game theoretic model involving Patients, Doctors or Clinical Investigators, and Research Firms. Within this static repeated game setting, players sequentially strategize to optimize their recruitment strategies, while research firms aim to optimize their overall interaction. The paper proposes a novel optimal solution that strikingly balances the payoffs of all three players. Moreover, the work presents a necessary condition and closed form for the existence of an equilibrium in the game, offering a strategic approach to recruitment optimization, and striking a balance between stakeholders. This equilibrium-seeking solution has the potential to revolutionize recruitment dynamics and foster collaboration. Additionally, the study&#x2019;s theoretical contributions lay the groundwork for future research in this critical healthcare domain.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "C. U. Om Kumar et al.",
      "keywords": "Computer science; Classifier (UML); Artificial intelligence; Machine learning; Autoencoder; Support vector machine; Decision tree; Clinical trial; Deep learning; Bioinformatics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3351688",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377966868",
      "doi": "10.1109/access.2023.3279732",
      "title": "A Data Analytics Methodology to Visually Analyze the Impact of Bias and Rebalancing",
      "abstract": "Data Analytics have become a key component of many business processes which influence several aspects of our daily life. Indeed, any misinterpretation or flaw in the outputs of Data Analytics results can cause significant damage, specialy when dealing with one of the most often overlooked issues, namely the unaware use of biased data. When data bias goes unadverted, it warps the meaning of data, having a devastating effect on Data Analytics results. Although it is widely argued that the most common manner to deal with data bias is to rebalance biased datasets, it is not an aseptic transformation, leading to several potentially undesired side-effects that will probably harm the result of data analyses. Therefore, in order to analyze the underlying bias in datasets, in this work we present (i) a comprehensive methodology based on visualization techniques, which assists users in the definition of their analytical requirements to detect and visually represent the data bias automatically helping them to find out whether it is appropriate to artificially rebalance their dataset or not; (ii) a novel metamodel for visually representing bias; (iii) a motivating real-world running example used to analyze the impact of bias in Data Analytics and (iv) an assessment of the improvements introduced by our proposal through a complete real-world case study by using a Fire Department Calls for Service dataset, thus demonstrating that rebalancing datasets is not always the best option. It is crucial to study the context where the decisions are going to be taken. Moreover, it is also important to do a pre-analysis with the aim of knowing the nature of the datasets and how biased they are.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ana Lavalle et al.",
      "keywords": "Computer science; Data science; Analytics; Context (archaeology); Visualization; Data visualization; Data analysis; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3279732",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4367728209",
      "doi": "10.1109/access.2023.3272373",
      "title": "A Deep Neural Network Based Wake-After-Sleep-Onset Time Aware Sleep Apnea Severity Estimation Scheme Using Single-Lead ECG Data",
      "abstract": "Obstructive sleep apnea (OSA) is a prevalent yet potentially severe sleep disorder. Polysomnography (PSG) is most commonly used to assess the severity of OSA. However, there have been numerous studies to find OSA patients more effectively since running a PSG test is expensive and time-consuming. The existing studies, however, raise four major concerns, such as (i) the use of inaccurate sleep time data to calculate the apnea-hypopnea index, (ii) the use of poor preprocessing techniques for real patient clinical datasets, (iii) the lack of multi-stage classification capability, and (iv) the absence of experiments on sufficiently large data sets. To address these concerns, we propose a novel OSA severity classification scheme based on single-lead electrocardiogram (ECG) data, as well as a novel deep learning model, CLNet, to perform apnea/hypopnea and sleep stage classification. By identifying apnea/hypopnea events from a patient&#x2019;s ECG data and computing AHI using &#x201C;pure&#x201D; sleep duration via CLNet, our method improves patient OSA severity degree estimation. CLNet was trained and evaluated using two different real-world datasets containing 286 OSA patient records and a total of 2,155 hours of ECG data. In our experiments, the proposed scheme outperforms existing approaches by up to 10&#x0025; in total accuracy and AUC on the public PhysioNet dataset. In terms of apnea classification sensitivity, we show that the proposed CLNet model outperforms the state-of-the-art model by up to 41.8&#x0025; for our clinical dataset. Our scheme can be used as a successful, high-quality pre-screening tool by more effectively prioritizing prospective OSA patients. We will be able to perform PSG on only the most severe patients, saving both time and money. Our algorithms are publicly available on GitHub.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Dae-Woong Seo et al.",
      "keywords": "Polysomnography; Artificial intelligence; Computer science; Obstructive sleep apnea; Sleep apnea; Apnea; Preprocessor; Deep learning; Machine learning; Artificial neural network; Data pre-processing; Hypopnea; Apnea\u2013hypopnea index; Medicine; Data mining; Cardiology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3272373",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391855245",
      "doi": "10.1109/access.2024.3366068",
      "title": "A Personalized Contactless Emergency Aid System Designed for Individuals With Profound Physical Disabilities",
      "abstract": "This study proposes the development of a contactless emergency assistance system designed for individuals with severe physical disabilities (tetraplegia and no voice but normal mouth movements) to address the limitations of traditional emergency bells in sudden emergencies. The core technology of the system includes artificial intelligence facial recognition and fuzzy motion algorithms to identify facial movements. After the auxiliary signal is triggered, the system uses Message Queuing Telemetry Transport (MQTT) technology to activate warning lights and speakers. The signal is then transmitted to the LINE application on a computer or smartphone platform via Wi-Fi, notifying caregivers to provide timely assistance. Experimental results show that the system has a user-friendly interface and an accuracy rate of about 96.69&#x0025;. This study is the successful development of an emergency assistance system controllable by quadriplegic patients. The one-to-many alarm device can establish a safe net, effectively help individuals with severe physical disabilities proactively seek help, reduce the risk of accidents, and alleviate caregiver shortages. For quadriplegics, this technology offers a unique alternative with significant advantages over commercially available manually operated or voice command call bells.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Chung-Min Wu et al.",
      "keywords": "Computer science; MQTT; ALARM; Interface (matter); Unavailability; Human\u2013computer interaction; Assistive technology; Computer security; Real-time computing; Internet of Things; Operating system; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3366068",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3089236942",
      "doi": "10.1109/access.2020.3025828",
      "title": "MuscNet, a Weighted Voting Model of Multi-Source Connectivity Networks to Predict Mild Cognitive Impairment Using Resting-State Functional MRI",
      "abstract": "The neurological disorder mild cognitive impairment (MCI) demonstrates minor impacts on the patient's daily activities and may be ignored as the status of normal aging. But some of the MCI patients may further develop into severe statuses like Alzheimer's disease (AD). The brain functional connectivity network (BFCN) was usually constructed from the resting-state functional magnetic resonance imaging (rs-fMRI) data. This technology has been widely used to detect the neurodegenerative dementia and to reveal the intrinsic mechanism of neural activities. The BFCN edge was usually determined by the pairwise correlation between the brain regions. This study proposed a weighted voting model of multi-source connectivity networks (MuscNet) by integrating multiple BFCNs of different correlation coefficients. Our model was further improved by removing redundant features. The experimental data demonstrated that different BFCNs contributed complementary information to each other and MuscNet outperformed the existing models on detecting MCI patients. The previous study suggested the existence of multiple solutions with similarly good performance for a machine learning problem. The proposed model MuscNet utilized a weighted voting strategy to slightly outperform the existing studies, suggesting an effective way to fuse multiple base models. The reason may need further theoretical investigations about why different base models contribute to each other for the MCI prediction.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jialiang Li et al.",
      "keywords": "Pairwise comparison; Cognitive impairment; Artificial intelligence; Correlation; Computer science; Functional magnetic resonance imaging; Pattern recognition (psychology); Voting; Dementia; Resting state fMRI; Functional connectivity; Machine learning; Majority rule; Cognition; Neuroscience; Psychology; Disease; Mathematics; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3025828",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4290716567",
      "doi": "10.1109/access.2022.3197167",
      "title": "Automated Question-Answering for Interactive Decision Support in Operations &amp; Maintenance of Wind Turbines",
      "abstract": "Intelligent question-answering (QA) systems have witnessed increased interest in recent years, particularly in their ability to facilitate information access, data interpretation or decision support. The wind energy sector is one of the most promising sources of renewable energy, yet turbines regularly suffer from failures and operational inconsistencies, leading to downtimes and significant maintenance costs. Addressing these issues requires rapid interpretation of complex and dynamic data patterns under time-critical conditions. In this article, we present a novel approach that leverages interactive, natural language-based decision support for operations &amp;#x0026; maintenance (O&amp;#x0026;M) of wind turbines. The proposed interactive QA system allows engineers to pose domain-specific questions in natural language, and provides answers (in natural language) based on the automated retrieval of information on turbine sub-components, their properties and interactions, from a bespoke domain-specific knowledge graph. As data for specific faults is often sparse, we propose the use of paraphrase generation as a way to augment the existing dataset. Our QA system leverages encoder-decoder models to generate Cypher queries to obtain domain-specific facts from the KG database in response to user-posed natural language questions. Experiments with an attention-based sequence-to-sequence (Seq2Seq) model and a transformer show that the transformer accurately predicts up to 89.75&amp;#x0025; of responses to input questions, outperforming the Seq2Seq model marginally by 0.76&amp;#x0025;, though being 9.46 times more computationally efficient. The proposed QA system can help support engineers and technicians during O&amp;#x0026;M to reduce turbine downtime and operational costs, thus improving the reliability of wind energy as a source of renewable energy.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Joyjit Chatterjee et al.",
      "keywords": "Computer science; Downtime; Question answering; Wind power; Natural language; Transformer; Decision support system; Turbine; Machine learning; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3197167",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312780987",
      "doi": "10.1109/access.2022.3226503",
      "title": "CardioID: Secure ECG-BCG Agnostic Interaction-Free Device Pairing",
      "abstract": "Usably secure ad-hoc device pairing fosters connectivity with hardware which is difficult to access (e.g., implanted) and grants convenience for ad-hoc short-term on-off pairing patterns (e.g. shared public domain). Examples are medical devices or fitness equipment. We present CardioID, an approach to extract features from heart rate variability for secure pairing keys that change with the randomness inherited in heart operation. Our processing chain is compatible with electrocardiogram (ECG, voltage), as well as ballistocardiogram (BCG, acceleration) type signals. Dissimilarities in locally generated sequences are accounted for using fuzzy cryptography exploiting Bose&#x2013;Chaudhuri&#x2013;Hocquenghem (BCH) codes. We propose a quantization to derive secure keys for cross BCG-ECG device pairing from heart-rate variability and analyze the performance in (inter- and intra-subject) BCG-to-ECG pairing. A secure communication protocol for Body Area Networks (BAN) is discussed. The attack surface of the protocol is analyzed, and we conduct a video-based attack study. In addition, two case studies with 5 (laboratory) and 20 (controlled in-field) subjects were conducted.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Si Zuo et al.",
      "keywords": "Pairing; Computer science; Randomness; Cryptography; Quantization (signal processing); Computer network; Theoretical computer science; Computer security; Algorithm; Mathematics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3226503",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394896991",
      "doi": "10.1109/access.2024.3390391",
      "title": "Ultra-Wideband Radar-Based Sleep Stage Classification in Smartphone Using an End-to-End Deep Learning",
      "abstract": "As an increasing number of people suffer from sleep disorders, such as insomnia or sleep apnea, sleep monitoring and management using consumer devices have gained increasing attention from research communities. As sleep quality is closely related to sleep structure based on hypnograms, the classification of sleep stages over the course of the night is important for accurate sleep monitoring. We present sleep stage classification using a smartphone equipped with ultra-wideband (UWB) radar. We focused on the development of easily accessible sleep monitoring system for the general population by placing the smartphone on a table near a bed, which is commonly used during sleep. We collected 509 nights of UWB radar and nocturnal in-laboratory polysomnography (PSG) data from various participants, including patients with apnea, using a customized Samsung Galaxy smartphone with a UWB radar chip placed on a table near the bed. A combination of 1D convolutional neural network and transformer architecture was proposed in this study, and a domain adaptation technique was applied to train the model with both large-scale respiratory signals from open database PSGs and UWB radar data to boost the performance by overcoming the lack of UWB radar data. With 5-fold validation, an epoch-by-epoch comparison between the predicted and expert-annotated four sleep stages (Wake, REM sleep, light sleep, and deep sleep) resulted in 0.76 of accuracy and 0.64 of Cohen&#x2019;s kappa. This study demonstrated that sleep stages can be monitored with substantial accuracy by simply placing a smartphone on a bedtable, making it highly usable and reliable in real use cases.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Jonghyun Park et al.",
      "keywords": "Polysomnography; Computer science; Deep learning; Sleep (system call); Radar; Artificial intelligence; Convolutional neural network; Sleep Stages; Medicine; Telecommunications; Apnea",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3390391",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2963642034",
      "doi": "10.1109/access.2019.2891948",
      "title": "Landscape of Big Medical Data: A Pragmatic Survey on Prioritized Tasks",
      "abstract": "Big medical data pose great challenges to life scientists, clinicians, computer scientists, and engineers. In this paper, a group of life scientists, clinicians, computer scientists, and engineers sit together to discuss several fundamental issues. First, what are the unique characteristics of big medical data different from those of the other domains? Second, what are the prioritized tasks in clinician research and practices utilizing big medical data? And do we have enough publicly available data sets for performing those tasks? Third, do the state-of-the-practice and state-of-the-art algorithms perform good jobs? Fourth, are there any benchmarks for measuring algorithms and systems for big medical data? Fifth, what are the performance gaps of the state-of-the-practice and state-of-the-art systems handling big medical data currently or in the future? Finally, but not least, are we, life scientists, clinicians, computer scientists, and engineers, ready for working together? We believe that answering the above-mentioned issues will help define and shape the landscape of big medical data.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Zhifei Zhang et al.",
      "keywords": "Big data; Computer science; Data science; State (computer science); Medical practice; Data mining; Medical education; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2891948",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390204376",
      "doi": "10.1109/access.2023.3346689",
      "title": "Detection of Obstructive Sleep Apnoea Using Features Extracted From Segmented Time-Series ECG Signals With a One Dimensional Convolutional Neural Network",
      "abstract": "This paper reports on ongoing research, which aims to prove that features of Obstructed Sleep Apnoea (OSA) can be automatically identified from single-lead electrocardiogram (ECG) signals using a One-Dimensional Convolutional Neural Network (1DCNN) model. The 1DCNN is also compared against other machine learning (ML) classifier models, namely Support Vector Machine (SVM) and Random Forest Classifier (RFC). The 1DCNN architecture consists of 4 major parts, a Convolutional Layer, a Flattened Dense Layer, a Max Pooling Layer and a Fully Connected Multilayer Perceptron (MLP), with 1 Hidden Layer and a SoftMax output. The model repeatedly learns how to better extract prominent features from one-dimensional data and map it to the MLP for increased prediction. Training and validation are achieved using pre-processed time-series ECG signals captured from 35 ECG recordings. Using our unique windowing strategy, the data is shaped into 5 datasets of different window sizes. A total of 15 models (5 for each group, 1DCNNs, RFCs, SVMs) were evaluated using various metrics, with each being run over numerous experiments. Results show the 1DCNN-500 model delivered the greatest degree of accuracy and rapidity in comparison to the best producing RFC and SVM classifiers. 1DCNN-500 (Sensitivity 0.9743, Specificity 0.9708, Accuracy 0.9699); RFC-500 (Sensitivity/Recall (0) 0.90 / (1) 0.94, Precision (0) 0.94 / (1) 0.90, Accuracy 0.91); SVM-500 (Sensitivity (0) 0.94 / (1) 0.50, Precision (0) 0.65 / (1) 0.90, Accuracy 0.72). The model presents a novel approach that could provide support mechanisms in clinical practice to promptly diagnose patients suffering from OSA.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Steven Thompson et al.",
      "keywords": "Softmax function; Support vector machine; Computer science; Artificial intelligence; Pattern recognition (psychology); Convolutional neural network; Multilayer perceptron; Random forest; Classifier (UML); Sensitivity (control systems); Precision and recall; Pooling; F1 score; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3346689",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392406089",
      "doi": "10.1109/access.2024.3373470",
      "title": "Feature-Based Text Search Engine Mitigating Data Diversity Problem Using Pre-Trained Large Language Model for Fast Deployment Services",
      "abstract": "The fairness &#x0026; bias of narrow coverage of AI becomes another challenge for AI researchers. If a commercial AI trains with a biased dataset, there will be severe gender or racial fairness and bias issues. Since the researchers use primary language datasets to train AI, the broad audience cannot be satisfied if a novel LLM (Large Language Model) AI shows a knowledge or creativity limitation on their specific spoken language. Narrow coverage of the LLMs can lead the audience to misinterpretation and confusion if the service involves STT (Speech-To-Text). In this paper, to overcome this issue of data diversity, we propose the idea that the embedded, extracted features have captured semantic proximity information that can be useful to mitigate diversity issues. This project focused on the Korean language food dataset for STT services, where a narrow-trained A.I. is prone to show its limitations, such as lifestyle-related elements. To present our proof of concept, we trained a baseline model, GPT2, with the Korean Wikipedia dataset in 2022. Then, we employed DistilBERT and KoBERT for comparison. The extracted hidden&#x005F;state&#x005F;output features from each model were utilized to build feature-extraction-based text search engines. We used the same idea of Local Sensitive Hashing (LSH) but effectively located a similar hash by applying transposed weights. We also present conventional classification benchmarks for performance comparison using top-k measurements, times for training and memory &#x0026; disc consumptions. In the discussion, we proposed that our idea can mitigate the diversity problem without re-training the model and tokenizer.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Y. Jeong et al.",
      "keywords": "Software deployment; Computer science; Feature (linguistics); Diversity (politics); Search engine; Information retrieval; World Wide Web; Artificial intelligence; Database; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3373470",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387831820",
      "doi": "10.1109/access.2023.3326342",
      "title": "PCSS: Skull Stripping With Posture Correction From 3D Brain MRI for Diverse Imaging Environment",
      "abstract": "A subject&#x2019;s head position in magnetic resonance imaging (MRI) scanners can vary significantly with the imaging environment and disease status. This variation is known to influence the accuracy of skull stripping (SS), a method to extract the brain region from the whole head image, which is an essential initial step to attain high performance in various neuroimaging applications. However, existing SS methods have failed to accommodate this wide range of variation. To achieve accurate, consistent, and fast SS, we introduce a novel two-stage methodology that we call posture correction skull stripping (PCSS): the first involves adjusting the subject&#x2019;s head angle and position, and the second involves the actual SS to generate the brain mask. PCSS also incorporates various machine learning techniques, such as a weighted loss function, adversarial training from generative adversarial networks, and ensemble methods. Thorough evaluations conducted on five publicly accessible datasets show that the PCSS method outperforms current state-of-the-art techniques in SS performance, achieving an average increase of 1.38 points on the Dice score and demonstrating the contributions of each PCSS component technique.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Kei Nishimaki et al.",
      "keywords": "Skull; Neuroimaging; Stripping (fiber); Computer science; Neuroscience; Medicine; Anatomy; Materials science; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326342",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313033643",
      "doi": "10.1109/access.2022.3221089",
      "title": "MMMF: Multimodal Multitask Matrix Factorization for Classification and Feature Selection",
      "abstract": "Integration of multiple biological datasets is crucial to understand comprehensive biological mechanisms with the aid of a rapid development of biomedical technology. However, the predictive modeling for such an integrated dataset faces two major challenges, namely, heterogeneity and imbalance in the acquired data. Thus, in this study, we present a method for the integration of multiple biological datasets called multimodal multitask matrix factorization (MMMF) to address these issues. The MMMF uses matrix factorization (MF) to integrate data from multiple heterogeneous biological datasets, and oversampling is applied to resolve the imbalanced data during the training step. Moreover, gradient surgery is used for multitask (MF and classification) learning to increase the quantity of classification information by projecting the gradients of the MF that conflict with the classification gradient onto the normal plane of a classification gradient. We demonstrate that MMMF outperforms other state-of-the-art biomedical classification models in binary and multi-class classification problems using five biological datasets. We also show that MMMF can be used as a feature selection approach for finding biomarkers that help in classification. The source code of the MMMF is available at <uri>https://github.com/DMCB-GIST/MMMF</uri>.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Jeongyoung Hwang et al.",
      "keywords": "Computer science; Artificial intelligence; Feature selection; Binary classification; Selection (genetic algorithm); Machine learning; Matrix decomposition; Feature (linguistics); Non-negative matrix factorization; Pattern recognition (psychology); Data mining; Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3221089",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389474223",
      "doi": "10.1109/tcss.2023.3330254",
      "title": "Aerospace Technology in Social Applications",
      "abstract": "Welcome to the concluding issue of IEEE Transactions on Computational Social Systems (TCSS) for the year 2023. We would like to seize this opportunity to extend our heartfelt appreciation and congratulations to all for your exceptional dedication and unwavering support. We eagerly anticipate further collaboration to enhance the publication quality and expedite the review process of TCSS in the upcoming year 2024.",
      "year": "2023",
      "journal": "IEEE Transactions on Computational Social Systems",
      "authors": "Yirong Wu et al.",
      "keywords": "Aerospace; Engineering management; Process (computing); Aeronautics; Quality (philosophy); Computer science; Engineering; Data science; Business; Aerospace engineering; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcss.2023.3330254",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391547784",
      "doi": "10.1109/access.2024.3362647",
      "title": "Cancer Subtype Identification Through Integrating Inter and Intra Dataset Relationships in Multi-Omics Data",
      "abstract": "Contains fulltext : 304285.pdf (Publisher\u2019s version ) (Open Access)",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mark Peelen et al.",
      "keywords": "Identification (biology); Computer science; Cancer; Omics; Data integration; Computational biology; Data mining; Bioinformatics; Biology; Genetics; Ecology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3362647",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389776444",
      "doi": "10.1109/access.2023.3343451",
      "title": "Full-Resolution Lung Nodule Localization From Chest X-Ray Images Using Residual Encoder-Decoder Networks",
      "abstract": "Lung cancer is the leading cause of cancer death, and early diagnosis is associated with a positive prognosis. Chest X-ray (CXR) provides an inexpensive imaging mode for lung cancer diagnosis. Computer vision algorithms have previously been proposed to assist human radiologists in this task; however, leading studies use down-sampled images and computationally expensive methods with unproven generalization. In contrast, this study localizes lung nodules from CXR images using efficient encoder-decoder neural networks that have been crafted to process full resolution input images, thereby avoiding signal loss resulting from down-sampling. Encoder-decoder networks are trained and tested using the Japanese Society of Radiological Technology dataset. The networks are used to localize lung nodules from an independent CXR dataset. These experiments allow for the determination of the optimal network depth, image resolution, and pre-processing pipeline for generalized lung nodule localization. We find that more subtle nodules are detected in earlier training epochs. Therefore, we propose a novel self-ensemble model from three consecutive epochs centered on the validation optimum. This ensemble achieved a sensitivity of 85&#x0025; in 10-fold internal testing with false positives of 8 per image. A sensitivity of 81&#x0025; is achieved at a false positive rate of 6 following morphological false positive reduction. This result is comparable to more computationally complex systems, but with a sub-second inference time that is faster than other methods presented in the literature. The proposed algorithm achieved excellent generalization results against a challenging external dataset with a sensitivity of 77&#x0025; at a false positive rate of 7.6.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Michael J. Horry et al.",
      "keywords": "Computer science; Residual; Encoder; Decoding methods; Nodule (geology); Resolution (logic); Lung; Artificial intelligence; Radiology; Algorithm; Medicine; Internal medicine; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3343451",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390423611",
      "doi": "10.1109/access.2023.3348244",
      "title": "Bridging Interpretability and Performance: Enhanced Machine Learning-Based Prediction of Hematoma Expansion Post-Stroke via Comprehensive Feature Selection",
      "abstract": "Monitoring and controlling the occurrence of hematoma expansion events after a stroke is a primary clinical focus. The introduction of machine learning (ML) techniques offers intelligent decision support for physicians in this domain. However, for doctors without an ML background, the behavior of a hematoma expansion predictor seems opaque, similar to a &#x201C;black box.&#x201D; Moreover, the vast and diverse set of features typically present in medical data acts as a double-edged sword: while encapsulating rich information with potential value, it also includes redundant details that offer little to predictive utility. Comprehensive feature selection is crucial, but many current state-of-the-art hematoma expansion prediction studies based on ML often overlook this step. In this paper, we propose a methodology tailored for comprehensive feature selection across diverse and abundant medical data features and rigorously evaluate ML models. Through experiments on a real-world post-stroke hematoma expansion prediction dataset, we demonstrate the efficacy of our approach in enhancing the performance of ML predictors. Visualization of the associated feature selection process and results further bolsters physicians&#x2019; understanding of the model&#x2019;s decision-making basis, thereby strengthening its interpretability.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Beigeng Zhao et al.",
      "keywords": "Interpretability; Feature selection; Computer science; Artificial intelligence; Bridging (networking); Machine learning; Selection (genetic algorithm); Feature (linguistics); Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3348244",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385338566",
      "doi": "10.1109/access.2023.3299877",
      "title": "Attention-Based Multimodal Deep Learning on Vision-Language Data: Models, Datasets, Tasks, Evaluation Metrics and Applications",
      "abstract": "Multimodal learning has gained immense popularity due to the explosive growth in the volume of image and textual data in various domains. Vision-language heterogeneous multimodal data has been utilized to solve a variety of tasks including classification, image segmentation, image captioning, question-answering, etc. Consequently, several attention mechanism-based approaches with deep learning have been proposed on image-text multimodal data. In this paper, we highlight the current status of attention-based deep learning approaches on vision-language multimodal data by presenting a detailed description of the existing models, their performances and the variety of evaluation metrics used therein. We revisited the various attention mechanisms on image-text multimodal data since its inception in 2015 till 2022 and considered a total of 75 articles for the survey. Our comprehensive discussion also encompasses the current tasks, datasets, application areas and future directions in this domain. This is the very first attempt to discuss the vast scope of attention-based deep learning mechanisms on image-text multimodal data.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Priyankar Bose et al.",
      "keywords": "Computer science; Closed captioning; Artificial intelligence; Variety (cybernetics); Deep learning; Multimodal learning; Machine learning; Scope (computer science); Contextual image classification; Popularity; Image (mathematics); Natural language processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3299877",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4382654244",
      "doi": "10.1109/tmi.2023.3278528",
      "title": "Guest Editorial Special Issue on Federated Learning for Medical Imaging: Enabling Collaborative Development of Robust AI Models",
      "abstract": "Federated Learning (FL) could solve the challenges of training AI models on large datasets for medical imaging due to data privacy and ownership concerns by allowing collaborative training without the need for sharing raw data. This Special Issue on Federated Learning for Medical Imaging features papers covering FL-related topics and discussing their implications for healthcare and medical imaging. The included articles focus on a broad range of federated scenarios and applications, such as semi-supervised and self-supervised learning, histopathology, image reconstruction, graph neural networks, privacy preservation, active learning, data auditing, multi-task learning, personalization, and swarm learning. The importance of training unbiased, privacy-preserving, and generalizable AI models that have the potential to be translated into clinical practice increases the need for collaborative training techniques such as FL. The articles included in this Special Issue have moved the needle markedly forward in this regard.",
      "year": "2023",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Holger R. Roth et al.",
      "keywords": "Computer science; Artificial intelligence; Personalization; Medical imaging; Audit; Deep learning; Data sharing; Task (project management); Machine learning; Data science; World Wide Web; Medicine",
      "mesh_terms": "",
      "pub_types": "editorial",
      "url": "https://doi.org/10.1109/tmi.2023.3278528",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392309215",
      "doi": "10.1109/access.2024.3371510",
      "title": "Separation of the Aortic and Pulmonary Components of the Second Heart Sound via Alternating Optimization",
      "abstract": "An algorithm for blind source separation (BSS) of the second heart sound (S2) into aortic and pulmonary components is proposed. It recovers aortic (A2) and pulmonary (P2) waveforms, as well as their relative delays, by solving an alternating optimization problem on the set of S2 sounds, without the use of auxiliary ECG or respiration phase measurement data. This unsupervised and data-driven approach assumes that the A2 and P2 components maintain the same waveform across heartbeats and that the relative delay between onset of the components varies according to respiration phase. The proposed approach is applied to synthetic heart sounds and to real-world heart sounds from 43 patients. It improves over two state-of-the-art BSS approaches by 10&#x0025; normalized root mean-squared error in the reconstruction of aortic and pulmonary components using synthetic heart sounds, demonstrates robustness to noise, and recovery of splitting delays. The detection of pulmonary hypertension (PH) in a Brazilian population is demonstrated by training a classifier on three scalar features from the recovered A2 and P2 waveforms, and this yields an auROC of 0.76.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Francesco Renna et al.",
      "keywords": "Waveform; Computer science; Heart sounds; Bioacoustics; Speech recognition; Pattern recognition (psychology); Mathematics; Cardiology; Medicine; Artificial intelligence; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3371510",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3021989992",
      "doi": "10.1109/access.2020.2992130",
      "title": "Investigating of Disease Name Normalization Using Neural Network and Pre-Training",
      "abstract": "Normalizing disease names is a crucial task for biomedical and healthcare domains. Previous work explored various approaches, including rules, machine learning and deep learning, which focused on only one approach or one model. In this study, we systematically investigated the performances of various neural models and the effects of different features. Our investigation was performed on two benchmark datasets, namely the NCBI disease corpus and the BioCreative V Chemical Disease Relation (BC5CDR) corpus. The convolutional neural network (CNN) performed the best (F1 90.11%) in the NCBI disease corpus and the attention neural network (Attention) performed the best (F1 90.78%) in the BC5CDR corpus. Compared with the state-of-the-art system, DNorm, our models improved the F1s by 1.74% and 0.86% respectively. In terms of features, character information could improve the F1 by about 0.5-1.0% while sentence information worsened the F1 by about 3-4%. Moreover, we proposed a novel approach for pre-training models, which improved the F1 by up to 9%. The CNN and Attention models are comparable in the task of disease name normalization while the recurrent neural network performs much worse. In addition, character information and pre-training techniques are helpful for this task while sentence information hurts the performance. Our proposed models and pre-training approach can be easily adapted to the normalization task for any other type of entities. Our source code is available at: https://github.com/yx100/EntityNorm.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Yinxia Lou et al.",
      "keywords": "Computer science; Normalization (sociology); Artificial neural network; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2992130",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392796614",
      "doi": "10.1109/tla.2024.10472960",
      "title": "Biomedical engineering research in Chilean universities - A bibliometric analysis",
      "abstract": "Biomedical engineering (BME) combines engineering, biology, and medicine to develop innovative healthcare solutions. There is an increasing demand for BME professionals following technological and scientific advances. In Chile, only three universities offer undergraduate BME programs: Universidad de Valparaiso, Universidad de Concepcion, and Universidad de Santiago de Chile. Each institution has defined its curriculum, professional profile, and research focus based on its perspective of the country's needs. However, the scope of their research contribution has not been studied. In this work, we perform a comprehensive bibliometric analysis using data from the SCOPUS database to evaluate publications by researchers affiliated with Chilean undergraduate BME programs from 2000 to 2022. The objective is to identify the research areas of BME in Chile, understand the similarities and differences between universities, analyse their research areas, explore collaboration relationships, and characterise the discipline's evolution. The main contributions of this work are (1) a quantitative and qualitative analysis of BME research in Chile, (2) the identification of BME research areas and their development over time, (3) the creation of a dashboard-style web tool, and (4) proposing a robust methodology for bibliometric analysis applicable to BME literature in Chile and similar contexts. This work represents the first collaboration involving authors from all universities with undergraduate Chilean BME programs.",
      "year": "2024",
      "journal": "IEEE Latin America Transactions",
      "authors": "Javiera V\u00e1squez-Salgado et al.",
      "keywords": "Bibliometrics; Data science; Computer science; Engineering; Library science; Engineering management; Engineering ethics; Regional science; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tla.2024.10472960",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389611468",
      "doi": "10.1109/tcss.2023.3342488",
      "title": "2023 Index IEEE Transactions on Computational Social Systems Vol. 10",
      "abstract": "",
      "year": "2023",
      "journal": "IEEE Transactions on Computational Social Systems",
      "authors": "Q Abbasi et al.",
      "keywords": "Index (typography); Computer science; Computer security; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcss.2023.3342488",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3008494873",
      "doi": "10.1109/tcyb.2021.3053599",
      "title": "Uncertainty-Aware Variational-Recurrent Imputation Network for Clinical Time Series",
      "abstract": "Electronic health records (EHR) consist of longitudinal clinical observations portrayed with sparsity, irregularity, and high-dimensionality, which become major obstacles in drawing reliable downstream clinical outcomes. Although there exist great numbers of imputation methods to tackle these issues, most of them ignore correlated features, temporal dynamics and entirely set aside the uncertainty. Since the missing value estimates involve the risk of being inaccurate, it is appropriate for the method to handle the less certain information differently than the reliable data. In that regard, we can use the uncertainties in estimating the missing values as the fidelity score to be further utilized to alleviate the risk of biased missing value estimates. In this work, we propose a novel variational-recurrent imputation network, which unifies an imputation and a prediction network by taking into account the correlated features, temporal dynamics, as well as the uncertainty. Specifically, we leverage the deep generative model in the imputation, which is based on the distribution among variables, and a recurrent imputation network to exploit the temporal relations, in conjunction with utilization of the uncertainty. We validated the effectiveness of our proposed model on two publicly available real-world EHR datasets: PhysioNet Challenge 2012 and MIMIC-III, and compared the results with other competing state-of-the-art methods in the literature.",
      "year": "2021",
      "journal": "IEEE Transactions on Cybernetics",
      "authors": "Ahmad Wisnu Mulyadi et al.",
      "keywords": "Imputation (statistics); Missing data; Leverage (statistics); Computer science; Data mining; Exploit; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tcyb.2021.3053599",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387350689",
      "doi": "10.1109/access.2023.3321831",
      "title": "A Deep Learning-Based National Digital Literacy Assessment Framework Utilizing Mobile Big Data and Survey Data",
      "abstract": "With the rapid advancement of digital technology, artificial intelligence has ushered in a digital society. In this era, digital literacy has become a prerequisite for individuals, as its absence can lead to new vulnerabilities and inequalities, hindering the pursuit of sustainable development goals. Previous researches predominantly relied on questionnaires to assess digital literacy, often focusing on specific groups due to survey costs, making their methodology unsuitable for comprehensive countrywide measurement. To address these limitations, we propose FLAKE, a national digital literacy assessment framework. Within this framework, we devise a multi-task deep learning model called DLMaN, which employs mobile big data, such as users&#x2019; digital behaviors, to predict citizens&#x2019; digital literacy. FLAKE enables cost-effective assessment of digital literacy for massive citizens by surveying only a fraction of them and it also has valuable implications for other social research tasks. We test the framework&#x2019;s performance using authentic survey data and mobile big data, achieving RMSE and MAPE of 5.233 and 8.65&#x0025; respectively, and the improvement is significant compared to the baseline model. We further employ this model to assess the digital literacy of numerous citizens in China and explore the implications for the society and individuals based on the obtained results.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Xingyu Chen et al.",
      "keywords": "Big data; Computer science; Literacy; Data science; Digital literacy; Deep learning; Artificial intelligence; Survey data collection; Machine learning; Multimedia; World Wide Web; Data mining; Statistics; Psychology; Mathematics; Pedagogy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3321831",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3034354639",
      "doi": "10.1109/access.2020.3001428",
      "title": "GSIC: A New Interpretable System for Knowledge Exploration and Classification",
      "abstract": "Machine learning and data mining techniques have been developed rapidly in recent times. In tasks such as classification, machine learning techniques have been shown to equal to and even surpass human performance. However, high performance models are usually complex, opaque and have low interpretability thus making it difficult to explain the underlying behaviors of those models that lead to the final outcomes. In many domains such as medicine and healthcare, interpretability is one of the most important factors when considering the adoption of those models. In this paper, we propose a two-stage binary classification system applicable for healthcare (or general) data that benefits from a high level of interpretability and can at the same time achieve the results comparable to commonly used classification techniques. The motivation behind the proposed system is the lack of effective classification methods for handling data generated by various distributions (such as healthcare or banking data) that can harmonize both performance and interpretability perspectives. In this work, we tackle the problem by applying divide and conquer strategy on a new disentangled representation of the underlying data. The merit of our system is evaluated by a classification experiment with a wide range of real data and popular transparent and black-box models. Furthermore, a use case in data of sepsis patients staying in the ICU (Intensive Care Unit) is depicted to prove the interpretability of the proposed model.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Thanh-Phu Nguyen et al.",
      "keywords": "Interpretability; Computer science; Machine learning; Artificial intelligence; Binary classification; Representation (politics); Divide and conquer algorithms; Data modeling; Big data; Data science; Black box; Data mining; Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3001428",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285117565",
      "doi": "10.1109/access.2022.3178088",
      "title": "Technology, Gender and Organizations: A Systematic Mapping Study",
      "abstract": "In this article, we employed a systematic mapping methodology to examine the existing literature at the intersection of technology, gender and organizations. While much has been written about gender in organizations, the research has not consistently considered that modern organizations are increasingly technology-driven &#x2013; in technology may lie an underexplored lever that could help expand our understanding of gender issues at the workplace. By analyzing a final sample of 168 research papers, we found that two main forms of conceptualizing technology emerged: technology as culture and technology as tools. Papers in the first category are concerned with environments in which technology drives a large part of what is produced, and, therefore, heavily influences culture; authors employ this framing to study technology companies, roles, and entire economic sectors under a gender perspective. The second approach corresponds to the understanding of technology as tools that individuals can use to perform their tasks. A tool can be physical, based on software, or even combine hardware, software, procedures and people; authors employ this framing to study gendered use, or adoption, of technologies to work. We synthesized all the extracted data to obtain a mapping of the literature and conclude with suggestions for future research at the intersection of technology, gender and organizations.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Gonzalo Vald\u00e9s et al.",
      "keywords": "Framing (construction); Computer science; Software; Knowledge management; Perspective (graphical); Data science; Sociology; Engineering; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3178088",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394585834",
      "doi": "10.1109/access.2024.3384973",
      "title": "An Investigation of Fundamental Frequency Pattern Prediction for Japanese Electrolaryngeal Speech Enhancement Based on Frame-Wise Phoneme Representations",
      "abstract": "Total laryngectomy (TL) is as a well-established treatment for advanced laryngeal malignancies, entailing the complete removal of the larynx. Speech rehabilitation following TL is crucial for improving the quality of life and facilitating social reintegration. Electrolaryngeal (EL) speech, a widely used voice restoration technique utilizing external excitation signals, often produces artificial and monotonous sound quality. Efforts to enhance EL speech include the application of statistical voice conversion and neural approaches to speech enhancement. These approaches typically aim to map spectral features into acoustic characteristics, including the fundamental frequency (<inline-formula> <tex-math notation=\"LaTeX\">$F_{0}$ </tex-math></inline-formula>). However, challenges arise owing to substantial discrepancies and pattern differences between extracted features for EL and normal speech, compounded by limited clinical training data. To address this issue, we explored <inline-formula> <tex-math notation=\"LaTeX\">$F_{0}$ </tex-math></inline-formula> pattern prediction based on frame-wise phoneme information using bidirectional long short-term memory recurrent neural networks. Beyond direct predictions based on phoneme labels, we expanded our analysis to include real-valued phoneme embeddings and conducted predictions for clustered embeddings representing low-dimensional input representations. Our findings demonstrate that both regression and classification predictive modeling can map frame-wise phoneme information into natural <inline-formula> <tex-math notation=\"LaTeX\">$F_{0}$ </tex-math></inline-formula> patterns. Additionally, phoneme labels can be considered as shared features between EL and normal speech, allowing for improved prediction accuracies by incorporating phoneme information from normal speech into the training sets for EL speech. Furthermore, by learning phoneme embeddings and creating input features for <inline-formula> <tex-math notation=\"LaTeX\">$F_{0}$ </tex-math></inline-formula> prediction based on the clustering of these embeddings, accurate <inline-formula> <tex-math notation=\"LaTeX\">$F_{0}$ </tex-math></inline-formula> patterns can be predicted, and the challenge of finding a strategy to reduce the dimensionality of the input features can be effectively alleviated.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mohammad Eshghi et al.",
      "keywords": "Computer science; Speech recognition; Frame (networking); Speech enhancement; Fundamental frequency; Speech coding; Artificial intelligence; Natural language processing; Acoustics; Noise reduction; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3384973",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392406148",
      "doi": "10.1109/jsen.2024.3370304",
      "title": "Reliability and Validity of Running Step Rate Derived From a Novel Wearable Smart Patch",
      "abstract": "A novel, wearable, stretchable Smart Patch can monitor various aspects of physical activity, including the dynamics of running. However, like any new device developed for such applications, it must first be tested for validity and reliability. Here, we compare the step rate while running on a treadmill measured by this smart patch with the corresponding values obtained with the \u201dgold standard\u201d OptoGait, as well as with other devices commonly used to assess running dynamics, i.e., the MEMS accelerometer and commercially available and widely used Garmin Running Dynamic Pod. The 14 healthy, physically active volunteers completed two identical sessions with a 5-minute rest between. Each session involved two one-minute runs at 11 km/h and 14 km/h separated by a one-min rest. The major finding was that the Smart Patch demonstrated fair to good test-retest reliability. The best test-retest reliability for the Running Pod was observed in connection with running at 11 km/h and both velocities combined (good and excellent, respectively) and for the OptoGait when running at 14 km/h (good). The best concurrent validity was achieved with the Smart Patch, as reflected in the highest Pearson correlation coefficient for this device when running at 11 or 14 km/h, as well as for both velocities combined. In conclusion, this study demonstrates that the novel wearable Smart Patch shows promising reliability and excellent concurrent validity in measuring step rate during treadmill running, making it a viable tool for both research and practical applications in sports and exercise science.",
      "year": "2024",
      "journal": "IEEE Sensors Journal",
      "authors": "Nina Verdel et al.",
      "keywords": "Reliability (semiconductor); Wearable computer; Reliability engineering; Computer science; Wearable technology; Engineering; Embedded system; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2024.3370304",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417298425",
      "doi": "10.1109/jbhi.2025.3647349",
      "title": "GuidedMorph: Two-Stage Deformable Registration for Breast MRI",
      "abstract": "Accurately registering breast MR images from different time points enables the alignment of anatomical structures and tracking of tumor progression, supporting more effective breast cancer detection, diagnosis, and treatment planning. However, the complexity of dense tissue and its highly non-rigid nature pose challenges for conventional registration methods, which primarily focus on aligning general structures while overlooking intricate internal details. To address this, we propose \\textbf{GuidedMorph}, a novel two-stage registration framework designed to better align dense tissue. In addition to a single-scale network for global structure alignment, we introduce a framework that utilizes dense tissue information to track breast movement. The learned transformation fields are fused by introducing the Dual Spatial Transformer Network (DSTN), improving overall alignment accuracy. A novel warping method based on the Euclidean distance transform (EDT) is also proposed to accurately warp the registered dense tissue and breast masks, preserving fine structural details during deformation. The framework supports paradigms that require external segmentation models and with image data only. It also operates effectively with the VoxelMorph and TransMorph backbones, offering a versatile solution for breast registration. We validate our method on ISPY2 and internal dataset, demonstrating superior performance in dense tissue, overall breast alignment, and breast structural similarity index measure (SSIM), with notable improvements by over 13.01% in dense tissue Dice, 3.13% in breast Dice, and 1.21% in breast SSIM compared to the best learning-based baseline.",
      "year": "2025",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Yaqian Chen et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2025.3647349",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3115679250",
      "doi": "10.1109/access.2021.3122998",
      "title": "Automatic Diagnosis of Pneumothorax From Chest Radiographs: A Systematic Literature Review",
      "abstract": "Among various medical imaging tools, chest radiographs are the most important and widely used diagnostic tool for detection of thoracic pathologies. Research is being carried out in order to propose robust automatic diagnostic tool for detection of pathologies from chest radiographs. Artificial Intelligence techniques especially deep learning methodologies have found to be giving promising results in automating the field of medicine. Lot of research has been done for automatic and fast detection of pneumothorax from chest radiographs while proposing several frameworks based on artificial intelligence and machine learning techniques. This study summarizes the existing literature for the automatic detection of pneumothorax from chest x-rays along with describing the available chest radiographs datasets. The comparative analysis of the literature is also provided in terms of goodness. Limitations of the existing literature along with the research gaps is also given for further investigation. The paper provides a brief overview of the present work for pneumothorax detection for helping the researchers in selection of optimal approach for future research.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Tahira Iqbal et al.",
      "keywords": "Pneumothorax; Radiography; Medicine; Medical physics; Radiology; Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2021.3122998",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377862186",
      "doi": "10.1109/access.2023.3279288",
      "title": "Fine-Grained Relation Extraction for Drug Instructions Using Contrastive Entity Enhancement",
      "abstract": "The extraction of relations between drug-related entities from drug instructions is essential for clinical diagnostic decision-making and drug use regulations, which is a critical task. However, due to the complexity of the textual descriptions in drug instructions, it is challenging to extract fine-grained relations, even with a considerable amount of training data. Moreover, since manually-labeled, high-quality datasets in the pharmaceutical domain are typically expensive, obtaining an extensive and accurate training dataset could be challenging. To overcome the above challenges, this paper proposes a drug relation extraction framework that combines entity information enhancement and contrastive feature learning, which can better extract fine-grained relations with limited data. More specifically, a sample generator creates a group of different samples with role semantic information from the training set, an entity encoder embeds the entity role information and context information to enhance the semantic representation, and a contrastive learning module employs a hybrid loss function to learn inter-sample and intra-sample differences. Empirical study indicates that the contrastive entity enhancement approach can achieve higher extraction accuracy and has better generalization capability. More specifically, the experimental results show that the F1 value of the model can reach 0.8892, which provides a 7.13&#x0025; improvement compared to the baseline pre-training method.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Feng Gao et al.",
      "keywords": "Computer science; Relationship extraction; Artificial intelligence; Natural language processing; Context (archaeology); Task (project management); Information extraction; Sample (material); Feature extraction; Set (abstract data type); Encoder; Generalization; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3279288",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393171370",
      "doi": "10.1109/access.2024.3380160",
      "title": "An Improved Saturation Degree-Based Constructive Heuristic for Master Surgery Scheduling Problem: Case Study",
      "abstract": "The Master Surgery Scheduling Problem (MSSP) can be described as a timetabling problem involving assigning surgery groups to operating theatre (OT) time slots. Previous MSSP optimization models considered throughput, waiting measures, resource utilization, costs, and schedule assignment objectives, but have overlooked consecutive days assignment preferences and surgical equipment-sharing limitations. Furthermore, previous works utilize greedy constructive heuristics to produce solutions, which increases quality but decreases feasibility. Our prior study demonstrated that the saturation degree heuristic enhances feasibility by considering assignment difficulty during event selection. However, its impact on solution quality remained unexplored. Therefore, this study proposes an improved saturation degree-based constructive heuristic that integrates objective function value for event selection to increase both quality and feasibility. The algorithm sorts surgery groups by unit scores, prioritizing higher assignment difficulty and objective value. The highest-scoring group is assigned to its feasible slot with the highest slot score. If no feasible slots exist, the repair mechanism vacates the slot with the highest swap score, which prioritizes lower assignment difficulty and objective value. A new mathematical model is also formulated, incorporating novel objectives regarding consecutive days assignment preference and surgical equipment-sharing limitations. Using real-world data from Hospital Canselor Tuanku Muhriz, the proposed algorithm is evaluated considering repair mechanism usage for feasibility and objective function value for quality. The algorithm is benchmarked against greedy, random, regret-based, and saturation degree-based constructive heuristics. Our algorithm achieved a 14.63&#x0025; improvement in feasibility compared to the original variant. Its objective function value is over two times better than the closest competitor and 2.6 times superior to the original variant. Comparison with the hospital&#x2019;s actual plan demonstrates competitive objective function value and a more balanced waiting time distribution among surgical groups. Our study showcases that a saturation degree-based constructive heuristic considering objective function value has increased solution quality while maintaining feasibility.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mohamad Khairulamirin Md Razali et al.",
      "keywords": "Constructive; Computer science; Job shop scheduling; Scheduling (production processes); Mathematical optimization; Degree (music); Mathematics; Schedule",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3380160",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365129631",
      "doi": "10.1109/access.2023.3266377",
      "title": "A Survey of Text Representation and Embedding Techniques in NLP",
      "abstract": "Natural Language Processing (NLP) is a research field where a language in consideration is processed to understand its syntactic, semantic, and sentimental aspects. The advancement in the NLP area has helped solve problems in the domains such as Neural Machine Translation, Name Entity Recognition, Sentiment Analysis, and Chatbots, to name a few. The topic of NLP broadly consists of two main parts: the representation of the input text (raw data) into numerical format (vectors or matrix) and the design of models for processing the numerical data. This paper focuses on the former part and surveys how the NLP field has evolved from rule-based, statistical to more context-sensitive learned representations. For each embedding type, we list their representation, issues they addressed, limitations, and applications. This survey covers the history of text representations from the 1970s and onwards, from regular expressions to the latest vector representations used to encode the raw text data. It demonstrates how the NLP field progressed from where it could comprehend just bits and pieces to all the significant aspects of the text over time.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Rajvardhan Patil et al.",
      "keywords": "Computer science; Natural language processing; Artificial intelligence; Representation (politics); Field (mathematics); Machine translation; Context (archaeology); Sentiment analysis; Embedding; Named-entity recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3266377",
      "cited_by_count": 145,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389891308",
      "doi": "10.1109/access.2023.3344579",
      "title": "Classification of Companion Animals\u2019 Ocular Diseases: Domain Adversarial Learning for Imbalanced Data",
      "abstract": "In contrast to the widespread implementation of computer-aided diagnosis of human diseases, the limited availability of veterinary image datasets has hindered its application in animals. Additionally, while most medical imaging data are captured in clinical settings, such as optical coherence tomography and fundus photography, diagnosis based on digital camera or smartphone images can be more beneficial for pet owners. This study specifically focuses on achieving generalization between screening environments, aiming to accurately diagnose diseases using casual images obtained by pet owners, despite the majority of training images being captured with specialized equipment in hospitals. Given these challenges and the significant role of computer-aided diagnosis in veterinary science, this study aims to develop a practical deep-learning framework for classifying ocular surface disease images in companion animals. The dataset used in this study consists of diverse ocular disease images of canines and felines obtained through slit lamps and digital cameras. The proposed approach includes two layers of labels for multitask learning and a gradient reversal layer based on normalized feature maps. We achieved 84.7&#x0025; and 65.4&#x0025; accuracy for the total dataset of canine and feline, respectively. For the camera domain in particular, canines and felines reached 86.2&#x0025; and 73.2&#x0025; accuracy, respectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mary G. Nam et al.",
      "keywords": "Computer science; Artificial intelligence; Computer vision; Optical coherence tomography; Domain (mathematical analysis); Digital pathology; Medical imaging; Fundus (uterus); Imaging science; Pattern recognition (psychology); Medicine; Radiology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3344579",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393241381",
      "doi": "10.1109/jbhi.2024.3379432",
      "title": "MCD-LightGBM System for Intelligent Analyzing Heterogeneous Clinical Drug Therapeutic Effects",
      "abstract": "Causal effect estimation of individual heterogeneity is a core issue in the field of causal inference, and its application in medicine poses an active and challenging problem. In high-risk decision-making domain such as healthcare, inappropriate treatments can have serious negative impacts on patients. Recently, machine learning-based methods have been proposed to improve the accuracy of causal effect estimation results. However, many of these methods concentrate on estimating causal effects of continuous outcome variables under binary intervention conditions, and give less consideration to multivariate intervention conditions or discrete outcome variables, thus limiting their scope of application. To tackle this issue, we combine the double machine learning framework with Light Gradient Boosting Machine (LightGBM) and propose a double LightGBM model. This model can estimate binary causal effects more accurately and in less time. Two cyclic structures were added to the model. Data correction method was introduced and improved to transform discrete outcome variables into continuous outcome variables. Multivariate Cyclic Double LightGBM model (MCD-LightGBM) was proposed to intelligently estimate multivariate treatment effects. A visual human-computer interaction system for heterogeneous causal effect estimation was designed, which can be applied to different types of data. This paper reports that the system improved the Logarithm of the Minimum Angle of Resolution (LogMAR) of visual acuity change after Vascular Endothelial Growth Factor (anti-VEGF) treatment in patients with diabetic macular degeneration. The improvement was observed in two clinical problems, from 0.05 to 0.33, and the readmission rate of diabetic patients after cure was reduced from 48.4% to 10.5%. The results above demonstrate the potential of the proposed system in predicting heterogeneous clinical drug treatment effects.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Xiaohui Yang et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Causal inference; Multivariate statistics; Gradient boosting; Outcome (game theory); Support vector machine; Decision tree; Data mining; Statistics; Random forest; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3379432",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W1641498739",
      "doi": "10.1109/tmi.2014.2377694",
      "title": "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)",
      "abstract": "In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low- and high-grade glioma patients-manually annotated by up to four raters-and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.",
      "year": "2014",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Bjoern Menze et al.",
      "keywords": "Artificial intelligence; Image segmentation; Benchmark (surveying); Computer science; Computer vision; Pattern recognition (psychology); Image (mathematics); Brain tumor; Segmentation; Medical imaging; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tmi.2014.2377694",
      "cited_by_count": 6141,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2804047627",
      "doi": "10.1109/tmi.2018.2837502",
      "title": "Deep Learning Techniques for Automatic MRI Cardiac Multi-Structures Segmentation and Diagnosis: Is the Problem Solved?",
      "abstract": "Delineation of the left ventricular cavity, myocardium, and right ventricle from cardiac magnetic resonance images (multi-slice 2-D cine MRI) is a common clinical task to establish diagnosis. The automation of the corresponding tasks has thus been the subject of intense research over the past decades. In this paper, we introduce the \"Automatic Cardiac Diagnosis Challenge\" dataset (ACDC), the largest publicly available and fully annotated dataset for the purpose of cardiac MRI (CMR) assessment. The dataset contains data from 150 multi-equipments CMRI recordings with reference measurements and classification from two medical experts. The overarching objective of this paper is to measure how far state-of-the-art deep learning methods can go at assessing CMRI, i.e., segmenting the myocardium and the two ventricles as well as classifying pathologies. In the wake of the 2017 MICCAI-ACDC challenge, we report results from deep learning methods provided by nine research groups for the segmentation task and four groups for the classification task. Results show that the best methods faithfully reproduce the expert analysis, leading to a mean value of 0.97 correlation score for the automatic extraction of clinical indices and an accuracy of 0.96 for automatic diagnosis. These results clearly open the door to highly accurate and fully automatic analysis of cardiac CMRI. We also identify scenarios for which deep learning methods are still failing. Both the dataset and detailed results are publicly available online, while the platform will remain open for new submissions.",
      "year": "2018",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Olivier Bernard et al.",
      "keywords": "Artificial intelligence; Deep learning; Computer science; Segmentation; Task (project management); Machine learning; Fully automatic; Automation; Medical imaging; Magnetic resonance imaging; Pattern recognition (psychology); Image segmentation; Medicine; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2018.2837502",
      "cited_by_count": 2067,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2942882625",
      "doi": "10.1109/access.2019.2913847",
      "title": "Deep Learning Framework for Alzheimer\u2019s Disease Diagnosis via 3D-CNN and FSBi-LSTM",
      "abstract": "Alzheimer's disease (AD) is an irreversible progressive neurodegenerative disorder. Mild cognitive impairment (MCI) is the prodromal state of AD, which is further classified into a progressive state (i.e., pMCI) and a stable state (i.e., sMCI). With the development of deep learning, the convolutional neural networks (CNNs) have made great progress in image recognition using magnetic resonance imaging (MRI) and positron emission tomography (PET) for AD diagnosis. However, due to the limited availability of these imaging data, it is still challenging to effectively use CNNs for AD diagnosis. Toward this end, we design a novel deep learning framework. Specifically, the virtues of 3D-CNN and fully stacked bidirectional long short-term memory (FSBi-LSTM) are exploited in our framework. First, we design a 3D-CNN architecture to derive deep feature representation from both MRI and PET. Then, we apply FSBi-LSTM on the hidden spatial information from deep feature maps to further improve its performance. Finally, we validate our method on the AD neuroimaging initiative (ADNI) dataset. Our method achieves average accuracies of 94.82%, 86.36%, and 65.35% for differentiating AD from normal control (NC), pMCI from NC, and sMCI from NC, respectively, and outperforms the related algorithms in the literature.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Chiyu Feng et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Convolutional neural network; Pattern recognition (psychology); Natural language processing; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2913847",
      "cited_by_count": 270,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210494925",
      "doi": "10.1109/tpami.2022.3145392",
      "title": "Deep ROC Analysis and AUC as Balanced Average Accuracy, for Improved Classifier Selection, Audit and Explanation",
      "abstract": "Optimal performance is desired for decision-making in any field with binary classifiers and diagnostic tests, however common performance measures lack depth in information. The area under the receiver operating characteristic curve (AUC) and the area under the precision recall curve are too general because they evaluate all decision thresholds including unrealistic ones. Conversely, accuracy, sensitivity, specificity, positive predictive value and the F1 score are too specific-they are measured at a single threshold that is optimal for some instances, but not others, which is not equitable. In between both approaches, we propose deep ROC analysis to measure performance in multiple groups of predicted risk (like calibration), or groups of true positive rate or false positive rate. In each group, we measure the group AUC (properly), normalized group AUC, and averages of: sensitivity, specificity, positive and negative predictive value, and likelihood ratio positive and negative. The measurements can be compared between groups, to whole measures, to point measures and between models. We also provide a new interpretation of AUC in whole or part, as balanced average accuracy, relevant to individuals instead of pairs. We evaluate models in three case studies using our method and Python toolkit and confirm its utility.",
      "year": "2022",
      "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Andre M. Carrington et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tpami.2022.3145392",
      "cited_by_count": 256,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2981036610",
      "doi": "10.1109/access.2019.2947606",
      "title": "Combining Noise-to-Image and Image-to-Image GANs: Brain MR Image Augmentation for Tumor Detection",
      "abstract": "Convolutional Neural Networks (CNNs) achieve excellent computer-assisted diagnosis with sufficient annotated training data. However, most medical imaging datasets are small and fragmented. In this context, Generative Adversarial Networks (GANs) can synthesize realistic/diverse additional training images to fill the data lack in the real image distribution; researchers have improved classification by augmenting data with noise-to-image (e.g., random noise samples to diverse pathological images) or image-to-image GANs (e.g., a benign image to a malignant one). Yet, no research has reported results combining noise-to-image and image-to-image GANs for further performance boost. Therefore, to maximize the DA effect with the GAN combinations, we propose a two-step GAN-based DA that generates and refines brain Magnetic Resonance (MR) images with/without tumors separately: (i) Progressive Growing of GANs (PGGANs), multi-stage noise-to-image GAN for high-resolution MR image generation, first generates realistic/diverse 256&#x00D7;256 images; (ii) Multimodal UNsupervised Image-to-image Translation (MUNIT) that combines GANs/Variational AutoEncoders or SimGAN that uses a DA-focused GAN loss, further refines the texture/shape of the PGGAN-generated images similarly to the real ones. We thoroughly investigate CNN-based tumor classification results, also considering the influence of pre-training on ImageNet and discarding weird-looking GAN-generated images. The results show that, when combined with classic DA, our two-step GAN-based DA can significantly outperform the classic DA alone, in tumor detection (i.e., boosting sensitivity 93.67% to 97.48%) and also in other medical imaging tasks.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Changhee Han et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Pattern recognition (psychology); Noise (video); Image (mathematics); Image texture; Contextual image classification; Computer vision; Context (archaeology); Boosting (machine learning); Image translation; Image noise; Image processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2947606",
      "cited_by_count": 234,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3111741353",
      "doi": "10.1109/tmi.2020.3042802",
      "title": "ROSE: A Retinal OCT-Angiography Vessel Segmentation Dataset and New Model",
      "abstract": "Optical Coherence Tomography Angiography (OCTA) is a non-invasive imaging technique that has been increasingly used to image the retinal vasculature at capillary level resolution. However, automated segmentation of retinal vessels in OCTA has been under-studied due to various challenges such as low capillary visibility and high vessel complexity, despite its significance in understanding many vision-related diseases. In addition, there is no publicly available OCTA dataset with manually graded vessels for training and validation of segmentation algorithms. To address these issues, for the first time in the field of retinal image analysis we construct a dedicated Retinal OCTA SEgmentation dataset (ROSE), which consists of 229 OCTA images with vessel annotations at either centerline-level or pixel level. This dataset with the source code has been released for public access to assist researchers in the community in undertaking research in related topics. Secondly, we introduce a novel split-based coarse-to-fine vessel segmentation network for OCTA images (OCTA-Net), with the ability to detect thick and thin vessels separately. In the OCTA-Net, a split-based coarse segmentation module is first utilized to produce a preliminary confidence map of vessels, and a split-based refined segmentation module is then used to optimize the shape/contour of the retinal microvasculature. We perform a thorough evaluation of the state-of-the-art vessel segmentation models and our OCTA-Net on the constructed ROSE dataset. The experimental results demonstrate that our OCTA-Net yields better vessel segmentation performance in OCTA than both traditional and other deep learning methods. In addition, we provide a fractal dimension analysis on the segmented microvasculature, and the statistical analysis demonstrates significant differences between the healthy control and Alzheimer's Disease group. This consolidates that the analysis of retinal microvasculature may offer a new scheme to study various neurodegenerative diseases.",
      "year": "2020",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Yuhui Ma et al.",
      "keywords": "Segmentation; Computer science; Artificial intelligence; Retinal; Optical coherence tomography; Computer vision; Pixel; Image segmentation; Pattern recognition (psychology); Medicine; Ophthalmology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2020.3042802",
      "cited_by_count": 280,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2889158831",
      "doi": "10.1109/tmi.2018.2866845",
      "title": "Fully Automatic Left Atrium Segmentation From Late Gadolinium Enhanced Magnetic Resonance Imaging Using a Dual Fully Convolutional Neural Network",
      "abstract": "Atrial fibrillation (AF) is the most prevalent form of cardiac arrhythmia. Current treatments for AF remain suboptimal due to a lack of understanding of the underlying atrial structures that directly sustain AF. Existing approaches for analyzing atrial structures in 3-D, especially from late gadolinium-enhanced (LGE) magnetic resonance imaging, rely heavily on manual segmentation methods that are extremely labor-intensive and prone to errors. As a result, a robust and automated method for analyzing atrial structures in 3-D is of high interest. We have, therefore, developed AtriaNet, a 16-layer convolutional neural network (CNN), on 154 3-D LGE-MRIs with a spatial resolution of 0.625 mm \u00d70.625 mm \u00d71.25 mm from patients with AF, to automatically segment the left atrial (LA) epicardium and endocardium. AtriaNet consists of a multi-scaled, dual-pathway architecture that captures both the local atrial tissue geometry and the global positional information of LA using 13 successive convolutions and three further convolutions for merging. By utilizing computationally efficient batch prediction, AtriaNet was able to successfully process each 3-D LGE-MRI within 1 min. Furthermore, benchmarking experiments have shown that AtriaNet has outperformed the state-of-the-art CNNs, with a DICE score of 0.940 and 0.942 for the LA epicardium and endocardium, respectively, and an inter-patient variance of <0.001. The estimated LA diameter and volume computed from the automatic segmentations were accurate to within 1.59 mm and 4.01 cm<sup>3</sup> of the ground truths. Our proposed CNN was tested on the largest known data set for LA segmentation, and to the best of our knowledge, it is the most robust approach that has ever been developed for segmenting LGE-MRIs. The increased accuracy of atrial reconstruction and analysis could potentially improve the understanding and treatment of AF.",
      "year": "2018",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Zhaohan Xiong et al.",
      "keywords": "Convolutional neural network; Segmentation; Magnetic resonance imaging; Endocardium; Artificial intelligence; Computer science; Atrial fibrillation; Pattern recognition (psychology); Image segmentation; Gadolinium; Computer vision; Medicine; Cardiology; Radiology; Materials science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2018.2866845",
      "cited_by_count": 149,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4315630813",
      "doi": "10.1109/tmi.2023.3236011",
      "title": "HoVer-Trans: Anatomy-Aware HoVer-Transformer for ROI-Free Breast Cancer Diagnosis in Ultrasound Images",
      "abstract": "Ultrasonography is an important routine examination for breast cancer diagnosis, due to its non-invasive, radiation-free and low-cost properties. However, the diagnostic accuracy of breast cancer is still limited due to its inherent limitations. Then, a precise diagnose using breast ultrasound (BUS) image would be significant useful. Many learning-based computer-aided diagnostic methods have been proposed to achieve breast cancer diagnosis/lesion classification. However, most of them require a pre-define region of interest (ROI) and then classify the lesion inside the ROI. Conventional classification backbones, such as VGG16 and ResNet50, can achieve promising classification results with no ROI requirement. But these models lack interpretability, thus restricting their use in clinical practice. In this study, we propose a novel ROI-free model for breast cancer diagnosis in ultrasound images with interpretable feature representations. We leverage the anatomical prior knowledge that malignant and benign tumors have different spatial relationships between different tissue layers, and propose a HoVer-Transformer to formulate this prior knowledge. The proposed HoVer-Trans block extracts the inter- and intra-layer spatial information horizontally and vertically. We conduct and release an open dataset GDPH&SYSUCC for breast cancer diagnosis in BUS. The proposed model is evaluated in three datasets by comparing with four CNN-based models and three vision transformer models via five-fold cross validation. It achieves state-of-the-art classification performance (GDPH&SYSUCC AUC: 0.924, ACC: 0.893, Spec: 0.836, Sens: 0.926) with the best model interpretability. In the meanwhile, our proposed model outperforms two senior sonographers on the breast cancer diagnosis when only one BUS image is given (GDPH&SYSUCC-AUC ours: 0.924 vs. reader1: 0.825 vs. reader2: 0.820).",
      "year": "2023",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Yuhao Mo et al.",
      "keywords": "Interpretability; Computer science; Artificial intelligence; Breast cancer; Breast ultrasound; Region of interest; Leverage (statistics); Ultrasound; Pattern recognition (psychology); Computer-aided diagnosis; CAD; Mammography; Medicine; Radiology; Cancer",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2023.3236011",
      "cited_by_count": 120,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2990331389",
      "doi": "10.1109/access.2019.2956018",
      "title": "Motor Imagery EEG Signals Decoding by Multivariate Empirical Wavelet Transform-Based Framework for Robust Brain\u2013Computer Interfaces",
      "abstract": "The robustness and computational load are the key challenges in motor imagery (MI) based on electroencephalography (EEG) signals to decode for the development of practical brain-computer interface (BCI) systems. In this study, we propose a robust and simple automated multivariate empirical wavelet transform (MEWT) algorithm for the decoding of different MI tasks. The main contributions of this study are four-fold. First, the multiscale principal component analysis method is utilized in the preprocessing module to obtain robustness against noise. Second, a novel automated channel selection strategy is proposed and then is further verified with comprehensive comparisons among three different strategies for decoding channel combination selection. Third, a sub-band alignment method by utilizing MEWT is adopted to obtain joint instantaneous amplitude and frequency components for the first time in MI applications. Four, a robust correlation-based feature selection strategy is applied to largely reduce the system complexity and computational load. Extensive experiments for subject-specific and subject independent cases are conducted with the three-benchmark datasets from BCI competition III to evaluate the performances of the proposed method by employing typical machine-learning classifiers. For subject-specific case, experimental results show that an average sensitivity, specificity and classification accuracy of 98% was achieved by employing multilayer perceptron neural networks, logistic model tree and least-square support vector machine (LS-SVM) classifiers, respectively for three datasets, resulting in an improvement of upto 23.50% in classification accuracy as compared with other existing method. While an average sensitivity, specificity and classification accuracy of 93%, 92.1% and 91.4% was achieved for subject independent case by employing LS-SVM classifier for all datasets with an increase of up to 18.14% relative to other existing methods. Results also show that our proposed algorithm provides a classification accuracy of 100% for subjects with small training size in subject-specific case, and for subject independent case by employing a single source subject. Such satisfactory results demonstrate the great potential of the proposed MEWT algorithm for practical MI EEG signals classification.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Muhammad Tariq Sadiq et al.",
      "keywords": "Computer science; Decoding methods; Electroencephalography; Motor imagery; Multivariate statistics; Wavelet transform; Brain\u2013computer interface; Artificial intelligence; Wavelet; Pattern recognition (psychology); Speech recognition; Computer vision; Machine learning; Psychology; Algorithm; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2956018",
      "cited_by_count": 188,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226275002",
      "doi": "10.1109/jtehm.2021.3134096",
      "title": "xViTCOS: Explainable Vision Transformer Based COVID-19 Screening Using Radiography",
      "abstract": "<i>Objective:</i> Since its outbreak, the rapid spread of COrona VIrus Disease 2019 (COVID-19) across the globe has pushed the health care system in many countries to the verge of collapse. Therefore, it is imperative to correctly identify COVID-19 positive patients and isolate them as soon as possible to contain the spread of the disease and reduce the ongoing burden on the healthcare system. The primary COVID-19 screening test, RT-PCR although accurate and reliable, has a long turn-around time. In the recent past, several researchers have demonstrated the use of Deep Learning (DL) methods on chest radiography (such as X-ray and CT) for COVID-19 detection. However, existing CNN based DL methods fail to capture the global context due to their inherent image-specific inductive bias. <i>Methods:</i> Motivated by this, in this work, we propose the use of vision transformers (instead of convolutional networks) for COVID-19 screening using the X-ray and CT images. We employ a multi-stage transfer learning technique to address the issue of data scarcity. Furthermore, we show that the features learned by our transformer networks are explainable. <i>Results:</i> We demonstrate that our method not only quantitatively outperforms the recent benchmarks but also focuses on meaningful regions in the images for detection (as confirmed by Radiologists), aiding not only in accurate diagnosis of COVID-19 but also in localization of the infected area. The code for our implementation can be found here - https://github.com/arnabkmondal/xViTCOS. <i>Conclusion:</i> The proposed method will help in timely identification of COVID-19 and efficient utilization of limited resources.",
      "year": "2021",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Arnab Kumar Mondal et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2021.3134096",
      "cited_by_count": 108,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2916686134",
      "doi": "10.1109/access.2019.2899608",
      "title": "AHCNet: An Application of Attention Mechanism and Hybrid Connection for Liver Tumor Segmentation in CT Volumes",
      "abstract": "The liver is a common site for the development of primary (i.e., originating from the liver, e.g., hepatocellular carcinoma) or secondary (i.e., spread to the liver, e.g., colorectal cancer) tumor. Due to its complex background, heterogeneous, and diffusive shape, automatic segmentation of tumor remains a challenging task. So far, only the interactive method has been adopted to obtain the acceptable segmentation results of a liver tumor. In this paper, we design an Attention Hybrid Connection Network architecture which combines soft and hard attention mechanism and long and short skip connections. We also propose a cascade network based on the liver localization network, liver segmentation network, and tumor segmentation network to cope with this challenge. Simultaneously, the joint dice loss function is proposed to train the liver localization network to obtain the accurate 3D liver bounding box, and the focal binary cross entropy is used as a loss function to fine-tune the tumor segmentation network for detecting more potentially malignant tumor and reduce false positives. Our framework is trained using the 110 cases in the LiTS dataset and extensively evaluated by the 20 cases in the 3DIRCADb dataset and the 117 cases in the Clinical dataset, which indicates that the proposed method can achieve faster network convergence and accurate semantic segmentation and further demonstrate that the proposed method has a good clinical value.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Huiyan Jiang et al.",
      "keywords": "Connection (principal bundle); Computer science; Mechanism (biology); Segmentation; Artificial intelligence; Computer vision; Mathematics; Physics; Geometry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2899608",
      "cited_by_count": 155,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3003562648",
      "doi": "10.1109/tmi.2020.2968765",
      "title": "Deep Neural Networks for Chronological Age Estimation From OPG Images",
      "abstract": "Chronological age estimation is crucial labour in many clinical procedures, where the teeth have proven to be one of the best estimators. Although some methods to estimate the age from tooth measurements in orthopantomogram (OPG) images have been developed, they rely on time-consuming manual processes whose results are affected by the observer subjectivity. Furthermore, all those approaches have been tested only on OPG image sets of good radiological quality without any conditioning dental characteristic. In this work, two fully automatic methods to estimate the chronological age of a subject from the OPG image are proposed. The first (DANet) consists of a sequential Convolutional Neural Network (CNN) path to predict the age, while the second (DASNet) adds a second CNN path to predict the sex and uses sex-specific features with the aim of improving the age prediction performance. Both methods were tested on a set of 2289 OPG images of subjects from 4.5 to 89.2 years old, where both bad radiological quality images and images showing conditioning dental characteristics were not discarded. The results showed that the DASNet outperforms the DANet in every aspect, reducing the median Error (E) and the median Absolute Error (AE) by about 4 months in the entire database. When evaluating the DASNet in the reduced datasets, the AE values decrease as the real age of the subjects decreases, until reaching a median of about 8 months in the subjects younger than 15. The DASNet method was also compared to the state-of-the-art manual age estimation methods, showing significantly less over- or under-estimation problems. Consequently, we conclude that the DASNet can be used to automatically predict the chronological age of a subject accurately, especially in young subjects with developing dentitions.",
      "year": "2020",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Nicol\u00e1s Vila-Blanco et al.",
      "keywords": "Convolutional neural network; Artificial intelligence; Estimator; Bone age; Computer science; Observer (physics); Image quality; Pattern recognition (psychology); Panoramic radiograph; Estimation; Artificial neural network; Statistics; Computer vision; Mathematics; Image (mathematics); Medicine; Radiography; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2020.2968765",
      "cited_by_count": 142,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4294811288",
      "doi": "10.1109/tnsre.2022.3204913",
      "title": "EEG-Based Graph Neural Network Classification of Alzheimer\u2019s Disease: An Empirical Evaluation of Functional Connectivity Methods",
      "abstract": "Alzheimer's disease (AD) is the leading form of dementia worldwide. AD disrupts neuronal pathways and thus is commonly viewed as a network disorder. Many studies demonstrate the power of functional connectivity (FC) graph-based biomarkers for automated diagnosis of AD using electroencephalography (EEG). However, various FC measures are commonly utilised, as each aims to quantify a unique aspect of brain coupling. Graph neural networks (GNN) provide a powerful framework for learning on graphs. While a growing number of studies use GNN to classify EEG brain graphs, it is unclear which method should be utilised to estimate the brain graph. We use eight FC measures to estimate FC brain graphs from sensor-level EEG signals. GNN models are trained in order to compare the performance of the selected FC measures. Additionally, three baseline models based on literature are trained for comparison. We show that GNN models perform significantly better than the other baseline models. Moreover, using FC measures to estimate brain graphs improves the performance of GNN compared to models trained using a fixed graph based on the spatial distance between the EEG sensors. However, no FC measure performs consistently better than the other measures. The best GNN reaches 0.984 area under sensitivity-specificity curve (AUC) and 92% accuracy, whereas the best baseline model, a convolutional neural network, has 0.924 AUC and 84.7% accuracy.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Dominik Klepl et al.",
      "keywords": "Electroencephalography; Computer science; Graph; Pattern recognition (psychology); Artificial intelligence; Convolutional neural network; Functional connectivity; Machine learning; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3204913",
      "cited_by_count": 99,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4310645210",
      "doi": "10.1109/jbhi.2022.3224727",
      "title": "Hi-BEHRT: Hierarchical Transformer-Based Model for Accurate Prediction of Clinical Events Using Multimodal Longitudinal Electronic Health Records",
      "abstract": "Electronic health records (EHR) represent a holistic overview of patients' trajectories. Their increasing availability has fueled new hopes to leverage them and develop accurate risk prediction models for a wide range of diseases. Given the complex interrelationships of medical records and patient outcomes, deep learning models have shown clear merits in achieving this goal. However, a key limitation of current study remains their capacity in processing long sequences, and long sequence modelling and its application in the context of healthcare and EHR remains unexplored. Capturing the whole history of medical encounters is expected to lead to more accurate predictions, but the inclusion of records collected for decades and from multiple resources can inevitably exceed the receptive field of the most existing deep learning architectures. This can result in missing crucial, long-term dependencies. To address this gap, we present Hi-BEHRT, a hierarchical Transformer-based model that can significantly expand the receptive field of Transformers and extract associations from much longer sequences. Using a multimodal large-scale linked longitudinal EHR, the Hi-BEHRT exceeds the state-of-the-art deep learning models 1% to 5% for area under the receiver operating characteristic (AUROC) curve and 1% to 8% for area under the precision recall (AUPRC) curve on average, and 2% to 8% (AUROC) and 2% to 11% (AUPRC) for patients with long medical history for 5-year heart failure, diabetes, chronic kidney disease, and stroke risk prediction. Additionally, because pretraining for hierarchical Transformer is not well-established, we provide an effective end-to-end contrastive pre-training strategy for Hi-BEHRT using EHR, improving its transferability on predicting clinical events with relatively small training dataset.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Yikuan Li et al.",
      "keywords": "Health records; Computer science; Electronic health record; Data modeling; Transformer; Data mining; Artificial intelligence; Engineering; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3224727",
      "cited_by_count": 118,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3107875635",
      "doi": "10.1109/access.2020.3040936",
      "title": "An Open Framework for Remote-PPG Methods and Their Assessment",
      "abstract": "International audience",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Giuseppe Boccignone et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3040936",
      "cited_by_count": 107,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3139397034",
      "doi": "10.1109/access.2021.3068614",
      "title": "The Benefits of the Matthews Correlation Coefficient (MCC) Over the Diagnostic Odds Ratio (DOR) in Binary Classification Assessment",
      "abstract": "To assess the quality of a binary classification, researchers often take advantage of a four-entry contingency table called <italic>confusion matrix</italic>, containing true positives, true negatives, false positives, and false negatives. To recap the four values of a confusion matrix in a unique score, researchers and statisticians have developed several rates and metrics. In the past, several scientific studies already showed why the Matthews correlation coefficient (MCC) is more informative and trustworthy than confusion-entropy error, accuracy, F<sub>1</sub> score, bookmaker informedness, markedness, and balanced accuracy. In this study, we compare the MCC with the diagnostic odds ratio (DOR), a statistical rate employed sometimes in biomedical sciences. After examining the properties of the MCC and of the DOR, we describe the relationships between them, by also taking advantage of an innovative geometrical plot called <italic>confusion tetrahedron</italic>, presented here for the first time. We then report some use cases where the MCC and the DOR produce discordant outcomes, and explain why the Matthews correlation coefficient is more informative and reliable between the two. Our results can have a strong impact in computer science and statistics, because they clearly explain why the trustworthiness of the information provided by the Matthews correlation coefficient is higher than the one generated by the diagnostic odds ratio.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Davide Chicco et al.",
      "keywords": "Contingency table; False positive paradox; Computer science; Confusion; Kappa; Confusion matrix; Artificial intelligence; Correlation coefficient; Statistics; Correlation; Data mining; Mathematics; Machine learning; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3068614",
      "cited_by_count": 102,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3118490356",
      "doi": "10.1109/access.2021.3050852",
      "title": "A Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection From Inpatient Facility Data",
      "abstract": "The whole world faces a pandemic situation due to the deadly virus, namely COVID-19. It takes considerable time to get the virus well-matured to be traced, and during this time, it may be transmitted among other people. To get rid of this unexpected situation, quick identification of COVID-19 patients is required. We have designed and optimized a machine learning-based framework using inpatient's facility data that will give a user-friendly, cost-effective, and time-efficient solution to this pandemic. The proposed framework uses Bayesian optimization to optimize the hyperparameters of the classifier and ADAptive SYNthetic (ADASYN) algorithm to balance the COVID and non-COVID classes of the dataset. Although the proposed technique has been applied to nine state-of-the-art classifiers to show the efficacy, it can be used to many classifiers and classification problems. It is evident from this study that eXtreme Gradient Boosting (XGB) provides the highest Kappa index of 97.00%. Compared to without ADASYN, our proposed approach yields an improvement in the kappa index of 96.94%. Besides, Bayesian optimization has been compared to grid search, random search to show efficiency. Furthermore, the most dominating features have been identified using SHapely Adaptive exPlanations (SHAP) analysis. A comparison has also been made among other related works. The proposed method is capable enough of tracing COVID patients spending less time than that of the conventional techniques. Finally, two potential applications, namely, clinically operable decision tree and decision support system, have been demonstrated to support clinical staff and build a recommender system.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Md. Abdul Awal et al.",
      "keywords": "Computer science; Bayesian optimization; Machine learning; Artificial intelligence; Naive Bayes classifier; Random forest; Decision tree; Hyperparameter optimization; Hyperparameter; Bayesian probability; Coronavirus disease 2019 (COVID-19); Multi-objective optimization; Boosting (machine learning); Classifier (UML); Data mining; Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3050852",
      "cited_by_count": 80,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2920663942",
      "doi": "10.1109/access.2019.2903015",
      "title": "Evolving Ensemble Models for Image Segmentation Using Enhanced Particle Swarm Optimization",
      "abstract": "In this paper, we propose particle swarm optimization (PSO)-enhanced ensemble deep neural networks and hybrid clustering models for skin lesion segmentation. A PSO variant is proposed, which embeds diverse search actions including simulated annealing, levy flight, helix behavior, modified PSO, and differential evolution operations with spiral search coefficients. These search actions work in a cascade manner to not only equip each individual with different search operations throughout the search process but also assign distinctive search actions to different particles simultaneously in every single iteration. The proposed PSO variant is used to optimize the learning hyper-parameters of convolutional neural networks (CNNs) and the cluster centroids of classical Fuzzy C-Means clustering respectively to overcome performance barriers. Ensemble deep networks and hybrid clustering models are subsequently constructed based on the optimized CNN and hybrid clustering segmenters for lesion segmentation. We evaluate the proposed ensemble models using three skin lesion databases, i.e., PH2, ISIC 2017, and Dermofit Image Library, and a blood cancer data set, i.e., ALL-IDB2. The empirical results indicate that our models outperform other hybrid ensemble clustering models combined with advanced PSO variants, as well as state-of-the-art deep networks in the literature for diverse challenging image segmentation tasks.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Teck Yan Tan et al.",
      "keywords": "Computer science; Cluster analysis; Artificial intelligence; Image segmentation; Pattern recognition (psychology); Segmentation; Particle swarm optimization; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2903015",
      "cited_by_count": 117,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2954333383",
      "doi": "10.1109/access.2019.2924481",
      "title": "Driver Drowsiness Detection Based on Respiratory Signal Analysis",
      "abstract": "Drowsy driving is a prevalent and serious public health issue that deserves attention. Recent studies estimate around 20% of car crashes have been caused by drowsy drivers. Nowadays, one of the main goals in the development of new advanced driver assistance systems is the trustworthy drowsiness detection. In this paper, a drowsiness detection method based on changes in the respiratory signal is proposed. The respiratory signal, which has been obtained using an inductive plethysmography belt, has been processed in real-time in order to classify the driver\u2019s state of alertness as drowsy or awake. The proposed algorithm is based on the analysis of the respiratory rate variability (RRV) in order to detect the fight against to fall asleep. Moreover, a method to provide a quality level of the respiratory signal is also proposed. Both methods have been combined to reduce false alarms due to changes of measured RRV associated not to drowsiness but body movements. A driving simulator cabin has been used to perform the validation tests and external observers have rated the drivers\u2019 state of alertness in order to evaluate the algorithm performance. It has been achieved a specificity of 96.6%, sensitivity of 90.3% and Cohen\u2019s Kappa agreement score of 0.75 on average across all subjects through a leave-one-subject-out cross-validation. A novel algorithm for driver\u2019s state of alertness monitoring through the identification of the fight against to fall asleep has been validated. The proposed algorithm may be a valuable vehicle safety system to alert drowsiness while driving",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Federico Guede-Fern\u00e1ndez et al.",
      "keywords": "Alertness; Computer science; SIGNAL (programming language); Simulation; Artificial intelligence; Real-time computing; Pattern recognition (psychology); Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2924481",
      "cited_by_count": 114,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3013280810",
      "doi": "10.1109/access.2020.2982434",
      "title": "Automatic Sleep Stage Classification With Single Channel EEG Signal Based on Two-Layer Stacked Ensemble Model",
      "abstract": "Sleep stage classification, including wakefulness (W), rapid eye movement (REM), and non- rapid eye movement (NREM) which includes three sleep stages that describe the depth of sleep, is one of the most critical steps in effective diagnosis and treatment of sleep-related disorders. Clinically, sleep staging is performed by domain experts through visual inspection of polysomnography (PSG) recordings, which is time-consuming, labor-intensive and often subjective in nature. Therefore, this study develops an automatic sleep staging system, which uses single channel electroencephalogram (EEG) signal, for convenience of wearing and less interference in the sleep, to do automatic identification of various sleep stages. To achieve the automatic sleep staging system, this study proposes a two-layer stacked ensemble model, which combines the advantages of random forest (RF) and LightGBM (LGB), where RF focuses on reducing the variance of the proposed model while LGB focuses on reducing the bias of the proposed model. Particularly, the proposed model introduces a class balance strategy to improve the N1 stage recognition rate. In order to evaluate the performance of the proposed model, experiments are performed on two datasets, including Sleep-EDF database (SEDFDB) and Sleep-EDF Expanded database (SEDFEDB). In the SEDFDB, the overall accuracy (ACC), weight F1-score (WF1), Cohen's Kappa coefficient (Kappa), sensitivity of N1 (SEN-N1) obtained by proposed model are 91.2%, 0.916, 0.864 and 72.52% respectively using subject-non-independent test (SNT). In parallel, the ACC, WF1, Kappa, SEN-N1 obtained by proposed model are 82.4%, 0.751, 0.719 and 27.15% respectively using subject-independent test (SIT). Experimental results show that the performance of the proposed model are competitive with the state-of-the-art methods and results, and the recognition rate of N1 stage is significantly improved. Moreover, in the SEDFEDB, the experimental results indicate the robustness and generality of the proposed model.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jinjin Zhou et al.",
      "keywords": "Computer science; Non-rapid eye movement sleep; Sleep Stages; Sleep (system call); Polysomnography; Artificial intelligence; Electroencephalography; Random forest; Pattern recognition (psychology); Eye movement; Speech recognition; Machine learning; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2982434",
      "cited_by_count": 63,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365421242",
      "doi": "10.1109/access.2023.3266511",
      "title": "Lightweight EfficientNetB3 Model Based on Depthwise Separable Convolutions for Enhancing Classification of Leukemia White Blood Cell Images",
      "abstract": "Acute lymphoblastic leukemia (ALL) is a type of leukemia cancer that arises due to the excessive growth of immature white blood cells (WBCs) in the bone marrow. The ALL rate for children and adults is nearly 80&#x0025; and 40&#x0025;, respectively. It affects the production of immature cells, leading to an abnormality of neurological cells and potential fatality. Therefore, a timely and accurate cancer diagnosis is important for effective treatment to improve survival rates. Since the image of acute lymphoblastic leukemia cells (cancer cells) under the microscope is complicated to recognize the difference between ALL cancer cells and normal cells. In order to reduce the severity of this disease, it is necessary to classify immature cells at an early stage. In recent years, different classification models have been introduced based on machine learning (ML) and deep learning (DL) algorithms, but they need to be improved to avoid issues related to poor generalization and slow convergence. This work enhances the diagnosis of ALL with a computer-aided system that yields accurate results by using DL techniques. This research study proposes a lightweight DL-assisted robust model based on EfficientNet-B3 using depthwise separable convolutions for classifying acute lymphoblastic leukemia and normal cells in the white blood cell images dataset. The proposed lightweight EfficientNet-B3 uses less trainable parameters to enhance the performance and efficiency of the leukemia classification. Furthermore, two publicly available datasets are considered to evaluate the effectiveness and generalization of the proposed lightweight EfficientNet-B3. In addition, different measures are employed, such as accuracy, precision, recall, and f1-score, to evaluate the effectiveness of the proposed and baseline classifiers. In addition, a detailed analysis is given to evaluate and compare the performance and efficiency of the proposed with existing pre-trained and ensemble DL classifiers. Experimental results show that the proposed model for image classification achieves better performance and outperforms the existing benchmark DL and other ensemble classifiers. Moreover, our finding suggests that the proposed lightweight EfficientNet-B3 model is reliable and generalized to facilitate clinical research and practitioners for leukemia detection.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Amreen Batool et al.",
      "keywords": "Separable space; Computer science; Leukemia; White blood cell; White (mutation); Artificial intelligence; Pattern recognition (psychology); Mathematics; Medicine; Internal medicine; Chemistry; Mathematical analysis",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3266511",
      "cited_by_count": 90,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3023149700",
      "doi": "10.1109/access.2020.2992752",
      "title": "Bio-Inspired Feature Selection: An Improved Binary Particle Swarm Optimization Approach",
      "abstract": "Feature selection is an effective approach to reduce the number of features of data, which enhances the performance of classification in machine learning. In this paper, we formulate a joint feature selection problem to reduce the number of the selected features while enhancing the accuracy. An improved binary particle swarm optimization (IBPSO) algorithm is proposed to solve the formulated problem. IBPSO introduces a local search factor based on Le&#x0301;vy flight, a global search factor based on weighting inertia coefficient, a population diversity improvement factor based on mutation mechanism and a binary mechanism to improve the performance of conventional PSO and to make it suitable for the binary feature selection problems. Experiments based on 16 classical datasets are selected to test the effectiveness of the proposed IBPSO algorithm, and the results demonstrate that IBPSO has better performance than some other comparison algorithms.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Bai Ji et al.",
      "keywords": "Particle swarm optimization; Feature selection; Computer science; Feature (linguistics); Artificial intelligence; Selection (genetic algorithm); Weighting; Binary number; Multi-swarm optimization; Population; Mathematical optimization; Pattern recognition (psychology); Algorithm; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2992752",
      "cited_by_count": 98,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2918321871",
      "doi": "10.1109/access.2019.2903131",
      "title": "TW3-Based Fully Automated Bone Age Assessment System Using Deep Neural Networks",
      "abstract": "Deep learning technology has rapidly evolved in recent years. Bone age assessment (BAA) is a typical object detection and classification problem that would benefit from deep learning. Convolutional neural networks (CNNs) and their variants are hence increasingly used for automating BAA, and they have shown promising results. In this paper, we propose a complete end-to-end BAA system to automate the entire process of the Tanner-Whitehouse 3 method, starting from localization of the epiphysis-metaphysis growth regions within 13 different bones and ending with estimation of the corresponding BA. Specific modifications to the CNNs and other stages are proposed to improve results. In addition, an annotated database of 3300 X-ray images is built to train and evaluate the system. The experimental results show that the average top-1 and top-2 prediction accuracies for skeletal bone maturity levels for 13 regions of interest are 79.6% and 97.2%, respectively. The mean absolute error and root mean squared error in age prediction are 0.46 years and 0.62 years, respectively, and accuracy within one year of the ground truth of 97.6% is achieved. The proposed system is shown to outperform a commercially available Greulich-Pyle-based system, demonstrating the potential for practical clinical use.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Sung Joon Son et al.",
      "keywords": "Bone age; Convolutional neural network; Computer science; Artificial intelligence; Epiphysis; Ground truth; Deep learning; Artificial neural network; Mean squared error; Mean absolute error; Pattern recognition (psychology); Process (computing); Machine learning; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2903131",
      "cited_by_count": 70,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4224941647",
      "doi": "10.1109/tmi.2022.3170077",
      "title": "MOOD 2020: A Public Benchmark for Out-of-Distribution Detection and Localization on Medical Images",
      "abstract": "Detecting Out-of-Distribution (OoD) data is one of the greatest challenges in safe and robust deployment of machine learning algorithms in medicine. When the algorithms encounter cases that deviate from the distribution of the training data, they often produce incorrect and over-confident predictions. OoD detection algorithms aim to catch erroneous predictions in advance by analysing the data distribution and detecting potential instances of failure. Moreover, flagging OoD cases may support human readers in identifying incidental findings. Due to the increased interest in OoD algorithms, benchmarks for different domains have recently been established. In the medical imaging domain, for which reliable predictions are often essential, an open benchmark has been missing. We introduce the Medical-Out-Of-Distribution-Analysis-Challenge (MOOD) as an open, fair, and unbiased benchmark for OoD methods in the medical imaging domain. The analysis of the submitted algorithms shows that performance has a strong positive correlation with the perceived difficulty, and that all algorithms show a high variance for different anomalies, making it yet hard to recommend them for clinical practice. We also see a strong correlation between challenge ranking and performance on a simple toy test set, indicating that this might be a valuable addition as a proxy dataset during anomaly detection algorithm development.",
      "year": "2022",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "David Zimmerer et al.",
      "keywords": "Benchmark (surveying); Artificial intelligence; Medical imaging; Mood; Computer science; Computer vision; Pattern recognition (psychology); Psychology; Psychiatry; Cartography; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2022.3170077",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2941578761",
      "doi": "10.1109/access.2019.2906605",
      "title": "Segmenting Hemorrhagic and Ischemic Infarct Simultaneously From Follow-Up Non-Contrast CT Images in Patients With Acute Ischemic Stroke",
      "abstract": "Cerebral infarct volume (CIV) measured from follow-up non contrast CT (NCCT) scans of acute ischemic stroke (AIS) patients is an important radiologic outcome measure of the effectiveness of ischemic stroke treatment. Post-treatment CIV in NCCT of AIS patients typically includes ischemic infarct only. In around 10% of AIS patients, however, hemorrhagic transformation or frank hemorrhage occurs along with ischemic infarction. Manual segmentation used to segment CIV into these two components in clinical practice is tedious and user dependent. Although automated segmentation methods exist, they can only segment either hemorrhage or ischemic infarct alone. In order to measure post-treatment CIV more efficiently, a novel joint segmentation approach is proposed to segment ischemic and hemorrhage infarct simultaneously. The proposed method makes use of advances in deep learning and convex optimization techniques. Specifically, convolutional neural network learned semantic information, local image context, and high-level user initialized prior are integrated into a multi-region time-implicit contour evolution scheme, which can be globally optimized by convex relaxation. The proposed segmentation approach is quantitatively evaluated using 30 patient images using Dice similarity coefficient and the mean and maximum absolute surface distance, compared to the gold standard of manual segmentation. The results show that the proposed semi-automatic segmentation is accurate and robust, outperforming some state-of-the-art semi-and automatic segmentation approaches.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Hulin Kuang et al.",
      "keywords": "Segmentation; Artificial intelligence; Medicine; Convolutional neural network; Context (archaeology); Pattern recognition (psychology); Image segmentation; Computer science; Stroke (engine); Similarity measure; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2906605",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2972944446",
      "doi": "10.1109/access.2019.2940418",
      "title": "FCA-Net: Adversarial Learning for Skin Lesion Segmentation Based on Multi-Scale Features and Factorized Channel Attention",
      "abstract": "International audience",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Vivek Kumar Singh et al.",
      "keywords": "Computer science; Artificial intelligence; Segmentation; Pattern recognition (psychology); Channel (broadcasting); Kernel (algebra); Convolutional neural network; Block (permutation group theory); Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2940418",
      "cited_by_count": 68,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4286542909",
      "doi": "10.1109/tnsre.2022.3192988",
      "title": "SleepFCN: A Fully Convolutional Deep Learning Framework for Sleep Stage Classification Using Single-Channel Electroencephalograms",
      "abstract": "Sleep is a vital process of our daily life as we roughly spend one-third of our lives asleep. In order to evaluate sleep quality and potential sleep disorders, sleep stage classification is a gold standard method. In this paper, we introduce a novel fully convolutional neural network architecture (SleepFCN) to classify sleep stages into five classes using single-channel electroencephalograms (EEGs). The framework of SleepFCN includes two major parts for feature extraction and temporal sequence encoding namely multi-scale feature extraction (MSFE) and residual dilated causal convolutions (ResDC), respectively. These are then followed by convolutional layers of 1-sized kernels instead of dense layers to build the fully convolutional neural network. Due to the imbalance in the distribution of sleep stages, we incorporate a weight corresponding to the number of samples of each class in our loss function. We evaluated the performance of SleepFCN using the Sleep-EDF and SHHS datasets. Our experimental results show that the proposed method outperforms state-of-the-art works in both classification correctness and learning speed.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Narjes Goshtasbi et al.",
      "keywords": "Convolutional neural network; Computer science; Sleep (system call); Artificial intelligence; Deep learning; Pattern recognition (psychology); Feature extraction; Sleep Stages; Residual; Correctness; Feature (linguistics); Channel (broadcasting); Speech recognition; Electroencephalography; Algorithm; Psychology; Polysomnography; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3192988",
      "cited_by_count": 80,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285105280",
      "doi": "10.1109/access.2022.3176091",
      "title": "The Devil is in the Details: Whole Slide Image Acquisition and Processing for Artifacts Detection, Color Variation, and Data Augmentation: A Review",
      "abstract": "Whole Slide Images (WSI) are widely used in histopathology for research and the diagnosis of different types of cancer. The preparation and digitization of histological tissues leads to the introduction of artifacts and variations that need to be addressed before the tissues are analyzed. WSI preprocessing can significantly improve the performance of computational pathology systems and is often used to facilitate human or machine analysis. Color preprocessing techniques are frequently mentioned in the literature, while other areas are usually ignored. In this paper, we present a detailed study of the state-of-the-art in three different areas of WSI preprocessing: Artifacts detection, color variation, and the emerging field of pathology-specific data augmentation. We include a summary of evaluation techniques along with a discussion of possible limitations and future research directions for new methods.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Neel Kanwal et al.",
      "keywords": "Computer science; Preprocessor; Digitization; Artificial intelligence; Computer vision; Image processing; Variation (astronomy); Data pre-processing; Field (mathematics); Digital pathology; Pattern recognition (psychology); Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3176091",
      "cited_by_count": 82,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3173922584",
      "doi": "10.1109/access.2021.3090825",
      "title": "Recent Automatic Segmentation Algorithms of MRI Prostate Regions: A Review",
      "abstract": "International audience",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Zia U. Khan et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Image segmentation; Computer vision; Algorithm",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3090825",
      "cited_by_count": 65,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3024925548",
      "doi": "10.1109/tuffc.2020.2993779",
      "title": "Deep Learning to Obtain Simultaneous Image and Segmentation Outputs From a Single Input of Raw Ultrasound Channel Data",
      "abstract": "Single plane wave transmissions are promising for automated imaging tasks requiring high ultrasound frame rates over an extended field of view. However, a single plane wave insonification typically produces suboptimal image quality. To address this limitation, we are exploring the use of deep neural networks (DNNs) as an alternative to delay-and-sum (DAS) beamforming. The objectives of this work are to obtain information directly from raw channel data and to simultaneously generate both a segmentation map for automated ultrasound tasks and a corresponding ultrasound B-mode image for interpretable supervision of the automation. We focus on visualizing and segmenting anechoic targets surrounded by tissue and ignoring or deemphasizing less important surrounding structures. DNNs trained with Field II simulations were tested with simulated, experimental phantom, and in vivo data sets that were not included during training. With unfocused input channel data (i.e., prior to the application of receive time delays), simulated, experimental phantom, and in vivo test data sets achieved mean \u00b1 standard deviation Dice similarity coefficients of 0.92 \u00b1 0.13, 0.92 \u00b1 0.03, and 0.77 \u00b1 0.07, respectively, and generalized contrast-to-noise ratios (gCNRs) of 0.95 \u00b1 0.08, 0.93 \u00b1 0.08, and 0.75 \u00b1 0.14, respectively. With subaperture beamformed channel data and a modification to the input layer of the DNN architecture to accept these data, the fidelity of image reconstruction increased (e.g., mean gCNR of multiple acquisitions of two in vivo breast cysts ranged 0.89-0.96), but DNN display frame rates were reduced from 395 to 287 Hz. Overall, the DNNs successfully translated feature representations learned from simulated data to phantom and in vivo data, which is promising for this novel approach to simultaneous ultrasound image formation and segmentation.",
      "year": "2020",
      "journal": "IEEE Transactions on Ultrasonics Ferroelectrics and Frequency Control",
      "authors": "Arun Asokan Nair et al.",
      "keywords": "Imaging phantom; Computer science; Beamforming; Artificial intelligence; Channel (broadcasting); Segmentation; Frame rate; Computer vision; Deep learning; Anechoic chamber; Physics; Telecommunications; Optics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tuffc.2020.2993779",
      "cited_by_count": 107,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3082947597",
      "doi": "10.1109/access.2020.3020802",
      "title": "Utilizing Knowledge Distillation in Deep Learning for Classification of Chest X-Ray Abnormalities",
      "abstract": "Automatic screening and diagnosis of lung abnormalities from chest X-ray images has been recently drawing attention from the computer vision and medical imaging communities. Previous studies of deep neural networks have predominantly demonstrated the effectiveness of lung disease binary classification procedures. However, large numbers of medical images-which can be labeled with a variety of existing or suspected pathologies-are required to be interpreted and reported upon daily by an individual radiologist; this poses a challenge in maintaining a consistently high diagnosis accuracy. In this paper, we present a competitive study of knowledge distillation (KD) in deep learning for classification of abnormalities in chest X-ray images. This method aims to either distill knowledge from cumbersome teacher models into lightweight student models or to self-train these student models, to generate weakly supervised multi-label lung disease classifications. Our approach was based on multi-task deep learning architectures that, in addition to multi-class classification, supported the visualizations utilized in saliency maps of the pathological regions where an abnormality was located. A self-training KD framework, in which the model learned from itself, was shown to outperform both the well-established baseline training procedure and the normal KD, achieving the AUC improvements of up to 6.39% and 3.89%, respectively. Through application to the publicly available ChestX-ray14 dataset, we demonstrated that our approach efficiently overcame the interdependency of 14 weakly annotated thorax diseases and facilitated the state-of-the-art classification compared with the current deep learning baselines.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Thi Kieu Khanh Ho et al.",
      "keywords": "Artificial intelligence; Computer science; Deep learning; Binary classification; Machine learning; Abnormality; Contextual image classification; Artificial neural network; Task (project management); Feature (linguistics); Convolutional neural network; Pattern recognition (psychology); Medical imaging; Image (mathematics); Medicine; Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3020802",
      "cited_by_count": 64,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2942336547",
      "doi": "10.1109/access.2019.2912273",
      "title": "Spectrum Analysis of EEG Signals Using CNN to Model Patient\u2019s Consciousness Level Based on Anesthesiologists\u2019 Experience",
      "abstract": "One of the most challenging predictive data analysis efforts is accurate prediction of depth of anesthesia (DOA) indicators which has attracted a growing attention since it provides patients a safe surgical environment in case of secondary damage caused by intraoperative awareness or brain injury. However, many researchers put heavily handcraft feature extraction or carefully tailored feature engineering to each patient to achieve very high sensitivity and low false prediction rate for a particular dataset. This limits the benefit of the proposed approaches if a different dataset is used. Recently, representations learned using deep convolutional neural network (CNN) for object recognition are becoming widely used model of the processing hierarchy in the human visual system. The correspondence between models and brain signals that holds the acquired activity at high temporal resolution has been explored less exhaustively. In this paper, deep learning CNN with a range of different architectures, is designed for identifying related activities from raw electroencephalography (EEG). Specifically, an improved short-time Fourier transform (STFT) is used to stand for the time-frequency information after extracting the spectral images of the original EEG as input to CNN. Then CNN models are designed and trained to predict the DOA levels from EEG spectrum without handcrafted features, which presents an intuitive mapping process with high efficiency and reliability. As a result, the best trained CNN model achieved an accuracy of 93.50%, interpreted as CNN\u2019s deep learning to approximate the DOA by senior anesthesiologists, which highlights the potential of deep CNN combined with advanced visualization techniques for EEG-based brain mapping.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Quan Liu et al.",
      "keywords": "Electroencephalography; Computer science; Consciousness; Speech recognition; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2912273",
      "cited_by_count": 65,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3102402553",
      "doi": "10.1109/access.2020.3037995",
      "title": "A Dynamic Filtering DF-RNN Deep-Learning-Based Approach for EEG-Based Neurological Disorders Diagnosis",
      "abstract": "Filtering of unwanted signals has a great impact on the performance of EEG signal processing applied to neurological disorders diagnosis. It is so difficult to remove undesirable noises using static filtering approaches as the performance of such techniques is strongly relying on specific EEG signal sub-bands, whose locations differ from one subject to another. In this paper, we present a novel dynamic filtering approach, which makes use of Finite and Infinite Impulse Response (FIR and IIR) filters along with a Recurrent Neural Networks using a Gated-Recurrent Unit (RNN-GRU), to identify and preprocess the most informative sub-bands pertaining to a particular neurological disorder. This combination of RNN with GRU requires more hidden layers than for conventional NN structures, and therefore offers much higher capacity to learn fitting and extract features from highly complex EEG data recording to afford better harmonization of the diagnosis process. Followed by an Independent Component Analysis (ICA) algorithm, all extracted features become independent to facilitate classification of clinical disorders using Convolutional Neural Network (CNN). The proposed diagnosis system achieves an average of 100% classification accuracy for epilepsy according to an offline diagnosis process using Bonn and MIT datasets, and when the same system is applied to autism provides an average accuracy of 99.5% using KAU dataset. The presented dynamic deep-learning approach applied to EEG classification pipeline, which includes artifact removal, feature extraction and classification, leads to significant improvements in the accuracy of the diagnosis classification regarding the targeted neurological pathologies.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ghaith Bouallegue et al.",
      "keywords": "Computer science; Recurrent neural network; Artificial intelligence; Feature extraction; Electroencephalography; Pattern recognition (psychology); Deep learning; Convolutional neural network; Finite impulse response; Infinite impulse response; Artifact (error); Artificial neural network; Machine learning; Filter (signal processing); Digital filter; Algorithm; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3037995",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323338315",
      "doi": "10.1109/tnsre.2023.3252880",
      "title": "Application of Home-Based Wearable Technologies in Physical Rehabilitation for Stroke: A Scoping Review",
      "abstract": "Using wearable technologies in the home setting is an emerging option for self-directed rehabilitation. A comprehensive review of its application as a treatment in home-based stroke rehabilitation is lacking. This review aimed to 1) map the interventions that have used wearable technologies in home-based physical rehabilitation for stroke, and 2) provide a synthesis of the effectiveness of wearable technologies as a treatment choice. Electronic databases of the Cochrane Library, MEDLINE, CINAHL, and Web of Science were systematically searched for work published from their inception to February 2022. This scoping review adopted Arksey and O'Malley's framework in the study procedure. Two independent reviewers screened and selected the studies. Twenty-seven were selected in this review. These studies were summarized descriptively, and the level of evidence was assessed. This review identified that most research focused on improving the hemiparetic upper limb (UL) function and a lack of studies applying wearable technologies in home-based lower limb (LL) rehabilitation. Virtual reality (VR), stimulation-based training, robotic therapy, and activity trackers are the interventions identified that apply wearable technologies. Among the UL interventions, \"strong\" evidence was found to support stimulation-based training, \"moderate\" evidence for activity trackers, \"limited\" evidence for VR, and \"inconsistent evidence\" for robotic training. Due to the lack of studies, understanding the effects of LL wearable technologies remains \"very limited.\" With newer technologies like soft wearable robotics, research in this area will grow exponentially. Future research can focus on identifying components of LL rehabilitation that can be effectively addressed using wearable technologies.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Sharon Fong Mei Toh et al.",
      "keywords": "CINAHL; Wearable computer; Rehabilitation; Psychological intervention; Wearable technology; MEDLINE; Physical medicine and rehabilitation; Cochrane Library; Computer science; Medicine; Activity tracker; Physical therapy; Meta-analysis; Nursing",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tnsre.2023.3252880",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2907845095",
      "doi": "10.1109/access.2019.2958663",
      "title": "Gated-Dilated Networks for Lung Nodule Classification in CT Scans",
      "abstract": "Different types of Convolutional Neural Networks (CNNs) have been applied to\\ndetect cancerous lung nodules from computed tomography (CT) scans. However, the\\nsize of a nodule is very diverse and can range anywhere between 3 and 30\\nmillimeters. The high variation of nodule sizes makes classifying them a\\ndifficult and challenging task. In this study, we propose a novel CNN\\narchitecture called Gated-Dilated (GD) networks to classify nodules as\\nmalignant or benign. Unlike previous studies, the GD network uses multiple\\ndilated convolutions instead of max-poolings to capture the scale variations.\\nMoreover, the GD network has a Context-Aware sub-network that analyzes the\\ninput features and guides the features to a suitable dilated convolution. We\\nevaluated the proposed network on more than 1,000 CT scans from the LIDC-LDRI\\ndataset. Our proposed network outperforms state-of-the-art baseline models\\nincluding Multi-Crop, Resnet, and Densenet, with an AUC of &gt;0.95. Compared to\\nthe baseline models, the GD network improves the classification accuracies of\\nmid-range sized nodules. Furthermore, we observe a relationship between the\\nsize of the nodule and the attention signal generated by the Context-Aware\\nsub-network, which validates our new network architecture.\\n",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Mundher Al-Shabi et al.",
      "keywords": "Computer science; Context (archaeology); Convolutional neural network; Nodule (geology); Pattern recognition (psychology); Artificial intelligence; Convolution (computer science); Residual neural network; Computed tomography; Network architecture; Artificial neural network; Radiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2958663",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312892255",
      "doi": "10.1109/tnsre.2022.3229330",
      "title": "Multiscale Convolutional Transformer for EEG Classification of Mental Imagery in Different Modalities",
      "abstract": "A new kind of sequence-to-sequence model called a transformer has been applied to electroencephalogram (EEG) systems. However, the majority of EEG-based transformer models have applied attention mechanisms to the temporal domain, while the connectivity between brain regions and the relationship between different frequencies have been neglected. In addition, many related studies on imagery-based brain-computer interface (BCI) have been limited to classifying EEG signals within one type of imagery. Therefore, it is important to develop a general model to learn various types of neural representations. In this study, we designed an experimental paradigm based on motor imagery, visual imagery, and speech imagery tasks to interpret the neural representations during mental imagery in different modalities. We conducted EEG source localization to investigate the brain networks. In addition, we propose the multiscale convolutional transformer for decoding mental imagery, which applies multi-head attention over the spatial, spectral, and temporal domains. The proposed network shows promising performance with 0.62, 0.70, and 0.72 mental imagery accuracy with the private EEG dataset, BCI competition IV 2a dataset, and Arizona State University dataset, respectively, as compared to the conventional deep learning models. Hence, we believe that it will contribute significantly to overcoming the limited number of classes and low classification performances in the BCI system.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Hyung-Ju Ahn et al.",
      "keywords": "Brain\u2013computer interface; Motor imagery; Electroencephalography; Computer science; Convolutional neural network; Artificial intelligence; Modalities; Mental image; Pattern recognition (psychology); Transformer; Speech recognition; Cognition; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3229330",
      "cited_by_count": 61,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4302276391",
      "doi": "10.1109/tmi.2022.3211764",
      "title": "CAT-Net: A Cross-Slice Attention Transformer Model for Prostate Zonal Segmentation in MRI",
      "abstract": "Prostate cancer is the second leading cause of cancer death among men in the United States. The diagnosis of prostate MRI often relies on accurate prostate zonal segmentation. However, state-of-the-art automatic segmentation methods often fail to produce well-contained volumetric segmentation of the prostate zones since certain slices of prostate MRI, such as base and apex slices, are harder to segment than other slices. This difficulty can be overcome by leveraging important multi-scale image-based information from adjacent slices, but current methods do not fully learn and exploit such cross-slice information. In this paper, we propose a novel cross-slice attention mechanism, which we use in a Transformer module to systematically learn cross-slice information at multiple scales. The module can be utilized in any existing deep-learning-based segmentation framework with skip connections. Experiments show that our cross-slice attention is able to capture cross-slice information significant for prostate zonal segmentation in order to improve the performance of current state-of-the-art methods. Cross-slice attention improves segmentation accuracy in the peripheral zones, such that segmentation results are consistent across all the prostate slices (apex, mid-gland, and base). The code for the proposed model is available at https://bit.ly/CAT-Net.",
      "year": "2022",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Alex Ling Yu Hung et al.",
      "keywords": "Segmentation; Computer science; Artificial intelligence; Image segmentation; Prostate; Transformer; Computer vision; Pattern recognition (psychology); Medicine; Cancer",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2022.3211764",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385819696",
      "doi": "10.1109/tnsre.2023.3304660",
      "title": "MSFR-GCN: A Multi-Scale Feature Reconstruction Graph Convolutional Network for EEG Emotion and Cognition Recognition",
      "abstract": "Graph Convolutional Network (GCN) excels at EEG recognition by capturing brain connections, but previous studies neglect the important EEG feature itself. In this study, we propose MSFR-GCN, a multi-scale feature reconstruction GCN for recognizing emotion and cognition tasks. Specifically, MSFR-GCN includes the MSFR and feature-pool characteristically, with the MSFR consisting of two sub-modules, multi-scale Squeeze-and-Excitation (MSSE) and multi-scale sample re-weighting (MSSR). MSSE assigns weights to channels and frequency bands based on their separate statistical information, while MSSR assigns sample weights based on combined channel and frequency information. The feature-pool, which pools across the feature dimension, is applied after GCN to retain EEG channel information. The MSFR-GCN achieves excellent results in emotion recognition when first tested on two public datasets, SEED and SEED-IV. Than the MSFR-GCN is tested on our self-collected Emotion and Cognition EEG dataset (ECED) for both emotion and cognition classification tasks. The results show MSFR-GCN's good performance in emotion and cognition classification tasks and reveal the implicit relationship between the two, which may provide aid in the rehabilitation of people with cognitive impairments from an emotional perspective.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Deng Pan et al.",
      "keywords": "Computer science; Cognition; Feature (linguistics); Graph; Pattern recognition (psychology); Artificial intelligence; Psychology; Neuroscience; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3304660",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391164242",
      "doi": "10.1109/access.2024.3358206",
      "title": "Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models",
      "abstract": "Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Hamideh Ghanadian et al.",
      "keywords": "Computer science; Suicidal ideation; Machine learning; Artificial intelligence; Synthetic data; Ideation; Set (abstract data type); Data set; Deep learning; Scarcity; Data science; Data modeling; Poison control; Psychology; Human factors and ergonomics; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3358206",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4221058302",
      "doi": "10.1109/access.2022.3157613",
      "title": "Outlier-Based Autism Detection Using Longitudinal Structural MRI",
      "abstract": "Diagnosis of Autism Spectrum Disorder (ASD) using clinical evaluation\\n(cognitive tests) is challenging due to wide variations amongst individuals.\\nSince no effective treatment exists, prompt and reliable ASD diagnosis can\\nenable the effective preparation of treatment regimens. This paper proposes\\nstructural Magnetic Resonance Imaging (sMRI)-based ASD diagnosis via an outlier\\ndetection approach. To learn Spatio-temporal patterns in structural brain\\nconnectivity, a Generative Adversarial Network (GAN) is trained exclusively\\nwith sMRI scans of healthy subjects. Given a stack of three adjacent slices as\\ninput, the GAN generator reconstructs the next three adjacent slices; the GAN\\ndiscriminator then identifies ASD sMRI scan reconstructions as outliers. This\\nmodel is compared against two other baselines -- a simpler UNet and a\\nsophisticated Self-Attention GAN. Axial, Coronal, and Sagittal sMRI slices from\\nthe multi-site ABIDE II dataset are used for evaluation. Extensive experiments\\nreveal that our ASD detection framework performs comparably with the\\nstate-of-the-art with far fewer training data. Furthermore, longitudinal data\\n(two scans per subject over time) achieve 17-28% higher accuracy than\\ncross-sectional data (one scan per subject). Among other findings, metrics\\nemployed for model training as well as reconstruction loss computation impact\\ndetection performance, and the coronal modality is found to best encode\\nstructural information for ASD detection.\\n",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "K N Devika et al.",
      "keywords": "Computer science; Discriminator; Artificial intelligence; Outlier; Pattern recognition (psychology); Anomaly detection; Detector",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3157613",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210336990",
      "doi": "10.1109/access.2022.3148402",
      "title": "CU-Net: A New Improved Multi-Input Color U-Net Model for Skin Lesion Semantic Segmentation",
      "abstract": "Melanoma is considered one of the most dangerous skin cancer diseases that threaten human health and life. Early diagnosis of melanoma is a big challenge, especially with the presence of color variations across similar lesion types. Automatic skin lesion segmentation is an essential step to build a successful skin disease classification system. Recent deep learning architectures significantly improve the skin lesion segmentation results. Especially, U-Net deep convolutional neural network (CNN) is considered one of the state-of-the-art models with promising performance. Most deep CNNs and particularly U-Net model utilize a single input RGB color image for skin lesion semantic segmentation. However, RGB color space is not usually the best choice to represent the invariant characteristics of skin lesion chromatic information. The selection of the optimal color space significantly affects the performance of segmentation results. In this paper, three novel variants of U-Net model with single, dual, and triple inputs, namely, Single Input Color U-Net (SICU-Net), Dual Input Color U-Net (DICU-Net) and Triple Input Color U-Net (TICU-Net) are proposed. The structure of SICU-Net, DICU-Net, and TICU-Net contains single, dual, and triple encoder sub-networks connected with only a single decoder path. Each encoder sub-network is fed with different color space of the input image. A channel-wise attention module is utilized to fuse the contribution of the learned feature maps from each encoder sub-network which is fed to the decoder sub-network to generate segmented image map. Moreover, a composite loss function is designed to improve the performance of the proposed CU-Net models. Three public benchmark datasets, namely, International Skin Imaging Collaboration (ISIC 2017, ISIC 2018) and PH2 datasets, are utilized to evaluate the performance of the proposed models. Experimental results reveal that the proposed models significantly improve the performance of the original U-Net model and achieve comparable performance with other state-of-the-art methods.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Rania Ramadan et al.",
      "keywords": "Artificial intelligence; Computer science; Color space; RGB color model; Segmentation; Pattern recognition (psychology); Encoder; Net (polyhedron); Convolutional neural network; Deep learning; Color image; RGB color space; Computer vision; Image processing; Mathematics; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3148402",
      "cited_by_count": 64,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377224436",
      "doi": "10.1109/access.2023.3278590",
      "title": "Role of Artificial Intelligence in Online Education: A Systematic Mapping Study",
      "abstract": "Artificial intelligence (AI) comprises various sub-fields, including machine learning (ML) and deep learning (DL) perform a key role in the transformation of many industries, including education. It changes traditional learning methods by using its Innovative techniques and applications. Using its applications, the teachers may keep track of each student&#x2019;s development, paying close attention to the areas in which they struggle. Many researchers are working with ML and DL to exploit its discoveries and insights. In education, traditional education methods (TEM) are the same for each student, which means each student is taught in the same way as ML and DL, making this process flexible and creative for solving complex problems and enhancing productivity. Nowadays, each institution adopts E-learning methods as the primary way of learning, especially during the pandemic. Despite this evolution of creativity, delivering quality education, making strategies for analyzing performance and future goals, and career counseling for students still pose challenges. The current study aims to offer a complete overview of the significance of ML approaches in online education. To accomplish this purpose, the study synthesizes information from multiple scientific papers that investigate (a) the methodology used to construct learning analysis tools, (b) the key data resources used, and (c) the scope&#x00C2; of data sources now available. This systematic literature review (SLR) examines the research conducted between 1961 and 2022, focusing on various machine learning (ML) and deep learning (DL) techniques. Its aim is to provide insights into the applications of these techniques and offer optimal solutions to the research questions at hand. We are convinced that our complete assessment will be a dependable resource for the research group in ascertainment the best approach and information source for their unique needs. Moreover, our findings provide valuable insights on the subject matter that could aid the research community in their future endeavors in the related field.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Rahman Shafique et al.",
      "keywords": "Computer science; Artificial intelligence; Data science; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3278590",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225339296",
      "doi": "10.1109/access.2022.3163247",
      "title": "A Survey of Deep Learning for Retinal Blood Vessel Segmentation Methods: Taxonomy, Trends, Challenges and Future Directions",
      "abstract": "Recent advancements in deep learning architectures have extended their application to computer vision tasks, one of which is the segmentation of retinal blood vessels from retinal fundus images. This is a problem that has piqued researchers&#x2019; interest in recent times. This paper presents a review of the taxonomy and analysis of enhancement techniques used in recent works to modify and optimize the performance of deep learning retinal blood vessels segmentation methods. The objectives of this study are to critically review the taxonomies of the state-of-the-art deep learning retinal blood vessels segmentation methods, observe the trends of the enhancement techniques of recent work, identify the challenges, and suggest potential future research directions. The taxonomies focused on in this paper include optimization algorithms, regularization methods, pooling operations, activation functions, transfer learning, and ensemble learning methods. In doing this, 110 relevant papers spanning the years 2016 to 2021 are reviewed. The findings could aid future research plans, while the suggested ideas would improve the predictive accuracy of future models for automatic retinal blood vessels segmentation algorithms with good generalization ability and optimal performance.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Olubunmi Omobola Sule",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Segmentation; Pooling; Machine learning; Transfer of learning; Retinal Disorder; Retinal",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3163247",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4281394190",
      "doi": "10.1109/mis.2022.3164313",
      "title": "AI in Combating the COVID-19 Pandemic",
      "abstract": "The SARS-CoV-2 virus, the COVID-19 disease, and the resulting pandemic have reshaped the entire world in an unprecedented manner. Massive efforts have been made by AI communities to combat the pandemic. What roles has AI played in tackling COVID-19? How has AI performed in the battle against COVID-19? Where are the gaps and opportunities? What lessons can we learn to enhance the ability of AI to battle future pandemics? These questions, despite being fundamental, are yet to be answered in full or systematically. They need to be addressed by AI communities as a priority despite the easing of the omicron infectiousness and threat. This article reviews these issues with reflections on global AI research and the literature on tackling COVID-19. It is envisaged that the demand and priority of developing \"pandemic AI\" will increase over time, with smart global epidemic early warning systems to be developed by a global collaborative AI effort.",
      "year": "2022",
      "journal": "IEEE Intelligent Systems",
      "authors": "Longbing Cao",
      "keywords": "Pandemic; Battle; Coronavirus disease 2019 (COVID-19); Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); 2019-20 coronavirus outbreak; Computer science; Political science; Data science; Computer security; Public relations; Virology; Infectious disease (medical specialty); History; Disease; Medicine",
      "mesh_terms": "",
      "pub_types": "editorial",
      "url": "https://doi.org/10.1109/mis.2022.3164313",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226181342",
      "doi": "10.1109/tnsre.2022.3166517",
      "title": "Inference of Brain States Under Anesthesia With Meta Learning Based Deep Learning Models",
      "abstract": "Monitoring the depth of unconsciousness during anesthesia is beneficial in both clinical settings and neuroscience investigations to understand brain mechanisms. Electroencephalogram (EEG) has been used as an objective means of characterizing brain altered arousal and/or cognition states induced by anesthetics in real-time. Different general anesthetics affect cerebral electrical activities in different ways. However, the performance of conventional machine learning models on EEG data is unsatisfactory due to the low Signal to Noise Ratio (SNR) in the EEG signals, especially in the office-based anesthesia EEG setting. Deep learning models have been used widely in the field of Brain Computer Interface (BCI) to perform classification and pattern recognition tasks due to their capability of good generalization and handling noises. Compared to other BCI applications, where deep learning has demonstrated encouraging results, the deep learning approach for classifying different brain consciousness states under anesthesia has been much less investigated. In this paper, we propose a new framework based on meta-learning using deep neural networks, named Anes-MetaNet, to classify brain states under anesthetics. The Anes-MetaNet is composed of Convolutional Neural Networks (CNN) to extract power spectrum features, and a time consequence model based on Long Short-Term Memory (LSTM) networks to capture the temporal dependencies, and a meta-learning framework to handle large cross-subject variability. We use a multi-stage training paradigm to improve the performance, which is justified by visualizing the high-level feature mapping. Experiments on the office-based anesthesia EEG dataset demonstrate the effectiveness of our proposed Anes-MetaNet by comparison of existing methods.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Qihang Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3166517",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3107293651",
      "doi": "10.1109/access.2020.3040340",
      "title": "A Novel Convolutional Variation of Broad Learning System for Alzheimer\u2019s Disease Diagnosis by Using MRI Images",
      "abstract": "Alzheimer's disease (AD) is a serious chronic health problem that causes great pain and loss to patients and their families. Its early and accurate diagnosis would achieve significant progress on the prevention and treatment of the disease. Magnetic Resonance Imaging (MRI) is a commonly used technique in nuclear medical diagnostics. However, it is still a challenging problem to diagnose AD, Control Normal (CN), and Mild Cognitive Impairment (MCI) because of the complex structures of MRI. In this paper, diagnosing models for MRI images are proposed to identify the various stages of AD based on the Broad Learning Systems (BLS), as well as its convolutional variants. To verify the validity of the proposed models, experiments on MRI images collected from the ADNI website are tested and evaluated. The results show that our algorithms outperform the other state-of-the-art algorithms for various tasks with better accuracy and less training times. Finally, the cross-domain learning ability of the proposed algorithms is verified on an independent AD dataset.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ruizhi Han et al.",
      "keywords": "Computer science; Magnetic resonance imaging; Artificial intelligence; Disease; Deep learning; Cognitive impairment; Convolutional neural network; Medical imaging; Neuroimaging; Domain (mathematical analysis); Machine learning; Pattern recognition (psychology); Medicine; Radiology; Pathology; Psychiatry; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3040340",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4321022081",
      "doi": "10.1109/tnsre.2023.3245285",
      "title": "Self-Supervised Learning for Label- Efficient Sleep Stage Classification: A Comprehensive Evaluation",
      "abstract": "The past few years have witnessed a remarkable advance in deep learning for EEG-based sleep stage classification (SSC). However, the success of these models is attributed to possessing a massive amount of labeled data for training, limiting their applicability in real-world scenarios. In such scenarios, sleep labs can generate a massive amount of data, but labeling can be expensive and time-consuming. Recently, the self-supervised learning (SSL) paradigm has emerged as one of the most successful techniques to overcome labels' scarcity. In this paper, we evaluate the efficacy of SSL to boost the performance of existing SSC models in the few-labels regime. We conduct a thorough study on three SSC datasets, and we find that fine-tuning the pretrained SSC models with only 5% of labeled data can achieve competitive performance to the supervised training with full labels. Moreover, self-supervised pretraining helps SSC models to be more robust to data imbalance and domain shift problems.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Emadeldeen Eldele et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Labeled data; Limiting; Deep learning; Supervised learning; Domain (mathematical analysis); Sleep (system call); Scarcity; Artificial neural network; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3245285",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3002349559",
      "doi": "10.1109/access.2020.2968395",
      "title": "Brain MRI Super-Resolution Using 3D Dilated Convolutional Encoder\u2013Decoder Network",
      "abstract": "The spatial resolution of magnetic resonance images (MRI) is limited by the hardware capacity, sampling time, signal-to-noise ratio (SNR), and patient comfort. Recently, deep convolutional neural networks (CNN) have achieved impressive success in MRI super-resolution (SR) reconstruction. Increasing network depth or width can enlarge the receptive field to improve SR accuracy, however, it is impractical for MRI reconstruction in clinical applications because of high computational loads. To address this issue, we propose a novel dilated convolutional encoder-decoder (DCED) network to improve the resolution of MRI. We exploit three-dimensional (3D) dilated convolutions as encoders to extract high-frequency features. The dilated encoders capture wider contextual information by exponentially enlarging the receptive field, without introducing additional parameters or layers. Then we decode the features using deconvolution operations to alleviate gridding artifacts and restore fine details. To improve information flow, the encoders and decoders are aggregated into symmetrically connected blocks. The output of each block is passed to the final convolution layer, which facilitates to extract hierarchical features. In addition, we also exploit a geometric self-ensemble 3D wavelet fusion method to improve the potential performance of MRI SR. Experimental results on four public available brain datasets show that our proposed method outperforms NLM (non-local means), LRTV (low-rank and total variation) and current CNN-based SR methods, which demonstrates that our method achieves a new state-of-the-art performance in MRI SR task.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jinglong Du et al.",
      "keywords": "Computer science; Convolutional neural network; Encoder; Artificial intelligence; Convolution (computer science); Deconvolution; Block (permutation group theory); Pattern recognition (psychology); Deep learning; Image resolution; Computer vision; Algorithm; Artificial neural network; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2968395",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295789126",
      "doi": "10.1109/access.2022.3206431",
      "title": "HeartNet: Self Multihead Attention Mechanism via Convolutional Network With Adversarial Data Synthesis for ECG-Based Arrhythmia Classification",
      "abstract": "Cardiovascular disease is now one of the leading causes of morbidity and mortality. Electrocardiogram (ECG) is a reliable tool for monitoring the health of the cardiovascular system. Currently, there has been a lot of focus on accurately categorizing heartbeats. There is a high demand for automatic ECG classification systems to assist medical professionals. But there is a big issue in obtaining original data extensively in medical domains in rare diseases, so it is essential to have a robust solution adopting this challenge. So, we need a solution that can address the problem of tackling data insufficiency, which is a major concern nowadays for medical applications. Without having, significant training samples the overall output can be demised. But the recent works on ECG classification did not address the challenge of solving the data insufficiency label problem. To overcome this issue, we developed a new generative adversarial network-based deep learning method called HeartNet for tackling the data insufficiency problem. The proposed deep learning method is compressed by a multi-head attention mechanism on CNN architecture. The main challenge of insufficient data labels is solved by adversarial data synthesis by adopting a generative adversarial network (GAN) with generating additional training samples. It drastically improves the overall performance of the proposed method by 5-10&#x0025; on each insufficient data label category. Since the training samples are increased. We evaluated our proposed method utilizing the MIT-BIH dataset. Our proposed method has shown <inline-formula> <tex-math notation=\"LaTeX\">$99.67\\pm {0.11}$ </tex-math></inline-formula> accuracy and 89.24&#x00B1; 1.71 MCC trained with adversarial data synthesized dataset. However, we have also utilized two individual datasets as Atrial Fibrillation Detection Database and PTB Diagnostic Database to see the performance and generalization of our proposed model on ECG classification. The effectiveness and robustness of the proposed method are validated by extensive experiments, comparison, and analysis. Later on, we also highlighted some limitations of this work.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Taki Hasan Rafi et al.",
      "keywords": "Computer science; Adversarial system; Deep learning; Artificial intelligence; Generative adversarial network; Big data; Machine learning; Convolutional neural network; Focus (optics); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3206431",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2978496518",
      "doi": "10.1109/access.2019.2944965",
      "title": "Assessment and Classification of Mental Workload in the Prefrontal Cortex (PFC) Using Fixed-Value Modified Beer-Lambert Law",
      "abstract": "Optical-neuro-imaging based functional Near-Infrared Spectroscopy (fNIRS) has been in use for several years in the fields of brain research to measure the functional response of brain activity and apply it in fields such as Neuro-rehabilitation, Brain-Computer Interface (BCI) and Neuro-ergonomics. In this paper we have enhanced the classification accuracy of a Mental workload task using a novel Fixed-Value Modified Beer-Lambert law (FV-MBLL) method. The hemodynamic changes corresponding to mental workload are measured from the Prefrontal Cortex (PFC) using fNIRS. The concentration changes of oxygenated and deoxygenated hemoglobin (&#x0394;c<sub>HbO</sub> (t) and &#x0394;c<sub>HbR</sub> (t)) of 20 participants are recorded for mental workload and rest. The statistical analysis shows that data obtained from fNIRS is statistically significant with p &lt;; 0.0001 and t-values &gt; 1.97 at confidence level of 0.95. The Support Vector Machine (SVM) classifier is used to discriminate mental math (coding) task from rest. Four features, namely mean, peak, slope and variance, are calculated on data processed through two different variants of Beer-lambert Law i.e., MBLL and FVMBLL for tissue blood flow. The optimal combination of the mean and peak values classified by SVM yielded the highest accuracy, 75%. This accuracy is further enhanced using the same feature combination, to 94% when those features are calculated using the novel algorithm FV-MBLL (with its optical density modelled form the first 4 sec stimulus data). The proposed technique can be effectively used with greater accuracies in the application of fNIRS for functional brain imaging and Brain-Machine Interface.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Umer Asgher et al.",
      "keywords": "Workload; Prefrontal cortex; Support vector machine; Artificial intelligence; Mathematics; Computer science; Psychology; Algorithm; Cognition; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2944965",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3130027632",
      "doi": "10.1109/access.2021.3061690",
      "title": "Hybrid Graph Convolutional Network for Semi-Supervised Retinal Image Classification",
      "abstract": "Diabetic Retinopathy (DR) causes a significant health threat to the patient's vision with diabetic disease, which may result in blindness in severe situations. Various automatic DR diagnosis models have been proposed along with the development of deep learning, while there always relies on a large scale annotated data to train the network. However, annotating medical fundus images is cost-expensive and requires well-trained professional doctors to identity the DR grades. To overcome this drawback, this paper focuses on utilizing the easily-obtained unlabeled data with the help of limited annotated data to identify DR grades accurately. Hence we proposes a semi-supervised retinal image classification method by a Hybrid Graph Convolutional Network (HGCN). This HGCN network designs a modularity-based graph learning module and integrates Convolutional Neural Network (CNN) features into the graph representation by graph convolutional network. The synthesized hybrid features are optimized by a semi-supervised classification task which is assisted by a similarity-based pseudo label estimator. Through the proposed HGCN method, the retinal image classification model can be trained efficiently by partially labeled samples and the complicated annotating work is not required for the most retinal images. The experimental results on MESSIDOR dataset demonstrate the favorable performance of HGCN on semi-supervised retinal image classification, and the fully labeled data training also achieves an obvious superiority to the state-of-the-art supervised learning methods.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Guanghua Zhang et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Pattern recognition (psychology); Graph; Contextual image classification; Deep learning; Similarity learning; Supervised learning; Machine learning; Artificial neural network; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3061690",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4280532335",
      "doi": "10.1109/tnsre.2022.3173946",
      "title": "Domain Adaptation With Self-Guided Adaptive Sampling Strategy: Feature Alignment for Cross-User Myoelectric Pattern Recognition",
      "abstract": "Gestural interfaces based on surface electromyographic (sEMG) signal have been widely explored. Nevertheless, due to the individual differences in the sEMG signals, it is very challenging for a myoelectric pattern recognition control system to adapt cross-user variability. Unsupervised domain adaptation (UDA) has achieved unprecedented success in improving the cross-domain robustness, and it is a promising approach to solve the cross-user challenge. Existing UDA methods largely ignore the instantaneous data distribution during model updating, thus deteriorating the feature representation given a large domain shift. To address this issue, a novel method is proposed based on a UDA model incorporated with a self-guided adaptive sampling (SGAS) strategy. This strategy is designed to utilize the domain distance in a kernel space as an indicator to screen out reliable instantaneous samples for updating the classifier. Thus, it enables improved alignment of feature representations of myoelectric patterns across users. To evaluate the performance of the proposed method, sEMG data were recorded from forearm muscles of nine subjects performing six finger and wrist gestures. Experiment results show that the UDA method with the SGAS strategy achieved a mean accuracy of 90.41% \u00b1 14.44% in a cross-user classification manner, outperformed the state-of-the-art methods with statistical significance ( ). This study demonstrates the effectiveness of the proposed UDA framework and offers a novel tool for implementing cross-user myoelectric pattern recognition towards a multi-user and user-independent control.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Xuan Zhang et al.",
      "keywords": "Computer science; Artificial intelligence; Pattern recognition (psychology); Cross-validation; Robustness (evolution); Gesture; Feature (linguistics); Classifier (UML); Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3173946",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3006915077",
      "doi": "10.1109/access.2020.2976601",
      "title": "Optimizing CNN Hyperparameters for Mental Fatigue Assessment in Demanding Maritime Operations",
      "abstract": "Human-related issues play an important role in accidents and causalities in demanding maritime operations. The industry lacks an approach capable of preventively assessing maritime operators' mental fatigue and awareness levels before accidents happen. Aiming to reduce intrusiveness, we focused on improving the mental fatigue assessment capabilities of a combination of electroencephalogram and electrocardiogram sensors by investigating the optimization of convolutional neural networks by Bayesian optimization with Gaussian process. We proposed a mapping function to optimize the network structure without the need for a tree-like structure to define the domain of variables for the optimization process. We applied the proposed approach in a simulated vessel piloting task. Even though the mental fatigue assessment for the cross-subject case is a complex classification task, the trained convolutional neural network could achieve good generalization performance (97.6% test accuracy). Finally, we also proposed a method to improve the depiction of the mental fatigue build up process. The framework presented in this work can contribute for reducing accident risk in maritime operations by improving the accuracy and assessment quality of neural network-based mental fatigue assessment tools.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Thiago Gabriel Monteiro et al.",
      "keywords": "Computer science; Convolutional neural network; Hyperparameter; Machine learning; Bayesian network; Artificial intelligence; Process (computing); Task (project management); Artificial neural network; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2976601",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2889595435",
      "doi": "10.1109/tnsre.2018.2868170",
      "title": "Automated Assessment of Movement Impairment in Huntington\u2019s Disease",
      "abstract": "Quantitative assessment of movement impairment in Huntington's disease (HD) is essential to monitoring of disease progression. This paper aimed to develop and validate a novel low cost, objective automated system for the evaluation of upper limb movement impairment in HD in order to eliminate the inconsistency of the assessor and offer a more sensitive, continuous assessment scale. Patients with genetically confirmed HD and healthy controls were recruited to this observational study. Demographic data, including age (years), gender, and unified HD rating scale total motor score (UHDRS-TMS), were recorded. For the purposes of this paper, a modified upper limb motor impairment score (mULMS) was generated from the UHDRS-TMS. All participants completed a brief, standardized clinical assessment of upper limb dexterity while wearing a tri-axial accelerometer on each wrist and on the sternum. The captured acceleration data were used to develop an automatic classification system for discriminating between healthy and HD participants and to automatically generate a continuous movement impairment score (MIS) that reflected the degree of the movement impairment. Data from 48 healthy and 44 HD participants was used to validate the developed system, which achieved 98.78% accuracy in discriminating between healthy and HD participants. The Pearson correlation coefficient between the automatic MIS and the clinician rated mULMS was 0.77 with a p-value < 0.01. The approach presented in this paper demonstrates the possibility of an automated objective, consistent, and sensitive assessment of the HD movement impairment.",
      "year": "2018",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Mohamed Bennasar et al.",
      "keywords": "Huntington's disease; Physical medicine and rehabilitation; Rating scale; Motor impairment; Movement disorders; Wrist; Psychology; Acquired brain injury; Physical therapy; Medicine; Disease; Rehabilitation; Internal medicine; Developmental psychology; Surgery",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2018.2868170",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385154203",
      "doi": "10.1109/ojits.2023.3297517",
      "title": "Fairness-Enhancing Deep Learning for Ride-Hailing Demand Prediction",
      "abstract": "Short-term demand forecasting for on-demand ride-hailing services is a fundamental issue in intelligent transportation systems. However, previous research predominantly focused on improving prediction accuracy, ignoring fairness issues such as systematic underestimations of travel demand in disadvantaged neighborhoods. This study investigates how to measure, evaluate, and enhance prediction fairness between disadvantaged and privileged communities in spatial-temporal demand forecasting of ride-hailing services. We developed a socially-aware neural network (SA-Net) that integrates socio-demographics and ridership information for fair demand prediction, and introduced a bias-mitigation regularization to reduce the prediction error gap between black and non-black, and low-income and high-income communities. The experimental results, using Chicago Transportation Network Company (TNC) data, demonstrate that our de-biasing SA-Net model outperforms other models in both prediction accuracy and fairness. Notably, the SA-Net exhibits a significant improvement in prediction accuracy, reducing 2.3&#x0025; in Mean Absolute Error (MAE) compared to state-of-the-art models. When coupled with the bias-mitigation regularization, the de-biasing SA-Net effectively bridges the mean percentage prediction error (MPE) gap between the disadvantaged and privileged groups, and protects the disadvantaged regions against systematic underestimation of TNC demand. Specifically, our approach reduces the MPE gap between black and non-black communities by 67&#x0025; without compromising overall prediction accuracy.",
      "year": "2023",
      "journal": "IEEE Open Journal of Intelligent Transportation Systems",
      "authors": "Yunhan Zheng et al.",
      "keywords": "Disadvantaged; Computer science; Demographics; Regularization (linguistics); Econometrics; Machine learning; Artificial intelligence; Economics; Economic growth",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojits.2023.3297517",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312240912",
      "doi": "10.1109/access.2022.3211313",
      "title": "Data Curation and Quality Evaluation for Machine Learning-Based Cyber Intrusion Detection",
      "abstract": "Intrusion detection is an essential task for protecting the cyber environment from attacks. Many studies have proposed sophisticated models to detect intrusions from a large amount of data, yet they ignored the fact that poor data quality has a direct impact on the performance of intrusion detection systems. Examples of poor data quality include mislabeled, inaccurate, incomprehensive, irrelevant, inconsistent, duplicated, and overlapped data. In order to investigate how data quality may affect machine learning performance, we conducted a series of experiments on 11 host-based intrusion datasets using eight machine learning (ML) models and two pre-trained language models BERT and GPT-2. The experimental results showed: 1. BERT and GPT-2 outperformed the other models on every dataset. 2. Data duplications and overlaps in a dataset had different performance impacts on the pre-trained models and the classic ML models. The pre-trained models were less susceptible to duplicate and overlapped data than the classic ML models. 3. Removing overlaps and duplicates from training data with a normal range of sequence similarities could improve the pre-trained models&#x2019; performances on most datasets. However, it may have adverse effects on model performance in datasets with highly similar sequences. 4. The reliability of model evaluation could be affected when testing data contains duplicates. 5. The overlapped rate between the normal class and the intrusion class seemed to have an inverse relationship to the performance of the pre-trained models in intrusion detection. Given the results, we proposed a framework for model selection and data quality assurance for building a high-quality machine learning-based intrusion detection system.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ngan Tran et al.",
      "keywords": "Computer science; Intrusion detection system; Machine learning; Workflow; Artificial intelligence; Data mining; Task (project management); Data modeling; Reliability (semiconductor); Intrusion; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3211313",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2911913754",
      "doi": "10.1109/access.2019.2896911",
      "title": "Enhancement of Perivascular Spaces Using Densely Connected Deep Convolutional Neural Network",
      "abstract": "Perivascular spaces (PVS) in the human brain are related to various brain diseases. However, it is difficult to quantify them due to their thin and blurry appearance. In this paper, we introduce a deep-learning-based method, which can enhance a magnetic resonance (MR) image to better visualize the PVS. To accurately predict the enhanced image, we propose a very deep 3D convolutional neural network that contains densely connected networks with skip connections. The proposed networks can utilize rich contextual information derived from low-level to high-level features and effectively alleviate the gradient vanishing problem caused by the deep layers. The proposed method is evaluated on 17 7T MR images by a twofold cross-validation. The experiments show that our proposed network is much more effective to enhance the PVS than the previous PVS enhancement methods.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Euijin Jung et al.",
      "keywords": "Convolutional neural network; Computer science; Perivascular space; Artificial intelligence; Pattern recognition (psychology); Anatomy; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2896911",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2947490884",
      "doi": "10.1109/jbhi.2019.2919732",
      "title": "I-Vector-Based Patient Adaptation of Deep Neural Networks for Automatic Heartbeat Classification",
      "abstract": "Automatic classification of electrocardiogram (ECG) signals is important for diagnosing heart arrhythmias. A big challenge in automatic ECG classification is the variation in the waveforms and characteristics of ECG signals among different patients. To address this issue, this paper proposes adapting a patient-independent deep neural network (DNN) using the information in the patient-dependent identity vectors (i-vectors). The adapted networks, namely i-vector adapted patient-specific DNNs (iAP-DNNs), are tuned toward the ECG characteristics of individual patients. For each patient, his/her ECG waveforms are compressed into an i-vector using a factor analysis model. Then, this i-vector is injected into the middle hidden layer of the patient-independent DNN. Stochastic gradient descent is then applied to fine-tune the whole network to form a patient-specific classifier. As a result, the adaptation makes use of not only the raw ECG waveforms from the specific patient but also the compact representation of his/her ECG characteristics through the i-vector. Analysis on the hidden-layer activations shows that by leveraging the information in the i-vectors, the iAP-DNNs are more capable of discriminating normal heartbeats against arrhythmic heartbeats than the networks that use the patient-specific ECG only for the adaptation. Experimental results based on the MIT-BIH database suggest that the iAP-DNNs perform better than existing patient-specific classifiers in terms of various performance measures. In particular, the sensitivity and specificity of the existing methods are all under the receiver operating characteristic curves of the iAP-DNNs.",
      "year": "2019",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Sean Shensheng Xu et al.",
      "keywords": "Computer science; Heartbeat; Artificial intelligence; Pattern recognition (psychology); Artificial neural network; Support vector machine; Classifier (UML); Mutual information; Stochastic gradient descent; Adaptation (eye); Speech recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2019.2919732",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2953634371",
      "doi": "10.1109/access.2019.2925965",
      "title": "Characteristics of a Highly Cited Article: A Machine Learning Perspective",
      "abstract": "Machine learning (ML) is a fast-growing topic that enables the extraction of patterns from varying types of datasets, ranging from medical data to financial data. However, the application of the ML methodology to understand the key characteristics of highly cited research articles has not been thoroughly investigated, despite the potential practical guidance that ML can provide for researchers during the publication process. To address this research gap, an ML algorithm known as principal component (PC) analysis is used to detect patterns in highly and lowly cited papers. In this paper, eight features (number of citations, number of views, number of characters with no spaces, number of figures, number of tables, number of equations, number of authors, and title length) are extracted from highly and lowly cited papers, leading to eight PCs (PC1-PC8). PC1 shows that the numbers of citations are positively correlated with the character count and negatively correlated with the title length. PC2 shows that the number of tables is positively correlated with the title length. PC3 shows that the number of figures is positively correlated with the number of tables. PC4-PC8 rank the importance of individual features in the descending order: number of equations, number of characters with no spaces, number of figures, number of views, and then the number of authors. The results of the ML analysis provide interesting and valuable tips for researchers, students, and all academic and non-academic writers who are seeking to improve their citation rates.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Mohamed Elgendi",
      "keywords": "Computer science; Citation; Rank (graph theory); Perspective (graphical); Information retrieval; Key (lock); Artificial intelligence; Mathematics; World Wide Web; Combinatorics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2925965",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385195123",
      "doi": "10.1109/tase.2023.3295600",
      "title": "Curriculum-Based Augmented Fourier Domain Adaptation for Robust Medical Image Segmentation",
      "abstract": "Accurate and robust medical image segmentation is fundamental and crucial for enhancing the autonomy of computer-aided diagnosis and intervention systems. Medical data collection normally involves different scanners, protocols, and populations, making domain adaptation (DA) a highly demanding research field to alleviate model degradation in the deployment site. To preserve the model performance across multiple testing domains, this work proposes the Curriculum-based Augmented Fourier Domain Adaptation (Curri-AFDA) for robust medical image segmentation. In particular, our curriculum learning strategy is based on the causal relationship of a model under different levels of data shift in the deployment phase, where the higher the shift is, the harder to recognize the variance. Considering this, we progressively introduce more amplitude information from the target domain to the source domain in the frequency space during the curriculum-style training to smoothly schedule the semantic knowledge transfer in an easier-to-harder manner. Besides, we incorporate the training-time chained augmentation mixing to help expand the data distributions while preserving the domain-invariant semantics, which is beneficial for the acquired model to be more robust and generalize better to unseen domains. Extensive experiments on two segmentation tasks of Retina and Nuclei collected from multiple sites and scanners suggest that our proposed method yields superior adaptation and generalization performance. Meanwhile, our approach proves to be more robust under various corruption types and increasing severity levels. In addition, we show our method is also beneficial in the domain-adaptive classification task with skin lesion datasets. The code is available at https://github.com/lofrienger/Curri-AFDA. <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Note to Practitioners</i> \u2014Medical image segmentation is key to improving computer-assisted diagnosis and intervention autonomy. However, due to domain gaps between different medical sites, deep learning-based segmentation models frequently encounter performance degradation when deployed in a novel domain. Moreover, model robustness is also highly expected to mitigate the effects of data corruption. Considering all these demanding yet practical needs to automate medical applications and benefit healthcare, we propose the Curriculum-based Fourier Domain Adaptation (Curri-AFDA) for medical image segmentation. Extensive experiments on two segmentation tasks with cross-domain datasets show the consistent superiority of our method regarding adaptation and generalization on multiple testing domains and robustness against synthetic corrupted data. Besides, our approach is independent of image modalities because its efficacy does not rely on modality-specific characteristics. In addition, we demonstrate the benefit of our method for image classification besides segmentation in the ablation study. Therefore, our method can potentially be applied in many medical applications and yield improved performance. Future works may be extended by exploring the integration of curriculum learning regime with Fourier domain amplitude fusion in the testing time rather than in the training time like this work and most other existing domain adaptation works.",
      "year": "2023",
      "journal": "IEEE Transactions on Automation Science and Engineering",
      "authors": "An Wang et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Robustness (evolution); Machine learning; Image segmentation; Computer vision; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tase.2023.3295600",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3046082810",
      "doi": "10.1109/access.2020.3012093",
      "title": "Computer-Aided Diagnosis Based on Extreme Learning Machine: A Review",
      "abstract": "Computer-Aided Diagnosis (CAD) can improve the accuracy of diagnosis effectively, reduce the rate of misdiagnosis, and provide the support for the valid decision. In clinical applications, high requirements are often imposed on the execution speed and accuracy of CAD systems. The classifier is regarded as the core of the CAD system, that is, the performance of the classifier will have a decisive influence on the operating affection of the CAD system. Extreme Learning Machine (ELM) is a fast learning algorithm using Single Hidden Layer Feedforward Neural Network (SLFN) structure. With its advantages in training speed, generalization performance and accuracy, ELM has draw attention in many research fields, including the development of CAD system. The applications of ELM in CAD are reviewed in this research. First, the mathematical model of ELM and framework of CAD system are briefly introduced. Then, the application of ELM in CAD is reviewed in detail, including the feature modeling method combined with ELM in CAD and the specific application of ELM. Finally, we summarized the current research status of CAD systems based on ELM, and the future work is prospected.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Zhiqiong Wang et al.",
      "keywords": "CAD; Extreme learning machine; Computer science; Classifier (UML); Machine learning; Artificial intelligence; Artificial neural network; Feed forward; Control engineering; Engineering drawing; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3012093",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394773557",
      "doi": "10.1109/access.2024.3387695",
      "title": "Novel Transformer Based Contextualized Embedding and Probabilistic Features for Depression Detection From Social Media",
      "abstract": "Depression constitutes a significant mental health condition, impacting an individual&#x2019;s emotional state, thought processes, and ability to carry out everyday tasks. Depression is defined by ongoing feelings of sadness, diminished interest in previously enjoyed activities, alterations in hunger, sleep disturbances, decreased vitality, and challenges with focus. The impact of depression extends beyond the individual, affecting society at large through decreased productivity and higher healthcare costs. In the realm of social media, users often express their thoughts and emotions through posts, which can provide insightful data for identifying patterns of depression. This research aims to detect depression early by analyzing social media user content with machine learning techniques. We have built advanced machine learning models using a benchmark depression database containing 20,000 tagged tweets from user profiles identified as depressed or non-depressed. We are introducing an innovative BERT-RF feature engineering method that extracts Contextualized Embeddings and Probabilistic Features from textual input. The Bidirectional Encoder Representations from Transformers (BERT) model, based on the Transformer architecture, is used to extract Contextualized Embedding features. These features are then fed into a random forest model to generate class probabilistic features. These prominent features aid in enhancing the identification of depression from social media. In order to classify tweets using the features derived from the BERT-RF features selection step, we have used five popular classifiers: Random Forest (RF), Multilayer Perceptron (MLP), K-Neighbors Classifier (KNC), Logistic Regression (LR), and Long Short-Term Memory (LSTM). Evaluation experiments show that our approach, using BERT-RF for feature engineering, enables the Logistic Regression model to outperform state-of-the-art methods with a high accuracy score of 99&#x0025;. We have validated the results through k-fold cross-validation and statistical T-tests. We achieved 99&#x0025; k-fold accuracy during the validation of the proposed approach. This research contributes significantly to computational linguistics and mental health analytics by providing a robust approach to the early detection of user depression from social media content.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Muhammad Asad Abbas et al.",
      "keywords": "Probabilistic logic; Computer science; Embedding; Transformer; Social media; Artificial intelligence; Computer security; World Wide Web; Electrical engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3387695",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387546367",
      "doi": "10.1109/tnsre.2023.3323892",
      "title": "A Novel Sleep Staging Method Based on EEG and ECG Multimodal Features Combination",
      "abstract": "Accurate sleep staging evaluates the quality of sleep, supporting the clinical diagnosis and intervention of sleep disorders and related diseases. Although previous attempts to classify sleep stages have achieved high classification performance, little attention has been paid to integrating the rich information in brain and heart dynamics during sleep for sleep staging. In this study, we propose a generalized EEG and ECG multimodal feature combination to classify sleep stages with high efficiency and accuracy. Briefly, a hybrid features combination in terms of multiscale entropy and intrinsic mode function are used to reflect nonlinear dynamics in multichannel EEGs, along with heart rate variability measures over time/frequency domains, and sample entropy across scales are applied for ECGs. For both the max-relevance and min-redundancy method and principal component analysis were used for dimensionality reduction. The selected features were classified by four traditional machine learning classifiers. Macro-F1 score, macro-geometric mean, and Cohen kappa value are adopted to evaluate the classification performance of each class in an imbalanced dataset. Experimental results show that EEG features contribute more to wake stage classification while ECG features contribute more to deep sleep stages. The proposed combination achieves the highest accuracy of 84.3% and the highest kappa value of 0.794 on the support vector machine in the ISRUC-S3 dataset, suggesting the proposed multimodal features combination is promising in accuracy and efficiency compared to other state-of-the-art methods.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Juntong Lyu et al.",
      "keywords": "Artificial intelligence; Sleep Stages; Computer science; Electroencephalography; Sample entropy; Pattern recognition (psychology); Support vector machine; Principal component analysis; Dimensionality reduction; Hilbert\u2013Huang transform; Machine learning; Polysomnography; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3323892",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391341345",
      "doi": "10.1109/access.2024.3360228",
      "title": "SALLoc: An Accurate Target Localization in WiFi-Enabled Indoor Environments via SAE-ALSTM",
      "abstract": "Developing a reliable and accurate indoor localization system is a crucial step for creating a seamless and interactive user-device experience in nearly all intelligent internet of things (IIoTs) and smart applications. Indoor localization systems based on WiFi fingerprinting have been considered as a promising alternative to model-based approaches owing to their accuracy, low cost, availability, and ease of configuration. However, recent studies have revealed that in complex environments, WiFi fingerprinting techniques are faced with a lot of challenges as the coverage area increases. These challenges include fingerprint spatial uncertainty, instability in the received signal strength indicator (RSSI) and discrepancy in fingerprint distribution. Furthermore, there is frequent need for database upgrades or even recreation whenever there is a change in the architecture of the location. These challenges have questioned the robustness and efficiency of most of the existing schemes. In this paper, we present an indoor localization architecture for complex multi-building multi-floor location prediction and subsequently propose SALLoc (SAE-ALSTM Localization), a WiFi fingerprinting indoor localization scheme based on Stacked Autoencoder (SAE) and Attention-based Long Short-Time Memory (ALSTM) framework. Firstly, stratified sampling technique is used to separate validation set from the entire uneven RSSI training set which ensures that the same proportion of RSSI samples are present in both sets. Secondly, SAE is utilized to select core features and decrease the dimensions of the RSSI samples. Finally, ALSTM is trained to focus on these features to achieve robust location prediction. Extensive investigations were conducted using UJIIndoorLoc, Tampere and UTSIndoorLoc datasets, and the results obtained demonstrated the superiority of the proposed scheme in terms of prediction accuracy, robustness, and generalizations when compared to state-of-the-art methods. The mean localization error (MLE) on UJIIndoorLoc, Tampere and UTSIndoorLoc datasets are 8.28 m, 9.52 m, and 6.48 m respectively. Consequently, it can be concluded that the proposed scheme is accurate and well-suited for large-scale indoor environment location prediction.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Shehu Lukman Ayinla et al.",
      "keywords": "Computer science; Real-time computing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3360228",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2946874644",
      "doi": "10.1109/jbhi.2019.2919270",
      "title": "Deep Sequential Models for Suicidal Ideation From Multiple Source Data",
      "abstract": "This paper presents a novel method for predicting suicidal ideation from electronic health records (EHR) and ecological momentary assessment (EMA) data using deep sequential models. Both EHR longitudinal data and EMA question forms are defined by asynchronous, variable length, randomly sampled data sequences. In our method, we model each of them with a recurrent neural network, and both sequences are aligned by concatenating the hidden state of each of them using temporal marks. Furthermore, we incorporate attention schemes to improve performance in long sequences and time-independent pre-trained schemes to cope with very short sequences. Using a database of 1023 patients, our experimental results show that the addition of EMA records boosts the system recall to predict the suicidal ideation diagnosis from 48.13% obtained exclusively from EHR-based state-of-the-art methods to 67.78%. Additionally, our method provides interpretability through the t-distributed stochastic neighbor embedding (t-SNE) representation of the latent space. Furthermore, the most relevant input features are identified and interpreted medically.",
      "year": "2019",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Ignacio Peis et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2019.2919270",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2952420526",
      "doi": "10.1109/access.2019.2922037",
      "title": "Examining Human-Horse Interaction by Means of Affect Recognition via Physiological Signals",
      "abstract": "For some time, equine-assisted therapy (EAT), i.e., the use of horse-related activities for therapeutic reasons, has been recognised as a useful approach in the treatment of many mental health issues such as post-traumatic stress disorder (PTSD), depression, and anxiety. However, despite the interest in EAT, few scientific studies have focused on understanding the complex emotional response that horses seem to elicit in human riders and handlers. In this work, the potential use of affect recognition techniques based on physiological signals is examined for the task of assessing the interaction between humans and horses in terms of the emotional response of the humans to this interaction. Electroencephalography (EEG), electrocardiography (ECG), and electromyography (EMG) signals were captured from humans interacting with horses, and machine learning techniques were applied in order to predict the self-reported emotional states of the human subjects in terms of valence and arousal. Supervised classification experiments demonstrated the potential of this approach for affect recognition during human-horse interaction, reaching an F1-score of 78.27% for valence and 65.49% for arousal.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Turke Althobaiti et al.",
      "keywords": "Arousal; Affect (linguistics); Valence (chemistry); Electroencephalography; Anxiety; Electromyography; Psychology; Cognitive psychology; Physical medicine and rehabilitation; Audiology; Medicine; Neuroscience; Psychiatry; Communication",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2922037",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4294811444",
      "doi": "10.1109/tnsre.2022.3204781",
      "title": "Automatic Upper-Limb Brunnstrom Recovery Stage Evaluation via Daily Activity Monitoring",
      "abstract": "Motor function assessment is crucial for post-stroke rehabilitation. Conventional evaluation methods are subjective, heavily depending on the experience of therapists. In light of the strong correlation between the stroke severity level and the performance of activities of daily living (ADLs), we explored the possibility of automatically evaluating the upper-limb Brunnstrom Recovery Stage (BRS) via three typical ADLs (tooth brushing, face washing and drinking). Multimodal data (acceleration, angular velocity, surface electromyography) were synchronously collected from 5 upper-limb-worn sensor modules. The performance of BRS evaluation system is known to be variable with different system parameters (e.g., number of sensor modules, feature types and classifiers). We systematically searched for the optimal parameters from different data segmentation strategies (five window lengths and four overlaps), 42 types of features, 12 feature optimization techniques and 9 classifiers with the leave-one-subject-out cross-validation. To achieve reliable and low-cost monitoring, we further explored whether it was possible to obtain a satisfactory result using a relatively small number of sensor modules. As a result, the proposed approach can correctly recognize the stages of all 27 participants using only three sensor modules with the optimized data segmentation parameters (window length: 7s, overlap: 50&#x0025;), extracted features (simple square integral, slope sign change, modified mean absolute value 1 and modified mean absolute value 2), the feature optimization method (principal component analysis) and the logistic regression classifier. According to the literature, this is the first study to comprehensively optimize sensor configuration and parameters in each stage of the BRS classification framework. The proposed approach can serve as a factor-screening tool towards the automatic BRS classification and is promising to be further used at home.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Long Meng et al.",
      "keywords": "Artificial intelligence; Segmentation; Pattern recognition (psychology); Computer science; Classifier (UML); Feature (linguistics); Sliding window protocol; Activities of daily living; Window (computing); Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tnsre.2022.3204781",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2972057671",
      "doi": "10.1109/access.2019.2939835",
      "title": "A New Hybrid Machine Learning Approach for Prediction of Phenanthrene Toxicity on Mice",
      "abstract": "Phenanthrene, a PAH with three fused benzene rings, is usually used as a model for the study on PAHs. During 4 days, 166 male mice were equally and randomly divided into two groups. One group was given vehicle-corn oil by oral gavage, the other was given phenanthrene at a dose of 450 milligrams per kilogram per day. In this study, in order to predict mice's phenanthrene poisoning by virtue of blood analysis indices, a new machine learning approach was put forward, which was based on an improved binary moth-flame optimizer combined with extreme learning machine. The results of the experiment have manifested that the blood analysis indices of the control and phenanthrene groups were significantly different (p&lt;; 0.5). The most important correlated indices including serum alanine aminotransferase (ALT), gamma-glutamyl transferase (GGT), plateletcrit (PCT) and red blood cell distribution width-standard deviation (RDW-SD) were screened through feature selection. The classification results demonstrated that the proposed method can achieve 93.38% accuracy and 98.33% specificity. Promisingly, there is a new and accurate way to detect the status of phenanthrene poisoning expectably.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yueting Xu et al.",
      "keywords": "Phenanthrene; Toxicity; Chemistry; Environmental chemistry; Organic chemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2939835",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4313119145",
      "doi": "10.1109/access.2022.3210347",
      "title": "Machine Learning Model for Hepatitis C Diagnosis Customized to Each Patient",
      "abstract": "Machine learning is now widely used in various fields, and it has made a big splash in the field of disease diagnosis. But traditional machine learning models are general-purpose, that is, one model is used to evaluate the health status of different patients. A general-purpose machine learning algorithm depends on a large amount of data and requires abundant computing power support, relies on the average level to describe the model performance, and cannot achieve optimal results on a specific problem. In this paper, we propose to train a unique model for each patient to improve the accuracy and ease of use of the model. The proposed approach to solving a problem in the paper is from three perspectives (1) targeted data processing, (2) model structure design: Passing in patient-related information into the model, and (3) hyperparameter tailored optimization. The preliminary experimental results show that using the custom model has advantages of high accuracy, high confidence, and low resource required to diagnose a patient. In the Hepatitis C dataset, over 99&#x0025; accuracy and 94&#x0025; recall were achieved using a smaller dataset (only 615 individuals&#x2019; data) without knowledge of the relevant field. Traditional algorithms such as XGBoost or multi-algorithm ensemble could achieve less than 95&#x0025; accuracy and only less than 70&#x0025; recall. Out of a total of 56 patients, the custom model was able to identify 53 patients 20 more than traditional methods, bringing a new and efficient tool for future hepatitis C prevention and treatment efforts.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Leran Chen et al.",
      "keywords": "Machine learning; Computer science; Hyperparameter; Artificial intelligence; Field (mathematics); Precision and recall; Recall",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3210347",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210900687",
      "doi": "10.1109/access.2022.3149956",
      "title": "Advanced Multi-Mutation With Intervention Policies Pandemic Model",
      "abstract": "A pandemic is a threat to humanity with potentially millions of deaths worldwide. Epidemiological models can be used to better understand pandemic dynamics and assist policymakers in optimizing their Intervention Policies (IPs). Most existing epidemiological models assume, sometimes incorrectly, that a pandemic is caused by a single pathogen, ignoring pathogen mutations over time that result in different pathogen strains with different characteristics. In addition, the existing models do not incorporate the effect of IPs like vaccinations and lockdowns during the fitting phase. In this work, we introduce a new model called Suspected-Infected-Vaccinated-Recovered-reInfected (SIVRI). This model extends the SIRS model with adaptation to incorporate available knowledge related to the different pathogen mutations together with multiple IPs. In order to find the model parameters we propose a new fitting procedure that supports the complex social, epidemiological, and clinical dynamics that occur during a pandemic. We examine the suggested SIVRI model in comparison to the SIRS and XGboost models on the COVID-19 pandemic in Israel that includes four COVID-19 mutations, and the vaccination and lockdown IPs. We show that the proposed model can fit accurately to the historical data and outperform the existing models in predictions of basic reproduction number, mortality rate, and severely infected individuals rate. MSC: 34-04 &#x007C; 65-05 &#x007C; 68U20",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Teddy Lazebnik et al.",
      "keywords": "Pandemic; Basic reproduction number; Computer science; Epidemic model; Social distance; Vaccination; Pathogen; Epidemiology; Coronavirus disease 2019 (COVID-19); Risk analysis (engineering); Virology; Biology; Medicine; Disease; Environmental health; Genetics; Infectious disease (medical specialty); Population",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3149956",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3100948072",
      "doi": "10.1109/access.2020.3038658",
      "title": "Empirical Comparison of Approaches for Mitigating Effects of Class Imbalances in Water Quality Anomaly Detection",
      "abstract": "Imbalanced class distribution and missing data are two common problems and occurrences in water quality anomaly detection domain. Learning algorithms in an imbalanced dataset can yield an overrated classification accuracy driven by a bias towards the majority class at the expense of the minority class. On the other hand, missing values in data can induce complexity in the learning classifiers during data analysis. These two problems pose substantial challenges to the performance of learning algorithms in real-life water quality anomaly detection problems. Hence, the need for them to be carefully considered and addressed to achieve better performance. In this paper, the performance of a range of several combinations of techniques to deal with imbalanced classes in the context of binary-imbalanced water quality anomaly detection problem and the presence of missing values is extensively compare. The methods considered include seven missing data and eight resampling methods, on ten different learning state-of-the-art classifiers taking into account diversity in their learning philosophies. The different classifiers are evaluated using stratified 5-fold cross-validation, based on three performance evaluation metrics namely accuracy, ROC-AUC and F1-measure. Further experiments are carried out on nineteen variants of homogeneous and heterogeneous ensemble techniques embedded with resampling and missing value strategies during their training phase as well as an optimized deep neural network model. The experimental results show an improvement in the performance of the learning classifiers, especially when dealing with the class imbalance problem (on the one hand) and the incomplete data problem (on the other hand). Furthermore, the neural network model exhibit superior performance when dealing with both problems.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Eustace M. Dogo et al.",
      "keywords": "Computer science; Artificial intelligence; Anomaly detection; Machine learning; Missing data; Resampling; Context (archaeology); Data mining; Ensemble learning; Binary classification; Artificial neural network; Pattern recognition (psychology); Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3038658",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295886290",
      "doi": "10.1109/access.2022.3205738",
      "title": "Exudate Regeneration for Automated Exudate Detection in Retinal Fundus Images",
      "abstract": "This paper presents a framework for the automated detection of Exudates, an early sign of Diabetic Retinopathy. The paper introduces a classification-extraction-superimposition (CES) mechanism for enabling the generation of representative exudate samples based on limited open-source samples. The paper demonstrates how the manipulation of Yolov5M output vector can be utilized for exudate extraction and super-imposition, segueing into the development of a custom CNN architecture focused on exudate classification in retinal based fundus images. The performance of the proposed architecture is compared with various state-of-the-art image classification architectures on a wide range of metrics, including the simulation of post deployment inference statistics. A self-label mechanism is presented, endorsing the high performance of the developed architecture, achieving 100% on the test dataset.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Muhammad Hussain et al.",
      "keywords": "Exudate; Computer science; Artificial intelligence; Pattern recognition (psychology); Feature extraction; Fundus (uterus); Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3205738",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4366667986",
      "doi": "10.1109/access.2023.3269068",
      "title": "Multi-Level Residual Feature Fusion Network for Thoracic Disease Classification in Chest X-Ray Images",
      "abstract": "Automated identification of thoracic diseases from chest X-ray images (CXR) is a significant area in computer-aided diagnosis. However, most existing methods have limited ability to extract multi-scale features and accurately capture the spatial location of lesions when dealing with thoracic diseases that exhibit concurrency and large variations in lesion size. Based on the above problems, we propose a multi-level residual feature fusion network (MLRFNet) for classifying thoracic diseases. Our approach can quickly capture receptive field information across different lesion sizes and enhance disease-specific features within the spatial domain on feature maps. The MLRFNet comprises two main components: a feature extractor that learns multi-scale semantic information from chest X-ray images and a multi-level residual feature classifier (MRFC) that refines disease-specific pathological features at spatial locations to reduce interference from irrelevant regions. Additionally, the ECA attention modules connect both components to enable flexible channel-wise focus on critical pathological information. We evaluated the performance of MLRFNet through a series of experiments on two datasets: ChestX-Ray14 and CheXpert. Our results show that MLRFNet achieves an average AUC of 0.853 on the ChestX-Ray14 dataset and 0.904 on the CheXpert dataset. The results of experiments demonstrate that our proposed method works better than the current state-of-the-art baselines. Future work will focus on investigating the interdependencies among labels for thoracic diseases and techniques for model compression.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Qiang Li et al.",
      "keywords": "Computer science; Artificial intelligence; Pattern recognition (psychology); Classifier (UML); Feature (linguistics); Focus (optics); Residual; Feature extraction; Spatial analysis",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3269068",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293371136",
      "doi": "10.1109/access.2022.3201911",
      "title": "On the Generalization of Sleep Apnea Detection Methods Based on Heart Rate Variability and Machine Learning",
      "abstract": "[EN] Obstructive sleep apnea (OSA) is a respiratory disorder highly correlated with severe cardiovascular diseases that has unleashed the interest of hundreds of experts aiming to overcome the elevated requirements of polysomnography, the gold standard for its detection. In this regard, a variety of algorithms based on heart rate variability (HRV) features and machine learning (ML) classifiers have been recently proposed for epoch-wise OSA detection from the surface electrocardiogram signal. Many researchers have employed freely available databases to assess their methods in a reproducible way, but most were purely tested with cross-validation approaches and even some using solely a single database for training and testing procedures. Hence, although promising values of diagnostic accuracy have been reported by some of these methods, they are suspected to be overestimated and the present work aims to analyze the actual generalization ability of several epoch-wise OSA detectors obtained through a common ML pipeline and typical HRV features. Precisely, the performance of the generated OSA detectors has been compared on two validation approaches, i.e., the widely used epoch-wise, k-fold cross-validation and the highly recommended external validation, both considering different combinations of well-known public databases. Regardless of the used ML classifiers and the selected HRV-based features, the external validation results have been 20 to 40% lower than those obtained with cross-validation in terms of accuracy, sensitivity, and specificity. Consequently, these results suggest that ML-based OSA detectors trained with public databases are still not sufficiently general to be employed in clinical practice, as well as that larger, more representative public datasets and the use of external validation are mandatory to improve the generalization ability and to obtain reliable assessment of the true predictive power of these algorithms, respectively.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Daniele Padovano et al.",
      "keywords": "Computer science; Polysomnography; Artificial intelligence; Machine learning; Generalization; Cross-validation; Obstructive sleep apnea; Sleep apnea; Gold standard (test); Heart rate variability; Apnea; Medicine; Heart rate; Mathematics; Cardiology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3201911",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392449785",
      "doi": "10.1109/access.2024.3374223",
      "title": "Energy-Efficient FPGA Based Sleep Apnea Detection Using EEG Signals",
      "abstract": "Sleep apnea is a prevalent sleep disorder characterized by frequent interruptions in breathing during sleep, leading to decreased levels of blood oxygen. This research introduces an energy-efficient digital hardware system built on an Artix 7 FPGA, explicitly designed for real-time sleep apnea detection. Our approach involves the classification of subject-specific sleep apnea and non-apnea events. We utilize inter-band energy ratio features extracted from multi-band Electroencephalogram (EEG) signals and employ a Linear Support Vector Machine (LSVM) classifier for this task. The features extracted&#x2014;namely energy, kurtosis, and mobility&#x2014;from five sub-bands demonstrate improved accuracy, sensitivity, and specificity compared to existing studies. The proposed model is evaluated using EEG signals from the openly accessible St. Vincent&#x2019;s sleep apnea UCDDB database. Our system achieves remarkable performance metrics, attaining the highest accuracy of 94.81&#x0025;, a sensitivity of 93.10&#x0025;, and a specificity of 96.43&#x0025;. It accomplishes all this while maintaining minimal dynamic power consumption (19mW) and using minimal FPGA resources. This hardware system can be integrated into a System-on-a-Chip (SoC) platform, serving as a crucial component of a smart, wearable, automated sleep apnea detection device for real-time critical health diagnosis and screening.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Md. Shamshad Alam et al.",
      "keywords": "Electroencephalography; Computer science; Field-programmable gate array; Sleep (system call); Sleep apnea; Energy (signal processing); Apnea; Artificial intelligence; Pattern recognition (psychology); Speech recognition; Medicine; Embedded system; Cardiology; Internal medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3374223",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3092551025",
      "doi": "10.1109/tmi.2020.3029286",
      "title": "Bayesian Approach for a Robust Speed-of-Sound Reconstruction Using Pulse-Echo Ultrasound",
      "abstract": "Computed ultrasound tomography in echo mode (CUTE) is a promising ultrasound (US) based multi-modal technique that allows to image the spatial distribution of speed of sound (SoS) inside tissue using hand-held pulse-echo US. It is based on measuring the phase shift of echoes when detected under varying steering angles. The SoS is then reconstructed using a regularized inversion of a forward model that describes the relation between the SoS and echo phase shift. Promising results were obtained in phantoms when using a Tikhonov-type regularization of the spatial gradient (SG) of SoS. In-vivo, however, clutter and aberration lead to an increased phase noise. In many subjects, this phase noise causes strong artifacts in the SoS image when using the SG regularization. To solve this shortcoming, we propose to use a Bayesian framework for the inverse calculation, which includes a priori statistical properties of the spatial distribution of the SoS to avoid noise-related artifacts in the SoS images. In this study, the a priori model is based on segmenting the B-Mode image. We show in a simulation and phantom study that this approach leads to SoS images that are much more stable against phase noise compared to the SG regularization. In a preliminary in-vivo study, a reproducibility in the range of 10 ms<sup>-1</sup> was achieved when imaging the SoS of a volunteer's liver from different scanning locations. These results demonstrate the diagnostic potential of CUTE for example for the staging of fatty liver disease.",
      "year": "2020",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Patrick St\u00e4hli et al.",
      "keywords": "Imaging phantom; Tikhonov regularization; Computer science; A priori and a posteriori; Clutter; Artificial intelligence; Iterative reconstruction; Bayesian probability; Noise (video); Algorithm; Computer vision; Inverse problem; Pattern recognition (psychology); Mathematics; Physics; Image (mathematics); Optics; Radar",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2020.3029286",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4284896232",
      "doi": "10.1109/access.2022.3180045",
      "title": "Reservoir Computing for Early Stage Alzheimer\u2019s Disease Detection",
      "abstract": "Artificial Neural Networks (ANNs) have amassed unprecedented success in information processing ranging from image recognition to time series prediction. The success can largely be attributed to the availability of large datasets for training and the increased complexity of the models. Unfortunately, for some applications only a limited amount of samples is available for training. Fewer training samples increases the risk of over-fitting and poor generalization especially in high complexity models. Moreover, complex models with a large number of trainable parameters require more energy to train and optimize compared to simpler ones. In this paper, to the best of our knowledge, we propose the first use of ANNs for Early Stage Alzheimer Disease classification (ES-AD) from the handwriting (HW). We propose using a framework for building Recurrent Neural Networks (RNNs) known as Reservoir Computing (RC), both numerically and experimentally, that simplifies training by optimizing the output layer only. We also propose the Bidirectional Long Term Short Term (BiLSTM) and Convolutional Neural Network (CNN) methods for comparison. For a fairer comparison, we not only consider the accuracies but also the energy costs incurred to obtain the respective accuracies in order to assess the accuracy-efficiency trade-off. Our numerical and experimental results show that RC yields a classification accuracy of 85&#x0025;, which is 3&#x0025; worse than that of BiLSTM and 2&#x0025; better than that of CNN, at a relatively lower training and significantly lower inference costs. We hope that our findings highlight the importance of examining the accuracy-efficiency trade-off of various models in the community in order to reduce the overall impact of ANNs training on the environment.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Nickson Mwamsojo et al.",
      "keywords": "Computer science; Generalization; Inference; Artificial intelligence; Convolutional neural network; Artificial neural network; Machine learning; Handwriting; Deep learning; Recurrent neural network; Pattern recognition (psychology); Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3180045",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225726302",
      "doi": "10.1109/access.2022.3165043",
      "title": "Using Machine Learning to Improve Lead Times in the Identification of Emerging Customer Needs",
      "abstract": "In recent years, computational approaches for automatically extracting the voice of the customer from user generated content have been proposed. These studies have tackled the task of obtaining current customer needs, however, there is a lack of methods that predict future needs (i.e. needs that may become popular in the marketplace). Therefore, this study presents a multi-document keyphrase extraction algorithm which predicts future customer needs from users&#x2019; social media posts on Reddit. Key to our approach is a novel document filtering method (discovering potentially relevant social media content) and a keyphrase ranking method, which promotes terms with rising frequency likely to be future product needs. In order to evaluate the approach, a case study of &#x201C;toothpaste&#x201D; needs is reviewed and a novel evaluation approach using ground truth automatically extracted from a collection of future specifications of new-to-market products is proposed. In our evaluation, we show that the approach is significantly better than simple baselines at identifying customer needs on social media before they trend in the marketplace. We also show that our approach can capture important customer needs identified by a large multinational company with lead times of up to 25 months ahead of them trending in the marketplace. The findings of this research could provide many benefits to businesses such as gaining early access into markets ahead of their competitors and giving early notice to manufacturers/engineers/developers before a need for a product is in demand.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "David Kilroy et al.",
      "keywords": "Computer science; Competitor analysis; Customer needs; Social media; Product (mathematics); Identification (biology); Key (lock); Task (project management); Notice; User-generated content; Ranking (information retrieval); World Wide Web; Marketing; Artificial intelligence; Business; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3165043",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312986972",
      "doi": "10.1109/access.2022.3225107",
      "title": "Performance Evaluation of Deep Learning Models for Image Classification Over Small Datasets: Diabetic Foot Case Study",
      "abstract": "Data scarcity is a common and challenging issue when working with Artificial Intelligence solutions, especially those including Deep Learning (DL) models for tasks such as image classification. This is particularly relevant in healthcare scenarios, in which data collection requires a long-lasting process, involving specific control protocols. The performance of DL models is usually quantified by different classification metrics, which may provide biased results, due to the lack of sufficient data. In this paper, an innovative approach is proposed to evaluate the performance of DL models when labeled data is scarce. This approach, which aims to detect the poor performance provided by DL models, in spite of traditional assessing metrics indicating otherwise, is based on information theoretic concepts and motivated by the Information Bottleneck framework. This methodology has been evaluated by implementing several experimental configurations to classify samples from a plantar thermogram dataset, focused on early stage detection of diabetic foot ulcers, as a case study. The proposed network architectures exhibited high results in terms of classification metrics. However, as our approach shows, only two of those models are indeed consistent to generalize the data properly. In conclusion, a new methodology was introduced and tested to identify promising DL models for image classification over small datasets without relying exclusively on the widely employed classification metrics. Example code and supplementary material using a state-of-the-art DL model are available at <uri>https://github.com/mt4sd/PerformanceEvaluationScarceDataset</uri>.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Abi\u00e1n Hern\u00e1ndez-Guedes et al.",
      "keywords": "Computer science; Bottleneck; Artificial intelligence; Machine learning; Contextual image classification; Process (computing); Data mining; Image (mathematics); Deep learning; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3225107",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2969630114",
      "doi": "10.1109/access.2019.2937124",
      "title": "A Novel Synthetic CT Generation Method Using Multitask Maximum Entropy Clustering",
      "abstract": "Due to the risk of radiation from computed tomography (CT) scanning on the human body, the number of CT scans that can be performed on an individual each year is limited. However, CT images play a very important role in medical diagnosis. Therefore, this study proposes a method of generating synthetic CT to solve this problem. Considering that magnetic resonance imaging (MRI) is not harmful to the human body, there is no limit on the number of scans that can be performed with this procedure. In this paper, an image segmentation method is used to segment an MRI, and each segment is given a corresponding Hounsfield Unit (HU) value to finally generate a synthetic CT image. Since the image segmentation performance directly affects the generated synthetic CT image, this paper introduces a multitask learning strategy into a maximum entropy clustering (MEC) algorithm. A multitask maximum entropy clustering (MT-MEC) algorithm is proposed, which is used to effectively segment the MRI of the brain. The algorithm can use knowledge from multiple tasks to improve the learning ability of all tasks, and the MEC algorithm can effectively avoid interference from noise. The experimental results show that the proposed MT-MEC algorithm has good image segmentation performance, which results in reliable performance of the final synthetic CT image.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yizhang Jiang et al.",
      "keywords": "Cluster analysis; Computer science; Artificial intelligence; Hounsfield scale; Image segmentation; Segmentation; Pattern recognition (psychology); Entropy (arrow of time); Medical imaging; Principle of maximum entropy; Computer vision; Algorithm; Computed tomography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2937124",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285299565",
      "doi": "10.1109/access.2022.3187959",
      "title": "A Comprehensive Exploration of Neural Networks for Forensic Analysis of Adult Single Tooth X-Ray Images",
      "abstract": "Determining the demographic characteristics of a person post-mortem is a fundamental task for forensic experts, and the dental system is a crucial source of those information. Those characteristics, namely age and sex, can reliably be determined. The mandible and individual teeth survive even the harshest conditions, making them a prime target for forensic analysis. Current methods in forensic odontology rely on time-consuming manual measurements and reference tables, many of which rely on the correct determination of the tooth type. This study thoroughly explores the applicability of deep learning for sex assessment, age estimation, and tooth type determination from x-ray images of individual teeth. A series of models that use state-of-the-art feature extraction architectures and attention have been trained and evaluated. Their hyperparameters have been explored and optimized using a combination of grid and random search, totaling over a thousand experiments and 14076 hours of GPU compute time. Our dataset contains 86495 individual tooth x-ray image samples, with a subset of 7630 images having additional information about tooth alterations. The best-performing models are fine-tuned, the impact of tooth alterations is analyzed, and model performance is compared to current methods in forensic odontology literature. We achieve an accuracy of 76.41&#x0025; for sex assessment, a median absolute error of 4.94 years for age estimation, and an accuracy of 87.24&#x0025; to 99.15&#x0025; for tooth type determination. The constructed models are fully automated and fast, their results are reproducible, and the performance is equal to or better than current state-of-the-art methods in forensic odontology.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Denis Milo\u0161evi\u0107 et al.",
      "keywords": "Computer science; Hyperparameter; Artificial intelligence; Pattern recognition (psychology); Feature (linguistics); Artificial neural network; Deep learning; Feature extraction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3187959",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3196371155",
      "doi": "10.1109/access.2021.3109780",
      "title": "Improving Outcome Prediction for Traumatic Brain Injury From Imbalanced Datasets Using RUSBoosted Trees on Electroencephalography Spectral Power",
      "abstract": "Reliable prediction of traumatic brain injury (TBI) outcomes based on machine learning (ML) that is derived from quantitative electroencephalography (EEG) features has renewed interest in recent years. Nevertheless, the approach has suffered from imbalanced datasets. Hence, to get a reliable predictive model for predicting outcomes, specifically in a high proportion of moderate TBI with good outcomes, could be challenging. This work proposes an improved outcome predictive model that combines the absolute power spectral density (PSD) as input features for training random under-sampling boosting decision trees (RUSBoosted Trees) as a classifier. Resting-state, eyes-closed EEG data were obtained from 27 moderate TBI patients with follow-up visits. Patient outcome at 4&#x2013;10 weeks to 12-month was dichotomized based on the Glasgow Outcome Scale as poor (GOS score &#x2264; 4) and good outcomes (GOS score = 5). The predictive values of absolute PSD from five frequency bands: <inline-formula> <tex-math notation=\"LaTeX\">$\\delta $ </tex-math></inline-formula> (0.5-4Hz), <inline-formula> <tex-math notation=\"LaTeX\">$\\theta $ </tex-math></inline-formula> (4-7Hz), <inline-formula> <tex-math notation=\"LaTeX\">$\\alpha $ </tex-math></inline-formula> (7-13Hz), <inline-formula> <tex-math notation=\"LaTeX\">$\\beta $ </tex-math></inline-formula> (13-30Hz) and <inline-formula> <tex-math notation=\"LaTeX\">$\\gamma $ </tex-math></inline-formula> (30&#x2013;100Hz) were evaluated to identify the most informative predictors for reliable prediction outcomes. RUSBoosted Trees performed best at discriminating patients into two outcomes categories (G-Mean &#x003D; 92.95&#x0025;, TP<sub>rate</sub> &#x003D; 100&#x0025;, TN<sub>rate</sub> &#x003D; 86.4&#x0025;) of absolute PSD in <inline-formula> <tex-math notation=\"LaTeX\">$\\delta $ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$\\gamma $ </tex-math></inline-formula> bands, which was excellent compared to the other state-of-the-art methods. The highest area under the curve (AUC) of absolute PSD in <inline-formula> <tex-math notation=\"LaTeX\">$\\delta $ </tex-math></inline-formula> (AUC<inline-formula> <tex-math notation=\"LaTeX\">$_\\delta =0.97$ </tex-math></inline-formula>) and <inline-formula> <tex-math notation=\"LaTeX\">$\\gamma $ </tex-math></inline-formula> (AUC<inline-formula> <tex-math notation=\"LaTeX\">$_\\gamma =0.95$ </tex-math></inline-formula>) revealed their predictive values as robust prognostic markers for prediction outcomes. The RUSBoosted Trees presents a promising result in prognosis prediction of highly imbalanced data, making it an accessible prediction tool for clinical decision-making, unlike the black-box approaches.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Nor Safira Elaina Mohd Noor et al.",
      "keywords": "Random forest; Traumatic brain injury; Glasgow Outcome Scale; Electroencephalography; Decision tree; Artificial intelligence; Classifier (UML); Computer science; Outcome (game theory); Predictive modelling; Statistics; Machine learning; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3109780",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4383960237",
      "doi": "10.1109/tmi.2023.3294248",
      "title": "Collaborative Multi-Metadata Fusion to Improve the Classification of Lumbar Disc Herniation",
      "abstract": "Computed tomography (CT) images are the most commonly used radiographic imaging modality for detecting and diagnosing lumbar diseases. Despite many outstanding advances, computer-aided diagnosis (CAD) of lumbar disc disease remains challenging due to the complexity of pathological abnormalities and poor discrimination between different lesions. Therefore, we propose a Collaborative Multi-Metadata Fusion classification network (CMMF-Net) to address these challenges. The network consists of a feature selection model and a classification model. We propose a novel Multi-scale Feature Fusion (MFF) module that can improve the edge learning ability of the network region of interest (ROI) by fusing features of different scales and dimensions. We also propose a new loss function to improve the convergence of the network to the internal and external edges of the intervertebral disc. Subsequently, we use the ROI bounding box from the feature selection model to crop the original image and calculate the distance features matrix. We then concatenate the cropped CT images, multiscale fusion features, and distance feature matrices and input them into the classification network. Next, the model outputs the classification results and the class activation map (CAM). Finally, the CAM of the original image size is returned to the feature selection network during the upsampling process to achieve collaborative model training. Extensive experiments demonstrate the effectiveness of our method. The model achieved 91.32% accuracy in the lumbar spine disease classification task. In the labelled lumbar disc segmentation task, the Dice coefficient reaches 94.39%. The classification accuracy in the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) reaches 91.82%.",
      "year": "2023",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Shuyi Lu et al.",
      "keywords": "Computer science; Artificial intelligence; Feature (linguistics); Convolutional neural network; Pattern recognition (psychology); Feature selection; Computer-aided diagnosis; Contextual image classification; Minimum bounding box; Feature extraction; S\u00f8rensen\u2013Dice coefficient; Segmentation; Image segmentation; Computer vision; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2023.3294248",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391216255",
      "doi": "10.1109/access.2024.3358423",
      "title": "A Review of Subjective Scales Measuring the User Experience of Voice Assistants",
      "abstract": "The use of Voice Assistants (VA) in both commercial and personal contexts has experienced significant growth, emphasizing the importance of assessing their user experience (UX) for long-term viability. Currently, the development of appropriate scales that capture user viewpoints after interacting with a system has become a popular method for measuring UX of the Graphical User Interface (GUI) systems. However, the applicability of these scales that are meant for GUI systems on VA is still questionable, hence the need for analyzing the nature of previous scales used for measuring UX of VA. Additionally, in order to keep track of the state of UX research in the VA domain, it is crucial to understand the dimensions of UX that are being utilized. In this study, a comprehensive Systematic Literature Review (SLR) was carried out to identify 21 individual scales used for measuring UX of VA. Furthermore, this study present the evaluation criteria for assessing the rigor of operationalization during the development of these scales. The study analysis reveals that the scales used for measuring UX of VA extends beyond the traditional VUDA (value, usability, desirability, adoptability) principles and incorporates novel aspects such as anthropomorphism and machine personality. Future VA UX researchers should also acknowledge the variations in the rigorous measures employed during scale development, notwithstanding some common and accepted practices. Consequently, an overview is provided, along with suggestions for prospective studies in the field of VA UX research.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Lawal Ibrahim Dutsinma Faruk et al.",
      "keywords": "Computer science; Human\u2013computer interaction; Speech recognition; Multimedia",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3358423",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392932753",
      "doi": "10.1109/ojsp.2024.3378595",
      "title": "An Overview of the ADReSS-M Signal Processing Grand Challenge on Multilingual Alzheimer's Dementia Recognition Through Spontaneous Speech",
      "abstract": "The ADReSS-M Signal Processing Grand Challenge was held at the 2023 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2023. The challenge targeted difficult automatic prediction problems of great societal and medical relevance, namely, the detection of Alzheimer's Dementia (AD) and the estimation of cognitive test scoress. Participants were invited to create models for the assessment of cognitive function based on spontaneous speech data. Most of these models employed signal processing and machine learning methods. The ADReSS-M challenge was designed to assess the extent to which predictive models built based on speech in one language generalise to another language. The language data compiled and made available for ADReSS-M comprised English, for model training, and Greek, for model testing and validation. To the best of our knowledge no previous shared research task investigated acoustic features of the speech signal or linguistic characteristics in the context of multilingual AD detection. This paper describes the context of the ADReSS-M challenge, its data sets, its predictive tasks, the evaluation methodology we employed, our baseline models and results, and the top five submissions. The paper concludes with a summary discussion of the ADReSS-M results, and our critical assessment of the future outlook in this field.",
      "year": "2024",
      "journal": "IEEE Open Journal of Signal Processing",
      "authors": "Saturnino Luz et al.",
      "keywords": "Dementia; SIGNAL (programming language); Speech recognition; Computer science; Natural language processing; Psychology; Medicine; Disease; Programming language; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojsp.2024.3378595",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285214285",
      "doi": "10.1109/access.2022.3185615",
      "title": "Assessing the Reidentification Risks Posed by Deep Learning Algorithms Applied to ECG Data",
      "abstract": "ECG (Electrocardiogram) data analysis is one of the most widely used and important tools in cardiology diagnostics. In recent years the development of advanced deep learning techniques and GPU hardware have made it possible to train neural network models that attain exceptionally high levels of accuracy in complex tasks such as heart disease diagnoses and treatments. We investigate the use of ECGs as biometrics in human identification systems by implementing state-of-the-art deep learning models. We train convolutional neural network models on approximately 81k patients from the US, Germany and China. Currently, this is the largest research project on ECG identification. Our models achieved an overall accuracy of 95.69%. Furthermore, we assessed the accuracy of our ECG identification model for distinct groups of patients with particular heart conditions and combinations of such conditions. For example, we observed that the identification accuracy was the highest (99.7%) for patients with both ST changes and supraventricular tachycardia. We also found that the identification rate was the lowest for patients diagnosed with both atrial fibrillation and complete right bundle branch block (49%). We discuss the implications of these findings regarding the reidentification risks of patients based on ECG data and how seemingly anonymized ECG datasets can cause privacy concerns for the patients.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Arin Ghazarian et al.",
      "keywords": "Deep learning; Artificial intelligence; Computer science; Convolutional neural network; Medical diagnosis; Machine learning; Identification (biology); Biometrics; Atrial fibrillation; Ventricular tachycardia; Right bundle branch block; Supraventricular tachycardia; Electrocardiography; Algorithm; Tachycardia; Internal medicine; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3185615",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385338801",
      "doi": "10.1109/tetci.2023.3297841",
      "title": "Memristor-Based CNNs for Detecting Stress Using Brain Imaging Signals",
      "abstract": "Typical convolutional neural networks (CNNs) are widely used to recognize a user's stress state using the functional near-infrared spectroscopy (fNIRS), which is the latest brain imaging technology. fNIRS signals are usually fed into CNN models in the form of high-dimensional image data. However, this approach is not easy to achieve high classification accuracy because of physiological noises in brain signals. It is also likely to overlook the process of evaluating the reliability of calculated classification accuracy. To solve these problems, we proposed a memristor-based CNN (M-CNNs) This model's weight update process involves using stochastic gradient descent with momentum (SGDM), where the normalized conductances of memristors are used as weight substitutes. These conductances are then adjusted to classify stress states. We calculated the classification accuracies between the control and stress groups by using the M-CNNs, and then compared them with those of the CNNs. We used DenseNet, the most recent CNN model, to simulate accuracy under the same conditions. To ensure a fair comparison, we divided the DenseNet into the memristor-based DenseNet (M-DenseNet) and the conventional DenseNet (C-DenseNet). As a result, we discovered that the accuracy of M-CNNs (93.33%) exceeded that of CNNs (87.50%), and is reliable by precision, recall, and F-Score calculated from a confusion matrix. Likewise, M-DenseNet (92.38%) has higher accuracy than C-DenseNet (90.00%), but shows lower accuracy than M-CNNs. Moreover, we observed the reproducibility of M-CNN/DenseNet in various datasets. Therefore, our study suggests a promising application of CNN by combining conductances of memristor for classifying stress states.",
      "year": "2023",
      "journal": "IEEE Transactions on Emerging Topics in Computational Intelligence",
      "authors": "SuJin Bak et al.",
      "keywords": "Neuroimaging; Artificial intelligence; Stress (linguistics); Neuroscience; Computer science; Pattern recognition (psychology); Psychology; Philosophy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tetci.2023.3297841",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3014184668",
      "doi": "10.1109/access.2020.2984657",
      "title": "A Parametric Optimization Oriented, AFSA Based Random Forest Algorithm: Application to the Detection of Cervical Epithelial Cells",
      "abstract": "Cervical cancer is one of the most common cancers among women in the world, over 570,000 patients are affected annually. Pathological examination for patients using Pap Smear becomes the mainstream of cervical cancer diagnoses. Accurate diagnoses and analyses largely rely on 3 factors: cell segmentation, feature extraction and selection as well as classification. Firstly, a 2-layer segmentation algorithm based on block Maximum Between-Class Variance (Otsu) and Gradient Vector Flow (GVF) Snake model is applied to obtain regions of interest (ROI). Then the features of chroma, shape and texture are extracted and selected for a better classification performance. The random forest algorithm based on Artificial Fish Swarms Algorithm (AFSA) is used to recognize and classify cervical epithelial cells. The proposed methods were tested on 200 cervical Pap Smear images. Experimental results show that cervical cells can be segmented with an effective segmentation result. The proposed feature selection method achieved an accuracy of 81.31% with the minimum feature number. The improved random forest algorithm with 2 and 7 classification under fivefold cross-validation reaches the highest classification accuracy (96.86%). Experimental results showed that the proposed method has obvious recognition advantages, and thus provides a practical classification frame for the diagnoses of cervical cancer.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Dongyao Jia et al.",
      "keywords": "Random forest; Computer science; Artificial intelligence; Segmentation; Feature selection; Pattern recognition (psychology); Medical diagnosis; Feature extraction; Image segmentation; Cervical cancer; Otsu's method; Algorithm; Feature (linguistics); Cancer; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2984657",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391582581",
      "doi": "10.1109/jstars.2024.3362936",
      "title": "EXNet: (2+1)D Extreme Xception Net for Hyperspectral Image Classification",
      "abstract": "3-D CNNs have demonstrated their capability to capture intricate nonlinear relationships within hyperspectral images (HSIs). However, the computational complexity of 3-D CNNs often leads to slower processing speeds, limited generalization, and susceptibility to overfitting. In response to these challenges, this study introduces the concept of depthwise separable convolutions using (2+1)-D convolutions as an alternative to traditional 3-D convolutions for hyperspectral image classification (HSIC). The study observes that (2+1)-D convolutions can effectively approximate the complex relationships represented by 3-D convolutions while requiring fewer convolutional operations, thereby reducing the computational overhead associated with classification. Experimental results obtained from benchmark HSI datasets, including Indian Pines, Botswana, Pavia University, and Salinas, demonstrate that the proposed model yields results that are comparable to those achieved by various state-of-the-art models in the existing literature.",
      "year": "2024",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Usman Ghous et al.",
      "keywords": "Hyperspectral imaging; Computer science; Overfitting; Benchmark (surveying); Generalization; Artificial intelligence; Computational complexity theory; Pattern recognition (psychology); Extreme learning machine; Overhead (engineering); Image (mathematics); Code (set theory); Contextual image classification; Convolutional neural network; Source code; Convolution (computer science); Algorithm; Mathematics; Artificial neural network; Set (abstract data type)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2024.3362936",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285297290",
      "doi": "10.1109/access.2022.3190102",
      "title": "Feature Modeling for Interpretable Low Back Pain Classification Based on Surface EMG",
      "abstract": "Low back pain (LBP) is a global health-problem phenomenon. Most patients are categorized as non-specific, thus requiring an individualized approach which still poses a major challenge. In this paper, sEMG recordings from two pairs of lumbar muscle sites were collected during an isometric trunk extension exercise. Ninety-one subjects were included in the study; 29 patients with non-specific chronic LBP (CLBP), 25 patients with radiculopathy (RLBP), and 37 control healthy subjects (HS). Six best-performing time-domain raw features were employed to model contextual secondary feature groups. Neuromuscular LBP characteristics were described with coordination, co-activation, trends, and fatigue measures. Altogether, a set of 327 secondary features was created where inputs into the classification models were further refined by employing neighborhood component analysis (NCA). NCA effectively reduced the number of features (&#x003C;20 components), alongside preserving them in the original interpretable domain. A set of 23 different classifiers was employed and explored, resulting in classification accuracy of 0.94 for HS vs. LBP, 0.89 for HS vs. CLBP, 0.98 for HS vs. RLBP, and 0.89 for CLBP vs. RLBP differentiation. High median precision (0.97) and sensitivity (0.99) across all classifiers for HS vs. RLBP differentiation was obtained, with only three feature components utilized (out of 327). Support vector machines (SVM) and <inline-formula> <tex-math notation=\"LaTeX\">${k}$ </tex-math></inline-formula>-nearest neighbor (<inline-formula> <tex-math notation=\"LaTeX\">${k}$ </tex-math></inline-formula>NN) based classifiers consistently demonstrated best classification results. Different profiles of CLBP patients were presented and discussed. The suggested method demonstrated the potential for patients&#x2019; subgrouping and subsequent more individualized rehabilitation treatments, backed by medical interpretations through feature modeling.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Vedran Srhoj-Egekher et al.",
      "keywords": "Low back pain; Support vector machine; Artificial intelligence; Pattern recognition (psychology); Feature (linguistics); Isometric exercise; Local binary patterns; Computer science; Trunk; Feature vector; Set (abstract data type); Domain (mathematical analysis); Medicine; Physical medicine and rehabilitation; Mathematics; Physical therapy; Histogram; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3190102",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3005841154",
      "doi": "10.1109/access.2020.2973898",
      "title": "Multi-Set Canonical Correlation Analysis for 3D Abnormal Gait Behaviour Recognition Based on Virtual Sample Generation",
      "abstract": "Small sample dataset and two-dimensional (2D) approach are challenges to vision-based abnormal gait behaviour recognition (AGBR). The lack of three-dimensional (3D) structure of the human body causes 2D based methods to be limited in abnormal gait virtual sample generation (VSG). In this paper, 3D AGBR based on VSG and multi-set canonical correlation analysis (3D-AGRBMCCA) is proposed. First, the unstructured point cloud data of gait are obtained by using a structured light sensor. A 3D parametric body model is then deformed to fit the point cloud data, both in shape and posture. The features of point cloud data are then converted to a high-level structured representation of the body. The parametric body model is used for VSG based on the estimated body pose and shape data. Symmetry virtual samples, pose-perturbation virtual samples and various body-shape virtual samples with multi-views are generated to extend the training samples. The spatial-temporal features of the abnormal gait behaviour from different views, body pose and shape parameters are then extracted by convolutional neural network based Long Short-Term Memory model network. These are projected onto a uniform pattern space using deep learning based multi-set canonical correlation analysis. Experiments on four publicly available datasets show the proposed system performs well under various conditions.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jian Luo et al.",
      "keywords": "Point cloud; Computer science; Artificial intelligence; Pattern recognition (psychology); Gait; Convolutional neural network; Gait analysis; Canonical correlation; Parametric statistics; Data set; Computer vision; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2973898",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4365790463",
      "doi": "10.1109/access.2023.3266983",
      "title": "DrOGA: An Artificial Intelligence Solution for Driver-Status Prediction of Genomics Mutations in Precision Cancer Medicine",
      "abstract": "Precision cancer medicine suggests that better cancer treatments would be possible guiding therapies by tumor\u2019s genomics alterations. This hypothesis boosted exome sequencing studies, collection of cancer variants databases and developing of statistical and Machine Learning-driven methods for alterations\u2019 analysis. In order to extract relevant information from huge exome sequencing data, accurate methods to distinguish driver and neutral or passengers mutations are vital. Nevertheless, traditional variant classification methods have often low precision in favour of higher recall. Here, we propose several traditional Machine Learning and new Deep Learning techniques to finely classify driver somatic non-synonymous mutations based on a 70-features annotation, derived from medical and statistical tools. We collected and annotated a complete database containing driver and neutral alterations from various public data sources. Our framework, called Driver-Oriented Genomics Analysis (DrOGA), presents the best performances compared to individual and other ensemble methods on our data. Explainable Artificial Intelligence is used to provide visual and clinical explanation of the results, with a particular focus on the most relevant annotations. This analysis and the proposed tool, along with the collected database and the feature engineering pipeline suggested, can help the study of genomics alterations in human cancers allowing precision oncology targeted therapies based on personal data from next-generation sequencing.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Matteo Bastico et al.",
      "keywords": "Computer science; Genomics; Exome sequencing; Precision medicine; Artificial intelligence; Exome; Annotation; Machine learning; Precision and recall; Big data; Personalized medicine; Deep learning; Mutation; Data mining; Bioinformatics; Genome; Biology; Genetics; Gene",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3266983",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392449791",
      "doi": "10.1109/access.2024.3374208",
      "title": "Improving Air Quality Zoning Through Deep Learning and Hyperlocal Measurements",
      "abstract": "According to the Air Quality Directive 2008/50/EC, air quality zoning divides a territory into air quality zones where pollution and citizen exposure are similar and can be monitored using similar strategies. However, there is no standardized computational methodology to solve this problem, and only a few experiences in the Comunidad of Madrid based on chemistry transport models. In this study, we propose a methodological improvement based on the application of deep learning. Our method uses the CHIMERE-WRF air quality modelling system and adds a step that uses neural networks architectures to calibrate the simulations. We have validated our method in the Region of Murcia. The results obtained are promising given the values of the Pearson coefficient, obtaining <inline-formula> <tex-math notation=\"LaTeX\">$r = 0.94$ </tex-math></inline-formula> for <inline-formula> <tex-math notation=\"LaTeX\">$NO_{2}$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$r = 0.95$ </tex-math></inline-formula> for <inline-formula> <tex-math notation=\"LaTeX\">$O_{3}$ </tex-math></inline-formula>, improving 86 &#x0025; and 29 &#x0025; the performances reported in the state of the art. In addition, the cluster score improves after applying neural networks, demonstrating that neural networks improve the consistency of clusters compared to the current air quality zoning. This opened new research opportunities based on the use of neural networks for dimension reduction in spatial clustering problems, and we were able to provide recommendations for a new measurement point in the Region of Murcia Air Quality Network.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Eduardo Illueca Fern\u00e1ndez et al.",
      "keywords": "Air quality index; Computer science; Artificial intelligence; Quality (philosophy); Algorithm; Geography; Meteorology; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3374208",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226343336",
      "doi": "10.1109/access.2022.3159923",
      "title": "Ensemble Convolutional Neural Networks With Support Vector Machine for Epilepsy Classification Based on Multi-Sequence of Magnetic Resonance Images",
      "abstract": "Classification of brain abnormalities as a pathological cue of epilepsy based on magnetic resonance (MR) images is essential for diagnosis. There are some types of brain structural abnormalities as a pathological cue of epilepsy. To identify it, a neurologist can involve some sequence of MR images at a time. Existing algorithms for abnormalities classification usually involve only one or two sequences of MR images. In this paper, we proposed ensemble convolutional neural networks with a support vector machine (SVM) scheme to classify brain abnormalities (epilepsy) vs. non-epilepsy based on the axial multi-sequence of MR images. The convolutional neural network (CNN) models on the proposed method are base-learner models with different architectures and have low parameters. The performance improvement on the proposed method is made by combining the output of the base-learner models and the combination of predictions from these models. The combination of predictions uses majority voting, weighted majority voting, and weighted average. Henceforth, the combined output becomes input in the meta-learning process with SVM for the final classification. The dataset for evaluation is the axial multi-sequences of MR images that include abnormal brain structures causing epilepsy and non-epilepsy with various subjects&#x2019; histories. The experimental results show the proposed method can obtain an accuracy average and F<sub>1</sub>-score of 86.37&#x0025; and 90.75&#x0025;, respectively, and an improvement of accuracy of 6.7&#x0025;-18.19&#x0025; against the CNN models on the base-learner and 2.54&#x0025;-2.65&#x0025; against the combination of predictions. With these results, the proposed architecture also provides better performance compared to the two existing CNN architectures.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Irwan Budi Santoso et al.",
      "keywords": "Support vector machine; Epilepsy; Artificial intelligence; Convolutional neural network; Computer science; Pattern recognition (psychology); Magnetic resonance imaging; Sequence (biology); Artificial neural network; Majority rule; Contextual image classification; Machine learning; Image (mathematics); Neuroscience; Medicine; Radiology; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3159923",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323022324",
      "doi": "10.1109/access.2023.3250770",
      "title": "Technology Dependency and Impact During COVID-19: A Systematic Literature Review and Open Challenges",
      "abstract": "The COVID-19 pandemic is still a challenge in many countries, although life must proceed while ensuring the pandemic is managed critically. Due to the delay in producing permanent medical intervention, despite the availability of vaccines, there is still a need to depend on technology in performing several tasks. A systematic literature review that provides comprehensive evidence on technology dependence and the impact of technology on individuals during the pandemic is lacking. This study systematically reviewed scholarly works related to technology dependency from a broad view since the pandemic and mapped the research findings into a taxonomy, thus establishing the trend in technology type, major areas of technology dependency, and the impact of technology during the pandemic. The mapped taxonomy is used to expound on open challenges and recommendations. The final set from the systematic search was 76 articles. Technology might be an avenue for administering and enhancing health services, improving outreaches, and supporting curbing the spread of diseases. However, the impact of technology dependence is both positive and negative. A systematic mapping was conducted to explore the literature on the impacts of technology, where there is a need for further research. Notwithstanding the category, most of the reviewed articles emphasized the usage and impact of technology at such a time of the pandemic and provided insights on the manner of addressing them. Realistically, there has been an acceleration of digitalization trends in the present era of the COVID-19 pandemic and the possibility of rapid development of novel digital technologies.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Azah Anir Norman et al.",
      "keywords": "Pandemic; Dependency (UML); Systematic review; Coronavirus disease 2019 (COVID-19); Computer science; Health technology; Open research; Data science; Intervention (counseling); Knowledge management; Business; Health care; Political science; MEDLINE; Medicine; Infectious disease (medical specialty); World Wide Web; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3250770",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3197612120",
      "doi": "10.1109/tnsre.2021.3111989",
      "title": "Recognition of Dementia Biomarkers With Deep Finer-DBN",
      "abstract": "The treatment of neurodegenerative diseases is expensive, and long-term treatment makes families bear a heavy burden. Accumulating evidence suggests that the high conversion rate can possibly be reduced if clinical interventions are applied at the early stage of brain diseases. Thus, a variety of deep learning methods are utilized to recognize the early stages of neurodegenerative diseases for clinical intervention and treatment. However, most existing methods have ignored the issue of sample imbalance, which often makes it difficult to train an effective model due to lack of a large number of negative samples. To address this problem, we propose a two-stage method, which is used to learn the compression and recover rules of normal subjects so that potential negative samples can be detected. The experimental results show that the proposed method can not only obtain a superb recognition result, but also give an explanation that conforms to the physiological mechanism. Most importantly, the deep learning model does not need to be retrained for each type of disease, which can be widely applied to the diagnosis of various brain diseases. Furthermore, this research could have great potential in understanding regional dysfunction of various brain diseases.",
      "year": "2021",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Zhengwang Xia et al.",
      "keywords": "Dementia; Artificial intelligence; Mechanism (biology); Disease; Intervention (counseling); Computer science; Deep learning; Neuroscience; Machine learning; Medicine; Psychology; Pathology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2021.3111989",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285240656",
      "doi": "10.1109/access.2022.3190373",
      "title": "Organisational Privacy Culture and Climate: A Scoping Review",
      "abstract": "New regulations worldwide are increasingly pressing organisations to review how they collect and process personal data to ensure the protection of individual privacy rights. This organisational transformation involves implementing several privacy practices (e.g., privacy policies, governance frameworks, and privacy-by-design methods) across multiple departments. The literature points to a strong influence of the organisations&#x2019; culture and climate in implementing such privacy practices, depending on how leaders and employees perceive and address privacy concerns. However, this new hybrid topic referred to as Organisational Privacy Culture and Climate (OPCC), remains poorly demarcated and weakly defined. In this paper, we report a Scoping Review (ScR) on the topic of OPCC to systematically identify and map studies, contributing with a synthesis of the existing work, distinguishing core and adjacent publications, research gaps, and pathways of future research. This ScR includes 36 studies categorised according to their demographics, research types, contribution types, research designs, proposed definitions, and conceptualisations. Also, 18 studies categorised as primary research were critically appraised, assessing the studies&#x2019; methodological quality and credibility of the evidence. Although published research has significantly advanced the topic of OPCC, more research is still needed. Our findings show that the topic is still in its embryonic stage. The theory behind OPCC has not yet been fully articulated, even though some definitions have been independently proposed. Only one measuring instrument for privacy culture was identified, but it needs to be further developed in terms of identifying and analysing its factors, and evaluating its validity and reliability. Initiatives of future research in OPCC will require interdisciplinary research efforts and close cooperation with industry to further propose and rigorously evaluate instruments. Only then OPCC would be considered an evidence-based research topic that can be reliably used to evaluate, measure, and embed privacy in organisations.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Leonardo Horn Iwaya et al.",
      "keywords": "Credibility; Privacy policy; Information privacy; Privacy by Design; Public relations; Knowledge management; Process (computing); Computer science; Business; Internet privacy; Political science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3190373",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2967271816",
      "doi": "10.1109/access.2019.2935691",
      "title": "A Resource Aware Parallelized Back Propagation Neural Network in Enabling Efficient Large-Scale Digital Health Data Processing",
      "abstract": "Along with the development of digital health, ef\ufb01cient machine learning is anxiously needed to handle the growing health data. Among various machine learning algorithms, back propagation neural network (BPNN) shows great effectiveness in both academia and industrial \ufb01elds. However, it is frequently reported that the conventional BPNN algorithm encounters low ef\ufb01ciency issue in dealing with large-scale digital health data. Therefore this paper presents a Hadoop based parallelized BPNN algorithm which is able to process the large-scale data ef\ufb01ciently. In order to complement the potential accuracy loss issue for the parallelized data processing, ensemble learning techniques are also involved. Additionally although Hadoop supplies a number of default schedulers, the heterogeneous distributed computing environment may still impact the ef\ufb01ciency of the parallelized BPNN. Consequently, this paper also presents a gene expression programming (GEP) algorithm based load balancing approach, which enables the computing resource awareness and the optimal scheduling of the parallelized BPNN. The experiments employ the classi\ufb01cation task as the underlying testing basis. Two types of the experiments are carried out, in which the \ufb01rst one focuses on evaluating the accuracy of the presented algorithm with classifying the benchmark dataset; the second one focuses on evaluating the ef\ufb01ciency of the presented algorithm with classifying the large-scale dataset. The experimental results show the effectiveness of the presented resource aware parallelized BPNN algorithm.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yang Liu et al.",
      "keywords": "Computer science; Artificial neural network; Scale (ratio); Backpropagation; Resource (disambiguation); Data processing; Artificial intelligence; Distributed computing; Computer architecture; Computer network; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2935691",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4213434993",
      "doi": "10.1109/access.2022.3153357",
      "title": "Multi-Scale Part-Based Syndrome Classification of 3D Facial Images",
      "abstract": "Identification and delineation of craniofacial characteristics support the clinical and molecular diagnosis of genetic syndromes. Deep learning (DL) frameworks for syndrome identification from 2D facial images are trained on large clinical datasets using standard convolutional neural networks for classification. In contrast, despite the increased availability of 3D scanners in clinical setups, similar frameworks remain absent for 3D facial photographs. The main challenges involve working with smaller datasets and the need for DL operations applicable to 3D geometric data. Therefore, to date, most 3D methods refrain from working across multiple syndromic groups and/or are solely based on traditional machine learning. The first contribution of this work is the use of geometric deep learning with spiral convolutions in a triplet-loss architecture. This geometric encoding (GE) learns a lower dimensional metric space from 3D facial data that is used as input to linear discriminant analysis (LDA) performing multiclass classification. Benchmarking is done against principal component analysis (PCA), a common technique in 3D facial shape analysis, and related work based on 65 distinct 3D facial landmarks as input to LDA. The second contribution of this work involves a part-based implementation to 3D facial shape analysis and multi-class syndrome classification, and this is applied to both GE and PCA. Based on 1,786 3D facial photographs of controls and individuals from 13 different syndrome classes, a five-fold cross-validation was used to investigate both contributions. Results indicate that GE performs better than PCA as input to LDA, and this especially so for more compact (lower dimensional) spaces. In addition, a part-based approach increases performance significantly for both GE and PCA, with a more significant improvement for the latter. I.e., this contribution enhances the power of the dataset. Finally, and interestingly, according to ablation studies within the part-based approach, the upper lip is the most distinguishing facial segment for classifying genetic syndromes in our dataset, which follows clinical expectation. This work stimulates an enhanced use of advanced part-based geometric deep learning methods for 3D facial imaging in clinical genetics.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Soha Sadat Mahdi et al.",
      "keywords": "Artificial intelligence; Computer science; Pattern recognition (psychology); Principal component analysis; Linear discriminant analysis; Convolutional neural network; Deep learning; Identification (biology); Feature extraction; Benchmarking",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3153357",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285172643",
      "doi": "10.1109/access.2022.3186888",
      "title": "A Binary Classification Study of Alzheimer\u2019s Disease Based on a Novel Subclass Weighted Logistic Regression Method",
      "abstract": "Based on proposed joint human connectome project multi-modal parcellation (JHCPMMP), the study on the binary classification of Alzheimer&#x2019;s disease was conducted. We tried to build a novel classification model, which can be interpretative and have the ability to deal with the complexity and individual differences of brain networks. The subclass weighted logistic regression (SWLR) based on logistic regression was proposed in this paper. We conducted five groups of experiments, in which the accuracy of HC vs. AD was 95.8&#x0025;, HC vs. EMCI was 91.6&#x0025;, HC vs. LMCI was 93.7&#x0025;, EMCI vs. LMCI was 89.5&#x0025;, and LMCI vs. AD was 91.6&#x0025;. In addition, we conducted a follow-up analysis of the coefficient matrix and found that the distribution of core deterioration brain regions in different stages is different in the development of Alzheimer&#x2019;s disease. We located these brain regions in two-dimensional images and found that they generally show a trend of continuous counterclockwise migration.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Jinhua Sheng et al.",
      "keywords": "Logistic regression; Pattern recognition (psychology); Subclass; Computer science; Artificial intelligence; Alzheimer's disease; Binary classification; Bivariate analysis; Statistics; Disease; Mathematics; Medicine; Pathology; Support vector machine; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3186888",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285246061",
      "doi": "10.1109/access.2022.3178847",
      "title": "Integration Design of Portable ECG Signal Acquisition With Deep-Learning Based Electrode Motion Artifact Removal on an Embedded System",
      "abstract": "For long-term electrocardiogram (ECG) signal monitoring, a portable and small size acquisition device with Bluetooth low energy (BLE) communication is designed and integrated with a Nvidia Jetson Xavier NX for realizing the electrode motion artifact removal technique. The digitalized ECG codes are converted from a front-end circuit, which contains several amplifiers and filters in the acquisition system. Thereafter, a zero padding scheme is applied for each 10-bits data to separate them into two-bytes data for BLE transmission. Xavier Edge AI platform receives these transmitted data and removes the electrode motion (EM) noise using the proposed low memory shortcut connection-based denoised autoencoder (LMSC-DAE). The simulation results demonstrate that the proposed algorithm significantly improves the signal-to-noise ratio (SNR) by 5.41 dB under the condition of SNR<sub>in</sub> &#x003D; 12 dB, compared with convolutional denoising autoencoder with long short-term memory (CNN-LSTM-DAE) method. For practical test, an Arduino DUE platform is employed to generate noise interference by controlling a commercial digital-to-analog convertor. By combining the proposed ECG acquisition device with a non-inverting weighted summer, it can be applied to verify the reproducibility of measurement for the proposed method. The measurement results clearly indicate that the proposed LMSC-DAE has a higher improvement of SNR and lower percentage root-mean-square difference than the state-of-the-art Fully Convolutional Denoising Autoencoder (FCN-DAE).",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Yu-Syuan Jhang et al.",
      "keywords": "Computer science; Noise reduction; Noise (video); Artifact (error); Data acquisition; Artificial intelligence; SIGNAL (programming language); Computer hardware; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3178847",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392406267",
      "doi": "10.1109/access.2024.3373558",
      "title": "Attention and Meta-Heuristic Based General Self-Efficacy Prediction Model From Multimodal Social Media Dataset",
      "abstract": "General Self-Efficacy (GSE) is a vital attribute of human psychology that describes one&#x2019;s belief about his own ability to succeed in specific situations. GSE is composed of cognitive, social, and behavioral skills of an individual. In this research, we first develop a GSE classification model by using Facebook content (i.e., profile photos and statuses). We collect data from a total of 435 Facebook users in an ethical data collection manner. Two hybrid machine learning methods are applied based on distinct feature extraction approaches: tool-based and deep learning-based. In our tool-based approach, we employ Linguistic Inquiry and Word Count (LIWC) and Bidirectional Encoder Representations from Transformers (BERT) for text and Mediapipe and DeepFace for image feature extraction. We apply Particle Swarm Optimization (PSO) for feature selection, resulting in a robust tabular dataset with high predictive performance for GSE scores. In the deep learning-based approach, we apply BERT and 1-dimensional convolutional neural network (1D-CNN) for text feature extraction, while UNet++ handles image segmentation, and VGG16 and ResNet-152 contribute image features, fused via Canonical Correlation Analysis (CCA). We also integrate a co-attention model for image and text features. Traditional machine learning models, including Random Forest (RF), Xgboost, AdaBoost, and Stacking, are then trained on the feature set to predict GSE scores. This comprehensive model showcases a multifaceted approach to GSE prediction, combining tool-based and deep learning methodologies for enhanced accuracy and insights. Then, we develop a GSE prediction model by using the mentioned tool-based (i.e., LIWC, BERT, Mediapipe, and DeepFace) and deep learning-based feature extraction methods from both image and text datasets. The tool-based model achieves remarkable accuracy percentages of 85.80&#x0025; (text), 91.06&#x0025; (image), and an outstanding 93.25&#x0025; for the hybrid model. The deep learning-based model exhibits competitive results, with accuracies of 64.80&#x0025; (text), 73.06&#x0025; (image), and 81.87&#x0025; for the hybrid model.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Md. Saddam Hossain Mukta et al.",
      "keywords": "Computer science; Social media; Heuristic; Artificial intelligence; Machine learning; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3373558",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2922420945",
      "doi": "10.1109/access.2019.2904143",
      "title": "Hippocampal Segmentation From Longitudinal Infant Brain MR Images via Classification-Guided Boundary Regression",
      "abstract": "Hippocampal segmentation from infant brain MR images is indispensable for studying early brain development. However, most of the hippocampal segmentation methods were developed for population-based adult brain images, which are not suitable for longitudinal infant brain images acquired in the first year of life due to the low image contrast and variable development patterns of the hippocampal structure. To address these challenges, we propose a classification-guided boundary regression method to first detect hippocampal boundaries in the longitudinal infant brain images and then use those detected boundaries to guide the deformable model for final segmentation. Specifically, we first employ a classification-guided regression forest to predict the 3D displacements from individual image voxels to the potential hippocampal boundaries. These predicted displacements then determine the boundary maps by a voting strategy. Second, we iteratively enhance the voted hippocampal boundary map by incorporating the spatial context information given the tentative boundary estimation of the current time point. Besides, the longitudinal context information from all time points of the temporal sequence of the same subject (i.e., given their tentative segmentation results) is also utilized to facilitate accurate segmentation. Finally, a deformable model is applied to the enhanced voted boundary maps for achieving the longitudinal hippocampal segmentation. The experiments on infant brain MR images acquired from 2-week-old to 1-year-old show promising hippocampal segmentation results, indicating the applicability of our method in early brain development study.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yeqin Shao et al.",
      "keywords": "Segmentation; Artificial intelligence; Hippocampal formation; Context (archaeology); Boundary (topology); Computer science; Image segmentation; Pattern recognition (psychology); Computer vision; Brain morphometry; Random forest; Neuroscience; Mathematics; Magnetic resonance imaging; Psychology; Geography; Medicine; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2904143",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3037722013",
      "doi": "10.1109/access.2020.3004409",
      "title": "Confident Classification Using a Hybrid Between Deterministic and Probabilistic Convolutional Neural Networks",
      "abstract": "Traditional neural networks trained using point-based maximum likelihood estimation are deterministic models and have exhibited near-human performance in many image classification tasks. However, their insistence on representing network parameters with point-estimates renders them incapable of capturing all possible combinations of the weights; consequently, resulting in a biased predictor towards their initialisation. Most importantly, these deterministic networks are inherently unable to provide any uncertainty estimate for their prediction which is highly sought after in many critical application areas. On the other hand, Bayesian neural networks place a probability distribution on network weights and give a built-in regularisation effect making these models able to learn well from small datasets without overfitting. These networks provide a way of generating posterior distribution which can be used for model's uncertainty estimation. However, Bayesian estimation is computationally very expensive since it greatly widens the parameter space. This paper proposes a hybrid convolutional neural network which combines high accuracy of deterministic models with posterior distribution approximation of Bayesian neural networks. This hybrid architecture is validated on 13 publicly available benchmark classification datasets from a wide range of domains and different modalities like natural scene images, medical images, and time-series. Our results show that the proposed hybrid approach performs better than both deterministic and Bayesian methods in terms of classification accuracy and also provides an estimate of uncertainty for every prediction. We further employ this uncertainty to filter out unconfident predictions and achieve significant additional gain in accuracy for the remaining predictions.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Muhammad Naseer Bajwa et al.",
      "keywords": "Computer science; Overfitting; Artificial intelligence; Convolutional neural network; Machine learning; Benchmark (surveying); Artificial neural network; Bayesian probability; Posterior probability; Probabilistic logic; Contextual image classification; Pattern recognition (psychology); Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3004409",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4383899511",
      "doi": "10.1109/jbhi.2023.3294278",
      "title": "Generalizable Pancreas Segmentation via a Dual Self-Supervised Learning Framework",
      "abstract": "Recently, numerous pancreas segmentation methods have achieved promising performance on local single-source datasets. However, these methods don't adequately account for generalizability issues, and hence typically show limited performance and low stability on test data from other sources. Considering the limited availability of distinct data sources, we seek to improve the generalization performance of a pancreas segmentation model trained with a single-source dataset, i.e., the single-source generalization task. In particular, we propose a dual self-supervised learning model that incorporates both global and local anatomical contexts. Our model aims to fully exploit the anatomical features of the intra-pancreatic and extra-pancreatic regions, and hence enhance the characterization of the high-uncertainty regions for more robust generalization. Specifically, we first construct a global-feature contrastive self-supervised learning module that is guided by the pancreatic spatial structure. This module obtains complete and consistent pancreatic features through promoting intra-class cohesion, and also extracts more discriminative features for differentiating between pancreatic and non-pancreatic tissues through maximizing inter-class separation. It mitigates the influence of surrounding tissue on the segmentation outcomes in high-uncertainty regions. Subsequently, a local-image-restoration self-supervised learning module is introduced to further enhance the characterization of the high-uncertainty regions. In this module, informative anatomical contexts are actually learned to recover randomly-corrupted appearance patterns in those regions. The effectiveness of our method is demonstrated with state-of-the-art performance and comprehensive ablation analysis on three pancreas datasets (467 cases). The results demonstrate a great potential in providing a stable support for the diagnosis and treatment of pancreatic diseases.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Jun Li et al.",
      "keywords": "Discriminative model; Computer science; Artificial intelligence; Segmentation; Generalizability theory; Generalization; Pattern recognition (psychology); Exploit; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3294278",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390604257",
      "doi": "10.1109/access.2024.3350430",
      "title": "Computer-Aided Diagnosis System for Lung Fibrosis: From the Effect of Radiomic Features and Multi-Layer-Perceptron Mixers to Pre-Clinical Evaluation",
      "abstract": "Medical image segmentation is a crucial element of computer-aided diagnosis (CAD) systems. Segmentation maps are used to calculate imaging features, such as quantitative disease distribution and radiomic features. Since their introduction in 2015, UNets have become the state-of-the-art segmentation tools. However, since that time, many new methods for image processing have been introduced, such as vision transformers and multi-layer-perceptron-mixers (MLP-Mixers). Alongside baseline UNets, we have now investigated the application of such MLP-Mixers for medical image segmentation, as part of a CAD system for the diagnosis of interstitial lung diseases (ILDs). Furthermore, we have investigated the effect of 2D and 3D data representations on segmentation and the final CAD results. We have evaluated the performance of the baseline segmentation methods and the MLP-Mixer primary on the overall diagnostic performance of the CAD system - as well as on the accuracy of segmentation as an intermediate step. In addition to network and data representation variations, we have investigated two different techniques for selecting features, an agnostic method and an alternative approach which selects features tailored to a specific segmentation map and diagnosis task. Finally, the CAD&#x2019;s performance was compared with that of four independent specialists in chest radiology. Among the 105 test cases, the diagnostic accuracy was 77.2&#x00B1;1.6&#x0025; for the AI-approaches and 79.0&#x00B1;6.9&#x0025; for the radiologists, indicating that the proposed systems perform comparably well to human readers in most of the cases. For the task of ILD pattern segmentation, similar results were obtained with 3D data and 2D tomography slices.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Matthias Fontanellaz et al.",
      "keywords": "Computer science; Perceptron; Artificial intelligence; Field (mathematics); Layer (electronics); Lung; Pattern recognition (psychology); Medicine; Artificial neural network; Internal medicine; Materials science; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3350430",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4290989953",
      "doi": "10.1109/access.2022.3197772",
      "title": "Exploring Transformer-Based Learning for Negation Detection in Biomedical Texts",
      "abstract": "NLP techniques have been widely adopted in the biomedical domain to perform various text-analytics tasks, such as searching biomedical literature and extracting and deriving new knowledge from biomedical data. One type of biomedical data is clinical texts (e.g., clinical cases and medical records), which typically contain physicians&#x2019; notes about a patient&#x2019;s health, including previous medical history (symptoms, diseases, lab exams, treatments, etc.), as every visit to the hospital leads to the addition of more information to the patient&#x2019;s record. Another type of biomedical data is biological articles, which typically discuss and explore a certain phenomenon, such as the behavior of biological entities (e.g., genetic relations and interactions among them) and the roles of specific biological processes in causing diseases (e.g., how genetic amplification can cause tumorous diseases). For both types of biomedical data, negation detection is an essential analytics task that can be applied to identify negated contexts in biomedical text (e.g., detecting the presence of a statement establishing that a patient does not have/fit a certain clinical condition or detecting statements that indicate the nonexistence of certain relations among biological entities). This task has been addressed in prior work by considering a variety of approaches such as rule-based systems, conventional machine-learning classifiers, and deep learning approaches. In this work, we propose applying transformer-based learning for negation detection in biomedical texts. We use pre-trained BERT and other similar models (such as ALBERT, XLNet, and ELECTRA) to address two negation-detection subtasks: negation sentence identification and negation scope recognition. We evaluated our approach using the BioScope corpus and relying on measures such as accuracy, precision, recall, F1, and percentage of correct scopes (PCS). Our findings show the potential of transformer-based learning for negation detection, reaching an accuracy of 99&#x0025; for negation identification and a PCS of 95&#x0025; for negation scope recognition.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ghadeer Althari et al.",
      "keywords": "Computer science; Negation; Transformer; Artificial intelligence; Natural language processing; Electrical engineering; Programming language; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3197772",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4282915363",
      "doi": "10.1109/jbhi.2022.3181148",
      "title": "Automatic Detection of Aortic Valve Events Using Deep Neural Networks on Cardiac Signals From Epicardially Placed Accelerometer",
      "abstract": "Deep neural networks can be used on signals from epicardially attached accelerometers for robust and accurate detection of the opening and closing of the aortic valve.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Ali Wajdan et al.",
      "keywords": "Accelerometer; Ground truth; Aortic valve; Computer science; Artificial intelligence; Deep learning; Artificial neural network; Acceleration; Medicine; Pattern recognition (psychology); Biomedical engineering; Computer vision; Cardiology; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3181148",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3216209701",
      "doi": "10.1109/ojuffc.2021.3130021",
      "title": "Spatiotemporal Bayesian Regularization for Cardiac Strain Imaging: Simulation and <i>In Vivo</i> Results",
      "abstract": "Cardiac strain imaging (CSI) plays a critical role in the detection of myocardial motion abnormalities. Displacement estimation is an important processing step to ensure the accuracy and precision of derived strain tensors. In this paper, we propose and implement Spatiotemporal Bayesian regularization (STBR) algorithms for two-dimensional (2-D) normalized cross-correlation (NCC) based multi-level block matching along with incorporation into a Lagrangian cardiac strain estimation framework. Assuming smooth temporal variation over a short span of time, the proposed STBR algorithm performs displacement estimation using at least four consecutive ultrasound radio-frequency (RF) frames by iteratively regularizing 2-D NCC matrices using information from a local spatiotemporal neighborhood in a Bayesian sense. Two STBR schemes are proposed to construct Bayesian likelihood functions termed as Spatial then Temporal Bayesian (STBR-1) and simultaneous Spatiotemporal Bayesian (STBR-2). Radial and longitudinal strain estimated from a finite-element-analysis (FEA) model of realistic canine myocardial deformation were utilized to quantify strain bias, normalized strain error and total temporal relative error (TTR). Statistical analysis with one-way analysis of variance (ANOVA) showed that all Bayesian regularization methods significantly outperform NCC with lower bias and errors (<i>p</i> < <i>0.001</i>). However, there was no significant difference among Bayesian methods. For example, mean longitudinal TTR for NCC, SBR, STBR-1 and STBR-2 were 25.41%, 9.27%, 10.38% and 10.13% respectively An <i>in vivo</i> feasibility study using RF data from ten healthy mice hearts were used to compare the elastographic signal-to-noise ratio (SNR <sub><b>e</b></sub> ) calculated using stochastic analysis. STBR-2 had the highest expected SNR <sub><b>e</b></sub> both for radial and longitudinal strain. The mean expected SNR <sub><b>e</b></sub> values for accumulated radial strain for NCC, SBR, STBR-1 and STBR-2 were 5.03, 9.43, 9.42 and 10.58, respectively. Overall results suggest that STBR improves CSI <i>in vivo</i>.",
      "year": "2021",
      "journal": "IEEE Open Journal of Ultrasonics Ferroelectrics and Frequency Control",
      "authors": "Rashid Al Mukaddim et al.",
      "keywords": "Bayesian probability; Regularization (linguistics); Mathematics; Algorithm; Bayesian inference; Bayes estimator; Statistics; Computer science; Pattern recognition (psychology); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojuffc.2021.3130021",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3093621556",
      "doi": "10.1109/access.2020.3030060",
      "title": "Deep Longitudinal Feature Representations for Detection of Postradiotherapy Brain Injury at Presymptomatic Stage",
      "abstract": "Temporal lobe injury (TLI), a form of nervous system damage in the brain, is a major neurological complication after radiation therapy (RT). TLI must be highly valued because of the irreversible brain injury. This article aims to develop a predictive pipeline, called deep longitudinal feature representations (DLFR), to detect TLI at the presymptomatic stage accurately via the learning of effective deep longitudinal feature representations. DLFR characterizes high-level information and developmental changes within and across subjects The DLFR consists of four components: (i) extraction of deep features from a pretrained ResNet50 model; (ii) compression of learned highly representative features by the global max pooling; (iii) fusion of deep longitudinal features for the fully use of all follow-up data; (iv) random forest-based prediction of the diagnostic status. In total, 244 nasopharyngeal carcinoma patients before and after RT with a follow-up period of 0 ~ 9 years were included for analysis. All patients were divided into four different latency groups, and the current latency was used for training to predict the diagnostic status of the next latency. The AUCs of the predicted three different latency groups using DLFR were 0.64 &#x00B1; 0.11, 0.76 &#x00B1; 0.10, and 0.88 &#x00B1; 0.05, while those of radiomics features were 0.56 &#x00B1; 0.06, 0.63 &#x00B1; 0.03, and 0.53 &#x00B1; 0.04, and those of histogram of oriented gradients features were 0.60 &#x00B1; 0.09, 0.52 &#x00B1; 0.03, and 0.58 &#x00B1; 0.06. Most importantly, the AUCs of the predicted three different latency groups for white matter regions were 0.66 &#x00B1; 0.10, 0.80 &#x00B1; 0.09, and 0.78 &#x00B1; 0.09. Our proposed method can dynamically detect TLI at the presymptomatic stage, which can enable the administration of preventive neurological intervention.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Liming Zhong et al.",
      "keywords": "Feature extraction; Deep learning; Computer science; Latency (audio); White matter; Artificial intelligence; Pattern recognition (psychology); Medicine; Magnetic resonance imaging; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3030060",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2969346893",
      "doi": "10.1109/access.2019.2936415",
      "title": "Self-Weighting Grading Biomarker Based on Graph-Guided Information Propagation for the Prediction of Mild Cognitive Impairment Conversion",
      "abstract": "Mild cognitive impairment (MCI) represents a transitional stage between normal aging and Alzheimer&amp;#x2019;s disease (AD), with a higher risk to convert to AD. The information of AD and normal control (NC) subjects can aid the classification between progressive MCI and stable MCI. In this paper, we develop an effective biomarker by combining the auxiliary information of AD and NC subjects with the relationship of brain regions of MCI subject, which makes best of auxiliary information and improves the prediction accuracy of MCI-to-AD conversion. Specifically, a projection vector is first obtained for each MCI subject via graph-guided information propagation. Next, the information of projection vector is integrated using a self-weighting grading method to acquire the novel biomarker. Finally, the self-weighting grading biomarkers derived from multiple morphological features are combined to provide more accurate prediction of MCI-to-AD conversion. Experimental results on the Alzheimer&amp;#x2019;s Disease Neuroimaging Initiative database demonstrate the effectiveness of the proposed biomarkers for the prediction of MCI conversion.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Ying Li et al.",
      "keywords": "Weighting; Computer science; Grading (engineering); Graph; Cognitive impairment; Artificial intelligence; Cognition; Machine learning; Data mining; Pattern recognition (psychology); Theoretical computer science; Psychology; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2936415",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205448747",
      "doi": "10.1109/access.2021.3136263",
      "title": "One-Class Classifier for Chest X-Ray Anomaly Detection via Contrastive Patch-Based Percentile",
      "abstract": "Given its low dose and compactness, chest radiography has been widely used as the first-line test to determine the presence of lung anomalies. Nevertheless, a high-performance diagnosis for initial screening to detect shadows in lungs due to general lung diseases is not available. During initial screening, chest radiography can be used to distinguish any diseased lung shadowing caused by lung diseases. Thus, chest radiography can contribute to the early diagnosis and prevention of novel lung infectious diseases if training for a specific disease is not required. Accordingly, we propose a deep-learning-based diagnostic system called contrast-shifted instances via patch-based percentile (CSIP) to automatically detect diseased lung shadowing via training only on chest X-ray data from healthy subjects. CSIP is the first application of a patch-based percentile approach to state-of-the-art one-class classifiers (OCCs). This application improves the sensitivity of the network to recognize shadowing density differences in each local area of the lung, thereby considerably improving the diagnostic performance of average area under the curve (AUC) by more than 20&#x0025; and achieving a sufficiently high diagnostic performance (average AUC of 0.96 for various lung diseases), compared to the existing OCC case without applying our patch-based approach (average AUC of 0.74). Therefore, CSIP may contribute to the early detection of anomalies caused by novel infectious diseases such as variants of the coronavirus disease, for whom training data are scarce. The code is available at <uri>https://github.com/kskim-phd/CSIP</uri>.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Kyungsu Kim et al.",
      "keywords": "Percentile; Radiography; Medicine; Lung; Radiology; Classifier (UML); Receiver operating characteristic; Computer science; Artificial intelligence; Internal medicine; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3136263",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391381313",
      "doi": "10.1109/mc.2023.3327653",
      "title": "Avoiding Past Mistakes in Unethical Human Subjects Research: Moving From Artificial Intelligence Principles to Practice",
      "abstract": "Artificial intelligence (AI) is increasingly affecting many aspects of our day-to-day lives. Although the benefits of AI to society are potentially transformative, many fear the cost to human rights may be too great without focused attention.",
      "year": "2024",
      "journal": "Computer",
      "authors": "Kristen Greene et al.",
      "keywords": "Computer science; Artificial intelligence; Data science; Knowledge management; Management science; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mc.2023.3327653",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389076586",
      "doi": "10.1109/access.2023.3337639",
      "title": "Automatic Pulmonary Function Estimation From Chest CT Scans Using Deep Regression Neural Networks: The Relation Between Structure and Function in Systemic Sclerosis",
      "abstract": "&lt;p&gt; Pulmonary function tests (PFTs) play an important role in screening and following-up pulmonary involvement in systemic sclerosis (SSc). However, some patients are not able to perform PFTs due to contraindications. In addition, it is unclear how lung function is affected by changes in lung structure in SSc. Therefore, this study aims to explore the potential of automatically estimating PFT results from chest CT scans of SSc patients and how different regions influence the estimation of PFTs. Deep regression networks were developed with transfer learning to estimate PFTs from 316 SSc patients. Segmented lungs and vessels were used to mask the CT images to train the network with different inputs: from entire CT scan, lungs-only to vessels-only. The network trained on entire CT scans with transfer learning achieved an ICC of 0.71, 0.76, 0.80, and 0.81 for the estimation of DLCO, FEV1, FVC and TLC, respectively. The performance of the networks gradually decreased when trained on data from lungs-only and vessels-only. Regression attention maps showed that regions close to large vessels were highlighted more than other regions, and occasionally regions outside the lungs were highlighted. These experiments show that apart from the lungs and large vessels, other regions contribute to PFT estimation. In addition, adding manually designed biomarkers increased the correlation (R) from 0.75, 0.74, 0.82, and 0.83 to 0.81, 0.83, 0.88, and 0.90, respectively. This suggests that that manually designed imaging biomarkers can still contribute to explaining the relation between lung function and structure. &lt;br&gt;&lt;/p&gt;",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jingnan Jia et al.",
      "keywords": "DLCO; Pulmonary function testing; Lung; Medicine; Regression; Artificial neural network; Radiology; Deep learning; Computer science; Artificial intelligence; Pattern recognition (psychology); Lung function; Internal medicine; Diffusing capacity; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3337639",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3186943679",
      "doi": "10.1109/access.2021.3057382",
      "title": "Hybrid Feature Embedded Sparse Stacked Autoencoder and Manifold Dimensionality Reduction Ensemble for Mental Health Speech Recognition",
      "abstract": "Speech feature learning is the key to speech mental health recognition. Deep feature learning can automatically extract the speech features but suffers from the small sample problem. The traditional feature extract method is effective, but cannot find the inter-feature structure to generate the new high-quality features. This paper proposes an embedded hybrid feature deep sparse stacked autoencoder ensemble method to solve this problem. Firstly, the speech features are extracted based on prior knowledge and called original features. Secondly, the original features are embedded into the deep network (Sparse Stacked Autoencoder) to filter the output of the hidden layer, to enhance the complementarity between the deep features and the original features. Thirdly, the L1 regularized feature selection mechanism is designed to reduce the hybrid feature set formed by the combination of deep features and original features. Finally, a manifold projection classifier ensemble is designed to enhance the stability of classification. Besides, this paper for the first time proposes a speech collection scheme for mental health recognition. We construct a large-scale Chinese mental health speech database for verification of the proposed algorithm of mental health. In the experimental section, the proposed algorithm is verified and compared with the representative related algorithms. The experimental results show that the proposed algorithm has better classification accuracy than the other representative algorithms. The proposed method combines the advantages of deep feature learning and traditional feature extraction methods more efficiently to solve the small sample problem.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hong Chen et al.",
      "keywords": "Computer science; Autoencoder; Artificial intelligence; Pattern recognition (psychology); Feature extraction; Deep belief network; Deep learning; Dimensionality reduction; Classifier (UML); Feature selection; Feature (linguistics); Ensemble learning; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3057382",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2969395543",
      "doi": "10.1109/access.2019.2936360",
      "title": "An Innovative Damped Cuckoo Search Algorithm With a Comparative Study Against Other Adaptive Variants",
      "abstract": "This paper aims to find the best variant of Cuckoo Search Algorithm that makes the step size of Le&#x0301;vy flight adaptive. For this reason, we introduce a new variant of CSA called Damped Cuckoo Search (DCS) in which the step size of Le&#x0301;vy flight is adaptive via the concept of damped oscillations that exist in most second order control systems. Moreover, we propose two other methods that tune the step size of Le&#x0301;vy flight based on chaotic maps. Then a deep comparative study is conducted among almost all variants of CSA that appeared in the last decade that modifies the step size of Le&#x0301;vy flight. All these variants are tested on CEC2017 benchmark functions. Statistical analyses are performed using the Friedman test followed by four post-hoc procedures to hold paired comparisons between the proposed DCS and the other CSA variants. Also, graphical statistical analyses are conducted on all variants via Box Plots. Finally, convergence graphs for all the variants are illustrated as well to show the speed of solution improvement over generations. Simulation results prove that the proposed DCS outperforms all other variants with a large degree of significance. Moreover, DCS increases the speed of convergence in comparison with the other variants. The box plot graphs prove that DCS has the most compact distribution for all results obtained in all runs on most functions.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Mohamed Reda et al.",
      "keywords": "Cuckoo search; Benchmark (surveying); Convergence (economics); Algorithm; Computer science; L\u00e9vy flight; Cuckoo; Rate of convergence; Mathematics; Key (lock); Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2936360",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390659165",
      "doi": "10.1109/access.2024.3351168",
      "title": "Exploring Sparse Gaussian Processes for Bayesian Optimization in Convolutional Neural Networks for Autism Classification",
      "abstract": "Autism Spectrum Disorder (ASD) constitutes a prevalent childhood condition, impacting approximately 0.62&#x0025; of the global population. Children grappling with ASD encounter challenges in acquiring language proficiency, comprehending spoken communication, and interpreting nonverbal cues, including eye contact, facial expressions, and hand gestures. This discourse delves into the application of eye tracking as a foundational instrument in ASD screening, leveraging the distinctive attributes of gaze behavior. Within the realm of Artificial Intelligence, Deep Learning manifests substantial promise, exhibiting considerable strides across diverse domains and emerging as an indispensable technological paradigm. This treatise introduces an innovative Convolutional Neural Network (CNN) model predicated on Bayesian optimization for the discernment of eye tracking images. The model comprises two primary components: the initial segment employs CNN to extract and amalgamate salient features, while the subsequent section incorporates a Bayesian optimizer tasked with fine-tuning the CNN&#x2019;s hyperparameters contingent on an objective function. In the preliminary analysis, three distinct scenarios devoid of specific elements are juxtaposed with Bayesian optimization. During the examination, these circumstances are assessed through convergence charts and metrics of accuracy. The algorithm proposed manifests an elevated performance, demonstrating a conspicuous accuracy threshold of &#x0025; during the evaluative phase of the model. This outcome constitutes a commendable advancement in research, accentuating the efficacy and resilience of the developed approach. The article undertakes a comparative analysis of research methodologies and thematic analysis approaches, furnishing valuable insights for qualitative researchers and offering methodologically robust pathways to address research inquiries. In practical applications, the model attests to heightened reliability and precision, thereby underscored as efficacious in real-world scenarios.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Suresh Cheekaty et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Machine learning; Autism; Deep learning; Psychology; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3351168",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385695888",
      "doi": "10.1109/jbhi.2023.3303494",
      "title": "Generative Perturbation Network for Universal Adversarial Attacks on Brain-Computer Interfaces",
      "abstract": "Deep neural networks (DNNs) have successfully classified EEG-based brain-computer interface (BCI) systems. However, recent studies have found that well-designed input samples, known as adversarial examples, can easily fool well-performed deep neural networks model with minor perturbations undetectable by a human. This paper proposes an efficient generative model named generative perturbation network (GPN), which can generate universal adversarial examples with the same architecture for non-targeted and targeted attacks. Furthermore, the proposed model can be efficiently extended to conditionally or simultaneously generate perturbations for various targets and victim models. Our experimental evaluation demonstrates that perturbations generated by the proposed model outperform previous approaches for crafting signal-agnostic perturbations. We demonstrate that the extended network for signal-specific methods also significantly reduces generation time while performing similarly. The transferability across classification networks of the proposed method is superior to the other methods, which shows our perturbations' high level of generality.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Jiyoung Jung et al.",
      "keywords": "Computer science; Adversarial system; Generative adversarial network; Artificial intelligence; Generative grammar; Theoretical computer science; Human\u2013computer interaction; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3303494",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391559590",
      "doi": "10.1109/tvcg.2024.3362628",
      "title": "Comparative Analysis of Interactive Modalities for Intuitive Endovascular Interventions",
      "abstract": "Endovascular intervention is a minimally invasive method for treating cardiovascular diseases. Although fluoroscopy, known for real-time catheter visualization, is commonly used, it exposes patients and physicians to ionizing radiation and lacks depth perception due to its 2D nature. To address these limitations, a study was conducted using teleoperation and 3D visualization techniques. This in-vitro study involved the use of a robotic catheter system and aimed to evaluate user performance through both subjective and objective measures. The focus was on determining the most effective modes of interaction. Three interactive modes for guiding robotic catheters were compared in the study: 1) Mode GM, using a gamepad for control and a standard 2D monitor for visual feedback; 2) Mode GH, with a gamepad for control and HoloLens providing 3D visualization; and 3) Mode HH, where HoloLens serves as both control input and visualization device. Mode GH outperformed other modalities in subjective metrics, except for mental demand. It exhibited a median tracking error of 4.72 mm, a median targeting error of 1.01 mm, a median duration of 82.34 s, and a median natural logarithm of dimensionless squared jerk of 40.38 in the in-vitro study. Mode GH showed 8.5%, 4.7%, 6.5%, and 3.9% improvements over Mode GM and 1.5%, 33.6%, 34.9%, and 8.1% over Mode HH for tracking error, targeting error, duration, and dimensionless squared jerk, respectively. To sum up, the user study emphasizes the potential benefits of employing HoloLens for enhanced 3D visualization in catheterization. The user study also illustrates the advantages of using a gamepad for catheter teleoperation, including user-friendliness and passive haptic feedback, compared to HoloLens. To further gauge the potential of using a more traditional joystick as a control input device, an additional study utilizing the Haption Virtuose robot was conducted. It reveals the potential for achieving smoother trajectories, with a 38.9% reduction in total path length compared to a gamepad, potentially due to its larger range of motion and single-handed control.",
      "year": "2024",
      "journal": "IEEE Transactions on Visualization and Computer Graphics",
      "authors": "Di Wu et al.",
      "keywords": "Computer science; Modalities; Data visualization; Visualization; Human\u2013computer interaction; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tvcg.2024.3362628",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388936702",
      "doi": "10.1109/access.2023.3336590",
      "title": "CT Perfusion is All we Need: 4D CNN Segmentation of Penumbra and Core in Patients With Suspected Acute Ischemic Stroke",
      "abstract": "Stroke is the second leading cause of death worldwide, and around 87 &#x0025; of strokes are ischemic strokes. Accurate and rapid prediction techniques for identifying ischemic regions, including dead tissue (core) and potentially salvageable tissue (penumbra), in patients with acute ischemic stroke (AIS) hold great clinical importance, as this can provide valuable information for diagnosis and treatment planning. Computed Tomography Perfusion (CTP) is often used as a primary tool for assessing stroke location, severity, and the volume of ischemic regions. Current automatic segmentation methods for CTP typically utilize pre-processed 3D parametric maps, traditionally used for clinical interpretation by radiologists. An alternative approach is to use the raw CTP data slice by slice as 2D&#x002B;time input, where the spatial information over the volume is overlooked. Additionally, these methods primarily focus on segmenting core regions, yet predicting penumbra regions can be crucial for treatment planning. This paper investigates different methods to utilize the entire raw 4D CTP as input to fully exploit the spatio-temporal information, leading us to propose a 4D convolution layer in a 4D CNN network. Our comprehensive experiments on a local dataset of 152 patients divided into three groups show that our proposed models generate more precise results than other methods explored. Adopting the proposed 4D mJ-Net, a Dice Coefficient of 0.53 and 0.23 is achieved for segmenting penumbra and core areas, respectively. Using the entire 4D CTP data for AIS segmentation offers improved precision and potentially better treatment planning in patients suspected of this condition.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "L Tomasetti et al.",
      "keywords": "Penumbra; Computer science; Artificial intelligence; Segmentation; S\u00f8rensen\u2013Dice coefficient; Pattern recognition (psychology); Image segmentation; Radiology; Medicine; Ischemia; Cardiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3336590",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2861732392",
      "doi": "10.1109/tmi.2019.2946345",
      "title": "Partial Policy-Based Reinforcement Learning for Anatomical Landmark Localization in 3D Medical Images",
      "abstract": "Deploying the idea of long-term cumulative return, reinforcement learning has shown remarkable performance in various fields. We propose a formulation of the landmark localization in 3D medical images as a reinforcement learning problem. Whereas value-based methods have been widely used to solve similar problems, we adopt an actor-critic based direct policy search method framed in a temporal difference learning approach. Successful behavior learning is challenging in large state and/or action spaces, requiring many trials. We introduce a partial policy-based reinforcement learning to enable solving the large problem of localization by learning the optimal policy on smaller partial domains. Independent actors efficiently learn the corresponding partial policies, each utilizing their own independent critic. The proposed policy reconstruction from the partial policies ensures a robust and efficient localization utilizing the sub-agents solving simple binary decision problems in their corresponding partial action spaces. The proposed reinforcement learning requires a small number of trials to learn the optimal behavior compared with the original behavior learning scheme.",
      "year": "2019",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Walid Abdullah Al et al.",
      "keywords": "Reinforcement learning; Landmark; Computer science; Artificial intelligence; Bellman equation; Temporal difference learning; Action (physics); Machine learning; Reinforcement; Term (time); Mathematical optimization; Mathematics; Psychology",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tmi.2019.2946345",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4289821874",
      "doi": "10.1109/access.2022.3195535",
      "title": "Forecasting the COVID-19 Space-Time Dynamics in Brazil With Convolutional Graph Neural Networks and Transport Modals",
      "abstract": "One of the major challenges imposed by the SARS-CoV-2 pandemic is the lack of pattern in which the virus spreads, making it difficult to create effective policies to prevent and tackle the pandemic. Several approaches have been proposed to understand the virus behavior and anticipate its infection and death curves at country and state levels, thus supporting containment measures. Those initiatives generalize well for general extents and decisions, but they do not predict so well the trajectory of the virus through specific regions, such as municipalities, considering their distinct interconnection profiles. Especially in countries with continental dimensions, like Brazil, too general decisions imply that containment measures are applied either too soon or too late. This study presents a novel scalable alternative to forecasting the numbers of cases and deaths by SARS-CoV-2, according to the influence that certain regions exert on others. By exploiting a single-model architecture of graph convolutional networks with recurrent networks, our approach maps the main access routes to municipalities in Brazil using the modals of transport and processes this information via neural network algorithms to forecast at the municipal level and for the whole country. We compared the performance in forecasting the pandemic daily numbers with three baseline models using Mean Absolute Error (MAE), Symmetric Mean Absolute Percentage Error (sMAPE) and Normalized Root Mean Square Error (NRMSE) metrics, with the forecasting horizon varying from 1 to 25 days. Results show that the proposed model overcomes the baselines when considering the MAE and NRMSE (<inline-formula> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula>-<inline-formula> <tex-math notation=\"LaTeX\">$value &lt; 0.01$ </tex-math></inline-formula>), being especially suitable for forecasts from 14 to 24 days ahead.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Lucas Caldeira de Oliveira et al.",
      "keywords": "Computer science; Convolutional neural network; Coronavirus disease 2019 (COVID-19); Artificial intelligence; Graph; Theoretical computer science; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3195535",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395096959",
      "doi": "10.1109/tmi.2024.3391215",
      "title": "3DTINC: Time-Equivariant Non-Contrastive Learning for Predicting Disease Progression From Longitudinal OCTs",
      "abstract": "Self-supervised learning (SSL) has emerged as a powerful technique for improving the efficiency and effectiveness of deep learning models. Contrastive methods are a prominent family of SSL that extract similar representations of two augmented views of an image while pushing away others in the representation space as negatives. However, the state-of-the-art contrastive methods require large batch sizes and augmentations designed for natural images that are impractical for 3D medical images. To address these limitations, we propose a new longitudinal SSL method, 3DTINC, based on non-contrastive learning. It is designed to learn perturbation-invariant features for 3D optical coherence tomography (OCT) volumes, using augmentations specifically designed for OCT. We introduce a new non-contrastive similarity loss term that learns temporal information implicitly from intra-patient scans acquired at different times. Our experiments show that this temporal information is crucial for predicting progression of retinal diseases, such as age-related macular degeneration (AMD). After pretraining with 3DTINC, we evaluated the learned representations and the prognostic models on two large-scale longitudinal datasets of retinal OCTs where we predict the conversion to wet-AMD within a six-month interval. Our results demonstrate that each component of our contributions is crucial for learning meaningful representations useful in predicting disease progression from longitudinal volumetric scans.",
      "year": "2024",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Taha Emre et al.",
      "keywords": "Computer science; Equivariant map; Artificial intelligence; Natural language processing; Mathematics; Pure mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2024.3391215",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4362714579",
      "doi": "10.1109/tse.2023.3265362",
      "title": "Specializing Neural Networks for Cryptographic Code Completion Applications",
      "abstract": "Similarities between natural languages and programming languages have prompted researchers to apply neural network models to software problems, such as code generation and repair. However, program-specific characteristics pose unique prediction challenges that require the design of new and specialized neural network solutions. In this work, we identify new prediction challenges in application programming interface (API) completion tasks and find that existing solutions are unable to capture complex program dependencies in program semantics and structures. We design a new neural network model Multi-HyLSTM to overcome the newly identified challenges and comprehend complex dependencies between API calls. Our neural network is empowered with a specialized dataflow analysis to extract multiple global API dependence paths for neural network predictions. We evaluate Multi-HyLSTM on 64,478 Android Apps and predict 774,460 Java cryptographic API calls that are usually challenging for developers to use correctly. Our Multi-HyLSTM achieves an excellent top-1 API completion accuracy at 98.99%. Moreover, we show the effectiveness of our design choices through an ablation study and have released our dataset.",
      "year": "2023",
      "journal": "IEEE Transactions on Software Engineering",
      "authors": "Ya Xiao et al.",
      "keywords": "Computer science; Artificial neural network; Application programming interface; Java; Dataflow; Programming language; Semantics (computer science); Cryptography; Artificial intelligence; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tse.2023.3265362",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4384159606",
      "doi": "10.1109/access.2023.3295118",
      "title": "The Role of the Eyes: Investigating Face Cognition Mechanisms Using Machine Learning and Partial Face Stimuli",
      "abstract": "Face cognition mechanism has changed throughout the SARS-CoV-2 pandemic because of wearing masks. Previous studies found that holistic face processing enhances face cognition ability, and covering part of the face features lowers such an ability. However, the question of why people can recognize faces regardless of missing some clues about the face feature remains unsolved. To study the face cognition mechanism, event-related potential (ERP) evoked during the rapid serial visual presentation task is used. ERP is often hidden under large artifacts and needs to be averaged across the tremendous number of trials, but increasing the trial number can cause fatigue and affect evoked ERP. To overcome this limitation, we adopt machine learning and aim to investigate the partial face cognition mechanism without directly considering the pattern characteristic of the ERP. We implemented an xDAWN spatial filter covariance matrix method to enhance the data quality and a support vector machine classification model to predict the participant&#x2019;s event of interest using ERP components evoked in the full and partial face cognition tasks. The combination of the missing two face components and the physical response was also investigated to explore the role of each face component and find the possibility of reducing fatigue caused during the experiment. Our results show that the classification accuracy decreased when the eye component was missing and became lowest <inline-formula> <tex-math notation=\"LaTeX\">$(p &lt; 0.005)$ </tex-math></inline-formula> when the eyes and mouth were absent, with an accuracy of 0.748 &#x00B1; 0.092 in the button press task and 0.746 &#x00B1; 0.084 in the no button press task (n.s.). We also observed that the button press error rate increased when the eyes were absent and reached its maximum when the eyes and mouth were covered <inline-formula> <tex-math notation=\"LaTeX\">$(p &lt; 0.05)$ </tex-math></inline-formula>. These results suggest that the eyes might be the most effective component, the mouth might also play a secondary role in face cognition, and no button press task could be used in substitution of a button press task to reduce the workload.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ingon Chanpornpakdi et al.",
      "keywords": "Cognition; Computer science; Event-related potential; Electroencephalography; Face (sociological concept); Stimulus (psychology); Cognitive psychology; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3295118",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4206656700",
      "doi": "10.1109/access.2021.3132401",
      "title": "Automatic Detection of Amyloid Beta Plaques in Somatosensory Cortex of an Alzheimer\u2019s Disease Mouse Using Deep Learning",
      "abstract": "Identification of amyloid beta ( A\u03b2 ) plaques in the cerebral cortex in models of Alzheimer\u2019s Disease (AD) is of critical importance for research into therapeutics. Here we propose an innovative framework which automatically measures A\u03b2 plaques in the cortex of a rodent model, based on anatomical segmentation using a deep learning approach. The framework has three phases: data acquisition to enhance image quality using preprocessing techniques and image normalization with a novel plaque removal algorithm, then an anatomical segmentation phase using the trained model, and finally an analysis phase to quantitate A\u03b2 plaques. Supervised training with 946 sets of mouse brain section annotations exhibiting A\u03b2 protein-labeled plaques ( A\u03b2 plaques) were trained with deep neural networks (DNNs). Five DNN architectures: FCN32, FCN16, FCN8, SegNet, and U-Net, were tested. Of these, U-Net was selected as it showed the most reliable segmentation performance. The framework demonstrated an accuracy of 83.98% and 91.21% of the Dice coefficient score for atlas segmentation with the test dataset. The proposed framework automatically segmented the somatosensory cortex and calculated the intensity and extent of A\u03b2 plaques. This study contributes to image analysis in the field of neuroscience, allowing region-specific quantitation of image features using a deep learning approach.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Heemoon Yoon et al.",
      "keywords": "Artificial intelligence; Segmentation; Deep learning; Preprocessor; Pattern recognition (psychology); Computer science; Somatosensory system; S\u00f8rensen\u2013Dice coefficient; Amyloid beta; Alzheimer's disease; Artificial neural network; Neuroscience; Image segmentation; Pathology; Medicine; Biology; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3132401",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3119238856",
      "doi": "10.1109/access.2021.3051188",
      "title": "Unpaired Stain Style Transfer Using Invertible Neural Networks Based on Channel Attention and Long-Range Residual",
      "abstract": "Hematoxylin and eosin (H&amp;E) stained colors is a critical step in the digitized pathological diagnosis of cancer. However, differences in section preparations, staining protocols and scanner specifications may result in the variations of stain colors in pathological images, which can potentially hamper the effectiveness of pathologist's diagnosis and the robustness. To alleviate this problem, several color normalization methods have been proposed. Most previous approaches map color information between images highly dependent on a reference template. However, due to the problem that pathological images are usually unpaired, these methods cannot produce satisfactory results. In this work, we propose an unsupervised color normalization method based on channel attention and long-range residual, using a technology called invertible neural networks (INN) to transfer the stain style while preserving the tissue semantics between different hospitals or centers, resulting in a virtual stained sample in the sense that no actual stains are used. In our method, the expert does not need to choose a template image. More specifically, we have developed a new unsupervised stain style transfer framework based on INN that is different from state-of-the-art methods. Meanwhile, we propose a new generator and a discriminator to further improve the performance. Our approach outperforms state-of-the-art methods both in objective metrics and subjective evaluations, yielding an improvement of 1.0 dB in terms of PSNR. Moreover, the amount of computation of the proposed network has been reduced by 33 %. This indicates that the inference speed is almost one third faster while the performance is better.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Junlin Lan et al.",
      "keywords": "Computer science; Artificial intelligence; Normalization (sociology); Pattern recognition (psychology); Discriminator; Residual; Robustness (evolution); Computer vision; Artificial neural network; Stain; Algorithm; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3051188",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3033752742",
      "doi": "10.1109/tts.2020.3032321",
      "title": "The \u201cCriminality From Face\u201d Illusion",
      "abstract": "The automatic analysis of face images can generate predictions about a person's gender, age, race, facial expression, body mass index, and various other indices and conditions. A few recent publications have claimed success in analyzing an image of a person's face in order to predict the person's status as Criminal / Non-Criminal. Predicting criminality from face may initially seem similar to other facial analytics, but we argue that attempts to create a criminality-from-face algorithm are necessarily doomed to fail, that apparently promising experimental results in recent publications are an illusion resulting from inadequate experimental design, and that there is potentially a large social cost to belief in the criminality from face illusion.",
      "year": "2020",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Kevin W. Bowyer et al.",
      "keywords": "Illusion; Face (sociological concept); Psychology; Analytics; Race (biology); Computer science; Index (typography); Facial expression; Expression (computer science); Social psychology; Artificial intelligence; Criminology; Cognitive psychology; Data science; Sociology; Gender studies; World Wide Web; Social science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tts.2020.3032321",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3101104924",
      "doi": "10.1109/access.2021.3072231",
      "title": "FastPathology: An Open-Source Platform for Deep Learning-Based Research and Decision Support in Digital Pathology",
      "abstract": "Deep convolutional neural networks (CNNs) are the current state-of-the-art for digital analysis of histopathological images. The large size of whole-slide microscopy images (WSIs) requires advanced memory handling to read, display and process these images. There are several open-source platforms for working with WSIs, but few support deployment of CNN models. These applications use third-party solutions for inference, making them less user-friendly and unsuitable for high-performance image analysis. To make deployment of CNNs user-friendly and feasible on low-end machines, we have developed a new platform, FastPathology, using the FAST framework and C++. It minimizes memory usage for reading and processing WSIs, deployment of CNN models, and real-time interactive visualization of results. Runtime experiments were conducted on four different use cases, using different architectures, inference engines, hardware configurations and operating systems. Memory usage for reading, visualizing, zooming and panning a WSI were measured, using FastPathology and three existing platforms. FastPathology performed similarly in terms of memory to the other C++ based application, while using considerably less than the two Java-based platforms. The choice of neural network model, inference engine, hardware and processors influenced runtime considerably. Thus, FastPathology includes all steps needed for efficient visualization and processing of WSIs in a single application, including inference of CNNs with real-time display of the results. Source code, binary releases and test data can be found online on GitHub at https://github.com/SINTEFMedtek/FAST-Pathology/.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Andr\u00e9 Pedersen et al.",
      "keywords": "Computer science; Convolutional neural network; Software deployment; Inference; Inference engine; Zoom; Visualization; Java; Artificial intelligence; Digital pathology; Process (computing); Deep learning; Source code; Computer hardware; Operating system; Embedded system",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2021.3072231",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393140463",
      "doi": "10.1109/access.2024.3381536",
      "title": "Effects of Class Imbalance Countermeasures on Interpretability",
      "abstract": "The widespread use of artificial intelligence (AI) in more and more real-world applications is accompanied by challenges that are not obvious at first glance. In machine learning, class imbalance, characterized by an imbalance in the frequency of classes, is one key challenge that poses essential problems for many common machine learning algorithms. This challenge led to the development of various countermeasures to tackle class imbalance. Although these countermeasures improve the prediction performance of models, they often jeopardize interpretability for both AI users and AI experts. Especially in sensitive domains where class imbalance is regularly present, for example, medicine, meteorology, or fraud detection, interpretability is of utmost importance. In this paper, we evaluate the effect of class imbalance countermeasures on interpretability with methods of explainable AI (XAI). Our work contributes to a more in-depth understanding of these countermeasures and connects the research fields of class imbalance learning and XAI. Our experimental results suggest that only feature selection and cost-sensitive approaches are the only class imbalance countermeasures that preserve interpretability for both AI users and AI experts. In contrast, resampling and most classification algorithms for imbalance learning are not suitable in settings where knowledge should be derived and where interpretability is a key requirement.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "David Cemernek et al.",
      "keywords": "Interpretability; Class (philosophy); Computer science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3381536",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285104833",
      "doi": "10.1109/access.2022.3174862",
      "title": "Sarcasm Over Time and Across Platforms: Does the Way We Express Sarcasm Change?",
      "abstract": "Sarcasm is a sophisticated form of speech used to convey a message other than the apparent one. To date, there are numerous papers that have discussed the idea of automatic sarcasm detection and how it could be used for sentiment analysis improvement. The objective of this paper is to provide non-experts with a comprehensive overview of the state of research in this field and the main findings regarding sarcasm detection. Therefore, in this paper, we survey the state-of-the-art work done in this field, we recapitulate the research effort done, with focus on the more recent works, and we present the expected performance out of the proposed works. Nevertheless, we study in detail how this form of speech is used in different platforms, and how the way we express it evolves over time. We also discuss the proposition that suggests that sarcasm is a polarity switcher for sentiment analysis. To achieve these goals, we run some experiments on 3 different data sets, collected from 3 different platforms, and compare how sarcasm is employed in each. These platforms are Twitter, Reddit, and some news websites. Our experiments show that the way sarcasm is expressed is highly dependent on language mastery and the platform used. For instance, in the Twitter data set, whose users vary widely in age, language mastery, and understanding what sarcasm means, the overall precision of detection of sarcastic statement reaches 89.31&#x0025;. In the reddit data set, the precision of detection of such statements is about 55.33&#x0025;, and in the news data set, the precision reaches over 96.67&#x0025;. Our experiments also show that, to a great extent, it is safe to affirm that sarcasm, when employed, switches the polarity of a given piece of text: for the 3 platforms presented above, sarcasm has been a polarity switcher for 89.3&#x0025;, 89.1&#x0025;, and 92.0&#x0025; of their respective instances.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mondher Bouazizi et al.",
      "keywords": "Sarcasm; Computer science; Sentiment analysis; Artificial intelligence; Set (abstract data type); Proposition; Statement (logic); Field (mathematics); Natural language processing; Data science; Linguistics; Irony",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3174862",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4322730954",
      "doi": "10.1109/tnsre.2023.3250641",
      "title": "Digital Biomarkers for Diagnosis of Muscle Disorders Using Stimulated Muscle Contraction Signal",
      "abstract": "We propose a digital biomarker related to muscle strength and muscle endurance (DB/MS and DB/ME) for the diagnosis of muscle disorders based on a multi-layer perceptron (MLP) using stimulated muscle contraction. When muscle mass is reduced in patients with muscle-related diseases or disorders, measurement of DBs that are related to muscle strength and endurance is needed to suitably recover damaged muscles through rehabilitation training. Furthermore, it is difficult to measure DBs using traditional methods at home without an expert; moreover, the measuring equipment is expensive. Additionally, because traditional measurements depend on the subjectb's volition, we propose a DB measurement technique that is unaffected by the subjectb's volition. To achieve this, we employed an impact response signal (IRS) based on multi-frequency electrical stimulation (MFES) using an electromyography sensor. The feature vector was then extracted using the signal. Because the IRS is obtained from stimulated muscle contraction, which is caused by electrical stimulation, it provides biomedical information about the muscle. Finally, to estimate the strength and endurance of the muscle, the feature vector was passed through the DB estimation model learned through the MLP. To evaluate the performance of the DB measurement algorithm, we collected the MFES-based IRS database for 50 subjects and tested the model with quantitative evaluation methods using the reference for the DB. The reference was measured using torque equipment. The results were compared with the reference, indicating that it is possible to check for muscle disorders which cause decreased physical performance using the proposed algorithm.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Kwangsub Song et al.",
      "keywords": "Computer science; Muscle contraction; Electromyography; Support vector machine; Biomedical engineering; Artificial intelligence; Pattern recognition (psychology); Physical medicine and rehabilitation; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3250641",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3204546721",
      "doi": "10.1109/access.2021.3118102",
      "title": "Real-Time Glaucoma Detection From Digital Fundus Images Using Self-ONNs",
      "abstract": "Glaucoma leads to permanent vision disability by damaging the optical nerve that transmits visual images to the brain. The fact that glaucoma does not show any symptoms as it progresses and cannot be stopped at the later stages, makes it critical to be diagnosed in its early stages. Although various deep learning models have been applied for detecting glaucoma from digital fundus images, due to the scarcity of labeled data, their generalization performance was limited along with high computational complexity and special hardware requirements. In this study, compact Self-Organized Operational Neural Networks (Self- ONNs) are proposed for early detection of glaucoma in fundus images and their performance is compared against the conventional (deep) Convolutional Neural Networks (CNNs) over three benchmark datasets: ACRIMA, RIM-ONE, and ESOGU. The experimental results demonstrate that Self-ONNs not only achieve superior detection performance but can also significantly reduce the computational complexity making it a potentially suitable network model for biomedical datasets especially when the data is scarce.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "\u00d6zer Can Devecio\u011flu et al.",
      "keywords": "Glaucoma; Convolutional neural network; Computer science; Artificial intelligence; Benchmark (surveying); Deep learning; Fundus (uterus); Generalization; Pattern recognition (psychology); Machine learning; Computer vision; Ophthalmology; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2021.3118102",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390872185",
      "doi": "10.1109/access.2024.3354711",
      "title": "Explicit Modeling of Brain State Duration Using Hidden Semi Markov Models in EEG Data",
      "abstract": "We consider the detection and characterization of brain state transitions based on ongoing electroencephalography (EEG). Here, a brain state represents a specific brain dynamical regime or mode of operation that produces a characteristic quasi-stable pattern of activity at the topography, sources, or network levels. These states and their transitions over time can reflect fundamental computational properties of the brain, shaping human behavior and brain function. The hidden Markov model (HMM) has emerged as a useful tool for uncovering the hidden dynamics of brain state transitions based on observed data. However, the limitations of the Geometric distribution of states\u2019 durations (dwell times) implicit in the standard HMM, make it sub-optimal for modeling brain states in EEG. We propose using hidden semi Markov models (HSMM), a<br/>generalization of HMM that allows modeling the brain states duration distributions explicitly. We present a Bayesian formulation of HSMM and use the variational Bayes framework to efficiently estimate the HSMM parameters, the number of brain states, and select among candidate brain state duration distributions. We assess HSMM performance against HMM on simulated data<br/>and demonstrate that the accurate modeling of state durations is paramount for making reliable inference when the task at hand requires accurate model predictions. Finally, we use actual resting-state EEG data to illustrate the benefits of the approach in practice. We demonstrate that the possibility of modeling brain state durations explicitly provides a new way for investigating the nature of the neural dynamics that generated the EEG data.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Nelson J. Trujillo\u2010Barreto et al.",
      "keywords": "Hidden Markov model; Computer science; Electroencephalography; Hidden semi-Markov model; Artificial intelligence; Inference; Generalization; Pattern recognition (psychology); Machine learning; Bayesian inference; Bayesian probability; Markov model; Markov chain; Mathematics; Variable-order Markov model; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3354711",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4291805097",
      "doi": "10.1109/tcss.2022.3195103",
      "title": "CovidTrak: A Vision on Social Intelligence-Empowered COVID-19 Contact Tracing",
      "abstract": "With the proliferation of smart devices and widespread Internet connectivity, social sensing is advancing as a pervasive sensing paradigm where experiences shared by individuals on social platforms (e.g., Twitter and Facebook) are analyzed to interpret the physical world. In this article, we introduce CovidTrak, a vision of social intelligence-empowered contact tracing that aims to scrutinize the knowledge derived using social sensing to track Coronavirus Disease 2019 (COVID-19) infections among the general public. Contact tracing is known to be an effective technique for detecting and monitoring persons who may have been exposed to individuals infected with any communicable disease. While a good number of contact tracing schemes are existent today (e.g., in-person and phone interviews, paper forms, email and web-based questionnaires, and smartphone apps), they often require active user participation and might miss certain cases of social interactions that go off-the-records but still lead to COVID-19 transmission. By contrast, social sensing provides an alternative avenue for spontaneously determining such contacts by harnessing the rich experiences and information conveyed by people on social data platforms (e.g., a group photograph tweeted from a house party with a potential contact). As such, CovidTrak can form a powerful basis to combat the COVID-19 pandemic. The vision of CovidTrak intends to answer the following questions: 1) how to bolster the privacy and security of the online users while determining their contacts? 2) how to collect relevant social signals that indicate in-person encounters among people? 3) how to reliably process the vast amount of noisy data from social platforms to identify chains of transmission? 4) how to handle the scarcity of location metadata in the incoming data? 5) how to effectively communicate crucial contact information to concerned individuals? and 6) how to model and handle the responses of the common people toward contact information? We envision unexplored opportunities to leverage multidisciplinary techniques to address the above questions and develop effective future CovidTrak schemes.",
      "year": "2022",
      "journal": "IEEE Transactions on Computational Social Systems",
      "authors": "Md Tahmid Rashid et al.",
      "keywords": "Contact tracing; Internet privacy; Phone; Coronavirus disease 2019 (COVID-19); Social contact; The Internet; Social media; Social distance; Computer science; Tracing; Social network (sociolinguistics); Computer security; World Wide Web; Psychology; Social psychology; Disease; Medicine; Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcss.2022.3195103",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393372038",
      "doi": "10.1109/access.2024.3383837",
      "title": "Evaluation of Machine Learning Techniques for Classifying and Balancing Data on an Unbalanced Mini-Mental State Examination Test Data Collection Applied in Chile",
      "abstract": "The Mini-Mental State Examination (MMSE) is the most widely used cognitive test for assessing whether suspected symptoms align with cognitive impairment or dementia. The results of this test are meaningful for clinicians but exhibit highly unbalanced distributions in studies and analyses regarding the classification of patients with cognitive impairment. This is a complex problem when a large number of MMSE tests are analysed. Therefore, data balancing and classification techniques are crucial to support decision-making in distinguishing patients with cognitive impairment in an effective and efficient manner. This study explores machine learning techniques for data balancing and classification using a real unbalanced dataset consisting of MMSE test responses collected from 103 elderly patients participating in a Chilean patient monitoring project. We used 8 data classification techniques and five data balancing techniques. We evaluated the performance of the techniques using the following metrics: sensitivity, specificity, F1-score, likelihood ratio (LR+ and LR-), diagnostic odds ratio (DOR), and the area under the ROC curve (AUC). From the set of data balancing and classification techniques used in this study, the results indicate that synthetic minority oversampling and random forest balancing techniques improve the accuracy of cognitive impairment diagnosis. The results obtained in this study support clinical decision-making regarding early classification or exclusion of older adult patients with suspected cognitive impairment.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Pablo Orme\u00f1o-Arriagada et al.",
      "keywords": "Computer science; Data collection; Test (biology); Test data; Artificial intelligence; State (computer science); Machine learning; Mental state; Data mining; Algorithm; Psychology; Statistics; Mathematics; Applied psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3383837",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3181320772",
      "doi": "10.1109/mra.2021.3105639",
      "title": "Making an Opportunity Out of a Crisis: The Inclusive Approach of the Italian Robotics Community",
      "abstract": "The COVID-19 pandemic is forcing a rethink in robotics. In the form it is known today, robotics has been the prerogative of a broad community of insiders. But now, in the wreckage left behind by COVID-19, a new era is beginning. What does it hold? During the pandemic, increasing numbers of people had manifested the hope that robotics might bring novel solutions. And this interest has emerged beyond the usual boundaries of the experts or technology enthusiasts. This provides an opportunity to reinforce the community of people involved in the process of innovation. By involving citizens, the community becomes more comprehensive (that is, plural and diverse). This broadening will involve more practical knowledge and therefore produce better robots of many shapes and functions. If progress is possible in the industry, why not in the hospitals, shopping malls, restaurants, hotels, and schools? What is more, the approach endorsed by the Italian robotics community during the lockdown has established a new cooperation among those who labor with robots, and the professionals who work in hospitals, which is bound to last a long time. As a major impact, this experience will enable an improvement on science's relationship with and for society. This may entail a further shift: to value more scientific knowledge and scientific literacy.",
      "year": "2021",
      "journal": "IEEE Robotics & Automation Magazine",
      "authors": "Alessandra Sciutti et al.",
      "keywords": "Robotics; Artificial intelligence; Robot; Plural; Prerogative; Work (physics); Process (computing); Pandemic; Coronavirus disease 2019 (COVID-19); Computer science; Political science; Public relations; Engineering ethics; Sociology; Engineering; Law; Politics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mra.2021.3105639",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3006066442",
      "doi": "10.1109/access.2020.2973815",
      "title": "Automatic and Adaptive Signal- and Background-ROIs With Analytic-Representation-Based Processing for Robust Webcam-Based Heart-Rate Estimation",
      "abstract": "Determining a suitable, adaptive region of interest (ROI) automatically for extracting information related to cardiac activity (signal-ROI/S-ROI), and another containing information on ambient light-fluctuation (background-ROI/B-ROI, as close as possible to the signal-ROI), and robust signal processing are important in webcam based heart-rate (HR) estimation - in real life situations. We describe a novel method of automatically determining both the ROIs. The forehead is the candidate for the S-ROI, due to its uniformity and minimum vulnerability for deformation. We first identify the skin-pixels within the face-region detected by the Viola-Jones (VJ) algorithm. The forehead-region, and a uniform sub-rectangle within it not containing hair - determined by using variance as a measure - yields the S-ROI. The B-ROI - consisting of 3 rectangles - each of the same size as that of S-ROI, at the two sides and the top of the VJ-rectangle - is used to generate a reference signal for an adaptive noise-cancellation scheme. The situation arising from (possibly simultaneous) facial expressions deforming the S-ROI, is addressed - by extracting the phase sequence associated with the analytic representation of the signal. Experiments conducted with 21 healthy subjects, using this novel array of techniques, have produced good correspondence with the ground truth obtained from a standard finger-pulse transducer - as reflected by the Bland-Altman plot.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "James E. A. John et al.",
      "keywords": "Region of interest; Artificial intelligence; Computer science; Computer vision; SIGNAL (programming language); Noise (video); Pixel; Rectangle; Ground truth; Pattern recognition (psychology); Mathematics; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2973815",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3114206414",
      "doi": "10.1109/access.2020.3046851",
      "title": "Penalized Functional Connectivity Maps for Patients With Focal Epilepsy",
      "abstract": "Objective: This study demonstrates how functional connectivity (FC) patterns are affected in direct relation to the lobe that is mostly affected by seizures. Methods: The novel idea of penalized FC (pFC) maps is compared against standard FC maps in the four fundamental EEG frequency sub-bands. The FC measure between any two specific electrodes is scaled depending on the probability of true FC between them, and their power content with respect to the two electrodes of maximum power within each frequency sub-band. The algorithm is automated and introduces adaptive power penalization based on the power distribution of the different sub-bands. Results: The pFC maps were found to be more effective at suppressing the local connectivity in the lobes that are less affected by the interictal epileptiform discharges (IEDs). More precisely, given the least amount of power penalization, pFC maps of the theta sub-band reveal statistical significance in terms of increased local connectivity margin of the affected region as compared to the standard FC maps. However, they cannot be solely relied upon as other sub-bands could alternatively show high local connectivity across different patients within the region of interest. Conclusion: penalized functional connectivity maps intrinsically provide more information regarding the whole brain network in context to regions of interest where the active lobe is determined by the neurologists to contain the focal source. Significance: Findings suggest that (1) the significant sub-band varies from patient to patient while remaining relatively consistent within the IED segments of a same patient, and (2) the pFC maps have an advanced capability in terms of pinpointing to a region of interest of the active lobe, and as such can play a critical role in providing insight as to a region of interest where the 3D source might be located when solving the ill-posed inverse problem.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ahmed Hossam Mohammed et al.",
      "keywords": "Ictal; Context (archaeology); Computer science; Margin (machine learning); Pattern recognition (psychology); Temporal lobe; Functional connectivity; Epilepsy; Statistical power; Artificial intelligence; Neuroscience; Mathematics; Statistics; Machine learning; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3046851",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3015228001",
      "doi": "10.1109/jbhi.2020.3037857",
      "title": "Probabilistic Modelling of Gait for Robust Passive Monitoring in Daily Life",
      "abstract": "Passive monitoring in daily life may provide invaluable insights about a person's health throughout the day. Wearable sensor devices are likely to play a key role in enabling such monitoring in a non-obtrusive fashion. However, sensor data collected in daily life reflects multiple health and behavior related factors together. This creates the need for structured principled analysis to produce reliable and interpretable predictions that can be used to support clinical diagnosis and treatment. In this work we develop a principled modelling approach for free-living gait (walking) analysis. Gait is a promising target for non-obtrusive monitoring because it is common and indicative of various movement disorders such as Parkinson's disease (PD), yet its analysis has largely been limited to experimentally controlled lab settings. To locate and characterize stationary gait segments in free living using accelerometers, we present an unsupervised statistical framework designed to segment signals into differing gait and non-gait patterns. Our flexible probabilistic framework combines empirical assumptions about gait into a principled graphical model with all of its merits. We demonstrate the approach on a new video-referenced dataset including unscripted daily living activities of 25 PD patients and 25 controls, in and around their own houses. We evaluate our ability to detect gait and predict medication induced fluctuations in PD patients based on modelled gait. Our evaluation includes a comparison between sensors attached at multiple body locations including wrist, ankle, trouser pocket and lower back.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Yordan P. Raykov et al.",
      "keywords": "Gait; Probabilistic logic; Wearable computer; Computer science; Gait analysis; Physical medicine and rehabilitation; Accelerometer; Ankle; Artificial intelligence; Machine learning; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/jbhi.2020.3037857",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382752061",
      "doi": "10.1109/taffc.2023.3291330",
      "title": "Investigating Cardiovascular Activation of Young Adults in Routine Driving",
      "abstract": "We report on a naturalistic study investigating the effects of routine driving on cardiovascular activation. We recruited 21 healthy young adults from a broad geographic area in the Southwestern United States. Using the participants' own smartphones and smartwatches, we monitored for a week both their driving and non-driving activities. Monitoring included the continuous recording of a) heart rate throughout the day, b) hand motion during driving as a proxy of persistent texting, and c) contextualized driving data, complete with traffic and weather information. These high temporal resolution variables were complemented with the drivers' biographic and psychometric profiles. Our analysis suggests that anxiety predisposition and high speeds are associated with significant cardiovascular activation on drivers, likely linked to sympathetic arousal. Surprisingly, these associations hold true under good weather, normal traffic, and with experienced drivers behind the wheel. The said findings call for attention to insidious effects of apparently benign drives even for people in their prime. Accordingly, our research contributes to intriguing new discourses on driving affect and personal health informatics.",
      "year": "2023",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "MD Tanim Hasan et al.",
      "keywords": "Smartwatch; Arousal; Anxiety; Affect (linguistics); Distress; Sleep deprivation; Mood; Psychology; Proxy (statistics); Human factors and ergonomics; Poison control; Developmental psychology; Medicine; Medical emergency; Cognition; Clinical psychology; Wearable computer; Computer science; Social psychology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taffc.2023.3291330",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386608828",
      "doi": "10.1109/access.2023.3313980",
      "title": "Efficient and Motion Correction-Free Myocardial Perfusion Segmentation in Small MRI Data Using Deep Transfer Learning From Cine Images: A Promising Framework for Clinical Implementation",
      "abstract": "Perfusion cardiovascular magnetic resonance imaging is used to quantify the heart&#x2019;s blood flow, which requires the segmentation of the myocardium, a laborious task. Deep learning-based methods, the most accurate to accomplish this task, still rely on expensive motion correction steps and require large labeled datasets. This paper presents an innovative, efficient approach to myocardial perfusion segmentation, utilizing deep learning techniques without motion correction and with minimal data requirements. Through transfer learning, this methodology leverages the wealth of information available from large, publicly accessible cine magnetic resonance datasets, which provide anatomically analogous images to perfusion ones. This methodology includes normalization and cropping of cine images using a Region-of-Interest detector based on a Markovian, graph-based visual saliency algorithm improved by a sequence of morphological operations. After pretraining a U-net convolutional neural network, a special fine-tuning scheme optimizes its performance. The parameters learned are the starting point for training on a smaller perfusion dataset from the Clinical Hospital of the University of Chile. After an ablation study, the best model is obtained when using both cropping and fine-tuning from the cine dataset, segmenting the left ventricle endocardium with Dice, IoU, and Hausdorff distance of 92.2&#x0025;, 85.9&#x0025;, and 5.1 mm respectively, and 95.6&#x0025;, 91.7&#x0025;, and 4.6 mm for the left ventricle epicardium. Notably, fine-tuning achieves a Dice of 91.8&#x0025; for endocardium and 95.2&#x0025; for epicardium when only 289 perfusion training images are available. These are promising results for developing targeted implementations in real healthcare settings when only small datasets are available.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Germ\u00e1n Garc\u00eda-Jara et al.",
      "keywords": "Computer science; Artificial intelligence; Segmentation; Computer vision; Motion (physics); Image segmentation; Transfer of learning; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3313980",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3099440999",
      "doi": "10.1109/tbme.2020.3045720",
      "title": "Domain Generalization in Biosignal Classification",
      "abstract": "Objective: When training machine learning models, we often assume that the training data and evaluation data are sampled from the same distribution. However, this assumption is violated when the model is evaluated on another unseen but similar database, even if that database contains the same classes. This problem is caused by domain-shift and can be solved using two approaches: domain adaptation and domain generalization. Simply, domain adaptation methods can access data from unseen domains during training; whereas in domain generalization, the unseen data is not available during training. Hence, domain generalization concerns models that perform well on inaccessible, domain-shifted data. Method: Our proposed domain generalization method represents an unseen domain using a set of known basis domains, afterwhich we classify the unseen domain using classifier fusion. To demonstrate our system, we employ a collection of heart sound databases that contain normal and abnormal sounds (classes). Results: Our proposed classifier fusion method achieves accuracy gains of up to 16% for four completely unseen domains. Conclusion: Recognizing the complexity induced by the inherent temporal nature of biosignal data, the two-stage method proposed in this study is able to effectively simplify the whole process of domain generalization while demonstrating good results on unseen domains and the adopted basis domains. Significance: To our best knowledge, this is the first study that investigates domain generalization for biosignal data. Our proposed learning strategy can be used to effectively learn domain-relevant features while being aware of the class differences in the data.",
      "year": "2020",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Theekshana Dissanayake et al.",
      "keywords": "Biosignal; Computer science; Classifier (UML); Artificial intelligence; Generalization; Domain (mathematical analysis); Machine learning; Domain adaptation; Pattern recognition (psychology); Mathematics",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tbme.2020.3045720",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3094826350",
      "doi": "10.1109/access.2020.3035804",
      "title": "A Shape Prior-Based Active Contour Model for Automatic Images Segmentation",
      "abstract": "Due to the variable shapes of objects, high noise intensity and complex environments, the field of image segmentation still has great challenges. To address these issues, we present a new image segmentation strategy based on active contour model and shape priori information, which can accurately and efficiently segment various images. The data fitting term, inspired by Chan-Vese (C-V) model, is used to guide the curve evolving to desired target boundary. Meanwhile, the contour is utilized to reconstruct a prior shape so that can help to deal with images in the presence of complex target. After that, the length regularity term of energy functional is incorporated to ensure the stable calculation of the evolution curve. The quantitative and qualitative experiments on various real and medical images indicate that our method is more efficient and accurate than the existing unified models.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Xiaoliang Jiang et al.",
      "keywords": "Artificial intelligence; Computer science; Active contour model; Segmentation; Computer vision; Image segmentation; A priori and a posteriori; Boundary (topology); Scale-space segmentation; Energy functional; Noise (video); Term (time); Pattern recognition (psychology); Active shape model; Level set (data structures); Curve fitting; Image (mathematics); Mathematics; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3035804",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391454449",
      "doi": "10.1109/thms.2024.3354413",
      "title": "Behavioral, Peripheral, and Central Neural Correlates of Augmented Reality Guidance of Manual Tasks",
      "abstract": "Objective: The use of commercially available optical-see-through (OST) head-mounted displays (HMDs) in their own peripersonal space leads the user to experience two perception conflicts that deteriorate their performance in precision manual tasks: the vergence-accommodation conflict (VAC) and the focus rivalry. In this work, we aim characterizing for the first time the psychophysiological response associated with user's incorrect focus cues during the execution of an augmented reality (AR)-guided manual task with the Microsoft HoloLens OST-HMD. Methods: 21 subjects underwent to a \"connecting-the-dots\" experiment with and without the use of AR, and in both binocular and monocular conditions. For each condition, we quantified the changes in autonomic nervous system (ANS) activity of subjects by analyzing the electrodermal activity (EDA) and heart rate variability. Moreover, we analyzed the neural central correlates by means of power measures of brain activity and multivariate autoregressive measures of brain connectivity extracted from the electroencephalogram (EEG). Results: No statistically significant differences of ANS correlates were observed among tasks, although all EDA-related features varied between rest and task conditions. Conversely, significant differences among conditions were present in terms of EEG-power variations in the beta(8-13) Hz and beta(13-30) Hz bands. In addition, significant changes in the causal interactions of a brain network involved in motor movement and eye-hand coordination comprising the precentral gyrus, the precuneus, and the fusiform gyrus were observed. Conclusion: The physiological plausibility of our results suggest promising future applicability to investigate more complex scenarios, such as AR-guided surgery.",
      "year": "2024",
      "journal": "IEEE Transactions on Human-Machine Systems",
      "authors": "Alejandro Luis Callara et al.",
      "keywords": "Task (project management); Focus (optics); Notation; Electroencephalography; Computer science; Augmented reality; Psychology; Artificial intelligence; Audiology; Mathematics; Neuroscience; Arithmetic; Engineering; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/thms.2024.3354413",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3202715770",
      "doi": "10.1109/access.2021.3116680",
      "title": "An Auto-Approval Approach for Laboratory Test Assessment",
      "abstract": "Background: Auto-approval (also known as <italic>autoverification</italic>) is the task of automatically evaluating the consistency of a test result throughout the laboratory information system rather than its manual evaluation by the biochemists. Most of the existing auto-approval systems rely on a rule-based solution obtained from expert knowledge. However, it is a challenging issue to produce a complete and general rule-base for every single test type. To that end, the studies have relied only on a small subset of laboratory tests. Methods: The rule-based auto-approval process was re-investigated in this study, and the rules predetermined by human experts were utilized as a pre-filtering step for grouping the laboratory test result via some common criteria. Subsequently, a machine learning-based approval method, smart-approval, was proposed to approve the tests more precisely. At this point, the expert knowledge in the rule-based pre-filtering was extended by the tendency to imitate the experts&#x2019; behavior in the smart-approval step. Two novel datasets (entitled with plot and real-time datasets) containing human experts&#x2019; responses to previously studied tests have been used to train the machine learning models. Results: Experiments have been handled on several machine learning models on plot dataset to obtain the trained models based on cross-validation. Here, the random forest classifier provided the best approval performance while also outperforming the approval success of existing studies in the literature. To observe the real-time performance of these trained models, they were also evaluated on real-time unseen data for 4 months. Here, random forest reaffirmed that it was the best approval model. Conclusions: The proposed auto-approval system relying on random forest can provide convincing classification performance on both of the obtained datasets. With the correct approval rate of 98.51&#x0025;, it surpasses many powerful approval methods in the literature.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Beg\u00fcm Mutlu et al.",
      "keywords": "Computer science; Test (biology); Reliability engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3116680",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3205783487",
      "doi": "10.1109/tse.2021.3128820",
      "title": "Deep State Inference: Toward Behavioral Model Inference of Black-Box Software Systems",
      "abstract": "Many software engineering tasks, such as testing, and anomaly detection can benefit from the ability to infer a behavioral model of the software.Most existing inference approaches assume access to code to collect execution sequences. In this paper, we investigate a black-box scenario, where the system under analysis cannot be instrumented, in this granular fashion.This scenario is particularly prevalent with control systems' log analysis in the form of continuous signals. In this situation, an execution trace amounts to a multivariate time-series of input and output signals, where different states of the system correspond to different `phases` in the time-series. The main challenge is to detect when these phase changes take place. Unfortunately, most existing solutions are either univariate, make assumptions on the data distribution, or have limited learning power.Therefore, we propose a hybrid deep neural network that accepts as input a multivariate time series and applies a set of convolutional and recurrent layers to learn the non-linear correlations between signals and the patterns over time.We show how this approach can be used to accurately detect state changes, and how the inferred models can be successfully applied to transfer-learning scenarios, to accurately process traces from different products with similar execution characteristics. Our experimental results on two UAV autopilot case studies indicate that our approach is highly accurate (over 90% F1 score for state classification) and significantly improves baselines (by up to 102% for change point detection).Using transfer learning we also show that up to 90% of the maximum achievable F1 scores in the open-source case study can be achieved by reusing the trained models from the industrial case and only fine tuning them using as low as 5 labeled samples, which reduces the manual labeling effort by 98%.",
      "year": "2021",
      "journal": "IEEE Transactions on Software Engineering",
      "authors": "Foozhan Ataiefard et al.",
      "keywords": "Computer science; Inference; Black box; TRACE (psycholinguistics); Process (computing); Set (abstract data type); Univariate; Software; Anomaly detection; Artificial intelligence; Deep learning; Transfer of learning; Machine learning; Multivariate statistics; Time series; Data mining; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tse.2021.3128820",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2904351506",
      "doi": "10.1109/comst.2018.2886932",
      "title": "Applications of Blockchains in the Internet of Things: A Comprehensive Survey",
      "abstract": "The Blockchain technology has revolutionized the digital currency space with the pioneering cryptocurrency platform named Bitcoin. From an abstract perspective, a blockchain is a distributed ledger capable of maintaining an immutable log of transactions happening in a network. In recent years, this technology has attracted significant scientific interest in research areas beyond the financial sector, one of them being the Internet of Things (IoT). In this context, the Blockchain is seen as the missing link towards building a truly decentralized, trustless and secure environment for the IoT and, in this survey, we aim to shape a coherent and comprehensive picture of the current state-of-the-art efforts in this direction. We start with fundamental working principles of blockchains and how blockchain-based systems achieve the characteristics of decentralization, security, and auditability. From there, we build our narrative on the challenges posed by the current centralized IoT models, followed by recent advances made both in industry and research to solve these challenges and effectively use blockchains to provide a decentralized, secure medium for the IoT.",
      "year": "2018",
      "journal": "IEEE Communications Surveys & Tutorials",
      "authors": "Muhammad Salek Ali et al.",
      "keywords": "Cryptocurrency; Computer science; Blockchain; Context (archaeology); Decentralization; Computer security; Internet of Things; The Internet; Ledger; Data science; World Wide Web; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/comst.2018.2886932",
      "cited_by_count": 822,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4288391568",
      "doi": "10.1109/tai.2022.3194503",
      "title": "An Overview of Artificial Intelligence Ethics",
      "abstract": "Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This paper will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.",
      "year": "2022",
      "journal": "IEEE Transactions on Artificial Intelligence",
      "authors": "Changwu Huang et al.",
      "keywords": "Engineering ethics; Ethical issues; Field (mathematics); Ethics of technology; Political science; Applied ethics; Information ethics; Sociology; Public relations; Artificial intelligence; Computer science; Engineering; Meta-ethics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tai.2022.3194503",
      "cited_by_count": 361,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2999472659",
      "doi": "10.1109/comst.2019.2962586",
      "title": "A Survey on the Internet of Things (IoT) Forensics: Challenges, Approaches, and Open Issues",
      "abstract": "&lt;p&gt;Today is the era of the Internet of Things (IoT). The recent advances in hardware and information technology have accelerated the deployment of billions of interconnected, smart and adaptive devices in critical infrastructures like health, transportation, environmental control, and home automation. Transferring data over a network without requiring any kind of human-to-computer or human-to-human interaction, brings reliability and convenience to consumers, but also opens a new world of opportunity for intruders, and introduces a whole set of unique and complicated questions to the field of Digital Forensics. Although IoT data could be a rich source of evidence, forensics professionals cope with diverse problems, starting from the huge variety of IoT devices and non-standard formats, to the multi-tenant cloud infrastructure and the resulting multi-jurisdictional litigations. A further challenge is the end-to-end encryption which represents a trade-off between users&#39; right to privacy and the success of the forensics investigation. Due to its volatile nature, digital evidence has to be acquired and analyzed using validated tools and techniques that ensure the maintenance of the Chain of Custody. Therefore, the purpose of this paper is to identify and discuss the main issues involved in the complex process of IoT-based investigations, particularly all legal, privacy and cloud security challenges. Furthermore, this work provides an overview of the past and current theoretical models in the digital forensics science. Special attention is paid to frameworks that aim to extract data in a privacy-preserving manner or secure the evidence integrity using decentralized blockchain-based solutions. In addition, the present paper addresses the ongoing Forensics-as-a-Service (FaaS) paradigm, as well as some promising cross-cutting data reduction and forensics intelligence techniques. Finally, several other research trends and open issues are presented, with emphasis on the need for proactive Forensics Readiness strategies and generally agreed-upon standards.&lt;/p&gt;",
      "year": "2020",
      "journal": "IEEE Communications Surveys & Tutorials",
      "authors": "Maria Stoyanova et al.",
      "keywords": "Computer science; Digital forensics; Computer security; Digital evidence; Cloud computing; Network forensics; Software deployment; Encryption; Variety (cybernetics); Computer forensics; Automation; Process (computing); The Internet; Internet privacy; Data science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/comst.2019.2962586",
      "cited_by_count": 802,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3009247505",
      "doi": "10.1109/tts.2020.2992344",
      "title": "Demographic Bias in Biometrics: A Survey on an Emerging Challenge",
      "abstract": "Systems incorporating biometric technologies have become ubiquitous in personal, commercial, and governmental identity management applications. Both cooperative (e.g. access control) and non-cooperative (e.g. surveillance and forensics) systems have benefited from biometrics. Such systems rely on the uniqueness of certain biological or behavioural characteristics of human beings, which enable for individuals to be reliably recognised using automated algorithms. Recently, however, there has been a wave of public and academic concerns regarding the existence of systemic bias in automated decision systems (including biometrics). Most prominently, face recognition algorithms have often been labelled as \u201cracist\u201d or \u201cbiased\u201d by the media, non-governmental organisations, and researchers alike. The main contributions of this article are: (1) an overview of the topic of algorithmic bias in the context of biometrics, (2) a comprehensive survey of the existing literature on biometric bias estimation and mitigation, (3) a discussion of the pertinent technical and social matters, and (4) an outline of the remaining challenges and future work items, both from technological and social points of view.",
      "year": "2020",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Pawel Drozdowski et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2020.2992344",
      "cited_by_count": 190,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3186924568",
      "doi": "10.1109/access.2021.3096799",
      "title": "Intelligent Fraud Detection in Financial Statements Using Machine Learning and Data Mining: A Systematic Literature Review",
      "abstract": "Fraudulent financial statements (FFS) are the results of manipulating financial elements by overvaluing incomes, assets, sales, and profits while underrating expenses, debts, or losses. To identify such fraudulent statements, traditional methods, including manual auditing and inspections, are costly, imprecise, and time-consuming. Intelligent methods can significantly help auditors in analyzing a large number of financial statements. In this study, we systematically review and synthesize the existing literature on intelligent fraud detection in corporate financial statements. In particular, the focus of this review is on exploring machine learning and data mining methods, as well as the various datasets that are studied for detecting financial fraud. We adopted the Kitchenham methodology as a well-defined protocol to extract, synthesize, and report the results. Accordingly, 47 articles were selected, synthesized, and analyzed. We present the key issues, gaps, and limitations in the area of fraud detection in financial statements and suggest areas for future research. Since supervised algorithms were employed more than unsupervised approaches like clustering, the future research should focus on unsupervised, semi-supervised, as well as bio-inspired and evolutionary heuristic methods for anomaly (fraud) detection. In terms of datasets, it is envisaged that future research making use of textual and audio data. While imposing new challenges, this unstructured data deserves further study as it can show interesting results for intelligent fraud detection.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Matin N. Ashtiani et al.",
      "keywords": "Computer science; Audit; Cluster analysis; Anomaly detection; Unsupervised learning; Focus (optics); Key (lock); Machine learning; Heuristic; Finance; Artificial intelligence; Data mining; Data science; Accounting; Computer security; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3096799",
      "cited_by_count": 169,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4375787811",
      "doi": "10.1109/comst.2023.3273282",
      "title": "Cyber Threat Intelligence Mining for Proactive Cybersecurity Defense: A Survey and New Perspectives",
      "abstract": "Today's cyber attacks have become more severe and frequent, which calls for a new line of security defenses to protect against them. The dynamic nature of new-generation threats, which are evasive, resilient, and complex, makes traditional security systems based on heuristics and signatures struggle to match. Organizations aim to gather and share real-time cyber threat information and then turn it into threat intelligence for preventing attacks or, at the very least, responding quickly in a proactive manner. Cyber Threat Intelligence (CTI) mining, which uncovers, processes, and analyzes valuable information about cyber threats, is booming. However, most organizations today mainly focus on basic use cases, such as integrating threat data feeds with existing network and firewall systems, intrusion prevention systems, and Security Information and Event Management systems (SIEMs), without taking advantage of the insights that such new intelligence can deliver. In order to make the most of CTI so as to significantly strengthen security postures, we present a comprehensive review of recent research efforts on CTI mining from multiple data sources in this article. Specifically, we provide and devise a taxonomy to summarize the studies on CTI mining based on the intended purposes (i.e., cybersecurity-related entities and events, cyber attack tactics, techniques and procedures, profiles of hackers, indicators of compromise, vulnerability exploits and malware implementation, and threat hunting), along with a comprehensive review of the current state-of-the-art. Lastly, we discuss research challenges and possible future research directions for CTI mining.",
      "year": "2023",
      "journal": "IEEE Communications Surveys & Tutorials",
      "authors": "Nan Sun et al.",
      "keywords": "Computer security; Psychology; Computer science; Internet privacy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/comst.2023.3273282",
      "cited_by_count": 215,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4313116287",
      "doi": "10.1109/access.2022.3216617",
      "title": "Explainable Intrusion Detection Systems (X-IDS): A Survey of Current Methods, Challenges, and Opportunities",
      "abstract": "The application of Artificial Intelligence (AI) and Machine Learning (ML) to cybersecurity challenges has gained traction in industry and academia, partially as a result of widespread malware attacks on critical systems such as cloud infrastructures and government institutions. Intrusion Detection Systems (IDS), using some forms of AI, have received widespread adoption due to their ability to handle vast amounts of data with a high prediction accuracy. These systems are hosted in the organizational Cyber Security Operation Center (CSoC) as a defense tool to monitor and detect malicious network flow that would otherwise impact the Confidentiality, Integrity, and Availability (CIA). CSoC analysts rely on these systems to make decisions about the detected threats. However, IDSs designed using Deep Learning (DL) techniques are often treated as black box models and do not provide a justification for their predictions. This creates a barrier for CSoC analysts, as they are unable to improve their decisions based on the model&amp;#x2019;s predictions. One solution to this problem is to design explainable IDS (X-IDS). This survey reviews the state-of-the-art in explainable AI (XAI) for IDS, its current challenges, and discusses how these challenges span to the design of an X-IDS. In particular, we discuss black box and white box approaches comprehensively. We also present the tradeoff between these approaches in terms of their performance and ability to produce explanations. Furthermore, we propose a generic architecture that considers human-in-the-loop which can be used as a guideline when designing an X-IDS. Research recommendations are given from three critical viewpoints: the need to define explainability for IDS, the need to create explanations tailored to various stakeholders, and the need to design metrics to evaluate explanations.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Subash Neupane et al.",
      "keywords": "Computer science; Intrusion detection system; Malware; Computer security; Black box; Cloud computing; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3216617",
      "cited_by_count": 146,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3119925017",
      "doi": "10.1109/access.2021.3050241",
      "title": "A Comparative Study: Blockchain Technology Utilization Benefits, Challenges and Functionalities",
      "abstract": "Blockchain technology enables users to verify, preserve, and synchronize the contents of a data sheet (a transaction ledger) replicated by multiple users. Blockchain technology has provided considerable advantages and incentives to industries in terms of enabling better services. This review aims to explore the benefits, challenges and functionalities that affect blockchain applications in different sectors. This article is constructed as a systematic literature review study. From 1976 articles, 168 final articles were selected and classified into three main dimensions, that is, benefits, challenges, and functionalities, in four different sectors: government, financial, manufacturing, and healthcare. The results were extracted and compared based on factors in three dimensions, which were categorized as benefits (informational, technological, economic, organizational, and strategic), challenges (technological, organizational, adoption, operational, and environmental and sustainability), and functionalities (point-to-point transmission, data ownership, data protection, and transaction processing). The results of this review study aim to support professionals, practitioners, and stakeholders who wish to implement and manage transformation projects related to blockchain in their sectors. Moreover, helping these possible blockchain users to understand the implied factors associated with blockchain would be beneficial for the decision-making processes of their organizations.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Omar Ali et al.",
      "keywords": "Blockchain; Government (linguistics); Incentive; Database transaction; Distributed ledger; Computer science; Knowledge management; Sustainability; Business; Process management; Computer security; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3050241",
      "cited_by_count": 283,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4285202968",
      "doi": "10.1109/access.2022.3186892",
      "title": "Blockchain for Industry 5.0: Vision, Opportunities, Key Enablers, and Future Directions",
      "abstract": "Industry 4.0 have witnessed a paradigm shift from cyber-physical systems (CPS) that aims at massive automation, to a more customer-driven approach. The shift has been attributed to the design of hyper-cognitive systems, integration of virtual and extended reality, digital machinery prototyping and twin designs, trusted machine boundaries, collaborative robots, and artificial intelligence (AI)-based supply chains. This new wave, termed Industry 5.0, is expected to leverage massive production with user-centric customization outside the scope of Industry 4.0 ecosystems. Industry 5.0 is expected to assist diverse industrial verticals like healthcare, smart farming, drones, smart grids, and supply chain production ecosystems. However, data is shared among multiple heterogeneous networks, spanning different authoritative domains. Thus, trusted and secured data transfer is crucial to synergize and secure the industrial perimeters. Blockchain (BC) is a preferred choice as a security enabler to Industry 5.0 ecosystems owing to its inherent property of immutability, chronology, and auditability in industrial systems. Limited works are proposed that present the vision and holistic view of BC-assisted Industry 5.0 applications. The article presents a first-of-its-kind survey on BC as a security enabler in Industry 5.0. Based on a descriptive survey methodology and research questions, we presented the key drivers, and potential applications, and propose an architectural vision of BC-based Industry 5.0 in diverse applicative verticals. The survey intends to present solutions that would assist industry practitioners, academicians, and researchers to drive novel BC-assisted solutions in Industry 5.0 verticals.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ashwin Verma et al.",
      "keywords": "Computer science; Industry 4.0; Enabling; Supply chain; Leverage (statistics); Cyber-physical system; Knowledge management; Process management; Computer security; Business; Artificial intelligence; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3186892",
      "cited_by_count": 174,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3171973514",
      "doi": "10.1109/access.2021.3086230",
      "title": "Deep Learning and Explainable Artificial Intelligence Techniques Applied for Detecting Money Laundering\u2013A Critical Review",
      "abstract": "Money laundering has been a global issue for decades, which is one of the major threat for economy and society. Government, regulatory and financial institutions are combating it together in their respective capacity, however still billions of dollars in fines by authorities make the headlines in the news. High-speed internet services have enabled financial institutions to deliver better customer experience through multi-channel engagements, which has led to exponential growth in transactions and new avenues for laundering the money for fraudsters. Literature shows the usage of statistical methods, data mining and Machine Learning (ML) techniques for money laundering detection, but limited research on Deep Learning (DL) techniques, primarily due to lack of model interpretability and explainability of the decisions made. Several studies are conducted on application of ML for Anti-Money Laundering (AML), and Explainable Artificial Intelligence (XAI) techniques in general, but lacks the study on usage of DL techniques together with XAI. This paper aims to review the current state-of-the-art literature on DL together with XAI for identifying suspicious money laundering transactions and identify future research areas. Key findings of the review are, researchers have preferred variants of Convolutional Neural Networks, and AutoEncoder; graph deep learning together with natural language processing is emerging as an important technology for AML; XAI use is not seen in AML domain; 51% ML methods used in AML are non-interpretable, 58% studies used sample of old real data; key challenges for researchers are access to recent real transaction data and scarcity of labelled training data; and data being highly imbalanced. Future research directions are, application of XAI techniques to bring-out explainability, graph deep learning using natural language processing (NLP), unsupervised and reinforcement learning to handle lack of labelled data; and joint research programs between re...",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Dattatray Vishnu Kute et al.",
      "keywords": "Money laundering; Computer science; Database transaction; Big data; Artificial intelligence; Government (linguistics); Key (lock); Scarcity; The Internet; Deep learning; Data science; Computer security; Business; Finance; Data mining; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3086230",
      "cited_by_count": 162,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390480754",
      "doi": "10.1109/access.2023.3349019",
      "title": "On the Integration of Artificial Intelligence and Blockchain Technology: A Perspective About Security",
      "abstract": "As reliance on disruptive applications based on Artificial Intelligence (AI) and Blockchain grows, the need for secure and trustworthy solutions becomes ever more critical. Whereas much research has been conducted on AI and Blockchain, there is a shortage of comprehensive studies examining their integration from a security perspective. Hence, this survey addresses such a gap and provides insights for policymakers, researchers, and practitioners exploiting AI and Blockchain\u2019s evolving integration. Specifically, this paper analyzes the potential benefits of the integration of AI and Blockchain as well as the related security concerns, identifying possible mitigation strategies, suggesting regulatory measures, and describing the impact it has on public trust.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Alexandr Kuznetsov et al.",
      "keywords": "Blockchain; Perspective (graphical); Computer science; Computer security; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3349019",
      "cited_by_count": 98,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3011053760",
      "doi": "10.1109/access.2020.2981892",
      "title": "Usability of Mobile Applications: A Systematic Literature Study",
      "abstract": "Since the release of the first mobile devices, the usability of on-board applications has been the concern not only of software vendors but hardware manufacturers as well. The academia community later willingly joined the discussion on usability in terms of theory and empirical measurement, having experience and knowledge in desktop settings. At first sight, such a background should guarantee a solid foundation to conduct research on software usability in a new setting. However, a preliminary study on the subject matter revealed methodological disorder in contemporary literature. As a matter of fact, a need emerged to review existing usability definitions, attributes and measures to recognize all associated aspects. In order to fill this void, we conducted a systematic literature review on usability studies indexed by the Scopus database and devoted to mobile applications. The input volume covers 790 documents from 2001 to 2018. The data analysis shows that the ISO 9241-11 usability definition has been adopted in an unchanged form and popularized as the standard by the HCI community. Secondly, in total, 75 attributes were identified and analysed. The most frequent are efficiency (70%), satisfaction (66%) and effectiveness (58%), which directly originate from the above definition. Subsequently, the less frequent are learnability (45%), memorability (23%), cognitive load (19%) and errors (17%). The last two concern simplicity (13%) and ease of use (9%). Thirdly, in the evaluation of usability, controlled observation and surveys are two major research methods applied, while eye-tracking, thinking aloud and interview are hardly used and serve as complementary to collect additional data. Moreover, usability evaluations are often confused with user experience dimensions, covering not only application quality characteristics, but also user beliefs, emotions and preferences. All these results indicate the need for further research on the usability of mobile applications, aiming to establish a consensus in the theory and practice among all interested parties.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Pawe\u0142 Weichbroth",
      "keywords": "Usability; Computer science; Heuristic evaluation; Usability inspection; Cognitive walkthrough; Web usability; Usability engineering; Learnability; Usability lab; Usability goals; Pluralistic walkthrough; System usability scale; World Wide Web; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2981892",
      "cited_by_count": 259,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4288391541",
      "doi": "10.1109/access.2022.3194569",
      "title": "Blockchain and AI-Empowered Healthcare Insurance Fraud Detection: an Analysis, Architecture, and Future Prospects",
      "abstract": "Nowadays, health insurance has become an essential part of people&#x2019;s lives as the number of health issues increases. Healthcare emergencies can be troublesome for people who can&#x2019;t afford huge expenses. Health insurance helps people cover healthcare services expenses in case of a medical emergency and provides financial backup against indebtedness risk. Health insurance and its several benefits can face many security, privacy, and fraud issues. For the past few years, fraud has been a sensitive issue in the health insurance domain as it incurs high losses for individuals, private firms, and governments. So, it is essential for national authorities and private firms to develop systems to detect fraudulent cases and payments. A high volume of health insurance data in electronic form is generated, which is highly sensitive and attracts malicious users. Motivated by these facts, we present a systematic survey for Artificial Intelligence (AI) and blockchain-enabled secure health insurance fraud detection in this paper. This paper presents a taxonomy of various security issues in health insurance. We proposed a blockchain and AI-based secure and intelligent system to detect health insurance fraud. Then, a case study related to health insurance fraud is presented. Finally, the open issues and research challenges in implementing the blockchain and an AI-empowered health insurance fraud detection system is presented.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Khyati Kapadiya et al.",
      "keywords": "Business; Backup; Health care; Payment; Self-insurance; Computer security; Actuarial science; Health insurance; Computer science; Finance; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3194569",
      "cited_by_count": 106,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3097734923",
      "doi": "10.1109/access.2020.3036322",
      "title": "Machine Learning for Financial Risk Management: A Survey",
      "abstract": "Financial risk management avoids losses and maximizes profits, and hence is vital to most businesses. As the task relies heavily on information-driven decision making, machine learning is a promising source for new methods and technologies. In recent years, we have seen increasing adoption of machine learning methods for various risk management tasks. Machine-learning researchers, however, often struggle to navigate the vast and complex domain knowledge and the fast-evolving literature. This paper fills this gap, by providing a systematic survey of the rapidly growing literature of machine learning research for financial risk management. The contributions of the paper are four-folds: First, we present a taxonomy of financial-risk-management tasks and connect them with relevant machine learning methods. Secondly, we highlight significant publications in the past decade. Thirdly, we identify major challenges being faced by researchers in this area. And finally, we point out emerging trends and promising research directions.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Akib Mashrur et al.",
      "keywords": "Computer science; Risk management; Machine learning; Artificial intelligence; Task (project management); Data science; Knowledge management; Domain (mathematical analysis); Risk analysis (engineering); Finance; Business; Management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3036322",
      "cited_by_count": 167,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3096019139",
      "doi": "10.1109/access.2020.3033784",
      "title": "An Investigation of Credit Card Default Prediction in the Imbalanced Datasets",
      "abstract": "Financial threats are displaying a trend about the credit risk of commercial banks as the incredible improvement in the financial industry has arisen. In this way, one of the biggest threats faces by commercial banks is the risk prediction of credit clients. Recent studies mostly focus on enhancing the classifier performance for credit card default prediction rather than an interpretable model. In classification problems, an imbalanced dataset is also crucial to improve the performance of the model because most of the cases lied in one class, and only a few examples are in other categories. Traditional statistical approaches are not suitable to deal with imbalanced data. In this study, a model is developed for credit default prediction by employing various credit-related datasets. There is often a significant difference between the minimum and maximum values in different features, so Min-Max normalization is used to scale the features within one range. Data level resampling techniques are employed to overcome the problem of the data imbalance. Various undersampling and oversampling methods are used to resolve the issue of class imbalance. Different machine learning models are also employed to obtain efficient results. We developed the hypothesis of whether developed models using different machine learning techniques are significantly the same or different and whether resampling techniques significantly improves the performance of the proposed models. One-way Analysis of Variance is a hypothesis-testing technique, used to test the significance of the results. The split method is utilized to validate the results in which data has split into training and test sets. The results on imbalanced datasets show the accuracy of 66.9% on Taiwan clients credit dataset, 70.7% on South German clients credit dataset, and 65% on Belgium clients credit dataset. Conversely, the results using our proposed methods significantly improve the accuracy of 89% on Taiwan clients credit dataset, 84.6% on South German clients credit dataset, and 87.1% on Belgium clients credit dataset. The results show that the performance of classifiers is better on the balanced dataset as compared to the imbalanced dataset. It is also observed that the performance of data oversampling techniques are better than undersampling techniques. Overall, the Gradient Boosted Decision Tree method performs better than other traditional machine learning classifiers. The Gradient Boosted Decision Tree method gives the best results while utilizing the K-means SMOTE oversampling method. Using one-way ANOVA, the null hypothesis was rejected by a p-value &lt;; 0.001, hence confirming that the proposed model improved performance is statistical significance. The interpretable model is also deployed on the web to ease the different stakeholders. This model will help commercial banks, financial organizations, loan institutes, and other decision-makers to predict the loan defaulter earlier.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Talha Mahboob Alam et al.",
      "keywords": "Undersampling; Computer science; Credit card; Resampling; Machine learning; Oversampling; Credit card fraud; Artificial intelligence; Credit risk; Normalization (sociology); Classifier (UML); Data mining; Econometrics; Finance; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3033784",
      "cited_by_count": 171,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386634193",
      "doi": "10.1109/access.2023.3314499",
      "title": "Understanding the Factors Influencing Higher Education Students\u2019 Intention to Adopt Artificial Intelligence-Based Robots",
      "abstract": "Although there has been some progress, the integration of artificial intelligence into higher education remains far from sufficient. The demand for teachers will persist for some time; however, with the introduction of AI-based robots into classrooms, the role of teachers has been reduced to a minimum. The purpose of the current study was to evaluate Chinese higher education students&#x2019; intentions to adopt AI-based robots for educational purposes. Based on the Technology Acceptance Model (TAM) 3 model, the current study proposes 14 hypotheses to evaluate students&#x2019; intention to adopt AI-based robots in education. The students&#x2019; data were collected and analyzed using PLS-SEM. The study findings revealed that 12 hypotheses were accepted and two were rejected. The results indicate that students are willing to accept AI-based robots in their education. However, the findings revealed an insignificant influence of job relevance and robot anxiety on perceived usefulness and ease of use, respectively. The findings of this study will provide insight into university administrations regarding the significance of AI-based robots in education. Moreover, the findings will help robot developers, policymakers, and university administrators design and implement AI-based robots that fulfill contemporary education needs.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mohammed A. M. AlGerafi et al.",
      "keywords": "Computer science; Robot; Artificial intelligence; Human\u2013computer interaction; Knowledge management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3314499",
      "cited_by_count": 85,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392151675",
      "doi": "10.1109/access.2024.3369906",
      "title": "A Review of Recent Advances, Challenges, and Opportunities in Malicious Insider Threat Detection Using Machine Learning Methods",
      "abstract": "Insider threat detection has become a paramount concern in modern times where organizations strive to safeguard their sensitive information and critical assets from malicious actions by individuals with privileged access. This survey paper provides a comprehensive overview of insider threat detection, highlighting its significance in the current landscape of cybersecurity. The review encompasses a broad spectrum of methodologies and techniques, with a particular focus on classical machine-learning approaches and their limitations in effectively addressing the intricacies of insider threats. Furthermore, the survey explores the utilization of modern deep learning and natural language processing (NLP) based methods as promising alternatives, shedding light on their advantages over traditional methods. The comprehensive analysis of results from experiments utilizing NLP and large language models to detect malicious insider threats on the CMU CERT dataset reveals promising insights. Studies surveyed in this paper indicate that these advanced techniques demonstrate notable efficacy in identifying suspicious activities and anomalous behaviors associated with insider threats within organizational systems. Additionally, the survey underscores the potential of NLP and large language model-based approaches, which can enhance threat detection by deciphering textual and contextual information. In the conclusion section, the paper offers valuable insights into the future directions of insider threat detection. It advocates for the integration of more sophisticated time-series-based techniques, recognizing the importance of temporal patterns in insider threat behaviors. These recommendations reflect the evolving nature of insider threats and emphasize the need for proactive, data-driven strategies to safeguard organizations against internal security breaches. In conclusion, this survey not only underscores the urgency of addressing insider threats but also provides a roadmap for the adoption of advanced methodologies to enhance detection and mitigation capabilities in contemporary cybersecurity paradigms.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Fatima Alzaabi et al.",
      "keywords": "Insider threat; Computer science; Computer security; Insider; Political science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3369906",
      "cited_by_count": 115,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3109725889",
      "doi": "10.1109/access.2020.3036728",
      "title": "A Holistic Review of Cybersecurity and Reliability Perspectives in Smart Airports",
      "abstract": "Advances in the Internet of Things (IoT) and aviation sector have resulted in the emergence of smart airports. Services and systems powered by the IoT enable smart airports to have enhanced robustness, efficiency and control, governed by real-time monitoring and analytics. Smart sensors control the environmental conditions inside the airport, automate passenger-related actions and support airport security. However, these augmentations and automation introduce security threats to network systems of smart airports. Cyber-attackers demonstrated the susceptibility of IoT systems and networks to Advanced Persistent Threats (APT), due to hardware constraints, software flaws or IoT misconfigurations. With the increasing complexity of attacks, it is imperative to safeguard IoT networks of smart airports and ensure reliability of services, as cyber-attacks can have tremendous consequences such as disrupting networks, cancelling travel, or stealing sensitive information. There is a need to adopt and develop new Artificial Intelligence (AI)-enabled cyber-defence techniques for smart airports, which will address the challenges brought about by the incorporation of IoT systems to the airport business processes, and the constantly evolving nature of contemporary cyber-attacks. In this study, we present a holistic review of existing smart airport applications and services enabled by IoT sensors and systems. Additionally, we investigate several types of cyber defence tools including AI and data mining techniques, and analyse their strengths and weaknesses in the context of smart airports. Furthermore, we provide a classification of smart airport sub-systems based on their purpose and criticality and address cyber threats that can affect the security of smart airport's networks.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Nickolaos Koroniotis et al.",
      "keywords": "Computer security; Computer science; Automation; Internet of Things; Context (archaeology); Cyber-attack; Smart system; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3036728",
      "cited_by_count": 166,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3011766849",
      "doi": "10.1109/access.2020.2981415",
      "title": "A Survey on Decentralized Consensus Mechanisms for Cyber Physical Systems",
      "abstract": "Modern industry 4.0 applications are shifting towards decentralized automation of computing and cyber-physical systems (CPS), which necessitates building a robust, secure, and efficient system that performs complex interactions with other physical processes. To handle complex interactions in CPS, trust and consensus among various stakeholders is a prime concern. In a similar direction, consensus algorithms in blockchain have evolved over the years that focus on building smart, robust, and secure CPS. Thus, it is imperative to understand the key components, functional characteristics, and architecture of different consensus algorithms used in CPS. Many consensus algorithms exist in the literature with a specified set of functionalities, performance, and computing services. Motivated from these facts, in this survey, we present a comprehensive analysis of existing state-of-the-art consensus mechanisms and highlight their strength and weaknesses in decentralized CPS applications. In the first part, we present the scope of the proposed survey and identify gaps in the existing surveys. Secondly, we present the review method and objectives of the proposed survey based on research questions that address the gaps in existing studies. Then, we present a solution taxonomy of decentralized consensus mechanisms for various CPS applications. Then, open issues and challenges are also discussed in deploying various consensus mechanisms in the CPS with their merits and demerits. The proposed survey will act as a road-map for blockchain developers and researchers to evaluate and design future consensus mechanisms, which helps to build an efficient CPS for industry 4.0 stakeholders.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Umesh Bodkhe et al.",
      "keywords": "Computer science; Cyber-physical system; Scope (computer science); Set (abstract data type); Key (lock); Data science; Strengths and weaknesses; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2981415",
      "cited_by_count": 178,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391791457",
      "doi": "10.1109/access.2024.3365634",
      "title": "Securing the Internet of Things in Artificial Intelligence Era: A Comprehensive Survey",
      "abstract": "The Internet of Things (IoT) has revolutionized various domains, enabling interconnected devices to communicate and exchange data. The integration of Artificial Intelligence (AI) in IoT systems further enhances their capabilities and potential benefits. Unfortunately, in the era of AI, ensuring the privacy and security of the IoT faces novel and specific challenges. IoT security is imperative, necessitating comprehensive strategies, including comprehension of IoT security challenges, implementation of AI methodologies, adoption of resilient security frameworks, and handling of privacy and ethical concerns to construct dependable and secure IoT systems. It is vital to note that the term &#x2018;security&#x2019; encompasses a more comprehensive view than cyberattacks alone. Therefore, with an emphasis on securing against cyberattacks, this comprehensive survey also includes physical security threats on the IoT. It investigates the complexities and solutions for IoT systems, placing particular emphasis on AI-based security techniques. The paper undertakes a categorization of the challenges associated with ensuring IoT security, investigates the utilization of AI in IoT security, presents security frameworks and strategies, underscores privacy and ethical considerations, and provides insights derived from practical case studies. Furthermore, the survey sheds light on emerging trends concerning IoT security in the AI era. This survey provides significant contributions to the understanding of establishing dependable and secure IoT systems through an exhaustive examination of the present condition of IoT security and the ramifications of AI on it.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mamoona Humayun et al.",
      "keywords": "Computer science; The Internet; Internet privacy; World Wide Web; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3365634",
      "cited_by_count": 61,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3163755028",
      "doi": "10.1109/access.2021.3078549",
      "title": "Internet of Things 2.0: Concepts, Applications, and Future Directions",
      "abstract": "Applications and technologies of the Internet of Things are in high demand with the increase of network devices. With the development of technologies such as 5G, machine learning, edge computing, and Industry 4.0, the Internet of Things has evolved. This survey article discusses the evolution of the Internet of Things and presents the vision for Internet of Things 2.0. The Internet of Things 2.0 development is discussed across seven major fields. These fields are machine learning intelligence, mission critical communication, scalability, energy harvesting-based energy sustainability, interoperability, user friendly IoT, and security. Other than these major fields, the architectural development of the Internet of Things and major types of applications are also reviewed. Finally, this article ends with the vision and current limitations of the Internet of Things in future network environments.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Ian Zhou et al.",
      "keywords": "Interoperability; Web of Things; Computer science; The Internet; Internet of Things; Scalability; Internet appliance; World Wide Web; Telecommunications; Computer security; Internet access",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3078549",
      "cited_by_count": 127,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387490462",
      "doi": "10.1109/access.2023.3323573",
      "title": "An Explainable Ensemble Deep Learning Approach for Intrusion Detection in Industrial Internet of Things",
      "abstract": "Ensuring the security of critical Industrial Internet of Things (IIoT) systems is of utmost importance, with a primary focus on identifying cyber-attacks using Intrusion Detection Systems (IDS). Deep learning (DL) techniques are frequently utilized in the anomaly detection components of IDSs. However, these models often generate high false-positive rates, and their decision-making rationale remains opaque, even to experts. Gaining insights into the reasons behind an IDS&#x2019;s decision to block a specific packet can aid cybersecurity professionals in assessing the system&#x2019;s effectiveness and creating more cyber-resilient solutions. In this paper, we offer an explainable ensemble DL-based IDS to improve the transparency and robustness of DL-based IDSs in IIoT networks. The framework incorporates Shapley additive explanations (SHAP) and Local comprehensible-independent Clarifications (LIME) methods to elucidate the decisions made by DL-based IDSs, providing valuable insights to experts responsible for maintaining IIoT network security and developing more cyber-resilient systems. The ToN&#x005F;IoT dataset was used to evaluate the efficacy of the suggested framework. As a baseline intrusion detection system, the extreme learning machines (ELM) model was implemented and compared with other models. Experiments show the effectiveness of ensemble learning to improve the results.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mousa'B Mohammad Shtayat et al.",
      "keywords": "Computer science; Intrusion detection system; Ensemble learning; Artificial intelligence; Robustness (evolution); Anomaly detection; Machine learning; Industrial Internet; Computer security; Transparency (behavior); The Internet; Deep learning; Network security; Internet of Things",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3323573",
      "cited_by_count": 70,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2921347871",
      "doi": "10.1109/access.2019.2904006",
      "title": "The Effect of Security, Privacy, Familiarity, and Trust on Users\u2019 Attitudes Toward the Use of the IoT-Based Healthcare: The Mediation Role of Risk Perception",
      "abstract": "The Internet of Things (IoT) refers to the network of devices which contain electronics, sensors or software that enables them to connect at anytime and anywhere through a cyber-physical system. Before the establishment of such a system, it should be considered to what extent the users are ready to adopt and use it in their daily routines. Therefore, this paper explores users' attitudes towards using IoT technologies to receive healthcare services. This is in contrast to most previous research, which has studied the technical requirements or devices of the IoT that are required in healthcare services, or ways in which connectivity and performance can be improved using the IoT. Based on known models of technology acceptance, an integrated framework was developed to investigate the impact of security and privacy concerns, and familiarity with the technology, on users' trust in the IoT, and then to measure the effect of that trust on Omani users' attitudes regarding use of IoT technologies to receive healthcare services. This framework enabled the measurement of risk perception as a mediator between user trust and their attitudes towards using the IoT. Data were collected from 387 respondents and were analysed using SPSS 25 and AMOS 25 statistics software. Exploratory and confirmatory analysis and structural equation modelling were applied. The findings showed that levels of security, privacy and familiarity affected trust in the IoT. Furthermore, these levels of trust in the IoT were found to affect both users' perceptions of risk in, and their attitude towards, using the IoT. The users' risk perception partially mediated the relations between users' trust and their attitude regarding use of the IoT. The framework was supported and interpreted by 40 per cent of the variance in the attitude towards using the IoT in healthcare, while the mediator showed 47 per cent of the variance in the attitude towards using the IoT in healthcare.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Mansour Naser Alraja et al.",
      "keywords": "Mediation; Structural equation modeling; Computer science; Risk perception; Internet of Things; Perception; Health care; Internet privacy; Confirmatory factor analysis; Technology acceptance model; Software; Computer security; Usability; Human\u2013computer interaction; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2904006",
      "cited_by_count": 131,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4366966548",
      "doi": "10.1109/access.2023.3269980",
      "title": "A Survey on Securing Federated Learning: Analysis of Applications, Attacks, Challenges, and Trends",
      "abstract": "The growth of data generation capabilities, facilitated by advancements in communication and computation technologies, as well as the rise of the Internet of Things (IoT), results in vast amounts of data that significantly enhance the performance of machine learning models. However, collecting all necessary data to train accurate models is often unfeasible due to privacy laws. Federated Learning (FL) evolved as a collaborative machine learning approach for training models without sharing private data. Unfortunately, several in-design vulnerabilities have been exposed, allowing attackers to infer private data of participants and negatively impacting the performance of the federated model. In light of these challenges and to encourage the development of FL solutions, this paper provides a comprehensive analysis of secure FL proposals that both protect user privacy and enhance the performance of the model. We performed a systematic review using predefined criteria to screen and extract data from multiple electronic databases, resulting in a final set of studies for analysis. Through the systematic review methodology, the paper groups the security vulnerabilities of FL into model performance and data privacy attacks. It also presents an analysis and comparison of potential mitigation strategies against these attacks. Additionally, the paper conducts a security analysis of state-of-the-art FL applications and proposals based on the vulnerabilities addressed. Finally, the paper outlines the main applications of secure FL and lists future research challenges. The survey highlights the crucial role of security strategies in ensuring the protection of user privacy and model performance in the context of future FL applications.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Helio N. Cunha Neto et al.",
      "keywords": "Computer science; Context (archaeology); Computer security; Data sharing; Federated learning; The Internet; Information privacy; Threat model; Big data; Data modeling; Data science; World Wide Web; Artificial intelligence; Database; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3269980",
      "cited_by_count": 75,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3198897768",
      "doi": "10.1109/access.2021.3109168",
      "title": "A Comprehensive Unsupervised Framework for Chronic Kidney Disease Prediction",
      "abstract": "The incidence, prevalence, and progression of chronic kidney disease (CKD) conditions have evolved over time, especially in countries that have varied social determinants of health. In most countries, diabetics and hypertension are the main causes of CKDs. The global guidelines classify CKD as a condition that results in decreased kidney function over time, as indicated by glomerular filtration rate (GFR) and markers of kidney damage. People with CKDs are likely to die at an early age. It is crucial for doctors to diagnose various conditions associated with CKD in an early stage because early detection may prevent or even reverse kidney damage. Early detection can provide better treatment and proper care to the patients. In many regional hospital/clinics, there is a shortage of nephrologists or general medical persons who diagnose the symptoms. This has resulted in patients waiting longer to get a diagnosis. Therefore, this research believes developing an intelligent system to classify a patient into classes of &#x2018;CKD&#x2019; or &#x2018;Non-CKD&#x2019; can help the doctors to deal with multiple patients and provide diagnosis faster. In time, organizations can implement the proposed machine learning framework in regional clinics that have lower medical expert retention, this can provide early diagnosis to patients in regional areas. Although, several researchers have tried to address the situation by developing intelligent systems using supervised machine learning methods, till date limited studies have used unsupervised machine learning algorithms. The primary aim of this research is to implement and compare the performance of various unsupervised algorithms and identify best possible combinations that can provide better accuracy and detection rate. This research has implemented five unsupervised algorithms, K-Means Clustering, DB-Scan, I-Forest, and Autoencoder. And integrating them with various feature selection methods. Integrating feature reduction methods with K-Means Clustering algorithm has achieved an overall accuracy of 99&#x0025; in classifying the clinical data of CKD and Non-CKD.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Linta Antony et al.",
      "keywords": "Kidney disease; Economic shortage; Renal function; Machine learning; Medicine; Artificial intelligence; Intensive care medicine; Incidence (geometry); Computer science; Disease; Healthcare system; Health care; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3109168",
      "cited_by_count": 68,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3016672529",
      "doi": "10.1109/access.2020.2988397",
      "title": "A Comprehensive State-of-the-Art Survey on Hybrid Renewable Energy System Operations and Planning",
      "abstract": "The use of hybrid renewable energy systems among household consumers in sub-Sahara Africa (SSA) is increasingly gaining attention. This is due to low electrification rates in many of the countries in SSA. A hybrid energy system for power generation combines various energy systems, either renewable or a combination of renewable and fossil-powered sources for optimal power extraction and operation. In the era of decarbonization of the electricity grid through the use of renewable energy, hybridization of sources is an essential condition for the production of electricity. Based on current quest for renewable energy (RE) expansion in the global energy mix, optimum conditions for the production and adoption of hybrid renewable energy systems (HRES) at micro-levels are indispensable and must be advocated for. This can be justified based on the perpetually rising cost of energy for socio-economic development. This paper presents a survey of major issues regarding the motivations and specific benefits behind the adoption of HRES. Also presented, is a discussion on different renewable energy sources that can be adopted for HRES application for both grid and off-grid consumers. Furthermore, a discussion on the important issues as it pertains to the design and implementation of HRES is also presented. Finally, a policy discussion on the affordability of HRES in a low-income household is presented.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Olubayo Moses Babatunde et al.",
      "keywords": "Renewable energy; Environmental economics; Electrification; Electricity generation; Electricity; Grid; Intermittent energy source; Energy mix; Feed-in tariff; Computer science; Business; Distributed generation; Energy policy; Power (physics); Economics; Engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2988397",
      "cited_by_count": 117,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391855027",
      "doi": "10.1109/access.2024.3365934",
      "title": "A Systematic Review of the Digital Transformation of the Building Construction Industry",
      "abstract": "Construction sector spending makes a significant contribution to the global economy, with approximately $10 trillion being spent on building and construction activities annually. However, the construction industry has traditionally been perceived as slow to adapt to new technologies compared to other sectors. Recently, the construction industry has experienced a substantial shift towards Digital Transformation. As new technologies have emerged, the construction industry has begun to realize the importance of Digital Transformation in the pre-construction, construction, and facility management phases. A high degree of Digital Transformation has been seen regarding site monitoring, wearables, sensors, and identifying hazards. This paper intends to sketch a global picture of digital technologies implemented in the construction industry throughout the entire project lifecycle. By fully analyzing more than 200 papers, the paper finds that various aspects of the construction industry, including technologies, policies, regulations, and infrastructures, are still in the early stages of Digital Transformation. The findings from this review will help researchers and practitioners in the construction industry understand the global picture of digital technology implementation and where the construction industry stands in the Digital Transformation process. This paper also serves as a starting point for future work on Digital Transformation in the construction industry. The research paper is limited to vertical aspects in building projects and does not include horizontal integration. Finally, this study will give a guideline with successful examples of which technologies are being used in specific phases, so future researchers can get a holistic view of the use of digital technology in the entire building environment.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Khalid K. Naji et al.",
      "keywords": "Computer science; Transformation (genetics); Digital transformation; Construction industry; Construction engineering; Engineering; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3365934",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3012041993",
      "doi": "10.1109/mts.2020.2967486",
      "title": "On the Morality of Artificial Intelligence [Commentary]",
      "abstract": "Examines ethical principles and guidelines that surround machine learning and artificial intelligence.",
      "year": "2020",
      "journal": "IEEE Technology and Society Magazine",
      "authors": "Alexandra Sasha Luccioni et al.",
      "keywords": "Morality; Artificial intelligence; Computer science; Cognitive science; Psychology; Political science; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mts.2020.2967486",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4384917038",
      "doi": "10.1109/access.2023.3296707",
      "title": "A Comprehensive Survey of Generative Adversarial Networks (GANs) in Cybersecurity Intrusion Detection",
      "abstract": "Generative Adversarial Networks (GANs) have seen significant interest since their introduction in 2014. While originally focused primarily on image-based tasks, their capacity for generating new, synthetic data has brought them into many different fields of Machine Learning research. Their use in cybersecurity has grown swiftly, especially in tasks which require training on unbalanced datasets of attack classes. In this paper we examine the use of GANs in Intrusion Detection Systems (IDS) and how they are currently being employed in this area of research. GANs are currently in use for the creation of adversarial examples, editing the semantic information of data, creating polymorphic samples of malware, augmenting data for rare classes, and much more. We have endeavored to create a paper that may act as a primer for cybersecurity specialists and machine learning researchers alike. This paper details what GANs are and how they work, the current types of GAN in use in the area, datasets used in this research, metrics for evaluation, current areas of use in intrusion detection, and when and how they are best used.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Aeryn Dunmore et al.",
      "keywords": "Computer science; Adversarial system; Malware; Intrusion detection system; Adversarial machine learning; Generative grammar; Computer security; Machine learning; Artificial intelligence; Intrusion; Data science; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3296707",
      "cited_by_count": 98,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3155975492",
      "doi": "10.1109/access.2021.3072782",
      "title": "AI Ethics: Algorithmic Determinism or Self-Determination? The GPDR Approach",
      "abstract": "Artificial Intelligence (AI) refers to systems designed by humans, interpreting the already collected data and deciding the best action to take, according to the pre-defined parameters, in order to achieve the given goal. Designing, trial and error while using AI, brought ethics to the center of the dialogue between tech giants, enterprises, academic institutions as well as policymakers. Ethical challenges in AI brought ethical AI framework in place in an attempt to regulate people&amp;#x2019;s lives and interactions, used for the benefit of society, for the human rights&amp;#x2019; protection as well as for the respect of individual&amp;#x2019;s privacy and autonomy. The paper aims to summarize and critically evaluate the basic principles for the use of AI, with emphasis to the General Data Protection Regulation&amp;#x2019;s (GDPR) approach, concerning data subject&amp;#x2019;s consent, data protection principles and data subject&amp;#x2019;s rights in a context of &amp;#x2018;privacy by design&amp;#x2019; architecture.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Maria Milossi et al.",
      "keywords": "Determinism; Computer science; Theoretical computer science; Epistemology; Philosophy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3072782",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3037923113",
      "doi": "10.1109/access.2020.3015962",
      "title": "Security and Privacy for mHealth and uHealth Systems: A Systematic Mapping Study",
      "abstract": "An increased adoption of mobile health (mHealth) and ubiquitous health\\n(uHealth) systems empower users with handheld devices and embedded sensors for\\na broad range of healthcare services. However, m/uHealth systems face\\nsignificant challenges related to data security and privacy that must be\\naddressed to increase the pervasiveness of such systems. This study aims to\\nsystematically identify, classify, compare, and evaluate state-of-the-art on\\nsecurity and privacy of m/uHealth systems. We conducted a systematic mapping\\nstudy (SMS) based on 365 qualitatively selected studies to (i) classify the\\ntypes, frequency, and demography of published research and (ii) synthesize and\\ncategorize research themes, (iii) recurring challenges, (iv) prominent\\nsolutions (i.e., research outcomes) and their (v) reported evaluations (i.e.,\\npractical validations). Results suggest that the existing research on security\\nand privacy of m/uHealth systems primarily focuses on select group of control\\nfamilies (compliant with NIST800-53), protection of systems and information,\\naccess control, authentication, individual participation, and privacy\\nauthorisation. In contrast, areas of data governance, security and privacy\\npolicies, and program management are under-represented, although these are\\ncritical to most of the organizations that employ m/uHealth systems. Most\\nresearch proposes new solutions with limited validation, reflecting a lack of\\nevaluation of security and privacy of m/uHealth in the real world. Empirical\\nresearch, development, and validation of m/uHealth security and privacy is\\nstill incipient, which may discourage practitioners from readily adopting\\nsolutions from the literature. This SMS facilitates knowledge transfer,\\nenabling researchers and practitioners to engineer security and privacy for\\nemerging and next generation of m/uHealth systems.\\n",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Leonardo Horn Iwaya et al.",
      "keywords": "Computer science; mHealth; Information privacy; Computer security; Internet privacy; World Wide Web; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3015962",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391992626",
      "doi": "10.1109/access.2024.3367792",
      "title": "ChatGPT\u2019s Security Risks and Benefits: Offensive and Defensive Use-Cases, Mitigation Measures, and Future Implications",
      "abstract": "ChatGPT has been acknowledged as a powerful tool that can radically boost productivity across a wide range of industries. It reveals potential in cybersecurity-related tasks such as social engineering. Nevertheless, this possibility raises important concerns regarding the thin line separating moral use of this technology from its harmful usage. It is imperative to address the challenges of distinguishing between legitimate and malevolent use of ChatGPT. This research paper investigates the many concerns of ChatGPT in cybersecurity, privacy and enterprise settings. It covers harmful attacker uses such as injecting malicious prompts, testing brute force attacks, preparing and developing ransomware attacks, etc. Defenders&#x2019; proactive activities are also addressed, highlighting ChatGPT&#x2019;s significance in security operations and threat intelligence. These defensive operations are classified based on the National Institute of Standards and Technology cybersecurity framework. They involve analyzing configuration files, inquiring about authoritative server, improving security in various systems, etc. Moreover, secure enterprise practices and mitigations spread through five classes are proposed, with an emphasis on clear usage standards and guidelines establishment, personally identifiable information protection, adversarial attack prevention, watermarking generated content, etc. An integrated discussion digs into the interaction of offensive and defensive applications, covering ethical and practical concerns. Future attacks are also discussed, along with potential solutions such as content filtering and collaboration. Finally, a comparative analysis with recent research on ChatGPT security concerns is directed. The paper provides a thorough framework to comprehend the range of implications associated with ChatGPT, enabling the navigation of cybersecurity and privacy challenges.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Maha Charfeddine et al.",
      "keywords": "Offensive; Risk analysis (engineering); Computer security; Computer science; Business; Operations research; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3367792",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285113672",
      "doi": "10.1109/access.2022.3180367",
      "title": "Blockchain-Based Identity Management Systems in Health IoT: A Systematic Review",
      "abstract": "Identity and Access Management (IAM) systems are crucial for any information system, such as healthcare information systems. Health IoT (HIoT) applications are targeted by attackers due to the high-volume and sensitivity of health data. Thus, IAM systems for HIoT need to be built with high standards and based on reliable frameworks. Blockchain (BC) is an emerging technology widely used for developing decentralized IAM solutions. Although, the integration of BC in HIoT for proposing IAM solutions has gained recent attention, BC is an evolving technology and needs to be studied carefully before using it for IAM solutions in HIoT applications. A systematic literature review was conducted on the BC-based IAM systems in HIoT applications to investigate the security aspect. Twenty-four studies that satisfied the inclusion criteria and passed the quality assessment were included in this review. We studied BC-based solutions in HIoT applications to explore the IAM system architecture, security requirements and threats. We summarized the main components and technologies in typical BC-based IAM systems and the layered architecture of the BC-based IAM system in HIoT. Accordingly, the security threats and requirements were summarized. Our systematic review shows that there is a lack of a comprehensive security framework, risk assessments, and security and functional performance evaluation metrics in BC-based IAM in HIoT applications",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Bandar Alamri et al.",
      "keywords": "Computer science; Identity management; Blockchain; Computer security; Risk analysis (engineering); Systematic review; Systems engineering; Access control; Engineering; MEDLINE; Business",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3180367",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3118345665",
      "doi": "10.1109/access.2021.3050929",
      "title": "Sketching an AI Marketplace: Tech, Economic, and Regulatory Aspects",
      "abstract": "Artificial intelligence shows promise for solving many practical societal problems in areas such as healthcare and transportation. However, the current mechanisms for AI model diffusion such as Github code repositories, academic project webpages, and commercial AI marketplaces have some limitations; for example, a lack of monetization methods, model traceability, and model auditabilty. In this work, we sketch guidelines for a new AI diffusion method based on a decentralized online marketplace. We consider the technical, economic, and regulatory aspects of such a marketplace including a discussion of solutions for problems in these areas. Finally, we include a comparative analysis of several current AI marketplaces that are already available or in development. We find that most of these marketplaces are centralized commercial marketplaces with relatively few models. CCBY",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Abhishek Kumar et al.",
      "keywords": "Monetization; Computer science; Traceability; Sketch; Work (physics); Data science; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3050929",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391547503",
      "doi": "10.1109/tpami.2024.3361979",
      "title": "Metrics for Dataset Demographic Bias: A Case Study on Facial Expression Recognition",
      "abstract": "Demographic biases in source datasets have been shown as one of the causes of unfairness and discrimination in the predictions of Machine Learning models. One of the most prominent types of demographic bias are statistical imbalances in the representation of demographic groups in the datasets. In this article, we study the measurement of these biases by reviewing the existing metrics, including those that can be borrowed from other disciplines. We develop a taxonomy for the classification of these metrics, providing a practical guide for the selection of appropriate metrics. To illustrate the utility of our framework, and to further understand the practical characteristics of the metrics, we conduct a case study of 20 datasets used in Facial Emotion Recognition (FER), analyzing the biases present in them. Our experimental results show that many metrics are redundant and that a reduced subset of metrics may be sufficient to measure the amount of demographic bias. The article provides valuable insights for researchers in AI and related fields to mitigate dataset bias and improve the fairness and accuracy of AI models.",
      "year": "2024",
      "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Iris Dominguez-Catena et al.",
      "keywords": "Artificial intelligence; Computer science; Facial expression; Facial expression recognition; Facial recognition system; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tpami.2024.3361979",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4205417788",
      "doi": "10.1109/access.2021.3132574",
      "title": "Exploring the Influence of Direct and Indirect Factors on Information Security Policy Compliance: A Systematic Literature Review",
      "abstract": "Information systems security is considered one of the key issues concerning organizations&#x2019; management. Despite the massive investment that organizations make to safeguard their systems, there are still many internal security breaches. The increase in insider threats to information systems can be related to the employees&#x2019; compliance toward information security policy. Several review papers were conducted to explore information security policy compliance behavior research. However, the literature lacks insight into the positive and negative (direct or indirect) influence of human and organizational theories and their factors influencing information security policy compliance behavior. Therefore, this paper provides a systematic literature review synthesizing the psychological theories, organizational theories, and other internal and external factors on information security policy compliance researches. The results analysis of 87 studies showed that the general deterrence theory, theory of planned behavior, and protection motivation theory are the most frequently used. The influencing factors of theories are mostly similar in the results. Furthermore, information security education, training and awareness, trust, and leadership, among many other internal and external factors, are highly used. This study is one of the first researches that explores the relationship types among the influencing factors; emphasizing the direct and indirect effect, and information security policy compliance behavior. This paper also identifies some gaps in information security policy compliance behavior research and proposes future works. In addition, it provides a theoretical contribution and practical insight in the context of information security policy compliance.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mada Alassaf et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3132574",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389332140",
      "doi": "10.1109/access.2023.3339553",
      "title": "Unleashing the Potential of Conversational AI: Amplifying Chat-GPT\u2019s Capabilities and Tackling Technical Hurdles",
      "abstract": "Conversational AI has seen a growing interest among government, researchers, and industrialists. This comprehensive survey paper provides an in-depth analysis of large language models, specifically focusing on ChatGPT. This paper discusses the architecture, training process, and challenges associated with large language models, including bias, interpretability, and ethics. It explores various applications of ChatGPT and examines future research trends, such as improving model generalization, addressing data scarcity, and integrating multimodal capabilities. This survey also serves as a roadmap for researchers, practitioners, and policymakers, offering valuable insights into the current state and future potential of large language models and ChatGPT.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Vikas Hassija et al.",
      "keywords": "Interpretability; Computer science; Scarcity; Government (linguistics); Process (computing); Generalization; Data science; Management science; Knowledge management; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3339553",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388936643",
      "doi": "10.1109/access.2023.3335984",
      "title": "An Optimized Role-Based Access Control Using Trust Mechanism in E-Health Cloud Environment",
      "abstract": "In today&#x2019;s world, services are improved and advanced in every field of life. Especially in the health sector, information technology (IT) plays a vigorous role in electronic health (e-health). To achieve benefits from e-health, its cloud-based implementation is necessary. With this environment&#x2019;s multiple benefits, privacy and security loopholes exist. As the number of users grows, the Electronic Healthcare System&#x2019;s (EHS) response time becomes slower. This study presented a trust mechanism for access control (AC) known as role-based access control (RBAC) to address this issue. This method observes the user&#x2019;s behavior and assigns roles based on it. The AC module has been implemented using SQL Server, and an administrator develops controls for users with roles and access to multiple EHS modules. To validate the user&#x2019;s trust value, A.net-based framework has been introduced. The framework of e-health proposed in this research ensures that users can protect their data from intruders and other security threats.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ateeq Ur Rehman Butt et al.",
      "keywords": "Cloud computing; Role-based access control; Access control; Computer science; Computer security; Control (management); Field (mathematics); Mechanism (biology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3335984",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392902203",
      "doi": "10.1109/access.2024.3376605",
      "title": "An IoT and Blockchain-Based Secure and Transparent Supply Chain Management Framework in Smart Cities Using Optimal Queue Model",
      "abstract": "The process of controlling the flow of products and services from a company by encompassing each stage involved in transforming raw materials and parts into finished items, also delivering them to the final consumer is known as Supply Chain Management (SCM). The development of numerous smart city applications including smart grids, smart homes, smart supply chains, and smart healthcare has drawn attention to the Internet of Things (IoT). Nowadays, researchers are considering the smart healthcare system&#x2019;s role as a Public Emergency Service (PES) to treat patients promptly. A distributed smart fire brigade system receives little attention like PES to save lives and property from catastrophic fire damage. The conventional PES methods are created using a centralized method that needs a lot of processing power and doesn&#x2019;t offer timely services. The traditional systems developed for managing the supply chain have drawbacks like single-point failure issues, data integrity, transparency, and lack of trust. To alleviate the existing issues, in this paper, a Blockchain and IoT Enable Secure and Transparent Supply Chain Management framework is utilized for PES in the smart city environment. Further, two edge computing servers, like a service controller and an IoT controller are adapted. The local storage is handled by the service and IoT controller. Thus, it enhances the data processing speed of PES requests and PES fulfillment. The service controller utilizes the Optimal Queue Model to manage the PES requests based on the minimum service queue length. The efficiency of the network is improved by fine-tuning the parameters from the Queue model with the aid of a Revised Fitness-based Political Optimizer (RF-PO). The multi-objective constraints like queue length, utilization, actual arrival time, expected arrival time, and end-to-end delay are utilized for the efficient supply chain system. These stimulated results show the feasibility and effectiveness of the supply chain framework.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ahmad Y. A. Bani Ahmad et al.",
      "keywords": "Blockchain; Internet of Things; Computer science; Supply chain management; Computer security; Supply chain; Queue; Computer network; Distributed computing; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3376605",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226313496",
      "doi": "10.1109/access.2022.3160213",
      "title": "Antimicrobial Resistance and Machine Learning: Challenges and Opportunities",
      "abstract": "Antimicrobial Resistance (AMR) has been identified by the World Health Organisation (WHO) as one of the top ten global health threats. Inappropriate use of antibiotics around the world and in particular in Low-to-Middle-Income Countries (LMICs), where antibiotics use and prescription are poorly managed, is considered one of the main reasons for this problem. It is projected that the COVID-19 pandemic will accelerate the threat of AMR due to the increasing use of antibiotics across the world, and especially in countries with limited resources. In recent years, machine learning-based methods showed promising results and proved capable of providing the necessary tools to inform antimicrobial prescription and combat AMR. This timely paper provides a critical and technical review of existing machine learning-based methods for addressing AMR. First, an overview of the AMR problem as a global threat to public health, and its impact on countries with limited resources (LMICs) are presented. Then, a technical review and evaluation of existing literature that utilises machine learning to tackle AMR are provided with emphasis on methods that use readily available demographic and clinical data as well as microbial culture and sensitivity laboratory data of clinical isolates associated with multi-drug resistant infections. This is followed by a discussion of challenges and limitations that are considered barriers to scaling up the use of machine learning to address AMR. Finally, a framework for accelerating the use of AMR data-driven framework, and building a feasible solution that can be realistically implemented in LMICs is presented with a discussion of future directions and recommendations.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Eyad Elyan et al.",
      "keywords": "Computer science; Pandemic; Risk analysis (engineering); Antibiotic resistance; Medical prescription; Global health; Machine learning; Artificial intelligence; Data science; Coronavirus disease 2019 (COVID-19); Public health; Medicine; Antibiotics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3160213",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226062023",
      "doi": "10.1109/access.2022.3169765",
      "title": "Machine Learning Methods in Smart Lighting Toward Achieving User Comfort: A Survey",
      "abstract": "Smart lighting has become a universal smart product solution, with global revenues of up to US<inline-formula> <tex-math notation=\"LaTeX\">$\\$ $ </tex-math></inline-formula>5.9 billion by 2021. Six main factors drive the technology: light-emitting diode (LED) lighting, sensors, control, analytics, and intelligence. The Internet of things (IoT) concept with the end device, platform, and application layer plays an essential role in optimizing the advantages of LED lighting in the emergence of smart lighting. The ultimate aim of smart lighting research is to introduce low energy efficiency and high user comfort, where the latter is still in the infancy stage. This paper presents a systematic literature review (SLR) from a bird&#x2019;s eye view covering full-length research topics on smart lighting, including issues, implementation targets, technological solutions, and prospects. In addition to that, this paper also provides a detailed and extensive overview of emerging machine learning techniques as a key solution to overcome complex problems in smart lighting. A comprehensive review of improving user comfort is also presented, such as the methodology and taxonomy of activity recognition as a promising solution and user comfort metrics, including light utilization ratio, unmet comfort ratio, light to comfort ratio, power reduction rate, flickering perception, Kruithof&#x2019;s comfort curve, correlated color temperature, and relative mean square error. Finally, we discuss in-depth open issues and future challenges in increasing user comfort in smart lighting using activity recognition.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Aji Gautama Putrada et al.",
      "keywords": "Computer science; Smart lighting; Human\u2013computer interaction; Architectural engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3169765",
      "cited_by_count": 84,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2999891794",
      "doi": "10.1109/access.2020.2967436",
      "title": "Requirements for Big Data Adoption for Railway Asset Management",
      "abstract": "Nowadays, huge amounts of data have been captured along with the day-to-day operation of assets including railway systems. Hence, we have come to the era of big data. The utilization of big data technologies for asset condition information management is becoming indispensable for improving asset management decision making. The vital information such as precursor information collected on failure modes and knowledge that may be available for analysis is hidden within the large extent of data. There are analysis tools incorporated with techniques such as multiple regression analysis and machine learning that are facilitated by the availability of big data. Therefore, the utilization of big data technologies for asset condition information management is becoming indispensable for improving asset management decision making. This paper provides a review of the requirements and challenges for big data analytics applications to railway asset management. The review focuses on railway asset data collection, data management, data applications with the implementation of Blockchain technology as well as big data analytics technologies. The need for, and the importance of big data analytics in railway asset management; and the requirement for the asset condition data collection in the railway industry are highlighted. Research challenges in railway asset management via application of big data analytics are identified and the future research directions are presented.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Paul E. McMahon et al.",
      "keywords": "Big data; Asset management; Asset (computer security); Computer science; Data management; Analytics; IT asset management; Data science; Data analysis; Risk analysis (engineering); Business; Database; Computer security; Finance; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2967436",
      "cited_by_count": 56,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4323644147",
      "doi": "10.1109/access.2023.3251892",
      "title": "Explainable Misinformation Detection Across Multiple Social Media Platforms",
      "abstract": "Web Information Processing (W.I.P.) has enormously impacted modern society since a huge percentage of the population relies on the internet to acquire information. Social Media platforms provide a channel for disseminating information and a breeding ground for spreading misinformation, creating confusion and fear among the population. One of the techniques for the detection of misinformation is machine learning-based models. However, due to the availability of multiple social media platforms, developing and training AI-based models has become a tedious job. Despite multiple efforts to develop machine learning-based methods for identifying misinformation, more work must be done on developing an explainable generalized detector capable of robust detection and generating explanations beyond black-box outcomes. Knowing the reasoning behind the outcomes is essential to make the detector trustworthy. Hence employing explainable A.I. techniques is of utmost importance. In this work, the integration of two machine learning approaches, namely domain adaptation and explainable A.I., is proposed to address these two issues of generalized detection and explainability. Firstly the Domain Adversarial Neural Network (DANN) develops a generalized misinformation detector across multiple social media platforms. DANN generates the classification results for test domains with relevant but unseen data. The DANN-based, traditional black-box model cannot justify and explain its outcome, i.e., the labels for the target domain. Hence a Local Interpretable Model-Agnostic Explanations (LIME) explainable A.I. model is applied to explain the outcome of the DANN model. To demonstrate these two approaches and their integration for effective explainable generalized detection, COVID-19 misinformation is considered a case study. We experimented with two datasets and compared results with and without DANN implementation. It is observed that using DANN significantly improves the F1 score of classification and increases the accuracy by 3&#x0025; and A.U.C. by 9&#x0025;. The results show that the proposed framework performs well in the case of domain shift and can learn domain-invariant features while explaining the target labels with LIME implementation. This can enable trustworthy information processing and extraction to combat misinformation effectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Gargi Joshi et al.",
      "keywords": "Misinformation; Computer science; Social media; Artificial intelligence; Machine learning; Population; Domain (mathematical analysis); Data science; World Wide Web; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3251892",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3019569977",
      "doi": "10.1109/access.2020.2989870",
      "title": "Comprehensive Survey of Machine Learning Approaches in Cognitive Radio-Based Vehicular Ad Hoc Networks",
      "abstract": "Nowadays, machine learning (ML), which is one of the most rapidly growing technical tools, is extensively used to solve critical challenges in various domains. Vehicular ad hoc network (VANET) is expected to be the key role player in reducing road casualties and traffic congestion. To ensure this role, a gigantic amount of data should be exchanged. However, current allocated wireless access for VANET is inadequate to handle such massive data amounts. Therefore, VANET faces a spectrum scarcity issue. Cognitive radio (CR) is a promising solution to overcome such an issue. CR-based VANET or CR-VANET must achieve several performance enhancement measures, including ultra-reliable and low-latency communication. ML methods can be integrated with CR-VANET to make CR-VANET highly intelligent, achieve rapid adaptability to the dynamicity of the environment, and improve the quality of service in an energy-efficient manner. This paper presents an overview of ML, CR, VANET, and CR-VANET, including their architectures, functions, challenges, and open issues. The applications and roles of ML methods in CR-VANET scenarios are reviewed. Insights into the use of ML for autonomous or driver-less vehicles are also presented. Current advancements in the amalgamation of these prominent technologies and future research directions are discussed.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Md. Asif Hossain et al.",
      "keywords": "Vehicular ad hoc network; Computer science; Cognitive radio; Wireless ad hoc network; Quality of service; Computer network; Wireless; Key (lock); Scarcity; Adaptability; Telecommunications; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2989870",
      "cited_by_count": 99,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391661563",
      "doi": "10.1109/access.2024.3364387",
      "title": "Trustworthiness Assurance Assessment for High-Risk AI-Based Systems",
      "abstract": "This work proposes methodologies for ensuring the trustworthiness of high-risk artificial&#13;\\nintelligence (AI) systems (AIS) to achieve compliance with the European Union\u2019s (EU) AI Act. Highrisk classified AIS must fulfill seven requirements to be considered trustworthy and human-centric, and&#13;\\nsubsequently be considered for deployment. These requirements are equally important, mutually supportive,&#13;\\nand should be implemented and evaluated throughout the AI lifecycle. The assurance of trustworthiness is&#13;\\ninfluenced by ethical considerations, amongst others. Hence, the operational design domain (ODD) and&#13;\\nbehavior competency (BC) concepts from the automated driving domain are utilized in risk assessment&#13;\\nstrategies to quantify different types of residual risks. The methodology presented is guided by the consistent&#13;\\napplication of the ODD and its related BC concept throughout the entire AI lifecycle, focusing on the&#13;\\ntrustworthiness assurance framework and its associated process as the main pillars for AIS certification.&#13;\\nThe achievement of the overall objective of trustworthy and human-centric AIS is divided into seven&#13;\\ninterconnected sub-goals: the formulation of use restrictions, the trustworthiness assurance/argument itself,&#13;\\nthe identification of dysfunctional cases, the utilization of scenario This work proposes methodologies for ensuring the trustworthiness of high-risk artificial intelligence (AI) systems (AIS) to achieve compliance with the European Union\u2019s (EU) AI Act. High-risk classified AIS must fulfill seven requirements to be considered trustworthy and human-centric, and subsequently be considered for deployment. These requirements are equally important, mutually supportive, and should be implemented and evaluated throughout the AI lifecycle. The assurance of trustworthiness is influenced by ethical considerations, amongst others. Hence, the operational design domain (ODD) and behavior competency (BC) concepts from the automated driving domain are utilized in risk assessment strategies to quantify different types of residual risks. The methodology presented is guided by the consistent application of the ODD and its related BC concept throughout the entire AI lifecycle, focusing on the trustworthiness assurance framework and its associated process as the main pillars for AIS certification. The achievement of the overall objective of trustworthy and human-centric AIS is divided into seven interconnected sub-goals: the formulation of use restrictions, the trustworthiness assurance/argument itself, the identification of dysfunctional cases, the utilization of scenario databases and datasets, the application of metrics for evaluation, the implementation of the proposed concept across the AI lifecycle, and sufficient consideration of human factors. The role of standards in the assurance process is discussed, considering any existing gaps and areas for improvement. The work concludes with a summary of the developed approach, highlighting key takeaways and action points. Finally, a roadmap to ensure trustworthy and human-centric behavior of future AIS is outlined.&#13;\\n",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Georg Stettinger et al.",
      "keywords": "Computer science; Trustworthiness; Certification; Risk analysis (engineering); Domain (mathematical analysis); Process (computing); Process management; Software deployment; Quality assurance; Argument (complex analysis); Knowledge management; Computer security; Software engineering; Engineering; Business; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3364387",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387885622",
      "doi": "10.1109/access.2023.3327174",
      "title": "The Impact of AI Applications on Smart Decision-Making in Smart Cities as Mediated by the Internet of Things and Smart Governance",
      "abstract": "Plenteous research has been undertaken on the direct effects of artificial intelligence (AI) on smart decision-making. However, little attention has been paid to contextual factors such as the Internet of Things (IoT) and smart governance that mediate the relationship between AI and smart decision-making. This research investigates direct, mediating, and parallel-sequential multiple mediating interactions between AI, the IoT, smart governance, and smart decision-making. We used a self-structured survey to collect cross-sectional data from citizens in the Republic of Korea, and 516 responses were examined using SmartPLS structural equation modeling (PLS-SEM). A parallel-sequential multiple mediator framework is assessed using the Hayes Process Model with bootstrapping. Our results reveal a substantial and favorable multi-mediating effect from the IoT and smart governance on the relationship between AI applications and smart decision-making, as predicted. Previous scholars have investigated a few factors that influence decision-making, but our research contributes to the literature of applied and social sciences, including traditional decision theory, by examining the impact of multi-mediating factors on smart decision-making. This study presents both theoretical and practical implications for scholars and policymakers engaged in the development of smart cities. Additionally, this study provides recommendations for future research.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Syed Asad Abbas Bokhari et al.",
      "keywords": "Corporate governance; Internet of Things; Computer science; Bootstrapping (finance); Knowledge management; Data science; Smart city; The Internet; Process (computing); Decision-making; Structural equation modeling; Management science; Artificial intelligence; Business; Computer security; Machine learning; Engineering; World Wide Web; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3327174",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3135343996",
      "doi": "10.1109/access.2021.3063301",
      "title": "Making Investment Decisions on RFID Technology: An Evaluation of Key Adoption Factors in Construction Firms",
      "abstract": "The importance of RFID technology is increasing as a means of enhancing productivity and efficiency, and reducing costs. The purpose of this research paper is to study the influence of technological, organizational, environmental, and innovation factors on the adoption of RFID technology by construction companies in Australia. With the growth of Australia's economy, in particular, the construction sector, the logistics departments in construction companies should pay attention to the adoption of more efficient technologies to provide better services for their customers. This paper provides a consolidated framework of RFID technology adoption based on studies on RFID technology adoption in particular from an IS perspective. The paper combines an integrated model of the Technology-Organization-Environment framework, the Diffusion of Innovation theory, and Actor-Network Theory to establish a more comprehensive innovation adoption framework for RFID technology. The data gathered to study the factors affecting the adoption of RFID technology are analysed from the results of a survey of construction companies in Australia, in which 297 Information Technology (IT) staff were participants in this research. The research results show that the factors which had a statistically significant and positive impact on the adoption of RFID services in construction companies were: relative advantage, compatibility, cost, expected benefits, top management support, external support and organization size. The findings from this research study have the potential to provide insights to firms seeking to make investment decisions on the adoption of RFID technology.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Tarik Mabad et al.",
      "keywords": "Business; Productivity; Information technology; Investment (military); Marketing; Knowledge management; Industrial organization; Process management; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3063301",
      "cited_by_count": 44,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2979253248",
      "doi": "10.1109/jcn.2019.000048",
      "title": "On the security aspects of Internet of Things: A systematic literature review",
      "abstract": "Internet of Things (IoT) has gained increasing visibility among emerging technologies and undoubtedly changing our daily life. Its adoption is strengthened by the growth of connected devices (things) as shown in recent statistics. However, as the number of connected things grows, responsibility related to security aspects also needs to increase. For instance, cyberattacks might happen if simple authentication mechanisms are not implemented on IoT applications, or if access control mechanisms are weakly defined. Considering the relevance of the subject, we performed a systematic literature review (SLR) to identify and synthesize security issues in IoT discussed in scientific papers published within a period of 8 years. Our literature review focused on four main security aspects, namely authentication, access control, data protection, and trust. We believe that a study considering these topics has the potential to reveal important opportunities and trends related to IoT security. In particular, we aim to identify open issues and technological trends that might guide future studies in this field, thus providing useful material both to researchers and to managers and developers of IoT systems. In this paper, we describe the protocol adopted to perform the SLR and present the state-of-the-art on the field by describing the main techniques reported in the retrieved studies. To the best of our knowledge, ours is the first study to compile information on a comprehensive set of security aspects in IoT. Moreover, we discuss the placement, in terms of architectural tiers, for deploying security techniques, in an attempt to provide guidelines to help design decisions of security solution developers. We summarize our results showing security trends and research gaps that can be explored in future studies.",
      "year": "2019",
      "journal": "Journal of Communications and Networks",
      "authors": "Evandro L. C. Macedo et al.",
      "keywords": "Computer science; Computer security; Field (mathematics); Internet of Things; Relevance (law); Authentication (law); Access control; Security controls; Data science; Control (management); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jcn.2019.000048",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366202000",
      "doi": "10.1109/tts.2023.3267382",
      "title": "Discerning Between the \u201cEasy\u201d and \u201cHard\u201d Problems of AI Governance",
      "abstract": "While there is widespread consensus that artificial intelligence (AI) needs to be governed owing to its rapid diffusion and societal implications, the current scholarly discussion on AI governance is dispersed across numerous disciplines and problem domains. This paper clarifies the situation by discerning two problem areas, metaphorically titled the \"easy\" and \"hard\" problems of AI governance, using a dialectic theory synthesis approach. The \"easy problem\" of AI governance concerns how organizations' design, development, and use of AI systems align with laws, values, and norms stemming from legislation, ethics guidelines, and the surrounding society. Organizations can provisionally solve the \"easy problem\" by implementing appropriate organizational mechanisms to govern data, algorithms, and algorithmic systems. The \"hard problem\" of AI governance concerns AI as a general-purpose technology that transforms organizations and societies. Rather than a matter to be resolved, the \"hard problem\" is a sensemaking process regarding socio-technical change. Partial solutions to the \"hard problem\" may open unforeseen issues. While societies should not lose track of the \"hard problem\" of AI governance, there is significant value in solving the \"easy problem\" for two reasons. First, the \"easy problem\" can be provisionally solved by tackling bias, harm, and transparency issues. Second, solving the \"easy problem\" helps solve the \"hard problem\", as responsible organizational AI practices create virtuous rather than vicious cycles.",
      "year": "2023",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Matti Minkkinen et al.",
      "keywords": "Corporate governance; Dialectic; Transparency (behavior); Harm; Computer science; Value (mathematics); Process (computing); Management science; Sociology; Artificial intelligence; Political science; Epistemology; Law; Economics; Management; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2023.3267382",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4365790425",
      "doi": "10.1109/access.2023.3267047",
      "title": "A Survey on Consensus Algorithms in Blockchain-Based Applications: Architecture, Taxonomy, and Operational Issues",
      "abstract": "Peer reviewed",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Saminur Islam et al.",
      "keywords": "Blockchain; Computer science; Interoperability; Consensus algorithm; Database transaction; Protocol (science); Architecture; Taxonomy (biology); Distributed computing; Data science; Computer security; Database; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3267047",
      "cited_by_count": 52,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4377290245",
      "doi": "10.1109/access.2023.3278261",
      "title": "A Review on the Applications of PSO-Based Algorithm in Demand Side Management: Challenges and Opportunities",
      "abstract": "The increase in energy consumption, environmental pollution issues, and low-carbon agenda has grown the research area of demand side management (DSM). DSM programs provide feasible solutions and significantly enhance the efficiency and sustainability of electrical distribution systems. This paper classifies and discusses the broad definition of DSM based on the comprehensive literature study considering demand response and energy efficiency. The implementation of Artificial Intelligence algorithms in DSM applications has been employed in many studies to help researchers make optimal decisions and achieve predictions by analyzing the massive amount of historical data. Owing to its simplicity and consistent performance in fast convergence time, Particle Swarm Optimization (PSO) is widely used as a part of the swarm AI algorithm and has become a prominent technique in the optimization process to exploit the full benefit of the demand-side program. The variants of PSO have been developed to overcome the limitations of the original PSO and solve the high complexity and uncertainty in the DSM optimization process. The proposed PSO-based algorithm can optimize consumers&#x2019; consumption curves, reducing the peak demand and hence minimizing the electricity cost when integrated with the DR programs or EE measures. The research works of the PSO algorithm in DSM have seen an increasing trend in the past decade. Therefore, this paper reviewed the application of the PSO-based algorithm in DSM fields with some constraints and discussed the challenges from the previous work. The potential for new opportunities is identified so that PSO methods can be developed for future research.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Farah Anishah Zaini et al.",
      "keywords": "Particle swarm optimization; Computer science; Swarm intelligence; Premature convergence; Process (computing); Convergence (economics); Exploit; Energy consumption; Electricity; Energy management; Sustainability; Mathematical optimization; Operations research; Algorithm; Energy (signal processing); Engineering; Economics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3278261",
      "cited_by_count": 68,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3097867666",
      "doi": "10.1109/access.2020.3034766",
      "title": "Software Vulnerability Analysis and Discovery Using Deep Learning Techniques: A Survey",
      "abstract": "Exploitable vulnerabilities in software have attracted tremendous attention in recent years because of their potentially high severity impact on computer security and information safety. Many vulnerability detection methods have been proposed to aid code inspection. Among these methods, there is a line of studies that apply machine learning techniques and achieve promising results. This paper reviews 22 recent studies that adopt deep learning to detect vulnerabilities, aiming to show how they utilize state-of-the-art neural techniques to capture possible vulnerable code patterns. Among reviewed studies, we identify four game changers that significantly impact the domain of deep learning-based vulnerability detection and provide detailed reviews of the insights, ideas, and concepts that the game changers have brought to this field of interest. Based on the four identified game changers, we review the remaining studies, presenting their approaches and solutions which either build on or extend the game changers, and sharing our views on the future research trends. We also highlight the challenges faced in this field and discuss potential research directions. We hope to motivate the readers to conduct further research in this developing but fast-growing field.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Peng Zeng et al.",
      "keywords": "Computer science; Vulnerability (computing); Field (mathematics); Deep learning; Data science; Artificial intelligence; Domain (mathematical analysis); Software; Vulnerability assessment; Machine learning; Computer security; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3034766",
      "cited_by_count": 72,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388709720",
      "doi": "10.1109/access.2023.3333242",
      "title": "Anomaly Detection in Industrial Machinery Using IoT Devices and Machine Learning: A Systematic Mapping",
      "abstract": "Anomaly detection is critical in the smart industry for preventing equipment failure, reducing downtime, and improving safety. Internet of Things (IoT) has enabled the collection of large volumes of data from industrial machinery, providing a rich source of information for Anomaly Detection (AD). However, the volume and complexity of data generated by the Internet of Things ecosystems make it difficult for humans to detect anomalies manually. Machine learning (ML) algorithms can automate anomaly detection in industrial machinery by analyzing generated data. Besides, each technique has specific strengths and weaknesses based on the data nature and its corresponding systems. However, a large portion of the existing systematic mapping studies on AD primarily focus on addressing network and cybersecurity-related problems, with limited attention given to the industrial sector. Additionally, the related literature do not cover the challenges involved in using ML for AD in industrial machinery within the context of the IoT ecosystems. Therefore, this paper presents a systematic mapping study on AD for industrial machinery using IoT devices and ML algorithms to address this gap. Our primary objective is to investigate the use of ML models for anomaly detection within an industrial setting, particularly within IoT ecosystems. The study comprehensively evaluates 84 relevant studies spanning from 2016 to 2023, providing an extensive review of AD research. Our findings identify the most commonly used algorithms, preprocessing techniques, and sensor types. Additionally, this review identifies application areas and points to future challenges and research opportunities.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "S\u00e9rgio F. Chevtchenko et al.",
      "keywords": "Anomaly detection; Computer science; Internet of Things; Anomaly (physics); Artificial intelligence; Machine learning; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3333242",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285213642",
      "doi": "10.1109/tem.2022.3170474",
      "title": "Homo Heuristicus: From Risk Management to Managing Uncertainty in Large-Scale Infrastructure Projects",
      "abstract": "Large-scale infrastructure projects tend to experience variances between estimated and final costs. Governments, in response, have been using statistical methods (including probabilistic approaches) such as reference class forecasting to try and mitigate cost overruns. While helpful in accommodating risk, such statistical methods often fail to account for a project&amp;#x0027;s cost uncertainty. To reduce cost variance under uncertainty, it is necessary to use heuristics when formulating an infrastructure project&amp;#x0027;s cost contingency. This article argues a need to adopt a vision of human nature described as Homo heuristicus (heuristics-using-person). We provide awareness and rationale for developing an &amp;#x201C;adaptive toolbox&amp;#x201D; of heuristics for ecologically rational and contextually aligned cost contingency decision-making. However, the selection, recognition, and evaluation heuristics for determining cost uncertainty have yet to be examined. Thus, future research is required to cultivate the heuristics needed to address the uncertainty that surrounds the determination of a cost contingency.",
      "year": "2022",
      "journal": "IEEE Transactions on Engineering Management",
      "authors": "Peter E.D. Love et al.",
      "keywords": "Heuristics; Toolbox; Cost contingency; Probabilistic logic; Risk analysis (engineering); Contingency; Computer science; Scale (ratio); Risk management; Project management; Variance (accounting); Operations research; Selection (genetic algorithm); Management science; Engineering; Business; Project management triangle; Artificial intelligence; Systems engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tem.2022.3170474",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386412330",
      "doi": "10.1109/access.2023.3311713",
      "title": "Decentralized Machine Learning Governance: Overview, Opportunities, and Challenges",
      "abstract": "Researchers have started to recognize the necessity for a well-defined ML governance framework based on the principle of decentralization and comprehensively defining its scope of research and practice due to the growth of machine learning (ML) research and applications in the real world and the success of blockchain-based technology. In this paper, we study decentralized ML governance, which includes ML value chain management, decentralized identity for the ML community, decentralized ownership and rights management of ML assets, community-based decision-making for the ML process, decentralized ML finance, and risk management.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Dana Alsagheer et al.",
      "keywords": "Decentralization; Corporate governance; Scope (computer science); Blockchain; Process (computing); Computer science; Process management; Risk management; Knowledge management; Business; Computer security; Finance; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3311713",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4366967092",
      "doi": "10.1109/access.2023.3269438",
      "title": "A Big Data-Driven Financial Auditing Method Using Convolution Neural Network",
      "abstract": "In the big data era, traditional auditing methods are facing challenge such as limited audit scope, uneven distribution of audit power, and insufficient audit analysis. To pursue high efficiency, the utilization of big data analysis technique in financial auditing has been a novel tendency in this area. The deep learning has been popular in many areas due to its high freedom degree. Thus, this paper employs a typical deep learning model convolution neural network (CNN), and proposes a big data-driven financial auditing method using CNN. Specifically, the strong ability of feature abstraction of CNN is leveraged to extract multi-level features in materials, such as visual features, textual features, etc. Then, the multi-source features from auditing materials can be well fused for final discrimination. Some simulation experiments are conducted on real-world financial auditing scenes for assessment. And the results show that the designed the proposed financial auditing method possesses relatively high auditing accuracy.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Hao Zhao et al.",
      "keywords": "Audit; Big data; Computer science; Convolutional neural network; Deep learning; Abstraction; Artificial intelligence; Artificial neural network; Information security audit; Accounting; Convolution (computer science); Data mining; Computer security; Business; Information security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3269438",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4313139316",
      "doi": "10.1109/access.2022.3210110",
      "title": "A Gap Between Blockchain and General Data Protection Regulation: A Systematic Review",
      "abstract": "As a service platform, blockchain has faced compliance issues since the General Data Protection Regulation (GDPR) came into effect in May 2018. Although many technical solutions have been proposed to solve the compatibility issues between blockchain and the GDPR, unresolved challenges remain. This study presents the gaps between the blockchain and the GDPR and explores solutions to bridge the gap. We review 91 previously published articles using a systematic literature review methodology. Then, we answer the following research questions: 1) Which solutions have been explored to allow the blockchain to comply with the GDPR? 2) What are the research gaps in the blockchain compliance field? Finally, we present five research gaps in this field: 1) development of a consent ontology model; 2) development of a methodology for monitoring fairness in the blockchain; 3) resolution of the contradiction between auditing and obfuscation; 4) development of a methodology for tracking controllers in the blockchain; and 5) integration of the different-purposed technical solutions without conflicts. Our research can raise the compatibility level of the blockchain and GDPR and guide the company adopting a blockchain to comply with the GDPR. Furthermore, it can advise the regulator to embrace new technologies into the GDPR while protecting a blockchain&#x2019;s nature.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Sejin Han et al.",
      "keywords": "Blockchain; General Data Protection Regulation; Computer science; Computer security; Risk analysis (engineering); Data Protection Act 1998; Business",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3210110",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4381798374",
      "doi": "10.1109/access.2023.3288696",
      "title": "A Survey on Hardware Security: Current Trends and Challenges",
      "abstract": "Hardware security has become a critical concern due to the globalization of the Integrated Circuit (IC) supply chain and the complex network connections of computing-intensive devices. Hardware security is essential in the modern world, as more and more connectivity of the Internet of Things (IoT) has paved the way for improvements in personalized healthcare, communication between home (or office) equipment, and the promise of self-driving cars, airplanes, and smart grid systems. As a result, recently, this field has attracted particular attention from the researcher. A significant amount of research has already been conducted to detect, defend, and create resiliency against hardware attacks. This paper investigates different hardware security approaches in the state-of-the-art literature and outlines their advantages and drawbacks. This paper also provides a comprehensive study of hardware security attacks, and their features, and categorizes different attack types. Finally, it presents the current challenges of the hardware security field and the impact of each one on the IC production supply chain.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sonia Akter et al.",
      "keywords": "Hardware security module; Computer science; Computer security; Internet of Things; Field (mathematics); State (computer science); Embedded system; Cryptography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3288696",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4206771767",
      "doi": "10.1109/access.2021.3138353",
      "title": "Evolution of Internet of Things From Blockchain to IOTA: A Survey",
      "abstract": "Internet of Things (IoT) is the new paradigm to the scaling nature of things and their elements, interconnected, exchanging data over a network supported with nodes. The Ubiquitous use of tiny devices and embedded sensor frameworks has pushed IoT to the forefront of emerging technologies used in many applications like peer-to-peer networks, smart energy grids, home and building automation, vehicle to vehicle communication, and wearable computing devices. This massive growth and extensive use brought forth security risks that could hinder its commencement in many novel applications. The number of interconnected devices leads the way to several entry points for intruders and, along with it, security risks. The sensitive nature of the IoT applications such as health, automation, and energy grids cannot afford security risks. Traditional security mechanisms will not design or develop to secure such an emerging technology as IoT. Existing technologies have to be relied on with the non-existence of security mechanisms for this purpose. Distributed Ledger Technology (DLT) is one such technology that can reduce the security risks in IoT. The central node vulnerability that can compromise the whole system can be mitigated by eliminating the need for a central node by using the distributed ledger. Blockchain, a distributed ledger technology, has attracted tremendous attention and harnessed in itself a real-world value. However, computationally costly with limited scalability is not entirely suited for the IoT environment. IoT Application (IOTA) technology is the distributed ledger technology that can provide unlimited scalability specifically suitable for the IoT industry. This survey provides an in-depth introduction to how blockchain performs and its constraints in its nature as a generic platform for DLT. In contrast, IOTA is introduced as the technology for IoT, the next-generation blockchain overcoming blockchain's limitations for its use in IoT. 2013 IEEE.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mays Alshaikhli et al.",
      "keywords": "Computer science; Scalability; Blockchain; Computer security; Node (physics); Wireless sensor network; Computer network; Engineering; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3138353",
      "cited_by_count": 79,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391341739",
      "doi": "10.1109/access.2024.3360306",
      "title": "Shortcut Learning Explanations for Deep Natural Language Processing: A Survey on Dataset Biases",
      "abstract": "The introduction of pre-trained large language models (LLMs) has transformed NLP by fine-tuning task-specific datasets, enabling notable advancements in news classification, language translation, and sentiment analysis. This has revolutionized the field, driving remarkable breakthroughs and progress. However, the growing recognition of bias in textual data has emerged as a critical focus in the NLP community, revealing the inherent limitations of models trained on specific datasets. LLMs exploit these dataset biases and artifacts as expedient shortcuts for prediction. The reliance of LLMs on dataset bias and artifacts as shortcuts for prediction has hindered their generalizability and adversarial robustness. Addressing this issue is crucial to enhance the reliability and resilience of LLMs in various contexts. This survey provides a comprehensive overview of the rapidly growing body of research on shortcut learning in language models, classifying the research into four main areas: the factors of shortcut learning, the origin of bias, the detection methods of dataset biases, and understanding mitigation strategies to address data biases. The goal of this study is to offer a contextualized, in-depth look at the state of learning models, highlighting the major areas of attention and suggesting possible directions for further research.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Varun Dogra et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Natural (archaeology); Natural language processing; Natural language; Data science; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3360306",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3083289774",
      "doi": "10.1109/access.2020.3021502",
      "title": "Model-Based Software Design and Testing in Blockchain Smart Contracts: A Systematic Literature Review",
      "abstract": "Blockchain technology promises to spark a real revolution. One of most important concepts associated with this technology is smart contracts, which enable the automatic execution of agreements and augur a world without intermediaries. The conditions and rules of &#x201C;contracts&#x201D; are established in a computer codes and trust is enforced by consensus among the participants. One relevant feature associated with smart contract is the immutability property, which establishes the non-alteration of blockchain network data after the clauses of the contract are been approved by all parties or entities involved. For this reason, smart contract development requires more effort and care than the development of other common programs. They require systematic mechanisms to collect requirements and functional specifications. In addition, it is necessary to verify and validate the agreed functionality and the implemented code before they are deployed in the blockchain platform. This article presents a systematic literature review of primary studies in the field of Software Development Life Cycle, focusing on model-based software design and testing in the blockchain domain of smart contracts. This research aims to identify gaps and/or opportunities for further research. After carried out this review, it was observed that no clear methodology exists for evaluating and validating the quality either of this software or the overall development process. This means that software developers may implement smart contract code in which bugs and serious security vulnerabilities appear when the software is delivered to their customers.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "N. S\u00e1nchez-G\u00f3mez et al.",
      "keywords": "Smart contract; Computer science; Blockchain; Software engineering; Computer security; Software development; Design by contract; Software development process; Immutability; Software security assurance; Software; Process (computing); Software construction; Programming language; Information security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3021502",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4312747208",
      "doi": "10.1109/access.2022.3231847",
      "title": "Threat Actors\u2019 Tenacity to Disrupt: Examination of Major Cybersecurity Incidents",
      "abstract": "The exponential growth in the interconnectedness of people and devices, as well as the upward trend in cyberspace usage will continue to lead to a greater reliance on the internet. Most people&#x2019;s daily activities are dependent on their ability to navigate the internet to access and manage information. There are usually real risks associated with managing or accessing information, and these risks when exploited by threat actors, often lead to cybersecurity incidents. It is a common knowledge that a major cybersecurity incident is likely to result in significant financial losses, legal liability, privacy violations, reputational damage, sensitive data compromises, as well as national security implications. Threat actors usually employ various attack techniques to cause these incidents. After we identified the major cybersecurity incident report that is consolidated by the Center for Strategic &#x0026; International Studies (CSIS) from which we derived the data of about the 803 major incidents that we analyzed, we then verified its (CSIS) credibility, non-partisan, global outreach and cybersecurity attack coverage by cross-referencing it with Data Breach Investigation Report (DBIR). We also through the lens of the Global Cybersecurity Index (GCI) ensured that this study is conducted within the context of cybersecurity principles. In reference to these attack techniques employed by threat actors, we conducted an exploratory investigation of 803 major cybersecurity incidents that were reported over the last decade. From a group of 244 of these major security incidents that happened and were reported between 2005 and 2021, this study reports that malware attack techniques were employed by threat actors to cause 48 percent of them and phishing attack techniques account for 19.7 percent of them. As many sources have confirmed the fact that major incidents will always happen, we echo the importance of readiness of organizations to conduct cybersecurity incident triage and or thorough investigation as necessary. Given the relevance of the guidelines outlined in the National Institute of Standards and Technology (NIST) incident response framework, we also recommend that organizations should adopt it or at least embrace similar guidelines as best as possible.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Olufunsho I. Falowo et al.",
      "keywords": "Computer security; Tenacity (mineralogy); Computer science; Internet privacy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3231847",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392902292",
      "doi": "10.1109/access.2024.3378126",
      "title": "Insights Into Privacy Protection Research in AI",
      "abstract": "This paper presents a systematic bibliometric analysis of the artificial intelligence (AI) domain to explore privacy protection research as AI technologies integrate and data privacy concerns rise. Understanding evolutionary patterns and current trends in this research is crucial. Leveraging bibliometric techniques, the authors analyze 8,322 papers from the Web of Science (WoS) database, spanning 1990 to 2023. The analysis highlights IEEE Transactions on Knowledge and Data Engineering and IEEE Access journals as highly influential, the former being an early contributor and the latter emerging as a pivotal source. The study demonstrates substantial disparities in scientific productivity across countries. Specifically, the top 10 countries collectively accounted for 74.8% of the articles, with China and the USA making up nearly half of the total contribution (46.1%). In contrast, regions in Africa and South America exhibited lower scientific production. The evolution of privacy preservation research is reflected, shifting from an algorithm-oriented approach to a focus on data orientation, and subsequently, to privacy solutions centered around Cloud Computing. In recent years, there has been a shift towards embracing Federated Learning and Differential Privacy. The analysis brings to light emerging themes and identifies research gaps, notably a global disparity in research output and a lag in ethical and legal inquiry. It asserts that enhanced interdisciplinary collaboration is imperative to formulate comprehensive privacy solutions for AI. Specifically, the paper imparts invaluable insights that are pivotal for effectively addressing the evolving privacy concerns in the era of AI and big data.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Shasha Yu et al.",
      "keywords": "Privacy protection; Computer science; Information privacy; Internet privacy; Computer security; Privacy software",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3378126",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394994574",
      "doi": "10.1109/access.2024.3391021",
      "title": "Three Challenges to Secure AI Systems in the Context of AI Regulations",
      "abstract": "This article examines the interplay between artificial intelligence (AI) and cybersecurity in light of future regulatory requirements on the security of AI systems, specifically focusing on the robustness of high-risk AI systems against cyberattacks in the context of the European Union&#x2019;s AI Act. The paper identifies and analyses three challenges to achieve compliance of AI systems with the cybersecurity requirement: accounting for the diversity and the complexity of AI technologies, assessing AI-specific risks, and developing secure-by-design AI systems. The contribution of the article consists in providing an overview of AI cybersecurity practices and identifying gaps in current approaches to security conformity assessment for AI systems. Our analysis highlights the unique vulnerabilities present in AI systems and the absence of established cybersecurity practices tailored to these systems, and emphasises the need for continuous alignment between legal requirements and technological capabilities, acknowledging the necessity for further research and development to address the challenges. It concludes that comprehensive cybersecurity practices must evolve to accommodate the unique aspects of AI, with a collaborative effort from various sectors to ensure effective implementation and standardisation.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ronan Hamon et al.",
      "keywords": "Computer science; Context (archaeology); Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3391021",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285265841",
      "doi": "10.1109/access.2022.3182656",
      "title": "Analysis of the Impact of Blockchain and Internet of Things (BIoT) on Public Procurement",
      "abstract": "Most countries in the world are currently faced with a series of public procurement challenges. Moreover, the large volumes of public procurement and the impact it may have of the global economy, the environment and the society at large justify a research study aimed at achieving sustainable and smart procurement. Smart public procurement intensively relies on emerging technologies and it is both an international priority and a challenge to achieve it. This paper is aimed at addressing such procurement-specific challenges. This study reflects the current status and the trends in public procurement, as well as the manner in which Blockchain and the Internet of Things (BIoT) may lead to a beneficial change in the field. In order to analyse the impact of BIoT, we are putting forward an assessment model comprising the definition and the description of six hypotheses. They are validated both by reference to the current knowledge status and via the analysis of the data collected in a survey which was conducted in Romania. It was aimed at collecting and analysing the data from the main stakeholders as well as at formulating recommendations/actions related to the modernisation of the current system. The study uses structural equation modelling (SEM) to validate the proposed model and to establish the relationships between the adoption of BIoT and smart, sustainable and transparent public procurement. At the same time, we analyse the links between the adoption of BIoT and aspects such as corruption and fraud, the challenges related to technological integration and the need to reengineer organisations, as well as national and international policies. Following our analyses, there emerged that BIoT adoption has a positive impact on the achievement of sustainable public procurement processes (the highest effect), on transparency and the trust in public procurement, on reducing corruption and fraud in public procurement and on the achievement of smart public procurement. The paper provides theoretical and practical contributions that should support solutions to the current major challenges and represent a vehicle for innovation and sustainable development alike.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Marinela Mircea et al.",
      "keywords": "Procurement; Business; Blockchain; Biot number; Computer science; Knowledge management; Process management; Environmental economics; Marketing; Computer security; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3182656",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390421883",
      "doi": "10.1109/access.2023.3348409",
      "title": "Security of 6G-Enabled Vehicle-to-Everything Communication in Emerging Federated Learning and Blockchain Technologies",
      "abstract": "Sixth-generation (6G) communication is emerging as a seamless and massive connection of almost all digital devices. Vehicles, which are extensively linked with human mobility, must keep up with a certain technological pace to maintain compatibility with the 6G era. 6G is also expected to potentially revolutionize Vehicle-to-Everything (V2X) communication. However, this modernization will surface several security challenges in the complex heterogeneous architecture of V2X communication in 6G. Similarly, the expansion of V2X is expected to introduce its own unconventional security risks and vulnerabilities. Therefore, the current paper aims to provide an overview of the security challenges associated with and solutions for V2X communication in the upcoming 6G era to visualize the future of this research domain. This paper discusses the architecture and standards utilized in 6G-enabled V2X communications and provisions a comprehensive analysis of V2X security in the Confidentiality, Integrity, Availability, Authentication, and Access Control (CIA3) domains. Through this process, we analyze the impact of the emerging technological concepts of Blockchain and Federated Learning (FL) in 6G-enabled V2X communication. Therefore, we propose a Blockchain-enabled FL-based generic security architecture for V2X communication in 6G networks. Ultimately, this review highlights the key lessons that have been learned and the future research directions in the domain of security of V2X communications in the 6G including Privacy in 3D Fog Computing, Privacy in Augmented Reality, Secure Software Defined Networking (SDN), Physical Layer Security in the THz Spectrum, SUMO (Simulation of Urban MObility), and Intrusion Detection using AI.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Myoungsu Kim et al.",
      "keywords": "Blockchain; Computer science; Computer security; Internet privacy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3348409",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392745485",
      "doi": "10.1109/access.2024.3376682",
      "title": "Evolving Malware and DDoS Attacks: Decadal Longitudinal Study",
      "abstract": "This study conducts analysis of cybersecurity events from 2013 to 2023, concentrating on major incidents associated with Distributed Denial of Service (DDoS), and malware attacks. Deriving data from the Center for Strategic &#x0026; International Studies (CSIS) report, it examines 925 major incidents to discern evolving cyber threat trends. A key finding is the escalation in the frequency and sophistication of attacks, with a marked increase in DDoS incidents in 2022 and a steady rise in malware attacks, peaking in 2023. This trend indicates growing threat actors&#x2019; capabilities and vulnerabilities in digital infrastructures. Additionally, the aggregate of other attack methods, such as phishing and zero-day exploits, surpasses the incidence of DDoS and malware attacks, illustrating the broad spectrum of cyber threats. Employing the ARIMA model, the study projects future DDoS and malware attack trends, factoring in historical data and assumptions of minimal technological advancement and unchanged geopolitical tensions. The forecast suggests a consistent pattern of cyber attacks over the next five years. This study also correlates the nature of cyber attacks with financial motives and geopolitical dynamics, applying reliability and validity testing to affirm the robustness of these findings. Despite ARIMA providing reliable historical-based forecasts, the dynamic nature of cyber threats necessitates cautious interpretation of future trends. In conclusion, the study emphasizes the necessity for dynamic, multifaceted cybersecurity strategies. Nations and organizations must adopt adaptive approaches, bolstered by data analysis and forecasts - crucial in combating the diverse cyber threats, highlighting the need for a proactive and collaborative global cybersecurity framework.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Olufunsho I. Falowo et al.",
      "keywords": "Malware; Denial-of-service attack; Computer science; Computer security; Application layer DDoS attack; Operating system; The Internet",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3376682",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4313855633",
      "doi": "10.1109/access.2023.3235016",
      "title": "Quantifying the Vulnerability of Attributes for Effective Privacy Preservation Using Machine Learning",
      "abstract": "Personal data have been increasingly used in data-driven applications to improve quality of life. However, privacy preservation of personal data while sharing it with analysts/ researchers has become an essential requirement to be met by data owners (hospitals, banks, insurance companies, etc.). The existing literature on privacy preservation does not precisely quantify the vulnerability of each item among user attributes, thereby leading to explicit privacy disclosures and poor data utility during published data analytics. In this work, we propose and implement an automated way of quantifying the vulnerability of each item among the attributes by using a machine learning (ML) technique to significantly preserve the privacy of users without degrading data utility. Our work can solve four technical problems in the privacy preservation field: optimization of the privacy-utility trade-off, privacy guarantees (i.e., safeguard against identity and sensitive information disclosures) in imbalanced data (or clusters), over-anonymization issues, and rectifying or enabling the applicability of prior privacy models when data have skewed distributions. The experiments were performed on two real-world benchmark datasets to prove the feasibility of the concept in practical scenarios. Compared with state-of-the-art (SOTA) methods, the proposed method effectively preserves the equilibrium between utility and privacy in the anonymized data. Furthermore, our method can significantly contribute towards responsible data science (extracting enclosed knowledge from data without violating subjects&#x2019; privacy) by controlling higher changes in data during its anonymization.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Abdul Majeed et al.",
      "keywords": "Computer science; Vulnerability (computing); Information privacy; Computer security; Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3235016",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3040172535",
      "doi": "10.1109/access.2020.3005643",
      "title": "Towards a Secure Internet of Things: A Comprehensive Study of Second Line Defense Mechanisms",
      "abstract": "The Internet of Things (IoT) exemplifies a large network of sensing and actuating devices that have penetrated into the physical world enabling new applications like smart homes, intelligent transportation, smart healthcare and smart cities. Through IoT, these applications have consolidated in the modern world to generate, share, aggregate and analyze large amount of security-critical and privacy sensitive data. As this consolidation gets stronger, the need for security in IoT increases. With first line of defense strategies like cryptography being unsuited due to the resource constrained nature, second line of defense mechanisms are crucial to ensure security in IoT networks. This paper presents a comprehensive study of existing second line of defense mechanisms for standardized protocols in IoT networks. The paper analyzes existing mechanisms in three aspects: Intrusion Detection Systems (IDS), Intrusion Prevention Systems (IPS) and Intrusion Response Systems (IRS). We begin by providing an overview of standardized protocol stack, its layers and defensive security systems in IoT. From there, we build our narrative by presenting an extended taxonomy of IDS, IPS and IRS classifying them on their techniques, deployment, attacks, datasets, evaluation metrics and data pre-processing methods. We then thoroughly review, compare and analyze the research proposals in this context, considering the unique characteristics involved in these systems. Based on the extensive analysis of the existing defensive security systems, the paper also identifies open research challenges and directions for effective design of such systems for IoT networks, which could guide future research in the area.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Kamaldeep et al.",
      "keywords": "Computer science; Computer security; Intrusion detection system; Software deployment; Internet of Things; Protocol stack; Context (archaeology); Wireless sensor network; Computer network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3005643",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387197123",
      "doi": "10.1109/mis.2023.3320437",
      "title": "Developing Responsible Chatbots for Financial Services: A Pattern-Oriented Responsible Artificial Intelligence Engineering Approach",
      "abstract": "The recent release of ChatGPT has gained huge attention and discussion worldwide, with responsible AI being a crucial topic of discussion. One key question is how we can ensure that AI systems, like ChatGPT, are developed and adopted in a responsible way? To tackle the responsible AI challenges, various ethical principles have been released by governments, organisations, and companies. However, those principles are very abstract and not practical enough. Further, significant efforts have been put on algorithm-level solutions that only address a narrow set of principles, such as fairness and privacy. To fill the gap, we adopt a pattern-oriented responsible AI engineering approach and build a Responsible AI Pattern Catalogue to operationalise responsible AI from a system perspective. In this article, we first summarise the major challenges in operationalising responsible AI at scale and introduce how we use the Responsible AI Pattern Catalogue to address those challenges. We then examine the risks at each stage of the chatbot development process and recommend pattern-driven mitigations to evaluate the the usefulness of the Responsible AI Pattern Catalogue in a real-world setting.",
      "year": "2023",
      "journal": "IEEE Intelligent Systems",
      "authors": "Qinghua Lu et al.",
      "keywords": "Computer science; Chatbot; Process (computing); Set (abstract data type); Scale (ratio); Key (lock); Perspective (graphical); Applications of artificial intelligence; Artificial intelligence; Data science; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mis.2023.3320437",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392909071",
      "doi": "10.1109/access.2024.3377124",
      "title": "A Novel Web Framework for Cervical Cancer Detection System: A Machine Learning Breakthrough",
      "abstract": "Cervical cancer, the second most prevalent cancer among women worldwide, is primarily attributed to the human papillomavirus (HPV). Despite advances in healthcare, it remains a significant cause of mortality among women across diverse regions, surpassing other hereditary cancers. Early detection is pivotal, as survival rates exceed 90&#x0025; when the disease is identified in its early stages. In response to this critical need, we introduce WFC2DS (Web Framework for Cervical Cancer Detection System), a novel expert web system specifically designed to revolutionize cervical cancer diagnosis. WFC2DS integrates a sophisticated ensemble of machine learning classification algorithms, including Artificial Neural Network (ANN), AdaBoost, K-Nearest Neighbor (KNN), Random Forest Classifier (RFC), Support Vector Machine (SVM), and Decision Tree (DT). This ensemble approach enables a comprehensive analysis of a large dataset comprising information from 858 patients with 36 attributes, with the primary objective being the early detection of cervical cancer, using the last attribute, Biopsy, as the target variable. Our evaluation criteria encompass accuracy, specificity, sensitivity, and the F1 score. Among the algorithms, RFC and DT emerge as the most promising, demonstrating exceptional performance with an accuracy of 98.1&#x0025; and an F1 score of 0.98. AdaBoost shows an accuracy of 97.4&#x0025; and an F1 score of 0.98, ANN attains an accuracy of 97.7&#x0025; and an F1 score of 0.96, SVM achieves an accuracy of 96.2&#x0025; and an F1 score of 0.96, and KNN reaches an accuracy of 90.6&#x0025; with an F1 score of 0.91. This research significantly contributes to reducing the global burden of cervical cancer, emphasizing transformative advancements in women&#x2019;s healthcare. WFC2DS, with its cutting-edge machine learning techniques, not only improves the accuracy of cervical cancer diagnosis but also enhances the overall healthcare landscape for women worldwide.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mimonah Al Qathrady et al.",
      "keywords": "Computer science; Cervical cancer; Artificial intelligence; Machine learning; Cancer; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3377124",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4296910038",
      "doi": "10.1109/access.2022.3208715",
      "title": "Machine Learning Model Generation With Copula-Based Synthetic Dataset for Local Differentially Private Numerical Data",
      "abstract": "With the development of IoT technology, personal data are being collected in many places. These data can be used to create new services, but consideration must be given to the individual&amp;#x2019;s privacy. We can safely collect personal data while adding noise by applying differential privacy. However, because such data are very noisy, the accuracy of machine learning trained by the data greatly decreased. In this study, our objective is to build a highly accurate machine learning model using these data. We focus on the decision tree machine learning algorithm, and, instead of applying it as is, we use a preprocessing technique wherein pseudodata are generated using a copula while removing the effect of noise added by differential privacy. In detail, the proposed novel protocol consists of three steps: generating a covariance matrix from the differentially private numerical data, generating a discrete cumulative distribution function from differentially private numerical data, and generating copula-based numerical samples. Simulation results using synthetic and real datasets verify the utility of the proposed method not only for the decision tree algorithm but also for other machine learning algorithms such as deep neural networks. This method will help create machine learning models, such as recommendation systems, using differential privacy data.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Yuichi Sei et al.",
      "keywords": "Copula (linguistics); Computer science; Data modeling; Machine learning; Artificial intelligence; Synthetic data; Data mining; Econometrics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3208715",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2579766263",
      "doi": "10.1109/access.2020.2981418",
      "title": "Emotional Testing on Facebook\u2019s User Experience",
      "abstract": "This study aims at understanding how a user's emotions fluctuate when undertaking certain tasks on a social media platform such as Facebook or other software products which may have emotional effects on its user. Specifically, we explored the difference in the usability aspect of Facebook concerning frequent and new Facebook users. The study involves a qualitative study on eighteen participants, nine of whom were Facebook users and nine non-Facebook users who had never used Facebook before participating in this study. During the testing procedure, users were asked to complete several tasks on Facebook, while the electrophysiological activity of their brain was recorded using an EEG (electroencephalogram) acquisition system. Certainly, this study can be applied to any software product, before its release, to improve its user interface by acquiring insight into how user-friendly it is for new users when compared to frequent users. Additionally, a correlation in user friendliness between new users and frequent users is investigated. Furthermore, the study will help us discern which parts of the brain had the most significant difference between groups and discuss the motives behind an individual's emotional state, concerning user experience. Based on the analysis of the power spectrum of the characteristic brain waves, this research establishes that there is a substantial statistical difference between new and frequent Facebook users. Also, it resulted that there is a significant difference between the central, temporal and occipital lobes of new and frequent users. These results will assist developers in creating optimal and user-friendly software products.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Roberto Stefano Mangion et al.",
      "keywords": "Usability; Computer science; Social media; Software; Significant difference; User interface; Human\u2013computer interaction; User experience design; Product (mathematics); World Wide Web; Internet privacy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2981418",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387010520",
      "doi": "10.1109/access.2023.3319083",
      "title": "Qualitative Survey on Artificial Intelligence Integrated Blockchain Approach for 6G and Beyond",
      "abstract": "Utilizing the 0.1 to 10 THz spectrum in the next-generation wireless communication networks holds potential for futuristic applications. However, managing resources to accommodate numerous devices raises privacy and security concerns. Further, technology proliferation entwines devices, infrastructure complexity, and resources. Indeed, the transition from 5G (fifth-generation) to 6G (sixth-generation) signifies a progression towards high-speed data rates, minimal latency, and seamless integration of artificial intelligence, enabling ground-breaking applications and services. However, it complicates network management, privacy, resource allocation, and data processing. Notably, integrating Blockchain Technology (BCT) and Machine Learning (ML) is a promising solution, enhancing security, decentralization, trust in ML decisions, and efficient data sharing. This survey thoroughly reviews the integrated ML and BCT, showcasing their collaborative enhancement of network security, decentralization, trust in ML decisions, immutability, and efficient model sharing. Furthermore, we also delve into various distinctive topics, such as BCT-enabled spectrum refarming, rate splitting multiple access, 6G radar-based communication, reconfigurable intelligent surfaces, visible light communication, and integrated sensing and communication. Moreover, it also explores the integration of ML and BCT in novel 6G communication technologies, including molecular, holographic, and semantic communication. Finally, critical open issues, challenges, solutions, and futuristic scope are identified for forthcoming researchers.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Vivek Pathak et al.",
      "keywords": "Computer science; Data sharing; Decentralization; Wireless; Blockchain; Telecommunications; Data science; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3319083",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391129796",
      "doi": "10.1109/access.2024.3357786",
      "title": "Exploring the Connectivity Between Education 4.0 and Classroom 4.0: Technologies, Student Perspectives, and Engagement in the Digital Era",
      "abstract": "The democratic welfare government is equally committed to quality-driven, impartial, and egalitarian education. The major contribution of this study is to examine the problems and opportunities posed by the incorporation of digital technology in the classroom via the lens of Classroom 4.0 (CLSR4) and education 4.0. The commitment of the democratic welfare government to equitable and quality education is investigated, in line with the Global Agenda SDG 4 goal of ensuring comprehensive and lifelong education for everyone. The modern classroom is witnessing a clash between traditional teaching methods and the digital competency of today&#x2019;s tech-savvy generation. The goal of this study is to examine the connections between education 4.0 and classroom 4.0 by looking at developments in classroom architecture and the use of digital platforms. The biggest issue found is instructors&#x2019; inability to adjust to changing conditions. In terms of methodology, confirmatory factor analysis is used in this work to investigate the dynamics of correlations in the context of Classroom 4.0. This method offers insights into the variables influenced by metaverse technology, resulting in a thorough comprehension of the evolving educational scene. This study&#x2019;s findings shed insight into how students see the changing classroom and the role that various platforms play in engaging them. The study underscores the need for educators to effectively integrate these tools and address this digital transformation to improve teaching and learning experiences. However, there are study constraints, most notably the limited contextual scope, which is exclusively focused on the Indian educational setting. Further research in other worldwide contexts is required to generalize the findings. In the future, it is critical to investigate and build creative instructional practices that effectively synergize with Classroom 4.0. Furthermore, further research should be conducted to determine how governments and educational institutions might adapt to this paradigm shift, ensuring a smooth and effective transition into the digital era of education.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Kapil Joshi et al.",
      "keywords": "Government (linguistics); Context (archaeology); Scope (computer science); Digital native; Computer science; Digital transformation; Public relations; Quality (philosophy); Sociology; Mathematics education; Pedagogy; Political science; Psychology; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3357786",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4384080173",
      "doi": "10.1109/access.2023.3294840",
      "title": "Requirements Engineering in Machine Learning Projects",
      "abstract": "Over the last decade, machine learning methods have revolutionized a large number of domains and provided solutions to many problems that people could hardly solve in the past. The availability of large amounts of data, powerful processing architectures, and easy-to-use software frameworks have made machine learning a popular, readily available, and affordable option in many different domains and contexts. However, the development and maintenance of production-level machine learning systems have proven to be quite challenging, as these activities require an engineering approach and solid best practices. Software engineering offers a mature development process and best practices for conventional software systems, but some of them are not directly applicable to the new programming paradigm imposed by machine learning. The same applies to the requirements engineering best practices. Therefore, this article provides an overview of the requirements engineering challenges in the development of machine learning systems that have been reported in the research literature, along with their proposed solutions. Furthermore, it presents our approach to overcoming those challenges in the form of a case study. Through this mixed-method study, the article tries to identify the necessary adjustments to (1) the best practices for conventional requirements engineering and (2) the conventional understanding of certain types of requirements to better fit the specifics of machine learning. Moreover, the article tries to emphasize the relevance of properly conducted requirements engineering activities in addressing the complexity of machine learning systems, as well as to motivate further discussion on the requirements engineering best practices in developing such systems.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ana Gjorgjevikj et al.",
      "keywords": "Computer science; Requirements engineering; Best practice; Relevance (law); Software engineering; Process (computing); Artificial intelligence; Software development; Software development process; Machine learning; Software; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3294840",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4311080970",
      "doi": "10.1109/tifs.2022.3216468",
      "title": "Exploring Bias in Sclera Segmentation Models: A Group Evaluation Approach",
      "abstract": "Bias and fairness of biometric algorithms have been key topics of research in recent years, mainly due to the societal, legal and ethical implications of potentially unfair decisions made by automated decision-making models. A considerable amount of work has been done on this topic across different biometric modalities, aiming at better understanding the main sources of algorithmic bias or devising mitigation measures. In this work, we contribute to these efforts and present the first study investigating bias and fairness of sclera segmentation models. Although sclera segmentation techniques represent a key component of sclera-based biometric systems with a considerable impact on the overall recognition performance, the presence of different types of biases in sclera segmentation methods is still underexplored. To address this limitation, we describe the results of a group evaluation effort (involving seven research groups), organized to explore the performance of recent sclera segmentation models within a common experimental framework and study performance differences (and bias), originating from various demographic as well as environmental factors. Using five diverse datasets, we analyze seven independently developed sclera segmentation models in different experimental configurations. The results of our experiments suggest that there are significant differences in the overall segmentation performance across the seven models and that among the considered factors, ethnicity appears to be the biggest cause of bias. Additionally, we observe that training with representative and balanced data does not necessarily lead to less biased results. Finally, we find that in general there appears to be a negative correlation between the amount of bias observed (due to eye color, ethnicity and acquisition device) and the overall segmentation performance, suggesting that advances in the field of semantic segmentation may also help with mitigating bias.",
      "year": "2022",
      "journal": "IEEE Transactions on Information Forensics and Security",
      "authors": "Matej Vitek et al.",
      "keywords": "Sclera; Biometrics; Segmentation; Computer science; Artificial intelligence; Machine learning; Image segmentation; Modalities; Data science; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tifs.2022.3216468",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387029079",
      "doi": "10.1109/access.2023.3319089",
      "title": "A Comprehensive Analysis of Blockchain Applications for Securing Computer Vision Systems",
      "abstract": "Blockchain (BC) and Computer Vision (CV) are the two emerging fields with the potential to transform various sectors. BC can offer decentralized and secure data storage, while CV allows machines to learn and understand visual data. The integration of the two technologies holds massive promise for developing innovative applications that can provide solutions to the challenges in various sectors such as supply chain management, healthcare, smart cities, and defense. This review explores a comprehensive analysis of the integration of BC and CV by examining their combination and potential applications. It also provides a detailed analysis of the fundamental concepts of both technologies, highlighting their strengths and limitations. This paper also explores current research efforts that make use of the benefits offered by this combination. The BC can be used as an added layer of security in CV systems and also ensure data integrity, enabling decentralized image and video analytics. The challenges and open issues associated with this integration are also identified, and appropriate potential future directions are also proposed.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "M. Ramalingam et al.",
      "keywords": "Computer science; Blockchain; Data science; Supply chain; Emerging technologies; Risk analysis (engineering); Computer security; Artificial intelligence; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3319089",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3166007351",
      "doi": "10.1109/jbhi.2021.3089287",
      "title": "A Knowledge Distillation Ensemble Framework for Predicting Short- and Long-Term Hospitalization Outcomes From Electronic Health Records Data",
      "abstract": "The ability to perform accurate prognosis is crucial for proactive clinical decision making, informed resource management and personalised care. Existing outcome prediction models suffer from a low recall of infrequent positive outcomes. We present a highly-scalable and robust machine learning framework to automatically predict adversity represented by mortality and ICU admission and readmission from time-series of vital signs and laboratory results obtained within the first 24 hours of hospital admission. The stacked ensemble platform comprises two components: a) an unsupervised LSTM Autoencoder that learns an optimal representation of the time-series, using it to differentiate the less frequent patterns which conclude with an adverse event from the majority patterns that do not, and b) a gradient boosting model, which relies on the constructed representation to refine prediction by incorporating static features. The model is used to assess a patient's risk of adversity and provides visual justifications of its prediction. Results of three case studies show that the model outperforms existing platforms in ICU and general ward settings, achieving average Precision-Recall Areas Under the Curve (PR-AUCs) of 0.891 (95% CI: 0.878-0.939) for mortality and 0.908 (95% CI: 0.870-0.935) in predicting ICU admission and readmission.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Zina M. Ibrahim et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3089287",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385569562",
      "doi": "10.1109/access.2023.3302262",
      "title": "Comprehensive Review on Development of Smart Cities Using Industry 4.0 Technologies",
      "abstract": "Smart Cities (SCs) have recently opened new lifestyles as they introduce effective approaches for improving urban management. These cities integrate Industry 4.0 technologies and new organizations into a social and technical system. A Smart City (SC) finally aims to integrate urban business, transportation, water, energy, and other subsystems by analyzing the data collected from sensors and Information and Communication Technology (ICT). In this regard, the current article proposes a hybrid structure based on Cloud Computing (CC), cloud processing, and internet technology to develop and manage SCs and urban planning. Moreover, the development and analysis of sensors to construct an SC, as well as supporting technologies, are addressed. Therefore, the present research is focused on defining and reviewing large data and objects of the Internet and CC to identify the current challenges and limitations. This research, thus, introduced a novel approach in the context of the Internet of objects, whose data are gathered from different geographic locations through devices and sensors to be used in a new system. CC services in a city can analyze and make smart decisions to optimally manage SCs and improve the welfare of citizens. This study consequently sets the path for further investigation into the problems and difficulties associated with Big Data (BD) applications in SCs.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Marieh Talebkhah et al.",
      "keywords": "Smart city; Cloud computing; Computer science; Big data; The Internet; Information and Communications Technology; Context (archaeology); Data science; Urban planning; Construct (python library); Internet of Things; World Wide Web; Engineering; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3302262",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392667179",
      "doi": "10.1109/access.2024.3375763",
      "title": "Designing an ML Auditing Criteria Catalog as Starting Point for the Development of a Framework",
      "abstract": "Although AI algorithms and applications become more and popular in the healthcare sector, only few institutions have an operational AI strategy. Identifying the best suited processes for ML algorithm implementation and adoption is a big challenge. Also, raising human confidence in AI systems is elementary to building trustworthy, socially beneficial and responsible AI. A commonly agreed AI auditing framework that provides best practices and tools could help speeding up the adoption process. In this paper, we first highlight important concepts in the field of AI auditing and then restructure and subsume them into an ML auditing core criteria catalog. We conducted a scoping study where we analyzed sources being associated with the term &#x201C;Auditable AI&#x201D; in a qualitative way. We utilized best practices from Mayring (2000), Miles and Huberman (1994), and Bortz and D&#x00F6;ring (2006). Based on referrals, additional relevant white papers and sources in the field of AI auditing were also included. The literature base was compared using inductively constructed categories. Afterwards, the findings were reflected on and synthesized into a resulting ML auditing core criteria catalog. The catalog is grouped into the categories: Conceptual Basics, Data &#x0026; Algorithm Design and Assessment Metrics. As a practical guide, it consists of 30 questions developed to cover the mentioned categories and to guide ML implementation teams. Our consensus-based ML auditing criteria catalog is intended as a starting point for the development of evaluation strategies by specific stakeholders. We believe it will be beneficial to healthcare organizations that have been or will start implementing ML algorithms. Not only to help them being prepared for any upcoming legally required audit activities, but also to create better, well-perceived and accepted products. Potential limitations could be overcome by utilizing the proposed catalog in practice on real use cases to expose gaps and to further improve the catalog. Thus, this paper is seen as a starting point towards the development of a framework, where essential technical components can be specified.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Markus Schwarz et al.",
      "keywords": "Computer science; Audit; Point (geometry); Accounting; Mathematics; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3375763",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388740296",
      "doi": "10.1109/access.2023.3333920",
      "title": "Taxonomy of Quality Assessment for Intelligent Software Systems: A Systematic Literature Review",
      "abstract": "The increasing integration of AI software into various aspects of our daily lives has amplified the importance of evaluating the quality of these intelligent systems. The rapid proliferation of AI-based software projects and the growing reliance on these systems underscore the urgency of examining their quality for practical applications in both industry and academia. This systematic literature review delves into the study of quality assessment metrics and methods for AI-based systems, pinpointing key attributes and properties of intelligent software projects that are crucial for determining their quality. Furthermore, a comprehensive analysis of this domain will enable researchers to devise novel methods and metrics for effectively and efficiently evaluating the quality of such systems. Despite its importance, this area of development is still relatively nascent and evolving. This paper presents a systematic review of the current state of the taxonomy of quality assessment for AI-based software. We analyzed 271 articles from six different sources that focused on the quality assessment of intelligent software systems. The primary objective of this work is to provide an overview of the field and consolidate knowledge, which will aid researchers in identifying additional areas for future research. Moreover, our findings reveal the necessity to establish remedial strategies and develop tools to automate the process of identifying appropriate actions in response to abnormal metric values. \u00a9 2013 IEEE.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ahror Jabborov et al.",
      "keywords": "Computer science; Software quality; Systematic review; Quality (philosophy); Software quality control; Software engineering; Software; Taxonomy (biology); Field (mathematics); Data science; Software development; Risk analysis (engineering)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3333920",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393170820",
      "doi": "10.1109/access.2024.3381528",
      "title": "Elliptic Crypt With Secured Blockchain Assisted Federated Q-Learning Framework for Smart Healthcare",
      "abstract": "In this paper, a novel Elliptic Crypt with Secured Blockchain-backed Federated Q-Learning Framework is proposed to offer an intelligent healthcare system that mitigates the attacks and data misused by malicious intruders. Initially, the entered IoMT data is collected from publicly available datasets and encrypted using the Extended Elliptic Curve Cryptography (E&#x005F;ECurCrypt) technique for ensuring the security. This encrypted data is fed as an input to the blockchain-powered collaborative learning model. Here, the federated Q-learning model trains the inputs and analyzes the presented attacks to ensure better privacy protection. Afterwards, the data is securely stored in decentralized blockchain technology. Subsequently, an effective Delegated Proof of Stake (Del&#x005F;PoS) consensus algorithm is used to validate the proposed framework. The experiment is conducted using the WUSTL-EHMS-2020 dataset and the performances are analyzed by evaluating multiple matrices and compared to other existing methods. The performance of the proposed framework can be assessed using multiple matrices and the results will be compared to other existing methods. As a result, the proposed method has achieved 99.23&#x0025; accuracy, 98.42&#x0025; precision, 98.12&#x0025; recall, 98.27&#x0025; F1 score, 59080.506 average throughput, 59080.506 average decryption time 1.94 seconds and an average encryption time of 1.84 seconds and are superior to conventional methods.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Sudhakaran Gajendran et al.",
      "keywords": "Blockchain; Computer science; Health care; Crypt; Computer security; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3381528",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4322706979",
      "doi": "10.1109/access.2023.3247486",
      "title": "Framework for the Assessment of Data Masking Performance Penalties in SQL Database Servers. Case Study: Oracle",
      "abstract": "Dynamic data masking (DDM) is a powerful data-security technique for protecting personal and other sensitive information in databases from unauthorized access. A DDM can be used to mask or obfuscate information in real time, as it is accessed by unauthorized users. This prevents sensitive information from being exposed, while still allowing authorized users to access the data. In current multilayered applications, data masking may be incorporated as special modules placed anywhere between the storage and user interface. In this paper, we consider the solution of implementing masking directly in the persistence layer so that data do not travel unmasked along the network. The data at rest are unchanged (i.e., unmasked), but when users query the database, the sensitive columns in the results are displayed in a masked format, which makes it impossible to identify the original data. Given the diversity of masking features proposed by commercial and open-source database servers, this study proposes a framework for assessing the performance penalty of SQL queries when using database masking relative to the original (unmasking) scenario. We implemented and applied the framework to a basic masking scenario in the Oracle database server using the TPC-H benchmark database. Exploratory analysis and Machine Learning models suggest that DDM has a weak impact on query performance. This could be a powerful incentive for incorporating DDM in real-world software applications when up to 100GB data is stored using Oracle database server.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Marin Fotache et al.",
      "keywords": "Computer science; Server; Database; Oracle; SQL; In-Memory Processing; Masking (illustration); Distributed database; Oracle database; Database server; Query by Example; Information retrieval; World Wide Web; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3247486",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312590693",
      "doi": "10.1109/access.2022.3225074",
      "title": "Cybersecurity for Industrial Internet of Things: Architecture, Models and Lessons Learned",
      "abstract": "Modern industrial systems now, more than ever, require secure and efficient ways of communication. The trend of making connected, smart architectures is beginning to show in various fields of the industry such as manufacturing and logistics. The number of IoT (Internet of Things) devices used in such systems is naturally increasing and industry leaders want to define business processes which are reliable, reproducible, and can be effortlessly monitored. With the rise in number of connected industrial systems, the number of used IoT devices also grows and with that some challenges arise. Cybersecurity in these types of systems is crucial for their wide adoption. Without safety in communication and threat detection and prevention techniques, it can be very difficult to use smart, connected systems in the industry setting. In this paper we describe two real-world examples of such systems while focusing on our architectural choices and lessons learned. We demonstrate our vision for implementing a connected industrial system with secure data flow and threat detection and mitigation strategies on real-world data and IoT devices. While our system is not an off-the-shelf product, our architecture design and results show advantages of using technologies such as Deep Learning for threat detection and Blockchain enhanced communication in industrial IoT systems and how these technologies can be implemented. We demonstrate empirical results of various components of our system and also the performance of our system as-a-whole.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "George Bravos et al.",
      "keywords": "Computer science; Computer security; Architecture; Industrial Internet; Internet of Things; Industry 4.0; The Internet; Product (mathematics); Embedded system; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3225074",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3199338376",
      "doi": "10.1109/tse.2021.3112503",
      "title": "How Templated Requirements Specifications Inhibit Creativity in Software Engineering",
      "abstract": "Desiderata is a general term for stakeholder needs, desires or preferences. Recent experiments demonstrate that presenting desiderata as templated requirements specifications leads to less creative solutions. However, these experiments do not establish how the presentation of desiderata affects design creativity. This study, therefore, aims to explore the cognitive mechanisms by which presenting desiderata as templated requirements specifications reduces creativity during software design. Forty-two software designers, organized into 21 pairs, participated in a dialog-based protocol study. Their interactions were transcribed and the transcripts were analyzed in two ways: (1) using inductive process coding and (2) using an a-priori coding scheme focusing on fixation and critical thinking. Process coding shows that participants exhibited seven categories of behavior: making design moves, uncritically accepting, rejecting, grouping, questioning, assuming and considering quality criteria. Closed coding shows that participants tend to accept given requirements and priority levels while rejecting newer, more innovative design ideas. Overall, the results suggest that designers fixate on desiderata presented as templated requirements specifications, hindering critical thinking. More precisely, requirements fixation mediates the negative relationship between specification formality and creativity.",
      "year": "2021",
      "journal": "IEEE Transactions on Software Engineering",
      "authors": "Rahul Mohanani et al.",
      "keywords": "Computer science; Formality; Creativity; Coding (social sciences); Software engineering; Requirements engineering; Software; Engineering design process; Software requirements specification; Stakeholder; TRIZ; Software requirements; Software design; Human\u2013computer interaction; Software development; Programming language; Artificial intelligence; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tse.2021.3112503",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4296338019",
      "doi": "10.1109/access.2022.3207812",
      "title": "Toward Accountable and Explainable Artificial Intelligence Part One: Theory and Examples",
      "abstract": "Like other Artificial Intelligence (AI) systems, Machine Learning (ML) applications cannot explain decisions, are marred with training-caused biases, and suffer from algorithmic limitations. Their eXplainable Artificial Intelligence (XAI) capabilities are typically measured in a two-dimensional space of explainability and accuracy ignoring the accountability aspects. During system evaluations, measures of comprehensibility, predictive accuracy and accountability remain inseparable. We propose an Accountable eXplainable Artificial Intelligence (AXAI) capability framework for facilitating separation and measurement of predictive accuracy, comprehensibility and accountability. The proposed framework, in its current form, allows assessing embedded levels of AXAI for delineating ML systems in a three-dimensional space. The AXAI framework quantifies comprehensibility in terms of the readiness of users to apply the acquired knowledge and assesses predictive accuracy in terms of the ratio of test and training data, training data size and the number of false-positive inferences. For establishing a chain of responsibility, accountability is measured in terms of the inspectability of input cues, data being processed and the output information. We demonstrate applying the framework for assessing the AXAI capabilities of three ML systems. The reported work provides bases for building AXAI capability frameworks for other genres of AI systems.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Masood Mehmood Khan et al.",
      "keywords": "Accountability; Computer science; Artificial intelligence; Space (punctuation); Machine learning; Big data; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3207812",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4296706757",
      "doi": "10.1109/access.2022.3208231",
      "title": "Complex Process Modeling in Process Mining: A Systematic Review",
      "abstract": "Process mining techniques are used to extract knowledge about the efficiency and compliance of an organization&#x2019;s business processes through process models. Real-life processes are unstructured, and applying process mining to discover such processes often results in complex process models that do not provide actionable insights. Several solutions have been presented to overcome this problem. However, the process mining domain lacks an explicit definition of complexity and its measurement. This vagueness results in ad-hoc solutions that vary according to the approach, modelling construct, and process properties. Additionally, the strength and limitations of the proposed solutions have not been adequately highlighted. Therefore, we conducted a systematic literature review on complexity in process mining over six popular scholarly literature indexing databases. Based on the review results, an explicit definition of complexity, the main contributing factors and their impact on process mining results were identified. We discovered various process complexity matrices and their application context. The analysis of studies led to the development of a taxonomy consisting of four different approaches for addressing the complexity problem, along with their strengths and limitations. Finally, the open research challenges and potential for future research are discussed.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mohammad Imran et al.",
      "keywords": "Process mining; Computer science; Process (computing); Vagueness; Data science; Business process discovery; Process modeling; Data mining; Context (archaeology); Domain (mathematical analysis); Business process; Business process modeling; Construct (python library); Work in process; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3208231",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4206362729",
      "doi": "10.1109/access.2021.3132580",
      "title": "Trust Management Systems in Cloud Services Environment: Taxonomy of Reputation Attacks and Defense Mechanisms",
      "abstract": "Using cloud data storage, large amounts of data can be stored by data owners in a flexible way and at low cost. Hence, there has been a major increase in online cloud service providers and their users. The privacy and security of data in the cloud computing environment is a major issue. Data privacy can be ensured by using a cryptographic access control method, so that data can only be accessed by authorized customers while keeping it inaccessible to unauthorized users. However, this type of cryptographic approach does not address the issue of trust. An integration between several trust models and cryptographic access control models has been presented in many research papers, the aim of which is to make data stored in cloud storage systems more secure. The objective of this study is to determine a solution that can suitably handle trust issues in access control models to decrease the risk as greater security to cloud storage systems, and the quality of decisions being made by data owners and cloud operators is improved. In this paper, we have presented a taxonomy for trust criteria and reputation attacks in cloud computing. Also, some of the fundamental concepts regarding trust management of services within cloud environments have been presented in this paper, along with the latest technologies. There are three layers in the model, and a series of dimensions are further determined for every layer (which are the assessment criteria), which serve as the benchmark to evaluate many research prototypes of trust models in a cloud computing environment by comparing these criteria when evaluating several trust models in a cloud computing environment. In this paper, a comparison of fifteen representative trust management research samples in cloud computing and the appropriate research domains were also carried out by employing this analytical model.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Salah T. Alshammari et al.",
      "keywords": "Cloud computing; Computer science; Computer security; Trust management (information system); Access control; Reputation; Cryptography; Cloud computing security; Data security; Data integrity; Cloud storage; Information privacy; Encryption",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3132580",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387490489",
      "doi": "10.1109/access.2023.3323445",
      "title": "A Review on Business Process Management System Design: The Role of Virtualization and Work Design",
      "abstract": "Business Process Management (BPM) has emerged as a fundamental aspect of modern business, revolutionizing task execution and operational efficiency. This study explored the integration of BPM, virtualization, and work design to enhance organizational performance and productivity. The objective is to contribute to the ongoing dialogue on the combined impact of these elements on BPM systems and their applicability in contemporary office settings. Through a systematic literature review, 136 journal articles were examined and selected from 2,248 articles matching the search criteria. This review reveals major gaps in the current literature and identifies opportunities for further research and investigation. These findings underscore the potential significance of integrating virtualization and work design in BPM systems to enhance flexibility, scalability, and agility. Organizations can effectively respond to dynamic business needs and market conditions by leveraging virtual resources, thus eliminating the constraints of physical proximity. We provide a reflective discussion linking theoretical understanding with empirical evidence from literature. Our analysis revealed promising avenues for future research, emphasizing the role of usability in BPM system design and its impact on task accomplishment. This systematic literature review underscores the role of virtualization and work design in BPM system design. We found that both components not only enhanced the performance and effectiveness of BPM systems, but also improved flexibility, scalability, and user experience. A holistic approach to BPM system design has emerged as crucial, encompassing process modelling, automation, workflow management, integration, analytics, reporting, governance, and continuous improvement. Despite the evident benefits, our review identified distinct challenges such as managing system complexity, ensuring security, navigating resistance to change, and harmonizing technology with human elements. Our analysis underscores avenues for research that have not yet been thoroughly explored and opportunities to further extend knowledge in this field.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Luke Bartlett et al.",
      "keywords": "Computer science; Virtualization; Business process management; Design science research; Workflow; Process management; Business process; Flexibility (engineering); Knowledge management; Design science; Information system; Work in process; Engineering; Cloud computing; Operations management",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3323445",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388505058",
      "doi": "10.1109/tsc.2023.3331083",
      "title": "An In-Depth Examination of Artificial Intelligence-Enhanced Cybersecurity in Robotics, Autonomous Systems, and Critical Infrastructures",
      "abstract": "Recent developments in cutting-edge robotics have been constantly faced with increased cyber-threats, not only in terms of the quantity or the frequency of attacks, but also when it comes to the quality and the severity of the intrusions. This paper provides a systematic overview and critical assessment of state-of-the-art scientific developments in the security aspects of robotics, autonomous systems, and critical infrastructures. Our review highlights open research questions addressing significant research gaps and/or new conceptual frameworks, considering recent advancements in artificial intelligence (AI) and machine learning. Thus the contributions of this paper can be summarised as follows. We first compare and contrast the benefits of multiple cutting-edge AI-based learning algorithms (e.g., fuzzy logic and neural networks) relative to traditional model-based systems (e.g. distributed control and filtering). Subsequently, we point out some specific benefits of AI algorithms to quickly learn and adapt the dynamics of non-linear systems in the absence of complex mathematical models. We also present some potential future research directions (open challenges) in the field. Lastly, this review also delivers an open message to encourage collaborations among experts from multiple disciplines. The implementation of multiple AI algorithms to tackle current security issues in robotics will transform and create novel, hybrid knowledge for intelligent cybersecurity at the application level.",
      "year": "2023",
      "journal": "IEEE Transactions on Services Computing",
      "authors": "Fendy Santoso et al.",
      "keywords": "Artificial intelligence; Robotics; Computer science; Field (mathematics); Machine learning; Applications of artificial intelligence; Artificial neural network; Robot; Data science; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tsc.2023.3331083",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391467349",
      "doi": "10.1109/access.2024.3361650",
      "title": "Tuning Machine Learning to Address Process Mining Requirements",
      "abstract": "Machine learning models are routinely integrated into process mining pipelines to carry out tasks like data transformation, noise reduction, anomaly detection, classification, and prediction. Often, the design of such models is based on some ad-hoc assumptions about the corresponding data distributions, which are not necessarily in accordance with the non-parametric distributions typically observed with process data. Moreover, mainstream machine-learning approaches tend to ignore the challenges posed by concurrency in operational processes. Data encoding is a key element to smooth the mismatch between these assumptions but its potential is poorly exploited. In this paper, we argue that a deeper understanding of the challenges associated with training machine learning models on process data is essential for establishing a robust integration of process mining and machine learning. Our analysis aims to lay the groundwork for a methodology that aligns machine learning with process mining requirements. We encourage further research in this direction to advance the field and effectively address these critical issues.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Paolo Ceravolo et al.",
      "keywords": "Computer science; Process (computing); Process mining; Artificial intelligence; Machine learning; Work in process; Engineering; Operating system; Business process modeling; Business process",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3361650",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3190455919",
      "doi": "10.1109/access.2022.3190975",
      "title": "Operationalizing Human Values in Software Engineering: A Survey",
      "abstract": "Human values (e.g., pleasure, privacy, and social justice) are what a person or a society considers important. Inability to address them in software-intensive systems can result in numerous undesired consequences (e.g., financial losses) for individuals and communities. Various solutions (e.g., methodologies, techniques) are developed to help &#x201C;operationalize values in software&#x201D;. The ultimate goal is to ensure building software (better) reflects and respects human values. In this survey, &#x201C;operationalizing values&#x201D; is referred to as <italic>the process of identifying human values and translating them to accessible and concrete concepts so that they can be implemented, validated, verified, and measured in software</italic>. This paper provides a deep understanding of the research landscape on operationalizing values in software engineering, covering 51 primary studies. It also presents an analysis and taxonomy of 51 solutions for operationalizing values in software engineering. Our survey reveals that most solutions attempt to help operationalize values in the early phases (requirements and design) of the software development life cycle. However, the later phases (implementation and testing) and other aspects of software development (e.g., &#x201C;team organization&#x201D;) still need adequate consideration. We outline implications for research and practice and identify open issues and future research directions to advance this area.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mojtaba Shahin et al.",
      "keywords": "Operationalization; Computer science; Software; Software engineering; Software development; Data science; Knowledge management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3190975",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3047945175",
      "doi": "10.1109/access.2020.3015152",
      "title": "Development of Novel Big Data Analytics Framework for Smart Clothing",
      "abstract": "Recent advances in micro electro-mechanical systems (MEMS) have produced wide variety of wearable sensors. Owing to their low cost, small size and interfacability, those MEMS based devices have become increasingly commonplace and part of daily life for many people. Large amount of data from heart and breath rates to electrocardiograph (ECG) signals, which contain a wealth of health-related information, can be measured. Hence, there is a timely need for novel interrogation and analysis methods for extracting health related features from such a Big Data. In this paper, the prospects from smart clothing such as wearable devices in generating Big Data are critically analyzed with a focus on applications related to healthcare, sports and fashion. The work also covers state-of-the-art data analytics methods and frameworks for health monitoring purposes. Subsequently, a novel data analytics framework that can provide accurate decision in both normal and emergency health situations is proposed. The proposed novel framework identifies and discusses sources of Big Data from the human body, data collection, communication, data storage, data analytics and decision making using artificial intelligence (AI) algorithms. The paper concludes by identifying challenges facing the integration of Big Data analytics with smart clothing. Recommendation for further development opportunities and directions for future work are also suggested.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mominul Ahsan et al.",
      "keywords": "Big data; Computer science; Analytics; Data science; Wearable computer; Wearable technology; Variety (cybernetics); Data analysis; Clothing; Artificial intelligence; Data mining; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3015152",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319459211",
      "doi": "10.1109/access.2023.3243195",
      "title": "Intelligent Framework to Support Technology and Business Specialists in the Public Sector",
      "abstract": "The development of intelligent routines to support complex decision-making is not always straight-forward. In the public service the difficulties may be related to the abundance of available data sources and the number of legal standards to be met, in addition to the need for the incorporation of transparency, auditability, standardization, and desirable reuse in the IT systems. This article presents the Domain Engineering process carried out to obtain a feature model for the implementation of a Framework that uses Artificial Intelligence for dealing with the governmental rules to support public decision-making. One highlight of the put forward framework is that it supports both, end users and IT people (i.e., experts in business and in technology), that are not experienced with intelligent techniques as well as it focuses on Compliance. For this research, the Design Science Research Methodology method was used, sorting the work into the steps of the problem identification and motivation, the definition of goals, the design and development, the verification and validation of the experiments, and the communication of the results. A systematic review identifying the lack of an AI Framework in the Public Sector was carried out beforehand. The research produced a Whitebox Framework aiming to supply recommendations for both groups of users based on solutions that have already been tested and applied to know problems in their respective areas, e.g., anomaly detection, fraud identification, rule extraction, and risk management, among others focused on Compliance. Moreover, the framework was built so that it can be evolved by experts with due use.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "\u00c1lvaro Farias Pinheiro et al.",
      "keywords": "Computer science; Standardization; Reuse; Domain (mathematical analysis); Public sector; Identification (biology); Design science research; Decision support system; Transparency (behavior); Knowledge management; Engineering management; Information system; Artificial intelligence; Computer security; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3243195",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206747626",
      "doi": "10.1109/access.2022.3141910",
      "title": "Job Forecasting Based on the Patent Information: A Word Embedding-Based Approach",
      "abstract": "The rapid change in technology makes it challenging to forecast the future of jobs. Previous studies have analyzed economics and employment data or employed expert-based methods to forecast the future of jobs, but these approaches were not able to reflect the latest technology trends in an objective way. To overcome the issue, this study matches jobs with patents and forecasts the future of jobs based on changes in the number of patents with time. A word embedding model is trained by patent classification code and job description data and used to find similar patent classification codes of jobs. For an illustration purpose, we identify information technology-related jobs listed in O<sup>&#x002A;</sup>NET and discover similar patent classification codes of the jobs. Based on the change in the number of patents, we find promising jobs presenting high technical demands. Several implications of our approach are also discussed.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Taehyun Ha et al.",
      "keywords": "Computer science; Word embedding; Word (group theory); Embedding; Natural language processing; Artificial intelligence; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3141910",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391936033",
      "doi": "10.1109/access.2024.3367445",
      "title": "Enhancing Cloud-Based Inventory Management: A Hybrid Blockchain Approach With Generative Adversarial Network and Elliptic Curve Diffie Helman Techniques",
      "abstract": "In contemporary business organizations, the pivotal role of automation in control processes is evident through Inventory Management Systems (IMS), which leverage advanced techniques and data analytics algorithms to optimize inventory levels, enhance accuracy, and minimize costs. However, existing security techniques for IMS, including access controls, firewalls, and audits, face challenges in effectively addressing the evolving threat landscape. These limitations, including struggles with dynamic user roles, susceptibility to data manipulation, and challenges in thwarting various cyber threats, necessitate innovative solutions for robust real-time management and security. Consequently, this work proposes a novel hybrid approach that integrates blockchain with RFID data, Generative Adversarial Networks, and Elliptic Curve Diffie-Hellman cryptographic techniques. In the developed hybrid approach, RFID readers are leveraged to collect inventory data, while the Generative Adversarial Network is specifically designed for processing the raw dataset, encompasses data filtering, normalization, and error correction tasks. The utilization of the Elliptic Curve Diffie-Hellman technique is integral for generating both private and shared keys, facilitating secure transmission between the IMS client and cloud-based servers. The blockchain module is engineered to enhance data security and protect shared secret keys, which is achieved through a two-layer mechanism involving encryption via the Advanced Encryption Standard algorithm and SHA-256 hashing function. Additionally, it incorporates the Artificial Algae Algorithm and an Elman Neural Network to ensure robust data access and integrity. To assess the effectiveness of the proposed hybrid approach, it is implemented on a publicly available dataset. The performance assessment involves a comparison with state-of-the-art security methods, considering key metrics such as encryption time, decryption time, key generation time, throughput, latency, and data confidentiality rate. Simulation results conclusively demonstrate that the proposed hybrid approach significantly reduces encryption time, decryption time, key generation time, and latency. Furthermore, it notably improves throughput and data confidentiality rates while aligning with stringent IMS security requirements.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Reyazur Rashid Irshad et al.",
      "keywords": "Adversarial system; Computer science; Blockchain; Generative adversarial network; Computer security; Artificial intelligence; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3367445",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3008043593",
      "doi": "10.1109/access.2020.2976751",
      "title": "Pair-Wise Matching of EEG Signals for Epileptic Identification via Convolutional Neural Network",
      "abstract": "Electroencephalogram (EEG) have been extensively analyzed to identify the characteristics of epileptic seizures in the literature. However, most of these studies focus on the properties of single channel EEG data while neglecting the association between signals from diverse channels. To bridge this gap, we propose an EEG instance matching-based epilepsy classification approach by introducing one convolutional neural network (CNN). First of all, each pair of EEG signals are exploited to form one 2 dimensional matrix, which could be used to reveal the interaction between them. Secondly, the generated matrices are fed into the proposed CNN that would discriminate the input representations. To evaluate the performance of the presented approach, the comparison experiments between the state-of-the-art techniques and our work are conducted on publicly available epilepsy EEG benchmark database. Experimental results indicate that the proposed algorithm could yield the performance with an average accuracy of 99.3%, average sensitivity of 99.5%, and average specificity 99.6%.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jian Lian et al.",
      "keywords": "Electroencephalography; Computer science; Convolutional neural network; Pattern recognition (psychology); Artificial intelligence; Epilepsy; Focus (optics); Sensitivity (control systems); Benchmark (surveying); Speech recognition; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2976751",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4382752485",
      "doi": "10.1109/access.2023.3290899",
      "title": "A Mapping Review on Cyber-Physical Smart Contracts: Architectures, Platforms, and Challenges",
      "abstract": "Smart contracts are software systems that monitor, automate, and control the execution of a process, react to violations, and enforce process terms and conditions. There is tremendous interest in developing smart contract applications in banking, finance, insurance, government, and supply chain markets. Many of these applications operate in a cyber-physical environment and adopt architectures based on Internet-of-Things (IoT) and blockchain technologies to support monitoring and ensure data integrity. To investigate how cyber-physical smart contracts are realized for compliance monitoring, together with associated challenges and research opportunities. A mapping review of the literature that surveys underlying architectures and their evaluation. The publications considered came from four databases (Scopus, Web of Science, IEEE Xplore, and Google Scholar), supplemented by manual snowballing. All publications considered are peer-reviewed, written in English, and published in non-predatory venues. A total of 368 publications were considered, with a final selection of 50 papers (all published between 2018 and 2023) that were analyzed along three dimensions: Cyber-physical architectures, infrastructure failures, and technical challenges. Blockchain technologies are the most commonly used platform for smart contracts as they provide decentralized architectures deploying interesting communication patterns, as well as multiple technologies to simplify communication for producing and consuming events. Moreover, such architectures can lead to many types of infrastructure failures including sensor/actuator attacks, network outages, and hardware/software failures, resulting in five important technical challenge areas related to security, availability, robustness, privacy, and legal aspects. Key insights and directions for future research are also reported. This review will inform readers about how cyber-physical smart contracts are being built and deployed and the challenges that are faced by their builders and users.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sofana Alfuhaid et al.",
      "keywords": "Computer science; Smart contract; Computer security; Cyber-physical system; Context (archaeology); Process (computing); Data science; Blockchain",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3290899",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4395027377",
      "doi": "10.1109/ojse.2024.3392691",
      "title": "Exploring Current Practices and Challenges of HIPAA Compliance in Software Engineering: Scoping Review",
      "abstract": "Healthcare systems and applications are increasingly used to improve patient care. However, these applications face data security, privacy, and regulatory compliance challenges. The health insurance portability and accountability act (HIPAA) regulates the use and disclosure of patient health information. Ensuring HIPAA compliance in the software engineering process poses critical challenges to software engineering practitioners. This review focuses on understanding the state-of-the-art in the current literature for ensuring HIPAA compliance in the software development life cycle, namely, requirement gathering, software design, implementation, software testing, and evolution. The findings of this study shed light on software engineers in creating HIPAA compliance healthcare systems and applications. This literature review presents the key themes and trends in this research area. Also, it provides recommendations for future research in the intersection of software engineering methods and HIPAA compliance.",
      "year": "2024",
      "journal": "IEEE Open Journal of Systems Engineering",
      "authors": "Farah Elkourdi et al.",
      "keywords": "Compliance (psychology); Current (fluid); Software; Medicine; Engineering; Engineering ethics; Computer science; Psychology; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojse.2024.3392691",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389161252",
      "doi": "10.1109/access.2023.3338176",
      "title": "High School Students\u2019 Engagement in Biology in the Context of XR Technology",
      "abstract": "With Extended Reality (XR), it is possible to enhance our real-world experiences through a fusion of immersive and interactive technologies. In the present research, the researchers intended to study high school students&#x2019; engagement in Biology learning in the context of XR. Fourteen tenth-grade students who learned the biological topics of the cell and the heart participated in the research. During the selection process, consideration was given to the students&#x2019; readiness to participate in the program. The researchers collected data via interviews and observations. The interview questions were related to the four types of engagement: The behavioral, the cognitive, the emotional, and the social. The observations were used to triangulate the interview-based data. To analyze the data, the researchers used deductive and inductive content analysis. The research results indicated the XR context encouraged the participants to engage in four types of engagement: cognitive engagement (learning perception, learning assessment, learning regulation, learning application), emotional engagement (learning sufficiency, affection for learning, and learning motivation), social engagement (interaction and communication), and behavioral engagement (achievement and good classroom behavior). The observations results supported the results from the interviews.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mohammad Hmoud et al.",
      "keywords": "Context (archaeology); Student engagement; Psychology; Affection; Cognition; Perception; Mathematics education; Computer science; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3338176",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386825103",
      "doi": "10.1109/ojcoms.2023.3316118",
      "title": "Data Quality in Human-Centric Sensing-Based Next-Generation IoT Systems: A Comprehensive Survey of Models, Issues, and Challenges",
      "abstract": "Human-Centric Sensing (HCS), a novel approach in the evolution of the Next Generation Internet of Things (NG-IoT), exploits the ubiquity of diverse smart devices, including smartphones or wearable devices, in conjunction with their enhanced sensing capabilities to collect information, leveraging human intelligence for the common benefit of the crowd. The main feature of HCS is the involvement of mobile users in data collection, processing, analysis and sharing. Thus, the main challenge in HCS systems is to ensure users&#x2019; participation and trustworthiness as well as data quality. The aim of this work is, as a first step, to identify and discuss the factors that affect data quality in HCS-based NG-IoT systems, as well as elaborate on their interrelation. Furthermore, potential solutions that could be adopted to ensure the highest possible degree of data quality are highlighted, in conjunction with critical aspects that should be considered, proposing a novel classification with three major categories: task assignment, reputation mechanisms and blockchain technology. Finally, a trust-aware task assignment model is proposed to effectively address the data quality challenge in HCS-based IoT systems, reflecting users&#x2019; trustworthiness, willingness, experience, and ability to collect and share high-quality data contributions. The proposed trust-aware task assignment model exploits a reputation mechanism and is designed using blockchain and smart contract technologies to enable the decentralized provision of trustworthy services among entities and preserve users&#x2019; privacy, harnessing the decentralization, transparency and immutability offered by blockchain. Trust-based task assignment offers an effective solution for trustworthy users&#x2019; selection while ensuring high-quality contributions and users&#x2019; privacy.",
      "year": "2023",
      "journal": "IEEE Open Journal of the Communications Society",
      "authors": "Konstantina Banti et al.",
      "keywords": "Computer science; Exploit; Reputation; Task (project management); Quality (philosophy); Data quality; Computer security; Transparency (behavior); Data science; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcoms.2023.3316118",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389665063",
      "doi": "10.1109/access.2023.3342365",
      "title": "Analysis of Log Files to Enable Smart-Troubleshooting in Industry 4.0: A Systematic Mapping Study",
      "abstract": "A crucial element of Industry 4.0, is the utilization of smart devices that generate log files. Log files are key components containing data on system operations, faults (unexpected glitches or malfunctions), errors (mistakes or incorrect actions), and failures (complete breakdowns or non-functionality). This paper presents a systematic mapping study analyzing research conducted on log files for smart-troubleshooting in Industry 4.0. To the best of our knowledge, this is the study that aims to identify research trends, log file attributes, techniques, and challenges involved in log file analysis for smart-troubleshooting. From an initial set of 941 potentially relevant peer-reviewed publications, 74 primary studies were selected and analyzed using a meticulous data extraction, analysis, and synthesis process. The results of the study demonstrate that the majority of research has focused on developing algorithms for log analysis, with machine learning being the most commonly used approach. The smart-troubleshooting encompasses a range of activities and tools that are essential for collecting failure data generated by diverse interconnected devices, conducting analyses, and aligning them with troubleshooting instructions and software remedies. Moreover, the study identifies the need for further research in the areas of real-time log analysis, anomaly detection, and the integration of log analysis with other Industry 4.0 technologies. In conclusion, our study provides insights into the current state of research in log analysis for smart-troubleshooting in Industry 4.0 and identifies areas for future research. The use of smart devices generating log files in Industry 4.0 highlights the importance of log file analysis for troubleshooting purposes. Further research is needed to address the challenges and opportunities in this field to integrate log analysis with other Industry 4.0 technologies for performing more efficient and effective troubleshooting.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sania Partovian et al.",
      "keywords": "Troubleshooting; Computer science; Key (lock); Process (computing); Web log analysis software; Data mining; Database; Data science; World Wide Web; Operating system; Web service",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3342365",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386025700",
      "doi": "10.1109/access.2023.3307018",
      "title": "A Fine-Grained System Driven of Attacks Over Several New Representation Techniques Using Machine Learning",
      "abstract": "Machine Learning (ML) techniques, especially deep learning, are crucial to many contemporary real world systems that use Computational Intelligence (CI) as their core technology, including self-deriving vehicles, assisting machines, and biometric authentication systems. We encounter a lot of attacks these days. Drive-by-download is used to covertly download websites when we view them, and emails we receive often have malicious attachments. The affected hosts and networks sustain significant harm as a result of the infection. Therefore, identifying malware is crucial. Recent attacks, however, is designed to evade detection using Intrusion Detection System (IDS). It is essential to create fresh signatures as soon as new malware is found in order to stop this issue. Using a variety of cutting-edge representation methodologies, we develop attack taxonomy and examine it. 1) N-gram-based representation: In this tactic, we look at a number of random representations that consider a technique of sampling the properties of the graph. 2) Signature-based representation: This technique uses the idea of invariant representation of the graph, which is based on spectral graph theory. One of the main causes is that a ML system setup is rely on a number of variables, including the input dataset, ML architecture, attack creation process, and defense strategy. To find any hostile attacks in the network system, we employ IDS with Deep Neural Network (DNN). In conclusion, the efficacy and efficiency of the suggested framework with Convolutional Neural Network (CNN) and Support Vector Machine (SVM) are assessed using the assessment indicators, including throughput, latency rate, accuracy and precision. The findings of the suggested model with a detection rate of 93&#x0025;, 14&#x0025;, 95.63&#x0025; and 95&#x0025; in terms of throughput, latency rate, accuracy and precision, which is based on adversarial assault, were better and more effective than CNN and SVM models. Additionally at the end we contrast the performance of the suggested model with that of earlier research that makes use of the same dataset, NSL-KDD, as we do in our scenario.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mohammed A. Al Ghamdi",
      "keywords": "Computer science; Malware; Artificial intelligence; Machine learning; Convolutional neural network; Support vector machine; Graph; Representation (politics); Feature learning; Data mining; Theoretical computer science; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3307018",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3115768870",
      "doi": "10.1109/access.2020.3047434",
      "title": "A Bibliometric Review of Two Decades\u2019 Research on Closed-Loop Supply Chain: 2001-2020",
      "abstract": "The closed-loop supply chain (CLSC) is generally regarded as an environmentally friendly approach that can help in reducing environmental impacts and achieving sustainable development of society and economics. In recent years, the popularity research of CLSC has been widely concerned by both business and academia practitioners. It is observed that most of the literatures have focused only on a particular journal or field; there is a distinct lack of comprehensive bibliometric review of two decades' research on CLSC. This study contributes in fulfilling this gap. A comprehensive bibliometric analysis was conducted based on 1,155 articles in Web of Science Core Collection Database from 2001 to 2020. In order to track research frontiers and hotspots, visualization software VOSviewer and CiteSpace are used for analysis. Initially, a descriptive analysis was carried out to identify the trends of number of publications, the leading journals, top authors and regions. A thematic cluster analysis was then carried out to identify the research domains. Subsequently, based on the analyses of co-keywords, dominant categories and co-citation, hot issues and research trends are summarized. \u201cgame theory\u201d, and \u201cremanufacturing\u201d are emerging research trends for CLSC. \u201cDual channel\u201d, \u201cquality\u201d and \u201ccircular economy\u201d had become hot topics. This review also finds the landmark nodes and pivot nodes in the research of CLSC. Finally, some research gaps are revealed to shed light on future directions.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Gaofeng Guan et al.",
      "keywords": "Computer science; Popularity; Supply chain; Citation analysis; Bibliometrics; Data science; Sustainability; Citation; Business; Library science; Marketing; Political science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3047434",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226031780",
      "doi": "10.1109/access.2022.3159798",
      "title": "Science and Technology Parks: A Futuristic Approach",
      "abstract": "Most of the existing science and technology parks resort to various conventional ways to attract different stakeholders to the park. Some of these traditional measures include business support, workspaces, laboratories, networking events, accommodation, and essential commodities. Besides, with rampantly changing multidisciplinary technologies and increased data-oriented business models, the classic science and technology park value-creation strategies may not be instrumental in the near future. Hence, we foresee that future science and a technology parks should be fully integrated, sustainable, and innovative living science cities. Where park tenants can actively interact and contribute to emerging technologies. Therefore, this paper carries out an in-depth study of world&#x2019;s best practices in smart cities and science and technology parks, their characteristics, and value-added contributions that excite the prospective tenants. Developing on the detailed survey, we propose a unique feature of &#x201C;Autonomous Systems as a Service&#x201D; to bestow a futuristic look to the science and technology parks. It is envisaged that autonomous systems will not only provide value-added services to the park tenants but will also provide an infrastructure for testing new technologies within park premises. Furthermore, this study evaluates security and privacy challenges associated with autonomous systems and data-oriented services and recommends appropriate security measures. The role of universities in the success of a science and technology park is also delineated. Finally, the components deemed essential for the attainment of science and technology parks&#x2019; objectives are highlighted.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Imran Makhdoom et al.",
      "keywords": "Multidisciplinary approach; Service (business); Business; Living lab; Business model; Science park; Computer science; Knowledge management; Engineering management; Marketing; Engineering; Sociology; Political science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3159798",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4395661540",
      "doi": "10.1109/access.2024.3394036",
      "title": "Exploring Central-Peripheral Nervous System Interaction Through Multimodal Biosignals: A Systematic Review",
      "abstract": "The interaction between the central nervous system (CNS) and peripheral nervous system (PNS) governs various physiological functions, influences cognitive processes and emotional states. It is necessary to unravel the mechanisms governing the interaction between the brain and the body, enhancing our understanding of physical and mental well-being. Neuro-ergonomics-based human-computer interaction can be improved by comprehending the intricate interrelation between the CNS and PNS. Various studies have been explored using diverse methodologies to study CNS-PNS interaction in specific psychophysiological states, such as emotion, stress, or cognitive tasks. However, there is a need for a thorough, extensive, and systematic review covering diverse interaction forms, applications, and assessments. In this work, an attempt has been made to perform a systematic review that examines the interaction between the CNS and PNS across diverse psychophysiological states, focusing on varied physiological signals. For this, scientific repositories, namely Scopus, PubMed, Association for Computing Machinery, and Web of Science, are accessed. In total, 61 articles have been identified within the period of January 2008 to April 2023 for systematic review. The selected research articles are analyzed based on factors, namely subject information, stimulation modality, types of interactions between the brain and other organs, feature extraction techniques, classification methods, and statistical approaches. The evaluation of the existing literature indicates a scarcity of publicly available databases for CNS-PNS interaction and limited application of machine learning and deep learning-based advanced tools. Furthermore, this review underscores the urgent need for enhancements in several key areas including the development of a more refined psycho-physiological model, improved analysis techniques, and better electrode-surface interface technology. Additionally, there is a need for more research involving daily life activities, female-oriented studies, and privacy considerations. This review contributes to standardizing protocols, improves the diagnostic relevance of various instruments, and extracts more reliable biomarkers. The novelty of this study lies in guiding researchers to point out various issues and potential solutions for future research in the field of bio-signal-based CNS-PNS interaction.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Sourabh Banik et al.",
      "keywords": "Computer science; Peripheral; Multimodal interaction; Central nervous system; Neuroscience; Human\u2013computer interaction; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3394036",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388097684",
      "doi": "10.1109/access.2023.3328535",
      "title": "A Comprehensive Survey on Ensemble Learning-Based Intrusion Detection Approaches in Computer Networks",
      "abstract": "Machine learning algorithms present a robust alternative for building Intrusion Detection Systems due to their ability to recognize attacks in computer network traffic by recognizing patterns in large amounts of data. Typically, classifiers are trained for this task. Together, ensemble learning algorithms have increased the performance of these detectors, reducing classification errors and allowing computer networks to be more protected. This research presents a comprehensive Systematic Review of the Literature where works related to intrusion detection with ensemble learning were obtained from the most relevant scientific bases. We offer 188 works, several compilations of datasets, classifiers, and ensemble algorithms, and document the experiments that stood out in their performance. A characteristic of this research is its originality. We found two surveys in the literature specifically focusing on the relationship between ensemble techniques and intrusion detection. We present for the last eight years covered by this survey a timeline-based view of the works studied to highlight evolutions and trends. The results obtained by our survey show a growing area, with excellent results in detecting attacks but with needs for improvement in pruning for choosing classifiers, which makes this work unprecedented for this context.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Thiago Jos\u00e9 Lucas et al.",
      "keywords": "Computer science; Intrusion detection system; Ensemble learning; Timeline; Machine learning; Artificial intelligence; Context (archaeology); Pruning; Task (project management); Intrusion; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3328535",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4317515961",
      "doi": "10.1109/access.2023.3238311",
      "title": "Post-Pandemic Follow-Up Audit of Security Checkpoints",
      "abstract": "This paper provides a follow-up audit of security checkpoints (or simply checkpoints) for mass transportation hubs such as airports and seaports aiming at the post-pandemic R&#x0026;D adjustments. The goal of our study is to determine biometric-enabled resources of checkpoints for a counter-epidemic response. To achieve the follow-up audit goals, we embedded the checkpoint into the Emergency Management Cycle (EMC) &#x2013; the core of any doctrine that challenges disaster. This embedding helps to identify the technology-societal gaps between contemporary and post-pandemic checkpoints. Our study advocates a conceptual exploration of the problem using EMC profiling and formulates new tasks for checkpoints based on the COVID-19 pandemic lessons learned. In order to increase practical value, we chose a case study of face biometrics for an experimental post-pandemic follow-up audit.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Kenneth Lai et al.",
      "keywords": "Audit; Pandemic; Computer security; Coronavirus disease 2019 (COVID-19); Computer science; Profiling (computer programming); Business; Accounting",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3238311",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4225518123",
      "doi": "10.1109/access.2022.3162890",
      "title": "Security and Privacy of Blockchain-Based Single-Bit Cache Memory Architecture for IoT Systems",
      "abstract": "This paper provides an overview of blockchain technology&#x2019;s security and privacy features, as well as an overview of IoT-based cache memory and single-bit six transistor static random-access memory cell sense amplifier architecture. Each chip&#x2019;s memory is used for recorded as blocks, which are encrypted and used as a blockchain for other memory devices. The architectures comprise of the circuit of write driver, six transistor static random access memory cells, and sense amplifiers such as current differential sense amplifier, charge transfer differential sense amplifier, and voltage latch sense amplifier. Furthermore, different parameters such as the number of transistors, sensing delay, and power consumption have been analyzed for varying resistance values (i.e., R&#x003D;<inline-formula> <tex-math notation=\"LaTeX\">$42.3\\Omega $ </tex-math></inline-formula> and R&#x003D;42.3K<inline-formula> <tex-math notation=\"LaTeX\">$\\Omega$ </tex-math></inline-formula>). Apart from that, power reduction techniques such as dual sleep, forced stack, sleep transistor, and sleep stack are used to optimize power consumption. These power reduction techniques are applied over different blocks of architecture, such as six transistors static random access memory cell and sense amplifier to optimize power consumption of the architecture. The conclusion arises that a single-bit six transistor static random access memory cell with power reduction dual sleep technique voltage latch sense amplifier with power reduction dual sleep technique in architecture consumes <inline-formula> <tex-math notation=\"LaTeX\">$11.65~\\mu \\text{W}$ </tex-math></inline-formula> of power and has 33 transistors which are lowest from other architectures.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Reeya Agrawal et al.",
      "keywords": "Computer science; Blockchain; Cache; Internet of Things; Architecture; Computer security; Computer network; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3162890",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4206551363",
      "doi": "10.1109/access.2021.3133020",
      "title": "Reusable Security Requirements Repository Implementation Based on Application/System Components",
      "abstract": "Forming high quality requirements has a direct impact on project success. Gathering security requirements could be challenging, since it demands a multidisciplinary approach and security expertise. Security requirements repository enables an effective alternative for addressing this challenge. The main objective of this paper is to present the design of a practical repository model for reusable security requirements, which is easy to use and understand for even non-security experts. The paper also portrays an approach and a software tool for using this model to determine subtle security requirements for improved coverage. Proposed repository consists of attributes determined by examining common security problems covered in state-of-the-art publications. A test repository was prepared using specification files and Common Criteria documents. The outcomes of applying the proposed model were compared with the sample requirement sets included in the state-of-the-art publications. The results reveal that in the absence of a security requirements repository, key security points can be missed. Repository improves the completeness of the security terms with reasonable effort.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Ferda \u00d6zdemir S\u00f6nmez et al.",
      "keywords": "Computer science; Security testing; Software security assurance; Computer security model; Security information and event management; Requirements analysis; Security service; Database; Software engineering; Computer security; Cloud computing security; Software; Information security; Cloud computing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3133020",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393106164",
      "doi": "10.1109/access.2024.3380888",
      "title": "Toward a Holistic Privacy Requirements Engineering Process: Insights From a Systematic Literature Review",
      "abstract": "Privacy requirements engineering is a crucial aspect of privacy engineering. It aims to integrate privacy principles into organizational and technical processes throughout the software development lifecycle. This specialized field involves various strategies, including compliance with regulatory frameworks, asset analysis, and system diagram development for threat modeling. The wide range of approaches, while beneficial in providing different perspectives, presents a significant challenge to the novice privacy engineer or developer in identifying the most effective methodologies. The lack of a single methodology highlights the need for a systematic literature review (SLR) to establish a standardized process for privacy requirements engineering that promotes consistency across different methodologies. To address this issue, we conducted a comprehensive SLR to synthesize existing privacy requirements engineering methodologies. Our analysis involved dissecting each method&#x2019;s processes, tasks, techniques, work products, and resources. Our review examined 40 privacy requirements engineering methodologies detailed in 50 papers, from which we extracted five key processes commonly followed in privacy requirements engineering research. We used this as the foundation for a holistic approach to facilitate the adoption of a comprehensive privacy requirements engineering process. The review also identifies ongoing challenges and suggests future directions in this field.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Guntur Budi Herwanto et al.",
      "keywords": "Computer science; Process (computing); Information privacy; Requirements engineering; Process management; Computer security; Engineering; Software",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3380888",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389890931",
      "doi": "10.1109/access.2023.3344038",
      "title": "PenChain: A Blockchain-Based Platform for Penalty-Aware Service Provisioning",
      "abstract": "Service provisioning is of paramount importance as we are now heading towards a world of integrated services giving rise to the next generation of service ecosystems. The huge number of service offerings that will be available to customers in future scenarios require a novel approach to service registry and discovery that allows customers to choose the offerings that best match their preferences. One way to achieve this is to introduce the provider\u2019s reputation, i.e., a quality indicator of the provisioned service, as an additional search criterion. Now, with blockchain technology in our hands, automated regulation of service-level agreements (SLAs) that capture mutual agreements between all involved parties has regained momentum. In this article, we report on our full-fledged work on the conception, design, and construction of a platform for SLA-minded service provisioning called PenChain. With our work, we demonstrate that penalty-aware SLAs of general services\u2013if represented in machine-readable logic and assisted by distributed ledger technology\u2013are programmatically enforceable. We devise algorithms for ranking services in a search result taking into account the digitized values of the SLAs. We offer two scenario-based evaluations of PenChain in the field of precision agriculture and in the domain of automotive manufacturing. Furthermore, we examine the scalability and data security of PenChain for precision agriculture.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Trung-Viet Nguyen et al.",
      "keywords": "Computer science; Provisioning; Scalability; Service (business); Service provider; Service level; Service-level agreement; Service level objective; Reputation; Blockchain; Computer security; Service design; Quality of service; Database; Computer network; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3344038",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4415368556",
      "doi": "10.1109/tccn.2025.3623369",
      "title": "Internet of Agents: Fundamentals, Applications, and Challenges",
      "abstract": "With the rapid proliferation of large language models and vision-language models, AI agents have evolved from isolated, task-specific systems into autonomous, interactive entities capable of perceiving, reasoning, and acting without human intervention. As these agents proliferate across virtual and physical environments, from virtual assistants to embodied robots, the need for a unified, agent-centric infrastructure becomes paramount. In this survey, we introduce the Internet of Agents (IoA) as a foundational framework that enables seamless interconnection, dynamic discovery, and collaborative orchestration among heterogeneous agents at scale. We begin by presenting a general IoA architecture, highlighting its hierarchical organization, distinguishing features relative to the traditional Internet, and emerging applications. Next, we analyze the key operational enablers of IoA, including capability notification and discovery, adaptive communication protocols, dynamic task matching, consensus and conflict-resolution mechanisms, and incentive models. Finally, we identify open research directions toward building resilient and trustworthy IoA ecosystems.",
      "year": "2025",
      "journal": "IEEE Transactions on Cognitive Communications and Networking",
      "authors": "Yuntao Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tccn.2025.3623369",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391164201",
      "doi": "10.1109/access.2024.3357943",
      "title": "Elevating Big Data Privacy: Innovative Strategies and Challenges in Data Abundance",
      "abstract": "The exponential growth of big data has ushered in transformative possibilities across various sectors, but it has also raised formidable privacy concerns. This article delves into the pressing need for enhancing big data privacy and explores innovative approaches to address this critical issue. In recent years, big data has been characterized by its immense volume, high velocity, and diverse data sources. These attributes have enabled organizations to gain unprecedented insights but have also exposed sensitive information to potential breaches. As such, ensuring the privacy of individuals and sensitive data within big data sets has emerged as a paramount concern. This article first elucidates the multifaceted nature of big data privacy, emphasizing its encompassment of privacy, confidentiality, integrity, and availability. It also acknowledges the challenges posed by existing privacy-preserving techniques, which often fall short of providing comprehensive protection for large and diverse data sets. The core focus of this article lies in presenting novel strategies and technologies designed to improve big data privacy. This article presents an innovative framework that combines advanced encryption methods, including fine-grained encryption techniques and differential privacy mechanisms specifically designed for the distinct traits of big data, like noisy techniques. To achieve this, the dataset undergoes categorization into key attributes, sensitive attributes, quasi attributes, and insensitive attributes. Subsequently, the fine-grained technique encrypts key and sensitive attributes, while the differential privacy mechanism encrypts the quasi attributes. To further substantiate the effectiveness of the proposed technique, this article references to empirical findings that demonstrate tangible improvements in big data privacy protection.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mohamed Elkawkagy et al.",
      "keywords": "Big data; Computer science; Differential privacy; Encryption; Information privacy; Data science; Key (lock); Transformative learning; Confidentiality; Internet privacy; Privacy software; Computer security; Privacy by Design; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3357943",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390097403",
      "doi": "10.1109/tem.2023.3342980",
      "title": "Exploring the Multifaceted Challenges of Women in Engineering: A Comprehensive Literature Review",
      "abstract": "The present research delves into the complex dynamics of gender equality, highlighting women's experiences within the engineering sector. Drawing from a literature spanning from 2005 to 2023, we gathered insights from 108 pertinent articles on the topic. Our results show that a substantial portion of research underscore the persistent biases and barriers women encounter in engineering. Through our analysis, we unveiled four dominant themes: \u2018The Impact of Sex Differences on Productivity\u2019, \u2018Gender Digital Divide\u2019, \u2018Discriminatory Behaviour\u2019, and \u2018Women and Performance\u2019. Applying the glass ceiling theory as analytical framework, we discern a prevailing neglect towards women's challenges in the engineering field. Our findings accentuate the necessity for innovative policy interventions. To this end, we introduce a comprehensive policy model tailored to champion robust gender equity initiatives within engineering field.",
      "year": "2023",
      "journal": "IEEE Transactions on Engineering Management",
      "authors": "Marina Dabi\u0107 et al.",
      "keywords": "Champion; Glass ceiling; Psychological intervention; Neglect; Gender equity; Field (mathematics); Engineering ethics; Engineering; Political science; Psychology; Sociology; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tem.2023.3342980",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390204009",
      "doi": "10.1109/access.2023.3347029",
      "title": "Empowering Medical Data Analysis: An Advanced Deep Fusion Model for Sorting Medicine Document",
      "abstract": "To enhance the accuracy of medical document classification, we propose an advanced deep fusion model for sorting medicine document. Specifically, we enhance text representation using the bidirectional encoder representation from transformers (BERT). BERT is a bidirectional model that considers context information in input sequences. This capability is particularly valuable for medical document, as medical information often requires understanding in a global context, such as diagnoses, medical history, and treatment plans. Furthermore, BERT can learn the semantics of words and phrases, comprehending the different meanings of the same word in distinct contexts, which is crucial for representing medical document. For example, In the context of cardiology, stroke often refers to a cerebrovascular accident, which is a condition where blood flow to the brain is disrupted, leading to neurological impairment. This type of stroke is related to the brain and is a significant concern in the field of cardiology due to its impact on the circulatory system. In dermatology, stroke might be used to refer to a type of skin condition, such as stroking the skin. However, this context is less common and not related to the cerebrovascular meaning. Subsequently, we employ both Convolutional Neural Network (ConvNet) and Bidirectional Long Short Term Memory (Bi-LSTM) to extract local features and global long-term dependencies, respectively. Their outputs are then fused to extract useful document features at multiple levels, effectively capturing the documental structure. The proposed deep fusion model leverages the complementary strengths of these components, enhancing the model&#x2019;s generalization ability and mitigating the risk of over-fitting. Ultimately, by comparing our approach with state-of-the-art methods in medical document classification, we demonstrate the effectiveness of the proposed methodology.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Bo Guan et al.",
      "keywords": "Computer science; Context (archaeology); Artificial intelligence; Deep learning; Natural language processing; Medical diagnosis; Representation (politics); Information retrieval; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3347029",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3160228533",
      "doi": "10.1109/tbiom.2021.3115465",
      "title": "Biometrics: Trust, But Verify",
      "abstract": "Over the past two decades, biometric recognition has exploded into a plethora of different applications around the globe. This proliferation can be attributed to the high levels of authentication accuracy and user convenience that biometric recognition systems afford end-users. However, in-spite of the success of biometric recognition systems, there are a number of outstanding problems and concerns pertaining to the various sub-modules of biometric recognition systems that create an element of mistrust in their use - both by the scientific community and also the public at large. Some of these problems include: i) questions related to system recognition performance, ii) security (spoof attacks, adversarial attacks, template reconstruction attacks and demographic information leakage), iii) uncertainty over the bias and fairness of the systems to all users, iv) explainability of the seemingly black-box decisions made by most recognition systems, and v) concerns over data centralization and user privacy. In this paper, we provide an overview of each of the aforementioned open-ended challenges. We survey work that has been conducted to address each of these concerns and highlight the issues requiring further attention. Finally, we provide insights into how the biometric community can address core biometric recognition systems design issues to better instill trust, fairness, and security for all.",
      "year": "2021",
      "journal": "IEEE Transactions on Biometrics Behavior and Identity Science",
      "authors": "Anil K. Jain et al.",
      "keywords": "Biometrics; Adversarial system; Computer security; Computer science; Globe; Internet privacy; Authentication (law); Data science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tbiom.2021.3115465",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4384284051",
      "doi": "10.1109/access.2023.3295780",
      "title": "Industry 4.0 Adoption in Food Supply Chain to Improve Visibility and Operational Efficiency\u2014A Content Analysis",
      "abstract": "Food can become unsafe or contaminated at any point from farm to fork. Customers and stakeholders are concerned about food safety and prompt delivery. Hence, there is a need for a visible food supply chain (FSC) which can be accomplished through innovative technologies. However, these technologies are expensive and take a long time to implement. Hence, operational efficiency, which takes into account cost, time, and waste, has become a priority for the parties involved in the FSC. This study aims to conduct a content analysis-based literature review to understand the impact of Industry 4.0 technologies in FSC in terms of visibility and operational efficiency. It is found that Blockchain, Internet of Things, and Radio Frequency Identification are considered to have great potential in the FSC. Although the FSC can tremendously benefit from other technologies, such as artificial intelligence, edge computing, and robots, they are not currently deployed in a practical or efficient way. This study also discovers how supply chain organisations can implement a technology cost-sharing system. Our study includes 16 emerging Industry 4.0 technologies and shows their impact on the FSC, as well as cost-sharing mechanisms. The findings of this work assist firms in technology cost sharing and selecting the right technologies for their supply chain. Finally, a conceptual framework is proposed to show how future work can be done to improve visibility and operational efficiency in the FSC using Industry 4.0 technologies.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Vasanthraj Vasanthraj et al.",
      "keywords": "Supply chain; Visibility; Computer science; Operational efficiency; Risk analysis (engineering); Emerging technologies; Industry 4.0; Work (physics); Business; Marketing; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3295780",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394711309",
      "doi": "10.1109/access.2024.3387730",
      "title": "Weaving Agility in Safety-Critical Software Development for Aerospace: From Concerns to Opportunities",
      "abstract": "Domain-specific standards and documents heavily regulate safety-critical systems. One example is the DO-178C standard for aerospace, which guides organizations to achieve system safety and evidence for their certification. Under such regulated contexts, most organizations use traditional development processes, in contrast to the massive adoption of Agile in the software industry. Among other benefits, Agile methods promise faster delivery and better flexibility to address customer needs. Adopting Agile methods and practices are possible in aerospace because the DO-178C standard does not prescribe concrete software development methods. In spite of that, Agile development is not used in DO-178C contexts. To help change that, our research aims to understand whether and how organizations engineering safety-critical software systems for aerospace may benefit from Agile methods and practices. We analyzed the DO-178C standard and confirm that it is compatible with Agile methods. Then, we present a systematic literature mapping of adopting Agile in software development for aerospace, where we identified significant concerns, recurrent issues, and several challenges. Some real industry aerospace projects provided us with important data and the perspective of domain experts about the pros and cons of Agile methods in this context. We conclude by proposing an agenda of research opportunities to improve safety-critical software development towards agility that we consider worthy of further research, application and confirmation in wider contexts.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "J. Eduardo Ferreira Ribeiro et al.",
      "keywords": "Weaving; Aerospace; Computer science; Software; Software development; Software development process; Software engineering; Avionics software; Life-critical system; Systems engineering; Engineering; Operating system; Aerospace engineering; Mechanical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3387730",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392902310",
      "doi": "10.1109/access.2024.3378735",
      "title": "Harnessing ICT-Enabled Warfare: A Comprehensive Review on South Korea\u2019s Military Meta Power",
      "abstract": "Major countries around the world are leveraging information and communications technology (ICT), such as artificial intelligence, big data, cloud computing and cybersecurity, to strengthen their militaries. These technological advancements are driving the changes in weapon systems, strategies, and tactics. In 2021, the South Korean Ministry of National Defense introduced the concept of &#x201C;military meta power&#x201D; to describe the power generated in the cognitive military domain utilizing ICT. This concept is significant in that it differentiates between cognitive and physical military power, emphasizing the importance of the cognition-based power in future warfare. Additionally, the concept consolidates various cognitive military capabilities, including AI capability, cyber capability, space capability, and C4ISR (Command, Control, Communications, Computers, Intelligence, Surveillance, and Reconnaissance), into a unified ICT-generated power. This study aims to contribute to the literature on &#x201C;military meta power&#x201D; by providing a comprehensive overview of its characteristics, composition, and attributes. To achieve this objective, the research begins with an exploration of the philosophical insights on technology related to ICT, followed by a comprehensive review of the perspectives of existing academic papers. Finally, this study provides an in-depth analysis of various military strategies.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Sang Jin Oh et al.",
      "keywords": "Information and Communications Technology; Power (physics); Electronic warfare; Computer science; Computer security; Telecommunications; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3378735",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4318586195",
      "doi": "10.1109/access.2023.3240775",
      "title": "Designing a 6G Testbed for Location: Use Cases, Challenges, Enablers and Requirements",
      "abstract": "Location will have a central role in Research and Development (R&#x0026;D) towards 6G networks, both as a service offered by the network (improving the current offering of 5G) and as an input to increasingly location-aware services and network functions. To integrate location into 6G standards, it will be very important to design validation systems such as testbeds, even when the actual technology is not yet commercially available. This paper performs a review of the use cases and their requirements, enabling technologies in 6G, and challenges; and proposes a flexible testbed architecture for performing network location related R&#x0026;D. This architecture will allow to deploy an evolving infrastructure which will allow early validation of 6G technologies.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Emil J. Khatib et al.",
      "keywords": "Testbed; Computer science; Architecture; Network architecture; Service (business); Systems engineering; Computer network; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3240775",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4379377703",
      "doi": "10.1109/access.2023.3282617",
      "title": "Identifying Factors That Impact Levels of Automation in Autonomous Systems",
      "abstract": "The need to support complex human and machine collaboration has increased because of recent advances in the use of software and artificial intelligence approaches across various application domains. Building applications with more autonomy has grown dramatically as modern system development capability has significantly improved. However, understanding how to assign duties between humans and machines still needs improvement, and there is a need for better approaches to apportion these tasks. Current methods do not make adaptive automation easy, as task assignments during system operation need to take knowledge about the optimal level of automation (LOA) into account during the collaboration. There is currently a lack of explicit knowledge regarding the factors that influence the variability of human-system interaction and the correct LOA. Additionally, models have not been provided to represent the adaptive LOA variation based on these parameters and their interactions and interdependencies. The study, presented in this paper, based on an extensive literature review, identifies and classifies the factors that affect the degree of automation in autonomous systems. It also proposes a model based on feature diagrams representing the factors and their relationships with LOAs. With the support of two illustrative examples, we demonstrate how to apply these factors and how they relate to one another. This work advances research in the design of autonomous systems by offering an adaptive automation approach that can suggest levels of automation to facilitate human-computer interactions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Glaucia Melo et al.",
      "keywords": "Automation; Computer science; Interdependence; Task (project management); Risk analysis (engineering); Data science; Artificial intelligence; Software engineering; Machine learning; Systems engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3282617",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4395471149",
      "doi": "10.1109/access.2024.3393610",
      "title": "Review of Digital Transformation in the Energy Sector: Assessing Maturity and Adoption Levels of Digital Services and Products via Fuzzy Logic",
      "abstract": "&lt;p&gt;Digitalization has begun as a transformative force within the energy sector, reforming traditional practices and paving the way for enhanced operational efficiency and sustainability. Enabled by key technologies such as smart meters, digitalization embodies a paradigm shift in energy management. Nonetheless, it is crucial to recognize that these enabling technologies are only the catalysts and not the end goal. This paper presents a comprehensive overviewof digital services and products in the energy sector, with a specific focus on emerging technologies like AI and Connected Data Spaces. The objective of this review paper is to assess the maturity and adoption levels of these digital solutions, seeking to draw insights into the factors influencing their varying levels of success. This maturity and adoption assessment was carried out by applying a Fuzzy logic approach which allowed us to compensate for the lack of detailed information in current literature. By analyzing the reasons behind high maturity-low adoption and vice-versa, this study seeks to cast light on the dynamics shaping the digital transformation of the energy sector.&lt;/p&gt;",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Salvador Carvalhosa et al.",
      "keywords": "Maturity (psychological); Transformative learning; Digital transformation; Computer science; Sustainability; Fuzzy logic; Capability Maturity Model; Efficient energy use; Process management; Knowledge management; Risk analysis (engineering); Business; Engineering; Artificial intelligence; World Wide Web; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3393610",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4377007281",
      "doi": "10.1109/access.2023.3276761",
      "title": "Synthesis of Tax Return Datasets for Development of Tax Evasion Detection",
      "abstract": "Datasets are an essential part of data science processes. However, retrieving a dataset, especially a tax return dataset, is challenging as privacy becomes more evident in our daily lives. Thus, data synthesis is an approach selected for our work by utilizing publicly available data and augmenting it using Generative Adversarial Network (GAN) and Synthetic Minority Oversampling TEchnique (SMOTE). The evaluation is performed using a Correlation Matrix, Principal Component Analysis (PCA), and Quality Score. In addition, fundamental machine learning models are utilized to detect tax evasion based on a literature review. The data are gathered from the financial statements of companies registered within the Stock Exchange of Thailand (SET). Our results indicate that synthetic datasets with 0.87 average Quality Score can train models that yield approximately 0.95 Accuracy and 0.91 F1-Score. Additionally, by increasing more instances, the effect of class imbalance and high variance can be mitigated. The expected benefits include the use of open data for analysis and application of synthetic datasets. Forthcoming research could consider the statistical behavior of different business sectors, multiclass labeling for advanced recommendations, and implementation of unsupervised models.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Narongchai Visitpanya et al.",
      "keywords": "Computer science; Oversampling; Principal component analysis; Machine learning; Data mining; Artificial intelligence; Data set",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3276761",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392667189",
      "doi": "10.1109/access.2024.3376239",
      "title": "MOTEF: A Testing Framework for Runtime Monitoring Infrastructures",
      "abstract": "Intelligent monitoring systems can effectively predict or detect anomalies and issues in smart working systems and ecosystems and implement the proper countermeasures. However, for their effective and efficient use, attributes like responsiveness, performance, and quality should be properly tested and assessed before integrating the monitoring system into an ecosystem. The work aims to present a framework, called MOnitoring TEsting Framework (MOTEF), focused on the testing and evaluation of a generic monitoring system performance. In particular, the framework allows testing the monitoring system in isolation or when used in a smart environment to provide functional or non-functional property predictions. By simulating the runtime execution of a smart environment, MOTEF lets testing and assessment of a generic monitoring system establish its working boundaries. The results collected can be used to design a smart environment architecture to fulfil its global performance constraints better. This work presents the architecture of MOTEF and its preliminary implementation. It also validated and showcased the use of MOTEF in evaluating the performance of an existing monitoring system in isolation and when it is used in a smart environment. The results have been assessed by considering two research questions about the monitoring system&#x2019;s responsiveness and effectiveness in proving required functional or non-functional property predictions.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Antonello Calabr\u00f2 et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3376239",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391936074",
      "doi": "10.1109/access.2024.3367600",
      "title": "CITE-PSO: Cross-ISP Traffic Engineering Enhanced by Particle Swarm Optimization in Blockchain Enabled SDONs",
      "abstract": "The immense potential of optical networks provides a highly favorable option for addressing rapidly increasing bandwidth needs. Elastic Optical Networks (EONs) exhibit considerable potential in enhancing availability, failure resilience, load balancing, and efficient resource allocations, rendering them a viable option for forthcoming high-speed networks. The integration of Software-Defined Networking (SDN) architecture with EONs, which separates the data and control planes, results in a dynamic and cooperative combination known as Software-Defined Optical Networking (SDON). However, the effective allocation of spectrum poses operational difficulties in this context. The proposed study introduces a framework called Cross-ISP (Internet Service Provider) Traffic Engineering enhanced by Particle Swarm Optimization (CITE-PSO) that is designed to facilitate Quality of Service (QoS)-focused cross-ISP spectrum assignment in SDONs through the integration of blockchain technology. The proposed framework aims to eliminate the need for centralized mediators while ensuring effective coordination of inter-ISP traffic based on QoS considerations. The research presents a novel application of blockchain technology that increases network efficiency and minimizes QoS signaling overhead during inter-ISP routing in SDONs. The proposed framework is evaluated under Hop-by-Hop Wavelength Switching (HWS) and Border-Node-Only Wavelength Switching (BWS) to assess its performance. The simulation results demonstrate that the CITE-PSO framework is proficient in managing the inter-ISP routing with QoS capabilities in the SDON architecture. This proficiency is measured by the various metrics across HWS and BWS scenarios.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Evrim G\u00fcler",
      "keywords": "Computer science; Quality of service; Particle swarm optimization; Software-defined networking; Computer network; Distributed computing; The Internet; Overhead (engineering); Node (physics); Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3367600",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388192201",
      "doi": "10.1109/tts.2023.3318396",
      "title": "Publishing for Impact: Interdisciplinary Reflections",
      "abstract": "The term research impact is variously defined in academic scholarship, by national and international research funding bodies, publishers, and other relevant entities, although common definitional elements exist. Concise definitions describe the term as relating to academic research that directly and or indirectly guides policymaking processes, by enabling evidence-based decision-making and or improving understanding of a given subject area or areas <xref ref-type=\"bibr\" rid=\"ref1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[1]</xref> . Underlying this and all definitions of research impact is the fundamental assumption that the outcome(s) of university research will serve the \u201cpublic good\u201d <xref ref-type=\"bibr\" rid=\"ref2\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[2, p. 1368]</xref> .",
      "year": "2023",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Roba Abbas et al.",
      "keywords": "Scholarship; Library science; Term (time); Publishing; Political science; Subject (documents); Computer science; Law; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2023.3318396",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4285262743",
      "doi": "10.1109/ojies.2022.3174218",
      "title": "A Cross-Disciplinary Outlook of Directions and Challenges in Industrial Electronics",
      "abstract": "[EN] How to build a sustainable society in view of industrial electronics has been discussed from energy, information and communication technologies, cyber-physical systems (CPSs), and other viewpoints. This paper presents a cross-disciplinary view that integrates the fields of human factors, professional education, electronic systems on chip, resilience and security for industrial applications, technology ethics and society, and standards. After explaining the efforts and challenges in these fields, this paper shows a methodology for cross-disciplinary technology that integrates the technical committees in Cluster 4, Industrial Electronics Society. A project, which was launched in March 2022, implements a 'Proof of Concept' trial of the methodology.",
      "year": "2022",
      "journal": "IEEE Open Journal of the Industrial Electronics Society",
      "authors": "Jinhua She et al.",
      "keywords": "Viewpoints; Electronics; Discipline; Resilience (materials science); Cross disciplinary; Engineering; Engineering management; Systems engineering; Cyber-physical system; Engineering ethics; Computer science; Sociology; Data science; Electrical engineering; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojies.2022.3174218",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4237610329",
      "doi": "10.1109/jsyst.2021.3054547",
      "title": "2020 Index IEEE Systems Journal Vol. 14",
      "abstract": "",
      "year": "2020",
      "journal": "IEEE Systems Journal",
      "authors": "See Khasawneh et al.",
      "keywords": "Index (typography); Computer science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsyst.2021.3054547",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3125584267",
      "doi": "10.1109/access.2021.3053763",
      "title": "Prediction of Chronic Kidney Disease - A Machine Learning Perspective",
      "abstract": "Chronic Kidney Disease is one of the most critical illness nowadays and proper diagnosis is required as soon as possible. Machine learning technique has become reliable for medical treatment. With the help of a machine learning classifier algorithms, the doctor can detect the disease on time. For this perspective, Chronic Kidney Disease prediction has been discussed in this article. Chronic Kidney Disease dataset has been taken from the UCI repository. Seven classifier algorithms have been applied in this research such as artificial neural network, C5.0, Chi-square Automatic interaction detector, logistic regression, linear support vector machine with penalty L1 &amp; with penalty L2 and random tree. The important feature selection technique was also applied to the dataset. For each classifier, the results have been computed based on (i) full features, (ii) correlation-based feature selection, (iii) Wrapper method feature selection, (iv) Least absolute shrinkage and selection operator regression, (v) synthetic minority over-sampling technique with least absolute shrinkage and selection operator regression selected features, (vi) synthetic minority over-sampling technique with full features. From the results, it is marked that LSVM with penalty L2 is giving the highest accuracy of 98.86% in synthetic minority over-sampling technique with full features. Along with accuracy, precision, recall, F-measure, area under the curve and GINI coefficient have been computed and compared results of various algorithms have been shown in the graph. Least absolute shrinkage and selection operator regression selected features with synthetic minority over-sampling technique gave the best after synthetic minority over-sampling technique with full features. In the synthetic minority over-sampling technique with least absolute shrinkage and selection operator selected features, again linear support vector machine gave the highest accuracy of 98.46%. Along with machine learning models one deep neural network has been applied on the same dataset and it has been noted that deep neural network achieved the highest accuracy of 99.6%.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Pankaj Chittora et al.",
      "keywords": "Feature selection; Artificial intelligence; Support vector machine; Computer science; Classifier (UML); Pattern recognition (psychology); Machine learning; Regression; Random forest; Logistic regression; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3053763",
      "cited_by_count": 305,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3184114351",
      "doi": "10.1109/access.2021.3098691",
      "title": "Machine Learning Tools for Long-Term Type 2 Diabetes Risk Prediction",
      "abstract": "A steady rise has been observed in the percentage of elderly people who want and are still able to contribute to society. Therefore, early retirement or exit from the labour market, due to health-related issues, poses a significant problem. Nowadays, thanks to technological advances and various data from different populations, the risk factors investigation and health issues screening are moving towards automation. In the context of this work, a worker-centric, IoT enabled unobtrusive users health, well-being and functional ability monitoring framework, empowered with AI tools, is proposed. Diabetes is a high-prevalence chronic condition with harmful consequences for the quality of life and high mortality rate for people worldwide, in both developed and developing countries. Hence, its severe impact on humans&#x2019; life, e.g., personal, social, working, can be considerably reduced if early detection is possible, but most research works in this field fail to provide a more personalized approach both in the modeling and prediction process. In this direction, our designed system concerns diabetes risk prediction in which specific components of the Knowledge Discovery in Database (KDD) process are applied, evaluated and incorporated. Specifically, dataset creation, features selection and classification, using different Supervised Machine Learning (ML) models are considered. The ensemble WeightedVotingLRRFs ML model is proposed to improve the prediction of diabetes, scoring an Area Under the ROC Curve (AUC) of 0.884. Concerning the weighted voting, the optimal weights are estimated by their corresponding Sensitivity and AUC of the ML model based on a bi-objective genetic algorithm. Also, a comparative study is presented among the Finnish Diabetes Risk Score (FINDRISC) and Leicester risk score systems and several ML models, using inductive and transductive learning. The experiments were conducted using data extracted from the English Longitudinal Study of Ageing (ELSA) database.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Nikos Fazakis et al.",
      "keywords": "Computer science; Machine learning; Context (archaeology); Artificial intelligence; Field (mathematics); Process (computing); Data mining; Risk analysis (engineering); Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3098691",
      "cited_by_count": 137,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3129822799",
      "doi": "10.1109/access.2021.3059658",
      "title": "Volumetric Feature-Based Alzheimer\u2019s Disease Diagnosis From sMRI Data Using a Convolutional Neural Network and a Deep Neural Network",
      "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder that is mostly prevalent in people older than 65 years. The hippocampus is a widely studied region of interest (ROI) for a number of reasons, such as memory function analysis, stress development observation and neurological disorder investigation. Moreover, hippocampal volume atrophy is known to be linked with Alzheimer's disease. On the other hand, several biomarkers, such as amyloid beta (a&#x00DF;<sub>42</sub>) protein, tau, phosphorylated tau and hippocampal volume atrophy, are being used to diagnose AD. In this research work, we have proposed a method to diagnose AD based on slice-wise volumetric features extracted from the left and right hippocampi of structural magnetic resonance imaging (sMRI) data. The proposed method is an aggregation of a convolutional neural network (CNN) model with a deep neural network (DNN) model. The left and right hippocampi have been localized automatically using a two-stage ensemble Hough-CNN. The localized hippocampal positions are used to extract (80 &#x00D7; 80x80 voxels) 3-D patches. The 2-D slices are then separated from the 3-D patches along axial, sagittal, and coronal views. The pre-processed 2-D patches are used to extract volumetric features from each slice by using a discrete volume estimation convolutional neural network (DVE-CNN) model. The extracted volumetric features have been used to train and test the classification network. The proposed approach has achieved average weighted classification accuracies of 94.82% and 94.02% based on the extracted volumetric features attributed to the left and right hippocampi, respectively. In addition, it has achieved area under the curve (AUC) values of 92.54% and 90.62% for the left and right hippocampi, respectively. Our method has outperformed the other methods by a certain margin in the same dataset.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Abol Basher et al.",
      "keywords": "Convolutional neural network; Computer science; Artificial intelligence; Feature (linguistics); Artificial neural network; Deep learning; Feature extraction; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3059658",
      "cited_by_count": 108,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3109221663",
      "doi": "10.1109/access.2020.3039439",
      "title": "Identifying Stroke Indicators Using Rough Sets",
      "abstract": "Stroke is widely considered as the second most common cause of mortality. The adverse consequences of stroke have led to global interest and work for improving the management and diagnosis of stroke. Various techniques for data mining have been used globally for accurate prediction of occurrence of stroke based on the risk factors that are associated with the electronic health care records (EHRs) of the patients. In particular, EHRs routinely contain several thousands of features and most of them are redundant and irrelevant that need to be discarded to enhance the prediction accuracy. The choice of feature-selection methods can help in improving the prediction accuracy of the model and efficient data management of the archived input features. In this paper, we systematically analyze the various features in EHR records for the detection of stroke. We propose a novel rough-set based technique for ranking the importance of the various EHR records in detecting stroke. Unlike the conventional rough-set techniques, our proposed technique can be applied on any dataset that comprises binary feature sets. stroke. We evaluated our proposed method in a publicly available dataset of EHR, and concluded that age, average glucose level, heart disease, and hypertension were the most essential attributes for detecting stroke in patients. Furthermore, we benchmarked the proposed technique with other popular feature-selection techniques. We obtained the best performance in ranking the importance of individual features in detecting stroke.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Muhammad Salman Pathan et al.",
      "keywords": "Computer science; Feature selection; Ranking (information retrieval); Stroke (engine); Artificial intelligence; Data mining; Feature (linguistics); Rough set; Set (abstract data type); Machine learning; Data set",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3039439",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4220778535",
      "doi": "10.1109/tts.2022.3156405",
      "title": "Biometrics and AI Bias",
      "abstract": "While humans share many physical characteristics, they are not replicas of one another in appearance. Despite their uniqueness, common features mean that comparisons can be made. The ability to identify someone by face has been one of the most fundamental ways that humans have connected with each other as distinct persons <xref ref-type=\"bibr\" rid=\"ref1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[1]</xref> . Recognizing someone is in fact a form of human visual information processing <xref ref-type=\"bibr\" rid=\"ref2\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[2]</xref> . Long before mirrors were available in the ancient world (circa 5th century BCE the Greeks used hand mirrors for grooming <xref ref-type=\"bibr\" rid=\"ref3\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[3]</xref> ), descriptions of one\u2019s face were always determined by another\u2019s gaze or at best one\u2019s own description of their reflection in clean water illuminated by sunlight. Some even gained nicknames through the identification of distinct features on their forehead, nose, eyes, eyebrows, ears, and cheeks, for example, or through some clear markings, such as freckles or a birthmark. These were all the usual ways of remembering individuals; not as a means of discrimination but simply for the purposes of identification. In villages that did not exceed 250 households, it was possible to know of, and remember everyone <xref ref-type=\"bibr\" rid=\"ref4\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[4]</xref> , especially given that relations possessed similar and familial features.",
      "year": "2022",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Katina Michael et al.",
      "keywords": "Identification (biology); Greeks; Face (sociological concept); Uniqueness; Artificial intelligence; Type (biology); Computer science; Mathematics; Computer vision; Art; Philosophy; Linguistics; Mathematical analysis; Geology; Biology; Classics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2022.3156405",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4296910322",
      "doi": "10.1109/access.2022.3208587",
      "title": "The Role of Intelligent Technologies in Early Detection of Autism Spectrum Disorder (ASD): A Scoping Review",
      "abstract": "Background: Two-year delay is reported between the first developmental concern raised by the parents and the diagnosis of ASD (Autism Spectrum Disorder), delaying the start of early intervention programs most beneficial within the first three years. Aim: Evaluate the role of technology in ASD detection by answering four research questions analyzing 1) evolution of technology, 2) use of various bio-behavioral data sources, 3) demographic categories, databases, controls, comparators, and assessment instruments, and 4) data collection, processing, and outcomes of the technology-based methods in ASD detection. Methods: Scoping review included behavioral-based ASD screening and diagnostic studies, published between 1st January 2011 to 31st December 2021 in PUBMED, SCOPUS, and IEEE Xplore databases for children under six years. The studies were evaluated using the Critical Appraisal Skills Programm (CASP) and the PRISMA scoping review checklist (PRISMA-ScR). Results: The shortlisted 35 studies were categorized into seven bio-behavioral categories. The review highlighted the extensive use of machine learning (ML) and Deep Learning (DL) to detect infants (as young as 9 to 12 months) at risk of ASD and Other developmental delays (ODD) using multimodal structured and unstructured data. However, the review reported various internal and external validity threats. Conclusion: Technology can significantly improve the current ASD detection process. The validation and adoption of technology can be fast-tracked by 1) designing robust study protocols, 2) executing multi-cultural field trials, 3) standardizing datasets, data quality, and feature engineering methods, 4) recruiting statistically significant participants from ASD, typically developing (TD) and other developmental disorders (ODD) groups to ensure technological generalization, validation, and adoption outside laboratory settings.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Manu Kohli et al.",
      "keywords": "Autism spectrum disorder; Checklist; Autism; Computer science; Systematic review; Psychology; Artificial intelligence; Data science; Applied psychology; MEDLINE; Developmental psychology; Cognitive psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3208587",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3201313642",
      "doi": "10.1109/access.2021.3113464",
      "title": "Facial Expression Recognition: A Review of Trends and Techniques",
      "abstract": "Facial Expression Recognition (FER) is presently the aspect of cognitive and affective computing with the most attention and popularity, aided by its vast application areas. Several studies have been conducted on FER, and many review works are also available. The existing FER review works only give an account of FER models capable of predicting the basic expressions. None of the works considers intensity estimation of an emotion; neither do they include studies that address data annotation inconsistencies and correlation among labels in their works. This work first introduces some identified FER application areas and provides a discussion on recognised FER challenges. We proceed to provide a comprehensive FER review in three different machine learning problem definitions: Single Label Learning (SLL)- which presents FER as a multiclass problem, Multilabel Learning (MLL)- that resolves the ambiguity nature of FER, and Label Distribution Learning- that recovers the distribution of emotion in FER data annotation. We also include studies on expression intensity estimation from the face. Furthermore, popularly employed FER models are thoroughly and carefully discussed in handcrafted, conventional machine learning and deep learning models. We finally itemise some recognise unresolved issues and also suggest future research areas in the field.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Olufisayo Ekundayo et al.",
      "keywords": "Computer science; Ambiguity; Annotation; Artificial intelligence; Field (mathematics); Machine learning; Popularity; Facial expression; Face (sociological concept); Expression (computer science); Deep learning; Facial expression recognition; Pattern recognition (psychology); Facial recognition system; Mathematics; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3113464",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388240319",
      "doi": "10.1109/access.2023.3329347",
      "title": "Safeguarding Online Spaces: A Powerful Fusion of Federated Learning, Word Embeddings, and Emotional Features for Cyberbullying Detection",
      "abstract": "Cyberbullying has emerged as a pervasive issue in the digital age, necessitating advanced techniques for effective detection and mitigation. This research explores the integration of word embeddings, emotional features, and federated learning to address the challenges of centralized data processing and user privacy concerns prevalent in previous methods. Word embeddings capture semantic relationships and contextual information, enabling a more nuanced understanding of text data, while emotional features derived from text extend the analysis to encompass the affective dimension, enhancing cyberbullying identification. Federated learning, a decentralized learning paradigm, offers a compelling solution to centralizing sensitive user data by enabling collaborative model training across distributed devices, preserving privacy while harnessing collective intelligence. In this study, we conduct an in-depth investigation into the fusion of word embeddings, emotional features, and federated learning, complemented by the utilization of BERT, Convolutional Neural Networks (CNN), Deep Neural Networks (DNN), and Long Short-Term Memory (LSTM) models. Hyperparameters and neural architecture are explored to find optimal configurations, leading to the generation of superior results. These techniques are applied in the context of cyberbullying detection, using publicly available multi-platform (social media) cyberbullying datasets. Through extensive experiments and evaluations, our proposed framework demonstrates superior performance and robustness compared to traditional methods. The results illustrate the enhanced ability to identify and combat cyberbullying incidents effectively, contributing to the creation of safer online environments. Particularly, the BERT model consistently outperforms other deep learning models (CNN, DNN, LSTM) in cyberbullying detection while preserving the privacy of local datasets for each social platform through our improved federated learning setup. We have provided Differential Privacy based security analysis for the proposed method to further strengthen the privacy and robustness of the system. By leveraging word embeddings, emotional features, and federated learning, this research opens new avenues in cyberbullying research, paving the way for proactive intervention and support mechanisms. The comprehensive approach presented herein highlights the substantial strengths and advantages of this integrated methodology, setting a foundation for future advancements in cyberbullying detection and mitigation.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nagwan Abdel Samee et al.",
      "keywords": "Safeguarding; Computer science; Word (group theory); Internet privacy; Artificial intelligence; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3329347",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3194821224",
      "doi": "10.23919/jsc.2021.0009",
      "title": "Hybrid Predictive Ensembles: Synergies Between Human and Computational Forecasts",
      "abstract": "An increasing proportion of decisions, design choices, and predictions are being made by hybrid groups consisting of humans and artificial intelligence (AI). In this paper, we provide analytic foundations that explain the potential benefits of hybrid groups on predictive tasks, the primary use of AI. Our analysis relies on interpretive and generative signal frameworks as well as a distinction between the big data used by AI and the thick, often narrative data used by humans. We derive several conditions on accuracy and correlation necessary for humans to remain in the loop. We conclude that human adaptability along with the potential for atypical cases that mislead AI will likely mean that humans always add value on predictive tasks.",
      "year": "2021",
      "journal": "Journal of Social Computing",
      "authors": "Lu Hong et al.",
      "keywords": "Adaptability; Artificial intelligence; Predictive value; Machine learning; Computer science; Generative grammar; Value (mathematics); Biology; Ecology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2021.0009",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312931084",
      "doi": "10.1109/access.2022.3220670",
      "title": "Toward Automated Feature Extraction for Deep Learning Classification of Electrocardiogram Signals",
      "abstract": "Many recent studies have focused on the automatic classification of electrocardiogram (ECG) signals using deep learning (DL) methods. Most rely on existing complex DL methods, such as transfer learning or providing the models with carefully designed extracted features based on domain knowledge. A common assumption is that the deeper and more complex the DL model is, the better it learns. In this study, we propose two different DL models for automatic feature extraction from ECG signals for classification tasks: A CNN-LSTM hybrid model and an attention/transformer-based model with wavelet transform for the dimensional embedding. Both of the models extract the features from time series at the initial layers of the neural networks and can obtain performance at least equal to, if not greater than, many contemporary deep neural networks. To validate our hypothesis, we used three publicly available data-sets to evaluate the proposed models. Our model achieved a benchmark accuracy of 99.92% for fall detection and 99.93% for the PTB database for myocardial infarction versus normal heartbeat classification.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Fatima Sajid Butt et al.",
      "keywords": "Feature extraction; Computer science; Artificial intelligence; Pattern recognition (psychology); Extraction (chemistry); Deep learning; Feature (linguistics); Speech recognition; Chemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3220670",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3162518928",
      "doi": "10.1109/access.2021.3080617",
      "title": "Reinforcing Synthetic Data for Meticulous Survival Prediction of Patients Suffering From Left Ventricular Systolic Dysfunction",
      "abstract": "Congestive heart failure is among leading genesis of concern that requires an immediate medical attention. Among various cardiac disorders, left ventricular systolic dysfunction is one of the well known cardiovascular disease which causes sudden congestive heart failure. The irregular functioning of a heart can be diagnosed through some of the clinical attributes, such as ejection fraction, serum creatinine etcetera. However, due to availability of a limited data related to the death events of patients suffering from left ventricular systolic dysfunction, a critical level of thresholds of clinical attributes cannot be estimated with higher precision. Hence, this paper proposes a novel pseudo reinforcement learning algorithm which overcomes a problem of majority class skewness in a limited dataset by appending a synthetic dataset across minority data space. The proposed pseudo agent in the algorithm continuously senses the state of the dataset (pseudo environment) and takes an appropriate action to populate the dataset resulting into higher reward. In addition, the paper also investigates the role of statistically significant clinical attributes such as age, ejection fraction, serum creatinine etc., which tends to efficiently predict the association of death events of the patients suffering from left ventricular systolic dysfunction.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mohammad Farhan Khan et al.",
      "keywords": "Ejection fraction; Heart failure; Cardiology; Internal medicine; Medicine; Sudden cardiac death; Creatinine; Algorithm; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3080617",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388739132",
      "doi": "10.1109/access.2023.3333946",
      "title": "Legal Natural Language Processing From 2015 to 2022: A Comprehensive Systematic Mapping Study of Advances and Applications",
      "abstract": "The surge in legal text production has amplified the workload for legal professionals, making many tasks repetitive and time-consuming. Furthermore, the complexity and specialized language of legal documents pose challenges not just for those in the legal domain but also for the general public. This emphasizes the potential role and impact of Legal Natural Language Processing (Legal NLP). Although advancements have been made in this domain, particularly after 2015 with the advent of Deep Learning and Large Language Models (LLMs), a systematic exploration of this progress until 2022 is nonexistent. In this research, we perform a Systematic Mapping Study (SMS) to bridge this gap.We aim to provide a descriptive statistical analysis of the Legal NLP research between 2015 and 2022. Categorize and sub-categorize primary publications based on their research problems. Identify limitations and areas of improvement in current research. Using a robust search methodology across four reputable indexers, we filtered 536 papers down to 75 pivotal articles. Our findings reveal the diverse methods employed for tasks such as Multiclass Classification, Summarization, and Question Answering in the Legal NLP field.We also highlight resources, challenges, and gaps in current methodologies and emphasize the need for curated datasets, ontologies, and a focus on inherent difficulties like data accessibility. As the legal sector gradually embraces Natural Language Processing (NLP), understanding the capabilities and limitations of Legal NLP becomes vital for ensuring efficient and ethical application. The research offers insights for both Legal NLP researchers and the broader legal community, advocating for continued advancements in automation while also addressing ethical concerns. Authors",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ernesto Quevedo et al.",
      "keywords": "Computer science; Automatic summarization; Artificial intelligence; Categorization; Data science; Legal case; Natural language processing; Question answering; Domain (mathematical analysis); Knowledge management; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3333946",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395096813",
      "doi": "10.1109/access.2024.3393243",
      "title": "Sensitive Quantification of Cerebellar Speech Abnormalities Using Deep Learning Models",
      "abstract": "Objective, sensitive, and meaningful disease assessments are critical to support clinical trials and clinical care. Speech changes are one of the earliest and most evident manifestations of cerebellar ataxias. This work aims to develop models that can accurately identify and quantify clinical signs of ataxic speech. We use convolutional neural networks to capture the motor speech phenotype of cerebellar ataxia based on time and frequency partial derivatives of log-mel spectrogram representations of speech. We train classification models to distinguish patients with ataxia from healthy controls as well as regression models to estimate disease severity. Classification models were able to accurately distinguish healthy controls from individuals with ataxia, including ataxia participants who clinicians rated as having no detectable clinical deficits in speech. Regression models produced accurate estimates of disease severity, were able to measure subclinical signs of ataxia, and captured disease progression over time. Convolutional networks trained on time and frequency partial derivatives of the speech signal can detect sub-clinical speech changes in ataxias and sensitively measure disease change over time. Learned speech analysis models have the potential to aid early detection of disease signs in ataxias and provide sensitive, low-burden assessment tools in support of clinical trials and neurological care.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Kyriakos Vattis et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Speech recognition; Natural language processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3393243",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2899937695",
      "doi": "10.1109/access.2018.2880224",
      "title": "Diagnosing Metabolic Syndrome Using Genetically Optimised Bayesian ARTMAP",
      "abstract": "Metabolic Syndrome (MetS) constitutes of metabolic abnormalities that lead to non-communicable diseases, such as type II diabetes, cardiovascular diseases, and cancer. Early and accurate diagnosis of this abnormality is required to prevent its further progression to these diseases. This paper aims to diagnose the risk of MetS using a new non-clinical approach called &#x201C;genetically optimized Bayesian adaptive resonance theory mapping&#x201D; (GOBAM). We evolve the Bayesian adaptive resonance theory mapping (BAM) by using genetic algorithm to optimize the parameters of BAM and its training input sequence. We use the GOBAM algorithm to classify individuals as either being at risk of MetS or not at risk of MetS with a related posterior probability, which ranges between 0 and 1. A data set of 11 237 Malaysians from the CLUSTer study stratified by age and gender into four subcategories was used to evaluate the proposed GOBAM algorithm. The comparative evaluation of our results suggested that the GOBAM performs significantly better than other classical adaptive resonance theory mapping models on the area under the receiver operating characteristic curves (AUC) and others criteria. Our algorithm gives an AUC of 86.42 &#x0025;, 87.04 &#x0025;, 91.08 &#x0025;, and 89.24 &#x0025; for the young female, middle aged female, young male, and middle-aged male subcategories, respectively. The proposed model can be used to support medical practitioners in accurate and early diagnosis of MetS.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Habeebah Adamu Kakudi et al.",
      "keywords": "Bayesian probability; Metabolic syndrome; Abnormality; Computer science; Posterior probability; Receiver operating characteristic; Bayes' theorem; Bayesian network; Medicine; Artificial intelligence; Diabetes mellitus; Machine learning; Endocrinology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2880224",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3022221178",
      "doi": "10.1109/access.2020.2992578",
      "title": "Intelligent Assessment of Percutaneous Coronary Intervention Based on GAN and LSTM Models",
      "abstract": "Coronary artery calcification affects the arteries that supply the heart with blood, and percutaneous coronary intervention (PCI) is a direct and effective surgery to alleviate this symptom. In this paper, we propose a framework to judge if a patient requires surgery, based on cardiac computerized tomography scans. We adopt generative adversarial network to segment the calcified areas from slices. This architecture provides an environment for the generator to perform joint learning from ground truth images and the high-resolution discriminator. We use images reconstructed using two types of filters to test our method. An F1 score of 96.1% and 85.0% was achieved for the soft and sharp filters. In addition, we explored different recurrent neural networks for making the final decision. Including long short-term memory, which was ultimately used to deal with the calcium score normalized by the age and score threshold. Using the soft reconstruction image as the input, the whole framework achieved an accuracy of 76.6%. These results certify that our method can precisely locate lesion in artery, and make a reasonable risk assessment for PCI.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Zizhuang Zou et al.",
      "keywords": "Conventional PCI; Percutaneous coronary intervention; Discriminator; Computer science; Artificial intelligence; Artery; Coronary arteries; Artificial neural network; Cardiology; Radiology; Medicine; Myocardial infarction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2992578",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295755966",
      "doi": "10.1109/jbhi.2022.3206100",
      "title": "Functional Data Analysis for Predicting Pediatric Failure to Complete Ten Brief Exercise Bouts",
      "abstract": "Physiological response to physical exercise through analysis of cardiopulmonary measurements has been shown to be predictive of a variety of diseases. Nonetheless, the clinical use of exercise testing remains limited because interpretation of test results requires experience and specialized training. Additionally, until this work no methods have identified which dynamic gas exchange or heart rate responses influence an individual's decision to start or stop physical activity. This research examines the use of advanced machine learning methods to predict completion of a test consisting of multiple exercise bouts by a group of healthy children and adolescents. All participants could complete the ten bouts at low or moderate-intensity work rates, however, when the bout work rates were high-intensity, 50% refused to begin the subsequent exercise bout before all ten bouts had been completed (task failure). We explored machine learning strategies to model the relationship between the physiological time series, the participant's anthropometric variables, and the binary outcome variable indicating whether the participant completed the test. The best performing model, a generalized spectral additive model with functional and scalar covariates, achieved 93.6% classification accuracy and an F1 score of 93.5%. Additionally, functional analysis of variance testing showed that participants in the 'failed' and 'success' groups have significantly different functional means in three signals: heart rate, oxygen uptake rate, and carbon dioxide uptake rate. Overall, these results show the capability of functional data analysis with generalized spectral additive models to identify key differences in the exercise-induced responses of participants in multiple bout exercise testing.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Nicholas Coronato et al.",
      "keywords": "Heart rate; Work rate; VO2 max; Physical therapy; Analysis of variance; Covariate; Physical medicine and rehabilitation; Anthropometry; Medicine; Machine learning; Computer science; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3206100",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2886588223",
      "doi": "10.1109/jbhi.2019.2918070",
      "title": "A Precision Environment-Wide Association Study of Hypertension via Supervised Cadre Models",
      "abstract": "We consider the problem in precision health of grouping people into subpopulations based on their degree of vulnerability to a risk factor. These subpopulations cannot be discovered with traditional clustering techniques because their quality is evaluated with a supervised metric: the ease of modeling a response variable over observations within them. Instead, we apply the supervised cadre model (SCM), which does use this metric. We extend the SCM formalism so that it may be applied to multivariate regression and binary classification problems. We also develop a way to use conditional entropy to assess the confidence in the process by which a subject is assigned their cadre. Using the SCM, we generalize the environment-wide association study (EWAS) workflow to be able to model heterogeneity in population risk. In our EWAS, we consider more than two hundred environmental exposure factors and find their association with diastolic blood pressure, systolic blood pressure, and hypertension. This requires adapting the SCM to be applicable to data generated by a complex survey design. After correcting for false positives, we found 25 exposure variables that had a significant association with at least one of our response variables. Eight of these were significant for a discovered subpopulation but not for the overall population. Some of these associations have been identified by previous researchers, while others appear to be novel. We examine several discovered subpopulations in detail, and we find that they are interpretable and that they suggest further research questions.",
      "year": "2019",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Alexander New et al.",
      "keywords": "False positive paradox; Multivariate statistics; Metric (unit); Population; Computer science; Logistic regression; Data mining; Statistics; Machine learning; Econometrics; Medicine; Mathematics; Environmental health; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/jbhi.2019.2918070",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2956281901",
      "doi": "10.1109/tvcg.2019.2934619",
      "title": "The What-If Tool: Interactive Probing of Machine Learning Models",
      "abstract": "A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.",
      "year": "2019",
      "journal": "IEEE Transactions on Visualization and Computer Graphics",
      "authors": "James Wexler et al.",
      "keywords": "Computer science; Key (lock); Visualization; Machine learning; Coding (social sciences); Measure (data warehouse); Data visualization; Human\u2013computer interaction; Data science; Range (aeronautics); Artificial intelligence; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tvcg.2019.2934619",
      "cited_by_count": 488,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285275086",
      "doi": "10.1109/access.2022.3184113",
      "title": "A Robust Approach for Brain Tumor Detection in Magnetic Resonance Images Using Finetuned EfficientNet",
      "abstract": "A brain tumor is a disorder caused by the growth of abnormal brain cells. The survival rate of a patient affected with a tumor is difficult to determine because they are infrequent and appear in various forms. These tumors can be identified through Magnetic Resonance (MRI) Images, which plays an essential role in determining the tumor site; however, manual detection is a time-consuming and challenging procedure that can cause some errors in results. The adoption of computer-assisted approaches is essential to help in overcoming these constraints. With the advancement of artificial intelligence, deep learning (DL) models are being used in medical imaging to diagnose brain tumors using MR images. In this study, a deep convolutional neural network (CNN) EfficientNet-B0 base model is fine-tuned with our proposed layers to efficiently classify and detect brain tumor images. The image enhancement techniques are used by applying various filters to enhance the quality of the images. Data augmentation methods are applied to increase the data samples for better training of our proposed model. The results show that the proposed fine-tuned state-of-the-art EfficientNet-B0 outperforms other CNN models by achieving the highest classification accuracy, precision, recall, and area under curve values surpassing other state-of-the-art models, with an overall accuracy of 98.87&#x0025; in terms of classification and detection. Other DL algorithms such as VGG16, InceptionV3, Xception, ResNet50, and InceptionResNetV2 are used for comparative analysis.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Hasnain Ali Shah et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Brain tumor; Deep learning; Magnetic resonance imaging; Recall rate; Recall; Medical imaging; Pattern recognition (psychology); Image (mathematics); Functional magnetic resonance imaging; Computer vision; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3184113",
      "cited_by_count": 294,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3189035319",
      "doi": "10.1109/access.2021.3102399",
      "title": "A Comparative Performance Analysis of Data Resampling Methods on Imbalance Medical Data",
      "abstract": "Medical datasets are usually imbalanced, where negative cases severely outnumber positive cases. Therefore, it is essential to deal with this data skew problem when training machine learning algorithms. This study uses two representative lung cancer datasets, PLCO and NLST, with imbalance ratios (the proportion of samples in the majority class to those in the minority class) of 24.7 and 25.0, respectively, to predict lung cancer incidence. This research uses the performance of 23 class imbalance methods (resampling and hybrid systems) with three classical classifiers (logistic regression, random forest, and LinearSVC) to identify the best imbalance techniques suitable for medical datasets. Resampling includes ten under-sampling methods (RUS, etc.), seven over-sampling methods (SMOTE, etc.), and two integrated sampling methods (SMOTEENN, SMOTE-Tomek). Hybrid systems include (Balanced Bagging, etc.). The results show that class imbalance learning can improve the classification ability of the model. Compared with other imbalanced techniques, under-sampling techniques have the highest standard deviation (SD), and over-sampling techniques have the lowest SD. Over-sampling is a stable method, and the AUC in the model is generally higher than in other ways. Using ROS, the random forest performs the best predictive ability and is more suitable for the lung cancer datasets used in this study. The code is available at <uri>https://mkhushi.github.io/</uri>",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Matloob Khushi et al.",
      "keywords": "Resampling; Computer science; Random forest; Artificial intelligence; Sampling (signal processing); Machine learning; Oversampling; Support vector machine; Data mining; Skew; Pattern recognition (psychology); Filter (signal processing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3102399",
      "cited_by_count": 297,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3049280464",
      "doi": "10.1109/access.2020.3016715",
      "title": "Prediction of Breast Cancer, Comparative Review of Machine Learning Techniques, and Their Analysis",
      "abstract": "Breast cancer is type of tumor that occurs in the tissues of the breast. It is most common type of cancer found in women around the world and it is among the leading causes of deaths in women. This article presents the comparative analysis of machine learning, deep learning and data mining techniques being used for the prediction of breast cancer. Many researchers have put their efforts on breast cancer diagnoses and prognoses, every technique has different accuracy rate and it varies for different situations, tools and datasets being used. Our main focus is to comparatively analyze different existing Machine Learning and Data Mining techniques in order to find out the most appropriate method that will support the large dataset with good accuracy of prediction. The main purpose of this review is to highlight all the previous studies of machine learning algorithms that are being used for breast cancer prediction and this article provides the all necessary information to the beginners who want to analyze the machine learning algorithms to gain the base of deep learning.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Noreen Fatima et al.",
      "keywords": "Machine learning; Computer science; Artificial intelligence; Breast cancer; Deep learning; Medical diagnosis; Focus (optics); Cancer; Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3016715",
      "cited_by_count": 243,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2971654674",
      "doi": "10.1109/access.2019.2939876",
      "title": "Cross-Domain Fault Diagnosis Using Knowledge Transfer Strategy: A Review",
      "abstract": "Data-driven fault diagnosis has been a hot topic in recent years with the development of machine learning techniques. However, the prerequisite that the training data and the test data should follow an identical distribution prevents the conventional data-driven diagnosis methods from being applied to the engineering diagnosis problems. To tackle this dilemma, cross-domain fault diagnosis using knowledge transfer strategy is becoming popular in the past five years. The diagnosis methods based on transfer learning aim to build models that can perform well on target tasks by leveraging knowledge from semantic related but distribution different source domains. This paper for the first time summarizes the state-of-art cross-domain fault diagnosis research works. The literatures are introduced from three different viewpoints: research motivations, cross-domain strategies, and application objects. In addition, the corresponding open-source fault datasets and several future directions are also presented. The survey provides readers a framework for better understanding and identifying the research status, challenges and future directions of cross-domain fault diagnosis.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Huailiang Zheng et al.",
      "keywords": "Computer science; Viewpoints; Fault (geology); Domain (mathematical analysis); Transfer of learning; Artificial intelligence; Knowledge transfer; Domain knowledge; Machine learning; Data science; Data mining; Knowledge management",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2019.2939876",
      "cited_by_count": 197,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3041090558",
      "doi": "10.1109/tbcas.2020.3036081",
      "title": "Hardware Implementation of Deep Network Accelerators Towards Healthcare and Biomedical Applications",
      "abstract": "The advent of dedicated Deep Learning (DL) accelerators and neuromorphic processors has brought on new opportunities for applying both Deep and Spiking Neural Network (SNN) algorithms to healthcare and biomedical applications at the edge. This can facilitate the advancement of medical Internet of Things (IoT) systems and Point of Care (PoC) devices. In this paper, we provide a tutorial describing how various technologies including emerging memristive devices, Field Programmable Gate Arrays (FPGAs), and Complementary Metal Oxide Semiconductor (CMOS) can be used to develop efficient DL accelerators to solve a wide variety of diagnostic, pattern recognition, and signal processing problems in healthcare. Furthermore, we explore how spiking neuromorphic processors can complement their DL counterparts for processing biomedical signals. The tutorial is augmented with case studies of the vast literature on neural network and neuromorphic hardware as applied to the healthcare domain. We benchmark various hardware platforms by performing a sensor fusion signal processing task combining electromyography (EMG) signals with computer vision. Comparisons are made between dedicated neuromorphic processors and embedded AI accelerators in terms of inference latency and energy. Finally, we provide our analysis of the field and share a perspective on the advantages, disadvantages, challenges, and opportunities that various accelerators and neuromorphic processors introduce to healthcare and biomedical domains.",
      "year": "2020",
      "journal": "IEEE Transactions on Biomedical Circuits and Systems",
      "authors": "Mostafa Rahimi Azghadi et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbcas.2020.3036081",
      "cited_by_count": 188,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206553819",
      "doi": "10.1109/access.2022.3140815",
      "title": "Rice-Fusion: A Multimodality Data Fusion Framework for Rice Disease Diagnosis",
      "abstract": "Rice leaf infections are a common hazard to rice production, affecting many farmers all over the world. Early detection and treatment of rice leaf infection are critical for promoting healthy rice plant growth and ensuring adequate supply for the fast-growing population. Computer-assisted rice leaf disease diagnoses are hampered due to strong image backgrounds. Popular Convolutional Neural Network (CNN) architecture extracts the features from images and diagnoses the disease to address the issues above. However, this method is best suitable for segmented images and gives low accuracy with real-time images. In this case, the Internet of Things is a paradigm shift that collects agro-meteorological information that effectively helps diagnose rice diseases. Motivated by the usefulness of CNN models and agricultural IoT, a novel multimodal data fusion framework named Rice-Fusion is proposed to diagnose rice disease. Rice disease diagnosis based on a single modality may not be accurate, and hence the fusion of heterogeneous modalities is essential for robust and reliable disease diagnosis. This gives a new dimension to the domain of rice disease diagnosis. The dataset was collected manually with 3200 rice health category samples using two modalities, namely agro-meteorological sensors and a camera. The Rice-Fusion framework initially extracts the numerical features from agro-meteorological data collected from sensors. Next, it extracts the visual features from the captured rice images. These extracted features are further fused using a concatenation layer followed by a dense layer, which provides single output for diagnosing the rice disease. The testing accuracy of Rice-Fusion is 95.31&#x0025; as opposed to other unimodal framework accuracies of 82.03&#x0025; and 91.25&#x0025; based on CNN and Multi-Layer Perceptron (MLP) architectures, respectively. Experimental results analysis demonstrates that the proposed Rice-Fusion multimodal data fusion framework outperforms the outcome of unimodal frameworks.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Rutuja Rajendra Patil et al.",
      "keywords": "Convolutional neural network; Computer science; Rice plant; Artificial intelligence; Medical diagnosis; Population; Sensor fusion; Pattern recognition (psychology); Medicine; Agronomy; Pathology; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3140815",
      "cited_by_count": 174,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2944539652",
      "doi": "10.1109/access.2019.2914873",
      "title": "Attention Dense-U-Net for Automatic Breast Mass Segmentation in Digital Mammogram",
      "abstract": "Breast mass is one of the most distinctive signs for the diagnosis of breast cancer, and the accurate segmentation of masses is critical for improving the accuracy of breast cancer detection and reducing the mortality rate. It is time-consuming for a physician to review the film. Besides, traditional medical segmentation techniques often require prior knowledge or manual extraction of features, which often lead to a subjective diagnosis. Therefore, developing an automatic image segmentation method is important for clinical application. In this paper, a fully automatic method based on deep learning for breast mass segmentation is proposed, which combines densely connected U-Net with attention gates (AGs). It contains an encoder and a decoder. The encoder is a densely connected convolutional network and the decoder is the decoder of U-Net integrated with AGs. The proposed method is tested on the public and authoritative database-Digital Database for Screening Mammography (DDSM) database. F1-score, mean intersection over union, sensitivity, specificity, and overall accuracy are used to evaluate the effectiveness of the proposed method. The experimental results show that dense U-Net integrated AGs achieve better segmentation results than U-Net, attention U-Net, DenseNet, and state-of-the-art methods.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Shuyi Li et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Mammography; Image segmentation; Digital mammography; Encoder; Deep learning; Pattern recognition (psychology); Intersection (aeronautics); Breast cancer; Computer vision; Cancer; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2914873",
      "cited_by_count": 165,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2982638646",
      "doi": "10.1109/jproc.2019.2947272",
      "title": "Brain Imaging Genomics: Integrated Analysis and Machine Learning",
      "abstract": "Brain imaging genomics is an emerging data science field, where integrated analysis of brain imaging and genomics data, often combined with other biomarker, clinical and environmental data, is performed to gain new insights into the phenotypic, genetic and molecular characteristics of the brain as well as their impact on normal and disordered brain function and behavior. It has enormous potential to contribute significantly to biomedical discoveries in brain science. Given the increasingly important role of statistical and machine learning in biomedicine and rapidly growing literature in brain imaging genomics, we provide an up-to-date and comprehensive review of statistical and machine learning methods for brain imaging genomics, as well as a practical discussion on method selection for various biomedical applications.",
      "year": "2019",
      "journal": "Proceedings of the IEEE",
      "authors": "Li Shen et al.",
      "keywords": "Genomics; Neuroimaging; Biomedicine; Artificial intelligence; Brain function; Computer science; Data science; Neuroscience; Computational biology; Machine learning; Genome; Bioinformatics; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2019.2947272",
      "cited_by_count": 182,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3039389508",
      "doi": "10.1109/mgrs.2020.2998816",
      "title": "High-Throughput Estimation of Crop Traits: A Review of Ground and Aerial Phenotyping Platforms",
      "abstract": "Crop yields need to be improved in a sustainable manner to meet the expected worldwide increase in population over the coming decades as well as the effects of anticipated climate change. Recently, genomics-assisted breeding has become a popular approach to food security; in this regard, the crop breeding community must better link the relationships between the phenotype and the genotype. While high-throughput genotyping is feasible at a low cost, highthroughput crop phenotyping methods and data analytical capacities need to be improved. High-throughput phenotyping offers a powerful way to assess particular phenotypes in large-scale experiments, using high-tech sensors, advanced robotics, and imageprocessing systems to monitor and quantify plants in breeding nurseries and field experiments at multiple scales. In addition, new bioinformatics platforms are able to embrace large-scale, multidimensional phenotypic datasets. Through the combined analysis of phenotyping and genotyping data, environmental responses and gene functions can now be dissected at unprecedented resolution. This will \\naid in finding solutions to currently limited and incremental improvements in crop yields. \\n",
      "year": "2020",
      "journal": "IEEE Geoscience and Remote Sensing Magazine",
      "authors": "Xiuliang Jin et al.",
      "keywords": "Throughput; Crop; Estimation; Food security; Population; Biotechnology; Biology; Computer science; Agricultural engineering; Ecology; Engineering; Agriculture; Medicine; Telecommunications; Systems engineering; Environmental health",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/mgrs.2020.2998816",
      "cited_by_count": 263,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2953680418",
      "doi": "10.1109/access.2019.2921480",
      "title": "Domain Adaptive Motor Fault Diagnosis Using Deep Transfer Learning",
      "abstract": "Motor fault diagnosis based on deep learning frameworks has gained much attention from academic research and industry to guarantee motor reliability. Those methods are commonly under two default assumptions: 1) massive labeled training samples and 2) the training and test data share a similar distribution under unvarying working conditions. Unfortunately, these assumptions are nearly invalid in a real-world scenario, where the signals are unlabeled and the working condition changes constantly, resulting in the diagnosis models of the previous studies that always fail in classifying the unlabeled data in real applications. To deal with those issues, in this paper, we propose a novel feature adaptive motor fault diagnosis using deep transfer learning to improve the performance by transferring the knowledge learned from labeled data under invariant working conditions to the unlabeled data under constantly changing working conditions. A convolutional neural network (CNN) is adopted as the base framework to extract multi-level features from raw vibration signals. Then, the regularization term of maximum mean discrepancy (MMD) is incorporated in the training process to impose constraints on the CNN parameters to reduce the distribution mismatch between the features in the source and target domains. To verify the effectiveness of our proposal, data from the motor tests of European driving cycle (NEDC) for simulating the real working scenario and the motor tests under invariant working conditions are, respectively, conducted as the target domain and the source domain. The results show that the proposal presents higher diagnosis accuracy for the unlabeled target data than other methods, and it is of applicability to bridge the discrepancy between different domains.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Dengyu Xiao et al.",
      "keywords": "Computer science; Convolutional neural network; Transfer of learning; Artificial intelligence; Regularization (linguistics); Test data; Machine learning; Deep learning; Raw data; Reliability (semiconductor); Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2921480",
      "cited_by_count": 147,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3046549628",
      "doi": "10.1109/access.2020.3013145",
      "title": "Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",
      "abstract": "Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACMdigital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The \ufffdfindings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Isaac Wiafe et al.",
      "keywords": "Computer science; Intrusion detection system; Computer security; Publication; Domain (mathematical analysis); Artificial intelligence; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3013145",
      "cited_by_count": 133,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3024620668",
      "doi": "10.1109/access.2020.2993967",
      "title": "Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning",
      "abstract": "A huge amount of potentially dangerous COVID-19 misinformation is appearing online. Here we use machine learning to quantify COVID-19 content among online opponents of establishment health guidance, in particular vaccinations (\"anti-vax\"). We find that the anti-vax community is developing a less focused debate around COVID-19 than its counterpart, the pro-vaccination (\"pro-vax\") community. However, the anti-vax community exhibits a broader range of \"flavors\" of COVID-19 topics, and hence can appeal to a broader cross-section of individuals seeking COVID-19 guidance online, e.g. individuals wary of a mandatory fast-tracked COVID-19 vaccine or those seeking alternative remedies. Hence the anti-vax community looks better positioned to attract fresh support going forward than the pro-vax community. This is concerning since a widespread lack of adoption of a COVID-19 vaccine will mean the world falls short of providing herd immunity, leaving countries open to future COVID-19 resurgences. We provide a mechanistic model that interprets these results and could help in assessing the likely efficacy of intervention strategies. Our approach is scalable and hence tackles the urgent problem facing social media platforms of having to analyze huge volumes of online health misinformation and disinformation.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Richard Sear et al.",
      "keywords": "Misinformation; Coronavirus disease 2019 (COVID-19); Pandemic; Computer science; Disinformation; Social media; Herd immunity; Internet privacy; Appeal; Social distance; World Wide Web; Vaccination; Medicine; Political science; Computer security; Virology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2993967",
      "cited_by_count": 137,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3023585707",
      "doi": "10.1109/jbhi.2020.2987943",
      "title": "Image-Based Food Classification and Volume Estimation for Dietary Assessment: A Review",
      "abstract": "A daily dietary assessment method named 24-hour dietary recall has commonly been used in nutritional epidemiology studies to capture detailed information of the food eaten by the participants to help understand their dietary behaviour. However, in this self-reporting technique, the food types and the portion size reported highly depends on users' subjective judgement which may lead to a biased and inaccurate dietary analysis result. As a result, a variety of visual-based dietary assessment approaches have been proposed recently. While these methods show promises in tackling issues in nutritional epidemiology studies, several challenges and forthcoming opportunities, as detailed in this study, still exist. This study provides an overview of computing algorithms, mathematical models and methodologies used in the field of image-based dietary assessment. It also provides a comprehensive comparison of the state of the art approaches in food recognition and volume/weight estimation in terms of their processing speed, model accuracy, efficiency and constraints. It will be followed by a discussion on deep learning method and its efficacy in dietary assessment. After a comprehensive exploration, we found that integrated dietary assessment systems combining with different approaches could be the potential solution to tackling the challenges in accurate dietary intake assessment.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Frank P.-W. Lo et al.",
      "keywords": "Nutritional epidemiology; Computer science; Field (mathematics); Estimation; Judgement; Machine learning; Artificial intelligence; Data science; Medicine; Epidemiology; Mathematics; Pathology; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jbhi.2020.2987943",
      "cited_by_count": 139,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3094843583",
      "doi": "10.1109/access.2020.3036572",
      "title": "Predicting Student Performance and Its Influential Factors Using Hybrid Regression and Multi-Label Classification",
      "abstract": "Understanding, modeling, and predicting student performance in higher education poses significant challenges concerning the design of accurate and robust diagnostic models. While numerous studies attempted to develop intelligent classifiers for anticipating student achievement, they overlooked the importance of identifying the key factors that lead to the achieved performance. Such identification is essential to empower program leaders to recognize the strengths and weaknesses of their academic programs, and thereby take the necessary corrective interventions to ameliorate student achievements. To this end, our paper contributes, firstly, a hybrid regression model that optimizes the prediction accuracy of student academic performance, measured as future grades in different courses, and, secondly, an optimized multi-label classifier that predicts the qualitative values for the influence of various factors associated with the obtained student performance. The prediction of student performance is produced by combining three dynamically weighted techniques, namely collaborative filtering, fuzzy set rules, and Lasso linear regression. However, the multi-label prediction of the influential factors is generated using an optimized self-organizing map. We empirically investigate and demonstrate the effectiveness of our entire approach on seven publicly available and varying datasets. The experimental results show considerable improvements compared to single baseline models (e.g. linear regression, matrix factorization), demonstrating the practicality of the proposed approach in pinpointing multiple factors impacting student performance. As future works, this research emphasizes the need to predict the student attainment of learning outcomes.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Abdullah Alshanqiti et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Regression; Classifier (UML); Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3036572",
      "cited_by_count": 125,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3144883044",
      "doi": "10.1109/access.2021.3071297",
      "title": "Automated Breast Mass Classification System Using Deep Learning and Ensemble Learning in Digital Mammogram",
      "abstract": "In recent years, deep learning techniques are employed in the mammography processing field to reduce radiologists&#x2019; costs. Existing breast mass classification systems are implemented using deep learning technologies such as a Convolutional Neural Network (CNN). CNN based systems have attained higher performance than the machine learning-based systems in the classification task of mammography images, but a few issues still exist. Some of these issues are; ignorance of semantic features, analysis limitation to the current patch of images, lost patches in less contrast mammography images, and ambiguity in segmentation. These issues lead to increased false information about patches of mammography image, computational cost, decisions based on current patches, and not recovering the variance of patches intensity. In turn, breast mass classification systems based on convolutional neural networks produced unsatisfactory classification accuracy. To resolve these issues and improve the accuracy of classification on low contrast images, we propose a novel Breast Mass Classification system named BMC. It has improved architecture based on a combination of k- mean clustering, Long Short-Term Memory network of Recurrent Neural Network (RNN), CNN, random forest, boosting techniques to classify the breast mass into benign, malignant, and normal. Further, the proposed BMC system is compared with existing classification systems using two publicly available datasets of mammographic images. Proposed BMC system achieves the sensitivity, specificity, F-measure, and accuracy for the DDSM dataset is 0.97&#x0025;, 0.98&#x0025;,0.97&#x0025;, 0.96&#x0025; and for the MIAS dataset is 0.97&#x0025;, 0.97&#x0025;,0.98&#x0025;, and 0.95&#x0025; respectively. Further Area Under Curve (AUC) rate of the proposed BMC system lies between 0.94&#x0025; - 0.97&#x0025; for DDSM and 0.94&#x0025;-0.98&#x0025; for the MIAS dataset. The BMC method worked comparably better than other mammography classification schemes that have previously been invented. Moreover, the Confidence interval statistical test is also employed to determine the classification accuracy of the BMC system using different configurations and neural network parameters.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Sharaf J. Malebary et al.",
      "keywords": "Computer science; Artificial intelligence; Ensemble learning; Deep learning; Machine learning; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3071297",
      "cited_by_count": 97,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387587680",
      "doi": "10.1109/jiot.2023.3324053",
      "title": "MalBoT-DRL: Malware Botnet Detection Using Deep Reinforcement Learning in IoT Networks",
      "abstract": "In the dynamic landscape of cyber threats, multi-stage malware botnets have surfaced as significant threats of concern. These sophisticated threats can exploit Internet of Things (IoT) devices to undertake an array of cyberattacks, ranging from basic infections to complex operations such as phishing, cryptojacking, and distributed denial of service (DDoS) attacks. Existing machine learning solutions are often constrained by their limited generalizability across various datasets and their inability to adapt to the mutable patterns of malware attacks in real world environments, a challenge known as model drift. This limitation highlights the pressing need for adaptive Intrusion Detection Systems (IDS), capable of adjusting to evolving threat patterns and new or unseen attacks. This paper introduces MalBoT-DRL, a robust malware botnet detector using deep reinforcement learning. Designed to detect botnets throughout their entire lifecycle, MalBoT-DRL has better generalizability and offers a resilient solution to model drift. This model integrates damped incremental statistics with an attention rewards mechanism, a combination that has not been extensively explored in literature. This integration enables MalBoT-DRL to dynamically adapt to the ever-changing malware patterns within IoT environments. The performance of MalBoT-DRL has been validated via trace-driven experiments using two representative datasets, MedBIoT and N-BaIoT, resulting in exceptional average detection rates of 99.80% and 99.40% in the early and late detection phases, respectively. To the best of our knowledge, this work introduces one of the first studies to investigate the efficacy of reinforcement learning in enhancing the generalizability of IDS.",
      "year": "2023",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Mohammad Al-Fawa\u2019reh et al.",
      "keywords": "Botnet; Malware; Computer science; Reinforcement learning; Intrusion detection system; Denial-of-service attack; Generalizability theory; Artificial intelligence; Exploit; Computer security; Machine learning; The Internet; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2023.3324053",
      "cited_by_count": 83,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4386608905",
      "doi": "10.1109/access.2023.3313977",
      "title": "Recent Advancements and Future Prospects in Active Deep Learning for Medical Image Segmentation and Classification",
      "abstract": "Medical images are helpful for the diagnosis, treatment, and evaluation of diseases. Precise medical image segmentation improves diagnosis and decision-making, aiding intelligent medical services for better disease management and recovery. Due to the unique nature of medical images, image segmentation algorithms based on deep learning face problems such as sample imbalance, edge blur, false positives, and false negatives. In view of these problems, researchers primarily improve the network structure but rarely improve from the unstructured aspect. The paper tackles these challenges, accentuating the limitations of deep convolutional neural network-based methods and proposing solutions to reduce annotation costs, particularly in complex images, and introduces the improvement strategies to solve the problems of sample imbalance, edge blur, false positives, and false negatives. Additionally, the article introduces the latest deep learning-based applications in medical image analysis, covering segmentation, image acquisition, enhancement, registration, and classification. Moreover, the article provides an overview of four cutting-edge deep learning models, namely convolutional neural network (CNN), deep belief network (DBN), stacked autoencoder (SAE), and recurrent neural network (RNN). The study selection involved searching benchmark academic databases, collecting relevant literature and appropriate indicator for analysis, emphasizing DL-based segmentation and classification approaches, and evaluating performance metrics. The research highlights clinicians&#x2019; and scholars&#x2019; obstacles in developing an efficient and accurate malignancy prognostic framework based on state-of-the-art deep-learning algorithms. Furthermore, future perspectives are explored to overcome challenges and advance the field of medical image analysis.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Tariq Mahmood et al.",
      "keywords": "Image segmentation; Artificial intelligence; Computer science; Deep learning; Segmentation; Contextual image classification; Pattern recognition (psychology); Computer vision; Machine learning; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3313977",
      "cited_by_count": 94,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3043116777",
      "doi": "10.1109/access.2020.3008899",
      "title": "Residual Connection-Based Encoder Decoder Network (RCED-Net) for Retinal Vessel Segmentation",
      "abstract": "Devising automated procedures for accurate vessel segmentation (retinal) is crucial for timely prognosis of vision-threatening eye diseases. In this paper, a novel supervised deep learning-based approach is proposed which extends a variant of the fully convolutional neural network. The existing fully convolutional neural network-based counterparts have associated critical drawbacks of involving a large number of tunable hyper-parameters and an increased end-to-end training time furnished by their decoder structure. The proposed approach addresses these intricate challenges by using a skip-connections strategy by sharing indices obtained through max-pooling to the decoder from the encoder stage (respective stages) for enhancing the resolution of the feature map. This significantly reduces the number of required tunable hyper-parameters and the computational overhead of the training as well as testing stages. Furthermore, the proposed approach particularly helps in eradicating the requirement for employing both post-processing and pre-processing steps. In the proposed approach, the retinal vessel segmentation problem is formulated as a semantic pixel-wise segmentation task which helps in spanning the gap between semantic segmentation and medical image segmentation. A prime contribution of the proposed approach is the introduction of external skip-connection for passing the preserved low-level semantic edge information in order to reliably detect tiny vessels in the retinal fundus images. The performance of the proposed scheme is analyzed based on the three publicly available notable fundus image datasets, while the widely recognized evaluation metrics of specificity, sensitivity, accuracy, and the Receiver Operating Characteristics curves are used. Based on the assessment of the images in {DRIVE, CHASE_DB1, and STARE}; datasets, the proposed approach achieves a sensitivity, specificity, accuracy, and ROC performance of {0.8252, 0.8440, and 0.8397};, {0.9787, 0.9810, and 0.9792};, {0.9649, 0.9722, and 0.9659};, and {0.9780, 0.9830, and 0.9810};, respectively. The reduced computational complexity and memory overhead along with improved segmentation performance advocates employing the proposed approach in the automated diagnostic systems for eye diseases.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Tariq M. Khan et al.",
      "keywords": "Computer science; Artificial intelligence; Segmentation; Convolutional neural network; Encoder; Residual; Pattern recognition (psychology); Sensitivity (control systems); Image segmentation; Computer vision; Feature (linguistics); Pooling; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3008899",
      "cited_by_count": 85,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3197896768",
      "doi": "10.1109/tnnls.2021.3106777",
      "title": "Synergistic Integration Between Machine Learning and Agent-Based Modeling: A Multidisciplinary Review",
      "abstract": "Agent-based modeling (ABM) involves developing models in which agents make adaptive decisions in a changing environment. Machine-learning (ML) based inference models can improve sequential decision-making by learning agents' behavioral patterns. With the aid of ML, this emerging area can extend traditional agent-based schemes that hardcode agents' behavioral rules into an adaptive model. Even though there are plenty of studies that apply ML in ABMs, the generalized applicable scenarios, frameworks, and procedures for implementations are not well addressed. In this article, we provide a comprehensive review of applying ML in ABM based on four major scenarios, i.e., microagent-level situational awareness learning, microagent-level behavior intervention, macro-ABM-level emulator, and sequential decision-making. For these four scenarios, the related algorithms, frameworks, procedures of implementations, and multidisciplinary applications are thoroughly investigated. We also discuss how ML can improve prediction in ABMs by trading off the variance and bias and how ML can improve the sequential decision-making of microagent and macrolevel policymakers via a mechanism of reinforced behavioral intervention. At the end of this article, future perspectives of applying ML in ABMs are discussed with respect to data acquisition and quality issues, the possible solution of solving the convergence problem of reinforcement learning, interpretable ML applications, and bounded rationality of ABM.",
      "year": "2021",
      "journal": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Wei Zhang et al.",
      "keywords": "Implementation; Computer science; Artificial intelligence; Machine learning; Reinforcement learning; NetLogo; Inference; Situational ethics; Bounded rationality; Management science; Risk analysis (engineering); Software engineering; Engineering; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tnnls.2021.3106777",
      "cited_by_count": 85,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3081831675",
      "doi": "10.1109/access.2020.3020296",
      "title": "A Novel Fault Identification Method for Photovoltaic Array via Convolutional Neural Network and Residual Gated Recurrent Unit",
      "abstract": "Under the background of the large-scale construction of photovoltaic (PV) power stations, it is crucial to discover and solve module failures in time for improving the service life and maintaining the normal operation efficiency of modules. Based on analyzing the difference of I-V curves of PV arrays under different fault states, the I-V curves, temperatures and irradiances are taken as input data, and a fusion model of convolutional neural network (CNN) and residual-gated recurrent unit (Res-GRU) is proposed to identify the PV array fault. This model consists of a 1-dimensional CNN module with a 4-layer structure and a Res-GRU module. It has the advantages of end-to-end fault diagnosis, no manual feature extraction, strong anti-interference ability, and usable in the absence of irradiances and temperatures. Moreover, it can not only identify a single fault (e.g., short circuit, partial shading, abnormal aging, etc.), but also can effectively identify hybrid faults. Experimental results show that the classification accuracy of the proposed method is 98.61%, which is better than the ones of the artificial neural network (ANN), the extreme learning machine with kernel function (KELM), the fuzzy C-mean (FCM) clustering, the residual neural network (ResNet), and the stage-wise additive modeling using multi-class exponential loss function based on the classification and regression tree (SAMME-CART). In addition, in the absence of temperatures and irradiances, the classification accuracy still reaches 95.23%, which has a broad application prospect in the online fault diagnoses of PV arrays.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Wei Gao et al.",
      "keywords": "Convolutional neural network; Residual; Photovoltaic system; Computer science; Identification (biology); Pattern recognition (psychology); Artificial neural network; Fault detection and isolation; Fault (geology); Unit (ring theory); Artificial intelligence; Algorithm; Engineering; Electrical engineering; Mathematics; Actuator",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3020296",
      "cited_by_count": 83,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3036726364",
      "doi": "10.1109/access.2020.3003424",
      "title": "Resting State fMRI and Improved Deep Learning Algorithm for Earlier Detection of Alzheimer\u2019s Disease",
      "abstract": "The development of computerized healthcare has been powered by diagnostic imaging and machine learning techniques. In particular, recent advances in deep learning have opened a new era in support of multimedia healthcare distribution. For earlier detection of Alzheimer's disease, the study suggested the Improved Deep Learning Algorithm (IDLA) and statistically significant text information. The specific information in clinical text includes the age, sex and genes of the person and apolipoprotein E; the brain function is established using resting-state functional data (MRI) for the measurement of connectivity in the brain regions. A specialized network of autoencoders is used in earlier diagnosis to distinguish between natural aging and disorder progression. The suggested approach incorporates effectively biased neural network functionality and allows a reliable Alzheimer's disease recognition. In comparison with conventional classifiers depends on time series R-fMRI results, the proposed deep learning algorithm has improved significantly and, in the best cases, the standard deviation reduced by 45%, indicating the forecast model is more reliable and efficient in relation to conventional methodologies. The work examines the benefits of improved deep learning algorithms from recognizing high-dimensional information in healthcare and can lead to the early diagnosis and prevention of Alzheimer's disease.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Haibing Guo et al.",
      "keywords": "Deep learning; Artificial intelligence; Computer science; Machine learning; Disease; Resting state fMRI; Artificial neural network; Pattern recognition (psychology); Medicine; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3003424",
      "cited_by_count": 88,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389897623",
      "doi": "10.1109/access.2023.3344653",
      "title": "A Survey on the Detection and Impacts of Deepfakes in Visual, Audio, and Textual Formats",
      "abstract": "In the rapidly evolving digital landscape, the generation of fake visual, audio, and textual content poses a significant threat to the trust of society, political stability, and integrity of information. The generation process has been enhanced and simplified using Artificial Intelligence techniques, which have been termed deepfake. Although significant attention has been paid to visual and audio deepfakes, there is also a burgeoning need to consider text-based deepfakes. Due to advancements in natural language processing and large language models, the potential of manipulating textual content to reshape online discourse and misinformation has increased. This study comprehensively examines the multifaceted nature and impacts of deep-fake-generated media. This work explains the broad implications of deepfakes in social, political, economic, and technological domains. State-of-the-art detection methodologies for all types of deepfake are critically reviewed, highlighting the need for unified, real-time, adaptable, and generalised solutions. As the challenges posed by deepfakes intensify, this study underscores the importance of a holistic approach that integrates technical solutions with public awareness and legislative action. By providing a comprehensive overview and establishing a framework for future exploration, this study seeks to assist researchers, policymakers, and practitioners navigate the complexities of deepfake phenomena.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Rami Mubarak et al.",
      "keywords": "Misinformation; Computer science; Data science; Politics; Computer security; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3344653",
      "cited_by_count": 96,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390939303",
      "doi": "10.1109/access.2024.3354774",
      "title": "A Reliable and Robust Deep Learning Model for Effective Recyclable Waste Classification",
      "abstract": "<p dir=\"ltr\">In response to the growing waste problem caused by industrialization and modernization, the need for an automated waste sorting and recycling system for sustainable waste management has become ever more pressing. Deep learning has made significant advancements in image classification, making it ideally suited for waste sorting applications. This application depends on the development of a suitable deep learning model capable of accurately categorizing various categories of waste. In this study, we present RWC-Net (recyclable waste classification network), a novel deep learning model designed for the classification of six distinct waste categories using the TrashNet dataset of 2,527 images of waste. The performance of our model is subjected to intensive quantitative and qualitative evaluations and is compared to various state-of-art waste classification techniques. The proposed model outperformed several state-of-the-art models by obtaining a remarkable overall accuracy rate of 95.01 percent. In addition, it receives high F1-scores for each of the six waste categories: 97.24% for cardboard, 96.18% for glass, 94% for metal, 95.73% for paper, 93.67% for plastic, and 88.55% for litter. The reliability of the model is demonstrated qualitatively through the saliency maps generated by Score-CAM (class activation mapping) model, which provide visual insights into its performance across various waste categories. These results highlight the model\u2019s accuracy and demonstrate its potential as an effective automated waste classification and management solution. <h2>Other Information</h2><p dir=\"ltr\">Published in: IEEE Access<br>License: <a href=\"https://creativecommons.org/licenses/by/4.0/deed.en\" rel=\"noreferrer noopener\" target=\"_blank\">https://creativecommons.org/licenses/by/4.0/</a> <br>See article on publisher's website: <a href=\"https://dx.doi.org/10.1109/access.2024.3354774\" target=\"_blank\">https://dx.doi.org/10.1109/access.2024.3354774</a>",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Md. Mosarrof Hossen et al.",
      "keywords": "Deep learning; Computer science; Artificial intelligence; Contextual image classification; Sorting; Machine learning; Waste management; Engineering; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3354774",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3199359719",
      "doi": "10.1109/tem.2021.3110427",
      "title": "Construction Industry 4.0 and Sustainability: An Enabling Framework",
      "abstract": "Governments worldwide are taking actions to address the construction sector's sustainability concerns, including high carbon emissions, health and safety risks, low productivity, and increasing costs. Applying Industry 4.0 technologies to construction (also referred to as Construction 4.0) could address some of these concerns. However, current understanding about this is quite limited, with previous work being largely fragmented and limited both in terms of technologies as well as their interrelationships with the triple bottom line of sustainability perspectives. The focus of this article is therefore on addressing these gaps by proposing a comprehensive multi-dimensional Construction 4.0 sustainability framework that identifies and categorizes the key Construction 4.0 technologies and their positive and negative impacts on environmental, economic, and social sustainability, and then establishing its applicability/usefulness through an empirical, multimethodology case study assessment of the UAE's construction sector. The findings indicate Construction 4.0\u2019s positive impacts on environmental and economic sustainability that far outweigh its negative effects, although these impacts are comparable with regards to social sustainability. On Construction 4.0 technologies itself, their application was found to be nonuniform with greater application seen for building information modeling and automation vis-\u00e0-vis others such as cyber-physical systems and smart materials, with significant growth expected in the future for blockchain- and three-dimensional-printing-related technologies. The proposed novel framework could enable the development of policy interventions and support mechanisms to increase Construction 4.0 deployment while addressing its negative sustainability-related impacts. The framework also has the potential to be adapted and applied to other country and sectoral contexts.",
      "year": "2021",
      "journal": "IEEE Transactions on Engineering Management",
      "authors": "Sreejith Balasubramanian et al.",
      "keywords": "Sustainability; Social sustainability; Software deployment; Productivity; Triple bottom line; Business; Sustainability organizations; Work (physics); Industry 4.0; Environmental economics; Process management; Environmental resource management; Engineering; Economics; Economic growth",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tem.2021.3110427",
      "cited_by_count": 105,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3125714359",
      "doi": "10.1109/tmi.2021.3054566",
      "title": "Myocardial Function Imaging in Echocardiography Using Deep Learning",
      "abstract": "Deformation imaging in echocardiography has been shown to have better diagnostic and prognostic value than conventional anatomical measures such as ejection fraction. However, despite clinical availability and demonstrated efficacy, everyday clinical use remains limited at many hospitals. The reasons are complex, but practical robustness has been questioned, and a large inter-vendor variability has been demonstrated. In this work, we propose a novel deep learning based framework for motion estimation in echocardiography, and use this to fully automate myocardial function imaging. A motion estimator was developed based on a PWC-Net architecture, which achieved an average end point error of (0.06\u00b10.04) mm per frame using simulated data from an open access database, on par or better compared to previously reported state of the art. We further demonstrate unique adaptability to image artifacts such as signal dropouts, made possible using trained models that incorporate relevant image augmentations. Further, a fully automatic pipeline consisting of cardiac view classification, event detection, myocardial segmentation and motion estimation was developed and used to estimate left ventricular longitudinal strain in vivo. The method showed promise by achieving a mean deviation of (-0.7\u00b11.6)% compared to a semi-automatic commercial solution for N=30 patients with relevant disease, within the expected limits of agreement. We thus believe that learning-based motion estimation can facilitate extended use of strain imaging in clinical practice.",
      "year": "2021",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Andreas \u00d8stvik et al.",
      "keywords": "Artificial intelligence; Computer science; Robustness (evolution); Segmentation; Deep learning; Image segmentation; Computer vision; Pattern recognition (psychology); Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2021.3054566",
      "cited_by_count": 73,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2901160118",
      "doi": "10.1109/access.2018.2880694",
      "title": "Progress on Artificial Neural Networks for Big Data Analytics: A Survey",
      "abstract": "Approximately 2.5 quintillion bytes of data are emitted on a daily basis, and this has brought the world into the era of &#x201C;big data.&#x201D; Artificial neural networks (ANNs) are known for their effectiveness and efficiency for small datasets, and this era of big data has posed a challenge to the big data analytics using ANN. Recently, much research effort has been devoted to the application of the ANN in big data analytics and is still ongoing, although it is in it is early stages. The purpose of this paper is to summarize recent progress, challenges, and opportunities for future research. This paper presents a concise view of the state of the art, challenges, and future research opportunities regarding the applications of the ANN in big data analytics and reveals that progress has been made in this area. Our review points out the limitations of the previous approaches, the challenges in the ANN approaches in terms of their applications in big data analytics, and several ANN architecture that have not yet been explored in big data analytics and opportunities for future research. We believe that this paper can serve as a yardstick for future progress on the applications of the ANN in big data analytics as well as a starting point for new researchers with an interest in the exploration of the ANN in big data analytics.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Haruna Chiroma et al.",
      "keywords": "Big data; Data science; Computer science; Analytics; Data analysis; Software analytics; Data mining; Software",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2880694",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385696134",
      "doi": "10.1109/comst.2023.3302474",
      "title": "A Survey on Approximate Edge AI for Energy Efficient Autonomous Driving Services",
      "abstract": "&amp;lt;p&amp;gt;Autonomous driving services depends on active sensing from modules such as camera, LiDAR, radar, and communication units. Traditionally, these modules process the sensed data on high-performance computing units inside the vehicle, which can deploy intelligent algorithms and AI models. The sensors mentioned above can produce large volumes of data, potentially reaching up to 20 Terabytes. This data size is influenced by factors such as the duration of driving, the data rate, and the sensor specifications. Consequently, this substantial amount of data can lead to significant power consumption on the vehicle. Similarly, a substantial amount of data will be exchanged between infrastructure sensors and vehicles for collaborative vehicle applications or fully connected autonomous vehicles. This communication process generates an additional surge of energy consumption. Although the autonomous vehicle domain has seen advancements in sensory technologies, wireless communication, computing and AI/ML algorithms, the challenge still exists in how to apply and integrate these technology innovations to achieve energy efficiency. This survey reviews and compares the connected vehicular applications, vehicular communications, approximation and Edge AI techniques. The focus is on energy efficiency by covering newly proposed approximation and enabling frameworks. To the best of our knowledge, this survey is the first to review the latest approximate Edge AI frameworks and publicly available datasets in energy-efficient autonomous driving. The insights from this survey can benefit the collaborative driving service development on low-power and memory-constrained systems and the energy optimization of autonomous vehicles.&amp;lt;/p&amp;gt;",
      "year": "2023",
      "journal": "IEEE Communications Surveys & Tutorials",
      "authors": "Dewant Katare et al.",
      "keywords": "Computer science; Energy consumption; Process (computing); Efficient energy use; Wireless sensor network; Enhanced Data Rates for GSM Evolution; Real-time computing; Distributed computing; Edge computing; Wireless; Terabyte; Service (business); Artificial intelligence; Telecommunications; Computer network; Engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/comst.2023.3302474",
      "cited_by_count": 70,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391147969",
      "doi": "10.1109/access.2024.3357514",
      "title": "FedCure: A Heterogeneity-Aware Personalized Federated Learning Framework for Intelligent Healthcare Applications in IoMT Environments",
      "abstract": "The advent of the Internet of Medical Things (IoMT) devices has led to a healthcare revolution, introducing a new era of smart applications driven by Artificial Intelligence (AI). These advanced technologies have greatly influenced the healthcare industry and have played a crucial role in enhancing the quality of life globally. Federated Learning (FL) has become popular as a technique to create models that can be shared universally using the vast datasets collected from IoMT devices while maintaining data privacy. However, the complex variations in IoMT environments, including diverse devices, data characteristics, and model complexities, create challenges for the straightforward application of traditional FL methods. Consequently, it is not well-suited for deployment in such contexts. This paper introduces FedCure, a personalized FL framework tailored for intelligent IoMT-based healthcare applications operating within a cloud-edge architecture. FedCure is adept at addressing the challenges within IoMT environments by employing personalized FL techniques that can effectively mitigate the impact of heterogeneity. Furthermore, the integration of edge computing technology enhances processing speed and minimizes latency in intelligent IoMT applications. Lastly, this research showcases several case studies encompassing IoMT-based applications, such as Eye Retinopathy Detection, Diabetes Monitoring, Maternal Health, Remote Health Monitoring, and Human Activity Recognition. These case studies provide a means to assess the effectiveness of the proposed FedCure framework and showcase exceptional performance with accuracy and minimal communication overhead, especially in addressing the challenges posed by heterogeneity.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Sachin D.N. et al.",
      "keywords": "Computer science; Cloud computing; Software deployment; Data science; The Internet; Edge computing; Health care; Overhead (engineering); Popularity; World Wide Web; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3357514",
      "cited_by_count": 56,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3161857679",
      "doi": "10.1109/access.2021.3080837",
      "title": "Entertainment Chatbot for the Digital Inclusion of Elderly People Without Abstraction Capabilities",
      "abstract": "Current language processing technologies allow the creation of conversational\\nchatbot platforms. Even though artificial intelligence is still too immature to\\nsupport satisfactory user experience in many mass market domains,\\nconversational interfaces have found their way into ad hoc applications such as\\ncall centres and online shopping assistants. However, they have not been\\napplied so far to social inclusion of elderly people, who are particularly\\nvulnerable to the digital divide. Many of them relieve their loneliness with\\ntraditional media such as TV and radio, which are known to create a feeling of\\ncompanionship. In this paper we present the EBER chatbot, designed to reduce\\nthe digital gap for the elderly. EBER reads news in the background and adapts\\nits responses to the user's mood. Its novelty lies in the concept of\\n\"intelligent radio\", according to which, instead of simplifying a digital\\ninformation system to make it accessible to the elderly, a traditional channel\\nthey find familiar -- background news -- is augmented with interactions via\\nvoice dialogues. We make it possible by combining Artificial Intelligence\\nModelling Language, automatic Natural Language Generation and Sentiment\\nAnalysis. The system allows accessing digital content of interest by combining\\nwords extracted from user answers to chatbot questions with keywords extracted\\nfrom the news items. This approach permits defining metrics of the abstraction\\ncapabilities of the users depending on a spatial representation of the word\\nspace. To prove the suitability of the proposed solution we present results of\\nreal experiments conducted with elderly people that provided valuable insights.\\nOur approach was considered satisfactory during the tests and improved the\\ninformation search capabilities of the participants.\\n",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Silvia Garc\u00eda-M\u00e9ndez et al.",
      "keywords": "Chatbot; Inclusion (mineral); Computer science; Abstraction; Entertainment; Digital inclusion; Multimedia; World Wide Web; Human\u2013computer interaction; The Internet; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3080837",
      "cited_by_count": 80,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2789184669",
      "doi": "10.1109/tg.2019.2901021",
      "title": "General Video Game AI: A Multitrack Framework for Evaluating Agents, Games, and Content Generation Algorithms",
      "abstract": "General Video Game Playing (GVGP) aims at designing an agent that is capable of playing multiple video games with no human intervention. In 2014, The General Video Game AI (GVGAI) competition framework was created and released with the purpose of providing researchers a common open-source and easy to use platform for testing their AI methods with potentially infinity of games created using Video Game Description Language (VGDL). The framework has been expanded into several tracks during the last few years to meet the demand of different research directions. The agents are required either to play multiple unknown games with or without access to game simulations, or to design new game levels or rules. This survey paper presents the VGDL, the GVGAI framework, existing tracks, and reviews the wide use of GVGAI framework in research, education and competitions five years after its birth. A future plan of framework improvements is also described.",
      "year": "2019",
      "journal": "IEEE Transactions on Games",
      "authors": "Diego P\u00e9rez-Li\u00e9bana et al.",
      "keywords": "Computer science; Video game; Video game design; Plan (archaeology); Game design; Game mechanics; Multimedia; Game Developer; Turns, rounds and time-keeping systems in games; Track (disk drive); Competition (biology); Video game development",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tg.2019.2901021",
      "cited_by_count": 63,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3094968949",
      "doi": "10.1109/access.2020.3034596",
      "title": "Smart Urban Mobility Innovations: A Comprehensive Review and Evaluation",
      "abstract": "Recent smart urban mobility innovations such as intelligent transportation systems, electric vehicles, autonomous vehicles, demand-responsive transportation, shared transportation, and mobility-as-a-service are consistently identified as the panacea to many of the economic, social and environmental effects associated with private vehicles-including road congestion, urban sprawl, social exclusion, increased costs, crashes, emissions, and environmental degradation. One of the strategies of many smart urban mobility policies is to view the transportation system from a holistic perspective to seek reduction of negative effects and an improve performance. Nonetheless, given the rapid technological advances in the transportation sector, there is a need to identify and evaluate primary smart mobility innovations from a sustainability perspective. This article presents a thorough technology review and evaluation of the main smart mobility innovations identified in the literature. The study has identified and categorized six main smart mobility innovations most commonly discussed within the literature including: (a) intelligent transport systems; (b) alternative fuel systems; (c) driving automation systems; (d) shared mobility services; (e) demand responsive transport; and (f) integrated mobility systems. Furthermore, this article includes a brief description of their characteristics, applications, and also evaluates their sustainability according to their proposed impacts on transport safety, road congestion, energy consumption, the environment, and accessibility.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Luke Butler et al.",
      "keywords": "Urban sprawl; Sustainability; Intelligent transportation system; Panacea (medicine); Transport engineering; Traffic congestion; Environmental economics; Computer science; Public transport; Personal mobility; Sustainable transport; Business; Risk analysis (engineering); Urban planning; Telecommunications; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3034596",
      "cited_by_count": 141,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391341809",
      "doi": "10.1109/access.2024.3359910",
      "title": "Machine Learning-Based Cardiovascular Disease Detection Using Optimal Feature Selection",
      "abstract": "Cardiovascular disease (CVD) is a prevalent and serious condition causing a significant global mortality rate. According to the World Health Organization (WHO), in 2022, CVD claimed the lives of approximately 19.1 million people, accounting for 33&#x0025; of global fatalities. ECG is widely used for automatic detection of CVD using traditional machine learning; however, it is usually difficult to select optimal features. Addressing this issue, a scalable machine learning-based architecture is proposed for early CVD detection based optimal feature selection. This architecture aims to revolutionize healthcare by enabling timely diagnosis and treatment, reducing CVD-related fatalities. Comprising data collection, storage, and processing components, the system employs machine learning classifiers to predict patients&#x2019; heart conditions. Initially features are extracted from ECG signals then feature selection techniques like FCBF, MrMr, and relief, along with PSO-optimization are used to select optimal features. Extra Tree and Random Forest classifiers trained on the selected features have achieved notable performance rates with accuracy of 100&#x0025; respectively. Furthermore, a comparison of the proposed method with state of the art on both small and large dataset is provided. The proposed system holds potential to revolutionize patient care and substantially lower CVD-related mortality, enhancing the quality of life for affected individuals. In summary, this architecture offers a promising solution to the pressing issue of CVD and paves the way for advanced healthcare systems.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Tahseen Ullah et al.",
      "keywords": "Computer science; Feature selection; Artificial intelligence; Selection (genetic algorithm); Machine learning; Disease; Pattern recognition (psychology); Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3359910",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3182487637",
      "doi": "10.1109/access.2021.3095380",
      "title": "A Novel Non-Invasive Estimation of Respiration Rate From Motion Corrupted Photoplethysmograph Signal Using Machine Learning Model",
      "abstract": "&lt;p&gt;Respiratory ailments such as asthma, chronic obstructive pulmonary disease (COPD), pneumonia, and lung cancer are life-threatening. Respiration rate (RR) is a vital indicator of the wellness of a patient. Continuous monitoring of RR can provide early indication and thereby save lives. However, a real-time continuous RR monitoring facility is only available at the intensive care unit (ICU) due to the size and cost of the equipment. Recent researches have proposed Photoplethysmogram (PPG) and/ Electrocardiogram (ECG) signals for RR estimation however, the usage of ECG is limited due to the unavailability of it in wearable devices. Due to the advent of wearable smartwatches with built-in PPG sensors, it is now being considered for continuous monitoring of RR. This paper describes a novel approach for RR estimation using motion artifact correction and machine learning (ML) models with the PPG signal features. Feature selection algorithms were used to reduce computational complexity and the chance of overfitting. The best ML model and the best feature selection algorithm combination were fine-tuned to optimize its performance using hyperparameter optimization. Gaussian Process Regression (GPR) with Fit a Gaussian process regression model (Fitrgp) feature selection algorithm outperformed all other combinations and exhibits a root mean squared error (RMSE), mean absolute error (MAE), and two-standard deviation (2SD) of 2.63, 1.97, and 5.25 breaths per minute, respectively. Patients would be able to track RR at a lower cost and with less inconvenience if RR can be extracted efficiently and reliably from the PPG signal.&lt;/p&gt;&lt;h2&gt;Other Information&lt;/h2&gt;&lt;p&gt;Published in: IEEE Access&lt;br&gt;License: &lt;a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\" target=\"_blank\"&gt;https://creativecommons.org/licenses/by/4.0/&lt;/a&gt;&lt;br&gt;See article on publisher's website: &lt;a href=\"https://dx.doi.org/10.1109/access.2021.3095380\" target=\"_blank\"&gt;https://dx.doi.org/10.1109/access.2021.3095380&lt;/a&gt;&lt;/p&gt;",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Md Nazmul Islam Shuzan et al.",
      "keywords": "Photoplethysmogram; Computer science; Artificial intelligence; Mean squared error; Overfitting; Feature selection; Machine learning; Approximation error; Unavailability; Feature (linguistics); Pattern recognition (psychology); Speech recognition; Statistics; Mathematics; Computer vision; Algorithm; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3095380",
      "cited_by_count": 56,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313169633",
      "doi": "10.1109/access.2022.3219068",
      "title": "A Smart Home Energy Management System Utilizing Neurocomputing-Based Time-Series Load Modeling and Forecasting Facilitated by Energy Decomposition for Smart Home Automation",
      "abstract": "The key advantage of using power-utility-owned smart meters is the ability to transmit electrical energy consumption data to power utilities&#x2019; remote data centers for various purposes, such as billing. Several useful consumer-centric use cases can also be identified for the collection and further analysis of consumers&#x2019; electrical energy consumption data from smart meters. One of the use cases is home automation. Recent related solutions for home automation involving home security and healthcare depend on the installation of sensors and/or other devices such as video cameras, which have high costs for installation and annual maintenance. Because the electrical energy consumption patterns mined from smart meter data are indicative of residents&#x2019; daily life, it is possible to develop a new home automation approach based on energy decomposition for smart home automation. Accordingly, in this work, a smart home energy management system (SHEMS) utilizing a parallel-processing-implemented, GPU-accelerated neurocomputing-based time-series load modeling and forecasting mechanism is proposed for smart home automation. Energy decomposition is used to facilitate the time-series load modeling and forecasting mechanism, which tracks appliance-level electrical energy consumption to be quantitatively modeled from circuit-level consumption, with no intrusive deployment of networked plug-level power meters for individual electrical home appliances. For the neurocomputing approach applied in this mechanism, an autoregressive multilayer perceptron methodology is compared against a stacked long short-term memory methodology. The presented neurocomputing-based time-series load modeling and forecasting mechanism facilitated by energy decomposition is capable of predicting residents&#x2019; daily behavioral patterns by nonintrusively analyzing and modeling relevant electrical home appliances based on their past trends for smart home automation.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Yu\u2010Hsiu Lin et al.",
      "keywords": "Home automation; Computer science; Automation; Decomposition; Energy (signal processing); Series (stratigraphy); Energy management; Time series; Smart grid; Water heating; Energy management system; Real-time computing; Embedded system; Machine learning; Engineering; Telecommunications; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3219068",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387350606",
      "doi": "10.1109/access.2023.3321800",
      "title": "A Comprehensive Survey of Machine Learning Methods for Surveillance Videos Anomaly Detection",
      "abstract": "Video Surveillance Systems (VSSs) are used in a wide range of applications including public safety and perimeter security. They are deployed in places such as markets, hospitals, schools, banks, shopping malls, offices, and smart cities. VSSs generate a massive amount of surveillance data, and significant research has been published on the use of machine learning algorithms to handle surveillance data. In this paper, we present an extensive overview and a thorough analysis of cutting-edge learning methods used in VSSs. Existing surveys on learning approaches in video surveillance have some drawbacks, such as a lack of in-depth analysis of the learning algorithms, omission of certain methodologies, insufficient critical evaluation, and absence of recent learning algorithms. To fill these gaps, this survey provides a thorough examination of the most recent learning algorithms for anomaly detection. A critical assessment of the algorithms including their strengths, weaknesses, and applicability as well as tailored classifications of anomaly types for different domains are provided. Our study also offers insights into the future development of learning techniques in VSS, positioning itself as a valuable resource for both researchers and practitioners in the field. Finally, we share our thoughts on what we learned and how it can help with new developments in the future.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nomica Choudhry et al.",
      "keywords": "Computer science; Anomaly detection; Strengths and weaknesses; Machine learning; Resource (disambiguation); Artificial intelligence; Computer security; Field (mathematics); Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3321800",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295886337",
      "doi": "10.1109/access.2022.3205618",
      "title": "A Comprehensive Survey on the Process, Methods, Evaluation, and Challenges of Feature Selection",
      "abstract": "Feature selection is employed to reduce the feature dimensions and computational complexity by eliminating irrelevant and redundant features. A vast amount of increasing data and its processing generates many feature sets, which are reduced by the feature selection process to improve the performance in all types of classification, regression, clustering models. This study performs a detailed analysis of motivation and concentrates on the fundamental architecture of feature selection. This study aims to establish a structured formation related to popular methods such as filters, wrappers and, embedded into search strategies, evaluation criteria, and learning methods. Different methods organize a comparison of the benefits and drawbacks followed by multiple classification algorithms and standard validation measures. The diversity of applications in multiple domains such as data retrieval, prediction analysis, and medical, intrusion, and industrial applications is efficiently highlighted. This study focuses on some additional feature selection methods for handling big data. Nonetheless, new challenges have surfaced in the analysis of such data, which were also addressed in this study. Reflecting on commonly encountered challenges and clarifying how to obtain the absolute feature selection method are the significant components of this study.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Md. Rashedul Islam et al.",
      "keywords": "Feature selection; Computer science; Feature (linguistics); Data mining; Cluster analysis; Process (computing); Artificial intelligence; Selection (genetic algorithm); Big data; Machine learning; Feature extraction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3205618",
      "cited_by_count": 65,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3115732278",
      "doi": "10.1109/access.2020.3048018",
      "title": "Tax Default Prediction Using Feature Transformation-Based Machine Learning",
      "abstract": "This study proposes to address the economic significance of unpaid taxes by using an automatic system for predicting a tax default. Too little attention has been paid to tax default prediction in the past. Moreover, existing approaches tend to apply conventional statistical methods rather than advanced data analytic approaches, including state-of-the-art machine learning methods. Therefore, existing studies cannot effectively detect tax default information in real-world financial data because they fail to take into account the appropriate data transformations and nonlinear relationships between early-warning financial indicators and tax default behavior. To overcome these problems, this study applies diverse feature transformation techniques and state-of-the-art machine learning approaches. The proposed prediction system is validated by using a dataset showing tax defaults and non-defaults at Finnish limited liability firms. Our findings provide evidence for a major role of feature transformation, such as logarithmic and square-root transformation, in improving the performance of tax default prediction. We also show that extreme gradient boosting and the systematically developed forest of multiple decision trees outperform other machine learning methods in terms of accuracy and other classification performance measures. We show that the equity ratio, liquidity ratio, and debt-to-sales ratio are the most important indicators of tax defaults for 1-year-ahead predictions. Therefore, this study highlights the essential role of well-designed tax default prediction systems, which require a combination of feature transformation and machine learning methods. The effective implementation of an automatic tax default prediction system has important implications for tax administration and can assist administrators in achieving feasible government expenditure allocations and revenue expansions.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammad Zoynul Abedin et al.",
      "keywords": "Computer science; Artificial intelligence; Feature (linguistics); Machine learning; Transformation (genetics); Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3048018",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4367333180",
      "doi": "10.1109/access.2023.3271410",
      "title": "A Multimodal Data Fusion and Deep Neural Networks Based Technique for Tea Yield Estimation in Pakistan Using Satellite Imagery",
      "abstract": "Achieving food security has become a major challenge for society. Crop yield estimation is essential for crop monitoring to ensure food security. Manual crop yield estimation is cumbersome and inaccurate and becomes infeasible when scaled up. Machine learning algorithms trained using remotely sensed data have played a vital role in estimating the yield of different crops. Furthermore, to enrich the data provided to a machine learning algorithm, multiple modalities can be combined to improve the predictive performance of these algorithms. In this research, we propose to combine data from multiple modalities, i.e., agrometeorological and remote sensing data, to predict the tea yield at the farm level. The dataset employed in this study is acquired from tea fields of the National Tea and High-Value Crop Research Institute (NTHRI), Mansehra, Pakistan. The remote sensing data of the Landsat-8 satellite is converted to farm-level NDVI statistics through geocoding. Before being used for regression modeling, the final dataset is subjected to some further preprocessing steps, including the selection of features and the optimization of feature sets. This preprocessed data is used to train the three classes of machine learning regression algorithms. Conventional regression algorithms, including Decision Trees, Multilayer Perceptron (MLP), Support Vector Regression (SVR), Gaussian Process Regression (GPR), and Multiple Linear Regression applied with and without interaction terms and stepwise feature inclusion with various kernels. Moreover, the following three variants of the ensemble learning methods have also been applied: random forest, gradient boosting, and XgBoost. Finally, this study proposed a neural architecture for tea yield estimation using Landsat imagery. This deep neural network is built using neural architecture search via Bayesian optimization and have three hidden layers, which can perform complex non-linear modeling. Experimental evaluation is performed through 10-fold cross-validation, and the proposed Deep neural network regression model provided the best predictive performance. The model provided a coefficient of determination (R-squared) of 0.99 with a Mean Square Error (MSE) of 108.17 kg/ha, Root Mean Square Error (RMSE) of 10.87 kg/ha, Mean Absolute Error (MAE) of 2.26 kg/ha and Mean Absolute Percentage Error (MAPE) of 2.92.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zeeshan Ramzan et al.",
      "keywords": "Random forest; Computer science; Machine learning; Artificial intelligence; Feature selection; Support vector machine; Artificial neural network; Decision tree; Data pre-processing; Multilayer perceptron; Normalized Difference Vegetation Index; Regression; Data mining; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3271410",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390187287",
      "doi": "10.1109/access.2023.3346875",
      "title": "Automatic Transportation Mode Classification Using a Deep Reinforcement Learning Approach With Smartphone Sensors",
      "abstract": "The increasing dependence on smartphones with advanced sensors has highlighted the imperative of precise transportation mode classification, pivotal for domains like health monitoring and urban planning. This research is motivated by the pressing demand to enhance transportation mode classification, leveraging the potential of smartphone sensors, notably the accelerometer, magnetometer, and gyroscope. In response to this challenge, we present a novel automated classification model rooted in deep reinforcement learning. Our model stands out for its innovative approach of harnessing enhanced features through artificial neural networks (ANNs) and visualizing the classification task as a structured series of decision-making events. Our model adopts an improved differential evolution (DE) algorithm for initializing weights, coupled with a specialized agent-environment relationship. Every correct classification earns the agent a reward, with additional emphasis on the accurate categorization of less frequent modes through a distinct reward strategy. The Upper Confidence Bound (UCB) technique is used for action selection, promoting deep-seated knowledge, and minimizing reliance on chance. A notable innovation in our work is the introduction of a cluster-centric mutation operation within the DE algorithm. This operation strategically identifies optimal clusters in the current DE population and forges potential solutions using a pioneering update mechanism. When assessed on the extensive HTC dataset, which includes 8311 hours of data gathered from 224 participants over two years. Noteworthy results spotlight an accuracy of 0.88&#x00B1;0.03 and an F-measure of 0.87&#x00B1;0.02, underscoring the efficacy of our approach for large-scale transportation mode classification tasks. This work introduces an innovative strategy in the realm of transportation mode classification, emphasizing both precision and reliability, addressing the pressing need for enhanced classification mechanisms in an ever-evolving digital landscape.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Siavash Taherinavid et al.",
      "keywords": "Computer science; Reinforcement learning; Machine learning; Artificial intelligence; Categorization; Initialization; Supervised learning; Crowdsensing; Population; Artificial neural network; Data mining; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3346875",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4378714780",
      "doi": "10.1109/access.2023.3280422",
      "title": "Multi-Input Deep Learning Approach for Breast Cancer Screening Using Thermal Infrared Imaging and Clinical Data",
      "abstract": "Breast cancer is one of the most prevalent causes of death among women across the globe. Early detection is the best strategy for reducing the mortality rate. Currently, mammography is the standard screening modality, which has its shortcomings. To complement this modality, thermal infrared-based Computer-Aided Diagnosis (CADx) tools have been presented as economical, less hazardous, and a suitable solution for various age groups. Although a viable solution, most CADx systems are built primarily from frontal breast thermograms, and are likely to miss lesions that may develop on the sides. Additionally, these systems often disregard critical clinical data, such as risk factors. This paper presents a novel CADx system that utilizes deep learning techniques for breast cancer detection. The system incorporates multiple breast thermogram views and corresponding patient clinical data to improve the accuracy of the diagnosis. We describe the methodology of the system, including the extraction of regions of interest from images and the use of transfer learning to train three different models. We evaluate the performance of the models and compare them to similar works from the literature. The results demonstrate that using multi-inputs outperforms single-input models and achieves an overall accuracy of 90.48&#x0025;, a sensitivity of 93.33&#x0025;, and an AUROC curve of 0.94. This approach could offer a more cost-effective and less hazardous screening option for breast cancer detection, particularly for a wide range of age groups.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Dennies Tsietso et al.",
      "keywords": "Mammography; Breast cancer; Modality (human\u2013computer interaction); Computer science; Artificial intelligence; Deep learning; Machine learning; Receiver operating characteristic; Cancer; Medical physics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3280422",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387350583",
      "doi": "10.1109/access.2023.3321686",
      "title": "Classification of Lung and Colon Cancer Histopathological Images Using Global Context Attention Based Convolutional Neural Network",
      "abstract": "The malignant neoplastic malady known as cancer appears to exhibit a significantly elevated rate of mortality owing to its virulence and pronounced propensity for metastasis. To augment the diagnostic efficacy, research endeavors have been undertaken utilizing complex deep learning architectures. However, the performance of these efforts remains circumscribed by smaller dataset size, quality of the data, the interclass variations present between lung adenocarcinoma and lung squamous cell carcinoma, and the complexity of deploying to mobile devices and failure to address both image and patient level accuracy measurements. To surmount these obstacles, the present study proposes a stage-based method for enhancing the images, in conjunction with utilizing a global context attention-guided convolutional neural network that effectively captures both channel and spatial information and semantic information extracted from the input image. Implementing the proposed methodology increased total image level accuracy to 99.76&#x0025; and a patient level accuracy of 96.5&#x0025;, a metric that has yet to be previously quantified. The addition of the global context attention module decreases the model&#x2019;s parameter count by 0.47 million, reduces the computational costs by saving 10.54 million floating point operations per second (FLOPs) and 10.72 million multiply-accumulate operations (MACs), and results in a 0.03s improvement in inference time. Furthermore, this module enhances both image level and patient level accuracy, boosting them by 2.84&#x0025; and 3.17&#x0025;, respectively, compared to using only the convolutional block attention module in the baseline convolutional neural network. Consequently, this modification renders the model highly suitable for deployment on mobile devices due to its adaptability. Our findings provide supporting evidence for the potential of this method to serve as a noninvasive screening tool capable of reliably classifying lung and colon cancer subtypes.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Md. Al-Mamun Provath et al.",
      "keywords": "Computer science; Convolutional neural network; Context (archaeology); Deep learning; Artificial intelligence; Inference; Machine learning; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3321686",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2982453279",
      "doi": "10.1109/access.2019.2949744",
      "title": "Computer-Vision Based Diagnosis of Parkinson\u2019s Disease via Gait: A Survey",
      "abstract": "Parkinson's Disease (PD) being the second most hazardous neurological disorder has developed its roots in damaging people's quality of life (QOL). The ineffectiveness of clinical rating scales makes the PD diagnosis a very complicated task. Thus, more efficient systems are required to perform an automated evaluation of PD for its earlier detection and to enhance life expectancy rate. Gait based clinical diagnosis can provide useful indications regarding the presence of PD. From recent years, computer vision-based (VB) analysis is in great demand and seems to be highly effective in PD inspection. The objective of this article is to systematically analyze the applications of computer vision in PD evaluation through gait. This paper surveys the VB PD gait acquisition modalities as well as provides a concise overview of preprocessing techniques. The study presents a description of PD related gait features, extraction and selection methods used for PD analysis. A number of machine learning techniques for classification of PD and healthy gait are also discussed. This article extensively surveys PD gait datasets considering data from 1997 to 2018. Also, several research gaps in existing studies have identified that need to be addressed in the future. At last, an outline of the proposed idea is given that can cope up with the related issues and can lead to quality VB PD gait investigation.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Navleen Kour et al.",
      "keywords": "Gait; Computer science; Parkinson's disease; Modalities; Gait analysis; Physical medicine and rehabilitation; Machine learning; Artificial intelligence; Quality of life (healthcare); Disease; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2949744",
      "cited_by_count": 56,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3016564562",
      "doi": "10.1109/tetc.2020.2983404",
      "title": "Privacy-Preserving Deep Learning NLP Models for Cancer Registries",
      "abstract": "Population cancer registries can benefit from Deep Learning (DL) to automatically extract cancer characteristics from the high volume of unstructured pathology text reports they process annually. The success of DL to tackle this and other real-world problems is proportional to the availability of large labeled datasets for model training. Although collaboration among cancer registries is essential to fully exploit the promise of DL, privacy and confidentiality concerns are main obstacles for data sharing across cancer registries. Moreover, DL for natural language processing (NLP) requires sharing a vocabulary dictionary for the embedding layer which may contain patient identifiers. Thus, even distributing the trained models across cancer registries causes a privacy violation issue. In this paper, we propose DL NLP model distribution via privacy-preserving transfer learning approaches without sharing sensitive data. These approaches are used to distribute a multitask convolutional neural network (MT-CNN) NLP model among cancer registries. The model is trained to extract six key cancer characteristics - tumor site, subsite, laterality, behavior, histology, and grade - from cancer pathology reports. Using 410,064 pathology documents from two cancer registries, we compare our proposed approach to conventional transfer learning without privacy-preserving, single-registry models, and a model trained on centrally hosted data. The results show that transfer learning approaches including data sharing and model distribution outperform significantly the single-registry model. In addition, the best performing privacy-preserving model distribution approach achieves statistically indistinguishable average micro- and macro-F1 scores across all extraction tasks (0.823,0.580) as compared to the centralized model (0.827,0.585).",
      "year": "2020",
      "journal": "IEEE Transactions on Emerging Topics in Computing",
      "authors": "Mohammed Alawad et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Convolutional neural network; Deep learning; Transfer of learning; Word embedding; Data sharing; Natural language processing; Embedding; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tetc.2020.2983404",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394564350",
      "doi": "10.1109/access.2024.3385781",
      "title": "Enhancing Medicare Fraud Detection Through Machine Learning: Addressing Class Imbalance With SMOTE-ENN",
      "abstract": "The healthcare fraud detection field is constantly evolving and faces significant challenges, particularly when addressing imbalanced data issues. Previous studies mainly focused on traditional machine learning (ML) techniques, often struggling with imbalanced data. This problem arises in various aspects. It includes the risk of overfitting with Random Oversampling (ROS), noise introduction by the Synthetic Minority Oversampling Technique (SMOTE), and potential crucial information loss with Random Undersampling (RUS). Moreover, improving model performance, exploring hybrid resampling techniques, and enhancing evaluation metrics are crucial for achieving higher accuracy with imbalanced datasets. In this paper, we present a novel approach to tackle the issue of imbalanced datasets in healthcare fraud detection, with a specific focus on the Medicare Part B dataset. First, we carefully extract the categorical feature &#x201C;Provider Type&#x201D; from the dataset. This allows us to generate new, synthetic instances by randomly replicating existing types, thereby increasing the diversity within the minority class. Then, we apply a hybrid resampling method named SMOTE-ENN, which combines the Synthetic Minority Over-sampling Technique (SMOTE) with Edited Nearest Neighbors (ENN). This method aims to balance the dataset by generating synthetic samples and removing noisy data to improve the accuracy of the models. We use six machine learning (ML) models to categorize the instances. When evaluating performance, we rely on common metrics like accuracy, F1 score, recall, precision, and the AUC-ROC curve. We highlight the significance of the Area Under the Precision-Recall Curve (AUPRC) for assessing performance in imbalanced dataset scenarios. The experiments show that Decision Trees (DT) outperformed all the classifiers, achieving a score of 0.99 across all metrics.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Rayene Bounab et al.",
      "keywords": "Computer science; Class (philosophy); Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3385781",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391547627",
      "doi": "10.1109/jbhi.2024.3356580",
      "title": "DeepHealthNet: Adolescent Obesity Prediction System Based on a Deep Learning Framework",
      "abstract": "The global prevalence of childhood and adolescent obesity is a major concern due to its association with chronic diseases and long-term health risks. Artificial intelligence technology has been identified as a potential solution to accurately predict obesity rates and provide personalized feedback to adolescents. This study highlights the importance of early identification and prevention of obesity-related health issues. To develop effective algorithms for the prediction of obesity rates and provide personalized feedback, factors such as height, weight, waist circumference, calorie intake, physical activity levels, and other relevant health information must be taken into account. Therefore, by collecting health datasets from 321 adolescents who participated in Would You Do It! application, we proposed an adolescent obesity prediction system that provides personalized predictions and assists individuals in making informed health decisions. Our proposed deep learning framework, DeepHealthNet, effectively trains the model using data augmentation techniques, even when daily health data are limited, resulting in improved prediction accuracy (acc: 0.8842). Additionally, the study revealed variations in the prediction of the obesity rate between boys (acc: 0.9320) and girls (acc: 0.9163), allowing the identification of disparities and the determination of the optimal time to provide feedback. Statistical analysis revealed that the performance of the proposed deep learning framework was more statistically significant (p 0.001) compared to the other general models. The proposed system has the potential to effectively address childhood and adolescent obesity.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Ji-Hoon Jeong et al.",
      "keywords": "Obesity; Artificial intelligence; Machine learning; Waist; Deep learning; Identification (biology); Computer science; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3356580",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391741368",
      "doi": "10.1109/access.2024.3365368",
      "title": "Could the Use of AI in Higher Education Hinder Students With Disabilities? A Scoping Review",
      "abstract": "Literature reviews on artificial intelligence (AI) have focused on the different applications of AI in higher education, the AI techniques used, and the benefits/risks of the use of AI. One of the greatest potentials of AI is to personalize higher education to the needs of students and offer timely feedback. This could benefit students with disabilities tremendously if their needs are also considered in the development of new AI educational technologies (EdTech). However, current reviews have failed to address the perspective of students with disabilities, which prompts ethical concerns. For instance, AI could treat people with disabilities as outliers in the data and end up discriminating against them. For that reason, this systematic literature review raises the following two questions: To what extent are ethical concerns considered in articles presenting AI applications assessing students (with disabilities) in higher education? What are the potential risks of using AI that assess students with disabilities in higher education? This scoping review highlights the lack of ethical reflection on AI technologies and an absence of discussion and inclusion of people with disabilities. Moreover, it identifies eight risks associated with the use of AI EdTech for students with disabilities. The review concludes with suggestions on how to mitigate these potential risks. Specifically, it advocates for increased attention to ethics within the field, the involvement of people with disabilities in research and development, as well as careful adoption of AI EdTech in higher education.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Oriane Pierr\u00e8s et al.",
      "keywords": "Inclusion (mineral); Learning disability; Perspective (graphical); Psychology; Special education; Engineering ethics; Higher education; Field (mathematics); Medical education; Computer science; Pedagogy; Artificial intelligence; Medicine; Political science; Social psychology; Developmental psychology; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3365368",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2974062192",
      "doi": "10.1109/access.2019.2941796",
      "title": "Prognostically Relevant Subtypes and Survival Prediction for Breast Cancer Based on Multimodal Genomics Data",
      "abstract": "Cancer is one of the deadliest diseases caused by abnormal behaviors of genes that control the cell division and growth. Genomics data and clinical outcomes from multiplatform and heterogeneous sources are used to make clinical decisions for the cancer patients, where both multimodality and heterogeneity impose significant challenges to bioinformatics tools and algorithms. Numerous works have been proposed to overcome these challenges by using sophisticated bioinformatics and machine learning algorithms as either primary or supporting tools. In this paper, we propose a new approach to analyze genomics data from The Cancer Genome Atlas (TCGA) to classify breast cancer patients based on their subtypes and survival rates. Since multiple factors such as estrogen receptor (ER), progesterone receptor (PGR), and human epidermal growth factor receptor 2 (HER2) statuses are involved in breast cancer diagnosis, we used DNA methylation, gene expression (GE), and miRNA expression data by creating a multiplatform network called Multimodal Autoencoders (MAE) classifier to support each data type. Experiment results demonstrate that our approach is promising with high confidence for predicting both breast cancer subtypes and survival rates. In particular, we achieved state-of-the-art results with accuracies of 91% and 86%, respectively for the ER and PGR-based subtype prediction and moderately low accuracy for the HER2-based subtype prediction as well as we perceived reasonably low MSE and positive coefficient of determination (R 2 ) scores in case of survival prediction. Additionally, we created unimodal and multimodal features from each input type and trained decision tree (DT), Naive Bayes (NB), K-nearest neighbors (KNN), logistic regression (LR), support vector machine (SVM), random forest (RF), and gradient boosting trees (GBT) as ML baseline models. Finally, we use the model averaging ensemble of top-3 models to report the final prediction.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Md. Rezaul Karim et al.",
      "keywords": "Breast cancer; Machine learning; Computer science; Artificial intelligence; Progesterone receptor; Genomics; Estrogen receptor; Naive Bayes classifier; Cancer; Oncology; Bioinformatics; Computational biology; Internal medicine; Biology; Medicine; Gene; Support vector machine; Genome; Genetics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2941796",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3109732498",
      "doi": "10.1109/jtehm.2020.3040236",
      "title": "Modeling Large Sparse Data for Feature Selection: Hospital Admission Predictions of the Dementia Patients Using Primary Care Electronic Health Records",
      "abstract": "A growing elderly population suffering from incurable, chronic conditions such as dementia present a continual strain on medical services due to mental impairment paired with high comorbidity resulting in increased hospitalization risk. The identification of at risk individuals allows for preventative measures to alleviate said strain. Electronic health records provide opportunity for big data analysis to address such applications. Such data however, provides a challenging problem space for traditional statistics and machine learning due to high dimensionality and sparse data elements. This article proposes a novel machine learning methodology: entropy regularization with ensemble deep neural networks (ECNN), which simultaneously provides high predictive performance of hospitalization of patients with dementia whilst enabling an interpretable heuristic analysis of the model architecture, able to identify individual features of importance within a large feature domain space. Experimental results on health records containing 54,647 features were able to identify 10 event indicators within a patient timeline: a collection of diagnostic events, medication prescriptions and procedural events, the highest ranked being essential hypertension. The resulting subset was still able to provide a highly competitive hospitalization prediction (Accuracy: 0.759) as compared to the full feature domain (Accuracy: 0.755) or traditional feature selection techniques (Accuracy: 0.737), a significant reduction in feature size. The discovery and heuristic evidence of correlation provide evidence for further clinical study of said medical events as potential novel indicators. There also remains great potential for adaption of ECNN within other medical big data domains as a data mining tool for novel risk factor identification.",
      "year": "2020",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Gavin Tsang et al.",
      "keywords": "Feature selection; Computer science; Machine learning; Dementia; Artificial intelligence; Dimensionality reduction; Heuristic; Big data; Data mining; Population; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2020.3040236",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4229455366",
      "doi": "10.1109/tnsre.2022.3173724",
      "title": "Multiscale Temporal Self-Attention and Dynamical Graph Convolution Hybrid Network for EEG-Based Stereogram Recognition",
      "abstract": "Stereopsis is the ability of human beings to get the 3D perception on real scenarios. The conventional stereopsis measurement is based on subjective judgment for stereograms, leading to be easily affected by personal consciousness. To alleviate the issue, in this paper, the EEG signals evoked by dynamic random dot stereograms (DRDS) are collected for stereogram recognition, which can help the ophthalmologists diagnose strabismus patients even without real-time communication. To classify the collected Electroencephalography (EEG) signals, a novel multi-scale temporal self-attention and dynamical graph convolution hybrid network (MTS-DGCHN) is proposed, including multi-scale temporal self-attention module, dynamical graph convolution module and classification module. Firstly, the multi-scale temporal self-attention module is employed to learn time continuity information, where the temporal self-attention block is designed to highlight the global importance of each time segments in one EEG trial, and the multi-scale convolution block is developed to further extract advanced temporal features in multiple receptive fields. Meanwhile, the dynamical graph convolution module is utilized to capture spatial functional relationships between different EEG electrodes, in which the adjacency matrix of each GCN layer is adaptively tuned to explore the optimal intrinsic relationship. Finally, the temporal and spatial features are fed into the classification module to obtain prediction results. Extensive experiments are conducted on collected datasets i.e., SRDA and SRDB, and the results demonstrate the proposed MTS-DGCHN achieves outstanding classification performance compared with the other methods. The datasets are available at https://github.com/YANGeeg/TJU-SRD-datasets and the code is at https://github.com/YANGeeg/MTS-DGCHN.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Lili Shen et al.",
      "keywords": "Computer science; Electroencephalography; Pattern recognition (psychology); Artificial intelligence; Graph; Convolution (computer science); Adjacency matrix; Artificial neural network; Theoretical computer science; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3173724",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3033072849",
      "doi": "10.1109/access.2020.3000068",
      "title": "Intelligent Diagnosis for Railway Wheel Flat Using Frequency-Domain Gramian Angular Field and Transfer Learning Network",
      "abstract": "The intelligent diagnosis of wheel flat based on vibration image classification is a promising research subject for performance maintenance of railway vehicles. However, the image representation method of vibration signal and classification network construction under small samples have become two obstacles to intelligent diagnosis of wheel flat. This paper presents a novel frequency-domain Gramian angular field (FDGAF) algorithm to encode the vibration signal of wheel flat to featured images. Furthermore, a modified transfer learning network is introduced to classify these featured images under small samples without any involvement of prior knowledge. The proposed FDGAF can calculate the Gramian angular matrix of axle box acceleration signal in frequency domain and assign frequency position dependence to the featured images to preserve original characteristic information. Then, these featured images can be intelligent classified by a transfer learning network under the condition of 30 sample without require of prior knowledge. To verify the efficiency of this proposed method, 12 cases of artificial wheel flats are processed on a scaled railway test rig, and their axle box acceleration signals are collected to obtain visual diagnosis results. The verfication proves that FDGAF is able to obtain accurate diagnostic results with high separability, for separability indexes of FDGAF reaches 10.8, 8.7, 14.9, and 5.8. We anticipate that this method will find use in the performance maintenance of railway vehicles and the improvement of industrial condition monitoring.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Yongliang Bai et al.",
      "keywords": "Computer science; Axle; Artificial intelligence; Vibration; Acceleration; SIGNAL (programming language); Frequency domain; Transfer of learning; Computer vision; Gramian matrix; Field (mathematics); Pattern recognition (psychology); Engineering; Acoustics; Mathematics; Structural engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3000068",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394564209",
      "doi": "10.1109/access.2024.3386032",
      "title": "Event Cameras in Automotive Sensing: A Review",
      "abstract": "Event cameras (EC) represent a paradigm shift and are emerging as valuable tools in the automotive industry, particularly for in-cabin and out-of-cabin monitoring. These cameras capture pixel intensity changes as &#x201D;events&#x201D; with ultra-low latency, making them suitable for real- time applications. In the context of in-cabin monitoring, EC offer solution for driver and passenger tracking, enhancing safety and comfort. For out-of-cabin monitoring, they excel in tracking objects and detecting potential hazards on the road. This article explores the applications, benefits, and challenges of event cameras in these two critical domains within the automotive industry. This review also highlights relevant datasets and methodologies, enabling researchers to make informed decisions tailored to their specific vehicular-technology and place their work in the broader context of EC sensing. Through an exploration of the hardware, the complexities of data processing, and customized algorithms for both in-cabin and out-of-cabin surveillance, this paper outlines a framework encompassing methodologies, tools, and datasets critical for the implementation of event camera sensing in automotive systems.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Waseem Shariff et al.",
      "keywords": "Automotive industry; Computer science; Event (particle physics); Context (archaeology); Complex event processing; Advanced driver assistance systems; Real-time computing; Embedded system; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3386032",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3183053987",
      "doi": "10.1109/access.2021.3094132",
      "title": "Deep Learning and Internet of Things Based Lung Ailment Recognition Through Coughing Spectrograms",
      "abstract": "Coughing analysis stays a region that has gotten meager consideration from AI scientists. This can be credited to a few factors, for example, wasteful auxiliary frameworks, high costs in getting databases, or trouble in building classifiers. The current paper classifies and audits the advancement on coughing sound investigation, AI models, and the information assortment strategies through IoT (Internet of Things) for the grouping of pulmonary sicknesses. Moreover, it proposes a Multi-layered Convolutional Neural Network (Deep Convolutional Neural Network-DCNN) for the arrangement of eight pneumonic infections. The DCNN utilizes otherworldly highlights, cepstral coefficients, chroma highlights, and spectrograms from coughing sound for preparing. To test the viability of the model, a similar report with four standard models was directed on a database of 112 patients gathered from a pediatric office in India through a cloud server and wearable electronic sensors. Results demonstrated that the proposed model accomplished an accuracy of 0.4 on the test segment, which was practically equivalent to recent models proposed in the writing overviewed.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Ajay Kumar et al.",
      "keywords": "Spectrogram; Convolutional neural network; Computer science; The Internet; Deep learning; Artificial neural network; Cloud computing; Artificial intelligence; Audit; Test (biology); Speech recognition; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3094132",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366331238",
      "doi": "10.1109/access.2023.3268064",
      "title": "Security and Privacy for Low Power IoT Devices on 5G and Beyond Networks: Challenges and Future Directions",
      "abstract": "The growth in the use of small sensor devices, commonly known as the Internet of Things (IoT), has resulted in unprecedented amounts of data being generated and captured. With the rapidly growing popularity of personal IoT devices, the collection of personal data through such devices has also increased exponentially. To accommodate the anticipated growth in connected devices, researchers are now investigating futuristic network technologies that are capable of processing large volumes of information at much faster speeds. However, the introduction of innovative network technologies coupled with existing vulnerabilities of personal IoT devices and insufficient device security standards is resulting in new challenges for the security of data collected on these devices. While existing research has focused on the technical aspects of security vulnerabilities and solutions in either network or IoT technologies separately, this paper thoroughly investigates common aspects impacting IoT security on existing and futuristic networks, including human-centric issues and the mechanisms that can lead to loss of confidentiality. By undertaking a comprehensive literature review of existing research, this article has identified five key areas that impact IoT security for futuristic next generation networks. Furthermore, by extensively analysing each area, the article reports on conclusive findings and future research opportunities for IoT privacy and security for the next generation of network technologies.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jonathan Cook et al.",
      "keywords": "Computer science; Internet of Things; Computer security; Information privacy; Internet privacy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3268064",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4383751174",
      "doi": "10.1109/access.2023.3293480",
      "title": "The Influence of Artificial Intelligence on E-Governance and Cybersecurity in Smart Cities: A Stakeholder\u2019s Perspective",
      "abstract": "Artificial intelligence (AI) has been identified as a critical technology of Fourth Industrial Revolution (Industry 4.0) for protecting computer network systems against cyber-attacks, malware, phishing, damage, or illicit access. AI has potential in strengthening the cyber capabilities and safety of nation-states, local governments, and non-state entities through e-Governance. Existing research provides a mixed association between AI, e-Governance, and cybersecurity; however, this relationship is believed to be context-specific. AI, e-Governance, and cybersecurity influence and are affected by various stakeholders possessing a variety of knowledge and expertise in respective areas. To fill this context specific gap, this study investigates the direct relationship between AI, e-Governance, and cybersecurity. Furthermore, this study examines the mediating role of e-Governance between AI and cybersecurity and moderating effect of stakeholders involvement on the relationship between AI, e-Governance, and cybersecurity. The results of PLS-SEM path modeling analysis revealed a partial mediating impact of e-Governance between AI and cybersecurity. Likewise, moderating influence of stakeholders involvement was discovered on the relationship between AI and e-Governance, as well as between e-Governance and cybersecurity. It implies that stakeholders involvement has vital significance in AI and e-Governance because all stakeholders have interest in vibrant, transparent, and secured cyberspace while using e-services. This study provides practical implications for governmental bodies of smart cities for strengthening their cybersecurity measures.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Syed Asad Abbas Bokhari et al.",
      "keywords": "Cyberspace; Corporate governance; Context (archaeology); Computer security; Cybercrime; Business; Stakeholder; Information governance; Data governance; Knowledge management; Public relations; Computer science; Political science; The Internet; Information system; Marketing; Law; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3293480",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392909042",
      "doi": "10.1109/access.2024.3378261",
      "title": "Immature Green Apple Detection and Sizing in Commercial Orchards Using YOLOv8 and Shape Fitting Techniques",
      "abstract": "Detecting and estimating size of apples during the early stages of growth is crucial for predicting yield, pest management, and making informed decisions related to crop-load management, harvest and post-harvest logistics, and marketing. Traditional fruit size measurement methods are laborious and time-consuming. This study employs the state-of-the-art YOLOv8 object detection and instance segmentation algorithm in conjunction with geometric shape fitting techniques on 3D point cloud data to accurately determine the size of immature green apples (or fruitlet) in a commercial orchard environment. The methodology utilized two RGB-D sensors: Intel RealSense D435i and Microsoft Azure Kinect DK. Notably, the YOLOv8 instance segmentation models exhibited proficiency in immature green apple detection, with the YOLOv8m-seg model achieving the highest AP@0.5 and AP@0.75 scores of 0.94 and 0.91, respectively. Using the ellipsoid fitting technique on images from the Azure Kinect, we achieved an RMSE of 2.35 mm, MAE of 1.66 mm, MAPE of 6.15 mm, and an R-squared value of 0.9 in estimating the size of apple fruitlets. Challenges such as partial occlusion caused some error in accurately delineating and sizing green apples using the YOLOv8-based segmentation technique, particularly in fruit clusters. In a comparison with 102 outdoor samples, the size estimation technique performed better on the images acquired with Microsoft Azure Kinect than the same with Intel Realsense D435i. This superiority is evident from the metrics: the RMSE values (2.35 mm for Azure Kinect vs. 9.65 mm for Realsense D435i), MAE values (1.66 mm for Azure Kinect vs. 7.8 mm for Realsense D435i), and the R-squared values (0.9 for Azure Kinect vs. 0.77 for Realsense D435i). This study demonstrated the feasibility of accurately sizing immature green fruit in early growth stages using the combined 3D sensing and shape-fitting technique, which shows promise for improved precision agricultural operations such as optimal crop-load management in orchards.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ranjan Sapkota et al.",
      "keywords": "Sizing; Computer science; Chemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3378261",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2912065849",
      "doi": "10.1109/access.2019.2897003",
      "title": "Kernel Context Recommender System (KCR): A Scalable Context-Aware Recommender System Algorithm",
      "abstract": "Recommender systems are intelligent data mining applications that deal with the issue of information overload significantly. The available literature discusses several methodologies to generate recommendations and proposes different techniques in accordance with users\u2019 needs. The majority of the work in the recommender system domain focuses on increasing the recommendation accuracy by employing several proposed approaches where the main motive remains to maximize the accuracy of recommendations while ignoring other design objectives, such as a user\u2019s an item\u2019s context. The biggest challenge for a recommender system is to produce meaningful recommendations by using contextual user-item rating information. A context is a vast term that may consider various aspects; for example, a user\u2019s social circle, time, mood, location, weather, company, day type, an item\u2019s genre, location, and language. Typically, the rating behavior of users varies under different contexts. From this line of research, we have proposed a new algorithm, namely Kernel Context Recommender System, which is a flexible, fast, and accurate kernel mapping framework that recognizes the importance of context and incorporates the contextual information using kernel trick while making predictions. We have benchmarked our proposed algorithm with pre- and post-filtering approaches as they have been the favorite approaches in the literature to solve the context-aware recommendation problem. Our experiments reveal that considering the contextual information can increase the performance of a system and provide better, relevant, and meaningful results on various evaluation metrics.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Misbah Iqbal et al.",
      "keywords": "Recommender system; Computer science; Context (archaeology); Scalability; Collaborative filtering; Kernel (algebra); Algorithm; Machine learning; Artificial intelligence; Theoretical computer science; Database; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2897003",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4288064604",
      "doi": "10.1109/access.2022.3194152",
      "title": "Ensembling of Efficient Deep Convolutional Networks and Machine Learning Algorithms for Resource Effective Detection of Tuberculosis Using Thoracic (Chest) Radiography",
      "abstract": "Tuberculosis (TB) is a communicable pulmonary disorder and countries with low and middle-income share a higher TB burden as compared to others. The year 2020&#x2013;2021 universally saw a brutal pandemic in the form of COVID-19, that crushed various lives, health infrastructures, programs, and economies worldwide at an unprecedented speed. The gravity of this estimation gets intensified in systems with limited technological advancements. To assist in the identification of tuberculosis, we propose the ensembling of efficient deep convolutional networks and machine learning algorithms that do not entail heavy computational resources. In this paper, the three of the most efficient deep convolutional networks and machine learning algorithms are employed for resource-effective (low computational and basic Imaging requirements) detection of Tuberculosis. The pivotal features extracted from the deep networks are ensembled and subsequently, the machine learning algorithms are used to identify the images based on the extracted features. The said model underwent k-fold cross-validation and achieved an accuracy of 87.90&#x0025; and 99.10&#x0025; with an AUC of 0.94 and 1 respectively in identifying TB infected images from Normal and COVID infected images. Also, the model&#x2019;s error rate, F-score, and youden&#x2019;s index values of 0.0093, 0.9901, and 0.9812 for TB versus COVID identification along with the model&#x2019;s accuracy claim that its use can be beneficial in identifying TB infections amid this COVID-19 pandemic, predominantly in countries with limited resources.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Rajat Mehrrotraa et al.",
      "keywords": "Machine learning; Artificial intelligence; Computer science; Tuberculosis; Deep learning; Convolutional neural network; Algorithm; Identification (biology); Pulmonary tuberculosis; Coronavirus disease 2019 (COVID-19); Medicine; Internal medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3194152",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2954680672",
      "doi": "10.1109/access.2019.2924445",
      "title": "A Machine Learning-Based Approach for Counting Blister Cards Within Drug Packages",
      "abstract": "Nowadays with the rapid development of technologies, machine vision has been used widely in various industries. The main applications of machine vision in industrial product lines are quality control (QC) and quality assurance (QA). The intelligent defects and anomalies recognition throughout the supply chain have come to be an integral part of quality control systems, in particular, in the food and pharmaceutical industries. In these industries, it is a legal requirement in manufacturing processes which can lead to minimizing the total number of defected products as well as maximizing the performance. In this paper, the machine vision has been utilized to monitor and control the proper packaging of drugs in pharmaceutical product lines. The main goal is counting the number of blister cards within a drug package. To tackle this problem, a new model based on object detection, feature extraction, and classification is proposed. Thanks to several strong approaches, such as the Haar cascade, HOG, ORG, Gabor wavelet, Radon transform, KNN, and SVM, and the accuracy over 88% is achieved in our experiments.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Mahdi Bahaghighat et al.",
      "keywords": "Computer science; Machine vision; Quality assurance; Feature extraction; Artificial intelligence; Quality (philosophy); Support vector machine; Pharmaceutical manufacturing; Machine learning; Pattern recognition (psychology); Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2924445",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2969834763",
      "doi": "10.1109/access.2019.2936989",
      "title": "A Machine Learning Metasystem for Robust Probabilistic Nonlinear Regression-Based Forecasting of Seasonal Water Availability in the US West",
      "abstract": "Hydroelectric power generation, water supplies for municipal, agricultural, manufacturing, and service industry uses including technology-sector requirements, dam safety, flood control, recreational uses, and ecological and legal constraints, all place simultaneous, competing demands on the heavily stressed water management infrastructure of the mostly arid American West. Optimally managing these resources depends on predicting water availability. We built a probabilistic nonlinear regression water supply forecast (WSF) technique for the US Department of Agriculture, which runs the largest stand-alone WSF system in the US West. Design criteria included improved accuracy over the existing system; uncertainty estimates that seamlessly handle complex (heteroscedastic, non-Gaussian) prediction errors; integration of physical hydrometeorological process knowledge and domain-specific expert experience; ability to accommodate nonlinearity, model selection uncertainty and equifinality, and predictor multicollinearity and high dimensionality; and relatively easy, low-cost implementation. Some methods satisfied some of these requirements but none met all, leading us to develop a novel, interdisciplinary, and pragmatic prediction metasystem through a carefully considered synthesis of well-established, off-the-shelf components and approaches, spanning supervised and unsupervised machine learning, nonparametric statistical modeling, ensemble learning, and evolutionary optimization, focusing on maintaining but radically updating the principal components regression framework widely used for WSF. Testing this integrated multi-method prediction engine demonstrated its value for river forecasting; USDA adoption is a landmark for transitioning machine learning from research into practice in this field. Its ability to handle all the foregoing design criteria and requirements, which are not unique to WSF, suggests potential for extension to complex probabilistic prediction problems in other fields.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Sean W. Fleming et al.",
      "keywords": "Computer science; Probabilistic logic; Machine learning; Artificial intelligence; Ensemble learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2936989",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366966561",
      "doi": "10.1109/access.2023.3269843",
      "title": "Human Sensing by Using Radio Frequency Signals: A Survey on Occupancy and Activity Detection",
      "abstract": "Applications for human sensing, also known as (human) occupancy detection, include energy management systems for intelligent buildings, intruder detection, e-health systems, the identification of everyday activity, and the monitoring of vital signs. These applications require intelligent decision-making that relies on human sensing. Multiple technologies based on vision, sensors, or radio signals can be used to detect occupancy. Vision-based systems use a multitude of cameras to recognize the human presence, but they are restricted by light availability, line-of-sight coverage, expensive equipment, and privacy concerns. Sensor-based techniques refer to a prospective method that employs various combinations of sensors. These solutions are static and necessitate costly equipment installation and maintenance. Due to technical advancements, radio-based signals, such as WiFi, have been integrated into various forms of infrastructure, including homes, offices, and constructions. Due to how human body movements affect wireless signal propagation, it is possible to detect human motions by analyzing the received wireless signals (such as reflection, diffraction, and scattering). Due to its low cost and non-intrusive nature, wireless-based human activity detection has received substantial attention and become a key topic of study. This article reviews the underlying principles, methodologies, and system architectures of radio-frequency-based occupancy detection systems. We classify the reviewed research studies based on the technical measures and applications they employ. In addition to focusing on the security aspects of occupancy detection and discussing future trends and difficulties, we also discuss practical considerations.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Reza Shahbazian et al.",
      "keywords": "Computer science; Occupancy; Wireless; Wireless sensor network; Real-time computing; Key (lock); Radio-frequency identification; Telecommunications; Computer security; Engineering; Computer network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3269843",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388240348",
      "doi": "10.1109/access.2023.3329573",
      "title": "Virtual Human: A Comprehensive Survey on Academic and Applications",
      "abstract": "As a creative method for virtual human individuals based on multiple fusion technologies such as artificial intelligence, computer graphics, and speech synthesis, virtual human technology has developed rapidly since its birth, and continuous discussions and studies have been conducted in both academia and industry. Starting from the film and television industries, the cross-disciplinary application of virtual human has been continuously recognized and applied in fields such as media, games, and finance. Although virtual human has achieved sufficient development and innovation, it faces many challenges such as emotion recognition, privacy, and security, as well as the uncanny valley effect. This article starts with the development history of virtual human and analyzes the current academic research status and application scenarios in combination with the characteristics, technical architecture, and application of virtual human technology. At the same time, this article sorts out seven mainstream application scenarios of virtual human and analyzes their main advantages and possible future challenges. This article provides a valuable reference for subsequent related research by exploring development trends, application fields, and future research trends in virtual human.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Lipeng Cui et al.",
      "keywords": "Computer science; Virtual actor; Virtual reality; Mainstream; Graphics; Computer graphics; Multimedia; Data science; Human\u2013computer interaction; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3329573",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4290043184",
      "doi": "10.1109/access.2022.3186701",
      "title": "Detecting Elderly Behaviors Based on Deep Learning for Healthcare: Recent Advances, Methods, Real-World Applications and Challenges",
      "abstract": "Machine learning has been applied in healthcare domain for the development of smart devices to improve the life of the elderly persons in the society. Taking care of elderly person in the society is a critical issue that need automation. To proffer solution, many researchers developed deep learning algorithms smart devices for detecting elderly behavior to improve the elderly healthcare. Despite the progress made in the applications of deep learning algorithms in elderly healthcare systems, to the best of the author&#x2019;s knowledge no comprehensive recent development has been published on this interesting research area especially focusing on deep learning. In this paper, we presented a comprehensive recent development on the advances, methods and real world applications on developing smart devices for detecting elderly behavior for use in smart home, smart clinic, smart hospital and smart elderly nursing home for elderly person&#x2019;s healthcare. Theories of the deep learning algorithms, recent development recorded as regard to the applicability of deep learning in elderly healthcare systems and case studies were discussed. A taxonomy based on the data extracted from the applicability of deep learning algorithms in elderly healthcare systems is created to ease pointing out areas that need more attention. The article shows that the deep learning algorithm that received tremendous attention from researchers is convolutional neural network architecture and its variants. To help in future development of the research area, we highlighted the challenges associated to the applicability of deep learning algorithms in elderly healthcare system and pointed out new point of view for future research. The research community can use our review as a benchmark for proposing novel deep learning algorithms based smart devices to detect elderly behavior for elderly healthcare systems. Industries and organizations can use the paper as a guide in selecting machine learning based smart device for detecting elderly behavior for elderly healthcare support.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mubarak Almutairi et al.",
      "keywords": "Deep learning; Health care; Computer science; Artificial intelligence; Convolutional neural network; Data science; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3186701",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393140327",
      "doi": "10.1109/access.2024.3380830",
      "title": "Remote Sensing and Decision Support System Applications in Precision Agriculture: Challenges and Possibilities",
      "abstract": "As the world&#x2019;s population rises, there will be a greater need for food, which will have repercussions on the environment and on crop yields. Increased production, efficient resource allocation, climate change adaptation, and diminished food waste are the four cornerstones of Agriculture 4.0&#x2019;s vision for the future of farming. Agriculture 4.0 makes use of cutting-edge data systems and Internet technology to acquire, analyze, and organize massive amounts of farming facts such as weather reports, soil conditions, market demands, and land usage to better guide farmers&#x2019; decisions and boost their bottom lines. As a result, research on agricultural decision support systems for Agriculture 4.0 has gained significant momentum. Crop monitoring and yield forecasting are two applications where remote sensing has proven useful, and these two areas are intrinsically linked to variations in soil, weather, and biophysical and biochemical factors. Multi- and hyper-spectral data, radar, and lidar imaging are just some of the remote tools that could be employed for crop monitoring and yield forecasting. This paper&#x2019;s goal is to examine some of the difficulties that can arise in the future while using agricultural decision-support platforms in the context of Agriculture 4.0. Addressing these identified obstacles may help future researchers create better decision-assistance systems. This research examines the possibilities, benefits, and drawbacks of each method, as well as how well they work in various agricultural settings. Furthermore, these methods are demonstrated in a variety of strategies that can be effectively employed. In this research, we take a look at some remote sensing techniques developed to increase farm profits while minimizing their impact on the natural world. This research shows how remote sensing information can be used to predict crop yields, evaluate plant nutrient needs and soil nutrient levels, calculate plant moisture levels, and manage weed populations, among other applications.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ibrahim M. Mehedi et al.",
      "keywords": "Precision agriculture; Computer science; Decision support system; Agriculture; Remote sensing; Data science; Artificial intelligence; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3380830",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3109024583",
      "doi": "10.1109/jstars.2020.3039844",
      "title": "Deep-Learning-Based Approach for Estimation of Fractional Abundance of Nitrogen in Soil From Hyperspectral Data",
      "abstract": "One of the vital growth nutrient parameters of crops is soil Nitrogen (N) content. The ability to accurately grasp soil nutrient information is a prerequisite for scientific fertilization within the field of precision agriculture. Information pertaining to soil macronutrients, such as N, may be obtained quickly through hyperspectral imaging techniques. Objective of this research is to explore the use of a deep learning (DL) network to estimate the abundance of urea fertilizer mixed soils for spectroradiometer data. The proposed approach was tested for silt clay and loamy types of soils. Spectral regions of 1899.2 nm for urea and 2195.1 nm for soils were identified as optimum spectral absorption features. The accuracy evaluation was performed using a linear regression model between actual and estimated abundances. At 1899.2 nm, the coefficient of determination (R<sup>2</sup>) for mixed samples of urea and silt clay soil was found to be 0.945, while R<sup>2</sup> for urea mixed loamy soil were 0.954. Similarly, at 2195.1 nm, R<sup>2</sup> obtained 0.953 for urea mixed silt clay soil and 0.944 for urea mixed loamy soil. The results show that the estimated abundances obtained through the derivative analysis for spectral unmixing (DASU)-based DL network facilitated a greater accuracy in comparison to the sole use of DASU. These results were then verified through conventional chemical analysis methods. The outcome of this article determines the abundance of urea mixed soils. Therefore, it is inferred that the hyperspectral imaging technique may be utilized in-situ to assess the agricultural land's soil fertility status.",
      "year": "2020",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Ajay Kumar Patel et al.",
      "keywords": "Loam; Hyperspectral imaging; Soil water; Soil science; Urea; Silt; Environmental science; Chemistry; Artificial intelligence; Computer science; Geology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2020.3039844",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393171344",
      "doi": "10.1109/access.2024.3380438",
      "title": "Data-Driven Intelligent Condition Adaptation of Feature Extraction for Bearing Fault Detection Using Deep Responsible Active Learning",
      "abstract": "The detection of faulty bearings is an essential step in guaranteeing the safe and efficient operation of rotating machinery. Bearings, which also transmit the loads and pressures generated by the machinery, support the rotating shafts. A common method for bearing fault diagnostics is using signal processing techniques. In terms of accuracy, dependability, and sensitivity to various fault types and severity levels, these techniques do, however, have significant limits. To address these limitations, practitioners often integrate signal processing with advanced techniques like machine learning and data analytics to enhance diagnostic accuracy, reliability, and overall effectiveness in bearing fault detection and predictive maintenance. Exploration of various models has demonstrated enhanced results in managing nonlinear data to a certain degree; however, these models face challenges when dealing with intricately complex patterns. Moreover, CNNs can automatically learn relevant features from raw sensor data, capturing intricate patterns and relationships in the data without the need for manual feature engineering. CNNs can be optimized for scalability and real-time processing, essential for applications requiring quick decisions and computationally less expensive for large datasets compared to other models. An optimized one-dimensional Convolutional Neural Network (1D CNN) using different kernel sizes is proposed for predicting and finding bearing problems to overcome these constraints. This method creates a feature vector by applying many filters of various sizes to the input signal. Using the created feature vector, the input signal can be divided into many categories, such as healthy or unhealthy. In comparison to other methods, the proposed technology performs better and offers a high accuracy of 99.52% in bearing fault identification. The 1D CNN model with multiple kernel sizes excels in preserving data structure during dimensionality reduction, as confirmed by comparing t-Distributed Stochastic Neighbor Embedding plots. Particularly, the optimized 1D CNN with multiple kernel sizes accurately classifies faults with minimal errors, showcasing its fault classification proficiency compared with the other state-of-the-art methods. The visualization underscores the methodology&#x2019;s efficacy in discerning intricate fault patterns within the data.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "T R Mahesh et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Feature extraction; Fault detection and isolation; Machine learning; Feature engineering; Bearing (navigation); Support vector machine; Signal processing; Deep learning; Pattern recognition (psychology); Feature (linguistics); Fault (geology); Data mining; Kernel (algebra); Digital signal processing; Actuator",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3380438",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384080276",
      "doi": "10.1109/access.2023.3294473",
      "title": "Application of Entropy for Automated Detection of Neurological Disorders With Electroencephalogram Signals: A Review of the Last Decade (2012\u20132022)",
      "abstract": "An automated Neurological Disorder detection system can be considered as a cost-effective and resource efficient tool for medical and healthcare applications. In automated Neurological Disorder detection, electroencephalograms are commonly used, but their low signal intensity and nonlinear features are difficult to analyze visually. A promising approach for processing of electroencephalogram signals is the concept of entropy, a nonlinear signal processing method to measure the chaos in the signal. The aim of this study was to find out the effective entropy measures and the machine learning approaches that produced promising output. Using Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines as our method, we have identified 84 studies published between 2012 and 2022 that has investigated epilepsy, Parkinson&#x2019;s disease, autism, Attention Deficit Hyperactive disorder, schizophrenia, Alzheimer&#x2019;s disease, depression, and alcohol use disorder with machine learning approaches considering entropy measures. We show that Support Vector Machines was the most commonly used machine learning model, with consistent performance in most of the studies whereas sample entropy was the most commonly used entropy measure, followed by the approximate entropy. For epilepsy detection, the most used entropy feature was the log energy entropy, whereas the multi-scale entropy was commonly used for Alzheimer&#x2019;s Disease, approximate and sample entropy used for Parkinson&#x2019;s Disease, multi scale and Shannon entropy applied for autism, approximate and Shannon entropy used for attention deficit hyperactive disorder, sample entropy used for depression, approximate and spectral entropy adopted for schizophrenia, and the approximate and sample entropy employed for alcohol use disorder. According to the majority of the studies, there is growing concern about the increase in neuro patients and the heavy resource burden that is associated with their prevalence and diagnosis. Based on these studies, we conclude that Computer-Aided Design systems would be economically advantageous in detecting Neurological Disorders. To incorporate Computer-Aided Design system into the mainstream health care system, future research could focus on multi-modal approaches to the disorder and its interpretation and explanation. We believe this is the first review that has combined the electroencephalograms, entropy, and automated detection possibility of the 8 distinct neurological disorders. The study is limited to the papers that used accuracy as their performance evaluation metric. The findings and synthesis of previous studies provides a clear pathway that identifies the entropy approach as a practical solution for automated detection of neurological disorder using electroencephalograms with potential applications in other kinds of signal analysis.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "S. Janifer Jabin Jui et al.",
      "keywords": "Electroencephalography; Computer science; Entropy (arrow of time); Neuroscience; Artificial intelligence; Pattern recognition (psychology); Psychology; Physics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3294473",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366205468",
      "doi": "10.1109/access.2023.3267964",
      "title": "A Survey of Federated Learning From Data Perspective in the Healthcare Domain: Challenges, Methods, and Future Directions",
      "abstract": "Recent advances in deep learning (DL) have shown that data-driven insights can be used in smart healthcare applications to improve the quality of life for patients. DL needs more data and diversity to build a more accurate system. To satisfy these requirements, more data need to be pooled at the centralized server to train the model deeply, but the process of pooling faces privacy and regulatory challenges. To settle them, the concept of sharing model learning rather than sharing data through federated learning (FL) is proposed. FL creates a more reliable system without transferring data to the server, resulting in the right system with stronger security and access rights to data that protect privacy. This research aims to (1) provide a literature review and an in-depth study on the roles of FL in the fields of healthcare; (2) highlight the effectiveness of current challenges facing standardized FL, including statistical data heterogeneity, privacy and security concerns, expensive communications, limited resources, and efficiency; and (3) present lists of open research challenges and recommendations for future FL for the academic and industrial sectors in telemedicine and remote healthcare applications. An extensive review of the literature on FL from a data-centric perspective was conducted. We searched the Science Direct, IEEE Xplore, and PubMed databases for publications published between January 2018 and January 2023. A new crossover matching between the approaches that solve or mitigate all types of skewed data has been proposed to open up opportunities to other researchers. In addition, a list of various applications was organized by learning application task types such as prediction, diagnosis, and classification. We think that this study can serve as a helpful manual for academics and industry professionals, giving them guidance and important directions for future studies.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zahraa K. Taha et al.",
      "keywords": "Computer science; Data sharing; Health care; Information privacy; Data science; Pooling; Knowledge management; Computer security; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3267964",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390932995",
      "doi": "10.1109/access.2024.3354794",
      "title": "Optimization of Deep Belief Network Based on Sparrow Search Algorithm for Rolling Bearing Fault Diagnosis",
      "abstract": "This study addresses the randomness of training parameters in the Deep Belief Network (DBN) and proposes an optimization method for rolling bearing fault diagnosis based on the Sparrow Search Algorithm (SSA). SSA is employed to globally optimize the structural and training parameters of the DBN network, effectively resolving the challenge of parameter determination. Simultaneously, vibration signals are extracted from multiple dimensions to capture different types of fault features. These features are derived through Wavelet Transformation (WT) for noise reduction and Intrinsic Mode Functions (IMFs) extraction through Ensemble Empirical Mode Decomposition (EEMD). The fusion of time-domain and frequency-domain dimensional features forms a multidimensional feature set. This comprehensive feature set optimizes the parameters of the deep learning network and significantly improves the accuracy and effectiveness of rolling bearing fault diagnosis. With a remarkable recognition accuracy of 99.17&#x0025;, this approach outperforms conventional feature sets and mainstream diagnostic methods such as PSO-DBN and SSA-SVM while maintaining high levels of generalization and stability. The introduction of this method represents a significant breakthrough in the field of rolling bearing fault diagnosis.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Donghao Xu et al.",
      "keywords": "Deep belief network; Computer science; Hilbert\u2013Huang transform; Artificial intelligence; Fault (geology); Pattern recognition (psychology); Feature extraction; Feature (linguistics); Bearing (navigation); Wavelet; Algorithm; Deep learning; White noise",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3354794",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313855839",
      "doi": "10.1109/access.2023.3235619",
      "title": "An Investigation of Exhaust Gas Temperature of Aircraft Engine Using LSTM",
      "abstract": "A significant obstacle to creating efficient machine health monitoring systems is estimating performance degradation in dynamic systems, like aero plane engines. In exceedingly complex systems with many components, states, and parameters, conventional model-based and data-driven methods fall short of producing satisfactory results. While traditional methods had several drawbacks, deep learning has emerged as a viable computational tool for dynamic system prediction. In order to track system deterioration and estimate the EGT, a novel technique based on the Long Short-Term Memory (LSTM) network, (an architecture created to find the hidden patterns hidden in time series data) is provided in this research. The health monitoring information of aircraft turbofan engines is used to assess the effectiveness of the proposed strategy. As a result of this network&#x2019;s ability to recognize the input data as a real-time series, the output in the following step can be predicted. Results of the suggested study show a significant ability to anticipate the output in the following time step. Additionally, the proposed model has a shorter learning curve and is more accurate.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Shafi Ullah et al.",
      "keywords": "Turbofan; Computer science; Obstacle; Time series; Series (stratigraphy); Deep learning; Data-driven; Artificial intelligence; Data modeling; Machine learning; Real-time computing; Automotive engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3235619",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3036083732",
      "doi": "10.1109/tpami.2020.3015420",
      "title": "SensitiveNets: Learning Agnostic Representations with Application to Face Images",
      "abstract": "This work proposes a novel privacy-preserving neural network feature representation to suppress the sensitive information of a learned space while maintaining the utility of the data. The new international regulation for personal data protection forces data controllers to guarantee privacy and avoid discriminative hazards while managing sensitive data of users. In our approach, privacy and discrimination are related to each other. Instead of existing approaches aimed directly at fairness improvement, the proposed feature representation enforces the privacy of selected attributes. This way fairness is not the objective, but the result of a privacy-preserving learning method. This approach guarantees that sensitive information cannot be exploited by any agent who process the output of the model, ensuring both privacy and equality of opportunity. Our method is based on an adversarial regularizer that introduces a sensitive information removal function in the learning objective. The method is evaluated on three different primary tasks (identity, attractiveness, and smiling) and three publicly available benchmarks. In addition, we present a new face annotation dataset with balanced distribution between genders and ethnic origins. The experiments demonstrate that it is possible to improve the privacy and equality of opportunity while retaining competitive performance independently of the task.",
      "year": "2020",
      "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Aythami Morales et al.",
      "keywords": "Computer science; Discriminative model; Feature learning; Representation (politics); Machine learning; Feature (linguistics); Artificial intelligence; Identity (music); Feature vector; Adversary; Process (computing); Information sensitivity; Data mining; Computer security",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tpami.2020.3015420",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388430322",
      "doi": "10.1109/access.2023.3330465",
      "title": "An Explainable AI System for Medical Image Segmentation With Preserved Local Resolution: Mammogram Tumor Segmentation",
      "abstract": "Medical image segmentation aims to identify important or suspicious regions within medical images. However, many challenges are usually faced while developing networks for this type of analysis. First, preserving the original image resolution is of utmost importance for this task where identifying subtle features or abnormalities can significantly impact the accuracy of diagnosis. While introducing the dilated convolution improves the resolution of the convolutional neural network (CNN), it is not without shortcoming, i.e., the loss of local spatial resolution due to increased kernel sparsity in checkboard patterns. To address this shortcoming, we conceptualize a double-dilated convolution module for maintaining local spatial resolution while improving the receptive field size. Then, this approach is applied, as a proof-of-work, to tumor segmentation task in mammograms. In addition, our proposal also tackles the class imbalance problem, originating at the pixel level of the mammogram screenings, by identifying and selecting the best candidate among a number of potential loss functions to facilitate mass segmentation. We also carry out quantitative and qualitative evaluations of the interpretability of our proposal by leveraging Grad-CAM (Gradient weighted Class Activation Map). We also present a comparative performance evaluation with existing explainable techniques tailored for segmenting images. Moreover, an empirical assessment on lesion segmentation is conducted on mammogram samples from the INBreast dataset, both with and without incorporating our envisaged dilation module into CNN. The obtained results elucidate the effectiveness of our proposal based on mass segmentation performance measures, such as Dice similarity and Miss Detection rate. Our analysis also promotes using the Tversky Loss function in training pixel-imbalanced data and integrating Grad-CAM for explaining image segmentation results.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Aya Farrag et al.",
      "keywords": "Artificial intelligence; Image segmentation; Computer vision; Computer science; Segmentation; Scale-space segmentation; Segmentation-based object categorization; Region growing; Image resolution; Resolution (logic); Pattern recognition (psychology); Medical imaging",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3330465",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390905307",
      "doi": "10.1109/access.2024.3354826",
      "title": "Enhancing the Quality and Authenticity of Synthetic Mammogram Images for Improved Breast Cancer Detection",
      "abstract": "Breast cancer is widespread throughout the world and can be cured if diagnosed early. Mammography is an irreplaceable and critical technique in modern medicine that serves as a foundation for the detection of breast cancer. In medical imaging, the reliability of synthetic mammogram images is produced by deep convolutional generative adversarial networks (DCGAN). Human validation to assess the quality of synthetic images to examine and calculate the perceptual variations between synthetic images and their real-world counterparts is a difficult task. Thus, this research focused on improving the quality and authenticity of synthetic mammogram images. For this, we explored and identified a new research gap because radiologists consistently expressed much higher confidence levels in real mammogram images in their assessment process. This research highlights the key difference between synthetic and real mammograms by defining mean scores. The defined mean identifies a large gap, with real mammographic images receiving an average score of 0.73 and a synthetic score of 0.31. A statistical analysis was performed, which produced a T-statistic of -6.35, a p-value less than 0.001, and a 95&#x0025; confidence interval ranging from -0.50 to -0.28. These results have a wide range of implications. It emphasizes the urgent need for further improvements in the generative model, improving the legitimacy and caliber of synthetic mammogram images. Our research highlights how crucial it is to incorporate synthetic images into clinical practice with caution and thought. Ethical considerations must encompass the potential consequences of relying on synthetic data in medical decision-making, along with concerns related to diagnostic accuracy and patient safety.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Dilawar Shah et al.",
      "keywords": "Mammography; Artificial intelligence; Computer science; Synthetic data; Breast cancer; Medical imaging; Machine learning; Medical physics; Medicine; Cancer",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3354826",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387247714",
      "doi": "10.1109/access.2023.3321152",
      "title": "Open Pose Mask R-CNN Network for Individual Cattle Recognition",
      "abstract": "Cattle&#x2019;s individual identification plays a crucial role in effectively managing large farms. To enhance agricultural efficiency, promote the digital transformation of animal husbandry, and improve animal welfare, it is essential to employ advanced identification technologies capable of real-time monitoring of cattle individual. This paper introduces a novel network called Open Pose Mask R-CNN (OP-Mask R-CNN) for individual cattle identification, which combines Open Pose with the Mask R-CNN network. Three key strategies are presented to improve the identification of individual cattle. First, optimize the number of convolutional layers in the Mask R-CNN backbone network, i.e., ResNet101. Second, introduce an Open Pose-based bovine skeleton feature extraction method. Finally, construct a fusion mechanism that combines the attention module, the convolutional block attention module (CBAM), the open pose module, and the ResNet101. Experimental results demonstrate that our proposed method achieves a 5.6&#x0025; increase in recognition accuracy and improves recognition speed compared to the original Mask R-CNN model. This work strikes a balance between accuracy and complexity, facilitating the development of a lightweight bovine individual recognition technique.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jianping Wang et al.",
      "keywords": "Computer science; Artificial intelligence; Computer vision; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3321152",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323767272",
      "doi": "10.1109/access.2023.3255110",
      "title": "On the Role of Thermal Imaging in Automotive Applications: A Critical Review",
      "abstract": "For decades, the number of automobiles in urban areas around the world has been increasing.&#13;\\nIt causes serious challenges such as traffic congestion, accidents, and pollution, which have a social,&#13;\\neconomic, and environmental impact on widespread urban cities. To overcome these challenges, we need to&#13;\\nexplore smart AI-based perception systems for vehicular applications. Such types of systems can provide&#13;\\nimproved situational awareness to the driver and generate early alarm about upcoming obstacles and road&#13;\\nincidents. In this study, we have presented the effective use of uncooled thermal IR sensors for designing&#13;\\nsmart thermal perception systems as an alternative to CMOS visible imaging by presenting state-of-the-art&#13;\\nstudies for in-cabin and out-cabin vehicular applications with potential long-term benefits for the automotive&#13;\\nindustry. The key rationale for selecting thermal IR sensors over conventional image sensors is that visible&#13;\\ncameras are highly dependent on lighting conditions and performance is degraded significantly in lowlighting scenarios and harsh weather conditions. Contrary to this, thermal sensors remain largely unaffected&#13;\\nby external lighting conditions or most environmental conditions, making it a perfect optical sensor choice&#13;\\nfor all-weather and harsh environmental conditions. This study presents a review of the current state of the&#13;\\nart for automotive thermal imaging with a focus on the contributions and advances achieved by the EUfunded project \u2018HELIAUS\u2019 in the domain of AI-based thermal imaging pipelines for safer and reliable road&#13;\\njourneys.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Muhammad Ali Farooq et al.",
      "keywords": "Automotive industry; Computer science; Situation awareness; SAFER; Night vision; Computer security; Engineering; Artificial intelligence; Aerospace engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3255110",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226081179",
      "doi": "10.1109/access.2022.3170037",
      "title": "Open-Source Face Recognition Frameworks: A Review of the Landscape",
      "abstract": "From holistic low-dimension feature-based segmentation to deep polynomial neural networks, Face Recognition (FR) accuracy has increased dramatically since its early days. The advancement and maturity of open-source FR frameworks have contributed to this trend, influencing many open-source research publications available in the public domain. The availability of modern accelerated computing capabilities through Graphics Process Unit (GPU) technology has played a substantial role in advancing open-source FR capabilities. The evolution and success of the open-source DL algorithms on FR, leveraging GPU technologies, have benefited from open datasets, resulting in many FR open-source implementations. This paper reviews the landscape of open-source FR frameworks, covering components of the FR pipeline across open datasets, face detection, face alignment, face representation, identification and verification, and deployment environments. We also discuss the current challenges and emerging directions in FR research.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "David Wanyonyi et al.",
      "keywords": "Computer science; Open source; Implementation; Pipeline (software); Software deployment; Data science; Facial recognition system; Open research; Face (sociological concept); Domain (mathematical analysis); Identification (biology); Artificial intelligence; Machine learning; Software engineering; Pattern recognition (psychology); World Wide Web; Software; Operating system",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3170037",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3154059647",
      "doi": "10.1109/access.2021.3074127",
      "title": "Bull Sperm Tracking and Machine Learning-Based Motility Classification",
      "abstract": "Sperm motility measurement using computer assisted sperm analysis (CASA) has been widely accepted as a substitute for manual measurement but still faces several challenges. In the tracking phase, tracking errors caused by detection failure often occur when measuring fresh bull semen. Tracking errors occur for two reasons: (1) the sperm move very fast, which makes them appear blurry, and (2) partial occlusion, which frequently occurs. This study proposes the mean angle of sperm motion and Tracking-Grid to predict the position of the sperm that failed to be detected. The Tracking-Grid has also been found useful in tracking fast-moving sperm. The proposed methods reduce identity switch (ID-switch) and achieve a multi-object tracking overall accuracy (MOTAL) of 73.2. The MOTAL result exhibits 5&#x0025; less ID-switch and is 15.6 MOTAL points higher than state-of-the-art simple online and real-time tracking with a deep association metric (Deep SORT). The speed achieved is 41.18 frames per second (fps), which is 1.8 times faster than Deep SORT. In sperm motility classification, most researchers use one or several CASA parameters with a static threshold value. Such a method is effective for motile-progressive sperm classification but is less reliable for identifying non-motile-progressive sperm such as vibrating and floating sperm. This study proposes a machine learning-based motility classifier using a support vector machine with three CASA parameters: curvilinear velocity (VCL), straight-line velocity (VSL), and linearity (LIN), which we call the bull sperm progressive motility classifier (BSPMC<sub>svm3casa</sub>). Experimental results show that BSPMC<sub>svm3casa</sub>&#x2019;s mean accuracy is 92.08&#x0025;, which is 2.51&#x2013;9.67 points higher than other classification methods.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Priyanto Hidayatullah et al.",
      "keywords": "Sperm; Sperm motility; Artificial intelligence; Computer science; Computer vision; Classifier (UML); Pattern recognition (psychology); Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3074127",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394862578",
      "doi": "10.1109/access.2024.3389707",
      "title": "An Integrated Two-Layered Voting (TLV) Framework for Coronary Artery Disease Prediction Using Machine Learning Classifiers",
      "abstract": "Cardiovascular problems have emerged as a significant concern, adversely impacting individuals across all age groups. Several recent research studies have used Machine learning (ML) techniques to design decision-making systems for the tremendous data in the medical sector. Although these works obtained promising results, most of the studies focused on small datasets. Since the size of the dataset affects algorithm performance, this study used two datasets, such as Kaggle&#x2019;s heart disease dataset of over 70,000 records and UCI&#x2019;s heart disease dataset of 1025 records. In addition to the old features the Pulse Pressure (PP), the Body Mass Index (BMI), and the Mean Arterial Pressure (MAP), three new features are introduced to improve the results. This paper proposes the TLV (Two-Layer Voting) model, which is an ensemble method of hard and soft voting. As part of layer 1, features are shortlisted by soft and hard voting using three statistical methods, including the ANOVA f-test, Chi-squared test, and Mutual Information. In layer 2, soft voting and hard voting performance are compared, which incorporates Multi-Layer Perceptron, Decision Tree, Support Vector Classifier, and Random Forest algorithms. Classification algorithms are hyper-tuned using the GridSearchCV method in the second layer. Using UCI&#x2019;s heart disease dataset and Kaggle&#x2019;s CVD dataset, the proposed TLV methodology with soft voting provided the highest accuracy of 99.03% and 88.09%, respectively. The proposed model significantly outperforms existing CAD disease prediction studies.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "D. Yaso Omkari et al.",
      "keywords": "Computer science; Voting; Coronary artery disease; Machine learning; Artificial intelligence; Cardiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3389707",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4365420325",
      "doi": "10.1109/ojcoms.2023.3265425",
      "title": "Distributed Intelligence in Wireless Networks",
      "abstract": "The cloud-based solutions are becoming inefficient due to considerably large time delays, high power consumption, and security and privacy concerns caused by billions of connected wireless devices and typically zillions of bytes of data they produce at the network edge. A blend of edge computing and Artificial Intelligence (AI) techniques could optimally shift the resourceful computation servers closer to the network edge, which provides the support for advanced AI applications (e.g., video/audio surveillance and personal recommendation system) by enabling intelligent decision making on computing at the point of data generation as and when it is needed, and distributed Machine Learning (ML) with its potential to avoid the transmission of the large dataset and possible compromise of privacy that may exist in cloud-based centralized learning. Besides, the deployment of AI techniques to redesign end-to-end communication is attracting attention to improve communication performance. Therefore, the interaction of AI and wireless communications generates a new concept, named native AI wireless networks. In this paper, we conduct a comprehensive overview of recent advances in distributed intelligence in wireless networks under the umbrella of native AI wireless networks, with a focus on the design of distributed learning architectures for heterogeneous networks, on AI-enabled edge computing, on the communication-efficient technologies to support distributed learning, and on the AI-empowered end-to-end communications. We highlight the advantages of hybrid distributed learning architectures compared to state-of-the-art distributed learning techniques. We summarize the challenges of existing research contributions in distributed intelligence in wireless networks and identify potential future opportunities.",
      "year": "2023",
      "journal": "IEEE Open Journal of the Communications Society",
      "authors": "Xiaolan Liu et al.",
      "keywords": "Computer science; Wireless network; Server; Edge computing; Cloud computing; Wireless; Distributed computing; Artificial intelligence; Computer network; Enhanced Data Rates for GSM Evolution; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcoms.2023.3265425",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385975767",
      "doi": "10.1109/access.2023.3306452",
      "title": "AI-Enabled Trust in Distributed Networks",
      "abstract": "Cybersecurity, as a crucial aspect of the information society, requires significant attention. Fortunately, the concept of trust, originating from the field of sociology, has been under extensive research in order to enhance cybersecurity by evaluating the trustworthiness of nodes with artificial intelligence (AI) techniques in distributed networks (DNs). However, the scalability issues faced by AI-enabled trust hinder its integration with the DNs. Currently, there is a lack of a comprehensive review article that explores the current state of AI-enabled trust development applications. This paper aims to address this gap by providing a review of the state-of-the-art AI-enabled trust in DNs. This review focuses on the concept of trust and how it can be facilitated through AI, particularly utilizing machine learning and deep learning methods. Additionally, the paper provides a comprehensive comparison and analysis of three key domains in the field of AI-enabled trust: trust management (TM), intrusion detection system (IDS), and recommender systems (RS). Some open problems and challenges that currently exist in the field are manifested, and some suggestions for future work are presented.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zhiqi Li et al.",
      "keywords": "Computer science; Distributed computing; Computer network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3306452",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388952969",
      "doi": "10.1109/access.2023.3336289",
      "title": "Multimodal Analysis of Unbalanced Dermatological Data for Skin Cancer Recognition",
      "abstract": "To date, skin cancer is the most commonly diagnosed form of cancer in humans and is one of the leading causes of death in cancer patients. AI technologies can match and exceed visual analysis methods in accuracy, but they carry the risk of a false negative response when a malignant pigmented lesion can be recognized as benign. Possible ways to improve accuracy and reduce the risk of false negatives are to analyze heterogeneous data, combine different preprocessing methods, and use modified loss functions to eliminate the negative impact of unbalanced dermatological data. The article proposes a multimodal neural network system with a modified cross-entropy loss function that is sensitive to unbalanced heterogeneous dermatological data. The novelty of the proposed system lies in the emerging synergy when using methods to improve the quality of intelligent systems, due to which there is a significant reduction in the number of false negative predictions and an increase in the accuracy of skin cancer recognition. Preliminary cleaning of hair structures on visual data, as well as parallel analysis of heterogeneous dermatological data using a multimodal neural network system sensitive to unbalanced data, were used as methods to improve accuracy. The recognition accuracy for 10 diagnostic categories for the proposed intelligent system was 85.20&#x0025;. The introduction of weighting factors made it possible to reduce the number of false negative forecasts, as well as increase the accuracy by 1.99-4.28 percentage points compared to the original multimodal systems.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Pavel Lyakhov et al.",
      "keywords": "Computer science; Preprocessor; Artificial intelligence; Weighting; Pattern recognition (psychology); Artificial neural network; Skin cancer; Machine learning; Cancer; Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3336289",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394897068",
      "doi": "10.1109/access.2024.3390234",
      "title": "A Novel Framework for Robust Bearing Fault Diagnosis: Preprocessing, Model Selection, and Performance Evaluation",
      "abstract": "Diagnosing bearing faults is crucial for maintaining, ensuring reliability, and extending the lifespan of rotary machines. This process helps prevent unexpected downtime in industries, ultimately reducing economic losses caused by the failure of rotary machines. Timely diagnosis of bearing faults is crucial to prevent catastrophic breakdowns, minimize maintenance expenses, and ensure uninterrupted productivity. With industries evolving rapidly and machines operating in increasingly diverse conditions, traditional fault detection methods face limitations. Despite extensive research in recent decades, there is an ongoing need for further advancements to enhance existing fault diagnosis techniques. This study addresses these challenges by utilizing advanced machine learning algorithms Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Recurrent Neural Network (RNN), Gated Recurrent Unit Network (GRU), Bidirectional LSTM, and for precise bearing fault diagnosis. Leveraging the CWRU dataset encompassing diverse fault classes and machine conditions, a comprehensive data preprocessing pipeline was executed to clean, normalize, and augment the dataset, ensuring model readiness and enhancing performance. Performance analysis revealed the proposed models achieving remarkable accuracies on the CWRU dataset. The CNN and LSTM models attained accuracies of 95%, while the RNN and GRU models achieved accuracies of <inline-formula> <tex-math notation=\"LaTeX\">$97\\%$ </tex-math></inline-formula>. Additionally, the Bidirectional LSTM model yielded an accuracy of 96%. These results signify substantial advancements in bearing fault diagnosis, emphasizing the models&#x2019; efficacy in accurately detecting and categorizing faults within the 10 classes of the CWRU dataset. The findings underscore the potential of advanced machine learning techniques in revolutionizing fault diagnosis for rotary machines, addressing the persistent need for more robust and accurate diagnostic methodologies.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Faisal Althobiani",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Convolutional neural network; Recurrent neural network; Fault (geology); Downtime; Deep learning; Preprocessor; Fault detection and isolation; Artificial neural network; Reliability engineering; Data mining; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3390234",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392902205",
      "doi": "10.1109/access.2024.3378515",
      "title": "HADE: Exploiting Human Action Recognition Through Fine-Tuned Deep Learning Methods",
      "abstract": "Human Action Recognition (HAR) is a vital area of computer vision with diverse applications in security, healthcare, and human-computer interaction. Addressing the challenges of HAR, particularly in dynamic and complex environments, is essential to advancing this field. The strength of the HADE framework is its carefully curated dataset, which was primarily derived from smartphone camera footage. This dataset encompasses a wide range of human actions captured in various settings, providing a robust foundation for training our novel HAR models, HADE I and HADE II. These models have been specifically designed and optimized for parallel processing on GPUs, showing significant improvements in the efficiency of both training and inference processes. Through a comprehensive evaluation, the HADE framework demonstrated a remarkable improvement in HAR accuracy, achieving 83.57&#x0025; accuracy on our custom dataset. This marks a considerable enhancement over existing methodologies and underscores the efficacy of the HADE approach in accurately interpreting complex human actions. The framework&#x2019;s potential applicability in healthcare in the domain of neurological patient care is particularly noteworthy, where it can aid in early detection and facilitate personalized treatment plans. Future research should focus on expanding the range of actions covered by HAR and exploring avenues for real-time processing. The introduction of the HADE framework not only makes a substantial contribution to the field of computer vision but also paves the way for its practical application across various sectors.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "M. Fazuan Abdul Karim et al.",
      "keywords": "Computer science; Field (mathematics); Inference; Convolutional neural network; Artificial intelligence; Data science; Machine learning; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3378515",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3019266337",
      "doi": "10.1109/access.2020.2989713",
      "title": "Mal-Light: Enhancing Lysine Malonylation Sites Prediction Problem Using Evolutionary-based Features",
      "abstract": "Post Translational Modification (PTM) is considered an important biological process with a tremendous impact on the function of proteins in both eukaryotes, and prokaryotes cells. During the past decades, a wide range of PTMs has been identified. Among them, malonylation is a recently identified PTM which plays a vital role in a wide range of biological interactions. Notwithstanding, this modification plays a potential role in energy metabolism in different species including Homo Sapiens. The identification of PTM sites using experimental methods is time-consuming and costly. Hence, there is a demand for introducing fast and cost-effective computational methods. In this study, we propose a new machine learning method, called Mal-Light, to address this problem. To build this model, we extract local evolutionary-based information according to the interaction of neighboring amino acids using a bi-peptide based method. We then use Light Gradient Boosting (LightGBM) as our classifier to predict malonylation sites. Our results demonstrate that Mal-Light is able to significantly improve malonylation site prediction performance compared to previous studies found in the literature. Using Mal-Light we achieve Matthew's correlation coefficient (MCC) of 0.74 and 0.60, Accuracy of 86.66% and 79.51%, Sensitivity of 78.26% and 67.27%, and Specificity of 95.05% and 91.75%, for Homo Sapiens and Mus Musculus proteins, respectively. Mal-Light is implemented as an online predictor which is publicly available at: (http://brl.uiu.ac.bd/MalLight/).",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Md. Wakil Ahmad et al.",
      "keywords": "Homo sapiens; Computer science; Artificial intelligence; Classifier (UML); Posttranslational modification; Computational biology; Boosting (machine learning); Machine learning; Biology; Biochemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2989713",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388819883",
      "doi": "10.1109/access.2023.3334434",
      "title": "Brain Tumor Categorization and Retrieval Using Deep Brain Incep Res Architecture Based Reinforcement Learning Network",
      "abstract": "The categorization and retrieval of brain tumors using Magnetic Resonance Imaging (MRI) is a difficult but necessary process for brain tumor diagnosis. In this study, a reinforcement learning agent is proposed that can interact with an environment that includes brain tumor images and retrieve and categorize the most comparable images to an unknown query image. This article proposes a unique fuzzy and Deep Learning (DL)-based Reinforcement Learning (RL) strategy for categorizing three types of brain tumors as well as no tumors. Deep Brain Incep Res Architecture 2.0 based Reinforcement Learning Network (DBIRA2.0-RLN), the proposed Convolutional Neural Network (CNN)-based technique, benefits from a novel architecture in which brain tumor descriptors are established using the inception block and effective skip-connection mapping arrangement. To improve the efficiency of DBIRA2.0-RLN, improved samples are created by training and testing the system with a fuzzy logic-based technique. To lower the dimension of the descriptor vector for improved image categorization and retrieval, the descriptor vector obtained from DBIRA2.0 is binary coded using Multilinear Principal Component Analysis. DBIRA2.0 produces and preserves brain tumors and no tumor descriptors in several layers, which are then used sequentially in numerous units to construct the final brain tumor categorization and retrieval. The proposed method&#x2019;s output is tested using a dataset, and the accuracy rates obtained for meningioma tumor, glioma tumor, pituitary tumor, and no tumor are 97.1&#x0025;, 98.7&#x0025;, 94.3&#x0025;, and 100&#x0025; respectively, indicating that the proposed approach outperforms the other brain tumor categorization and retrieval approaches used in the literature.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jyotismita Chaki et al.",
      "keywords": "Computer science; Artificial intelligence; Categorization; Reinforcement learning; Convolutional neural network; Pattern recognition (psychology); Brain tumor; Contextual image classification; Deep learning; Block (permutation group theory); Machine learning; Image (mathematics); Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3334434",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225335144",
      "doi": "10.1109/access.2022.3165583",
      "title": "Plant Identification in a Combined-Imbalanced Leaf Dataset",
      "abstract": "Plant identification has applications in ethnopharmacology and agriculture. Since leaves are one of a distinguishable feature of a plant, they are routinely used for identification. Recent developments in deep learning have made it possible to accurately identify the majority of samples in five publicly available leaf datasets. However, each dataset captures the images in a highly controlled environment. This paper evaluates the performance of EfficientNet and several other convolutional neural network (CNN) architectures when applied to a combination of the LeafSnap, Middle European Woody Plants 2014, Flavia, Swedish, and Folio datasets. To normalize the impact of imbalance resulting from combining the original datasets, we used oversampling, undersampling, and transfer learning techniques to construct an end-to-end CNN classifier. We placed greater emphasis on metrics appropriate for a diverse-imbalanced dataset rather than stressing high performance on any one of the original datasets. A model from EfficientNet&#x2019;s family of CNN models achieved a highly accurate F-score of 0.9861 on the combined dataset.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Viraj K. Gajjar et al.",
      "keywords": "Undersampling; Computer science; Classifier (UML); Artificial intelligence; Convolutional neural network; Plant identification; Identification (biology); Oversampling; Machine learning; Transfer of learning; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3165583",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391984636",
      "doi": "10.1109/access.2024.3367719",
      "title": "Enhanced Bitcoin Price Direction Forecasting With DQN",
      "abstract": "In the Bitcoin trading landscape, predicting price movements is paramount. Our study focuses on identifying the key factors influencing these price fluctuations. Utilizing the Pearson correlation method, we extract essential data points from a comprehensive set of 14 data features. We consider historical Bitcoin prices, representing past market behavior; trading volumes, which highlight the level of trading activity; network metrics that provide insights into Bitcoin&#x2019;s blockchain operations; and social indicators: analyzed sentiments from Twitter, tracked Bitcoin-related search trends on Google and on Twitter. These social indicators give us a more nuanced understanding of the digital community&#x2019;s sentiment and interest levels. With this curated data, we forge ahead in developing a predictive model using Deep Q-Network (DQN). A defining aspect of our model is its innovative reward function, tailored for enhancing predicting Bitcoin price direction, distinguished by its multi-faceted reward function. This function is a blend of several critical factors: it rewards prediction accuracy, incorporates confidence scaling, applies an escalating penalty for consecutive incorrect predictions, and includes a time-based discounting to prioritize recent market trends. This composite approach ensures that the model&#x2019;s performance is not only precise in its immediate predictions but also adaptable and responsive to the evolving patterns of the cryptocurrency market. Notably, in our tests, our model achieved an impressive F1-score of 95&#x0025;, offering substantial promise for traders and investors.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Azamjon Muminov et al.",
      "keywords": "Computer science; Cryptocurrency; Econometrics; Computer security; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3367719",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312399320",
      "doi": "10.1109/access.2022.3230282",
      "title": "A Survey of FPGA-Based Vision Systems for Autonomous Cars",
      "abstract": "On the road to making self-driving cars a reality, academic and industrial researchers are working hard to continue to increase safety while meeting technical and regulatory constraints Understanding the surrounding environment is a fundamental task in self-driving cars. It requires combining complex computer vision algorithms. Although state-of-the-art algorithms achieve good accuracy, their implementations often require powerful computing platforms with high power consumption. In some cases, the processing speed does not meet real-time constraints. FPGA platforms are often used to implement a category of latency-critical algorithms that demand maximum performance and energy efficiency. Since self-driving car computer vision functions fall into this category, one could expect to see a wide adoption of FPGAs in autonomous cars. In this paper, we survey the computer vision FPGA-based works from the literature targeting automotive applications over the last decade. Based on the survey, we identify the strengths and weaknesses of FPGAs in this domain and future research opportunities and challenges.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "David Castells\u2010Rufas et al.",
      "keywords": "Field-programmable gate array; Computer science; Automotive industry; Implementation; Latency (audio); Advanced driver assistance systems; Self driving; Strengths and weaknesses; Domain (mathematical analysis); Efficient energy use; Task (project management); Embedded system; Power consumption; Energy consumption; Human\u2013computer interaction; Artificial intelligence; Power (physics); Software engineering; Systems engineering; Telecommunications; Engineering; Transport engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3230282",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3033376681",
      "doi": "10.1109/access.2020.2999899",
      "title": "Performance Analysis of Classification Algorithms on Birth Dataset",
      "abstract": "Generating intuitions from data using data mining and machine learning algorithms to predict outcomes is useful area of computing. The application area of data mining techniques and machine learning is wide ranging including industries, healthcare, organizations, academics etc. A continuous improvement is witnessed due to an ongoing research, as seen particularly in healthcare. Several researchers have applied machine learning to develop decision support systems, perform analysis of dominant clinical factors, extraction of useful information from hideous patterns in historical data, making predictions and disease classification. Successful researches created opportunities for physicians to take appropriate decision at right time. In current study, we intend to utilize the learning capability of machine learning methods towards the classification of birth data using bagging and boosting classification algorithms. It is obvious that differences in living styles, medical assistances, religious implications and the region you live in collectively affect the residents of that society. This motive has encouraged the researchers to conduct studies at regional levels to comprehensively explore the associated medical factors that contribute towards complications among women during pregnancy. The current study is a comprehensive comparison of bagging and boosting classification algorithms performed on birth data collected from the government hospitals of city Muzaffarabad, Kashmir. The experimental tasks are carried out using caret package in R which is considered an inclusive framework for building machine learning models. Accuracy based results with different evaluation measures are presented. Bagging functions including Adabag and BagFda performed marginally better in terms of accuracy, precision and recall. Improvements are observed in comparison to previous study performed on same dataset.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Syed Ali Abbas et al.",
      "keywords": "Machine learning; Computer science; Artificial intelligence; Boosting (machine learning); Statistical classification; Health care; Government (linguistics); F1 score; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2999899",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390590975",
      "doi": "10.1109/access.2024.3349971",
      "title": "Improving Turkish Text Sentiment Classification Through Task-Specific and Universal Transformations: An Ensemble Data Augmentation Approach",
      "abstract": "The exponential growth of digital data in recent years has spurred a significant interest in natural language processing (NLP) and sentiment analysis. However, the effectiveness of NLP models heavily relies on the availability of large, annotated datasets, which are often scarce or entirely absent for numerous languages, including Turkish. This scarcity of annotated data for Turkish presents a formidable obstacle in developing NLP models for the language. To overcome this challenge, various techniques have been proposed to augment the size of annotated datasets, with text data augmentation emerging as a promising solution. Text data augmentation involves the generation of synthetic data by transforming existing data, thus expanding the diversity and volume of the annotated dataset. While this technique has shown remarkable success in bolstering the performance of NLP models, its exploration in the context of Turkish and other low-resource languages has been limited. This paper introduces a novel ensemble approach to text data augmentation tailored for Turkish text sentiment classification. Our approach integrates both task-specific and universal transformations, capitalizing on the strengths of each to enrich the training dataset. We evaluate our proposed approach on the TRSAv1 dataset and compare it with established data augmentation techniques. The experimental results demonstrate that our ensemble method achieves superior accuracy in sentiment classification compared to conventional techniques. Additionally, we conduct an in-depth analysis to assess the impact of individual transformation functions on classification performance. Our contribution lies in bridging the gap in research on data augmentation techniques tailored to Turkish NLP, emphasizing the need for more advanced ensemble methods, and offering benchmarking results that pave the way for the development of precise NLP models not only for Turkish but also for other low-resource languages.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Aytu\u011f Onan et al.",
      "keywords": "Computer science; Turkish; Task (project management); Artificial intelligence; Sentiment analysis; Natural language processing; Machine learning; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3349971",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3165373734",
      "doi": "10.1109/access.2021.3082108",
      "title": "A Comparative NLP-Based Study on the Current Trends and Future Directions in COVID-19 Research",
      "abstract": "COVID-19 is a global health crisis that has altered human life and still promises to create ripples of death and destruction in its wake. The sea of scientific literature published over a short time-span to understand and mitigate this global phenomenon necessitates concerted efforts to organize our findings and focus on the unexplored facets of the disease. In this work, we applied natural language processing (NLP) based approaches on scientific literature published on COVID-19 to infer significant keywords that have contributed to our social, economic, demographic, psychological, epidemiological, clinical, and medical understanding of this pandemic. We identify key terms appearing in COVID literature that vary in representation when compared to other virus-borne diseases such as MERS, Ebola, and Influenza. We also identify countries, topics, and research articles that demonstrate that the scientific community is still reacting to the short-term threats such as transmissibility, health risks, treatment plans, and public policies, underpinning the need for collective international efforts towards long-term immunization and drug-related challenges. Furthermore, our study highlights several long-term research directions that are urgently needed for COVID-19 such as: global collaboration to create international open-access data repositories, policymaking to curb future outbreaks, psychological repercussions of COVID-19, vaccine development for SARS-CoV-2 variants and their long-term efficacy studies, and mental health issues in both children and elderly.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Priyankar Bose et al.",
      "keywords": "Pandemic; Public health; Global health; Coronavirus disease 2019 (COVID-19); Political science; Public relations; Data science; Medicine; Disease; Computer science; Infectious disease (medical specialty); Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3082108",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3038580595",
      "doi": "10.1109/access.2020.3005536",
      "title": "Solution for Information Overload Using Faceted Search\u2013A Review",
      "abstract": "In the modern society, Internet provides massive amounts of heterogeneous information, hence Information overload has become an ubiquitous issue. In this paper, we conduct a large scale quantitative study for articles dealing with (1) information overloading; (2) faceted search; and (3) filtering the data in three major databases, namely, Web of Science, ScienceDirect, and IEEE Explore. These three databases have presented 172 articles, which can be classified into four categories. The first category contains review and survey papers related to information overload. The second category includes papers that concentrate on developing theoretical frameworks to reduce information overloading. The third category contains papers dealing with improving structure or architectural of software for filtering the huge data. The fourth category includes papers that provide criteria to evaluate filtering techniques. Finally, our contribution provides further understanding of information overload, and gives an important basis for future research. Moreover, we illustrate that the dynamic faceted filters are more efficient to reduce the information overload.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammed Najah Mahdi et al.",
      "keywords": "Information overload; Computer science; Information retrieval; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3005536",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391165157",
      "doi": "10.1109/access.2024.3357946",
      "title": "Exploiting Data-Efficient Image Transformer-Based Transfer Learning for Valvular Heart Diseases Detection",
      "abstract": "Recent studies have shown the potential of the Data-Efficient Image Transformer (DeiT)-based transfer learning method in speech/image recognition and classification utilizing models pre-trained on image datasets. However, the use of DeiT models, especially those pre-trained on image datasets, has not yet been explored for Valvular Heart Disease (VHD) detection. This paper proposes a transfer learning methodology using the DeiT model pre-trained on image datasets for VHD classification. Additionally, we introduce a hybrid Convolution-DeiT (Conv-DeiT) architecture to further improve classification performance. The Conv-DeiT framework integrates a convolutional block with a Squeeze-and-Excitation (SE) attention mechanism to enhance the channel and spatial information within the input features before processing by the DeiT model. The proposed models were assessed using the Heart Sound Murmur (HSM) database, accessible on GitHub. Experimental results show that the DeiT-based transfer learning approach achieved an overall accuracy of 97.44&#x0025;. Moreover, our Conv-DeiT method outperformed the DeiT-based transfer learning with an impressive overall accuracy of 99.44&#x0025;. This study indicates the effectiveness of transfer learning using DeiT models pre-trained on image datasets for heart sound classification. Specifically, our hybrid Conv-DeiT method, which combines the convolutional block and the SE-attention mechanism, demonstrates significant advantages in this context.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Talit Jumphoo et al.",
      "keywords": "Computer science; Transfer of learning; Artificial intelligence; Transformer; Pattern recognition (psychology); Block (permutation group theory); Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3357946",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390075181",
      "doi": "10.1109/access.2023.3345342",
      "title": "A Recommendation System for Electric Vehicles Users Based on Restricted Boltzmann Machine and WaterWheel Plant Algorithms",
      "abstract": "Ensuring reliable and easily accessible charging infrastructure becomes crucial as more people adopt electric vehicles. This study introduces a recommendation system designed to assist electric vehicle users in finding convenient charging stations, enhancing the charging experience, and reducing range anxiety. The system employs advanced data analysis techniques to offer personalized suggestions based on users&#x2019; preferences. Real-time data on factors like charging station availability, individual preferences, and past usage patterns are collected and processed using a restricted Boltzmann machine-learning algorithm. The waterwheel plant algorithm, known for its effectiveness in solving complex optimization problems, is utilized to optimize the parameters of the restricted Boltzmann machine. The recommendation system considers various user preferences, including charging speed, cost, network compatibility, amenities, and proximity to the user&#x2019;s current location. The system aims to minimize user frustration, improve charging performance, and enhance customer satisfaction by addressing these aspects. Results indicate the system&#x2019;s efficiency in suggesting convenient charging locations. The study explores the statistical significance of the optimized waterwheel plant algorithm and restricted Boltzmann machine model through Wilcoxon rank-sum and Analysis of Variance tests.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Abdelhameed Ibrahim\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c\u202c et al.",
      "keywords": "Computer science; Boltzmann machine; Electric vehicle; Algorithm; Recommender system; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3345342",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390480744",
      "doi": "10.1109/access.2023.3348817",
      "title": "KONet: Toward a Weighted Ensemble Learning Model for Knee Osteoporosis Classification",
      "abstract": "Knee osteoporosis (KOP) is a skeletal disorder characterized by bone tissue degradation and low bone density, leading to a high risk of bone fractures in the knee area. The traditional method for identifying knee osteoporosis is knee radiography, which requires sufficient expertise from specialists. However, the sheer volume of X-rays and the subtle variations among them may lead to misinterpretation. In recent years, deep learning algorithms have revolutionized medical diagnosis and reduced misclassification. Specifically, convolutional neural network (CNN)-based algorithms have been utilized to automate the diagnostic process as they have the inherent ability to extract important features that are difficult to identify manually. However, relying on a single method may result in suboptimal performance, leading to ineffective deployment in the medical domain. To alleviate this issue, in this study, we propose a robust detection method, KONet, which utilizes a weighted ensemble approach to distinguish between normal and osteoporotic knee conditions, even when there are minor variations in the data. To validate the architectural choices in the ensemble approach, we conducted experiments on various state-of-the-art CNN-based models using transfer learning. Extensive experiments indicated that the proposed model achieves a higher accuracy than existing models, outperforming the state-of-the-art models by a significant margin.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "M. J. Aashik Rasool et al.",
      "keywords": "Ensemble learning; Computer science; Artificial intelligence; Machine learning; Osteoporosis; Pattern recognition (psychology); Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3348817",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382175358",
      "doi": "10.1109/access.2023.3276264",
      "title": "Manta Ray Foraging Optimization Algorithm: Modifications and Applications",
      "abstract": "The novel metaheuristic manta ray foraging optimization (MRFO) algorithm is based on the smart conduct of manta rays. The MRFO algorithm is a newly developed swarm-based metaheuristic approach that emulates the supportive conduct performed by manta rays in search of food. The MRFO algorithm efficiently resolves several optimization difficulties in various domains due to its ability to provide an equilibrium between global and local searches during the search procedure, resulting in nearly optimal results. Thus, researchers have developed several variants of MRFO since its introduction. This paper provides an in-depth examination of recent MRFO research. First, the paper introduces the natural inspiration context of MRFO and its conceptual optimization framework, and then MRFO modifications, hybridizations, and applications across different domains are discussed. Finally, a meta-analysis of the developments of the MRFO is presented along with the possible future research directions. This study can be useful for researchers and practitioners in optimization, engineering design, machine learning, scheduling, image processing, and other fields.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mohammed Abdullahi et al.",
      "keywords": "Foraging; Computer science; Algorithm; Optimization algorithm; Mathematical optimization; Mathematics; Ecology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3276264",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386536277",
      "doi": "10.1109/access.2023.3313189",
      "title": "Sentiment Analysis Using Hybrid Model of Stacked Auto-Encoder-Based Feature Extraction and Long Short Term Memory-Based Classification Approach",
      "abstract": "Customer reviews about a brand or product, movie reviews, and social media reviews can be analyzed through sentiment analysis. Sentiment analysis is used to identify the emotional tone of language to comprehend the attitudes, opinions, and feelings represented in online reviews. As for large data, it is a task that can take a lot of time and can be automated as the machine learns through the training and testing of data. Previously, various standard machine learning and deep learning models namely Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), Long Short Term Memory (LSTM), Na&#x00EF;ve Bayes (NB), Support Vector Machine (SVM), Gated Recurrent Unit (GRU) have been used. The key issue in our research is that when text is provided to LSTM directly, it cannot adequately extract informative features from the text, leading to less accurate findings. The softmax layer of Stacked Auto-encoder when used directly to categorize the extracted features, is power-constrained and unable to do so accurately. A hybrid of the Stacked Auto-encoder (SAE) and LSTM models was proposed. SAE is used for the extraction of relevant informative features. LSTM was used for further classification of sentiments based on the extracted features. The proposed model is evaluated on an IMDB dataset by splitting it into five different training testing ratios using the following performance evaluation metrics: confusion matrix, classification accuracy, precision, recall, sensitivity, specificity, and F1 score. The hybrid results performed best at a ratio of 90/10 and classified sentiments with an accuracy of 87&#x0025;. The accuracy of proposed hybrid model is better than that of standard models namely RNN, CNN, LSTM, NB, SVM, and GRU.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Iqra Kanwal et al.",
      "keywords": "Computer science; Artificial intelligence; Support vector machine; Sentiment analysis; Softmax function; Convolutional neural network; Feature extraction; Machine learning; Recurrent neural network; Naive Bayes classifier; Deep learning; Artificial neural network; Pattern recognition (psychology); Encoder; Speech recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3313189",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4206096530",
      "doi": "10.1109/access.2021.3140189",
      "title": "Evaluating Uses of Deep Learning Methods for Causal Inference",
      "abstract": "Logistic regression (LR) is a popular method that is used for estimating causal effects in observational studies using propensity scores. We examine the use of deep learning models such as the deep neural network (DNN), PropensityNet (PN), convolutional neural network (CNN), and convolutional neural network-long short-term memory network (CNN-LSTM) to estimate propensity scores and evaluate causal inference. We conducted studies using simulated data with different sample sizes (N &#x003D; 500, N &#x003D; 1000, N &#x003D; 2000), 15 covariates, a continuous outcome and a binary exposure. These data were used in seven scenarios that were different in the degree of nonlinearity and nonadditivity associations between the exposure and covariates. Estimation of propensity scores was considered a classification task and performance metrics that included classification accuracy, receiver operating characteristic curve area under the curve (AUCROC), covariate balance, standard error, absolute bias, and the 95&#x0025; confidence interval coverage were evaluated for each model. Our simulation results show that deep learning models (CNN, DNN, and CNN-LSTM) outperformed LR in the estimation of the propensity score. CNN and CNN-LSTM achieved good results for covariate balance, classification accuracy, AUCROC, and Cohen&#x2019;s Kappa. Although LR provided substantially better bias reduction, it produced subpar performance based on classification accuracy, AUCROC, Cohen&#x2019;s Kappa, and 95&#x0025; confidence interval coverage compared to the deep learning models. The results suggest that deep learning methods, especially CNN, may be useful for estimating propensity scores that are used to estimate causal effects.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Albert Whata et al.",
      "keywords": "Causal inference; Artificial intelligence; Covariate; Convolutional neural network; Computer science; Deep learning; Inference; Artificial neural network; Receiver operating characteristic; Binary classification; Machine learning; Confidence interval; Statistics; Logistic regression; Kernel (algebra); Pattern recognition (psychology); Mathematics; Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3140189",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4309389268",
      "doi": "10.1109/tmrb.2022.3215749",
      "title": "Review of Bioinspired Vision-Tactile Fusion Perception (VTFP): From Humans to Humanoids",
      "abstract": "Humanoid robots are designed and expected to resemble humans in structure and behavior, showing increasing application potentials in various fields. Like their biological counterparts, their environmental perception ability is fundamental. In particular, the visual and tactile perception are the two main sensory modes that humanoids use to understand and interact with the environment. Vision-Tactile Fusion Perception (VTFP) has shown multiple possibilities for better sensing understanding in challenging conditions, causing new research interests and questions. The overlap between visual and tactile perception in humanoids is continually growing. This work has reviewed the current state of the art of VTFP. It starts with the physiological basis of biological vision and tactile systems as well as the VTFP mechanisms as inspirations for humanoid perception. Then, the bioinspired visual-tactile fusion systems for humanoids are reviewed as the emphasis. After the survey on the vision and tactile sensors of robots, seven currently publicly available VTFP datasets are introduced. They are the data sources for several studies on neural network-inspired fusion algorithms. Furthermore, the applications of VTFP on humanoids are summarized. Finally, the challenges and future work are discussed. This review aims to provide several references for further exploitation of VTFP and its applications on humanoids.",
      "year": "2022",
      "journal": "IEEE Transactions on Medical Robotics and Bionics",
      "authors": "Bin He et al.",
      "keywords": "Perception; Tactile perception; Humanoid robot; Human\u2013computer interaction; Active perception; Computer science; Artificial intelligence; Robot; Sensor fusion; Sensory system; Visual perception; Tactile sensor; Computer vision; Psychology; Cognitive psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmrb.2022.3215749",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388505131",
      "doi": "10.1109/access.2023.3331316",
      "title": "EngineFaultDB: A Novel Dataset for Automotive Engine Fault Classification and Baseline Results",
      "abstract": "This paper introduces EngineFaultDB, a novel dataset capturing the intricacies of automotive engine diagnostics. Centered around the widely represented C14NE spark ignition engine, data was collected under controlled laboratory conditions, simulating various operational states, including normal and specific fault scenarios. Utilizing tools such as an NGA 6000 gas analyzer and a USB 6008 data acquisition card from National Instruments, we were able to monitor and capture a comprehensive range of engine parameters, from throttle position and fuel consumption to exhaust gas emissions. Our dataset, comprising 55,999 meticulously curated entries across 14 distinct variables, provides a holistic picture of engine behavior, making it an invaluable resource for automotive researchers and practitioners. For evaluation, several classifiers, including logistic regression, decision trees, random forests, support vector machines, k-nearest neighbors, and a feed-forward neural network, were trained on this dataset. Their performance, under standard configurations and a simple neural network architecture, offers foundational benchmarks for future explorations. Results underscore the dataset&#x2019;s potential in fostering advanced diagnostic algorithms. As a testament to our commitment to open research, EngineFaultDB is freely available for academic use. Future work involves expanding the dataset&#x2019;s diversity, exploring deeper neural architectures, and integrating real-world automotive conditions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mary Vergara et al.",
      "keywords": "Baseline (sea); Computer science; Automotive industry; Fault (geology); Artificial intelligence; Data mining; Engineering; Geology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3331316",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3154415878",
      "doi": "10.1109/jstars.2021.3073351",
      "title": "Dengue Vector Population Forecasting Using Multisource Earth Observation Products and Recurrent Neural Networks",
      "abstract": "This article introduces a technique for using recurrent neural networks to forecast Ae. aegyptimosquito (Dengue transmission vector) counts at neighborhood-level, using Earth Observation data inputs as proxies to environmental variables. The model is validated using in situdata in two Brazilian cities, and compared with state-of-the-art multioutput random forest and k-nearest neighbor models. The approach exploits a clustering step performed before the model definition, which simplifies the task by aggregating mosquito count sequences with similar temporal patterns.",
      "year": "2021",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Oladimeji Mudele et al.",
      "keywords": "Dengue fever; Cluster analysis; Population; Computer science; Artificial neural network; Artificial intelligence; Data mining; Machine learning; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2021.3073351",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390783054",
      "doi": "10.1109/tiv.2024.3351131",
      "title": "A Survey of Vehicle Dynamics Modeling Methods for Autonomous Racing: Theoretical Models, Physical/Virtual Platforms, and Perspectives",
      "abstract": "This paper presents the first survey of vehicle dynamics modeling methods for autonomous racing. Previous surveys have covered dynamics models for standard autonomous vehicles or, alternatively, concentrated on planning and control methods in autonomous racing with vehicle dynamics models briefly mentioned. However, previous surveys overlook the importance of vehicle dynamics under challenging conditions of top speeds and non-steady state driving, which are unique characteristics in autonomous racing. Recognizing the vital role of vehicle dynamics modeling in an autonomous racecar's prediction, planning, and control modules, this survey seeks to ascertain to what degree the nominal full-scale racecar dynamics can be streamlined without sacrificing accuracy for simplicity. Furthermore, this survey provides essential guidance for organizers of virtual autonomous races, helping them choose vehicle dynamics models that meet the required level of precision. This paper begins with a review of previous surveys on vehicle dynamics modeling, highlighting their limitations in the context of autonomous racing. Following this, it investigates the existing dynamics models for autonomous racing vehicles, along with a comprehensive examination of the existing physical/virtual testing platforms. The paper concludes by discussing emerging trends and offering perspectives in the field of vehicle dynamics modeling for autonomous racing, paving the way for groundbreaking research and innovations in autonomous racing.",
      "year": "2024",
      "journal": "IEEE Transactions on Intelligent Vehicles",
      "authors": "Tantan Zhang et al.",
      "keywords": "Dynamics (music); Vehicle dynamics; Context (archaeology); Field (mathematics); Computer science; Control (management); System dynamics; Simulation; Systems engineering; Engineering; Artificial intelligence; Aerospace engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tiv.2024.3351131",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3183156452",
      "doi": "10.1109/access.2021.3096828",
      "title": "A Reinforcement Learning Approach for Optimal Placement of Sensors in Protected Cultivation Systems",
      "abstract": "Optimal placement of sensors in protected cultivation systems to maximize monitoring and control capabilities can guide effective decision-making toward achieving the highest levels of productivity and other desirable outcomes. Reinforcement learning, unlike conventional machine learning methods such as supervised learning does not require large, labeled datasets thereby providing opportunities for more efficient and unbiased design optimization. With the objective of determining the optimal locations of sensors in a greenhouse, a multi-arm bandit problem was formulated using the Beta distribution and solved by the Thompson sampling algorithm. A total of 56 two-in-one sensors designed to measure both internal air temperature and relative humidity were installed at a vertical distance of 1 m and a horizontal distance of 3m apart in a greenhouse used to cultivate strawberries. Data was collected over a period of seven months covering four major seasons, February (winter), March, April, and May (spring), June and July (summer), and October (autumn) and analyzed separately. Results showed unique patterns for sensor selection for temperature and relative humidity during the different months. Furthermore, temperature and relative humidity each had different optimal location selections suggesting that two-in-one sensors might not be ideal in these cases. The use of reinforcement learning to design optimal sensor placement in this study aided in identifying 10 optimal sensor locations for monitoring and controlling temperature and relative humidity.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Daniel Dooyum Uyeh et al.",
      "keywords": "Reinforcement learning; Relative humidity; Greenhouse; Computer science; Reinforcement; Environmental science; Sampling (signal processing); Humidity; Artificial intelligence; Agricultural engineering; Machine learning; Simulation; Statistics; Real-time computing; Mathematics; Meteorology; Engineering; Computer vision; Structural engineering; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3096828",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387758108",
      "doi": "10.1109/access.2023.3322376",
      "title": "Sparrow Search Algorithm With Stacked Deep Learning Based Medical Image Analysis for Pancreatic Cancer Detection and Classification",
      "abstract": "Medical image analysis for pancreatic cancer (PC) classification and recognition is a vital domain of research and medical practices. PC is challenging to diagnose and treat; medical imaging approaches aid early diagnosis to analyse and treat, and employ of medical imaging approaches are support early diagnosis, correct analysis, and treatment planning. Computed Tomography (CT) scans are generally utilized to detect and classify PCs. Deep learning (DL) approaches have demonstrated the ability to support the diagnosis and detection of several medical conditions, containing PC. Convolutional Neural Networks (CNNs) are a kind of DL approach generally employed for image analysis that is trained to automatically learn and extract features in medical images. So, this study purposes a new Sparrow Search Algorithm with Stacked Deep Learning based Medical Image Analysis for Pancreatic Cancer Detection and Classification (SSASDL-PCDC) technique on CT images. The purpose of the study is to design an SSASDL-PCDC technique to achieve improved pancreatic cancer detection performance. In addition, the SSASDL-PCDC technique applies Harris Hawks Optimization (HHO) with a densely connected networks (DenseNet) model for the feature extraction process. Moreover, convolutional neural network with bi-directional long short-term memory (CNN-BiLSTM) approach was utilized for PC detection and classification. Furthermore, Sparrow Search Algorithm (SSA) is used to adjust the hyperparameter values of the CNN-BiLSTM technique. To evaluate the effectiveness of the SSASDL-PCDC technique, extensive experiments were executed on a comprehensive database of pancreatic CT images. The simulation outcome value depicted that the SSASDL-PCDC technique with maximum sensitivity of 99.26&#x0025;, specificity of 99.26&#x0025;, and accuracy of 99.26&#x0025;.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Janjhyam Venkata Naga Ramesh et al.",
      "keywords": "Convolutional neural network; Artificial intelligence; Computer science; Hyperparameter; Deep learning; Feature extraction; Medical imaging; Contextual image classification; Pattern recognition (psychology); Artificial neural network; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3322376",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391097216",
      "doi": "10.1109/access.2024.3357114",
      "title": "SPCM: A Machine Learning Approach for Sentiment-Based Stock Recommendation System",
      "abstract": "Recommendation systems play a pivotal role in delivering user preference information. However, they often face the challenge of information cocoons due to repeated content delivery, particularly prevalent in stock recommendations that are susceptible to investor sentiment. In response to the information cocoons, we propose the Sentiment and Price Combined Model (SPCM), which leverages sentiment features and price factors to predict stock price movements. This novel framework combines collective sentiment analysis with state-of-the-art BERT transformer models and advanced machine learning techniques. Over a three-year period, we collected 40 million stock comments from the Guba platform, extracting investor sentiment conveyed in text information and investigating the impact of metrics such as homophily on stock recommendations. Experimental results indicate that both the volume of posts and the agreement index affect the effectiveness of investor sentiment, while homophily reduces the accuracy of participants&#x2019; stock price judgments. The recognition accuracy of the BERT-based sentiment analysis model reaches an impressive 84.12&#x0025;, and the portfolio constructed by SPCM yields a cumulative return four times that of the industry benchmark. Furthermore, homogeneous quantitative metrics also enhance diversification in stock selection.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Jiawei Wang et al.",
      "keywords": "Computer science; Sentiment analysis; Stock (firearms); Portfolio; Machine learning; Artificial intelligence; Homophily; Econometrics; Diversification (marketing strategy); Financial economics; Economics; Business; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3357114",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4395661532",
      "doi": "10.1109/access.2024.3394243",
      "title": "Ethical Considerations in the Use of ChatGPT: An Exploration Through the Lens of Five Moral Dimensions",
      "abstract": "This article seeks to illuminate the ethical challenges and concerns presented by the utilization of the large language model, ChatGPT. Five critical ethical dimensions as proposed by Laudon and Laudon &#x2013; Information rights and obligations, Property rights and obligations, Accountability and control, System quality, and Quality of life &#x2013; will serve as the analytical framework to explore the pertinent issues. Although our investigation revealed that AI technologies like ChatGPT have tremendous potential for societal advancement they also present complex ethical challenges. The implications of our research have impact not only for developers of large language models but also developers of AI technologies in general, policy makers, end-users of these AI applications, and society as whole. Based on our findings we propose key recommendations to address the current concerns with respect to the ethical issues surrounding large language models. By assessing these ethical dimensions within the context of ChatGPT, this paper underscores the importance of developing comprehensive ethical guidelines and policies in the era of increasingly sophisticated AI applications.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ahmad Ghandour et al.",
      "keywords": "Lens (geology); Through-the-lens metering; Computer science; Optics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3394243",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4296079524",
      "doi": "10.1109/access.2022.3207272",
      "title": "Avoiding the Hook: Influential Factors of Phishing Awareness Training on Click-Rates and a Data-Driven Approach to Predict Email Difficulty Perception",
      "abstract": "Phishing attacks are still seen as a significant threat to cyber security, and large parts of the industry rely on anti-phishing simulations to minimize the risk imposed by such attacks. This study conducted a large-scale anti-phishing training with more than 31000 participants and 144 different simulated phishing attacks to develop a data-driven model to classify how users would perceive a phishing simulation. Furthermore, we analyze the results of our large-scale anti-phishing training and give novel insights into users&amp;#x2019; click behavior. Analyzing our anti-phishing training data, we find out that 66&amp;#x0025; of users do not fall victim to credential-based phishing attacks even after being exposed to twelve weeks of phishing simulations. To further enhance the phishing awareness-training effectiveness, we developed a novel manifold learning-powered machine learning model that can predict how many people would fall for a phishing simulation using the several structural and state-of-the-art NLP features extracted from the emails. In this way, we present a systematic approach for the training implementers to estimate the average &amp;#x201C;convincing power&amp;#x201D; of the emails prior to rolling out. Moreover, we revealed the top-most vital factors in the classification. In addition, our model presents significant benefits over traditional rule-based approaches in classifying the difficulty of phishing simulations. Our results clearly show that anti-phishing training should focus on the training of individual users rather than on large user groups. Additionally, we present a promising generic machine learning model for predicting phishing susceptibility.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Thomas Sutter et al.",
      "keywords": "Phishing; Computer science; Credential; Machine learning; Artificial intelligence; Computer security; World Wide Web; The Internet",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3207272",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3203800148",
      "doi": "10.1109/mc.2021.3055892",
      "title": "Artificial Intelligence in Critical Infrastructure Systems",
      "abstract": "Seven expert panelists discuss the use of artificial intelligence in critical infrastructure systems and how it can be used and misused. They also address issues of public confidence in such systems and many more important questions.",
      "year": "2021",
      "journal": "Computer",
      "authors": "Phil Laplante et al.",
      "keywords": "Computer science; Critical infrastructure; Expert system; Data science; Computer security; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mc.2021.3055892",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390659221",
      "doi": "10.1109/access.2024.3351188",
      "title": "An Improved Ensemble Method for Predicting Hyperchloremia in Adults With Diabetic Ketoacidosis",
      "abstract": "Diabetic ketoacidosis (DKA) is a serious complication that affects millions of individuals globally and presents significant health complications. Hyperchloremia, an electrolyte imbalance characterized by high levels of chloride in the blood, may result in gastrointestinal problems, kidney damage, and even death, especially in DKA patients. Early detection and treatment of hyperchloremia are of utmost importance in the management of DKA. This study explores the potential of the bootstrap aggregating ensemble with random subspaces machine learning approach to predict the occurrence of hyperchloremia, providing a basis for early intervention and improved patient outcomes. We tested our approach with the retrospective MIMIC-III database containing 1177 DKA patients and compared it with previous studies with an area under the curve (AUC) of 100&#x0025;. Our approach showed significant performance outperforming other methods. The combination of this approach may enhance the early detection and timely intervention of hyperchloremia cases, ultimately leading to improved patient outcomes and a more effective management of DKA-associated complications. Our work aims to contribute to the development of decision support tools for healthcare professionals, assisting them in making informed decisions for DKA patients, with a focus on preventing and managing hyperchloremia.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "George Obaido et al.",
      "keywords": "Hyperchloremia; Diabetic ketoacidosis; Ketoacidosis; Diabetes mellitus; Computer science; Medicine; Internal medicine; Endocrinology; Acidosis; Type 1 diabetes",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3351188",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386825026",
      "doi": "10.1109/access.2023.3316515",
      "title": "Multi Perceptron Neural Network and Voting Classifier for Liver Disease Dataset",
      "abstract": "The liver is one of the most significant organs in the human body. We can predict liver disease in a patient at an early stage based on previously predicted values using data from patients with abnormal liver function. Which helps the doctors to make a diagnosis. In this paper, the liver function test is analyzed for predicting liver disease, where the input of the patient&#x2019;s details and output data are passed into various classifiers such as Support Vector Machine, K-Nearest Neighbor, Hard Voting Classifier, and Deep Neural Network Multilayer Perceptron Techniques. Model Evaluation Criteria such as the Confusion Matrix, Precision Score, Recall, Accuracy, Specificity, and F-score are used to determine the best model. A dataset of 583 individuals suffering from liver disease is analyzed and we found that Hard Voting Classifier (HVC) is the best for this dataset. Additionally, this Voter Classifier prediction algorithm gives higher accuracy, which will help to diagnose liver disease.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Victor Anthonysamy et al.",
      "keywords": "Confusion matrix; Computer science; Artificial intelligence; Classifier (UML); Support vector machine; Multilayer perceptron; Artificial neural network; Pattern recognition (psychology); Machine learning; Confusion; Voting; Majority rule; Liver disease; Medicine; Gastroenterology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3316515",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391305844",
      "doi": "10.1109/jstars.2024.3359636",
      "title": "Quantifying Uncertainty in Slum Detection: Advancing Transfer Learning With Limited Data in Noisy Urban Environments",
      "abstract": "In the intricate landscape of mapping urban slum dynamics, the significance of robust and efficient techniques is often underestimated and remains absent in many studies. This not only hampers the comprehensiveness of research but also undermines potential solutions that could be pivotal for addressing the complex challenges faced by these settlements. With this ethos in mind, we prioritize efficient methods to detect the complex urban morphologies of slum settlements. Leveraging transfer learning with minimal samples and estimating the probability of predictions for slum settlements, we uncover previously obscured patterns in urban structures. By using Monte Carlo dropout, we not only enhance classification performance in noisy datasets and ambiguous feature spaces but also gauge the uncertainty of our predictions. This offers deeper insights into the model's confidence in distinguishing slums, especially in scenarios where slums share characteristics with formal areas. Despite the inherent complexities, our custom CNN STnet stands out, delivering performance on par with renowned models like ResNet50 and Xception but with notably superior efficiency\u2014faster training and inference, particularly with limited training samples. Combining Monte Carlo dropout, class-weighted loss function, and class-balanced transfer learning, we offer an efficient method to tackle the challenging task of classifying intricate urban patterns amidst noisy datasets. Our approach not only enhances artificial intelligence model training in noisy datasets but also advances our comprehension of slum dynamics, especially as these uncertainties shed light on the intricate intraurban variabilities of slum settlements.",
      "year": "2024",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Thomas Stark et al.",
      "keywords": "Computer science; Slum; Transfer of learning; Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2024.3359636",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390577812",
      "doi": "10.1109/access.2024.3349691",
      "title": "FedOps: A Platform of Federated Learning Operations With Heterogeneity Management",
      "abstract": "Federated learning (FL) is a decentralized machine learning (ML) method that enables model training while preserving privacy. FL is gaining attention because it avoids data transfer to the server, facilitating the decentralized learning of the traditional ML model. Despite its potential, FL project is significantly more challenging to develop than centralized ML methods owing to decentralized local data. We propose FedOps, federated learning operations for constructing systematic FL project by enhancing machine learning operations (MLOps) to be effectively applied to FL while preserving its core process. To address complexity of FL implementation, we developed FedOps platform, which involves FedOps-based projects to manage the whole lifecycle in FL context. We also investigated methods to identify performance degradation factors in FL and suggest an approach for improvement. FedOps Platform provides an analysis tool for client heterogeneity, called chunk-bench. This tool enables researchers and engineers to gain insights into systems heterogeneity by using only small chunk of the clients&#x2019; data to execute test in the shortest time possible while tracking the systems heterogeneity across the clients. By addressing systems heterogeneity, FedOps Platform achieved 13&#x0025;&#x2013;43&#x0025; improvement in communication cost-to-accuracy and 20&#x0025;&#x2013;68&#x0025; improvement in time-to-accuracy. We believe that FedOps Platform offers an optimal solution for end-to-end development of FL projects, with significantly improving both computational and communication efficiencies.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "J. Moon et al.",
      "keywords": "Computer science; Context (archaeology); Artificial intelligence; Machine learning; Information retrieval",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3349691",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4375928288",
      "doi": "10.1109/access.2023.3274117",
      "title": "Time-Aware Recommender Systems: A Comprehensive Survey and Quantitative Assessment of Literature",
      "abstract": "Recommender systems (RS) are among the most widely used applications in data mining and machine-learning technologies. These technologies recommend relevant products to customers, such as movies to watch, items to buy, and books to read. The difference in user preferences over time is one of the most significant issues faced by recommender systems. Researchers have focused on time-sensitive recommender systems, and numerous studies have been conducted in this field. These studies aim to consider the time factor while offering recommendations to users by incorporating and utilizing temporal data in recommendations. In this work, we review existing works in this field and present the most prominent techniques and algorithms that have the ability to capture changes in user preferences over time, and the most important application areas for these recommendations. In addition, we present a quantitative assessment of comprehensive literature that investigates publications in terms of publication time, publication type, and datasets used. Finally, we highlight a range of findings and conclusions and provide the reader with insights based on a general analysis of time-sensitive recommender systems.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Reham Alabduljabbar et al.",
      "keywords": "Recommender system; Computer science; Field (mathematics); Data science; Information retrieval; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3274117",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3199617745",
      "doi": "10.1109/access.2021.3111527",
      "title": "Explainable AI for Multimodal Credibility Analysis: Case Study of Online Beauty Health (Mis)-Information",
      "abstract": "&amp;#x201C;One person&amp;#x2019;s data or experience is another person&amp;#x2019;s information&amp;#x201D; this has become the golden rule of the 21st century which has resulted in a massive reservoir of data and immense amounts of information generation. However, there is no control over the source of this information, accessibility of this information, or the quality of it, which has given rise to the presence of &amp;#x201C;misinformation.&amp;#x201D; The research community has reacted by proposing frameworks and difficulties, which are helpful for (different subtasks of) recognizing misinformation. Most of these frameworks, however, fail to consider all the aspects that can contribute to making information &amp;#x201C;credible&amp;#x201D;. Furthermore, a valid explanation for each considered feature&amp;#x2019;s contribution to the model&amp;#x2019;s decision stands missing in most work. With this in mind, the authors have attempted to produce a system that yields highly accurate decisions, thus effectively separating credible health blogs from their non-credible counterparts while providing valid user-friendly explanations. The study proposes an Explainable AI-assisted Multimodal Credibility Assessment System that examines the credibility of the platform where the blog is hosted, the credibility of the author of the blog and the credibility of the images that contribute to the blog. This novel framework contributes to the existing body of knowledge by assessing the credibility of misleading beauty blogs using multiple crucial modalities which would lead to an insightful information consumption by the users. The proposed pipeline was successfully implemented on multiple carefully curated datasets and correctly identified 274 non credible blogs out of 321 blogs with an accuracy of 97.5&amp;#x0025;, Precision of 0.973 &amp;#x0026; F1score of 0.986. Further, the Explainable AI model, with the help of several visualizations displayed the feature contributions for each blog &amp;#x0026; it&amp;#x2019;s impact and magnitude in a concise comprehensible format. The framework can be further customized and applied to various domains where presence of misinformation is of high concern such as pharmaceutical drug information, pandemic management, financial advisories, online healthcare services and cyber frauds.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Vidisha Wagle et al.",
      "keywords": "Credibility; Misinformation; Computer science; Modalities; Pipeline (software); Data science; Beauty; Counterintuitive; Heuristics; Information retrieval; Internet privacy; World Wide Web; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3111527",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391697093",
      "doi": "10.1109/access.2024.3364373",
      "title": "Automatic Radiology Report Generator Using Transformer With Contrast-Based Image Enhancement",
      "abstract": "Writing radiology reports based on radiographic images is a time-consuming task that demands the expertise of skilled radiologists. Consequently, the integration of technology capable of automated report generation would be advantageous. Developing a coherent predictive text is the main challenge in automatic report generation. It is necessary to develop methods that can increase the relevance of features in producing predictive text. This study constructed a medical report generator model using the transformer approach and image enhancement implementation. To leverage the visual and semantic features, an approach to enhance the noise-prone nature of the medical image is explored in this study along with the transformers method to generate a radiology report based on Chest X-ray images. Four contrast-based image enhancement methods were used to investigate the effect of image enhancement techniques on the radiology report generator. The encoder-decoder model is used with text feature embedding using Bidirectional Encoder Representation from Transformer (BERT) and visual feature extraction utilizing a pre-trained model ChexNet and Multi-Head Attention (MHA) mechanism. The performance of the MHA model with gamma correction is 5&#x0025; in better with a 0.377 value using the Bilingual Assessment Understudy (BLEU) with 4 n-gram evaluation. MHA also produces 15&#x0025; better results with a 0.412 value than the baseline model. This method is able to outperform the baseline model and other previous works. It can be concluded that the use of transformer MHA encoder layer and BERT is effective in leveraging visual and text features. Additionally, the inclusion of an image enhancement approach has been found to have a positive impact on the model&#x2019;s performance.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Hilya Tsaniya et al.",
      "keywords": "Computer science; Computer vision; Artificial intelligence; Contrast enhancement; Transformer; Generator (circuit theory); Magnetic resonance imaging; Radiology; Electrical engineering; Medicine; Voltage; Engineering; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3364373",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391953550",
      "doi": "10.1109/jbhi.2024.3367736",
      "title": "Neural Networks Based Smart E-Health Application for the Prediction of Tuberculosis Using Serverless Computing",
      "abstract": "The convergence of the Internet of Things (IoT) with e-health records is creating a new era of advancements in the diagnosis and treatment of disease, which is reshaping the modern landscape of healthcare. In this paper, we propose a neural networks-based smart e-health application for the prediction of Tuberculosis (TB) using serverless computing. The performance of various Convolution Neural Network (CNN) architectures using transfer learning is evaluated to prove that this technique holds promise for enhancing the capabilities of IoT and e-health systems in the future for predicting the manifestation of TB in the lungs. The work involves training, validating, and comparing Densenet-201, VGG-19, and Mobilenet-V3-Small architectures based on performance metrics such as test binary accuracy, test loss, intersection over union, precision, recall, and F1 score. The findings hint at the potential of integrating these advanced Machine Learning (ML) models within IoT and e-health frameworks, thereby paving the way for more comprehensive and data-driven approaches to enable smart healthcare. The best-performing model, VGG-19, is selected for different deployment strategies using server and serless-based environments. We used JMeter to measure the performance of the deployed model, including the average response rate, throughput, and error rate. This study provides valuable insights into the selection and deployment of ML models in healthcare, highlighting the advantages and challenges of different deployment options. Furthermore, it also allows future studies to integrate such models into IoT and e-health systems, which could enhance healthcare outcomes through more informed and timely treatments.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Subramaniam Subramanian Murugesan et al.",
      "keywords": "Computer science; Artificial neural network; Artificial intelligence; Tuberculosis; Machine learning; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3367736",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3038932756",
      "doi": "10.1109/access.2020.3005987",
      "title": "Joint Transfer of Model Knowledge and Fairness Over Domains Using Wasserstein Distance",
      "abstract": "Owing to the increasing use of machine learning in our daily lives, the problem of fairness has recently become an important topic in machine learning societies. Recent studies regarding fairness in machine learning have been conducted to attempt to ensure statistical independence between individual model predictions and designated sensitive attributes. However, in reality, cases exist in which the sensitive variables of data used for learning models differ from the data upon which the model is applied. In this paper, we investigate a methodology for developing a fair classification model for data with limited or no labels, by transferring knowledge from another data domain where information is fully available. This is done by controlling the Wasserstein distances between relevant distributions. Subsequently, we obtain a fair model that could be successfully applied to two datasets with different sensitive attributes. We present theoretical results validating that our approach provably transfers both classification performance and fairness over domains. Experimental results show that our method does indeed promote fairness for the target domain, while retaining reasonable classification accuracy, and that it often outperforms comparative models in terms of joint fairness.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Tae-Ho Yoon et al.",
      "keywords": "Computer science; Independence (probability theory); Joint (building); Machine learning; Domain (mathematical analysis); Artificial intelligence; Transfer of learning; Data modeling; Domain knowledge; Data mining; Mathematics; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3005987",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4395027673",
      "doi": "10.1109/access.2024.3392595",
      "title": "State-of-the-Art and Challenges in Pancreatic CT Segmentation: A Systematic Review of U-Net and Its Variants",
      "abstract": "In medical image analysis, segmenting pancreatic CT images presents a significant challenge due to the complex anatomy of the pancreas and the generally low contrast of these images. Accurate pancreas segmentation is crucial in clinical scenarios, particularly for the diagnosis and treatment of pancreatic cancer. The U-Net architecture and its variations have achieved significant progress in deep learning-based image segmentation, especially in the context of pancreatic CT image segmentation. However, there is a noticeable gap in the comprehensive evaluation of their performance, limitations, and potential improvements specifically in this area. This systematic review aims to address this gap in the literature, focusing particularly on U-Net and its variants in pancreatic CT image segmentation. Adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, this review includes relevant studies published since 2019 in the field of pancreatic segmentation. The findings illuminate the current limitations of these methods and establish a theoretical foundation for future research directions.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Chaohui Zhang et al.",
      "keywords": "Computer science; Segmentation; State (computer science); Artificial intelligence; Algorithm",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3392595",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390590921",
      "doi": "10.1109/access.2024.3349698",
      "title": "A Deep Learning-Based Fully Automated Pipeline for Regurgitant Mitral Valve Anatomy Analysis From 3D Echocardiography",
      "abstract": "Three-dimensional transesophageal echocardiography (3DTEE) is the recommended imaging technique for the assessment of mitral valve (MV) morphology and lesions in case of mitral regurgitation (MR) requiring surgical or transcatheter repair. Such assessment is key to thorough intervention planning and to intraprocedural guidance. However, it requires segmentation from 3DTEE images, which is time-consuming, operator-dependent, and often merely qualitative. In the present work, a novel workflow to quantify the patient-specific MV geometry from 3DTEE is proposed. The developed approach relies on a 3D multi-decoder residual convolutional neural network (CNN) with a U-Net architecture for multi-class segmentation of MV annulus and leaflets. The CNN was trained and tested on a dataset comprising 55 3DTEE examinations of MR-affected patients. After training, the CNN is embedded into a fully automatic, and hence fully repeatable, pipeline that refines the predicted segmentation, detects MV anatomical landmarks and quantifies MV morphology. The trained 3D CNN achieves an average Dice score of 0.82 &#x00B1; 0.06, mean surface distance of 0.43 &#x00B1; 0.14 mm and 95&#x0025; Hausdorff Distance (HD) of 3.57 &#x00B1; 1.56 mm before segmentation refinement, outperforming a state-of-the-art baseline residual U-Net architecture, and provides an unprecedented multi-class segmentation of the annulus, anterior and posterior leaflet. The automatic 3D linear morphological measurements of the annulus and leaflets, specifically diameters and lengths, exhibit differences of less than 1.45 mm when compared to ground truth values. These measurements also demonstrate strong overall agreement with analyses conducted by semi-automated commercial software. The whole process requires minimal user interaction and requires approximately 15 seconds.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Riccardo Munaf\u00f2 et al.",
      "keywords": "Mitral valve; Pipeline (software); Cardiology; Computer science; Internal medicine; Medicine; Artificial intelligence; Anatomy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3349698",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390836741",
      "doi": "10.1109/access.2024.3351754",
      "title": "Comparative Analysis of Artificial Intelligence Methods for Streamflow Forecasting",
      "abstract": "Deep learning excels at managing spatial and temporal time series with variable patterns for streamflow forecasting, but traditional machine learning algorithms may struggle with complicated data, including non-linear and multidimensional complexity. Empirical heterogeneity within watersheds and limitations inherent to each estimation methodology pose challenges in effectively measuring and appraising hydrological statistical frameworks of spatial and temporal variables. This study emphasizes streamflow&#13;\\nforecasting in the region of Johor, a coastal state in Peninsular Malaysia, utilizing a 28-year streamflowpattern dataset from Malaysia\u2019s Department of Irrigation and Drainage for the Johor River and its tropical&#13;\\nrainforest environment. For this dataset, wavelet transformation significantly improves the resolution of&#13;\\nlag noise when historical streamflow data are used as lagged input variables, producing a 6% reduction&#13;\\nin the root-mean-square error. A comparative analysis of convolutional neural networks and artificial neural&#13;\\nnetworks reveals these models\u2019 distinct behavioral patterns. Convolutional neural networks exhibit lower&#13;\\nstochasticity than artificial neural networks when dealing with complex time series data and with data&#13;\\ntransformed into a format suitable for modeling. However, convolutional neural networks may suffer from&#13;\\noverfitting, particularly in cases in which the structure of the time series is overly simplified. Using Bayesian&#13;\\nneural networks, we modeled network weights and biases as probability distributions to assess aleatoric&#13;\\nand epistemic variability, employing Markov chain Monte Carlo and bootstrap resampling techniques.&#13;\\nThis modeling allowed us to quantify uncertainty, p",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Wei Yaxing et al.",
      "keywords": "Computer science; Streamflow; Overfitting; Artificial neural network; Artificial intelligence; Machine learning; Convolutional neural network; Time series; Data mining; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3351754",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2981627686",
      "doi": "10.1109/jtehm.2019.2948604",
      "title": "A Practical Electronic Health Record-Based Dry Weight Supervision Model for Hemodialysis Patients",
      "abstract": "<i>Objective</i>: Dry Weight (DW) is a typical hemodialysis (HD) prescription for End-Stage Renal Disease (ESRD) patients. However, an accurate DW assessment is difficult due to the complication of body components and individual variations. Our objective is to model a clinically practicable DW estimator. <i>Method</i>: We proposed a time series-based regression method to evaluate the weight fluctuation of HD patients according to Electronic Health Record (EHR). A total of 34 patients with 5100 HD sessions data were selected and partitioned into three groups; in HD-stabilized, HD-intolerant, and near-death. Each group's most recent 150 HD sessions data were adopted to evaluate the proposed model. <i>Results</i>: Within a 0.5 kg absolute error margin, our model achieved 95.44%, 91.95%, and 83.12% post-dialysis weight prediction accuracies for the HD-stabilized, HD-intolerant, and near-death groups, respectively. Within a 1%relative error margin, the proposed method achieved 97.99%, 95.36%, and 66.38% accuracies. For HD-stabilized patients, the Mean Absolute Error (MAE) of the proposed method was 0.17 kg \u00b1 0.04 kg. In the model comparison experiment, the performance test showed that the quality of the proposed model was superior to those of the state-of-the-art models. <i>Conclusion</i>: The outcome of this research indicates that the proposed model could potentially automate the clinical weight management for HD patients. <i>Clinical Impact</i>: This work can aid physicians to monitor and estimate DW. It can also be a health risk indicator for HD patients.",
      "year": "2019",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Zhaori Bi et al.",
      "keywords": "Electronic health record; Hemodialysis; Health records; Computer science; Medicine; Health care; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2019.2948604",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4381187992",
      "doi": "10.1109/tbme.2023.3238680",
      "title": "Deep Learning for Multiple Sclerosis Differentiation Using Multi-Stride Dynamics in Gait",
      "abstract": "Our proposed DL algorithms might contribute to efforts to automate MS diagnoses.",
      "year": "2023",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Rachneet Kaur et al.",
      "keywords": "Artificial intelligence; Intelligent design; Computer science; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2023.3238680",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392151785",
      "doi": "10.1109/access.2024.3370157",
      "title": "Classification of Oral Cancer Into Pre-Cancerous Stages From White Light Images Using LightGBM Algorithm",
      "abstract": "Cancer is one of the foremost reasons for death worldwide, with nearly 10 million deaths noted in 2020. Globally, oral cancer ranks sixth when compared to other cancers. It is lethal because most cases are noticed at advanced stages, which can be prevented if screened for or treated early in the pre-cancerous stages, successively leading to a significant decrease in the mortality rate. In this work, a method is proposed that can effectively differentiate between benign and malignant oral cavity lesions and also classify their pre-cancerous stages. The method involves exploring five distinct color spaces and extracting color and texture features, which are then classified using a machine learning technique called Light Gradient Boosting Machine (LightGBM). The overall performance is promising, outperforming the state-of-art methods for the task of oral cancer classification, with a testing accuracy of 99.25&#x0025;, precision of 99.18&#x0025;, recall of 99.31&#x0025;, f1-score of 99.24&#x0025; and specificity of 99.31&#x0025; for the binary classification, and testing accuracy of 98.88&#x0025;, precision of 98.86&#x0025;, recall of 97.92&#x0025;, f1-score of 98.38&#x0025; and specificity of 99.03&#x0025; for multi-class classification. The proposed method used hand-crafted features and a machine-learning classifier, which uses limited resources and is less time-consuming.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Bibek Goswami et al.",
      "keywords": "Computer science; Artificial intelligence; White light; Algorithm; Cancer; Pattern recognition (psychology); Medicine; Optics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3370157",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385453267",
      "doi": "10.1109/access.2023.3300376",
      "title": "Dependable DNN Accelerator for Safety-Critical Systems: A Review on the Aging Perspective",
      "abstract": "In the modern era, artificial intelligence (AI) and deep learning (DL) seamlessly integrate into various spheres of our daily lives. These cutting-edge disciplines have given rise to numerous safety-critical applications such as autonomous driving with a paramount concern on ensuring a high promise of dependability because of the high risk of human injury in the case of malfunction. Even the dependability becomes more crucial as shrinking CMOS technology feature size enhances resilience concerns due to factors like aging. In the context of DL accelerators, which heavily rely on the efficiency and speed of computations, addressing the effects of aging is of utmost significance to ensure their optimal design and performance. This paper addresses the overarching dependability issue of advanced deep neural networks (DNN) accelerators from the aging perspective. Especially, a comprehensive survey and taxonomy of techniques used to evaluate and mitigate aging effects are introduced. We cover different aging effects like permanent faults, timing errors, and lifetime issues. We review research by the layer-wise approach and categorize several resilience classes to bring out major features. The concluding part of this review highlights the questions answered and several future research directions. This study is expected to benefit researchers in different areas of DNN deployment, especially the dependability of this emergent paradigm.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Iraj Moghaddasi et al.",
      "keywords": "Dependability; Computer science; Perspective (graphical); Resilience (materials science); Risk analysis (engineering); Software deployment; Deep learning; Categorization; Artificial intelligence; Data science; Software engineering; Business",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3300376",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287636565",
      "doi": "10.1109/access.2023.3315343",
      "title": "RDIS: Random Drop Imputation With Self-Training for Incomplete Time Series Data",
      "abstract": "Time-series data with missing values are a common occurrence in various fields, including healthcare, meteorology, and robotics. The process of imputation aims to fill in the missing values with valid values. Most imputation methods implicitly train models due to the presence of missing values. In this paper, we propose Random Drop Imputation with Self-training (RDIS), a novel training method for time-series data imputation models. In RDIS, we generate extra missing values by applying a random drop to the observed values in incomplete data. We can explicitly train the imputation models by filling in the missing values. Moreover, we utilize self-training with pseudo values to exploit the original missing values. To enhance the quality of pseudo values, we set a threshold and filter them based on entropy calculation. To evaluate the effectiveness of RDIS for imputing time-series data, we test it across several imputation models and obtain competitive results on three real-world datasets.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Tae-Min Choi et al.",
      "keywords": "Imputation (statistics); Missing data; Computer science; Time series; Data mining; Artificial intelligence; Statistics; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3315343",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394994663",
      "doi": "10.1109/jbhi.2024.3392354",
      "title": "CLADSI: Deep Continual Learning for Alzheimer's Disease Stage Identification Using Accelerometer Data",
      "abstract": "Alzheimer's disease (AD) is a neurodegenerative disorder that can cause a significant impairment in physical and cognitive functions. Gait disturbances are also reported as a symptom of AD. Previous works have used Convolutional Neural Networks (CNNs) to analyze data provided by motion sensors that monitor Alzheimer's patients. However, these works have not explored continual learning algorithms that allow the CNN to configure itself as it receives new data from these sensors. This work proposes a method aimed at enabling CNNs to learn from a continuous stream of data from motion sensors without having full access to previous data. The CNN identifies the stage of AD from the analysis of data provided by motion sensors. The work includes an experimentation with data captured by accelerometers that monitored the activity of 35 Alzheimer's patients for a week in a daycare center. The CNN achieves an accuracy of 86,94%, 86,48% and 84,37% for 2, 3 and 4 experiences respectively. The proposal provides advantages to working with a continuous stream of data so that the CNN are constantly self-configuring without the intervention of a human. The work can be considered as promising and helpful in finding deep learning solutions in medical cases in which patients are constantly monitored.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Santos Bringas et al.",
      "keywords": "Convolutional neural network; Computer science; Accelerometer; Deep learning; Artificial intelligence; Motion (physics); Machine learning; Identification (biology); Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3392354",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3036622268",
      "doi": "10.1109/access.2020.3003138",
      "title": "Automatic Tumor Segmentation by Means of Deep Convolutional U-Net With Pre-Trained Encoder in PET Images",
      "abstract": "To assist physicists in developing radiation therapy treatment plans and in evaluating the effects of radiotherapy, an accurate and automatic tumor segmentation approach in positron emission tomography (PET) images is highly demanded in the clinical practice. In the present paper we investigate and construct a neural network architecture for auto-segmenting tumors by leveraging a 14-layer U-Net model with two blocks of a VGG19 encoder pre-trained with ImageNet. For pursuing efficient learning, a series of training strategies are proposed with limited training data. First, we apply a loss function based on Jaccard distance to re-balance the weights of training samples without re-weighting. Because of highly unbalanced data, re-weighting is an essential step but brings additional computation when cross-entropy loss function is used for medical image segmentation. Second, we import the DropBlock technique to replace the normal regularization dropout method as the former can help the U-Net efficiently avoid overfitting. We use a database containing 1309 PET images to train and test the proposed model. The mask, contour, and smoothed contour of a tumor are used as truths for teaching the proposed model. These are provided by expert radiologists. The segmentation accuracy compared to the truths is evaluated by calculating the Dice coefficient, Hausdorff distance, Jaccard index, sensitivity, and precision metrics. Extensive experimental results show that our method has achieved a relatively competitive performance in PET images on tumor segmentation. The volumes of the segmented tumors provided by our model would enable accurate automated identification and serial measurement of tumor volumes in PET images.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "LU Yong-zhou et al.",
      "keywords": "Jaccard index; Computer science; Artificial intelligence; Segmentation; Convolutional neural network; Cross entropy; Pattern recognition (psychology); Overfitting; S\u00f8rensen\u2013Dice coefficient; Weighting; Dice; Image segmentation; Deep learning; Artificial neural network; Computer vision; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3003138",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391468028",
      "doi": "10.1109/access.2024.3361832",
      "title": "Comparison of Electrodermal Activity Signal Decomposition Techniques for Emotion Recognition",
      "abstract": "Emotions play an essential role in human life as they are linked to well-being and markers of various diseases. Physiological signals can be used to assess emotions objectively and continuously. Electrodermal activity (EDA) is particularly interesting to assess emotions due to its relationship with the sympathetic nervous system. EDA signals are composed of tonic and phasic components that react differently to emotions, and various methods are available to obtain these components. However, the most accurate and effective method used for emotion analysis based on the phasic component of EDA has not been reported so far. This study presents the comparison of various EDA decomposition methods used for emotion detection based on levels of affective dimensions (arousal and valence) levels (low vs. high). In this study, EDA was decomposed using six methods, namely convex optimization-based EDA(cvxEDA), Time-Varying Sympathetic Activity (TVSymp), continuous decomposition analysis (CDA), dynamic causal modeling (DCM), BayesianEDA, and sparse deconvolution approach (Sparse). To test the most usable decomposition method for objective assessment of emotions, EDA signals from the database for emotion analysis using physiological signals (DEAP) were obtained. Statistical, morphological, Hjorth, and non-linear Entropy features were extracted from the phasic component obtained from each decomposition method and fed to the Random Forest and support vector machine classifiers for detection of arousal and valence affective dimension. TVSymp yielded the highest F1 score of 72.79&#x0025; and 73.49&#x0025; for classifying Arousal and Valence, respectively.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Yedukondala Rao Veeranki et al.",
      "keywords": "Computer science; Decomposition; SIGNAL (programming language); Speech recognition; Emotion recognition; Pattern recognition (psychology); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3361832",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313028924",
      "doi": "10.1109/access.2022.3228600",
      "title": "CNO-LSTM: A Chaotic Neural Oscillatory Long Short-Term Memory Model for Text Classification",
      "abstract": "Long Short-Term Memory (LSTM) networks are unique to exercise data in its memory cell with long-term memory as Natural Language Processing (NLP) tasks have inklings of intensive time and computational power due to their complex structures like magnitude language model Transformer required to pre-train and learn billions of data performing different NLP tasks. In this paper, a dynamic chaotic model is proposed for the objective of transforming neurons states in network with neural dynamic characteristics by restructuring LSTM as Chaotic Neural Oscillatory-Long-Short Term Memory (CNO-LSTM), where neurons in LSTM memory cells are weighed in substitutes by oscillatory neurons to speed up computational training of language model and improve text classification accuracy for real-world applications. From the implementation perspective, five popular datasets of general text classification including binary, multi classification and multi-label classification are used to compare with mainstream baseline models on NLP tasks. Results showed that the performance of CNO-LSTM, a simplified model structure and oscillatory neurons state in exercising different types of text classification tasks are above baseline models in terms of evaluation index such as Accuracy, Precision, Recall and F1. The main contributions are time reduction and improved accuracy. It achieved approximately 46.76&#x0025; of the highest reduction training time and 2.55&#x0025; accuracy compared with vanilla LSTM model. Further, it achieved approximately 35.86&#x0025; in time reduction compared with attention model without oscillatory indicating that the model restructure has reduced GPU dependency to improve training accuracy.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Nuobei Shi et al.",
      "keywords": "Computer science; Artificial intelligence; Artificial neural network; Recurrent neural network; Language model; Reduction (mathematics); Recall; Machine learning; Speech recognition; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3228600",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4395027831",
      "doi": "10.1109/access.2024.3392624",
      "title": "Machine Learning-Based Cellular Traffic Prediction Using Data Reduction Techniques",
      "abstract": "Estimating and analyzing traffic patterns become essential in managing Quality of Service (QoS) metrics while assessing internet data traffic in cellular networks. Cellular network planners frequently apply various approaches to predict network traffic. However, most existing studies focus on using the available local data to jointly build prediction models, facing data security challenges and time complexity, especially with multi-dimensional datasets. Therefore, this paper proposes a framework to handle traffic prediction with the considerable potential of Machine Learning (ML) algorithms. An Adaptive Machine Learning-based Cellular Traffic Prediction (AML-CTP) framework is presented to select a suitable ML algorithm for multi-dimensional datasets. Its objective is to streamline and speed up the selection of an appropriate model for predicting network traffic load. The framework employs two density-based clustering algorithms to categorize similar nearby traffic into various clusters, considering data similarity and convergence. Additionally, it assesses data quality and homogeneity by training models with data samples from each cluster to accurately determine the most suitable machine learning model. The optimal model is selected from four supervised predicting algorithms, reducing training time and hardware complexity. Two case studies from a popular telecommunication equipment corporation in Egypt are implemented using real-life cellular traffic with multi-dimensional features. The case studies show that the framework can help reduce the computational cost of training the model and reduce the risk of overfitting. The experimental results show that selecting the best prediction model training could save up to 85&#x0025; of computational time compared to two state-of-the-art techniques while achieving an accuracy of 98.8&#x0025;.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Heba Nashaat et al.",
      "keywords": "Computer science; Reduction (mathematics); Machine learning; Artificial intelligence; Data reduction; Data mining; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3392624",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390357562",
      "doi": "10.1109/access.2023.3348091",
      "title": "Development of an Early Warning System to Support Educational Planning Process by Identifying At-Risk Students",
      "abstract": "The development of data analysis techniques and intelligent systems has had a considerable impact on education, and has seen the emergence of the field of educational data mining (EDM). The Early Warning System (EWS) has been of great use in predicting at-risk students or analyzing learners&#x2019; performance. Our project concerns the development of an early warning system that takes into account a number of socio-cultural, structural and educational factors that have a direct impact on a student&#x2019;s decision to drop out of school. We have worked on an original database dedicated to this issue, which reflects our approach of seeking exhaustiveness and precision in the choice of dropout indicators. The model we built performed very well, particularly with the K-Nearest Neighbor (KNN) algorithm, with an accuracy rate of over 99.5&#x0025; for the training set and over 99.3&#x0025; for the test set. The results are visualized using a Django application we developed for this purpose, and we show how this can be useful for educational planning.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mustapha Skittou et al.",
      "keywords": "Computer science; Warning system; Field (mathematics); Process (computing); Early warning system; Dropout (neural networks); Set (abstract data type); Drop out; Educational data mining; Decision support system; Artificial intelligence; Machine learning; Data science; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3348091",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390969350",
      "doi": "10.1109/tcds.2024.3349593",
      "title": "Kernel-Ridge-Regression-Based Randomized Network for Brain Age Classification and Estimation",
      "abstract": "<p dir=\"ltr\">Accelerated brain aging and abnormalities are associated with variations in brain patterns. Effective and reliable assessment methods are required to accurately classify and estimate brain age. In this study, a brain age classification and estimation framework is proposed using structural magnetic resonance imaging (sMRI) scans, a 3-D convolutional neural network (3-D-CNN), and a kernel ridge regression-based random vector functional link (KRR-RVFL) network. We used 480 brain MRI images from the publicly availabel IXI database and segmented them into gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF) images to show age-related associations by region. Features from MRI images are extracted using 3-D-CNN and fed into the wavelet KRR-RVFL network for brain age classification and prediction. The proposed algorithm achieved high classification accuracy, 97.22%, 99.31%, and 95.83% for GM, WM, and CSF regions, respectively. Moreover, the proposed algorithm demonstrated excellent prediction accuracy with a mean absolute error (MAE) of <b>3.89</b> years, <b>3.64 </b>years, and <b>4.49</b> years for GM, WM, and CSF regions, confirming that changes in WM volume are significantly associated with normal brain aging. Additionally, voxel-based morphometry (VBM) examines age-related anatomical alterations in different brain regions in GM, WM, and CSF tissue volumes. <h2>Other Information</h2><p dir=\"ltr\">Published in: IEEE Transactions on Cognitive and Developmental Systems<br>License: <a href=\"https://creativecommons.org/licenses/by/4.0/deed.en\" target=\"_blank\">https://creativecommons.org/licenses/by/4.0/</a><br>See article on publisher's website: <a href=\"https://dx.doi.org/10.1109/tcds.2024.3349593\" target=\"_blank\">https://dx.doi.org/10.1109/tcds.2024.3349593</a>",
      "year": "2024",
      "journal": "IEEE Transactions on Cognitive and Developmental Systems",
      "authors": "Raveendra Pilli et al.",
      "keywords": "Artificial intelligence; Pattern recognition (psychology); Voxel; Computer science; White matter; Convolutional neural network; Support vector machine; Regression; Magnetic resonance imaging; Voxel-based morphometry; Brain morphometry; Kernel (algebra); Brain size; Medicine; Mathematics; Statistics; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcds.2024.3349593",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390692172",
      "doi": "10.1109/access.2024.3352436",
      "title": "Optimized Operation Management With Predicted Filling Levels of the Litter Bins for a Fleet of Autonomous Urban Service Robots",
      "abstract": "Autonomous smart waste management services are becoming an essential component of sustainable urbanization. However, the lack of data and insights from current service-providers impedes a reliable transition from labor-intensive to autonomous services. Deploying information gathering devices makes services expensive and resource-demanding. In project MARBLE (Mobile Autonomous RoBot for Litter Emptying) we are currently investigating the implementation of a fleet of service robots. In this framework, we could show that the absence of filling data of litter bins (LBs) hinders the possibility of providing an energy-efficient and time-effective service. Hence, we introduce an approach where machine learning-based predictions for filling levels of LBs, derived from our extensive data gathering, are used to effectively manage the autonomous emptying process. The novel Simulated Rebalancing approach in route-planning combined with the Knapsack algorithm ensures efficient service in comparison to the Nearest Neighbor algorithm. A promising 82&#x0025; filling level prediction accuracy was achieved with the XGBoost binary classifier, as compared to the 59&#x0025; baseline accuracy. Through incorporating the predicted filling level data in the Simulated Rebalancing approach, a reduction of 26&#x0025; in operational time and 31&#x0025; in energy consumption was achieved for our simulated tests for service-event-area (SEA) James-Simon-Monbijoupark in Berlin with 49 LBs.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Anton Pollak et al.",
      "keywords": "Computer science; Artificial intelligence; Service (business); Operations research; Data mining; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3352436",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388676599",
      "doi": "10.1109/access.2023.3332667",
      "title": "Crowdsensing for Road Pavement Condition Monitoring: Trends, Limitations, and Opportunities",
      "abstract": "Road Pavement Condition Monitoring (RPCM) is indispensable for proactive maintenance, especially amidst increasing traffic and unpredictable weather patterns. The demand for cost-efficient solutions leveraging emerging technologies such as the Internet of Things (IoT), Machine Learning (ML), and cloud computing is increasing. This work examines the evolution of RPCM solutions, examines the challenges, and proposes future improvements. An extensive literature review is presented which exposes the challenges with existing RPCM solutions. The assessment criteria are the sensory platform, algorithms employed, detected road deformities, and performance. The approaches employed in RPCM are examined including their advantages and limitations. A holistic assessment of RPCM methodologies is presented which includes threshold, dynamic time warping, computer vision, and ML approaches. It is determined that smartphone-based monitoring solutions incorporating data acquisition and ML are superior to other methods. Future research directions are presented considering the limitations of existing solutions and the goal of cost-effective and efficient RPCM solutions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Munawar Jan et al.",
      "keywords": "Variety (cybernetics); Computer science; Leverage (statistics); Data science; Process (computing); Cloud computing; Risk analysis (engineering); Scopus; Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3332667",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392667218",
      "doi": "10.1109/access.2024.3376237",
      "title": "Arabic Speech Recognition: Advancement and Challenges",
      "abstract": "Speech recognition is a captivating process that revolutionizes human-computer interactions, allowing us to interact and control machines through spoken commands. The foundation of speech recognition lies in understanding a given language&#x2019;s linguistic and textual characteristics. Although automatic speech recognition (ASR) systems flawlessly convert speech into text for various international languages, their implementation for Arabic remains inadequate. In this research, we diligently explore the current state of Arabic ASR systems and unveil the challenges encountered during their development. We categorize these challenges into two groups: those specific to the Arabic language and those more general. We propose strategies to overcome these obstacles and emphasize the need for ASR architectures tailored to the Arabic language&#x2019;s unique grammatical and phonetic structure. In addition, we provide a comprehensive and explicit description of various feature extraction methods, language models, and acoustic models utilized in the Arabic ASR system.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ashifur Rahman et al.",
      "keywords": "Computer science; Speech recognition; Arabic; Natural language processing; Artificial intelligence; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3376237",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394773562",
      "doi": "10.1109/access.2024.3388088",
      "title": "Overview of Vehicle-to-Vehicle Energy Sharing Infrastructure",
      "abstract": "Electric vehicles (EVs) play a pivotal role in fostering sustainable societies, industries, and economies. By curbing greenhouse gas emissions, enhancing air quality, and promoting energy independence, they represent a significant step toward a greener future. As the global EV market continues to expand over the coming decades, the demand for charging stations (CSs) will inevitably surge, necessitating substantial investments from both governments and private investors. In this context, vehicle-to-vehicle (V2V) energy sharing emerges as a transformative solution that can offer EV owners flexibility and energy security beyond the reliance on conventional CSs. This survey delves into the existing technologies harnessed in V2V energy sharing activities while addressing critical challenges to ensure the success of a V2V charge transfer system. It begins by outlining the research methodology, followed by an analysis of the technological landscape, pinpointing the latest advancements and identifying gaps in V2V energy sharing technologies. As a result, it proposes a comprehensive framework for a robust V2V energy and charge-sharing infrastructure. The survey also evaluates the financial and economic implications of V2V energy sharing, shedding light on the potential returns for stakeholders and investors. Furthermore, the survey discusses crucial policy and regulatory considerations necessary for a smooth and efficient integration of V2V systems into existing infrastructures. By elucidating solutions to address implementation challenges, the paper aims to pave the way for the successful adoption and widespread deployment of V2V energy sharing systems.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Marwa Alghawi et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3388088",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4379618878",
      "doi": "10.1109/access.2023.3283568",
      "title": "Automatic Early Diagnosis of Dome Galls in Cordia Dichotoma G. Forst. Using Deep Transfer Learning",
      "abstract": "There are several infections and diseases that can affect plants. Diagnosis of plant diseases is a challenging task. A fascinating method for identifying plant diseases is computer-based diagnosis using digital images of plant&#x2019;s leaves. Most of the earlier research in this field has been devoted to feature engineering and traditional machine learning (ML) techniques. Based on hand-crafted features taken from digital photographs of the plant&#x2019;s leaves, these methods identify various plant diseases. It can be challenging to use feature engineering to extract high-quality features from these digital images. Deep learning (DL) algorithms, have relieved feature engineering by automatically extracting and learning resilient features. However, the high number of parameters in conventional DL models typically leads to overfitting. Therefore, gradient vanishing problems in vast networks intensify learning failure and generalization errors. Additionally, getting a big dataset for starting from scratch to train a deep learning model is also difficult. To solve these issues to detect Dome Galls in <italic>Cordia dichotoma</italic> G. Forst. early, this research suggests quick and efficient deep transfer learning (DTL) model. In the proposed method, a custom dataset of <italic>Cordia dichotoma</italic> leaf images is created. 1784 images of <italic>Cordia dichotoma</italic> leaf are collected in real world environment, and offline augmentation techniques are applied for obtaining the final training dataset of 5400 images. Further, image preprocessing techniques are used to enhance the images. A DL model, Yolov4, has been modified and is trained for the early detection of dome galls in the leaves of Cordia. The model is trained using pre-trained weights, a process called transfer learning (TL). The model is tested on another set of 200 images, and the results show an accuracy of 95&#x0025; and an F1-score of 95.8&#x0025;. Experimental results show that the modified Yolov4 performs 3&#x0025; more accurately than the original Yolov4.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Muhammad Ayaz et al.",
      "keywords": "Dome (geology); Computer science; Botany; Artificial intelligence; Biology; Paleontology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3283568",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390969331",
      "doi": "10.1109/access.2024.3355816",
      "title": "Backdoor Attacks to Deep Neural Networks: A Survey of the Literature, Challenges, and Future Research Directions",
      "abstract": "Deep neural network (DNN) classifiers are potent instruments that can be used in various security-sensitive applications. Nonetheless, they are vulnerable to certain attacks that impede or distort their learning process. For example, backdoor attacks involve polluting the DNN learning set with a few samples from one or more source classes, which are then labeled as target classes by an attacker. Even if the DNN is trained on clean samples with no backdoors, this attack will still be successful if a backdoor pattern exists in the training data. Backdoor attacks are difficult to spot and can be used to make the DNN behave maliciously, depending on the target selected by the attacker. In this study, we survey the literature and highlight the latest advances in backdoor attack strategies and defense mechanisms. We finalize the discussion on challenges and open issues, as well as future research opportunities.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Orson Mengara et al.",
      "keywords": "Backdoor; Computer science; Set (abstract data type); Artificial neural network; Class (philosophy); Computer security; Deep learning; Process (computing); Artificial intelligence; Deep neural networks; Malware; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3355816",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4311413142",
      "doi": "10.1109/mts.2022.3219132",
      "title": "Humanistic Engineering: Engineering for the People",
      "abstract": "\"The core of the belief in progress is that human values and goals converge in parallel with our increasing knowledge. The twentieth century shows the contrary. Human beings use the power of scientific knowledge to assert and defend the values and goals they already have. New technologies can be used to alleviate suffering and enhance freedom. They can, and will, also be used to wage war and strengthen tyranny.\" \u2014John Gray <xref ref-type=\"bibr\" rid=\"ref10\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[10, p. 106]</xref>",
      "year": "2022",
      "journal": "IEEE Technology and Society Magazine",
      "authors": "Matthew L. Bolton",
      "keywords": "Humanism; Wage; Power (physics); Gray (unit); Computer science; Artificial intelligence; Political science; Engineering management; Engineering; Sociology; Law; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mts.2022.3219132",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3022941453",
      "doi": "10.1109/access.2020.2991298",
      "title": "Impact of a Photodiode\u2019s Angular Characteristics on RSS-Based VLP Accuracy",
      "abstract": "Photodiode (PD)-based Visible Light Positioning (VLP)-based localisation systems seem propitious for the low-cost tracking and route-configurable navigation of automated guided vehicles, found in warehouse settings. Delivering the required high accuracy, currently necessitates measuring and fitting the received power - distance relation. This paper shows that accurately modelling the PD receiver's angular characteristics obsoletes this calibrating fit, while still providing accurate positioning estimates. A new responsivity model Square (SQ) is proposed, which is a function of the square of the incidence angle rather than its cosine. Both its aptitude in matching real-life propagation and its associated localisation accuracy are verified using two extensive measurement sets, each detailing the propagation of a PD moving across a 2D plane 3 m below a 4-LED plane. SQ is compared to the responsivity and calibration fit models available in the literature. In conjunction with model-based fingerprinting positioning, SQ outscores the Lambertian and generalised Lambertian model in terms of the 90th percentile root-mean-square error (rMSE) p90 by 45.36 cm (83.1%) and 0.84 cm (8.4%) respectively for the non-Lambertian-like receiver. SQ exhibits an equivalent performance as the generalised Lambertian model for the Lambertian-like photodiode. Accounting for the appropriate receiver model can also boost trilateration's rMSE. A 50th percentile rMSE reduction of respectively 1.87 cm and 2.66 cm is found in the setup.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Sander Bastiaens et al.",
      "keywords": "Photodiode; Mean squared error; Responsivity; Trilateration; Calibration; Computer science; Root mean square; Optics; Mathematics; Algorithm; Detector; Physics; Acoustics; Statistics; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2991298",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4377007934",
      "doi": "10.1109/access.2023.3276757",
      "title": "Bias Detection for Customer Interaction Data: A Survey on Datasets, Methods, and Tools",
      "abstract": "With the increase in usage of machine learning models within many different aspects of customer interactions, it has become very clear that bias detection within associated customer interaction datasets has led to a critical focus on issues such as the identification of bias prior to model building, lack of understanding and transparency within models, and ultimately the prevention of biased predictions or classifications. This has never been more important since the introduction of the EU General Data Protection Regulation (GDPR) and the associated rule of &#x201C;right of explanation&#x201D;. In this paper, we survey the state of the art for bias detection, avoidance and mitigation within datasets, and the associated methods and tools available. Our purpose is to establish an understanding of how established customer interaction-based use cases can utilise these techniques. The focus is primarily on tackling the bias in unstructured text data as a pre-process prior to the machine learning model training phase. We hope that this research encourages the further establishment of responsible usage of customer interaction datasets to allow the prevention of bias being introduced into machine learning pipelines and to also allow greater awareness of the potential for further research in this area.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Andy Donald et al.",
      "keywords": "Computer science; Transparency (behavior); Identification (biology); Process (computing); Focus (optics); Data science; Machine learning; Data mining; Artificial intelligence; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3276757",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285179327",
      "doi": "10.1109/tits.2022.3182569",
      "title": "Complementing Location-Based Social Network Data With Mobility Data: A Pattern-Based Approach",
      "abstract": "Location-Based Social Networks can be profitably exploited to characterize citizens' activities in urban environments. However, collecting LBSN is potentially challenging due to privacy concerns, connectivity issues, and potential imbalances in LBSN service usage. We propose to complement LBSN data with mobility data in the analysis of citizens' activities in urban areas. Unlike the explicit insights provided by LBSN users, mobility data give implicit feedback on citizens' habits. This paper explores the spatial and temporal conditions under which user habits are coherent according to both sources and reports the most reliable common sequences of visited categories of Points-Of-Interests. To this aim, it relies on a multidimensional model in which recurrent citizens' activities are described by a new pattern type, namely the generalized activity pattern. It also detects the eventual presence of bias between LBSN and mobility user activities by customizing the established Statistical Parity metric. The motivations behind the detected bias are explained in terms of combinations of POI categories that are most likely to be the main causes. We evaluate the proposed approach on real-world data achieved from Foursquare check-ins, taxi service, and free-floating car sharing. The results highlight not only the complementarity of the data sources regarding specific POI categories, but also their interchangeability in many spatio-temporal conditions.",
      "year": "2022",
      "journal": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "Elena Daraio et al.",
      "keywords": "Complementarity (molecular biology); Computer science; Data mining; Metric (unit); Interchangeability; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tits.2022.3182569",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2980380893",
      "doi": "10.1109/access.2019.2947759",
      "title": "Non-Contact Infrared-Depth Camera-Based Method for Respiratory Rhythm Measurement While Driving",
      "abstract": "This work proposes a new non-contact method based on Infrared and Depth cameras to measure respiratory rhythm in real-life situations. The proposed algorithm consists on using both video feeds to track the movements of the subject in real-time, compute the location of the face and calculate the most suitable ROI to extract the respiratory signal in adult population. 20 subjects were measured while driving in a car simulator with no constraints other than the simulator itself. The algorithm has been validated using a commercial thorax plethysmography system. An opportunistic approach has been used to obtain pieces from the tests for each subject, thus making a more realistic approach to the real-life situations where the signal is likely to contain errors. The breath-to-breath respiratory signal and the instantaneous frequency from both methods has been computed from each piece to characterise the error between the proposed method and the reference system. The results show a high correlation between the measured rhythm from the reference method and the proposed method, with relatively low error results and good sensitivity in cycle detection and low errors for the instantaneous frequency between methods. The error results have also been compared with the ones obtained in previous studies showing a good agreement between the obtained results and the ones presented in the previous studies. No relationship between the length of the pieces and the error has been found either for the respiratory cycle signal or the instantaneous frequency signal. The proposed algorithm can be used to measure respiratory rhythm in unconstrained conditions and with opportunistic measurements, thus making it suitable to perform in real-life situations while driving. Further studies taking into account vibrations or light changing conditions are needed to confirm that the proposed method performs with the same accuracy with these constraints.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Marc Mateu-Mateus et al.",
      "keywords": "Computer science; SIGNAL (programming language); Measure (data warehouse); Computer vision; Artificial intelligence; Population; Sensitivity (control systems); Rhythm; Simulation; Algorithm; Speech recognition; Acoustics; Electronic engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2947759",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392694128",
      "doi": "10.1109/jstars.2024.3374818",
      "title": "Improving Geological Remote Sensing Interpretation Via a Contextually Enhanced Multiscale Feature Fusion Network",
      "abstract": "Geological remote sensing interpretation plays a pivotal role in the field of regional geological mapping, encompassing the analysis of rock, soil, and water features. However, these geological elements can be obscured by the surrounding geographical environment and can undergo modifications caused by geological activities. The former hinders the effectiveness of satellite remote sensing data, resulting in the invisibility of element features, while the latter leads to the complex distribution of element features and significant spatial variations of geological elements. Consequently, existing deep learning-based models for interpreting geological elements often exhibit limited accuracy. To address these issues, this study proposes the contextually enhanced multiscale feature fusion network for the efficient interpretation of geological elements. First, the context enhancement module is employed to extract abundant feature information and reinforce contextual features, aiming to capture essential features and strengthen their interconnections. Second, the multiscale feature fusion module incorporates the SimAM attention mechanism to adaptively learn features from different channels, emphasizing the feature information that contributes to interpretation results and maximizing the comprehensive and crucial feature information for each element. Extensive experiments demonstrate the superior performance of both the context enhancement module and the multiscale feature fusion module compared to several representative deep learning networks in terms of overall interpretation accuracy on two datasets. The model demonstrated improvements in oPA and mIoU of 2.4&#x0025; and 2.8&#x0025;, respectively, on the Landsat 8 dataset, and 3.5&#x0025; and 3.2&#x0025;, respectively, on the Sentinel-2 dataset.",
      "year": "2024",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "\u5eb7\u5229 \u5343\u8cc0 et al.",
      "keywords": "Feature (linguistics); Context (archaeology); Computer science; Interpretation (philosophy); Field (mathematics); Remote sensing; Artificial intelligence; Feature learning; Data mining; Sensor fusion; Invisibility; Pattern recognition (psychology); Geology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2024.3374818",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4378905748",
      "doi": "10.1109/access.2023.3281655",
      "title": "Improving Security Architecture of Internet of Medical Things: A Systematic Literature Review",
      "abstract": "Ever since its emergence, the concept internet of things (IoT) has been applied in many fields. In the area of medical sciences, a new concept &#x201C;Internet of Medical Things&#x201D; (IoMT) has been explored. IoMT establishes a connection between humans &#x0026; machines and serves both of them. It has been expected that, by 2025, services of IoMT would reach the entire world. IoMT has covered a wide scope pertaining to health but unfortunately been facing many security challenges. Healthcare systems consist of sensitive and significant data, which is unorganized and noisy and needs additional power to be calculated for effective analysis &#x0026; workable results. This data is worked upon for the purpose of making critical decisions. Therefore, it has become the main target of Cyber Criminals. The need of robust security and privacy (S&#x0026;P) is gradually increasing as more and more devices are getting connected to the IoMT. The S&#x0026;P of the IoMT has now become a great challenge, considering the utmost significance and vulnerability of the data in the healthcare industry. Lack of sufficient S&#x0026;P in IoMT devices keeps the patient&#x2019; privacy at high stake. This research is intended to propose a Security Model to cope with these Security threats, attacks, issues and challenges. The proposed model has been developed by thoroughly investigating all the major security models through a detailed systematic literature review. The SLR has been conducted to explore all the security threats, security attacks, security issues and security challenges. Extensive meta-analysis has been performed for each of the defined category in order to prioritize these risks. After analyzing these risks, a comprehensive security model has been proposed. The interface has been developed in Python which is well structured, user friendly and easy to implement. The developed module not only identify and prioritize the risks but also automatically control different level of threats. The developed system also contain user intimation modules in case of any threat. This research is based on a very flexible and comprehensive model, which would be highly beneficial to future researchers who desire to work on existing models for the improvement as well as to those who wish to create new security models for IoMT.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mudasir Mahmood et al.",
      "keywords": "Computer science; Computer security; Scope (computer science); The Internet; Vulnerability (computing); Internet privacy; Cloud computing security; World Wide Web; Cloud computing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3281655",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3120258198",
      "doi": "10.1109/access.2021.3049798",
      "title": "Quality of Experience Comparison of Stereoscopic 3D Videos in Different Projection Devices: Flat Screen, Panoramic Screen and Virtual Reality Headset",
      "abstract": "The use of Stereoscopic 3D (S3D) videos has been popular in commercial markets with ongoing developments in the field of visual entertainment in recent years. A wide variety of projection methods of 3D video content is currently available, such as projection to a panoramic screen and projection of omnidirectional video content from head mounted displays using Virtual Reality (VR) technology. This article investigates the Quality of Experience (QoE) and associated Visually Induced Motion Sickness (VIMS) caused by the viewing of S3D videos. The investigations used three different projection screens: a 3D flat screen, a 3D panoramic screen in a hemispherical shaped room and a VR headset. Several assessment methods including a Simulator Sickness Questionnaire (SSQ), ElectroEncephaloGraphy (EEG), and measurement tools for eye blink rate detection were applied to measure the QoE experienced by viewers. The SSQ scores were also compared with the behavioral data such as attention and meditation levels and enjoyment ratings acquired from different video content and projection screens. The results indicate that the projection screen is a key factor affecting the level of visual fatigue, VIMS and QoE assessments, which are discussed in-depth in the article.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Siu-Ming Choy et al.",
      "keywords": "Headset; Computer science; Stereoscopy; Virtual reality; Simulator sickness; Projection (relational algebra); Computer vision; Artificial intelligence; Computer graphics (images)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3049798",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3130837094",
      "doi": "10.1109/tits.2021.3057240",
      "title": "Mining Actionable Patterns of Road Mobility From Heterogeneous Traffic Data Using Biclustering",
      "abstract": "The comprehensive access to road traffic patterns in the continuously growing urban areas is key to achieve a sustainable mobility. However, the inherent complexity of urban traffic poses many challenges to achieve this goal, including: i) the need to integrate heterogeneous views of road traffic (such as speed limits, jam size, delay, throughput) from available sources; ii) the complex spatiotemporal intricacies of geolocalized speed and loop counter data; iii) the need to mine congestion patterns robust to the inherent traffic variability and unexpected occurrence of events, taking also into consideration the varying degrees of congestion severity; and iv) the need to guarantee the statistical significance and interpretability of the target patterns. In the context of our work, a road traffic pattern is a recurrent congestion profile (w.r.t. speed limits, jam extent and flow) that can span multiple locations and time periods within a day. Biclustering, the discovery of coherent subspaces (local patterns) within real-valued data, has unique properties of interest, being positioned to unravel such traffic patterns, while satisfying the aforementioned challenges. Despite its relevance, the potentialities of applying biclustering in mobility domains remain unexplored. This work proposes a structured view on why, when and how to apply biclustering for mining traffic patterns of road mobility, a subject remaining largely unexplored up to date. Using the city of Lisbon as a guiding case, we illustrate the relevance of biclustering geolocalized speed data and loop counter data. The gathered results confirm the role of biclustering in comprehensively finding statistically significant and actionable spatiotemporal associations of road mobility.",
      "year": "2021",
      "journal": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "Francisco Neves et al.",
      "keywords": "Computer science; Context (archaeology); Relevance (law); Interpretability; Data mining; Biclustering; Traffic congestion; Cluster analysis; Artificial intelligence; Transport engineering; Geography; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tits.2021.3057240",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4211019430",
      "doi": "10.23919/jsc.2021.0020",
      "title": "Social Scale and Collective Computation: Does Information Processing Limit Rate of Growth in Scale?",
      "abstract": "Collective computation is the process by which groups store and share information to arrive at decisions for collective behavior. How societies engage in effective collective computation depends partly on their scale. Social arrangements and technologies that work for small- and mid-scale societies are inadequate for dealing effectively with the much larger communication loads that societies face during the growth in scale that is a hallmark of the Holocene. An important bottleneck for growth may be the development of systems for persistent recording of information (writing), and perhaps also the abstraction of money for generalizing exchange mechanisms. Building on Shin et al., we identify a Scale Threshold to be crossed before societies can develop such systems, and an Information Threshold which, once crossed, allows more or less unlimited growth in scale. We introduce several additional articles in this special issue that elaborate or evaluate this Thresholds Model for particular types of societies or times and places in the world.",
      "year": "2022",
      "journal": "Journal of Social Computing",
      "authors": "Timothy A. Kohler et al.",
      "keywords": "Bottleneck; Scale (ratio); Computation; Computer science; Abstraction; Data science; Process (computing); Collective behavior; Limit (mathematics); Sociology; Social science; Mathematics; Geography; Epistemology; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2021.0020",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388145374",
      "doi": "10.1109/access.2023.3329139",
      "title": "A Tabular Variational Auto Encoder-Based Hybrid Model for Imbalanced Data Classification With Feature Selection",
      "abstract": "Cancer is the deadliest disease in humankind. Ovarian Cancer (OC) is important among female-specific cancers. Epithelial Ovarian Cancer (EOC) is the most commonly occurring subtype of OC. The disease is identified in later stages due to the unrevealed symptoms in the early stages. Gene Expression experiments and machine learning (ML) methodologies can lead to preventive care of OC. This can be achieved by identifying malignant gene transformations earlier and using precision medicine that aids in fast recovery. The proposed hybrid Tabular Variational Auto Encoder oriented dictionary based Stratified K Fold Cross Validation (TVAE&#x005F;dict&#x005F;SKCV) is an effective model to handle the threat. The main objective is to assess the significance of EOC screening variables for categorizing high-risk patients. It initially generated synthetic data using the TVAE model to increase the EOC subtype data size from the Cancer Cell Line Encyclopedia. The synthesized data were balanced utilizing the Synthetic Minority Oversampling Technique. Significant features were selected with the Boruta Feature Selection method. The HYPERPARAMETERS were fine-tuned employing Optuna optimizer and applied enhanced SKCV with Random Forest classifier. The TVAE&#x005F;dict&#x005F;SKCV method with Boruta acquired an accuracy of 98.5 &#x0025; and outperformed the experiment with Lasso Feature Selection and with original data. Shapley Additive explanations summarize the main features which classify. Optuna efficiently reduced the computing time compared to the Grid Search Cross Validation optimizer.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Asha Abraham et al.",
      "keywords": "Feature selection; Computer science; Hyperparameter; Oversampling; Classifier (UML); Data classification; Artificial intelligence; Data mining; Pattern recognition (psychology); Random forest; Encoder; Machine learning; Bandwidth (computing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3329139",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391407055",
      "doi": "10.1109/access.2024.3360480",
      "title": "Exploring Sentence Parsing: OpenAI API-Based and Hybrid Parser-Based Approaches",
      "abstract": "This study focuses on the fundamental process of parsing sentences to create semantic graphs from textual documents. It introduces novel techniques for parsing phrases within semantic graph-based induction, employing both ChatGPT-based and Hybrid parser-based approaches. Through a thorough analysis, the study evaluates the performance of these methods in generating semantic networks from text, particularly in capturing detailed event descriptions and relationships. Results indicate a slight advantage in accuracy for the Hybrid parser-based approach (87&#x0025;) compared to ChatGPT (85&#x0025;) in sentence parsing tasks. Furthermore, efficiency analysis reveals that ChatGPT&#x2019;s response quality varies with prompt sizes, while the Hybrid parser-based method consistently maintains excellent response quality.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Walelign Tewabe Sewunetie et al.",
      "keywords": "Parsing; Computer science; Top-down parsing; Bottom-up parsing; Parser combinator; Natural language processing; Artificial intelligence; Sentence; Programming language; Top-down parsing language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3360480",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386766733",
      "doi": "10.1109/access.2023.3316032",
      "title": "EOG-Based Reading Detection in the Wild Using Spectrograms and Nested Classification Approach",
      "abstract": "<p dir=\"ltr\">Electrooculography, also known as EOG, is a technique that is used to calculate the corneo-retinal standing potential, which is located between the cornea and the retina of the human eye. Applications of EOG include eye disease diagnosis and eye movement tracking. There has been various research on reading activity detection from EOG signals in controlled laboratory settings. However, determining reading behaviours from data collected from real-world environments remains a challenging problem. Detecting reading in practical scenarios can lead us to track our daily reading activity, thereby improving our learning experience and even workplace productivity. Tracking regular reading behaviour can also lead to further research in cognitive psychology, literacy development, reading motivation, and reading comprehension. In this study, we investigated an electrooculogram dataset that was collected on the field from 10 users who were engaged in their daily activities on two separate days. We propose a pipeline combining the statistical features with deep learning features from pre-trained ImageNet models. To detect the fine-grained reading activities, we adopted a nested classification approach. Initially, we differentiate between reading and not reading and then we employ an additional classification step to discriminate among three distinct types of reading activities. With our pipeline, we could achieve 66.56% accuracy in detecting the reading activities whereas the original dataset publication showed a baseline performance of only 32%. <h2>Other Information</h2><p dir=\"ltr\">Published in: IEEE Access<br>License: <a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">https://creativecommons.org/licenses/by/4.0/</a><br>See article on publisher's website: <a href=\"https://dx.doi.org/10.1109/access.2023.3316032\" target=\"_blank\">https://dx.doi.org/10.1109/access.2023.3316032</a>",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sriman Bidhan Baray et al.",
      "keywords": "Reading (process); Computer science; Electrooculography; Artificial intelligence; Eye movement; Eye tracking; Speech recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3316032",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394994608",
      "doi": "10.1109/access.2024.3391903",
      "title": "METAEDUCATION: State-of-the-Art Methodology for Empowering Feature Education",
      "abstract": "Education has become the most essential endeavor in our lives. There are many ways to learn, but only a few capture my interest. However, education has grown more interesting and attractive with the aid of technology. A fascinating step forward in education is merging the real and digital worlds through Virtual Reality (VR) and Augmented Reality (AR). The term used to denote the digital world is the &#x201C;Metaverse.&#x201D; Metaverse enables us to engage in virtual conversations with others by utilizing avatars that mirror ourselves. Using Metaverse technology, readers of certain books have discovered ways to study rather than focusing on their screens. Several advanced technologies, such as Blockchain, Big Data, Artificial Intelligence (AI), game design, Internet computing, and the Internet of Things (IoT), are integrated into the Metaverse, an innovative idea in social work. The integration of the Metaverse is expected to contribute significantly to the advancement of education. On the other hand, it is important to acknowledge that the development of educational Metaverse concepts is still in its early stages. Addressing issues related to the Metaverse&#x2019;s objective in the classroom is critical. This research aims to conduct a comprehensive literature review on integrating the Metaverse in educational environments. We will start by giving a general overview of the Metaverse, its educational uses, and some background on the motivations behind its use. Moving on to the educational aspect, we examine the Metaverse, identifying its defining characteristics, including educational environments, Integrated technologies, and customized instructions. Following this, we suggested an essential structure for how teachers and students could connect in the Metaverse classroom. In addition, we investigate the most recent case studies of Metaverse in education, including investigations conducted by academic institutions and technology enterprises. Finally, this paper thoroughly analyzes the Metaverse in education, covering its current technological state, challenges, opportunities, prospects, and feature directions. The findings of our research indicate that the Metaverse is a valuable resource for educational purposes.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Dileep Kumar Murala",
      "keywords": "Computer science; State (computer science); Feature (linguistics); Artificial intelligence; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3391903",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388820040",
      "doi": "10.1109/access.2023.3335199",
      "title": "Imbalanced Bearing Fault Diagnosis Based on RFH-GAN and PSA-DRSN",
      "abstract": "Bearings in actual working environments typically operate in healthy conditions, resulting in an imbalance in the data collected data. The majority of the collected data are related to bearings in healthy conditions, with insufficient data related to faults. This imbalance leads to accuracy and stability issues in deep learning models used for diagnosis purposes. To address this issue, we propose employing a residual factorized hierarchical search-based generative adversarial network (RFH-GAN) and a residual shrinkage network with pyramidal squeezed attention (PSA-DRSN) for unbalanced fault diagnosis. The process involves transforming vibration signals collected from bearings into time-frequency (TF) domain images through the utilization of the continuous wavelet transform (CWT). The enhanced RFH-GAN generates synthetic fault samples with authentic characteristics, while the PSA-DRSN performs fault diagnosis. The experimental findings substantiate that our method improves the quality of the generated samples, mitigates the data imbalance issues that are inherent in conventional diagnosis methods, and attains heightened precision and efficacy in fault diagnosis tasks.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zhidan Zhong et al.",
      "keywords": "Fault (geology); Computer science; Residual; Artificial intelligence; Bearing (navigation); Process (computing); Wavelet; Vibration; Pattern recognition (psychology); Deep learning; Wavelet transform; Data mining; Machine learning; Real-time computing; Algorithm; Acoustics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3335199",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388543831",
      "doi": "10.1109/access.2023.3331720",
      "title": "An Artificial Intelligence Based Approach Toward Predicting Mortality in Head and Neck Cancer Patients With Relation to Smoking and Clinical Data",
      "abstract": "Head and neck cancers are one of the most common cancers in the world which affects the mouth, throat, and tongue regions of the human body. Lifestyle factors such as smoking, and tobacco have been long associated with the generation of cancerous cells in the body. This paper is a novel approach towards extracting the correlation between these life factors and head and neck cancers, supported by crucial cancer attributes like the tumor-node-metastasis and human papilloma virus. Mortality prediction algorithms in cases of head and neck cancers will help doctors pre-determine the factors that are most crucial and help deliver specialized and targeted treatments. The paper used eight machine learning and four deep learning hyper-parameter tuned models to predict the mortality rate associated with head and neck cancer. The maximum accuracy of 98.8&#x0025; was achieved by the gradient boosting algorithm in the paper. The feature importance of smoking and human papilloma virus positivity using the same classifier was approximately 4&#x0025; and 2.5&#x0025; respectively. The most influential factor in mortality prediction was the duration of follow-up from diagnosis to the last contact date, with 40.8&#x0025; importance. Quantitative results from the area under the receiver operating characteristic curve substantiate the classifiers&#x2019; performance, with a maximum value of 0.99 for gradient boosting. This paper is bound to impact many medical professionals by helping them predict the mortality of cancer patients and aid appropriate treatments.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Naman Dhariwal et al.",
      "keywords": "Receiver operating characteristic; Head and neck cancer; Medicine; Artificial intelligence; Tongue; Gradient boosting; Machine learning; Random forest; Mortality rate; Classifier (UML); Cancer; Computer science; Internal medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3331720",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3125378889",
      "doi": "10.1109/access.2021.3054823",
      "title": "Survival Time Prediction of Breast Cancer Patients Using Feature Selection Algorithm Crystall",
      "abstract": "Breast cancer is one of main causes of death for women. Most of the existing survival analyses focus on the features' associations with whether the patients may survive five years or not. The personalized question remains largely unresolved about how long a breast cancer patient will live. This study aims to predict the patient-specific survival time of breast cancer patients. It formulates the personalized question into two machine learning problems. The first problem is the binary classification of whether a patient will live longer than five years or not. The second one is to build a regression model to predict the patient's survival time within five years. The methylome of a breast cancer patient is used for the prediction. A new algorithm Crystall is presented to find the methylomic features for this regression model. Our models perform well in the above two problems, and achieve the mean absolute error (MAE) of about 1 month for predicting how long a breast cancer patient will live within five years. The detected biomarker genes demonstrate close connections with breast cancers.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Shuai Liu et al.",
      "keywords": "Breast cancer; Feature selection; Machine learning; Cancer; Artificial intelligence; Computer science; Feature (linguistics); Algorithm; Survival analysis; Biomarker; Oncology; Medicine; Internal medicine; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3054823",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392406185",
      "doi": "10.1109/access.2024.3373264",
      "title": "Face Recognition for Automatic Border Control: A Systematic Literature Review",
      "abstract": "<italic>Context:</italic> Facial recognition is one aspect of research that still has broad potential for research and development, especially as a security system for automatic border control. There is a significant continuous need to understand the characteristics of system development by considering system complexity and implementation environmental conditions. <italic>Objective:</italic> This research aims to provide in-depth insight and assist researchers and practitioners in developing large-scale facial detection systems for automatic border control. It has a high level of complexity that necessitates special attention to several factors such as real-time system, privacy, variations in facial features, quantity of data, model, and implementation environment. <italic>Method:</italic> This study used a systematic literature review as a research methodology by Kitchenham. The analysis was based on studies published between 2019 and 2023 on using facial recognition in autonomous border control. A systematic analysis of research was conducted by examining 112 scientific studies from 7884 papers in scientific databases. <italic>Result:</italic> Based on research questions, 12 types of threats are often encountered in ABC face recognition, which can be seen in <xref ref-type=\"sec\" rid=\"sec4\">section IV</xref>. The method most widely used is deep learning, especially for detecting emotional features and morphing attacks. Apart from that, most datasets used are private because they require collaboration with organizations and are related to privacy. Three remaining issues are encountered in this research, including face recognition methodology, privacy, and architecture for large-scale development. <italic>Future directions:</italic> This study suggests two future research topics to enhance achieving desired results in large-scale and complex advancements in a methodical and structured while upholding privacy ethics.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Fadhil Hidayat et al.",
      "keywords": "Computer science; Face (sociological concept); Facial recognition system; Artificial intelligence; Computer vision; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3373264",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388756079",
      "doi": "10.1109/access.2023.3334278",
      "title": "A Systematic Literature Review on Social Media Slang Analytics in Contemporary Discourse",
      "abstract": "Social media slang, encompassing informal language, words, phrases, and acronyms on digital platforms, reflects the dynamic nature of online communication. Analyzing social media slang offers valuable insights for organizations and researchers, enabling a deeper understanding of communication trends, sentiment analysis, and user behavior in the digital sphere. It plays a pivotal role in shaping effective marketing strategies and enhancing communication, ultimately facilitating informed decision-making in the digital age. In our study, we conducted a systematic review of research articles from the Web of Science and Scopus databases, spanning the years 2016 to 2023. Our rigorous selection process, based on quality assessments as per PRISMA guidelines, revealed several key findings. Social media slang exhibits a remarkable adaptability to different platforms, mirroring the communication styles and user cultures found on each. Notably, it influences user behavior, impacting interactions, content engagement, and decision-making, particularly in marketing and communication strategies. Furthermore, our research highlights the value of social media slang in sentiment analysis, providing insights into public sentiment and supporting well-informed decision-making. Our study underscores the versatile applications of slang analytics across various industries and research domains, emphasizing its pivotal role in providing specialized insights and enhancing communication strategies. In conclusion, our research offers a comprehensive understanding of the dynamic landscape of informal language in the context of contemporary digital communication, furnishing valuable insights that inform decision-making, refine marketing strategies, and enhance communication.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Aishwarya Sundaram et al.",
      "keywords": "Slang; Social media; Computer science; Data science; Social media analytics; Context (archaeology); Sentiment analysis; Knowledge management; World Wide Web; Artificial intelligence; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3334278",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3106978254",
      "doi": "10.1109/access.2020.3042342",
      "title": "Heath-PRIOR: An Intelligent Ensemble Architecture to Identify Risk Cases in Healthcare",
      "abstract": "Smart city environments, when applied to healthcare, improve the quality of people's lives, enabling, for instance, disease prediction and treatment monitoring. In medical settings, case prioritization is of great importance, with beneficial outcomes both in terms of patient health and physicians' daily work. Recommender systems are an alternative to automatically integrate the data generated in such environments with predictive models and recommend actions, content, or services. The data produced by smart devices are accurate and reliable for predictive and decision-making contexts. This study main purpose is to assist patients and doctors in the early detection of disease or prediction of postoperative worsening through constant monitoring. To achieve this objective, this study proposes an architecture for recommender systems applied to healthcare, which can prioritize emergency cases. The architecture brings an ensemble approach for prediction, which adopts multiple Machine Learning algorithms. The methodology used to carry out the study followed three steps. First, a systematic literature mapping, second, the construction and development of the architecture, and third, the evaluation through two case studies. The results demonstrated the feasibility of the proposal. The predictions are promising and adherent to the application context for accurate datasets with a low amount of noises or missing values.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Felipe Neves et al.",
      "keywords": "Computer science; Context (archaeology); Architecture; Recommender system; Health care; Ensemble learning; Quality (philosophy); Machine learning; Predictive analytics; Artificial intelligence; Prioritization; Risk analysis (engineering); Process management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3042342",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312561388",
      "doi": "10.1109/access.2022.3219832",
      "title": "Improving the Forecasting and Classification of Extreme Events in Imbalanced Time Series Through Block Resampling in the Joint Predictor-Forecast Space",
      "abstract": "A novel resampling strategy is introduced to improve the forecasting and classification accuracies of events in imbalanced time series (ITS) containing a mix of low probability extreme observations and high probability normal observations. The lag-based strategy mitigates the imbalance problem by modelling an ITS as a composition of normal and extreme observations, combining the input predictor variables and the associated forecast output into moving blocks, categorizing the blocks as extreme event (EE) or normal event (NE) blocks, and selectively resampling the blocks. Combining the predictor variables and the associated forecast enables resampling of the input and output simultaneously in the joint predictor-forecast (PF)-space. Imbalance is decreased by oversampling the minority EE blocks and undersampling the majority NE blocks. The EE blocks are oversampled using a modification of block bootstrapping and a modification of the synthetic minority oversampling technique. The Box-Cox transform is employed to decrease the pattern complexity caused by the mixing of disparate extreme and normal observations in the ITS. Convolution neural networks and long-short term memory deep neural networks (DNNs) are selected for forecast modelling and tested on a set of simulated and real sub-basin outflow ITS. The root mean square errors, forecast plots, and classification accuracies show that the hybrid forecasting and classification DNN models trained on the block-balanced training sets extracted from the Box-Cox transformed ITS dramatically outperform the corresponding baseline models which are trained directly with the ITS.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Xiaoqian Chen et al.",
      "keywords": "Resampling; Oversampling; Bootstrapping (finance); Computer science; Block (permutation group theory); Event (particle physics); Undersampling; Artificial neural network; Artificial intelligence; Pattern recognition (psychology); Machine learning; Algorithm; Statistics; Mathematics; Econometrics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3219832",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3200281777",
      "doi": "10.1109/jstars.2021.3112209",
      "title": "Interband Retrieval and Classification Using the Multilabeled Sentinel-2 BigEarthNet Archive",
      "abstract": "Conventional remote sensing data analysis techniques have a significant bottleneck of operating on a selectively chosen small-scale dataset. Availability of an enormous volume of data demands handling large-scale, diverse data, which have been made possible with neural network-based architectures. This article exploits the contextual information capturing ability of deep neural networks, particularly investigating multispectral band properties from Sentinel-2 image patches. Besides, an increase in the spatial resolution often leads to nonlinear mixing of land-cover types within a target resolution cell. We recognize this fact and group the bands according to their spatial resolutions, and propose a classification and retrieval framework. We design a representation learning framework for classifying the multispectral data by first utilizing all the bands and then using the grouped bands according to their spatial resolutions. We also propose a novel triplet-loss function for multilabeled images and use it to design an interband group retrieval framework. We demonstrate its effectiveness over the conventional triplet-loss function. Finally, we present a comprehensive discussion of the obtained results. We thoroughly analyze the performance of the band groups on various land-cover and land-use areas from agro-forestry regions, water bodies, and human-made structures. Experimental results for the classification and retrieval framework on the benchmarked BigEarthNet dataset exhibit marked improvements over existing studies.",
      "year": "2021",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Ushasi Chaudhuri et al.",
      "keywords": "Computer science; Land cover; Bottleneck; Contextual image classification; Exploit; Image resolution; Multispectral image; Convolutional neural network; Remote sensing; Pattern recognition (psychology); Artificial intelligence; Spectral bands; Scale (ratio); Data mining; Image (mathematics); Land use; Geography; Cartography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2021.3112209",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389104898",
      "doi": "10.1109/access.2023.3334910",
      "title": "Performance Analysis of Federated Learning Algorithms for Multilingual Protest News Detection Using Pre-Trained DistilBERT and BERT",
      "abstract": "Data scientists in the Natural Language Processing (NLP) field confront the challenge of reconciling the necessity for data-centric analyses with the imperative to safeguard sensitive information, all while managing the substantial costs linked to the collection process of training data. In a Federated Learning (FL) system, these challenges can be alleviated by the training of a global model, eliminating the need to centralize sensitive data of clients. However, distributed NLP data is usually Non-Independent and Identically Distributed (Non-IID), which leads to poorer generalizability of the global model when trained with Federated Averaging (FedAvg). Recently proposed extensions to FedAvg promise to improve the global model performance on Non-IID data. Yet, such advanced FL algorithms trained on multilingual Non-IID texts have not been studied in industry and academia in detail. This paper compares, for the first time, the FL algorithms: FedAvg, FedAvgM, FedYogi, FedAdam and FedAdagrad for a binary text classification task using 12078 tailored real-world news reports in English, Portuguese, Spanish and Hindi. For this objective, pre-trained DistilBERT and BERT models fine-tuned with these texts are used. The paper results show that FedYogi is the most stable and robust FL algorithm when DistilBERT is used, achieving an average macro F1 score of 0.7789 for IID and 0.7755 for Non-IID protest news. The study also exhibits that BERT models trained with weighted FedAvg and FedAvgM can achieve a similar prediction power as centralized language models, demonstrating the potential of leveraging FL in the NLP domain without the need to collect data centrally.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Pascal Riedel et al.",
      "keywords": "Computer science; Generalizability theory; Artificial intelligence; Machine learning; Process (computing); Natural language processing; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3334910",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4319993368",
      "doi": "10.1109/access.2023.3240084",
      "title": "Hypertension Monitoring by a Real Time Management System for Patients in Community and Its Data Mining by Vector Autoregressive Model",
      "abstract": "Blood pressure has a 24-hour repetitive and regular variation which shows circadian rhythm. Using the multivariate time series analysis method of vector autoregressive model, we could realize the simultaneous prediction for both systolic and diastolic blood pressures. We choose blood pressure from 6 AM to 10 AM in 3 weeks as an episode to construct a prediction model. Missing values were imputed by regression models. Subsequently, we defined segments as positive or negative segments according to blood pressure measurements. The predictions were accomplished by vector autoregressive model (VAR). Both positive and negative segments were randomly selected from each patient to summarize the effect of prediction models. In this study, the MAPE (Mean Absolute Percentage Error) of systolic blood pressure and diastolic blood pressure were both less than 10&#x0025;, indicating that the VAR model was adaptable in predicting the blood pressure of hypertensive patients. Based on VAR, we could provide early warning to breakthrough of blood pressure thresholds. The sensitivity, specificity, and accuracy for patients in the training sets were 77.50&#x0025;, 81.58 &#x0025;, and 79.49&#x0025; respectively, and the sensitivity, specificity, and accuracy for patients in the training sets were 76.92&#x0025;, 80.00&#x0025; and 78.43&#x0025; respectively. This research took information of both systolic and diastolic blood pressures at the same time to establish the VAR models and enabled simultaneous prediction for systolic and diastolic blood pressure.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Siyang Chen et al.",
      "keywords": "Blood pressure; Autoregressive model; Diastole; Cardiology; Mean absolute percentage error; Internal medicine; Autoregressive integrated moving average; Time series; Multivariate statistics; Medicine; Autoregressive\u2013moving-average model; Computer science; Mathematics; Statistics; Mean squared error",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3240084",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4296705752",
      "doi": "10.1109/tnsre.2022.3208312",
      "title": "The Effects of Bilateral Phase-Dependent Closed-Loop Vibration Stimulation With Motor Imagery Paradigm",
      "abstract": "Vibration stimulation has been shown to have the potential to improve the activation pattern of unilateral motor imagery (MI) and to promote motor recovery. However, in the widely used left and right hand MI brain-computer interface (BCI) paradigm, the vibration stimuli cannot be directly applied to the imaginary side due to the spontaneity of imagery. In this study, we proposed a method of phase-dependent closed-loop vibration stimulation to be applied on both hands, and explored the effects of different vibration stimuli on the left and right hand MI-BCI. Eighteen healthy subjects were recruited and asked to perform, in sequence, MI tasks under three different conditions of vibratory feedback, which were no vibration stimulus (MI), phase-dependent closed-loop vibration stimulus (PDS), and continuous vibration stimulus (CS). Then the performance of the left and right hand MI-BCI and the patterns of brain oscillation were compared and analyzed under these different stimulation conditions. The results showed that vibration stimulation effectively boosted the activation of the sensorimotor cortex and enhanced the functional connectivity among sensorimotor-related brain regions during MI. The closed-loop stimulation evoked stronger event-related desynchronization patterns on the contralateral side of the imagined hand compared to continuous stimulation. There was a more obvious distinction between left hand task and right hand task. In addition, phase-dependent closed-loop vibration stimulation increased classification accuracy by approximately 7% (paired t-test, p=0.004, n=18) compared to MI alone, while continuous vibration stimulation only increased it by 4% (paired t-test, p=0.067, n=18). This result further demonstrated the effectiveness of the phase-dependent closed-loop vibration stimulation method in improving the overall performance of the MI paradigm and is expected to be further applied in areas such as stroke rehabilitation in the future.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Wenbin Zhang et al.",
      "keywords": "Stimulation; Stimulus (psychology); Motor imagery; Brain\u2013computer interface; Vibration; Psychology; Neuroscience; Motor cortex; Electroencephalography; Physics; Acoustics; Cognitive psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3208312",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392157443",
      "doi": "10.1109/access.2024.3369674",
      "title": "Toward Improved Classification of Perceived Stress Using Time Domain Features",
      "abstract": "Perceived stress is the predominant mental health concern in this age of development and progress. Timely and precise recognition of perceived stress is vital for appropriate and effective treatment. Previously, many studies intended to classify perceived stress with considerable accuracy using electroencephalography (EEG). This research study aims to accurately classify perceived stress with a lesser number of electrodes by using significant features identified by the information-gain technique. The dataset employed in this research comprises EEG signals from twenty-eight participants in a closed-eye state, utilizing commercially available Muse EEG headbands. We have preprocessed EEG data and performed analysis on EEG data spanning 210 seconds. Two segmentation techniques have been employed: non-overlap and overlap. After segmentation, twenty-time domain features have been extracted, and feature selection has been performed using an information-gain-based method. It has been applied to enhance feature relevance and to reduce the dimensionality of feature vectors. To label the EEG data into stressed and non-stressed groups, the Perceived Stress Scale (PSS) questionnaire has been utilized. Employing a Random Forest classifier alongside the overlap segmentation technique, our proposed method attained a maximum classification accuracy of 93.8%. This accuracy surpasses existing stress classification schemes found in the literature with a similar number of electrodes.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Usman Rauf et al.",
      "keywords": "Computer science; Stress (linguistics); Domain (mathematical analysis); Pattern recognition (psychology); Artificial intelligence; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3369674",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392908771",
      "doi": "10.1109/access.2024.3378097",
      "title": "Colposcopic Image Segmentation Based on Feature Refinement and Attention",
      "abstract": "The current computer-aided diagnosis for cervical cancer screening encounters issues with missing detailed information during colposcopic image segmentation and incomplete edge delineation. To overcome these challenges, this study introduces the RUC-U2Net architecture, which enhances image segmentation through feature refinement and upsampling connections. Two variants are developed: RUC-U2Net and the lightweight RUC&#x002B;-U2Net. Initially, a feature refinement module that leverages an attention mechanism is proposed to improve detail capture by the model&#x2019;s fundamental unit during downsampling. Subsequently, the integration of diagonal attention in connecting peer-level encoders and decoders supplements finer semantic details to the decoder&#x2019;s feature maps, addressing the problem of incomplete edge segmentation. Finally, the application of the Focal Tversky loss function allows the model to concentrate on difficult samples, mitigating the challenges posed by imbalanced distributions of positive and negative samples in training datasets. Experimental evaluations on three publicly available datasets demonstrate that the proposed models significantly outperform existing methods across seven performance metrics, evidencing their superior segmentation accuracy.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Yuxi He et al.",
      "keywords": "Computer science; Upsampling; Feature (linguistics); Segmentation; Artificial intelligence; Pattern recognition (psychology); Encoder; Image segmentation; Enhanced Data Rates for GSM Evolution; Inference; Image (mathematics); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3378097",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4207036512",
      "doi": "10.1109/access.2022.3145969",
      "title": "FastMDE: A Fast CNN Architecture for Monocular Depth Estimation at High Resolution",
      "abstract": "A depth map helps robots and autonomous vehicles (AVs) visualize the three-dimensional world to navigate and localize neighboring obstacles. However, it is difficult to develop a deep learning model that can estimate the depth map from a single image in real-time. This study proposes a fast monocular depth estimation model named <italic>FastMDE</italic> by optimizing the deep convolutional neural network according to the encoder-decoder architecture. The decoder needs to obtain partial and semantic feature maps from the encoding phase to improve the depth estimation accuracy. Therefore, we designed FastMDE with two effective strategies. The first one involved redesigning the skip connection with the features of the squeeze-excitation module to obtain partial and semantic feature maps of the encoding phase. The second strategy involved redesigning the decoder by using the fusion dense block to permit the usage of high-resolution features that were learned earlier in the network before upsampling. The proposed FastMDE model utilizes only 4.1 M parameters, which is much lesser than the parameters utilized by state-of-art models. Thus, FastDME has a higher accuracy and lower latency than previous models. This study also demonstrates that MDE can leverage deep neural networks in real-time (i.e., 30 fps) with the Linux embedded board Nvidia Jetson Xavier NX. The model can facilitate the development and applications with superior performances and easy deployment on an embedded platform.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Thien-Thanh Dao et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Deep learning; Encoder; Leverage (statistics); Upsampling; Feature (linguistics); Computer vision; Decoding methods; Image (mathematics); Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3145969",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312742786",
      "doi": "10.1109/access.2022.3230152",
      "title": "OurRank: A Software Requirements Prioritization Method Based on Qualitative Assessment and Cost-Benefit Prediction",
      "abstract": "Requirements prioritization is an activity aimed at determining the essential requirements to include in a software release. Although there are several prioritization methods to systematize this task, there are still unresolved challenges. Existing methods do not guarantee that requirements prioritization meets stakeholder expectations and goals. This is because most prioritization methods operate by considering only quantitative information, making it difficult to formally capture stakeholder interests and perspectives that can rather be made explicit in qualitative terms. Likewise, methods including qualitative information only consider elements associated with benefit estimation, that is, positive aspects of the project, but neglect costs or negative aspects. As a result, the prioritization process is driven by a partial view of constraints. Such methods also fail at capturing and combining expert knowledge that decision-makers can bring into the decision-making process. In this research, we propose a novel method for software requirements prioritization, which facilitates incorporating experts&#x2019; qualitative assessment at the outset of the prioritization process and considers both benefit and cost constraints. Details of the method are presented, together with a case study describing a real application scenario. Recommendations and guidelines regarding the application of the method are proposed based on the results of the case study.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Luis Rojas et al.",
      "keywords": "Prioritization; Requirement prioritization; Computer science; Stakeholder; Process (computing); Risk analysis (engineering); Software; Management science; Requirements management; Requirements analysis; Engineering; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3230152",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390872858",
      "doi": "10.1109/jstars.2024.3353754",
      "title": "Poverty Estimation Using a ConvLSTM-Based Model With Multisource Remote Sensing Data: A Case Study in Nigeria",
      "abstract": "Poverty is a global challenge, the effects of which are felt on the individual to national scale. To develop effective support policies to reduce poverty, local governments require precise poverty distribution data, which are lacking in many areas. In this study, we proposed a model to estimate poverty on a spatial scale of 10 &#x00D7; 10 km by combining features extracted from multiple data sources, including nighttime light remote sensing data, normalized difference vegetation index, surface reflectance, land cover type, and slope data, and applied the model to Nigeria. Considering that the trends of environmental factors contain valid information related to poverty, time-series features were extracted through convolutional long short-term memory and used for the assessment. The poverty level is represented by the wealth index derived from the Demographic and Health Survey Program. The model exhibited good ability to estimate poverty, with an <italic>R</italic><sup>2</sup> of 0.73 between the actual and estimated wealth index in Nigeria in 2018. Applying the proposed model to poverty estimation for Nigeria in 2021 yielded an <italic>R</italic><sup>2</sup> value of 0.69, indicating good generalization ability. To further validate model reliability, we compared the assessment results with high-resolution satellite imagery and a state-level multidimensional poverty index. We also investigated the impact of incorporating time-series features on the accuracy of poverty assessment. Results showed that the addition of time-series features increased the accuracy of poverty estimation from 0.64 to 0.73. The proposed method has valuable applications for estimating poverty at the grid scale in countries without such data.",
      "year": "2024",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Jie Tang et al.",
      "keywords": "Poverty; Small area estimation; Index (typography); Estimation; Scale (ratio); Statistics; Computer science; Econometrics; Geography; Mathematics; Economic growth; Economics; Cartography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2024.3353754",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393864386",
      "doi": "10.1109/jstars.2024.3384511",
      "title": "Deep-Learning-Based Marine Aquaculture Zone Extractions From Dual-Polarimetric SAR Imagery",
      "abstract": "Efficient monitoring of marine aquaculture zones (MAZs) is crucial for facilitating coastal resource management. To achieve this, we developed a specialized deep convolutional neural network tailored for extracting MAZs from synthetic aperture radar (SAR) imagery, integrating prior analytical knowledge of MAZ imaging features. A total of 47 Sentinel-1 dual-polarized (VV and VH) SAR images spanning 2016&#x2013;2023 in China&#x0027;s Subei Sandbanks along the Yellow Sea coast were collected due to appropriate tidal level and acquired time. We first comprehensively analyzed of normalized radar cross section (NRCS) values for MAZs under varying tidal levels and aquaculture facility structures. Rising tide-induced submergence resulted in a significant mean NRCS reduction of 7.01 dB (VV) and 4.54 dB (VH), causing MAZ signals to resemble seawater. In addition, during low tide, volume scattering from the net screen on the aquaculture rafts increased VH-polarized image recognizability, with a smaller NRCS overlap (64&#x0025;) between MAZs and tidal flats compared to VV-polarized images. Hence, VH-polarized images taken during low tide with intact aquaculture facilities were selected for dataset construction due to their reliability in characterizing MAZs. Building upon the classical U-Net framework, we introduced four modifications informed by our imaging characteristics analysis to enhance the model&#x0027;s performance. Testing experiments demonstrated an impressive F1-score of 94.77&#x0025;, highlighting the effectiveness of incorporating prior knowledge into refining deep learning models. Applying the model to SAR images from 2016 to 2023 revealed concentrated MAZs in the relatively flat southeastern Subei Sandbanks, with a noticeable scale decline post-2021 resulting in a 67.65&#x0025; reduction over the years.",
      "year": "2024",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Wantai Chen et al.",
      "keywords": "Remote sensing; Synthetic aperture radar; Geology; Radar imaging; Computer science; Aquaculture; Polarimetry; Artificial intelligence; Dual (grammatical number); Fish <Actinopterygii>; Radar; Fishery; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2024.3384511",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4319878680",
      "doi": "10.1109/access.2023.3244088",
      "title": "Datasets for the Quality Assessment of Light Field Imaging: Comparison and Future Directions",
      "abstract": "With the increasing research focus on light field imaging in recent years, it has become essential for researchers in this field to either benefit from access to equipped laboratories with light field acquisition devices and displays or to have access to publicly available light field imaging datasets. Some datasets are indeed available, each with a different nature. For instance, some contain real world images or sources while others are based on purely synthetic images or sources generated by computer graphic tools; others are a combination of both. Datasets for the quality assessment of light field content include pristine light field content as well as sources affected by different levels of impairments. The latter are tested subjectively by a panel of viewers and often objective metrics are also calculated. This paper presents a comprehensive comparative review of 33 publicly available datasets that span from content-only datasets to specific task based datasets and quality assessment datasets. While our aim is to review and investigate what each dataset has to offer and which tests had been considered by their proposers, we also take the opportunity to leverage the results of previous studies to identify and discuss the challenges ahead and identify the areas with potential for improvement.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Edris Shafiee et al.",
      "keywords": "Leverage (statistics); Computer science; Field (mathematics); Data science; Quality (philosophy); Light field; Task (project management); Focus (optics); Information retrieval; Artificial intelligence; Systems engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3244088",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391365556",
      "doi": "10.1109/tnsre.2024.3360137",
      "title": "Temporal Alpha Dissimilarity of ADHD Brain Network in Comparison With CPT and CATA",
      "abstract": "Attention deficit hyperactivity disorder (ADHD) is a chronic neurological and psychiatric disorder that affects children during their development. To find neural patterns for ADHD and provide subjective features as decision references to assist specialists and physicians. Many studies have been devoted to investigating the neural dynamics of the brain through resting-state or continuous performance tests (CPT) with EEG or functional magnetic resonance imaging (fMRI). The present study used coherence, which is one of the functional connectivity (FC) methods, to analyze the neural patterns of children and adolescents (8-16 years old) under CPT and continuous auditory test of attention (CATA) task. In the meantime, electroencephalography (EEG) oscillations were recorded by a wireless brain-computer interface (BCI). 72 children were enrolled, of which 53 participants were diagnosed with ADHD and 19 presented to be typical developing (TD). The experimental results exhibited a higher difference in alpha and theta bands between the TD group and the ADHD group. While the differences between the TD group and the ADHD group in all four frequency domains were greater than under CPT conditions. Statistically significant differences ( [Formula: see text]) were observed between the ADHD and TD groups in the alpha rhythm during the CATA task in the short-range of coherence. For the temporal lobe FC during the CATA task, the TD group exhibited statistically significantly FC ( [Formula: see text]) in the alpha rhythm compared to the ADHD group. These findings offering new possibilities for more techniques and diagnostic methods in finding more ADHD features. The differences in alpha and beta frequencies were more pronounced in the ADHD group during the CPT task compared to the CATA task. Additionally, the disparities in brain activity were more evident across delta, theta, alpha and beta frequency domains when the task given was a CATA as opposed to a CPT. The findings presented the underlying mechanisms of the FC differences between children and adolescents with ADHD. Moreover, these findings should extend to use machine learning approaches to assist the ADHD classification and diagnosis.",
      "year": "2024",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Jo-Wei Lin et al.",
      "keywords": "Electroencephalography; Alpha (finance); Attention deficit hyperactivity disorder; Psychology; Functional magnetic resonance imaging; Audiology; Temporal lobe; Resting state fMRI; Brain activity and meditation; Alpha wave; Task (project management); Developmental psychology; Neuroscience; Epilepsy; Psychiatry; Medicine; Psychometrics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2024.3360137",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312542766",
      "doi": "10.1109/access.2022.3217770",
      "title": "A Statistical Learning Approach to Evaluate Factors Associated With Post-Traumatic Stress Symptoms in Physicians: Insights From the COVID-19 Pandemic",
      "abstract": "Physicians facing the COVID-19 pandemic are likely to experience acute and chronic, and often unpredictable, occupational stressors that can incur post-traumatic stress symptoms (PTSS), prevention of which is of utmost importance to enhance healthcare workforce efficiency. Unlike previous studies, in this paper we developed a generalized data-driven framework to generate insights into the complex, nonlinear associations of cognitive/occupational factors with physicians&#x2019; PTSS-risk. Data were collected from practicing physicians in the 18 states with the largest COVID-19 cases by deploying a cross-sectional, anonymous, web-based survey, following the second COVID-19 peak in the US. Analyses revealed that physicians directly treating COVID-19 patients (frontline) were at higher occupational risk of PTSS than those who didn&#x2019;t (secondline). We implemented a suite of eight statistical learning algorithms to evaluate the associations between cognitive/occupational factors and PTSS in frontline physicians. We found that random forest outperformed all other models, in particular the traditionally-used logistic regression by 6.4&#x0025; (F1-score) and 9.6&#x0025; (accuracy) in goodness-of-fit performance, and 4.8&#x0025; (F1-score) and 4.6&#x0025; (accuracy) in predictive performance, indicating existence of complex interactions and nonlinearity in associations between the cognitive/occupational factors and PTSS-risk. Our results show that depression, burnout, negative coping, fears of contracting/transmitting COVID-19, perceived stigma, and insufficient resources to treat COVID-19 patients are positively associated with PTSS-risk, while higher resilience and support from employer/friends/family/significant others are negatively associated with PTSS-risk. Insights obtained from this study will help to bring new attention to frontline physicians, allowing for more informed prioritization of their care during future pandemics/epidemics.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Sayanti Mukherjee et al.",
      "keywords": "Workforce; Logistic regression; Burnout; Pandemic; Coronavirus disease 2019 (COVID-19); Cognition; Clinical psychology; Psychology; Coping (psychology); Mental health; Stressor; Occupational stress; Medicine; Psychiatry; Computer science; Machine learning; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3217770",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2996546656",
      "doi": "10.1109/access.2019.2958474",
      "title": "Employing Environmental Data and Machine Learning to Improve Mobile Health Receptivity",
      "abstract": "Behavioral intervention strategies can be enhanced by recognizing human activities using eHealth technologies. As we find after a thorough literature review, activity spotting and added insights may be used to detect daily routines inferring receptivity for mobile notifications similar to just-in-time support. Towards this end, this work develops a model, using machine learning, to analyze the motivation of digital mental health users that answer self-assessment questions in their everyday lives through an intelligent mobile application. A uniform and extensible sequence prediction model combining environmental data with everyday activities has been created and validated for proof of concept through an experiment. We find that the reported receptivity is not sequentially predictable on its own, the mean error and standard deviation are only slightly below by-chance comparison. Nevertheless, predicting the upcoming activity shows to cover about 39% of the day (up to 58% in the best case) and can be linked to user individual intervention preferences to indirectly find an opportune moment of receptivity. Therefore, we introduce an application comprising the influences of sensor data on activities and intervention thresholds, as well as allowing for preferred events on a weekly basis. As a result of combining those multiple approaches, promising avenues for innovative behavioral assessments are possible. Identifying and segmenting the appropriate set of activities is key. Consequently, deliberate and thoughtful design lays the foundation for further development within research projects by extending the activity weighting process or introducing a model reinforcement.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Max-Marcel Theilig et al.",
      "keywords": "Computer science; Machine learning; Weighting; Receptivity; Artificial intelligence; Process (computing); Intervention (counseling); Set (abstract data type); Human\u2013computer interaction; mHealth; Everyday life; Data science; Psychological intervention; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2958474",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4327661581",
      "doi": "10.1109/jstars.2023.3258059",
      "title": "Machine Learning Approaches for Road Condition Monitoring Using Synthetic Aperture Radar",
      "abstract": "Airborne Synthetic Aperture Radar (SAR) has the potential to monitor remotely the road traffic infrastructure on a large scale. Of particular interest is the road surface roughness, which is an important road safety parameter. For this task, novel algorithms need to be developed. Machine learning approaches, such as Artificial Neural Networks (ANN) and Random Forest Regression, which can perform non-linear regression, can achieve&#13;\\nthis goal. This work considers fully polarimetric airborne radar datasets captured with DLR\u2019s airborne F-SAR radar system. Several machine learning-based approaches were tested on the datasets to estimate road surface roughness. The resulting models were then compared with ground truth surface roughness values and also with the semi-empirical surface roughness model studied in previous work.",
      "year": "2023",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Lucas Germano Rischioni et al.",
      "keywords": "Synthetic aperture radar; Computer science; Surface roughness; Radar; Random forest; Artificial intelligence; Remote sensing; Ground truth; Machine learning; Artificial neural network; Radar imaging; Computer vision; Geology; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2023.3258059",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386322019",
      "doi": "10.1109/jbhi.2023.3310869",
      "title": "Decentralized Data-Privacy Preserving Deep-Learning Approaches for Enhancing Inter-Database Generalization in Automatic Sleep Staging",
      "abstract": "Automatic sleep staging has been an active field of development. Despite multiple efforts, the area remains a focus of research interest. Indeed, while promising results have reported in past literature, uptake of automatic sleep scoring in the clinical setting remains low. One of the current issues regards the difficulty to generalization performance results beyond the local testing scenario, i.e. across data from different clinics. Issues derived from data-privacy restrictions, that generally apply in the medical domain, pose additional difficulties in the successful development of these methods. We propose the use of several decentralized deep-learning approaches, namely ensemble models and federated learning, for robust inter-database performance generalization and data-privacy preservation in automatic sleep staging scenario. Specifically, we explore four ensemble combination strategies (max-voting, output averaging, size-proportional weighting, and Nelder-Mead) and present a new federated learning algorithm, so-called sub-sampled federated stochastic gradient descent (ssFedSGD). To evaluate generalization capabilities of such approaches, experimental procedures are carried out using a leaving-one-database-out direct-transfer scenario on six independent and heterogeneous public sleep staging databases. The resulting performance is compared with respect to two baseline approaches involving single-database and centralized multiple-database derived models. Our results show that proposed decentralized learning methods outperform baseline local approaches, and provide similar generalization results to centralized database-combined approaches. We conclude that these methods are more preferable choices, as they come with additional advantages concerning improved scalability, flexible design, and data-privacy preservation.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Adriana Anido-Alonso et al.",
      "keywords": "Computer science; Generalization; Artificial intelligence; Scalability; Machine learning; Stochastic gradient descent; Weighting; Database; Deep learning; Transfer of learning; Baseline (sea); Information privacy; Data mining; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3310869",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391454427",
      "doi": "10.1109/jstars.2024.3361183",
      "title": "Forest Disturbance Detection via Self-Supervised and Transfer Learning With Sentinel-1&amp;2 Images",
      "abstract": "In this study, we examine the potential of leveraging self-supervised learning (SSL) and transfer learning methodologies for forest disturbance mapping using Earth Observation (EO) data. Our focus is on natural disturbances caused by windthrow and snowload damages. Particularly, we investigate the potential of knowledge-distillation-based contrastive learning approaches to obtain comprehensive representations of forest structure changes using Copernicus Sentinel-1 and Sentinel-2 satellite imagery. Leveraging pretrained backbone models from knowledge distillation, we employ transfer learning based on deep change vector analysis to delineate forest changes. We demonstrate developed approaches on two use cases, namely, mapping windthown forest using bitemporal Sentinel-1 and Sentinel-2 images, and mapping forest areas damaged by excessive snowload using bitemporal Sentinel-1 images. Developed self-supervised models were compared in a benchmarking exercise. The best results were provided by pixel-level contrastive learning for Sentinel-1-based snowload damage mapping with an overall accuracy of 84% and an F1 score of 0.567, and for Sentinel-2-based forest windthrow mapping with an overall accuracy of 76.5% and an F1 score of 0.692. We expect that developed methodologies can be useful for mapping also other types of forest disturbances using Copernicus Sentinel images or similar EO data. Our findings underscore the potential of SSL and transfer learning for enhancing forest disturbance detection using EO.",
      "year": "2024",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "R\u0131dvan Salih Kuzu et al.",
      "keywords": "Artificial intelligence; Computer science; Transfer of learning; Deep learning; Random forest; Satellite imagery; Machine learning; Vegetation (pathology); Remote sensing; Pattern recognition (psychology); Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2024.3361183",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388145353",
      "doi": "10.1109/tuffc.2023.3329119",
      "title": "Review of Deep Learning Approaches for Interleaved Photoacoustic and Ultrasound (PAUS) Imaging",
      "abstract": "Photoacoustic (PA) imaging provides optical contrast at relatively large depths within the human body, compared to other optical methods, at ultrasound (US) spatial resolution. By integrating real-time PA and US (PAUS) modalities, PAUS imaging has the potential to become a routine clinical modality bringing the molecular sensitivity of optics to medical US imaging. For applications where the full capabilities of clinical US scanners must be maintained in PAUS, conventional limited view and bandwidth transducers must be used. This approach, however, cannot provide high-quality maps of PA sources, especially vascular structures. Deep learning (DL) using data-driven modeling with minimal human design has been very effective in medical imaging, medical data analysis, and disease diagnosis, and has the potential to overcome many of the technical limitations of current PAUS imaging systems. The primary purpose of this article is to summarize the background and current status of DL applications in PAUS imaging. It also looks beyond current approaches to identify remaining challenges and opportunities for robust translation of PAUS technologies to the clinic.",
      "year": "2023",
      "journal": "IEEE Transactions on Ultrasonics Ferroelectrics and Frequency Control",
      "authors": "MinWoo Kim et al.",
      "keywords": "Photoacoustic imaging in biomedicine; Modalities; Ultrasound imaging; Modality (human\u2013computer interaction); Ultrasound; Medical imaging; Optical imaging; Optoacoustic imaging; Medical physics; Engineering; Computer science; Medicine; Artificial intelligence; Radiology; Acoustics; Physics; Optics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tuffc.2023.3329119",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297325296",
      "doi": "10.1109/mc.2022.3190786",
      "title": "Machine Intelligence for Human Health: A Few Noteworthy Cases",
      "abstract": "Many machine learning solutions are effectively used in health care for detecting diseases, supporting doctors, helping patients, improving health-care processes, and saving lives. This article discusses several success stories of computing benefiting humanity in this significant application sector.",
      "year": "2022",
      "journal": "Computer",
      "authors": "Domenico Talia",
      "keywords": "Humanity; Computer science; Health care; Artificial intelligence; Data science; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mc.2022.3190786",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319878207",
      "doi": "10.1109/taffc.2023.3244041",
      "title": "Measuring and Fostering Diversity in Affective Computing Research",
      "abstract": "This work presents a longitudinal study of diversity among the Affective Computing research community members. We explore several dimensions of diversity, including gender, geography, institutional types of affiliations and selected combinations of dimensions. We cover the last 10 years of the IEEE Transactions on Affective Computing (TAFFC) journal and the International Conference on Affective Computing and Intelligent Interaction (ACII), the primary sources of publications in Affective Computing. We also present an analysis of diversity among the members of the Association for the Advancement of Affective Computing (AAAC). Our findings reveal a \u201cleaky pipeline\u201d in the field, with a low \u2013albeit slowly increasing over the years\u2013 representation of women. They also show that academic institutions clearly dominate publications, ahead of industry and governmental centres. In terms of geography, most publications come from the USA, contributions from Latin America or Africa being almost non-existent. Lastly, we find that diversity in the characteristics of researchers (gender and geographic location) influences diversity in the topics. To conclude, we analyse initiatives that have been undertaken in other AI-related research communities to foster diversity, and recommend a set of initiatives that could be applied to the Affective Computing field to increase diversity in its different facets. The diversity data collected in this work are publicly available, ensuring strict personal data protection and governance rules.",
      "year": "2023",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Isabelle Hupont et al.",
      "keywords": "Diversity (politics); Affective computing; Psychology; Cognitive psychology; Social psychology; Computer science; Human\u2013computer interaction; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taffc.2023.3244041",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3035781705",
      "doi": "10.1109/access.2020.3003624",
      "title": "Notice of Violation of IEEE Publication Principles: Deep Learning Assisted Image Interactive Framework for Brain Image Segmentation",
      "abstract": "Exacting medical imaging, surgical planning, and many others are very important to handle brain image segmentation. The Convolutional Neural Networks (CNN) has been developed by the efficient auto segmentation technology. In fact, the clinical outcomes are not appropriately specific and detailed. Nevertheless, the lack of sensitivity to images and lack of generality is reduced in traditionally invisible object classes. In this paper, Deep Learning Assisted Image Interactive Medical Image Segmentation (DL-IIMIS) is proposed to tackle these difficulties by including CNNs in the bounding box and scribble-based pipeline. To adapt a CNN model to one test frame, it is proposed that image fine tuning and geodesic transformations can be either unsupervised or supervised. In this frame, two applications are involved: 2-D multi-organ magnetic resonance (MR) segmentation, with only two types of training and 3-D segmentation within brain tumor center and in entire brain tumors with different MR sequences where only one MR sequence is reported. Compared with other algorithms, the proposed framework can output a better performance in brain image segmentation.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Yibo Han et al.",
      "keywords": "Notice; Deep learning; Computer science; Segmentation; Artificial intelligence; Convolutional neural network; Image segmentation; Image (mathematics); Medical imaging",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3003624",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4378647831",
      "doi": "10.1109/jstars.2023.3280905",
      "title": "Generation of Hypothetical Radiances for Missing Green and Red Bands in Geostationary Environment Monitoring Spectrometer",
      "abstract": "True-color imagery is essential for an intuitive comprehension of atmospheric data. However, the Geostationary Environment Monitoring Spectrometer (GEMS) of the geostationary Korea multipurpose satellite (GK) 2B lacks green and red bands, which limits its ability to monitor atmospheric environments. To mitigate this issue, we suggest an innovative method of generating virtual GEMS green and red bands using conditional generative adversarial networks with data observed in the blue-green-red (RGB) bands of the Advanced Meteorological Imager sensor, a payload of the GK-2A satellite. The paired datasets of the AMI blue band and the AMI RGB bands were used to train and test the data-to-data (D2D) translation model. Using the GEMS blue band as input data, the D2D model generated GEMS hypothetical radiance data at the green and red bands. Our results show that the D2D model generated hypothetical GEMS green and red bands with outstanding performance. The averaged values of the correlation coefficient, root-mean-square error, and bias between the observed and D2D-generated GEMS blue band were 0.999, 3.450 W&#x002F;cm<sup>2</sup>&#x002F;cm&#x002F;sr, and &#x2212;1.858 W&#x002F;cm<sup>2</sup>&#x002F;cm&#x002F;sr, respectively. This research is expected to significantly contribute to the monitoring and comprehension of atmospheric environments in Asia and potentially improve the GEMS&#x0027;s global ability to monitor air quality. Additionally, the proposed method has the potential to enhance the capabilities of other satellites with limited spectral bands.",
      "year": "2023",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Han-Sol Ryu et al.",
      "keywords": "Geostationary orbit; Radiance; Remote sensing; RGB color model; Computer science; Environmental science; Satellite; Spectral bands; Atmospheric correction; Artificial intelligence; Physics; Geology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2023.3280905",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391164068",
      "doi": "10.1109/access.2024.3357980",
      "title": "Combinatorial Analysis of Deep Learning and Machine Learning Video Captioning Studies: A Systematic Literature Review",
      "abstract": "Recent improvements formulated in the area of video captioning have brought rapid revolutions in its methods and the performance of its models. Machine learning and deep learning techniques are both employed in this regard. However, there is a lack of tracing the latest studies and their remarkable results. Although several studies have been proposed employing the ML and DL algorithms in different other areas, there is no systematic review utilizing the video captioning task. This study aims to examine, evaluate, and synthesize the primary studies into a thorough Systematic Literature Review (SLR) that provides a general overview of the methods used for video captioning. We performed the SLR to determine the research problems under which machine learning models were preferred over the deep learning models and vice versa. We collected a total of 1,656 studies retrieved from four electronic databases; Scopus, WoS, IEEE Xplore, and ACM, based on our search string from which 162 published studies passed the selection criteria related to one primary and two secondary research questions after a systematic process. Moreover, insufficient data collection and inefficient comparison of results are common issues identified during the review process. We conclude that the 2D/3D CNN for video feature extraction and LSTM for caption generation, METEOR and BLEU performance evaluation tools, and MSVD dataset are most frequently employed for video captioning. Our study is the pioneer in comparing the implementation of ML and DL algorithms employing the video captioning area. Thus, our study will accelerate the critical assessment of the state-of-the-art in other research fields of video analysis and human-computer interaction.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Tanzila Kehkashan et al.",
      "keywords": "Closed captioning; Computer science; Artificial intelligence; Machine learning; Deep learning; Natural language processing; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3357980",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390224490",
      "doi": "10.1109/access.2023.3347635",
      "title": "Multidimensional Prediction Method for Thyroid Cancer Based on Spatiotemporally Imbalanced Distribution Data",
      "abstract": "In complex data environments, rational handling of unbalanced datasets is key to improving the reliability of early disease prediction. Early warning of disease risk in both temporal and spatial terms, contributes to disease prevention and treatment. To this end, a bi-dimensional substratum information mining model based on Association Rule Digging with Dynamic Thresholding and Weight Optimization (ARDdtwo) was proposed for the early diagnosis of thyroid cancer. It is an integrated assessment framework consisting of association rule digging by constructing a dynamic threshold model (ADRcdt) for qualitative analysis, and a self-optimizing component importance measurement model (SoCIM) for quantitative analysis. ARDcdt incorporates temporal and spatial features of sparse data to address the distributional bias problem. Moreover, new importance diagnostic calculations were designed to further identify high-risk low-frequency (HRLF). The SoCIM can determine the relative weight of each component by assessing its level of risk in the overall system based on the Risk Enhancement Level (REL) and Risk Reduction Level (RRL), realizing the self-adjustment and optimization of the weight setting. Finally, the model was validated through an empirical analysis. The evaluation of the research work shows that improved results were achieved, such as accuracy, f1-score, and precision, with optimized values of 36.04&#x0025;,56.57&#x0025;, and 53.89&#x0025;, respectively. The overall area under the curve for the model was 0.882. This proves the validity of the proposed model for practical applications. For patients, it can simplify the pathological process and reduce the examination costs.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zhiwei Jia et al.",
      "keywords": "Computer science; Thresholding; Reliability (semiconductor); Data mining; Component (thermodynamics); Artificial intelligence; Machine learning; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3347635",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3037518329",
      "doi": "10.1109/mts.2020.2991495",
      "title": "Leveraging Digital Disruptions for a Climate-Safe and Equitable World: The D&amp;circ;2S Agenda: [Commentary]",
      "abstract": "A new report, Digital Disruptions for Sustainability Agenda (the DA2S Agenda), developed by Future Earth's Sustainability in the Digital Age initiative is discussed in this paper. The DA2S Agenda was developed over the course of a year, engaging over 250 experts from around the world through workshops, online consultations, and desktop research. This article provides an overview of the analysis and findings outlined in the DA2S Agenda. We begin with an overview of the research on how to change systems and drive societal transformations. We then describe the process used to develop the DA2S Agenda and provide a summary of the research and innovations outlined in it. The final section outlines near-term actions needed to establish the enabling conditions to drive the transformative systems changes needed for a climate-safe and equitable world.",
      "year": "2020",
      "journal": "IEEE Technology and Society Magazine",
      "authors": "Amy Luers et al.",
      "keywords": "Sustainability; Transformative learning; Political science; Process (computing); Engineering ethics; Climate change; Public relations; Business; Engineering; Computer science; Sociology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mts.2020.2991495",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393307056",
      "doi": "10.1109/access.2024.3383142",
      "title": "Effect of Interruptions and Cognitive Demand on Mental Workload: A Critical Review",
      "abstract": "Worker safety and productivity are crucial for effective job management. Interruptions to an individual\u2019s work environment and their impact on mental health can have adverse effects. One prospective instrument for assessing and calculating an individual\u2019s mental state in an interrupted scenario and cognitive demand levels is the use of physiological computing devices in conjunction with behavioral and subjective measurements. This study sought to address how to gather and compute data on individuals\u2019 cognitive states in interrupted work settings through critical analysis. Thirty-three papers were considered after the literature search and selection procedure. This descriptive study is conducted from three perspectives: parameter measurement, research design, and data analysis. The variables evaluated were working memory, stress, emotional state, performance, and resumption lag. The subject recruitment, experimental task design, and measurement techniques were examined from the standpoint of the experimental design. Data analysis included computing and cognitive pre-processing. Four future research directions are suggested to address the shortcomings of the present studies. This study offers suggestions for researchers on experiment planning and using computing to analyze individuals\u2019 cognitive states during interrupted work scenarios. Additionally, it offers helpful recommendations for organizing and conducting future research.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Nitin Koundal et al.",
      "keywords": "Workload; Computer science; Cognition; Psychology; Psychiatry; Operating system",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3383142",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4318825855",
      "doi": "10.1109/access.2023.3241489",
      "title": "Retracted: Real-Time Water and Electricity Consumption Monitoring Using Machine Learning Techniques",
      "abstract": "This work studies the automatic classification of water consumption patterns and electrical devices, both supervised and unsupervised. This involves training machine learning algorithms to identify normal and abnormal water consumption patterns and differentiate between different types of electrical devices. We performed an unsupervised classification of consumer water patterns in direct and indirect ways. The first is to use the raw consumption patterns obtained directly from the server. The second one corresponds to the use of the sampled consumption patterns. This classification is performed using hierarchical bottom-up classification and a self-organizing map. A probabilistic analysis of daily water consumption is performed to extract the percentage of daily consumption with the most information. It enables us to identify water consumption patterns more quickly by reducing the number of data points for each daily pattern, allowing us to recognize and classify anomalous behaviors as soon as feasible. Then, the signatures of electrical devices are classified using three ML algorithms: multilayer perceptron (MLP), k nearest neighbor (KNN), and decision tree (DT). Furthermore, assembly approaches are also studied. These are based on the OAA (One Against All) principle, which presents one class against all other classes, and the ECOC (Error-Correcting Output Codes) philosophy, which allows the classification error to be corrected. According to the bias/variance trade-off, both techniques enhanced classification by ensuring accuracy and generalization. A more in-depth analysis of the properties of the electrical devices is handled with an esemplastic approach based on gradient-boosting decision trees. The features of electrical devices can be extracted using this analysis based on the nature of their harmonic signatures",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Shariq Bashir",
      "keywords": "Computer science; Artificial intelligence; Decision tree; Machine learning; Gradient boosting; Boosting (machine learning); Unsupervised learning; Multilayer perceptron; Pattern recognition (psychology); Probabilistic logic; Data mining; Artificial neural network; Random forest",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3241489",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4382319393",
      "doi": "10.1109/access.2023.3275561",
      "title": "Entropy-Aware Similarity for Balanced Clustering: A Case Study With Melanoma Detection",
      "abstract": "Clustering data is an unsupervised learning approach that aims to divide a set of data points into multiple groups. It is a crucial yet demanding subject in machine learning and data mining. Its successful applications span various fields. However, conventional clustering techniques necessitate the consideration of balance significance in specific applications. Therefore, this paper addresses the challenge of imbalanced clustering problems and presents a new method for balanced clustering by utilizing entropy-aware similarity, which can be defined as the degree of balances. We have coined the term, entropy-aware similarity for balanced clustering (EASB), which maximizes balance during clustering by complementary clustering of unbalanced data and incorporating entropy in a novel similarity formula that accounts for both angular differences and distances. The effectiveness of the proposed approach is evaluated on actual melanoma medial data, specifically the International Skin Imaging Collaboration (ISIC) 2019 and 2020 challenge datasets, to demonstrate how it can successfully cluster the data while preserving balance. Lastly, we can confirm that the proposed method exhibited outstanding performance in detecting melanoma, comparing to classical methods.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Seok Bin Son et al.",
      "keywords": "Cluster analysis; Computer science; Entropy (arrow of time); Data mining; Artificial intelligence; Consensus clustering; Fuzzy clustering; Similarity (geometry); Machine learning; Pattern recognition (psychology); Correlation clustering; CURE data clustering algorithm; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3275561",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3120802549",
      "doi": "10.1109/taffc.2020.3048587",
      "title": "Silicon Copp\u00e9lia and the Formalization of the Affective Process",
      "abstract": "After 20 years of testing a framework for affective user responses to artificial agents and robots, we compiled a full formalization of our findings so to make the agent respond affectively to its user. Silicon Coppelia as we dubbed our system works from the features of the observed other, appraises these in various domains (e.g., ethics and affordances), then compares them to goals and concerns of the agent, to finally reach a response that includes intentions to work with the user as well as a level of being engaged with the user. This ultimately results into an action that adds to or changes the situation both agencies are in. Unlike many other systems, Silicon Coppelia can deal with ambiguous emotions of its user and has ambiguous \u2018feelings\u2019 of itself, which makes its decisions quite human-like. In the current paper, we advance a fuzzy-sets approach and show the inner workings of our system through an elaborate example. We also present a number of simulation experiments, one of which showed decision behaviors based on biases when agent goals had low priorities. Silicon Coppelia is open to scrutiny and experimentation by way of an open-source implementation in Ptolemy.",
      "year": "2021",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Johan F. Hoorn et al.",
      "keywords": "COPP; Computer science; Action (physics); Process (computing); Feeling; Human\u2013computer interaction; Scrutiny; Artificial intelligence; Psychology; Social psychology; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taffc.2020.3048587",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4323891861",
      "doi": "10.1109/access.2023.3255983",
      "title": "A Comparative Analysis of Sampling Techniques for Click-Through Rate Prediction in Native Advertising",
      "abstract": "Native advertising is a popular form of online advertisements that has similar styles and functions with the native content displayed on online platforms, such as news, sports and social websites. It can better capture users&#x2019; attention, and they have gained increasing popularity in many online platforms and among advertisers. In advertising, Click Trough Rate (CTR) prediction is essential but challenging due to data sparsity: the non-clicks constitute most of the data, whereas clicks form a significantly smaller portion. The performance of 19 class imbalance approaches is compared in this study with the use of four traditional classifiers, to determine the most effective imbalance methods for our native ads dataset. The data used is real traffic data from Finland over the course of seven days provided by the native advertising platform ReadPeak. The resampling methods used include seven undersampling techniques, four oversampling techniques, four hybrid sampling techniques, and four ensemble systems. The findings demonstrate that class imbalance learning can enhance the model&#x2019;s capacity for classification by as much as 20&#x0025;. In general, oversampling is more stable comparatively. But, undersampling performed the best with Random Forest. Our study also demonstrates that the imbalance ratio plays an important role in the performance of the model and the features importance.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nadir Sahllal et al.",
      "keywords": "Undersampling; Computer science; Oversampling; Popularity; Resampling; Random forest; Machine learning; Artificial intelligence; Class (philosophy); Advertising",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3255983",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388450965",
      "doi": "10.1109/access.2023.3330858",
      "title": "Multi-Point RCNN for Predicting Deformation in Deep Excavation Pit Surrounding Soil Mass",
      "abstract": "Accurate prediction and forecasting of soil mass deformation in deep excavation pits are pivotal for risk monitoring and safety assessment. Nonetheless, the complex underlying dynamics inherent in field sensing measurements pose challenges to the forecasting endeavor. In light of these challenges, the present study leverages recent strides in deep learning and introduces a spatiotemporal learning framework tailored to forecast soil mass deformation marked by resilient temporal interconnections and spatial associations. This study focuses on developing a Multi-Point Recurrent Convolutional Neural Network (RCNN) model for predicting sensor-based temporal patterns. This model integrates data feature fusion to extract spatiotemporal latent features from the dataset, thereby constructing a surrogate model for forecasting soil mass deformation. The proposed methodology is deployed to forecast strain responses in a deep excavation pit using a dataset spanning over five months. A comparative analysis is conducted, contrasting the performance of the proposed approach with that of a conventional temporal-only network. The analysis reveals that the prediction errors generated by the Multi-Point RCNN are predominantly concentrated within the range of 10&#x0025; for all sensors, with a high-confidence interval (CI) of 96&#x0025;, compared to the RCNN model (82&#x0025;) and the LSTM model (79&#x0025;). The compelling outcomes underscore the efficacy of the Multi-Point RCNN approach as a promising, dependable, and computationally efficient method for accurately predicting soil mass deformation in deep excavation pits, grounded in data-driven principles.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Fei Song et al.",
      "keywords": "Deep learning; Artificial intelligence; Computer science; Convolutional neural network; Excavation; Point (geometry); Range (aeronautics); Machine learning; Data mining; Geotechnical engineering; Geology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3330858",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391827445",
      "doi": "10.1109/access.2024.3366228",
      "title": "To See and be Seen\u2014Perceived Ethics and Acceptability of Pervasive Augmented Reality",
      "abstract": "Augmented reality (AR) glasses are likely to become omnipresent, providing a continuous and ubiquitous experience of computer-mediated reality. This new Pervasive AR will lead to perceptual, acceptance, and ethical issues which are increasingly discussed in the literature. However, given such Pervasive AR prototypes are currently not commercially available, little is known about potential end-users&#x2019; input into this discussion. To address this, we developed a Pervasive AR (PAR) prototype serving as a technology probe and conducted an empirical study in a semi-public space involving 54 participants. We collected data from focus groups, questionnaires, and observations of users and bystanders. Extending concerns with existing technology, like smartphones and augmented reality, PAR exposes privacy and security breaches with its unprompted, all-seeing capability, has a higher potential to cause societal fractures and divisions, and raises new questions on information transparency and trust with significant implications for the design of future PAR systems.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Holger Regenbrecht et al.",
      "keywords": "Augmented reality; Transparency (behavior); Ubiquitous computing; Internet privacy; Computer science; Perception; Focus (optics); Space (punctuation); Ethical issues; Human\u2013computer interaction; Computer security; Psychology; Engineering ethics; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3366228",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386175750",
      "doi": "10.1109/access.2023.3308811",
      "title": "EEG-Based Emotion Recognition Using Spatial-Temporal Connectivity",
      "abstract": "The connectivity properties between EEG signaling channels were found to play an important role in emotion recognition. During the generation and change of emotions, the connectivity between EEG signal channels is not only manifested in the spatial domain at a specific time, but also interconnected between different time intervals, which is often overlooked. A novel approach is proposed to exploit the shapes of spatial-temporal connectivity for EEG-based emotion recognition. By quantifying the connectivity strength of EEG signal channels within and across time intervals, spatial-temporal connectivity features are extracted, and these features can be represented by shapes in the three-dimensional space of EEG signals. Through these shapes, a mapping of different emotional states and brain activity is constructed. Subsequently, a parallel multi-scale convolutional neural network is employed to extract discriminative features from these connectivity shapes, facilitating the classification and identification of emotional states. Experimental results on the DEAP dataset show that our method achieves excellent performance, with an average classification accuracy of 93.25&#x0025; and 93.16&#x0025; for the two emotion dimensions of valence and arousal, respectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Wenhao Chu et al.",
      "keywords": "Electroencephalography; Discriminative model; Pattern recognition (psychology); Computer science; Artificial intelligence; Convolutional neural network; Emotion classification; Feature extraction; Speech recognition; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3308811",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393078931",
      "doi": "10.1109/access.2024.3380842",
      "title": "Research on Fault Diagnosis of Robot Arm With Dynamic Simulation and Domain Adaptation",
      "abstract": "The main challenges in the field of fault diagnosis of robot arms lie in the difficulties of acquiring fault data and ensuring model applicability. For a fault robot arm, the trained models typically only perform well on test data and cannot be effectively applied in practical scenarios. As a result, the time cost is very much to construct adequate fault datasets. The paper proposes a dynamic simulation method for obtaining fault data to address these issues. The motion feature of the arm with joint faults is replicated by the simulation software, thereby obtaining vibration signals in the fault mode as samples. Additionally, under the main framework of Deep Learning (DL) with an end-to-end feature extraction capability, a Stacked Continuous Wavelet Transform (SCWT) method is designed to visualize timing signals graphically based on the traditional wavelet transform. Furthermore, to enhance traditional DL performance, a dual-channel architecture for data fusion within DL is designed to enrich the feature space and improve fault-distinguishing ability. Lastly, a Domain Discriminator <inline-formula> <tex-math notation=\"LaTeX\">$G_{d}$ </tex-math></inline-formula> is designed to identify the upper bounds for differences between spatial distributions of simulated and actual fault data. By the domain discriminator, the feature distribution of target and source data is aligned, facilitating the transfer application of the simulation-trained diagnostic model on the actual fault. The proposed method is tested and evaluated using a self-constructed experimental data set. The results substantiate its effectiveness and superiority.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Gang Wang et al.",
      "keywords": "Computer science; Robotic arm; Fault (geology); Adaptation (eye); Domain adaptation; Domain (mathematical analysis); Robot; Dynamic simulation; Mobile robot; Simulation; Artificial intelligence; Geology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3380842",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389331913",
      "doi": "10.1109/access.2023.3339584",
      "title": "Temporal Modeling of Instantaneous Interbeat Interval Based on Physical Activity",
      "abstract": "Heartbeat serves as a vital sign of health, aiding the diagnosis of various health issues. The autonomic nervous system (ANS) is responsible for regulating heartbeat, and physical activity (PA) can influence the heart rhythm. Changes in heart rate can signal alterations in PA. However, poor measurements or extreme conditions can result in the loss of heartbeat data, which can negatively impact the analysis of heartbeats. To accurately monitor the Heart Rate Variability (HRV) and cardiovascular health, a proper model to compensate for lost data is necessary. This study investigated the effect of different PAs on InterBeat Interval (IBI) prediction and the possibility of using models trained on unrelated activities to predict the next IBI. The IBI series is divided into piecewise stationary sections based on PA, that is, running, walking, and sitting, as verified by a statistical test. Various machine and deep learning methods have been used to model the IBIs related to specific activities. The models were then used to predict the next IBI for the testing sets of related and unrelated activities, and the error changes were compared for each permutation of training and testing. The models were tested using a Physionet archived dataset. The findings suggest that linear models offer the least prediction error, whereas PA-relevant training could minimize errors in most scenarios. However, in cases where specific PA data are not available, the proposed CNN model demonstrated superior generalization capabilities. These findings can improve HRV error correction techniques and enhance cardiovascular health and ANS monitoring.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Hamed Mojtahed et al.",
      "keywords": "Heartbeat; Computer science; Heart rate variability; Generalization; Cardiorespiratory fitness; Artificial intelligence; Vital signs; Heart rate; Machine learning; Pattern recognition (psychology); Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3339584",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386536281",
      "doi": "10.1109/access.2023.3313506",
      "title": "Leveraging ISMOTE-KPCA-STACKING Algorithm for Enhanced Vascular Vertigo/Dizziness Diagnosis and Clinical Decision Support",
      "abstract": "Vascular vertigo/dizziness is a complex clinical syndrome involving multiple disciplines and specialties, such as neurology and psychiatry. Due to the intricate etiology and the similarity between causes and symptoms, traditional diagnostic methods based on clinical symptoms and signs are often inaccurate. This study aims to establish an effective and accurate intelligent diagnostic method for vascular dizziness to address this issue. Initially, we collected patients&#x2019; medical history and biochemical indicators as research indices. To tackle the sample imbalance issue in clinical data, we employed an improved SMOTE(ISMOTE) algorithm to generate minority class data. The enhancement of the ISMOTE algorithm lies in its ability to more effectively identify and generate minority class samples in sparse regions, resolving the issue of traditional SMOTE algorithms potentially neglecting sparse areas when generating synthetic samples. Subsequently, we utilized the Pearson correlation coefficient for feature correlation analysis, screening and analyzing the original features, and identified 13 feature indices. To further improve model performance and simplify the computational process, we applied the KPCA algorithm to these indices for dimensionality reduction, ultimately obtaining three comprehensive feature indices. Finally, we constructed a Stacking ensemble algorithm model comprising base models (including KNN, RF, Naive Bayes, SVM, GBDT, and XGBoost). To optimize the overall model performance, we introduced a fully connected cascade neural network as a meta-layer model and employed grid search and the Levenberg-Marquardt (LM) algorithm to optimize the base models and meta-layer model, respectively. This enabled the Stacking ensemble algorithm better to learn the correlations among predictions from each base model, enhancing the model&#x2019;s generalization ability. Experimental results demonstrate that the proposed ISMOTE-KPCA-STACKING model exhibits significant advantages in diagnosing vascular vertigo/dizziness, outperforming single base models in multiple evaluation metrics. Furthermore, the model excels in handling imbalanced data and feature selection, providing an effective method for accurately diagnosing vascular vertigo/dizziness.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Dengqin Song et al.",
      "keywords": "Vertigo; Computer science; Stacking; Algorithm; Pattern recognition (psychology); Artificial intelligence; Speech recognition; Physical medicine and rehabilitation; Medicine; Surgery",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3313506",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388936708",
      "doi": "10.1109/access.2023.3335931",
      "title": "Development and Validation of the Engineering Computational Thinking Diagnostic for Undergraduate Students",
      "abstract": "Computational thinking is one barrier to enculturating as a professional engineer. We created the Engineering Computational Thinking Diagnostic (ECTD) as an instructional tool that can identify at-risk first-year engineering students. The purpose of this study is to provide construct validity, internal consistency reliability, item characteristics, and criterion validity evidence for this diagnostic. From fall 2020 to fall 2021, 469 students from three institutions in the United States took the diagnostic. The data from 152 students at one institution was used to provide evidence of predictive validity. Exploratory and confirmatory factor analyses resulted in 20 items loading onto one factor in a good model fit range, with the internal consistency reliability coefficient, Cronbach <inline-formula> <tex-math notation=\"LaTeX\">$\\alpha $ </tex-math></inline-formula> of 0.86. From item analyses based on classical test theory, the diagnostic items on average tended to be slightly easy but had sufficient discrimination power. The correlation matrix for criterion validity evidence indicated that the diagnostic functions well to differentiate students&#x2019; computational thinking ability by prior computer science course experience as well as by first-generation status. Predictive validity evidence from regression analyses revealed the statistically significant effect of students&#x2019; diagnostic scores assessed at the beginning of the first semester on predicting their end of semester course grades. The ECTD can have a broad impact because it provides a tool to gauge the entry-level skills of students, enabling early curriculum interventions to help retention and persistence to graduation. We make the case that the ECTD could contribute to the development of a more diverse workforce in engineering.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Noemi V. Mendoza D\u00edaz et al.",
      "keywords": "Cronbach's alpha; Construct validity; Engineering education; Graduation (instrument); Psychology; Computational thinking; Reliability (semiconductor); Confirmatory factor analysis; Mathematics education; Scale (ratio); Curriculum; Computer science; Test (biology); Exploratory factor analysis; Mathematics; Engineering; Psychometrics; Clinical psychology; Machine learning; Pedagogy; Structural equation modeling; Engineering management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3335931",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394711256",
      "doi": "10.1109/access.2024.3387547",
      "title": "PCaLDI: Explainable Similarity and Distance Metrics Using Principal Component Analysis Loadings for Feature Importance",
      "abstract": "In the evolving landscape of interpretable machine learning (ML) and explainable artificial intelligence, transparent and comprehensible ML models are crucial for data-driven decision-making. Traditional approaches have limitations in distinguishing whether the observed importance of features in principal component analysis (PCA)-transformed similarity metrics is due to the intrinsic characteristics of the data or artifacts introduced by the PCA. This ambiguity hampers the accurate interpretation of feature contributions to similarity and distance metrics, which are fundamental to data-analysis techniques. To address these challenges, I introduce the novel PCA loading-dependent importance (PCaLDI), which elucidates the similarity and distance metrics by synergistically leveraging the strengths of PCA loadings and permutation feature importance. PCaLDI innovatively utilizes PCA loadings to prioritize the most influential features, streamlining the assessment of feature importance. This approach provides clearer insights into the contributions of the features and reduces the computational inefficiencies inherent to traditional methods. Importantly, PCaLDI uniquely clarifies the contributions of individual features to similarity metrics within the PCA-transformed space, distinguishing between the effects attributed to PCA and genuine influence of features on the similarity measures. This distinction is pivotal for accurately understanding the data structure and making informed decisions. Moreover, the versatility of PCaLDI extends to any data format compatible with PCA, highlighting its broad applicability and utility across data types. Comprehensive experiments and comparisons with baseline methods demonstrate that PCaLDI exhibits high effectiveness and efficiency, offering rapid and accurate assessments of feature importance with substantial reduced computational demands.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Takafumi Nakanishi",
      "keywords": "Principal component analysis; Computer science; Similarity (geometry); Pattern recognition (psychology); Artificial intelligence; Component (thermodynamics); Feature (linguistics); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3387547",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3198553792",
      "doi": "10.1109/access.2022.3144841",
      "title": "Transmittance Multispectral Imaging for Reheated Coconut Oil Differentiation",
      "abstract": "Oil reheating has a significant impact on global health due to its extensive consumption, especially in South Asia, and severe health risks. Nevertheless, food image analysis using multispectral imaging systems(MISs) has not been applied to oil reheating analysis despite their vast application in rapid food quality screening. To that end, the paper discusses the application of a low-cost MSI to estimate the &#x2018;reheat cycle count classes&#x2019; (number of times an oil sample is recursively heated) and identify &#x2018;critical classes&#x2019; at which substantial changes in the oil sample have materialized. Firstly, the reheat cycle count class is estimated with Bhattacharyya distance between the reheated and a pure oil sample as the input. The classification was performed using a support vector machine classifier that resulted in an accuracy of 83.34&#x0025; for reheat cycle count identification. Subsequently, an unsupervised clustering procedure was introduced using a modified spectral clustering (SC) algorithm to distinguish critical classes under reheating. In addition, laboratory experiments were performed to ascertain the ramifications of the reheating process with a chemical analysis. The chemical analysis of the coconut oil samples used in the experiment coincided with the image analysis results and was statistically significant (<inline-formula> <tex-math notation=\"LaTeX\">$p &lt; 0.05$ </tex-math></inline-formula>). Accordingly, the proposed work closes the gap for using multispectral imaging for oil reheating and proposes a novel algorithm for unsupervised detection of critical property changes in the oil. Hence, the proposed research work is significant in its practical implications, contribution to food image analysis, and unsupervised classification mechanisms.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Yasiru Ranasinghe et al.",
      "keywords": "Multispectral image; Cluster analysis; Computer science; Artificial intelligence; Multispectral pattern recognition; Pattern recognition (psychology); Bhattacharyya distance; Coconut oil; Classifier (UML); Sample (material); Process engineering; Food science; Chemistry; Chromatography; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3144841",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387546208",
      "doi": "10.1109/tnsre.2023.3323902",
      "title": "Electroencephalogram-Driven Machine-Learning Scenario for Assessing Impulse Control Disorder Comorbidity in Parkinson\u2019s Disease Using a Low-Cost, Custom LEGO-Like Headset",
      "abstract": "Patients with Parkinson's disease (PD) may develop cognitive symptoms of impulse control disorders (ICDs) when chronically treated with dopamine agonist (DA) therapy for motor deficits. Motor and cognitive comorbidities critically increase the disability and mortality of the affected patients. This study proposes an electroencephalogram (EEG)-driven machine-learning scenario to automatically assess ICD comorbidity in PD. We employed a classic Go/NoGo task to appraise the capacity of cognitive and motoric inhibition with a low-cost, custom LEGO-like headset to record task-relevant EEG activity. Further, we optimized a support vector machine (SVM) and support vector regression (SVR) pipeline to learn discriminative EEG spectral signatures for the detection of ICD comorbidity and the estimation of ICD severity, respectively. With a dataset of 21 subjects with typical PD, 9 subjects with PD and ICD comorbidity (ICD), and 25 healthy controls (HC), the study results showed that the SVM pipeline differentiated subjects with ICD from subjects with PD with an accuracy of 66.3% and returned an around-chance accuracy of 53.3% for the classification of PD versus HC subjects without the comorbidity concern. Furthermore, the SVR pipeline yielded significantly higher severity scores for the ICD group than for the PD group and resembled the ICD vs. PD distinction according to the clinical questionnaire scores, which was barely replicated by random guessing. Without a commercial, high-precision EEG product, our demonstration may facilitate deploying a wearable computer-aided diagnosis system to assess the risk of DA-triggered cognitive comorbidity in patients with PD in their daily environment.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Wei\u2010Che Lin et al.",
      "keywords": "Comorbidity; Electroencephalography; Medicine; Cognition; Alertness; Machine learning; Internal medicine; Computer science; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3323902",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2974990566",
      "doi": "10.1109/access.2019.2944211",
      "title": "Low-Rank Constrained Latent Domain Adaptation Co-Regression for Robust Depression Recognition",
      "abstract": "Focusing on the facial-based depression recognition where the feature distribution could be shifted due to unlimited variations in facial image acquisition, we propose a novel Low-rank constrained latent Domain Adaptation Depression Recognition (LDADR) framework by jointly utilizing facial appearance and dynamics features. Under this framework, to alleviate the domain distribution bias in depression recognition, we devote to uncover a compact and more informative latent space on appearance feature representation to minimize the domain distribution divergence as well as to share more discriminative structures between domains. In this optimal latent space, both source and target classification loss functions are incorporated as parts of its co-regression function by encoding the common components of the classifier models as a low-rank constraint term. Moreover, the target prediction results on both appearance features and dynamics features are constrained to be consistent for better fusing the discriminative information from different representations. We specially adopt the l<sub>2,1</sub>-norm based loss function for learning robust classifiers on different feature representations. Different from the state of the arts, our algorithm can adapt knowledge from another source for Automated Depression Recognition (ADR) even if the features of the source and target domains are partially different but overlapping. The proposed methods are evaluated on three depression databases, and the outstanding performance for almost all learning tasks has been achieved compared with several representative algorithms.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Jianwen Tao et al.",
      "keywords": "Discriminative model; Pattern recognition (psychology); Artificial intelligence; Computer science; Classifier (UML); Feature vector; Feature (linguistics); Feature learning; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2944211",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393033094",
      "doi": "10.1109/access.2024.3380439",
      "title": "Exploring the Impact of Partial Occlusion on Emotion Classification From Facial Expressions: A Comparative Study of XR Headsets and Face Masks",
      "abstract": "This study provides of a comparative analysis of emotion estimation from facial expressions under partial occlusion caused by face masks and extended reality (XR) headsets. Unlike previous studies that have independently explored these two scenarios, this research compares and analyzes the statistical differences between them. In order to achieve this, the RAF-DB dataset has been used as a non-occluded baseline to construct two new datasets: i) a dataset formed by faces partially occluded by face masks, and ii) a dataset formed by faces partially occluded by XR headsets. To evaluate the impact of occlusion in emotion estimation, three deep learning models have been fine-tuned using transfer learning, and results from a random classifier have been used as a baseline. Seven different metrics were obtained per dataset, and a 2-way ANOVA test was performed on each metric. As expected, significant statistical differences are observed between the non-occluded faces (acc. 0.8780) and the faces partially occluded by face masks (acc. 0.7520) and XR headsets (acc. 0.7400) on all metrics. Notably, the comparison between the two partially occluded datasets revealed significant statistical differences in the metrics f1-score (macro), precision (macro) and recall (macro), which we attribute to different types of occlusion affecting different parts of the face that are key to some emotions. This research contributes to advancing emotion recognition systems by highlighting their robustness and effectiveness even in partial occlusion settings, and showing a full comparative analysis between two common types of occlusion.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Alberto Casas-Ortiz et al.",
      "keywords": "Facial expression; Emotion recognition; Face (sociological concept); Computer science; Facial recognition system; Emotion classification; Speech recognition; Artificial intelligence; Computer vision; Pattern recognition (psychology); Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3380439",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3126665069",
      "doi": "10.1109/access.2021.3058247",
      "title": "Real-Time Monitoring System of Exercise Status Based on Internet of Health Things Using Safety Architecture Model",
      "abstract": "As an emerging field of information technology, the Internet of Health Things has attracted great attention from governments, scholars, and related enterprises, and is seen as a major opportunity for development and change in the information field. The European Commission believes that the development and application of the Internet of Health Things will make a significant contribution to solving modern social problems in the next 5 to 15 years. In this paper, the corresponding motion detection algorithms such as pacing detection algorithm, sleep quality and sedentary reminder detection algorithm are designed for real-time detection of motion status. In addition, this paper builds a new safety architecture model based on real-time motion detection, and proposes a time-domain feature-based motion detection method for walking, walking upstairs and walking downstairs. The original acceleration signal is smoothed and denoised using a sliding-average filter. The acceleration signal is segmented by a rectangular window with 50&#x0025; overlap, and the variance, X-quartile difference, and X-axis bias coefficient are extracted from a single time window.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Long Qin et al.",
      "keywords": "Computer science; Acceleration; The Internet; Feature (linguistics); Field (mathematics); Architecture; Artificial intelligence; Motion (physics); Sliding window protocol; Computer vision; Wireless sensor network; Real-time computing; Window (computing); Computer network; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3058247",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392745433",
      "doi": "10.1109/access.2024.3376657",
      "title": "Adversarial Neural Network Training for Secure and Robust Brain-to-Brain Communication",
      "abstract": "In the rapidly evolving domain of brain-to-brain communication, safeguarding the transmission of information against adversarial threats is paramount. This study introduces an advanced approach to enhance the resilience and security of brain-to-brain communication systems utilizing electroencephalogram data against such threats through adversarial neural network training. Concentrating on event-related potentials and employing a diverse collection of eight datasets, our research rigorously evaluates and optimizes the system&#x2019;s defense mechanisms against adversarial manipulations. We specifically target the optimization of trial durations and sampling rates to bolster system security. Our findings reveal a marked improvement in the system&#x2019;s defensive capabilities, demonstrated by a significant increase in adversarial accuracy by 17&#x0025; and enhancement in the area under the receiver operating characteristic curve by 0.12 points. These results underscore the efficacy of our approach in fortifying brain-to-brain communication systems against sophisticated cyber threats, marking a significant step forward in the secure and robust transmission of neural signals.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Hossein Ahmadi et al.",
      "keywords": "Adversarial system; Computer science; Training (meteorology); Artificial neural network; Computer network; Artificial intelligence; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3376657",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312353857",
      "doi": "10.1109/access.2022.3225407",
      "title": "NIFL: A Statistical Measures-Based Method for Client Selection in Federated Learning",
      "abstract": "Federated learning (FL) has been proposed as a machine learning approach to collaboratively learn a shared prediction model. Although, during FL training, only a subset of workers participate in each round, existing approaches introduce model bias when considering the average of local model parameters of heterogeneous workers, which degrades the accuracy of the learned global model. In this paper, we introduce NIFL, a new strategy for worker selection that handles the statistical challenges of FL when local data is Non-Independent and Identically Distributed (N-IID). In NIFL, the server starts sending the signal to the workers that react by sending the number of their samples. The server then selects a percentage of workers with the highest number of samples and requests data statistics such as mean and standard deviation. After that, the server calculates our proposed N-IID index, based on the statistical information collected from the workers without having access to their data, and uses this index as a criterion for worker selection. Finally, the server broadcasts the global model to the selected workers. NIFL takes into account the disparity in the distribution of workers&#x2019; data in order to improve the performance of the model in heterogeneous data environment. We have performed several experiments with N-IID data. The obtained results show that both the convergence of our method and the test accuracy increased considerably comparing to the other techniques while keeping a reasonable computation and communication costs.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mohamed M\u2019Haouach et al.",
      "keywords": "Computer science; Independent and identically distributed random variables; Index (typography); Selection (genetic algorithm); Standard deviation; Convergence (economics); Server; Data modeling; Machine learning; Artificial intelligence; Data mining; Statistics; Random variable; Database; Computer network; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3225407",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387623797",
      "doi": "10.1109/access.2023.3324555",
      "title": "Characterizing Discourse and Engagement Across Topics of Misinformation on Twitter",
      "abstract": "In recent years, online misinformation has become increasingly prevalent, leading to significant issues such as political polarisation and distrust of genuine information. Misinformation on social media platforms affects various aspects of society, including health and politics, and can take many forms, such as text and images. However, current studies mainly focus on analysing singular topics and modalities, without considering the heterogeneity of the issue. Our research aimed to examine the relationship between visual elements and engagement, as well as the relationship between sentiment analysis, hate speech, and bots on a variety of topics on the Twitter social media platform Twitter. We labelled 12,581 misinformation posts that were manually modelled into a topic hierarchy. We then analysed these posts, including their sentiments, the prevalence of hate speech, and bot activity on different topics. The results revealed that political misinformation tends to contain more hate speech than COVID-19 misinformation and that political misinformation also has a higher number of bots. Furthermore, the findings suggest that misinformation online with more than 40&#x0025; negative sentences can have a high level of hate speech identified for both tweets and replies. This study provides detailed information on topics and the volume of misinformation on social media platforms, and the findings can be used to develop more advanced detection systems and support further analysis. Our findings can help policy makers understand what kind of online misinformation has been spreading on Twitter and how to plan campaigns to make users more aware of how to spot its various features in an online user-to-user Twitter environment.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Dominika Nadia Wojtczak et al.",
      "keywords": "Misinformation; Social media; Distrust; Computer science; Internet privacy; Sentiment analysis; Modalities; Politics; Political science; Artificial intelligence; World Wide Web; Sociology; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3324555",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393285887",
      "doi": "10.1109/access.2024.3382819",
      "title": "NRAAF: A Framework for Comparative Analysis of fMRI Registration Algorithms and Their Impact on Resting-State Neuroimaging Accuracy",
      "abstract": "The rapid evolution of neuroimaging techniques underscores the necessity for robust medical image registration algorithms, essential for the precise analysis of resting-state networks. This study introduces a comprehensive modular evaluation framework, designed to assess and compare the differences of four state-of-the-art algorithms in the field: FSL, ANTs, DARTEL, and AFNI. Our framework highlights the critical importance of algorithm selection in neuroimaging, addressing the unique challenges and strengths each algorithm presents in processing complex brain imaging data. Our rigorous evaluation delves into the algorithms\u2019 differences, with a focus on spatial localisation accuracy and the fidelity of resting-state network identification. The comparative analysis uncovers distinct advantages and limitations inherent to each algorithm, illuminating how specific characteristics can shape neuroimaging study outcomes. For instance, we reveal FSL\u2019s robustness in handling diverse datasets, ANTs\u2019 precision in spatial normalization, DARTEL\u2019s suitability for large-scale studies, and AFNI\u2019s adaptability in functional and structural image analysis. The findings highlight the nuanced considerations necessary in choosing the right registration algorithm for neuroimaging data, advocating for a bespoke approach based on the unique requirements of each study. This detailed analysis advances the field, guiding researchers towards more informed algorithm selection and application, thus aiming to improve the accuracy and reliability of neuroimaging outcomes. Presenting a clear, comprehensive overview of each algorithm within our novel framework, the study addresses the needs of the neuroimaging community and paves the way for future advancements in medical image registration.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Martin Svejda et al.",
      "keywords": "Neuroimaging; Resting state fMRI; Computer science; Artificial intelligence; Algorithm; Pattern recognition (psychology); Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3382819",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4322703895",
      "doi": "10.23919/jsc.2022.0017",
      "title": "Fiduciary Responsibility: Facilitating Public Trust in Automated Decision Making",
      "abstract": "Automated decision-making systems are being increasingly deployed and affect the public in a multitude of positive and negative ways. Governmental and private institutions use these systems to process information according to certain human-devised rules in order to address social problems or organizational challenges. Both research and real-world experience indicate that the public lacks trust in automated decision-making systems and the institutions that deploy them. The recreancy theorem argues that the public is more likely to trust and support decisions made or influenced by automated decision-making systems if the institutions that administer them meet their fiduciary responsibility. However, often the public is never informed of how these systems operate and resultant institutional decisions are made. A \u201cblack box\u201d effect of automated decision-making systems reduces the public\u2019s perceptions of integrity and trustworthiness. Consequently, the institutions administering these systems are less able to assess whether the decisions are just. The result is that the public loses the capacity to identify, challenge, and rectify unfairness or the costs associated with the loss of public goods or benefits. The current position paper defines and explains the role of fiduciary responsibility within an automated decision-making system. We formulate an automated decision-making system as a data science lifecycle (DSL) and examine the implications of fiduciary responsibility within the context of the DSL. Fiduciary responsibility within DSLs provides a methodology for addressing the public\u2019s lack of trust in automated decision-making systems and the institutions that employ them to make decisions affecting the public. We posit that fiduciary responsibility manifests in several contexts of a DSL, each of which requires its own mitigation of sources of mistrust. To instantiate fiduciary responsibility, a Los Angeles Police Department (LAPD) predictive policing case study is examined. We examine the development and deployment by the LAPD of predictive policing technology and identify several ways in which the LAPD failed to meet its fiduciary responsibility.",
      "year": "2022",
      "journal": "Journal of Social Computing",
      "authors": "Shannon B. Harper et al.",
      "keywords": "Fiduciary; Context (archaeology); Business; Public relations; Order (exchange); Political science; Law; Finance",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2022.0017",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389747875",
      "doi": "10.1109/access.2023.3342862",
      "title": "TCNAEC: Advancing Sentence-Level Revision Evaluation Through Diverse Non-Native Academic English Insights",
      "abstract": "In the domain of Natural Language Processing (NLP), the English Writing Fluency Improvement for non-native speakers, particularly in academic contexts, poses significant challenges. While Sentence-level Revision (SentRev) endeavors to address this concern, the existing evaluation corpus, SMITH, falls short in offering a robust and comprehensive assessment of the task. To bridge this gap, our research offers a novel evaluation corpus generation scheme, leading to the creation of Ten-Country Non-native Academic English Corpus (TCNAEC). A meticulous analysis revealed the superior characteristics of TCNAEC over SMITH in various dimensions. Our evaluation also uncovered intriguing linguistic phenomena, offering valuable insights for fellow researchers. In contrast, the Grammatical Error Correction (GEC) task, which shares similarities with SentRev, has been more extensively explored, resulting in a richer set of training and evaluation corpora. However, the distinctive attributes of SentRev present a heightened challenge in NLP implementation. The TCNAEC, representing ten countries, captures the unique English expression styles of non-native speakers worldwide, offering a more holistic view compared to the Japan-centric SMITH. Furthermore, while SMITH primarily revolves around computational linguistics, TCNAEC spans multiple disciplines, accentuating its comprehensiveness. The construction strategy of TCNAEC, ensuring semantic consistency between Draft and Reference, emphasizes meaningful structural variations, reflecting the stylistic disparities between non-academic and academic texts.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zhendong Du et al.",
      "keywords": "Computer science; Fluency; Task (project management); Natural language processing; Sentence; Set (abstract data type); Consistency (knowledge bases); Artificial intelligence; Linguistics; Bridge (graph theory); Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3342862",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3187520186",
      "doi": "10.1109/jsen.2021.3103608",
      "title": "Tutorial: A Versatile Bio-Inspired System for Processing and Transmission of Muscular Information",
      "abstract": "FIGURES 1 &amp; 2. Aedeagi, dorsal views. \u2013 1, Enochrus (Hugoscottia) plicatus (holotype). 2, Enochrus (Hugoscotia) talamanca (holotype).",
      "year": "2021",
      "journal": "IEEE Sensors Journal",
      "authors": "F\u00e1bio Rossi et al.",
      "keywords": "Bluetooth; Computer science; Toolchain; Computer hardware; Microcontroller; Firmware; Embedded system; Transmission (telecommunications); Artificial intelligence; Wireless; Software; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2021.3103608",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4221143135",
      "doi": "10.1109/access.2022.3190014",
      "title": "Characterization of Semantic Segmentation Models on Mobile Platforms for Self-Navigation in Disaster-Struck Zones",
      "abstract": "The role of unmanned vehicles for searching and localizing the victims in\\ndisaster impacted areas such as earthquake-struck zones is getting more\\nimportant. Self-navigation on an earthquake zone has a unique challenge of\\ndetecting irregularly shaped obstacles such as road cracks, debris on the\\nstreets, and water puddles. In this paper, we characterize a number of\\nstate-of-the-art FCN models on mobile embedded platforms for self-navigation at\\nthese sites containing extremely irregular obstacles. We evaluate the models in\\nterms of accuracy, performance, and energy efficiency. We present a few\\noptimizations for our designed vision system. Lastly, we discuss the trade-offs\\nof these models for a couple of mobile platforms that can each perform\\nself-navigation. To enable vehicles to safely navigate earthquake-struck zones,\\nwe compiled a new annotated image database of various earthquake impacted\\nregions that is different than traditional road damage databases. We train our\\ndatabase with a number of state-of-the-art semantic segmentation models in\\norder to identify obstacles unique to earthquake-struck zones. Based on the\\nstatistics and tradeoffs, an optimal CNN model is selected for the mobile\\nvehicular platforms, which we apply to both low-power and extremely low-power\\nconfigurations of our design. To our best knowledge, this is the first study\\nthat identifies unique challenges and discusses the accuracy, performance, and\\nenergy impact of edge-based self-navigation mobile vehicles for\\nearthquake-struck zones. Our proposed database and trained models are publicly\\navailable.\\n",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ryan Zelek et al.",
      "keywords": "Computer science; Segmentation; Enhanced Data Rates for GSM Evolution; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3190014",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3096657077",
      "doi": "10.1109/access.2020.3033537",
      "title": "AMMDAS: Multi-Modular Generative Masks Processing Architecture With Adaptive Wide Field-of-View Modeling Strategy",
      "abstract": "The usage of transportation systems is inevitable; any assistance module which can catalyze the flow involved in transportation systems, parallelly improving the reliability of processes involved is a boon for day-to-day human lives. This paper introduces a novel, cost-effective, and highly responsive Post-active Driving Assistance System, which is \"Adaptive-Mask-Modelling Driving Assistance System\" with intuitive wide field-of-view modeling architecture. The proposed system is a vision-based approach, which processes a panoramic-front view (stitched from temporal synchronous left, right stereo camera feed) &amp; simple monocular-rear view to generate robust &amp; reliable proximity triggers along with co-relative navigation suggestions. The proposed system generates robust objects, adaptive field-of-view masks using FRCNN+Resnet-101_FPN, DSED neural-networks, and are later processed and mutually analyzed at respective stages to trigger proximity alerts and frame reliable navigation suggestions. The proposed DSED network is an Encoder-Decoder-Convolutional-Neural-Network to estimate lane-offset parameters which are responsible for adaptive modeling of field-of-view range (157<sup>o</sup>-210<sup>o</sup>) during live inference. Proposed stages, deep-neural-networks, and implemented algorithms, modules are state-of-the-art and achieved outstanding performance with minimal loss(L{p, t}, L<sub>&#x03B4;</sub>, L<sub>Total</sub>) values during benchmarking analysis on our custombuilt, KITTI, MS-COCO, Pascal-VOC, Make-3D datasets. The proposed assistance-system is tested on our custom-built, multiple public datasets to generalize its reliability and robustness under multiple wild conditions, input traffic scenarios &amp; locations.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Venkata Subbaiah Desanamukula et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Modular design; Field (mathematics); Offset (computer science); Artificial neural network; Computer vision; Real-time computing; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3033537",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392449924",
      "doi": "10.1109/access.2024.3374056",
      "title": "Video Quality Prediction: An Exploratory Study With Valence and Arousal Signals",
      "abstract": "With the explosion of online video consumption, assessing and anticipating how users will evaluate the content they watch has become increasingly important. Traditional methods based on explicit user feedback are often limited in their ability to do this, as they can be time-consuming and expensive to collect. This study explores techniques to predict users&#x2019; ratings about a video&#x2019;s ability to evoke emotions through emotional signals. In particular, it is proposed a method of emotional analysis that uses valence and arousal data as key signals for predicting user ratings through systems that use machine-learning techniques. Hence, an experiment in the wild involved 112 participants who completed questionnaires to create a dataset of emotional data and video quality ratings to train different intelligent systems. The best system comprised a Medium Gaussian Support Vector Machine (SVM) classifier that detected users&#x2019; ratings between Ineffective and Effective based on valence and arousal features as input, achieving an accuracy higher than 87&#x0025;. The result demonstrated that it is possible to predict users&#x2019; ratings on the ability of the movie to elicit emotion, using users&#x2019; emotional states in terms of valence and arousal. The system has several advantages, such as eliminating the need for user reports, predicting user ratings in real-time more quickly and dynamically, and utilizing only the initial emotional state to predict users&#x2019; ratings. In addition, it has potential applications in advertising, education, and entertainment fields. Advertisers could better understand how consumers perceive their products and create more effective advertising campaigns; educational institutions could develop more engaging and effective learning materials; entertainment providers could create more popular and successful content.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Antonio Di Tecco et al.",
      "keywords": "Computer science; Valence (chemistry); Arousal; Exploratory research; Quality (philosophy); Speech recognition; Artificial intelligence; Psychology; Social psychology; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3374056",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387886071",
      "doi": "10.1109/access.2023.3326725",
      "title": "A Dataset Fusion Algorithm for Generalised Anomaly Detection in Homogeneous Periodic Time Series Datasets",
      "abstract": "A preprint of this article is available at arXiv under a CC BY licence at https://doi.org/10.48550/arXiv.2305.08197. It has not been certified by peer review. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ayman Elhalwagy et al.",
      "keywords": "Computer science; Anomaly detection; Homogeneous; Series (stratigraphy); Data mining; Time series; Algorithm; Sensor fusion; Reduction (mathematics); Artificial intelligence; Anomaly (physics); Fusion; Pattern recognition (psychology); Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326725",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392979617",
      "doi": "10.1109/ojemb.2024.3379733",
      "title": "Quantifying the Suitability of Biosignals Acquired During Surgery for Multimodal Analysis",
      "abstract": "<i>Goal:</i> Recently, large datasets of biosignals acquired during surgery became available. As they offer multiple physiological signals measured in parallel, multimodal analysis - which involves their joint analysis - can be conducted and could provide deeper insights than unimodal analysis based on a single signal. However, it is unclear what percentage of intraoperatively acquired data is suitable for multimodal analysis. Due to the large amount of data, manual inspection and labelling into suitable and unsuitable segments are not feasible. Nevertheless, multimodal analysis is performed successfully in sleep studies since many years as their signals have proven suitable. Hence, this study evaluates the suitability to perform multimodal analysis on a surgery dataset (VitalDB) using a multi-center sleep dataset (SIESTA) as reference. <i>Methods:</i> We applied widely known algorithms entitled \"signal quality indicators\" to the common biosignals in both datasets, namely electrocardiography, electroencephalography, and respiratory signals split in segments of 10 s duration. As there are no multimodal methods available, we used only unimodal signal quality indicators. In case, all three signals were determined as being adequate by the indicators, we assumed that the whole signal segment was suitable for multimodal analysis. <i>Results:</i> 82% of SIESTA and 72% of VitalDB are suitable for multimodal analysis. Unsuitable signal segments exhibit constant or physiologically unreasonable values. Histogram examination indicated similar signal quality distributions between the datasets, albeit with potential statistical biases due to different measurement setups. <i>Conclusions:</i> The majority of data within VitalDB is suitable for multimodal analysis.",
      "year": "2024",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Ennio Idrobo-\u00c1vila et al.",
      "keywords": "Multimodal therapy; Computer science; Medicine; Surgery",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2024.3379733",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389776589",
      "doi": "10.1109/access.2023.3343500",
      "title": "Smatable: A Vibration-Based Sensing Method for Making Ordinary Tables Touch-Interfaces",
      "abstract": "In recent years, the equipment that makes up smart homes is required not only to be functional, but also to be integrated with the design and aesthetics of the living space. Among them, interfaces that directly touch the human eye and hands are the key to maintaining design, but there were many issues in terms of integration with design and aesthetics of living spaces. In this paper, we propose an interface system that operates existing furniture by touching it as a new interface that integrates beautifully into the living space. The proposed system detects user operations with four small vibration sensors attached to hidden locations of existing furniture and uses deep learning to learn the vibrations when a person touches the furniture. Using this method, thick materials difficult to achieve with normal capacitive touch sensors can be utilized. In the experiment, a dining table was used as a representative piece of furniture, and the accuracy of detecting the direction in which three participants swiped in four directions on the table was verified. As a result of the experiment, the accuracy was confirmed by Leave-One-Person-Out-Cross-Validation using 3 sessions of swipe data for each individual for 3 participants, and the accuracy was 0.67. Furthermore, we verified the accuracy of a trained model created by adding only one session of evaluation target data to each learning dataset used in the Leave-One-Person-Out-Cross-Validation. As a result, the accuracy reached 0.90, achieving practical precision.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Makoto Yoshida et al.",
      "keywords": "SwIPe; Computer science; Session (web analytics); Interface (matter); Key (lock); Table (database); Human\u2013computer interaction; Multi-touch; Assisted living; Artificial intelligence; Space (punctuation); Capacitive sensing; Computer vision; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3343500",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392309514",
      "doi": "10.1109/tnsre.2024.3371704",
      "title": "3D Visual Discomfort Assessment With a Weakly Supervised Graph Convolution Neural Network Based on Inaccurately Labeled EEG",
      "abstract": "Visual discomfort significantly limits the broader application of stereoscopic display technology. Hence, the accurate assessment of stereoscopic visual discomfort is a crucial topic in this field. Electroencephalography (EEG) data, which can reflect changes in brain activity, have received increasing attention in objective assessment research. However, inaccurately labeled data, resulting from the presence of individual differences, restrict the effectiveness of the widely used supervised learning methods in visual discomfort assessment tasks. Simultaneously, visual discomfort assessment methods should pay greater attention to the information provided by the visual cortical areas of the brain. To tackle these challenges, we need to consider two key aspects: maximizing the utilization of inaccurately labeled data for enhanced learning and integrating information from the brain's visual cortex for feature representation purposes. Therefore, we propose the weakly supervised graph convolution neural network for visual discomfort (WSGCN-VD). In the classification part, a center correction loss serves as a weakly supervised loss, employing a progressive selection strategy to identify accurately labeled data while constraining the involvement of inaccurately labeled data that are influenced by individual differences during the model learning process. In the feature extraction part, a feature graph module pays particular attention to the construction of spatial connections among the channels in the visual regions of the brain and combines them with high-dimensional temporal features to obtain visually dependent spatio-temporal representations. Through extensive experiments conducted in various scenarios, we demonstrate the effectiveness of our proposed model. Further analysis reveals that the proposed model mitigates the impact of inaccurately labeled data on the accuracy of assessment.",
      "year": "2024",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Na Lu et al.",
      "keywords": "Electroencephalography; Artificial intelligence; Computer science; Graph; Pattern recognition (psychology); Convolution (computer science); Convolutional neural network; Artificial neural network; Psychology; Neuroscience; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2024.3371704",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391621131",
      "doi": "10.1109/access.2024.3363879",
      "title": "CAMELON: A System for Crime Metadata Extraction and Spatiotemporal Visualization From Online News Articles",
      "abstract": "Crimes result in not only loss to individuals but also hinder national economic growth. While crime rates have been reported to decrease in developed countries, underdeveloped and developing nations still suffer from prevalent crimes, especially those undergoing rapid expansion of urbanization. The ability to monitor and assess trends of different types of crimes at both regional and national levels could assist local police and national-level policymakers in proactively devising means to prevent and address the root causes of criminal incidents. Furthermore, such a system could prove useful to individuals seeking to evaluate criminal activity for purposes of travel, investment, and relocation decisions. Recent literature has opted to utilize online news articles as a reliable and timely source for information on crime activity. However, most of the crime monitoring systems fueled by such news sources merely classified crimes into different types and visualized individual crimes on the map using extracted geolocations, lacking crucial information for stakeholders to make relevant, informed decisions. To better serve the unique needs of the target user groups, this paper proposes a novel comprehensive crime visualization system that mines relevant information from large-scale online news articles. The system features automatic crime-type classification and metadata extraction from news articles. The crime classification and metadata schemes are designed to serve the need for information from law enforcement and policymakers, as well as general users. Novel interactive spatiotemporal designs are integrated into the system with the ability to assess the severity and intensity of crimes in each region through the novel Criminometer index. The system is designed to be generalized for implementation in different countries with diverse prevalent crime types and languages composing the news articles, owing to the use of deep learning cross-lingual language models. The experiment results reveal that the proposed system yielded 86&#x0025;, 51&#x0025;, and 67&#x0025; F1 in crime type classification, metadata extraction, and closed-form metadata extraction tasks, respectively. Additionally, the results of the system usability tests indicated a notable level of contentment among the target user groups. The findings not only offer insights into the possible applications of interactive spatiotemporal crime visualization tools for proactive policymaking and predictive policing but also serve as a foundation for future research that utilizes online news articles for intelligent monitoring of real-world phenomena.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Siripen Pongpaichet et al.",
      "keywords": "Metadata; Law enforcement; Computer science; Visualization; Internet privacy; Business; World Wide Web; Political science; Data mining; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3363879",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4313306401",
      "doi": "10.1109/ojim.2022.3232650",
      "title": "An Online Parsing Framework for Semistructured Streaming System Logs of Internet of Things Systems",
      "abstract": "This article presents a novel log abstraction framework based on neural open information extraction (OpenIE) and dynamic word embedding principles. Though various log parsing frameworks are proposed in the literature, the existing frameworks are modeled on predefined heuristics or auto-regressive methodologies that work well in offline scenarios. However, these frameworks are less suitable for dynamic self-adaptive systems, such as the Internet of Things (IoT), where the log outputs have diverse contextual variations and disparate time irregularities. Therefore, it is essential to move away from these traditional approaches and develop a systematic model that can effectively analyze log outputs in real-time and increase the system up-time of IoT networks so that they are almost always available. To address these needs, the proposed framework used OpenIE along with term frequency/inverse document frequency (TF/IDF) vectorization for constructing a set of relational triples (aka triple-sets). Additionally, a dynamic pretrained encoder&#x2013;decoder architecture is utilized to imbibe the positional and contextualized information in its resultant outputs. The adopted methodology has enabled the proposed framework to extract richer word representations with dynamic contextualization of time-sensitive event logs to enhance further downstream activities, such as failure prediction and prognostic analysis of IoT networks. The proposed framework is evaluated on the system event log traces accumulated from a long range wide-area network (LoRaWAN) IoT gateway to proactively determine the probable causes of its various failure scenarios. Additionally, the study also provided a comparative analysis of its mathematical representations with that of the current state-of-the-art (SOTA) approaches to project the advantages and benefits of the proposed model, particularly from its data analytics standpoint.",
      "year": "2022",
      "journal": "IEEE Open Journal of Instrumentation and Measurement",
      "authors": "Susnata Bhattacharya et al.",
      "keywords": "Computer science; Parsing; Event (particle physics); Data mining; Word (group theory); Pruning; Set (abstract data type); Abstraction; Artificial intelligence; Information retrieval; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojim.2022.3232650",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4322707268",
      "doi": "10.1109/access.2023.3247627",
      "title": "A Vision and Semantics-Jointly Driven Hybrid Intelligence Method for Automatic Pairwise Language Conversion",
      "abstract": "In modern society where connections among nations have been more and more frequent, it remains important to realize automatic language conversion methods for the public. Currently, most the existing research works were conducted upon the basis of semantics analysis. But from the perspective of linguistics, the vision characteristics is also a kind of concomitant existence. To deal with such challenge, this paper proposes a vision and semantics-jointly driven hybrid intelligence method for automatic pairwise language conversion. The whole technical framework can be divided into two components: vision sensing part and semantics sensing part. For the former, the virtual reality is introduced for use to capture the visual feature representation for language contents. For the latter, the recurrent neural network model is utilized to capture semantic feature representation for language texts. They are then integrated into a jointly driving framework, so as to improve the conversion efficiency. Taking two dialects (Sichuan dialect and Chongqing dialect) in China as the example, the simulative experiments are conducted on massive real-world training corpus to evaluate the proposal. The results can reflect feasibility of it.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jianchao Zhao et al.",
      "keywords": "Computer science; Semantics (computer science); Pairwise comparison; Artificial intelligence; Feature (linguistics); Perspective (graphical); Natural language processing; Representation (politics); Programming language; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3247627",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389382698",
      "doi": "10.1109/ojcoms.2023.3339721",
      "title": "CSI-Based Proximity Estimation: Data-Driven and Model-Based Approaches",
      "abstract": "Proximity estimation forms the backbone of contact tracing solutions, as quarantining potentially infected individuals is essential for controlling the spread of epidemics. It is also essential for device discovery in Device-to-Device (D2D) and Vehicle-to-Vehicle (V2V) communications, which will be critical in future 6G networks. Despite the widespread coverage of cellular networks, no previous work has evaluated cellular-based proximity estimation in an experimental setting. In this paper, we collect Channel State Information (CSI) measurements from an actual cellular network and utilize them to train and evaluate two proposed solutions. Capitalizing on CSI spatial correlation, we propose a data-driven method to classify devices based on their respective proximity. The proposed neural network has an accuracy of 91.18&#x0025; when classifying devices as within 5 meters from one another or not, from only 10 seconds of CSI measurements. This method is complemented by a model-based approach that provides a solid theoretical model for estimating proximity. The model-based approach uses Bayesian inference of the conditional distribution of power correlation across devices, assuming spatially-correlated shadowing and stochastic geometry tools. The proposed Bayesian regressor fits our dataset better than the standard exponentially-decaying correlation model, reaching a <inline-formula> <tex-math notation=\"LaTeX\">$2.8 \\times $ </tex-math></inline-formula> lower RMSE while requiring fine-tuning of only two more parameters. A Bayesian classifier is also proposed and reached a 91.67&#x0025; accuracy on the binary case while also outperforming the data-driven model significantly at higher distances.",
      "year": "2023",
      "journal": "IEEE Open Journal of the Communications Society",
      "authors": "Lucas C. D. Bezerra et al.",
      "keywords": "Computer science; Inference; Data mining; Bayesian probability; Bayesian inference; Artificial neural network; Artificial intelligence; Channel state information; Spatial correlation; Machine learning; Pattern recognition (psychology); Algorithm; Wireless",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcoms.2023.3339721",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4214742677",
      "doi": "10.1109/access.2022.3153313",
      "title": "MADFAM: MicroArchitectural Data Framework and Methodology",
      "abstract": "In the aftermath of Spectre and Meltdown researchers have proposed a variety of attack detection solutions by applying machine learning to data collected from hardware performance monitoring units. Although many microarchitectural attack detection systems provide high-accuracy detection results, the behavior of the underlying data collection mechanisms is not well described or understood. This research introduces the MicroArchitectural Data Framework And Methodology (MADFAM) to prescribe a systematic approach to collecting and preserving the information available in sequences of microarchitectural data. The proposed framework focuses on hardware performance counters (HPCs) as the primary data source. HPC configuration is complex, which makes it difficult for others to reproduce results or advance the state-of-the-art. This framework includes a description of design decisions that HPC research must consider across an array of problem domains, including information security. MADFAM proposes a data collection architecture and evaluation criteria to improve the discussion about the experimental settings and design decisions used in HPC research. The proposed framework evaluation criteria are then used to establish a baseline characterization of time series data that future research can use to compare alternative framework implementations.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Tor J. Langehaug et al.",
      "keywords": "Computer science; Implementation; Variety (cybernetics); Data collection; Microarchitecture; Data science; Computer architecture; Data mining; Embedded system; Artificial intelligence; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3153313",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388240350",
      "doi": "10.1109/access.2023.3329571",
      "title": "Leveraging Inference: A Regression-Based Learner Performance Prediction System for Knowledge Tracing",
      "abstract": "Learner modelling and performance prediction have seen numerous advances in the last decade which include Neural Network (NN) based approaches like Deep Knowledge Tracing (DKT), Factorisation machines for estimation and automatic detection of skill tags amongst others. Intelligent Tutoring Systems (ITSs), which try to tailor each user&#x2019;s learning by adaptively scheduling problems depend upon learner modelling and the accurate prediction of learner performance to operate. ITSs have led to the availability of large-scale datasets enabling the development of richer models. The classical Bayesian approaches have been overtaken by faster, more scalable and more accurate models like DASH and DAS3H. Despite recent gains in prediction accuracy by NN based models, they are getting increasingly complex and computationally expensive. The issues with the scalability of recent models hinder their widespread adoption in Massive Online Open Courses (MOOCs) which outnumber ITSs by several magnitudes. NN models have very limited transferability. In this paper, the state-of-the-art approach involving Logistic Regression (LR) is examined on 8 public datasets and an alternative system based on variational encoding is presented. The proposed system outperforms the LR model in accuracy for 4 datasets. The new model is applied to the biggest Educational Data Mining (EDM) dataset available and shows that training on such a large dataset is possible without batching, which is not possible by other techniques. The paper focuses on the increase in scalability with a smaller memory footprint (requiring 22.5 &#x00B1; 7.45 &#x0025; less memory). The system also had a reduction in runtime for 5 among the 8 datasets. However, the variance in reduction is high with an average of <inline-formula> <tex-math notation=\"LaTeX\">$10.12\\pm 21.55 \\%$ </tex-math></inline-formula> reduced run times. The proposed system was developed specifically for lightweight MOOCs with limited Learning Management Systems (LMS) such as Moodle. By estimating a learner ability parameter, the proposed system provides richer information to downstream applications like adaptive scheduling. The proposed model retains a high level of interpretability and transferability.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Abhilash Sridhara et al.",
      "keywords": "Computer science; Scalability; Machine learning; Artificial intelligence; Memory footprint; Tracing; Inference; Deep learning; Data mining; Scheduling (production processes); Artificial neural network; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3329571",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226065492",
      "doi": "10.1109/access.2022.3160290",
      "title": "A Multi-Feature Fusion Network for Pathological Identification of Tumor Cells",
      "abstract": "A novel multi-feature fusion neural network (MFNet) is proposed to address the lack of applicability of existing medical aid diagnostic methods for cross-site and cross-tissue cytopathic lesion screening. MFNet consists of a data-sharing layer, a detailed feature transfer branch, a microscopic identification branch, and an auxiliary loss function. The data-sharing layer converts data images into a feature matrix and extracts detailed elements such as cell morphology, contour, and texture. The microscopic recognition branch obtains multilevel elements by convolving the input elements in stages and fusing them, so that the network can focus on high-level semantic elements such as minor differences of cytopathy. The detail feature transfer branch transfers detail elements across layers and achieves cross-layer fusion with semantic elements. The auxiliary loss function enables the network feature classification capability to be enhanced. MFNet is experimentally compared with AlexNet, VGG-16, ResNet-50, and other models on the tumor cell datasets, and the results show that the proposed method can effectively improve the recognition accuracy.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Zhongda Lu et al.",
      "keywords": "Computer science; Feature (linguistics); Pattern recognition (psychology); Artificial intelligence; Focus (optics); Feature extraction; Identification (biology); Artificial neural network; Backbone network; Fusion",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3160290",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390187221",
      "doi": "10.1109/access.2023.3346675",
      "title": "Detecting Topics and Polarity From Twitter: A University Faculty Case",
      "abstract": "Social networks have become a powerful communication tool, with millions of people exchanging information, opinions, and experiences daily. Companies, organizations, and even people have turned this tool into a marketing platform to position themselves and gain popularity. However, not only do companies present products or services to society, but society also provides feedback. This feedback also has a significant impact. It is impossible to process all this vast information manually in time, but it is crucial. This information is precious even to governmental or public entities such as universities. Potential future students will use social media to learn about the general feel of the institution. Therefore, this study presents a new dataset called CEIMaT2021, which compiles all tweets in Spanish related to the Technical School of Industrial Engineering of the Universidad Polit&#x00E9;cnica de Madrid (ETSII-UPM). This dataset is designed for two main tasks of Online Reputation Management: 1) automatic detection of topics and 2) polarity. Furthermore, this study shows that the BETO model obtains better performance for topic detection for these tasks. Meanwhile, the MarIA model obtains better results for polarity detection.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Almudena S\u00e1nchez Ru\u00edz et al.",
      "keywords": "Reputation; Popularity; Social media; Polarity (international relations); Computer science; Institution; Process (computing); Position (finance); World Wide Web; State (computer science); Data science; Knowledge management; Business; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3346675",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4244955348",
      "doi": "10.1109/jstars.2021.3050695",
      "title": "2020 Index IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing Vol. 13",
      "abstract": "",
      "year": "2020",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "See Huang et al.",
      "keywords": "Index (typography); Computer science; Remote sensing; Earth (classical element); Geology; World Wide Web; Physics; Astronomy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2021.3050695",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387986939",
      "doi": "10.1109/access.2023.3328173",
      "title": "Accelerating Super-Resolution Network Inference via Sensitivity-Based Weight Sparsity Allocation",
      "abstract": "Weight sparsification has been extensively studied in image classification and object detection to accelerate network inference. However, for image generation tasks, such as image super-resolution, forcing some weights to zeros is a non-trivial task that typically causes significant degradation in restoration quality, that is, peak signal-to-noise (PSNR). In this study, we first introduce a sensitivity metric to measure PSNR degradation for layer-wise sparsity changes and observe that the sensitivities vary significantly across network layers. We demonstrate that a uniform sparsity allocation method generally causes a non-negligible decrease in accuracy, that is, approximately 0.17 dB, for 65&#x0025; of the zero weights. In addition, finding an optimal solution to the sparsity allocation problem is not feasible because the design space is exponential with respect to the number of weights and layers. To address this problem, we proposed a simple yet effective sparsity allocation method based on layer-wise sensitivity. The experimental results demonstrate that the proposed method achieves up to 35&#x0025; computation reduction with an average accuracy drop of 0.02 dB varying between 0.01 to 0.04 dB across the well-known datasets Set5, Set14, B100, and Urban100. Moreover, when integrated with the activation sparsity SMSR, the proposed method reduced the computation by 46&#x0025; on average.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Tuan Nghia Nguyen et al.",
      "keywords": "Computer science; Inference; Sensitivity (control systems); Resolution (logic); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3328173",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4304807415",
      "doi": "10.1109/tits.2022.3208067",
      "title": "Table of Contents",
      "abstract": "",
      "year": "2022",
      "journal": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "W Li et al.",
      "keywords": "Table (database); Computer science; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tits.2022.3208067",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4383751759",
      "doi": "10.1109/access.2023.3294097",
      "title": "A Microcontroller-Based Platform for Cognitive Tracking of Sensorimotor Training",
      "abstract": "A new generation of fitness trackers is pervasively invading different aspects of our life, taking profit from wireless technology, embedded sensors, and increasingly accurate AI-based data analysis. The most crucial aspects concerning the design of these systems include energy efficiency and accuracy. In this paper, we propose a system relying on two microcontroller-based sensor nodes to track the physical activity during sensorimotor training, a type of exercise that challenges the user&#x2019;s balance skill, which has been proven to be very effective in improving performance, preventing injuries and recovering from them. One of the sensor nodes is integrated into a custom wobble-board and the second is wearable by the user. The nodes are adaptable to be set in different operating modes, depending on the use case needs, enabling different steps of near-sensor pre-processing. The most power-efficient operating mode executes a CNN-based analysis directly on the microcontroller, to recognize physical exercises. The algorithm provides an accuracy of respectively 99.4&#x0025; and 97.6&#x0025; on the two nodes. In-place execution of the CNN saves up to 65&#x0025; power consumption with respect to the transmission of raw data for on-cloud analysis.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Matteo Antonio Scrugli et al.",
      "keywords": "Computer science; Microcontroller; Wearable computer; Embedded system; Real-time computing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3294097",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385626777",
      "doi": "10.1109/access.2023.3303105",
      "title": "In\u00c9ire: An Interpretable NLP Pipeline Summarizing Inclusive Policy Making Concerning Migrants in Ireland",
      "abstract": "Reaching marginal and other migrant communities to elicit their political views and opinions is a well-known challenge. Social media has enabled a certain amount of online activism and participation, especially in societies with abundant multicultural identities. However, it can be quite challenging to isolate the voice of the migrant in English-speaking countries, especially with an abundance of content in English on social media. In this paper, we pursue a case study of Ireland\u2019s Twitter landscape, specifically migrant and native activists. We present a methodology that can accurately ( &gt;80% ) isolate the Irish migrant voice with as little as 25 English tweets without relying on user metadata and using simple, highly explainable, out-of-the-box machine learning methods. Using this, we distil (via sentiment analysis) polarities of views, segment (via BERT-based topic modelling) and summarise (via ChatGPT) differentiated views in a consumable manner for policymakers. Our approach enables policymakers to further their understanding of multicultural communities and use this to inform their decision-making processes.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Arefeh Kazemi et al.",
      "keywords": "Pipeline (software); Artificial intelligence; Natural language processing; Computer science; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3303105",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392642840",
      "doi": "10.1109/access.2024.3375334",
      "title": "Domain Adaptation of Time Series Classification",
      "abstract": "In the era of big data and the rapid development of sensor technology, the time series classification problem has become an important research direction in the field of data mining. The complexity and diversity of time series data itself may lead to the inconsistency of the distribution between the training set and the test set, and this distribution difference may cause significant fluctuations in the model performance in practical applications. In contrast, domain adaptation models aim to adapt to test data with different distributions from the training data to improve the model performance. To address this challenge, we propose the Au-RAINCOAT model based on the RAINCOAT model, which is a closed-set domain adaptation model for complex time series. The model first considers the introduction of an Auto-Correlation mechanism module, which aims to compensate for the shortcomings of the Fourier transform by capturing local information while improving the computational efficiency. Second, to avoid the stability problems associated with the choice of regularization parameters in Sinkhorn divergence, we choose to use the Proxy-A-Distance(PAD).In this paper, we use four common datasets such as WISDM, HAR, HHAR, Sleep-EDF, and experiments are conducted on seven models. The experimental results show that the method has better results on the four datasets.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Xinli Wang et al.",
      "keywords": "Computer science; Series (stratigraphy); Domain adaptation; Time series; Adaptation (eye); Domain (mathematical analysis); Artificial intelligence; Machine learning; Mathematics; Geology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3375334",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392498841",
      "doi": "10.1109/tcss.2023.3306571",
      "title": "Digital Learning Challenges in Tertiary Education in Sri Lanka: A Social Capital Perspective",
      "abstract": "This study investigates the underlying factors that contribute to the success of digital learning in higher education using a social capital perspective. It is important to address the issues faced in tertiary education as these students will soon be a part of the workforce. Although digital learning has advanced in developed countries, many developing nations, including Sri Lanka, are still in the early stages of adopting it. Previous research has not adequately explored the relationship between social capital and the challenges of digital learning in the Sri Lankan context. Thus, this study focuses on examining the structural, relational, and cognitive aspects of social capital in relation to the difficulties in digital education in tertiary institutions. The research uses a quantitative approach, and the data were collected through an online survey of students in nonstate universities in Sri Lanka. Structural equation modeling was used to analyze the data, and the results showed that the three dimensions of poor social capital have a negative impact on digital education in tertiary institutions. This study also used multigroup moderation analysis to examine the effect of gender and location. This article will provide new insights into the role of social capital in digital education and will help policy makers to improve the quality and accessibility of digital education for all.",
      "year": "2024",
      "journal": "IEEE Transactions on Computational Social Systems",
      "authors": "Jayoda Weerapperuma et al.",
      "keywords": "Sri lanka; Perspective (graphical); Social capital; Higher education; Economic growth; Development economics; Engineering; Engineering management; Computer science; Political science; Sociology; Social science; Economics; Socioeconomics; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcss.2023.3306571",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392607835",
      "doi": "10.1109/jstars.2024.3373753",
      "title": "Siamese Biattention Pooling Network for Change Detection in Remote Sensing",
      "abstract": "Change detection (CD) in remote sensing aims to identify variations in image pairs captured at the same location but different times. While recent deep learning approaches, particularly those incorporating attention mechanisms, have achieved encouraging results on this task, they often fall short of comprehensively exploiting the change relevant patterns that are present in paired images. In this study, we propose a novel deep learning architecture, namely Siamese Bi-Attention Pooling Network (SBA-PN), to emphasize broad-scale change patterns by exploiting both intraimage and interimage contexts. The overall structure of SBA-PN aligns with the U-Net based encoder-decoder paradigm. A Siamese Transformer-like encoder formulates paired multiscale feature maps. To effectively emphasize change relevant patterns, a spatial optimal pooling module is devised, replacing the conventional self-attention mechanism. A contrastive pixel-wise supervision scheme is designed for shallow encoder layers in pursuit of change-aware feature maps. Next, the decoder mirrors the multiscale design, which formulates difference maps using a novel biattention mechanism from paired feature maps. During the decoding phase, a channel deviation pooling module is devised to further emphasize salient change regions. Comprehensive experimental results demonstrate the effectiveness of the proposed method with the state-of-the-art performance on two commonly used benchmark datasets, Sun Yat-Sen University (SYSU)-CD and LEarning VIsion Remote sensing (LEVIR)-CD.",
      "year": "2024",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Hengzhi Chen et al.",
      "keywords": "Computer science; Pooling; Remote sensing; Change detection; Artificial intelligence; Geology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2024.3373753",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205913465",
      "doi": "10.1109/msp.2021.3124108",
      "title": "2021 Index IEEE Signal Processing Magazine Vol. 38",
      "abstract": "",
      "year": "2021",
      "journal": "IEEE Signal Processing Magazine",
      "authors": "C Pak et al.",
      "keywords": "Index (typography); Computer science; Signal processing; SIGNAL (programming language); Speech recognition; Digital signal processing; Computer hardware; World Wide Web; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/msp.2021.3124108",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4395069518",
      "doi": "10.23919/jsc.2024.0003",
      "title": "Multifaceted Disparities Associated with Translator Earnings: A Quantitative Study of Upwork Profiles",
      "abstract": "This study aims to quantitatively explore the multifaceted determinants that influence earnings in the translation industry. Using a dataset comprising 45 000 translator profiles, the study focusses on delineating disparities correlated with demographic variables such as age, gender, home country wealth, and language pairs. The study uses a random forest regression model to delineate the complex interaction between gender, the economic standing of a translator\u2019s domicile country, age, and linguistic proficiency, as they relate to earnings. Our findings substantiate and, in many ways, extend existing qualitative and anecdotal evidence that has shaped the discourse in this sector. The rigorous empirical framework employed here can be replicated or adapted to study other sectors within the gig economy, thus contributing to a more comprehensive understanding of labour dynamics in the digital age.",
      "year": "2024",
      "journal": "Journal of Social Computing",
      "authors": "Tyler Horan",
      "keywords": "Earnings; Geography; Psychology; Business; Accounting",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2024.0003",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4304807446",
      "doi": "10.1109/tits.2022.3207363",
      "title": "Scanning the Issue",
      "abstract": "This survey paper reviews the risk assessment methodology for autonomous vehicles. The paper explains the necessity of real-time risk assessment in conjunction with traditional approaches, especially for highly automated driving. The current methodologies are segmented into different approaches to help identify risk in the aspects of quantitative or qualitative measurements. Further analyses are conducted for each methodology used during development or real-time usage. The outcome of this paper includes a recommended list that addresses each of these methodologies for their suitability toward ISO 26262 and ISO/PAS 21448. In addition, this paper addresses the importance of determinism and uncertainty in different risk assessment methodologies, especially in the usage of AI and machine learning.",
      "year": "2022",
      "journal": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "Azim Eskandarian",
      "keywords": "Computer science; Risk analysis (engineering); Outcome (game theory); Risk assessment; Artificial intelligence; Computer security; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tits.2022.3207363",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4382138511",
      "doi": "10.1109/access.2023.3289295",
      "title": "Forecasting National-Level Self-Harm Trends With Social Networks",
      "abstract": "Self-harm pertains to actions of self-inflicted poisoning or injury that lead to either non-fatal injuries or death, irrespective of the individual&#x2019;s intention. Self-harm incidents not only cause loss to individuals but also incur a negative impact on the nation&#x2019;s economy. Studies have demonstrated an increase in trends of self-harm that are correlated with the emergence of technological advancements and swift urban expansion in developing countries. The capacity to nowcast and forecast national-level patterns of self-harm trends could be imperative to policymakers and stakeholders in the public health sector, as it would enable them to implement prompt measures to counteract the underlying factors or avert these projected calamities. Prior research has utilized historical data to predict self-harm trends at the population level in various nations using conventional statistical forecasting methods. However, in some countries, such historical statistics may be challenging to obtain or insufficient for accurate prediction, impeding the ability to comprehend and project the national self-harm landscape in a timely manner. This paper proposes <italic>FAST</italic>, a framework designed to forecast self-harm patterns at the national level by analyzing mental signals obtained from a large volume of social media data. These signals serve as a proxy for real-world population mental health that could be used to enhance the forecastability of self-harm trends. Specifically, language-agnostic language models are first trained to extract different mental signals from collected social media messages. Then, these signals are aggregated and processed into multi-variate time series, on which the time-delay embedding algorithm is applied to transform into temporal embedded instances. Finally, various machine learning regressors are validated for their forecastability. The proposed method is validated through a case study in Thailand, which utilizes a set of 12 mental signals extracted from tweets to forecast death and injury cases resulting from self-harm. The results show that the proposed method outperformed the traditional ARIMA baseline by 43.56&#x0025; and 36.48&#x0025; on average in terms of MAPE on forecasting death and injury cases from self-harm, respectively. As far as current understanding permits, our research represents the initial exploration of utilizing aggregated social media information for the purposes of nowcasting and forecasting trends of self-harm on a nationwide scale. The results not only provide insight into improved forecasting techniques for self-harm trends but also establish a foundation for forthcoming social-network-driven applications that hinge on the capacity to predict socioeconomic factors.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Suppawong Tuarob et al.",
      "keywords": "Harm; Computer science; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3289295",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285032226",
      "doi": "10.1109/tits.2022.3185868",
      "title": "Scanning the Issue",
      "abstract": "Resource Allocation of Video Streaming Over Vehicular Networks: A Survey, Some Research Issues and Challenges",
      "year": "2022",
      "journal": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "Azim Eskandarian",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tits.2022.3185868",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388283547",
      "doi": "10.1109/tpwrs.2023.3328250",
      "title": "2023 Index IEEE Transactions on Power Systems Vol. 38",
      "abstract": "",
      "year": "2023",
      "journal": "IEEE Transactions on Power Systems",
      "authors": "See Donaldson et al.",
      "keywords": "Index (typography); Electric power system; Computer science; Reliability engineering; Power (physics); Electrical engineering; Engineering; Physics; Thermodynamics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tpwrs.2023.3328250",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387987020",
      "doi": "10.1109/access.2023.3328175",
      "title": "A Video Game-Crowdsourcing Approach to Discover a Player\u2019s Strategy for Problem Solution to Facility Location",
      "abstract": "In recent times, there has been a growing interest in the domain of computationally challenging problem solving within both scientific and organizational contexts. This study is primarily concerned with the extraction and comprehension of the methodologies and strategies employed by individuals when confronted with intricate problems, specifically those falling under the purview of NP-hard problems. The Facility Location Problem (FLP) serves as a prominent exemplar within this study&#x2019;s framework. Traditionally, the handling of such complex problems has leaned upon intuitive reasoning and visual perception as the primary tools. However, these conventional approaches tend to provide only limited insight into the underlying processes employed in solving such problems. The present research seeks to bridge this knowledge gap through the utilization of advanced machine learning techniques for the purpose of categorizing and scrutinizing the strategies deployed by individuals in their attempts to tackle computationally challenging problems. The analysis conducted as part of this study unveils discernible and well-defined patterns and strategies that are employed by participants, some of whom have achieved notable levels of success. Remarkably, in certain instances, the outcomes achieved by these individuals have demonstrated a competitive edge when compared to the results produced by sophisticated computational methods, such as genetic algorithms. A fundamental component of our research methodology involves the application of heatmaps and clustering techniques. Through the normalization of results, our findings distinctly delineate two primary categories of games: those characterized by uniform player strategies and those characterized by a multitude of diverse and individualized tactics. Furthermore, our research employs a systematic approach to represent games by clustering them based on inherent similarities, utilizing cosine similarity as a metric for this purpose. By computing the averages of vectors within each cluster, we derive centroids that encapsulate the central tendencies exhibited by games belonging to that cluster. These centroids are then visually presented in a three-dimensional format, complemented by proportional spheres. These visual representations serve to vividly illustrate the dispersion and influence associated with each cluster. Our research significantly contributes to the understanding of human problem-solving strategies when confronted with computationally challenging problems. It unearths valuable insights regarding the potential for harnessing human intuition and expertise in addressing complex computational challenges. Through the integration of machine learning methodologies and intuitive visualizations, this work advances our comprehension of the approaches individuals employ to excel in solving computationally intricate problems.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mariano Vargas-Santiago et al.",
      "keywords": "Crowdsourcing; Computer science; Facility location problem; Video game; Multimedia; World Wide Web; Operations research; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3328175",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4236940928",
      "doi": "10.1109/jstars.2020.3046663",
      "title": "Table of Contents",
      "abstract": "",
      "year": "2020",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "T Guo et al.",
      "keywords": "Computer science; Table (database); Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2020.3046663",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390888841",
      "doi": "10.1109/tiv.2024.3353608",
      "title": "2023 Index IEEE Transactions on Intelligent Vehicles Vol. 8",
      "abstract": "",
      "year": "2023",
      "journal": "IEEE Transactions on Intelligent Vehicles",
      "authors": "P De Araujo et al.",
      "keywords": "Index (typography); Computer science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tiv.2024.3353608",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4395069498",
      "doi": "10.23919/jsc.2024.0004",
      "title": "Media Power Measuring via Emotional Contagion",
      "abstract": "Media power, the impact that media have on public opinion and perspectives, plays a significant role in maintaining internal stability, exerting external influence, and shaping international dynamics for nations /regions. However, prior research has primarily concentrated on news content and reporting time, resulting in limitations in evaluating media power. To more accurately assess media power, we use news content, news reporting time, and news emotion simultaneously to explore the emotional contagion between media. We use emotional contagion to measure the mutual influence between media and regard the media with greater impact as having stronger media power. We propose a framework called Measuring Media Power via Emotional Contagion (MMPEC) to capture emotional contagion among media, enabling a more accurate assessment of media power at the media and national/regional levels. MMPEC also interprets experimental results through correlation and causality analyses, ensuring explainability. Case analyses confirm the higher accuracy of MMPEC compared to other baseline models, as demonstrated in the context of COVID-19-related news, yielding compelling and interesting insights.",
      "year": "2024",
      "journal": "Journal of Social Computing",
      "authors": "Xue Lin et al.",
      "keywords": "Emotional contagion; Psychology; Power (physics); Cognitive psychology; Social psychology; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2024.0004",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388486518",
      "doi": "10.1109/access.2023.3331323",
      "title": "Breaking Barriers in Sentiment Analysis and Text Emotion Detection: Toward a Unified Assessment Framework",
      "abstract": "Sentiment analysis (SA) and text emotion detection (TED) are two computer techniques used to analyze text. SA categorizes text into positive, negative, or neutral opinions, while TED can identify a wide array of emotional states, allowing an automated agent to respond appropriately. These techniques can be helpful in areas such as employee and customer management, online support, and customer loyalty, where identifying human emotions is crucial. Among other approaches, research has been conducted using machine learning (ML) algorithms, and labeled datasets have been created to train these models. Current state-of-the-art research for supervised ML algorithms reports good performance for TED (approximately 80&#x0025; accuracy) and even better results for SA (above 90&#x0025;). After conducting an extensive review of 30 surveys, the primary objective of this manuscript is to point out that most of these articles (94&#x0025;) focus heavily on comparing the applied computational methods (the algorithm). At the same time, relatively diminished attention is paid to three other critical factors, namely the selection of an appropriate emotion model (mentioned only in 23&#x0025; of cases), the corpora utilized for training (30&#x0025;), and the data source employed during analysis and evaluation (20&#x0025;). The lack of standardization across these essential elements presents a significant challenge when performing meaningful performance comparisons among algorithms. Consequently, the absence of a unified framework for comparison hampers the practical implementation of SA and TED techniques within mission-critical scenarios within real-world mission-critical scenarios.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Alejandro de Le\u00f3n Langur\u00e9 et al.",
      "keywords": "Sentiment analysis; Computer science; Standardization; Artificial intelligence; Machine learning; Feature (linguistics); Data science; Loyalty; Labeled data; Natural language processing; Information retrieval",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3331323",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3003667836",
      "doi": "10.1109/access.2020.2970143",
      "title": "Digital Twin: Values, Challenges and Enablers From a Modeling Perspective",
      "abstract": "Digital twin can be defined as a virtual representation of a physical asset enabled through data and simulators for real-time prediction, optimization, monitoring, controlling, and improved decision making. Recent advances in computational pipelines, multiphysics solvers, artificial intelligence, big data cybernetics, data processing and management tools bring the promise of digital twins and their impact on society closer to reality. Digital twinning is now an important and emerging trend in many applications. Also referred to as a computational megamodel, device shadow, mirrored system, avatar or a synchronized virtual prototype, there can be no doubt that a digital twin plays a transformative role not only in how we design and operate cyber-physical intelligent systems, but also in how we advance the modularity of multi-disciplinary systems to tackle fundamental barriers not addressed by the current, evolutionary modeling practices. In this work, we review the recent status of methodologies and techniques related to the construction of digital twins mostly from a modeling perspective. Our aim is to provide a detailed coverage of the current challenges and enabling technologies along with recommendations and reflections for various stakeholders.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Adil Rasheed et al.",
      "keywords": "Computer science; Data science; Big data; Perspective (graphical); Data sharing; Human\u2013computer interaction; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2970143",
      "cited_by_count": 1548,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4296079469",
      "doi": "10.1109/access.2022.3207287",
      "title": "A Survey of Ensemble Learning: Concepts, Algorithms, Applications, and Prospects",
      "abstract": "Ensemble learning techniques have achieved state-of-the-art performance in diverse machine learning applications by combining the predictions from two or more base models. This paper presents a concise overview of ensemble learning, covering the three main ensemble methods: bagging, boosting, and stacking, their early development to the recent state-of-the-art algorithms. The study focuses on the widely used ensemble algorithms, including random forest, adaptive boosting (AdaBoost), gradient boosting, extreme gradient boosting (XGBoost), light gradient boosting machine (LightGBM), and categorical boosting (CatBoost). An attempt is made to concisely cover their mathematical and algorithmic representations, which is lacking in the existing literature and would be beneficial to machine learning researchers and practitioners.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ibomoiye Domor Mienye et al.",
      "keywords": "Boosting (machine learning); Gradient boosting; AdaBoost; Ensemble learning; Machine learning; Artificial intelligence; Computer science; Categorical variable; Random forest; Algorithm; Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3207287",
      "cited_by_count": 987,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2988359971",
      "doi": "10.1109/access.2019.2953499",
      "title": "A Survey on Digital Twin: Definitions, Characteristics, Applications, and Design Implications",
      "abstract": "When, in 1956, Artificial Intelligence (AI) was officially declared a research field, no one would have ever predicted the huge influence and impact its description, prediction, and prescription capabilities were going to have on our daily lives. In parallel to continuous advances in AI, the past decade has seen the spread of broadband and ubiquitous connectivity, (embedded) sensors collecting descriptive high dimensional data, and improvements in big data processing techniques and cloud computing. The joint usage of such technologies has led to the creation of digital twins, artificial intelligent virtual replicas of physical systems. Digital Twin (DT) technology is nowadays being developed and commercialized to optimize several manufacturing and aviation processes, while in the healthcare and medicine fields this technology is still at its early development stage. This paper presents the results of a study focused on the analysis of the state-of-the-art definitions of DT, the investigation of the main characteristics that a DT should possess, and the exploration of the domains in which DT applications are currently being developed. The design implications derived from the study are then presented: they focus on socio-technical design aspects and DT lifecycle. Open issues and challenges that require to be addressed in the future are finally discussed.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Barbara Rita Barricelli et al.",
      "keywords": "Computer science; Data science; Cloud computing; Field (mathematics); Big data; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2953499",
      "cited_by_count": 1274,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W1541250240",
      "doi": "10.1109/jbhi.2015.2450362",
      "title": "Big Data for Health",
      "abstract": "This paper provides an overview of recent developments in big data in the context of biomedical and health informatics. It outlines the key characteristics of big data and how medical and health informatics, translational bioinformatics, sensor informatics, and imaging informatics will benefit from an integrated approach of piecing together different aspects of personalized information from a diverse range of data sources, both structured and unstructured, covering genomics, proteomics, metabolomics, as well as imaging, clinical diagnosis, and long-term continuous physiological sensing of an individual. It is expected that recent advances in big data will expand our knowledge for testing new hypotheses about disease management from diagnosis to prevention to personalized treatment. The rise of big data, however, also raises challenges in terms of privacy, security, data ownership, data stewardship, and governance. This paper discusses some of the existing activities and future opportunities related to big data for health, outlining some of the key underlying issues that need to be tackled.",
      "year": "2015",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Javier Andreu-P\u00e9rez et al.",
      "keywords": "Big data; Data science; Health informatics; Informatics; Computer science; Translational bioinformatics; Context (archaeology); Translational research informatics; Stewardship (theology); Data governance; Data management; Health Administration Informatics; Genomics; Health care; Data mining; Data quality; Engineering; Political science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jbhi.2015.2450362",
      "cited_by_count": 672,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3034560014",
      "doi": "10.1109/access.2020.3001973",
      "title": "Artificial Intelligence and COVID-19: Deep Learning Approaches for Diagnosis and Treatment",
      "abstract": "COVID-19 outbreak has put the whole world in an unprecedented difficult situation bringing life around the world to a frightening halt and claiming thousands of lives. Due to COVID-19's spread in 212 countries and territories and increasing numbers of infected cases and death tolls mounting to 5,212,172 and 334,915 (as of May 22 2020), it remains a real threat to the public health system. This paper renders a response to combat the virus through Artificial Intelligence (AI). Some Deep Learning (DL) methods have been illustrated to reach this goal, including Generative Adversarial Networks (GANs), Extreme Learning Machine (ELM), and Long/Short Term Memory (LSTM). It delineates an integrated bioinformatics approach in which different aspects of information from a continuum of structured and unstructured data sources are put together to form the user-friendly platforms for physicians and researchers. The main advantage of these AI-based platforms is to accelerate the process of diagnosis and treatment of the COVID-19 disease. The most recent related publications and medical reports were investigated with the purpose of choosing inputs and targets of the network that could facilitate reaching a reliable Artificial Neural Network-based tool for challenges associated with COVID-19. Furthermore, there are some specific inputs for each platform, including various forms of the data, such as clinical data and medical imaging which can improve the performance of the introduced approaches toward the best responses in practical applications.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammad Jamshidi et al.",
      "keywords": "Computer science; Artificial intelligence; Coronavirus disease 2019 (COVID-19); Adversarial system; Deep learning; Artificial neural network; Machine learning; Process (computing); Data science; Generative grammar; Infectious disease (medical specialty); Disease; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3001973",
      "cited_by_count": 546,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2997177758",
      "doi": "10.1109/access.2019.2963053",
      "title": "A Machine Learning Methodology for Diagnosing Chronic Kidney Disease",
      "abstract": "Chronic kidney disease (CKD) is a global health problem with high morbidity and mortality rate, and it induces other diseases. Since there are no obvious symptoms during the early stages of CKD, patients often fail to notice the disease. Early detection of CKD enables patients to receive timely treatment to ameliorate the progression of this disease. Machine learning models can effectively aid clinicians achieve this goal due to their fast and accurate recognition performance. In this study, we propose a machine learning methodology for diagnosing CKD. The CKD data set was obtained from the University of California Irvine (UCI) machine learning repository, which has a large number of missing values. KNN imputation was used to fill in the missing values, which selects several complete samples with the most similar measurements to process the missing data for each incomplete sample. Missing values are usually seen in real-life medical situations because patients may miss some measurements for various reasons. After effectively filling out the incomplete data set, six machine learning algorithms (logistic regression, random forest, support vector machine, k-nearest neighbor, naive Bayes classifier and feed forward neural network) were used to establish models. Among these machine learning models, random forest achieved the best performance with 99.75% diagnosis accuracy. By analyzing the misjudgments generated by the established models, we proposed an integrated model that combines logistic regression and random forest by using perceptron, which could achieve an average accuracy of 99.83% after ten times of simulation. Hence, we speculated that this methodology could be applicable to more complicated clinical data for disease diagnosis.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Jiongming Qin et al.",
      "keywords": "Machine learning; Naive Bayes classifier; Random forest; Artificial intelligence; Computer science; Missing data; Logistic regression; Support vector machine; Multilayer perceptron; Kidney disease; Artificial neural network; Perceptron; Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2963053",
      "cited_by_count": 303,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4376226279",
      "doi": "10.1109/tpami.2023.3275156",
      "title": "Multimodal Learning With Transformers: A Survey",
      "abstract": "Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and Big Data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal Big Data era, (2) a systematic review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community.",
      "year": "2023",
      "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Peng Xu et al.",
      "keywords": "Transformer; Computer science; Multimodal learning; Multimodal therapy; Artificial intelligence; Machine learning; Engineering; Electrical engineering; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tpami.2023.3275156",
      "cited_by_count": 735,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3023901165",
      "doi": "10.1109/jbhi.2020.2993072",
      "title": "A Patient-Centric Health Information Exchange Framework Using Blockchain Technology",
      "abstract": "Health Information Exchange (HIE) exhibits remarkable benefits for patient care such as improving healthcare quality and expediting coordinated care. The Office of the National Coordinator (ONC) for Health Information Technology is seeking patient-centric HIE designs that shift data ownership from providers to patients. There are multiple barriers to patient-centric HIE in the current system, such as security and privacy concerns, data inconsistency, timely access to the right records across multiple healthcare facilities. After investigating the current workflow of HIE, this paper provides a feasible solution to these challenges by utilizing the unique features of blockchain, a distributed ledger technology which is considered \"unhackable\". Utilizing the smart contract feature, which is a programmable self-executing protocol running on a blockchain, we developed a blockchain model to protect data security and patients' privacy, ensure data provenance, and provide patients full control of their health records. By personalizing data segmentation and an \"allowed list\" for clinicians to access their data, this design achieves patient-centric HIE. We conducted a large-scale simulation of this patient-centric HIE process and quantitatively evaluated the model's feasibility, stability, security, and robustness.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Yan Zhuang et al.",
      "keywords": "Blockchain; Workflow; Smart contract; Health information exchange; Computer science; Expediting; Health information technology; Health care; Computer security; Data security; Data exchange; Encryption; Database; Health information",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2020.2993072",
      "cited_by_count": 250,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3007212997",
      "doi": "10.1109/access.2020.2974687",
      "title": "An IoT Framework for Heart Disease Prediction Based on MDCNN Classifier",
      "abstract": "Nowadays, heart disease is the leading cause of death worldwide. Predicting\\nheart disease is a complex task since it requires experience along with\\nadvanced knowledge. Internet of Things (IoT) technology has lately been adopted\\nin healthcare systems to collect sensor values for heart disease diagnosis and\\nprediction. Many researchers have focused on the diagnosis of heart disease,\\nyet the accuracy of the diagnosis results is low. To address this issue, an IoT\\nframework is proposed to evaluate heart disease more accurately using a\\nModified Deep Convolutional Neural Network (MDCNN). The smartwatch and heart\\nmonitor device that is attached to the patient monitors the blood pressure and\\nelectrocardiogram (ECG). The MDCNN is utilized for classifying the received\\nsensor data into normal and abnormal. The performance of the system is analyzed\\nby comparing the proposed MDCNN with existing deep learning neural networks and\\nlogistic regression. The results demonstrate that the proposed MDCNN based\\nheart disease prediction system performs better than other methods. The\\nproposed method shows that for the maximum number of records, the MDCNN\\nachieves an accuracy of 98.2 which is better than existing classifiers.\\n",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammad Ayoub Khan",
      "keywords": "Computer science; Convolutional neural network; Heart disease; Machine learning; Artificial intelligence; Internet of Things; Artificial neural network; Deep learning; Classifier (UML); Logistic regression; Data mining; Embedded system; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2974687",
      "cited_by_count": 319,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3040868855",
      "doi": "10.1109/rbme.2020.3007816",
      "title": "Machine Learning for Clinical Outcome Prediction",
      "abstract": "Clinical decision-making in healthcare is already being influenced by predictions or recommendations made by data-driven machines. Numerous machine learning applications have appeared in the latest clinical literature, especially for outcome prediction models, with outcomes ranging from mortality and cardiac arrest to acute kidney injury and arrhythmia. In this review article, we summarize the state-of-the-art in related works covering data processing, inference, and model evaluation, in the context of outcome prediction models developed using data extracted from electronic health records. We also discuss limitations of prominent modeling assumptions and highlight opportunities for future research.",
      "year": "2020",
      "journal": "IEEE Reviews in Biomedical Engineering",
      "authors": "Farah E. Shamout et al.",
      "keywords": "Outcome (game theory); Inference; Computer science; Context (archaeology); Machine learning; Predictive modelling; Artificial intelligence; Data science; Data modeling; Health records; Health care; Clinical Practice; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/rbme.2020.3007816",
      "cited_by_count": 198,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3018662283",
      "doi": "10.1109/jbhi.2020.2990529",
      "title": "Homecare Robotic Systems for Healthcare 4.0: Visions and Enabling Technologies",
      "abstract": "Powered by the technologies that have originated from manufacturing, the fourth revolution of healthcare technologies is happening (Healthcare 4.0). As an example of such revolution, new generation homecare robotic systems (HRS) based on the cyber-physical systems (CPS) with higher speed and more intelligent execution are emerging. In this article, the new visions and features of the CPS-based HRS are proposed. The latest progress in related enabling technologies is reviewed, including artificial intelligence, sensing fundamentals, materials and machines, cloud computing and communication, as well as motion capture and mapping. Finally, the future perspectives of the CPS-based HRS and the technical challenges faced in each technical area are discussed.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Geng Yang et al.",
      "keywords": "Vision; Computer science; Health care; Healthcare system; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jbhi.2020.2990529",
      "cited_by_count": 191,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2760537051",
      "doi": "10.1109/taffc.2017.2724035",
      "title": "Automatic Assessment of Depression Based on Visual Cues: A Systematic Review",
      "abstract": "International audience",
      "year": "2017",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Anastasia Pampouchidou et al.",
      "keywords": "Artificial intelligence; Computer science; Dimensionality reduction; Machine learning; Sensory cue; Feature extraction; Domain (mathematical analysis)",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/taffc.2017.2724035",
      "cited_by_count": 217,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2979164675",
      "doi": "10.1109/access.2019.2945129",
      "title": "Development of Disease Prediction Model Based on Ensemble Learning Approach for Diabetes and Hypertension",
      "abstract": "Early diseases prediction plays an important role for improving healthcare quality and can help individuals avoid dangerous health situations before it is too late. This paper proposes a disease prediction model (DPM) to provide an early prediction for type 2 diabetes and hypertension based on individual's risk factors data. The proposed DPM consists of isolation forest (iForest) based outlier detection method to remove outlier data, synthetic minority oversampling technique tomek link (SMOTETomek) to balance data distribution, and ensemble approach to predict the diseases. Four datasets were utilized to build the model and extract the most significant risks factors. The results showed that the proposed DPM achieved highest accuracy when compared to other models and previous studies. We also developed a mobile application to provide the practical application of the proposed DPM. The developed mobile application gathers risk factor data and send it to a remote server, so that an individual's current condition can be diagnosed with the proposed DPM. The prediction result is then sent back to the mobile application; thus, immediate and appropriate action can be taken to reduce and prevent individual's risks once unexpected health situations occur (i.e., type 2 diabetes and/or hypertension) at early stages.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Norma Latif Fitriyani et al.",
      "keywords": "Computer science; Oversampling; Outlier; Ensemble learning; Anomaly detection; Data mining; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2945129",
      "cited_by_count": 183,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2972687021",
      "doi": "10.1109/access.2019.2941419",
      "title": "A Survey on Multimodal Data-Driven Smart Healthcare Systems: Approaches and Applications",
      "abstract": "Multimodal data-driven approach has emerged as an important driving force for smart healthcare systems with applications ranging from disease analysis to triage, diagnosis and treatment. Smart healthcare system necessitates new demands for data management and decision-making, which has inspired the rapid development of medical services using artificial intelligence and new transformations in the healthcare industry. In this paper, we provide a comprehensive survey of existing techniques which include not only state-of-the-art methods but also the most recent trends in the field. In particular, this review focuses on the types of decision-making processes used in smart healthcare systems. Firstly, approaches that utilize multimodal association mining with fine-grained data semantics in smart healthcare systems are introduced. We review the smart healthcare-oriented semantic perception, semantic alignment, entity association mining, and discuss the pros and cons of these approaches. Secondly, we discuss approaches for multimodal data fusion and cross-border association that have been employed in developing smart healthcare systems. Finally, we focus specifically on the use of the panoramic decision framework, interactive decision making, and intelligent decision support systems. We introduce how smart healthcare systems can be applied to and benefit a wide variety of fields, including knowledge discovery and privacy protection.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Qiong Cai et al.",
      "keywords": "Computer science; Health care; Data science; Variety (cybernetics); Field (mathematics); Decision support system; Semantics (computer science); Intelligent decision support system; Knowledge management; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2941419",
      "cited_by_count": 155,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3021137017",
      "doi": "10.1109/tai.2020.3020521",
      "title": "Leveraging Data Science to Combat COVID-19: A Comprehensive Review",
      "abstract": "COVID-19, an infectious disease caused by the SARS-CoV-2 virus, was declared a pandemic by the World Health Organisation (WHO) in March 2020. By mid-August 2020, more than 21 million people have tested positive worldwide. Infections have been growing rapidly and tremendous efforts are being made to fight the disease. In this paper, we attempt to systematise the various COVID-19 research activities leveraging data science, where we define data science broadly to encompass the various methods and tools-including those from artificial intelligence (AI), machine learning (ML), statistics, modeling, simulation, and data visualization-that can be used to store, process, and extract insights from data. In addition to reviewing the rapidly growing body of recent research, we survey public datasets and repositories that can be used for further work to track COVID-19 spread and mitigation strategies. As part of this, we present a bibliometric analysis of the papers produced in this short span of time. Finally, building on these insights, we highlight common challenges and pitfalls observed across the surveyed works. We also created a live resource repository at https://github.com/Data-Science-and-COVID-19/Leveraging-Data-Science-To-Combat-COVID-19-A-Comprehensive-Review that we intend to keep updated with the latest resources including new papers and datasets.",
      "year": "2020",
      "journal": "IEEE Transactions on Artificial Intelligence",
      "authors": "Siddique Latif et al.",
      "keywords": "Coronavirus disease 2019 (COVID-19); Data science; Pandemic; Computer science; Resource (disambiguation); Visualization; Process (computing); Citizen science; Big data; Data visualization; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); Infectious disease (medical specialty); Artificial intelligence; Data mining; Disease; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tai.2020.3020521",
      "cited_by_count": 245,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3132679163",
      "doi": "10.1109/access.2021.3059858",
      "title": "A Review on the Role of Machine Learning in Enabling IoT Based Healthcare Applications",
      "abstract": "The Internet of Things (IoT) is playing a vital role in the rapid automation of the healthcare sector. The branch of IoT dedicated towards medical science is at times termed as Healthcare Internet of Things (H-IoT). The key elements of all H-IoT applications are data gathering and processing. Due to the large amount of data involved in healthcare, and the enormous value that accurate predictions hold, the integration of machine learning (ML) algorithms into H-IoT is imperative. This paper aims to serve both as a compilation as well as a review of the various state of the art applications of ML algorithms currently being integrated with H-IoT. Some of the most widely used ML algorithms have been briefly introduced and their use in various H-IoT applications has been analyzed in terms of their advantages, scope, and possible improvements. Applications have been divided into the domains of diagnosis, prognosis and spread control, assistive systems, monitoring, and logistics. In healthcare, practical use of a model requires it to be highly accurate and to have ample measures against security attacks. The applications of ML algorithms in H-IoT discussed in this paper have shown experimental evidence of accuracy and practical usability. The constraints and drawbacks of each of these applications have also been described.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hemantha Krishna Bharadwaj et al.",
      "keywords": "Computer science; Internet of Things; Scope (computer science); Key (lock); Usability; Health care; Automation; Data science; Artificial intelligence; Computer security; Human\u2013computer interaction; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3059858",
      "cited_by_count": 198,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394676676",
      "doi": "10.1109/access.2024.3386826",
      "title": "A Comprehensive Systematic Review of YOLO for Medical Object Detection (2018 to 2023)",
      "abstract": "YOLO (You Only Look Once) is an extensively utilized object detection algorithm that has found applications in various medical object detection tasks. This has been accompanied by the emergence of numerous novel variants in recent years, such as YOLOv7 and YOLOv8. This study encompasses a systematic exploration of the PubMed database to identify peer-reviewed articles published between 2018 and 2023. The search procedure found 124 relevant studies that employed YOLO for diverse tasks including lesion detection, skin lesion classification, retinal abnormality identification, cardiac abnormality detection, brain tumor segmentation, and personal protective equipment detection. The findings demonstrated the effectiveness of YOLO in outperforming alternative existing methods for these tasks. However, the review also unveiled certain limitations, such as well-balanced and annotated datasets, and the high computational demands. To conclude, the review highlights the identified research gaps and proposes future directions for leveraging the potential of YOLO for medical object detection.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mohammed Gamal Ragab et al.",
      "keywords": "Computer science; Object (grammar); Object detection; Artificial intelligence; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3386826",
      "cited_by_count": 200,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2988828954",
      "doi": "10.1109/access.2019.2952609",
      "title": "Machine Learning-Based Models for Early Stage Detection of Autism Spectrum Disorders",
      "abstract": "Autism Spectrum Disorder (ASD) is a group of neurodevelopmental disabilities that are not curable but may be ameliorated by early interventions. We gathered early-detected ASD datasets relating to toddlers, children, adolescents and adults, and applied several feature transformation methods, including log, Z-score and sine functions to these datasets. Various classification techniques were then implemented with these transformed ASD datasets and assessed for their performance. We found SVM showed the best performance for the toddler dataset, while Adaboost gave the best results for the children dataset, Glmboost for the adolescent and Adaboost for the adult datasets. The feature transformations resulting in the best classifications was sine function for toddler and Z-score for children and adolescent datasets. After these analyses, several feature selection techniques were used with these Z-score-transformed datasets to identify the significant ASD risk factors for the toddler, child, adolescent and adult subjects. The results of these analytical approaches indicate that, when appropriately optimised, machine learning methods can provide good predictions of ASD status. This suggests that it may possible to apply these models for the detection of ASD in its early stages.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Tania Akter et al.",
      "keywords": "Autism spectrum disorder; Toddler; AdaBoost; Artificial intelligence; Machine learning; Autism; Computer science; Support vector machine; Feature (linguistics); Feature selection; Pattern recognition (psychology); Psychology; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2952609",
      "cited_by_count": 210,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2900404321",
      "doi": "10.1109/access.2019.2903568",
      "title": "Survey of State-of-the-Art Mixed Data Clustering Algorithms",
      "abstract": "Mixed data comprises both numeric and categorical features, and mixed datasets occur frequently in many domains, such as health, finance, and marketing. Clustering is often applied to mixed datasets to find structures and to group similar objects for further analysis. However, clustering mixed data is challenging because it is difficult to directly apply mathematical operations, such as summation or averaging, to the feature values of these datasets. In this paper, we present a taxonomy for the study of mixed data clustering algorithms by identifying five major research themes. We then present a state-of-the-art review of the research works within each research theme. We analyze the strengths and weaknesses of these methods with pointers for future research directions. Lastly, we present an in-depth analysis of the overall challenges in this field, highlight open research questions and discuss guidelines to make progress in the field.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Amir Ahmad et al.",
      "keywords": "Cluster analysis; Categorical variable; Computer science; Strengths and weaknesses; Data mining; Field (mathematics); Theme (computing); Data science; Open research; Information retrieval; Machine learning; Mathematics; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2903568",
      "cited_by_count": 243,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2736814566",
      "doi": "10.1109/tcds.2017.2721552",
      "title": "Artificial Intelligent System for Automatic Depression Level Analysis Through Visual and Vocal Expressions",
      "abstract": "A human being's cognitive system can be simulated by artificial intelligent systems. Machines and robots equipped with cognitive capability can automatically recognize a humans mental state through their gestures and facial expressions. In this paper, an artificial intelligent system is proposed to monitor depression. It can predict the scales of Beck depression inventory II (BDI-II) from vocal and visual expressions. First, different visual features are extracted from facial expression images. Deep learning method is utilized to extract key visual features from the facial expression frames. Second, spectral low-level descriptors and mel-frequency cepstral coefficients features are extracted from short audio segments to capture the vocal expressions. Third, feature dynamic history histogram (FDHH) is proposed to capture the temporal movement on the feature space. Finally, these FDHH and audio features are fused using regression techniques for the prediction of the BDI-II scales. The proposed method has been tested on the public Audio/Visual Emotion Challenges 2014 dataset as it is tuned to be more focused on the study of depression. The results outperform all the other existing methods on the same dataset.",
      "year": "2017",
      "journal": "IEEE Transactions on Cognitive and Developmental Systems",
      "authors": "Asim Jan et al.",
      "keywords": "Computer science; Artificial intelligence; Facial expression; Support vector machine; Mel-frequency cepstrum; Histogram; Speech recognition; Feature extraction; Feature (linguistics); Pattern recognition (psychology); Feature vector; Gesture",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcds.2017.2721552",
      "cited_by_count": 203,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3040351441",
      "doi": "10.1109/access.2020.3007561",
      "title": "An Efficient IoT-Based Patient Monitoring and Heart Disease Prediction System Using Deep Learning Modified Neural Network",
      "abstract": "The leading causes of death worldwide are chronic illnesses suchlike diabetes, Heart Disease (HD), cancer as well as chronic respiratory malady. It is remarkably intricate to diagnose HD with disparate symptoms or features. With the augmentation in popularity of smart wearable gadgets, a chance to render an Internet of Things (IoT) solution has turned out to be more. Unfortunately, the survival rates are low for the people suffering from sudden heart attacks. Consequently, a patient monitoring scheme intended for heart patients utilizing IoT centered Deep Learning Modified Neural Network (DLMNN) is proposed to assist in the HD diagnosis, and medication is given accordingly. This proposed technique is executed via `3' steps: I) Authentication, ii) Encryption, and iii) Classification. First, by utilizing the substitution cipher (SC) together with the SHA-512, the heart patient of the specific hospital is authenticated. Subsequently, the wearable IoT sensor device, which is fixed to the patient's body, concurrently transmits the sensor data to the cloud. This sensor data is encrypted and securely transmitted to the cloud utilizing the PDH-AES technique. After that, the encrypted data is finally decrypted, and by employing the DLMNN classifier, the classification is done. The classified outcomes comprise `2'types of data: i) normal and ii) abnormal. It denotes the patient's heart condition and if the outcome is abnormal, an alert text is passed to the physician for treating the patient. The investigational outcomes are estimated and the DLMNN for HD diagnosis shows improvement as compared to existing algorithms. Additionally, the proposed PDH-AES used in support of secure data transmission results in the highest level of security i.e. 95.87%, and it is achieved in the lowest time for encryption along with decryption when weighted against the existent AES.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Simanta Shekhar Sarmah",
      "keywords": "Computer science; Encryption; Wearable computer; Deep learning; Artificial neural network; Artificial intelligence; Cloud computing; Internet of Things; Machine learning; Advanced Encryption Standard; Classifier (UML); Wearable technology; Computer security; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3007561",
      "cited_by_count": 226,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3001869580",
      "doi": "10.1109/access.2020.2968537",
      "title": "Realizing an Efficient IoMT-Assisted Patient Diet Recommendation System Through Machine Learning Model",
      "abstract": "Recent studies have shown that robust diets recommended to patients by Dietician or an Artificial Intelligent automated medical diet based cloud system can increase longevity, protect against further disease, and improve the overall quality of life. However, medical personnel are yet to fully understand patient-dietician's rationale of recommender system. This paper proposes a deep learning solution for health base medical dataset that automatically detects which food should be given to which patient base on the disease and other features like age, gender, weight, calories, protein, fat, sodium, fiber, cholesterol. This research framework is focused on implementing both machine and deep learning algorithms like, logistic regression, naive bayes, Recurrent Neural Network (RNN), Multilayer Perceptron (MLP), Gated Recurrent Units (GRU), and Long Short-Term Memory (LSTM). The medical dataset collected through the internet and hospitals consists of 30 patient's data with 13 features of different diseases and 1000 products. Product section has 8 features set. The features of these IoMT data were analyzed and further encoded before applying deep and machine and learning-based protocols. The performance of various machine learning and deep learning techniques was carried and the result proves that LSTM technique performs better than other scheme with respect to forecasting accuracy, recall, precision, and F1-measures. We achieved 97.74% accuracy using LSTM deep learning model. Similarly 98% precision, 99% recall and 99% F1-measure for allowed class is achieved, and for not-allowed class precision is 89%, recall score is 73% and F1 Measure score is 80%.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Celestine Iwendi et al.",
      "keywords": "Artificial intelligence; Machine learning; Computer science; Deep learning; Naive Bayes classifier; Multilayer perceptron; Artificial neural network; Recommender system; Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2968537",
      "cited_by_count": 218,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2982215737",
      "doi": "10.1109/access.2019.2948430",
      "title": "Explainable Prediction of Chronic Renal Disease in the Colombian Population Using Neural Networks and Case-Based Reasoning",
      "abstract": "This paper presents a neural network-based classifier to predict whether a person is at risk of developing chronic kidney disease (CKD). The model is trained with the demographic data and medical care information of two population groups: on the one hand, people diagnosed with CKD in Colombia during 2018, and on the other, a sample of people without a diagnosis of this disease. Once the model is trained and evaluation metrics for classification algorithms are applied, the model achieves 95 accuracy in the test data set, making its application for disease prognosis feasible. However, despite the demonstrated efficiency of the neural networks to predict CKD, this machine-learning paradigm is opaque to the expert regarding the explanation of the outcome. Current research on eXplainable AI proposes the use of twin systems, where a black-box machine-learning method is complemented by another white-box method that provides explanations about the predicted values. Case-Based Reasoning (CBR) has proved to be an ideal complement as this paradigm is able to find explanatory cases for an explanation-by-example justification of a neural networks prediction. In this paper, we apply and validate a NN-CBR twin system for the explanation of CKD predictions. As a result of this research, 3,494,516 people were identified as being at risk of developing CKD in Colombia, or 7 of the total population.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Gabriel R. V\u00e1squez-Morales et al.",
      "keywords": "Computer science; Artificial neural network; Artificial intelligence; Machine learning; Kidney disease; Population; Classifier (UML); Disease; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2948430",
      "cited_by_count": 138,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3115324092",
      "doi": "10.1109/access.2020.3047942",
      "title": "A Novel Wrapper\u2013Based Feature Selection for Early Diabetes Prediction Enhanced With a Metaheuristic",
      "abstract": "Diabetes leads to health problems for hundreds of millions of people globally every year. Available medical records of patients quantify symptoms, body features, and clinical laboratory test values, which can be used to perform biostatistics analysis aimed at finding patterns or features undetectable by current practice. In this work, we proposed a machine learning model to predict the early onset of diabetes patients. It is a novel wrapper-based feature selection utilizing Grey Wolf Optimization (GWO) and an Adaptive Particle Swam Optimization (APSO) to optimize the Multilayer Perceptron (MLP) to reduce the number of required input attributes. Moreover, we also compared the results achieved using this method and several conventional machine learning algorithms approaches such as Support Vector Machine (SVM), Decision Tree (DT), K-Nearest Neighbor (KNN), Nai&#x0308;ve Bayesian Classifier (NBC), Random Forest Classifier (RFC), Logistic Regression (LR). Computational results of our proposed method show not only that much fewer features are needed, but also higher prediction accuracy can be achieved (96% for GWO - MLP and 97% for APGWO - MLP). This work has the potential to be applicable to clinical practice and become a supporting tool for doctors/physicians.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Tuan Minh Le et al.",
      "keywords": "Computer science; Feature selection; Artificial intelligence; Random forest; Machine learning; Support vector machine; Naive Bayes classifier; Decision tree; Classifier (UML); Particle swarm optimization; Multilayer perceptron; Perceptron; Logistic regression; Data mining; Artificial neural network; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3047942",
      "cited_by_count": 145,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3082833877",
      "doi": "10.1109/trpms.2020.3020212",
      "title": "Photon Counting CT: Clinical Applications and Future Developments",
      "abstract": "The use of a photon counting detector in CT (PCD CT) is currently the subject of intense investigation and development. In this review article, we will describe potential clinical applications of this technology with a particular focus on the experience of our own institution with a prototype PCD CT scanner. PCDs have three primary advantages over conventional, energy integrating detectors (EIDs): they provide spectral information without need for a dedicated dual energy protocol; they are immune to electronic noise; and they can be made very high resolution without significant compromises to quantum efficiency. These advantages translate into several clinical applications. Metal artifacts, beam hardening artifacts, and noise streaks from photon starvation can be better mitigated using PCD CT. Certain incidental findings can be better characterized using the spectral information from PCD CT. High-contrast, high-resolution structures such as the temporal bone can be better visualized using PCD CT and at greatly reduced dose. We also discuss new possibilities on the horizon, including new contrast agents, and how anticipated improvements in PCD CT will translate to performance in these applications.",
      "year": "2020",
      "journal": "IEEE Transactions on Radiation and Plasma Medical Sciences",
      "authors": "Scott S. Hsieh et al.",
      "keywords": "Photon counting; Medical physics; Photon; Physics; Computer science; Optics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/trpms.2020.3020212",
      "cited_by_count": 158,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4316660992",
      "doi": "10.1109/access.2023.3237554",
      "title": "Distributed Anomaly Detection in Smart Grids: A Federated Learning-Based Approach",
      "abstract": "The smart grid integrates Information and Communication Technologies (ICT) into the traditional power grid to manage the generation, distribution, and consumption of electrical energy. Despite its many advantages, it faces significant challenges, such as detecting abnormal behaviours in the grid. Identifying anomalous behaviours helps to discover unusual user power consumption, faulty infrastructure, power outages, equipment failures, energy thefts, or cyberattacks. Machine learning (ML)-based techniques on smart meter data has shown remarkable results in anomaly detection. However, traditional ML-based anomaly detection requires smart meters to share local data with a central server, which raises concerns regarding data security and user privacy. Server-based model training faces additional challenges, such as the requirement of centralised computing power, reliable network communication, large bandwidth capacity, and latency issues, all of which affect the real-time anomaly detection performance. Motivated by these concerns, we propose a Federated Learning (FL)-based smart grid anomaly detection scheme where ML models are trained locally in smart meters without sharing data with a central server, thus ensuring user privacy. In the proposed approach, a global model is downloaded from the server to smart meters for on-device training. After local training, local model parameters are sent to the server to improve the global model. We secure the model parameter updates from adversaries using the SSL/TLS protocol. Using standard datasets, we investigate the anomaly detection performance of federated learning and observe that FL models achieve anomaly detection performance comparable to centralised ML models while ensuring user privacy. Further, our study shows that the proposed FL-based models perform efficiently in terms of memory, CPU usage, bandwidth and power consumption at edge devices and are suitable for implementation in resource-constrained environments, such as smart meters, for anomaly detection.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "J. Jithish et al.",
      "keywords": "Computer science; Anomaly detection; Smart grid; Smart meter; Data modeling; Computer network; Real-time computing; Data mining; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3237554",
      "cited_by_count": 173,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3044427673",
      "doi": "10.1109/access.2020.3010556",
      "title": "Intensive Care Unit Mortality Prediction: An Improved Patient-Specific Stacking Ensemble Model",
      "abstract": "The intensive care unit (ICU) admits the most seriously ill patients requiring extensive monitoring. Early ICU mortality prediction is crucial for identifying patients who are at great risk of dying and for providing suitable interventions to save their lives. Accordingly, early prediction of patients at high mortality risk will enable their provision of appropriate and timely medical services. Although various severity scores and machine-learning models have recently been developed for early mortality prediction, such prediction remains challenging. This paper proposes a novel stacking ensemble approach to predict the mortality of ICU patients. Our approach is more accurate and medically intuitive compared to the literature work. Data were prepared and feature selection was processed under the supervision of the ICU domain expert. The data were split into six modalities based on the expert's decisions. For the prediction process, a separate classifier was selected for each modality based on the performance of the classifiers. We utilized the most popular and diverse classifiers in the literature, including linear discriminant analysis, decision tree (DT), multilayer perceptron, k-nearest neighbor, and logistic regression (LR). Then, a stacking ensemble classifier was constructed and optimized based on the fusion of these five classifier decisions. The framework was evaluated using 10,664 patients from the medical information mart for intensive care (MIMIC III) benchmark dataset. To predict patient mortality, extensive experiments were conducted using the patients' time series data of different lengths. For each patient, the first 6, 12, and 24 hours of the first stay were tested. The results indicate that our model outperformed the state-of-the-art approaches in terms of accuracy (94.4%), F1 score (93.7%), precision (96.4%), recall (91.1%), and area under the receiver operator characteristic (ROC) curve (93.3%). These results demonstrate the ability and efficiency of our approach to predict ICU mortality.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Nora El-Rashidy et al.",
      "keywords": "Computer science; Stacking; Intensive care unit; Unit (ring theory); Artificial intelligence; Intensive care medicine; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3010556",
      "cited_by_count": 106,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3125218497",
      "doi": "10.1109/jbhi.2022.3148820",
      "title": "An Explainable Transformer-Based Deep Learning Model for the Prediction of Incident Heart Failure",
      "abstract": "Predicting the incidence of complex chronic conditions such as heart failure is challenging. Deep learning models applied to rich electronic health records may improve prediction but remain unexplainable hampering their wider use in medical practice. We aimed to develop a deep-learning framework for accurate and yet explainable prediction of 6-month incident heart failure (HF). Using 100,071 patients from longitudinal linked electronic health records across the U.K., we applied a novel Transformer-based risk model using all community and hospital diagnoses and medications contextualized within the age and calendar year for each patient's clinical encounter. Feature importance was investigated with an ablation analysis to compare model performance when alternatively removing features and by comparing the variability of temporal representations. A post-hoc perturbation technique was conducted to propagate the changes in the input to the outcome for feature contribution analyses. Our model achieved 0.93 area under the receiver operator curve and 0.69 area under the precision-recall curve on internal 5-fold cross validation and outperformed existing deep learning models. Ablation analysis indicated medication is important for predicting HF risk, calendar year is more important than chronological age, which was further reinforced by temporal variability analysis. Contribution analyses identified risk factors that are closely related to HF. Many of them were consistent with existing knowledge from clinical and epidemiological research but several new associations were revealed which had not been considered in expert-driven risk prediction models. In conclusion, the results highlight that our deep learning model, in addition high predictive performance, can inform data-driven risk factor identification.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Shishir Rao et al.",
      "keywords": "Artificial intelligence; Medical diagnosis; Machine learning; Deep learning; Computer science; Health records; Receiver operating characteristic; Predictive modelling; Transformer; Recall; Medicine; Health care; Engineering; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3148820",
      "cited_by_count": 120,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3119269115",
      "doi": "10.1109/access.2021.3049325",
      "title": "A Novel Blockchain-Based Integrity and Reliable Veterinary Clinic Information Management System Using Predictive Analytics for Provisioning of Quality Health Services",
      "abstract": "The recent advances in information management systems coupled with machine learning algorithms paved the way for a significant revolution in animal healthcare industries. However, the data in such systems suffer from various challenges such as security, reliability, and convenience, to name a few. Traditional systems are not useful to meet these critical issues because these systems have not a consistent structure for data security and reliability policies. Therefore, a new solution is required to enhance data accessibility and should regulate government security policies to ensure the accountability of the usage of the medical records system. Moreover, it is also required to analyze historical data of veterinary clinic using data mining and machine learning techniques to predict the future appointments scheduling requests, which is essential for veterinary management to drive better future decisions, for instance, future demands of medical supplies and to plan veterinary medical staff, etc. This paper aims to fill the gap by proposing a novel blockchain-based reliable and intelligent veterinary information management system (RIVIMS) using smart contract and machine learning techniques. The proposed RIVIMS consists of two main modules; blockchain-based secured veterinary information management, data and predictive analytics modules. First, a blockchain-based secure and reliable veterinary clinic information management system is developed using Hyperledger Fabric. Second, a smart contract enabled data, and predictive analytics modules are developed using permissioned blockchain framework. The data and predictive modules aim to analyze veterinary clinic patients appointments data in order to discover underlying patterns and build a robust prediction model using machine learning algorithms. The data and predictive helps veterinary management to drive better future business decisions to provide better healthcare services to veterinary patients. Hyperledger Caliper is used as a benchmark tool to evaluate the performance of the developed blockchain-based system in terms of transaction per second, transaction success rate, transaction throughput, and transaction latency. Furthermore, machine learning performance measures have utilized, such as MAE, RMSE, and R2 score to evaluate the overall performance of the prediction model. The experimental results demonstrate the effectiveness and robustness of the proposed RIVIMS.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Naeem Iqbal et al.",
      "keywords": "Blockchain; Provisioning; Quality (philosophy); Computer science; Data integrity; Analytics; Computer security; Business; Data science; Computer network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3049325",
      "cited_by_count": 115,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2962459300",
      "doi": "10.1109/jsen.2019.2928777",
      "title": "Deep Learning for Monitoring of Human Gait: A Review",
      "abstract": "The essential human gait parameters are briefly reviewed, followed by a detailed review of the state-of-the-art in deep learning for human gait analysis. The modalities for capturing gait data are grouped according to the sensing technology: video sequences, wearable sensors and floor sensors, as well as the publicly available datasets. The established Artificial Neural Network architectures for deep learning are reviewed for each group, and their performance compared, with particular emphasis on the spatiotemporal character of gait data and the motivation for multi-sensor, multi-modality fusion. It is shown that, by most of the essential metrics, deep learning Convolutional Neural Networks typically outperform shallow learning models. In the light of the discussed character of gait data, this is attributed to the possibility to extract the gait features automatically in Deep Learning, as opposed to shallow learning from handcrafted gait features.",
      "year": "2019",
      "journal": "IEEE Sensors Journal",
      "authors": "Abdullah Alharthi et al.",
      "keywords": "Deep learning; Artificial intelligence; Gait; Computer science; Convolutional neural network; Modality (human\u2013computer interaction); Modalities; Machine learning; Wearable computer; Artificial neural network; Sensor fusion; Gait analysis; Physical medicine and rehabilitation",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jsen.2019.2928777",
      "cited_by_count": 162,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4220840763",
      "doi": "10.1109/jproc.2022.3149785",
      "title": "Wearable Photoplethysmography for Cardiovascular Monitoring",
      "abstract": "Smart wearables provide an opportunity to monitor health in daily life and are emerging as potential tools for detecting cardiovascular disease (CVD). Wearables such as fitness bands and smartwatches routinely monitor the photoplethysmogram signal, an optical measure of the arterial pulse wave that is strongly influenced by the heart and blood vessels. In this survey, we summarize the fundamentals of wearable photoplethysmography and its analysis, identify its potential clinical applications, and outline pressing directions for future research in order to realize its full potential for tackling CVD.",
      "year": "2022",
      "journal": "Proceedings of the IEEE",
      "authors": "Peter H. Charlton et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2022.3149785",
      "cited_by_count": 147,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3202722194",
      "doi": "10.1109/jbhi.2021.3117575",
      "title": "Tufts Dental Database: A Multimodal Panoramic X-Ray Dataset for Benchmarking Diagnostic Systems",
      "abstract": "The application of Artificial Intelligence in dental healthcare has a very promising role due to the abundance of imagery and non-imagery-based clinical data. Expert analysis of dental radiographs can provide crucial information for clinical diagnosis and treatment. In recent years, Convolutional Neural Networks have achieved the highest accuracy in various benchmarks, including analyzing dental X-ray images to improve clinical care quality. The Tufts Dental Database, a new X-ray panoramic radiography image dataset, has been presented in this paper. This dataset consists of 1000 panoramic dental radiography images with expert labeling of abnormalities and teeth. The classification of radiography images was performed based on five different levels: anatomical location, peripheral characteristics, radiodensity, effects on the surrounding structure, and the abnormality category. This first-of-its-kind multimodal dataset also includes the radiologist's expertise captured in the form of eye-tracking and think-aloud protocol. The contributions of this work are 1) publicly available dataset that can help researchers to incorporate human expertise into AI and achieve more robust and accurate abnormality detection; 2) a benchmark performance analysis for various state-of-the-art systems for dental radiograph image enhancement and image segmentation using deep learning; 3) an in-depth review of various panoramic dental image datasets, along with segmentation and detection systems. The release of this dataset aims to propel the development of AI-powered automated abnormality detection and classification in dental panoramic radiographs, enhance tooth segmentation algorithms, and the ability to distill the radiologist's expertise into AI.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Karen Panetta et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Radiography; Segmentation; Medical imaging; Deep learning; Panoramic radiograph; Computer vision; Benchmark (surveying); Abnormality; Pattern recognition (psychology); Medicine; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3117575",
      "cited_by_count": 142,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3001215021",
      "doi": "10.1109/access.2020.2968900",
      "title": "Machine Learning and End-to-End Deep Learning for the Detection of Chronic Heart Failure From Heart Sounds",
      "abstract": "Chronic heart failure (CHF) affects over 26 million of people worldwide, and its incidence is increasing by 2% annually. Despite the significant burden that CHF poses and despite the ubiquity of sensors in our lives, methods for automatically detecting CHF are surprisingly scarce, even in the research community. We present a method for CHF detection based on heart sounds. The method combines classic Machine-Learning (ML) and end-to-end Deep Learning (DL). The classic ML learns from expert features, and the DL learns from a spectro-temporal representation of the signal. The method was evaluated on recordings from 947 subjects from six publicly available datasets and one CHF dataset that was collected for this study. Using the same evaluation method as a recent PhysoNet challenge, the proposed method achieved a score of 89.3, which is 9.1 higher than the challenge's baseline method. The method's aggregated accuracy is 92.9% (error of 7.1%); while the experimental results are not directly comparable, this error rate is relatively close to the percentage of recordings labeled as &#x201C;unknown&#x201D; by experts (9.7%). Finally, we identified 15 expert features that are useful for building ML models to differentiate between CHF phases (i.e., in the decompensated phase during hospitalization and in the recompensated phase) with an accuracy of 93.2%. The proposed method shows promising results both for the distinction of recordings between healthy subjects and patients and for the detection of different CHF phases. This may lead to the easier identification of new CHF patients and the development of home-based CHF monitors for avoiding hospitalizations.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Martin Gjoreski et al.",
      "keywords": "End-to-end principle; Computer science; Heart failure; Artificial intelligence; Speech recognition; Cardiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2968900",
      "cited_by_count": 140,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3011706185",
      "doi": "10.1109/access.2020.2981159",
      "title": "Recursion Enhanced Random Forest With an Improved Linear Model (RERF-ILM) for Heart Disease Detection on the Internet of Medical Things Platform",
      "abstract": "Nowadays, Heart disease is one of the crucial impacts of mortality in the country. In clinical data analysis, predicting cardiovascular disease is a primary challenge. Deep learning (DL) has been demonstrated to be effective in helping to determine and forecast a huge amount of data produced by the health industry. In this paper, the proposed Recursion enhanced random forest with an improved linear model (RFRF-ILM) to detect heart disease. This paper aims to find the key features of the prediction of cardiovascular diseases through the use of machine learning techniques. The prediction model is adding various combinations of features and various established methods of classification. it produces a better level of performance with precision through the heart disease prediction model. In this study, the factors leading to cardiovascular disease can be diagnosed. A comparison of important variables showed with the Internet of Medical Things (IoMT) platform, for data analysis. This indicates that coronary artery disease develops more often in older ages. Also important in this disease's outbreak is high blood pressure. For this purpose, measures must be taken to prevent this disease and Diabetes provides a further aspect that should be taken into consideration in the occurrence of coronary artery disease with 96.6 % accuracy,96.8% stability ratio and 96.7% F-measure ratio.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Chunyan Guo et al.",
      "keywords": "Random forest; Computer science; Disease; Coronary artery disease; Diabetes mellitus; The Internet; Heart disease; Key (lock); Machine learning; Artificial intelligence; Internal medicine; Medicine; Computer security; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2981159",
      "cited_by_count": 116,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3186028265",
      "doi": "10.1109/thms.2021.3092684",
      "title": "Cobots in Industry 4.0: A Roadmap for Future Practice Studies on Human\u2013Robot Collaboration",
      "abstract": "With the vision of Industry 4.0 and cobots, working conditions in industrial settings are starting to change. We review related literature from the fields of human-robot interaction, work and organizational psychology, and sociology of work, as well as an exemplary project case study, and identify research gaps regarding the implications of cobots for work environments. We argue that we are in a transition phase from automation to actual collaboration with robots in manufacturing, and that this will open up a new problem space for investigations, in which a practice lens will be crucial. Based on this, we propose a research agenda for social practice and workplace studies to explore the sociotechnical environment of Industry 4.0 involving cobots at the individual, team, and organizational levels.",
      "year": "2021",
      "journal": "IEEE Transactions on Human-Machine Systems",
      "authors": "Astrid Weiss et al.",
      "keywords": "Sociotechnical system; Robot; Industrial and organizational psychology; Work (physics); Knowledge management; Automation; Human\u2013robot interaction; Industrial sociology; Sociology; Engineering; Management; Psychology; Computer science; Artificial intelligence; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/thms.2021.3092684",
      "cited_by_count": 203,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2906027675",
      "doi": "10.1109/access.2018.2884249",
      "title": "Metabolic Syndrome and Development of Diabetes Mellitus: Predictive Modeling Based on Machine Learning Techniques",
      "abstract": "The objective of this inductive research was to investigate: 1) the relationship between diabetes mellitus and individual risk factors of metabolic syndrome (MetS), in a non-conservative setting; 2) the prediction of future onset of diabetes using relevant risk factors of MetS; and 3) to investigate the relative performance of machine learning methods when data sampling techniques are used to generate balanced training sets. The dataset used in this research contains 667 907 records for a period ranging from 2003 to 2013. Quantifying the contribution of individual risk factors of MetS in the development of diabetes in a non-conservative setting logistic regression analysis was performed. Our analyses contradict the view that diabetes is commonly associated with low levels of high-density lipoprotein (HDL). Instead, our results demonstrate that the increased levels of HDL are positively correlated with diabetes onset, particularly in women. We also proposed J48 decision tree and Na&#x00EF;ve Bayes methods for prediction of future onset of diabetes using relevant risk factors obtained from logistic regression analysis, over balanced and unbalanced datasets. The results demonstrated the supremacy of Na&#x00EF;ve Bayes with K-medoids under-sampling technique as compared to random under-sampling, oversampling, and no sampling. It is achieved on average 79&#x0025; receiver operating characteristic performance with the increased true positive rate. The results of this paper suggest further research to clarify the pathophysiological significance of HDL and pathways in the development of diabetes.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Sajida Perveen et al.",
      "keywords": "Logistic regression; Diabetes mellitus; Naive Bayes classifier; Decision tree; Machine learning; Metabolic syndrome; Random forest; C4.5 algorithm; Artificial intelligence; Medicine; Oversampling; Computer science; Bayes' theorem; Sampling (signal processing); Statistics; Internal medicine; Mathematics; Endocrinology; Support vector machine; Bayesian probability; Filter (signal processing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2884249",
      "cited_by_count": 88,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377294226",
      "doi": "10.1109/access.2023.3278273",
      "title": "Automated Stroke Prediction Using Machine Learning: An Explainable and Exploratory Study With a Web Application for Early Intervention",
      "abstract": "Stroke is a dangerous medical disorder that occurs when blood flow to the brain is disrupted, resulting in neurological impairment. It is a big worldwide threat with serious health and economic implications. To solve this, researchers are developing automated stroke prediction algorithms, which would allow for early intervention and perhaps save lives. The number of people at risk for stroke is growing as the population ages, making precise and effective prediction systems increasingly critical. wo In a comparison examination with six well-known classifiers, the effectiveness of the proposed ML technique was explored in terms of metrics relating to both generalization capability and prediction accuracy. To give insight into the black-box machine learning models, we also studied two kinds of explainable techniques, namely SHAP and LIME, in this study. SHAP (Shapley Additive Explanations) and LIME (Local Interpretable Model-agnostic Explanations) are well-established and reliable approaches for explaining model decision-making, particularly in the medical industry. The findings of the experiment revealed that more complicated models outperformed simpler ones, with the top model obtaining almost 91&#x0025; accuracy and the other models achieving 83-91&#x0025; accuracy. The proposed framework, which includes global and local explainable methodologies, can aid in standardizing complicated models and gaining insight into their decision-making, which can enhance stroke care and treatment.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Krishna Mridha et al.",
      "keywords": "Computer science; Intervention (counseling); Machine learning; Artificial intelligence; Stroke (engine); Exploratory research; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3278273",
      "cited_by_count": 83,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3111112601",
      "doi": "10.1109/access.2020.3043221",
      "title": "Ensembling Classical Machine Learning and Deep Learning Approaches for Morbidity Identification From Clinical Notes",
      "abstract": "The past decade has seen an explosion of the amount of digital information generated within the healthcare domain. Digital data exist in the form of images, video, speech, transcripts, electronic health records, clinical records, and free-text. Analysis and interpretation of healthcare data is a daunting task, and it demands a great deal of time, resources, and human effort. In this paper, we focus on the problem of co-morbidity recognition from patient\u2019s clinical records. To this aim, we employ both classical machine learning and deep learning approaches.We use word embeddings and bag-of-words representations, coupled with feature selection techniques. The goal of our work is to develop a classification system to identify whether a certain health condition occurs for a patient by studying his/her past clinical records. In more detail, we have used pre-trained word2vec, domain-trained, GloVe, fastText, and universal sentence encoder embeddings to tackle the classification of sixteen morbidity conditions within clinical records. We have compared the outcomes of classical machine learning and deep learning approaches with the employed feature representation methods and feature selection methods. We present a comprehensive discussion of the performances and behaviour of the employed classical machine learning and deep learning approaches. Finally, we have also used ensemble learning techniques over a large number of combinations of classifiers to improve the single model performance. For our experiments, we used the n2c2 natural language processing research dataset, released by Harvard Medical School. The dataset is in the form of clinical notes that contain patient discharge summaries. Given the unbalancedness of the data and their small size, the experimental results indicate the advantage of the ensemble learning technique with respect to single classifier models. In particular, the ensemble learning technique has slightly improved the performances of single classification models but has greatly reduced the variance of predictions stabilizing the accuracies (i.e., the lower standard deviation in comparison with single classifiers). In real-life scenarios, our work can be employed to identify with high accuracy morbidity conditions of patients by feeding our tool with their current clinical notes. Moreover, other domains where classification is a common problem might benefit from our approach as well.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Vivek Kumar et al.",
      "keywords": "Artificial intelligence; Computer science; Machine learning; Deep learning; Feature selection; Word2vec; Identification (biology); Feature learning; Feature engineering; Sentence; Feature (linguistics); Multi-task learning; Domain (mathematical analysis); Natural language processing; Task (project management)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3043221",
      "cited_by_count": 91,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3197552172",
      "doi": "10.1109/access.2021.3109806",
      "title": "Big-ECG: Cardiographic Predictive Cyber-Physical System for Stroke Management",
      "abstract": "Electrocardiogram (ECG) is sensitive to autonomic dysfunction and cardiac complications derived from ischemic or hemorrhage stroke and is supposed to be a potential prognostic tool in stroke identification and post-stroke treatment. ECG data generated cannot be real-time accumulated, processed, and used for enterprise-level healthcare and wellness services with the existing cardiovascular monitoring system used in hospitals. This study aims to assess the feasibility of a cyber-physical cardiac monitoring system to classify stroke patients with altered cardiac activity and healthy adults. Here, we propose Big-ECG, a cyber-physical cardiac monitoring system for stroke management, consisting of a wearable ECG sensor, data storage and data analysis in a big data platform, and health advisory services using data analytics and medical ontology. We investigated our proposed ECG-based patient monitoring system with 45 stroke patients (average age 70.8 years old, 68&#x0025; men) admitted to the rehabilitation center of the hospital and 40 healthy elderly volunteers (average age 75.4 years old, 38&#x0025; men). We recorded ECG at resting state using a single-channel ECG patch within three months of diagnosis of ischemic stroke (clinically confirmed). In statistical results, ECG fiducial features, RR-I, QRS, QT, ST, and heart rate variability (HRV) features, SDSD, LF/HF, LF/(LF &#x002B; HF), and HF/(LF &#x002B; HF) are observed as significantly distinctive biomarkers for the stroke group relative to the healthy control group. The Random Trees model presented the best classification performance (overall accuracy: 95.6&#x0025;) utilizing ECG fiducial variables. This system may assist healthcare enterprises in prognosis and rehabilitation management during post-stroke treatment.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Iqram Hussain et al.",
      "keywords": "Medicine; Stroke (engine); Electrocardiography; Internal medicine; Cardiology; QRS complex; Medical emergency; Physical therapy; Physical medicine and rehabilitation",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3109806",
      "cited_by_count": 96,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3021058087",
      "doi": "10.1109/access.2020.2992869",
      "title": "Predicting Students\u2019 Performance With School and Family Tutoring Using Generative Adversarial Network-Based Deep Support Vector Machine",
      "abstract": "It has been witnessed that supportive learning has played a crucial role in educational quality enhancement. School and family tutoring offer personalized help and provide positive feedback on students' learning. Predicting students' performance is of much interest which reflects their understanding on the subjects. Particularly it is desired students to manage well in fundamental knowledge in order to build a strong foundation for post-secondary studies and career. In this paper, improved conditional generative adversarial network based deep support vector machine (ICGAN-DSVM) algorithm has been proposed to predict students' performance under supportive learning via school and family tutoring. Owning to the nature of the students' academic dataset is generally low sample size. ICGAN-DSVM offers dual benefits for the nature of low sample size in students' academic dataset in which ICGAN increases the data volume whereas DSVM enhances the prediction accuracy with deep learning architecture. Results with 10-fold cross-validation show that the proposed ICGAN-DSVM yields specificity, sensitivity and area under the receiver operating characteristic curve (AUC) of 0.968, 0.971 and 0.954 respectively. Results also suggest that incorporating both school and family tutoring into the prediction model could further improve the performance compared with only school tutoring and only family tutoring. To show the necessity of ICGAN and DSVM, comparison has been made between ICGAN and traditional conditional generative adversarial network (CGAN). Also, the proposed kernel design via heuristic based multiple kernel learning (MKL) is compared with typical kernels including linear, radial basis function (RBF), polynomial and sigmoid. The prediction of student's performance with and without GAN is presented which is followed by comparison with DSVM and with traditional SVM. The proposed ICGAN-DSVM outperforms related works by 8-29% in terms of performance indicators specificity, sensitivity and AUC.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Kwok Tai Chui et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Support vector machine; Generative grammar; Sample (material); Kernel (algebra); Heuristic; Deep learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2992869",
      "cited_by_count": 112,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285123209",
      "doi": "10.1109/access.2022.3175317",
      "title": "A Novel Time-Aware Food Recommender-System Based on Deep Learning and Graph Clustering",
      "abstract": "Food recommender-systems are considered an effective tool to help users adjust their eating habits and achieve a healthier diet. This paper aims to develop a new hybrid food recommender-system to overcome the shortcomings of previous systems, such as ignoring food ingredients, time factor, cold start users, cold start food items and community aspects. The proposed method involves two phases: food content-based recommendation and user-based recommendation. Graph clustering is used in the first phase, and a deep-learning based approach is used in the second phase to cluster both users and food items. Besides a holistic-like approach is employed to account for time and user-community related issues in a way that improves the quality of the recommendation provided to the user. We compared our model with a set of state-of-the-art recommender-systems using five distinct performance metrics: Precision, Recall, F1, AUC and NDCG. Experiments using dataset extracted from &#x201C;Allrecipes.com&#x201D; demonstrated that the developed food recommender-system performed best.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mehrdad Rostami et al.",
      "keywords": "Recommender system; Computer science; Cluster analysis; Cold start (automotive); Graph; Learning to rank; Set (abstract data type); Precision and recall; Deep learning; Machine learning; Information retrieval; Artificial intelligence; Data mining; Ranking (information retrieval)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3175317",
      "cited_by_count": 131,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380684657",
      "doi": "10.1109/access.2023.3286344",
      "title": "Crime Prediction Using Machine Learning and Deep Learning: A Systematic Review and Future Directions",
      "abstract": "Predicting crime using machine learning and deep learning techniques has gained considerable attention from researchers in recent years, focusing on identifying patterns and trends in crime occurrences. This review paper examines over 150 articles to explore the various machine learning and deep learning algorithms applied to predict crime. The study provides access to the datasets used for crime prediction by researchers and analyzes prominent approaches applied in machine learning and deep learning algorithms to predict crime, offering insights into different trends and factors related to criminal activities. Additionally, the paper highlights potential gaps and future directions that can enhance the accuracy of crime prediction. Finally, the comprehensive overview of research discussed in this paper on crime prediction using machine learning and deep learning approaches serves as a valuable reference for researchers in this field. By gaining a deeper understanding of crime prediction techniques, law enforcement agencies can develop strategies to prevent and respond to criminal activities more effectively",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Varun Mandalapu et al.",
      "keywords": "Machine learning; Artificial intelligence; Computer science; Law enforcement; Deep learning; Field (mathematics); Crime analysis; Data science; Criminology; Political science; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3286344",
      "cited_by_count": 133,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3096211615",
      "doi": "10.1109/access.2020.3035327",
      "title": "Machine Learning in the Prevention, Diagnosis and Management of Diabetic Foot Ulcers: A Systematic Review",
      "abstract": "Diabetic foot ulcers (DFUs) are a serious complication for people with diabetes. They result in increased morbidity and pressures on health system resources. Developments in machine learning (ML) offer an opportunity for improved care of individuals at risk of DFUs, to identify and synthesise evidence about the current uses and accuracy of ML in the interventional care and management of DFUs, and, to provide a reference for areas of future research. PubMed, Google Scholar, Web of Science and Scopus were searched using the Preferred Reporting Items for a Systematic Review and Meta-analysis of Diagnostic Test Accuracy Studies (PRISMA-DTA) guidelines for papers involving ML and DFUs. In order to be included, studies needed to mention ML, DFUs, and report relevant outcome measures regarding ML algorithm accuracy. Bias in included studies was assessed using the quality assessment tool for diagnostic accuracy (QUADAS-2). 37 out of 3769 papers were included after applying eligibility criteria. Included papers reported accuracy measures for multiple types of ML algorithms in DFU studies. Whilst varying across the ML algorithm used, all studies reported at least 90% accuracy compared to gold standards using a minimum of one reported ML algorithm for processing or recording data. Applications where ML had positive effects on DFU data analysis and outcomes include image segmentation and classification, raw data analysis and risk assessment. ML offers an effective and accurate solution to guide analysis and procurement of data from interventions which are designed for the care of DFUs in small samples and study conditions. Current research is limited, and, for the development of more applicable ML algorithms, future research should address the following: direct comparison of ML applications with current standards of care, health economic analyses and large scale data collection. There is currently no evidence to confidently suggest that ML methods in DFU diagnosis are ready for implementation and use in healthcare settings.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jack Tulloch et al.",
      "keywords": "Medicine; Diabetic foot; Scopus; Psychological intervention; MEDLINE; Systematic review; Meta-analysis; Gold standard (test); Artificial intelligence; Computer science; Diabetes mellitus; Internal medicine; Nursing",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3035327",
      "cited_by_count": 79,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226239514",
      "doi": "10.1109/access.2022.3160841",
      "title": "Systematic Review of Using Machine Learning in Imputing Missing Values",
      "abstract": "Missing data are a universal data quality problem in many domains, leading to misleading analysis and inaccurate decisions. Much research has been done to investigate the different mechanisms of missing data and the proper techniques in handling various data types. In the last decade, machine learning has been utilized to replace conventional methods to address the problem of missing values more efficiently. By studying and analyzing recently proposed methods using machine learning approaches, vital adoptions in accuracy, performance, and time consumed can be highlighted. This study aimed to help data analysts and researchers address the limitations of machine learning imputation methods by conducting a systematic literature review to provide a comprehensive overview of using such methods to impute missing values. Novel proposed machine learning approaches used for data imputation are analyzed and summarized to assist researchers in selecting a proper machine learning method based on several factors and settings. The review was performed on research studies published between 2016 and 2021 on adopting machine learning to impute missing values, focusing on their strengths and limitations. A total of 684 research articles from various scientific databases were analyzed using search engines, and 94 of them were selected as primary studies. Finally, several recommendations were given to guide future researchers in applying machine learning to impute missing values.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mustafa Alabadla et al.",
      "keywords": "Missing data; Imputation (statistics); Computer science; Machine learning; Artificial intelligence; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3160841",
      "cited_by_count": 83,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3097973207",
      "doi": "10.1109/access.2020.3034324",
      "title": "Cyber Resilience in Healthcare Digital Twin on Lung Cancer",
      "abstract": "As a key service of the future 6G network, healthcare digital twin is the virtual replica of a person, which employs Internet of Things (IoT) technologies and AI-powered models to predict the state of health and provide suggestions to a range of clinical questions. To support healthcare digital twins, the right cyber resilience technologies and policies must be applied and maintained to preserve cyber resilience. Vulnerability detection is a fundamental technology for cyber resilience in healthcare digital twins. Recently, deep learning (DL) has been applied to address the limitations of traditional machine learning in vulnerability detection. However, it is important to consider code context relationships and pay attention on the vulnerability related keywords for searching an IoT vulnerability in healthcare digital twins. Due to massive software and complexity of healthcare digital twin, a full automatic solution is really needed for assisting cyber resilience check in the real-world scenarios. This article presents a novel scheme for recognising potential vulnerable functions to support healthcare digital twins. We develop a new deep neural model to capture bi-directional context relationships among the risky code keywords. A number of well-designed experiments are carried out on a large ground truth, which consists of tens of thousands of vulnerable and non-vulnerable functions from IoT related software. The results show our new scheme outperforms the state-of-the-art DL-based methods for vulnerability detection.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jun Zhang et al.",
      "keywords": "Computer science; Vulnerability (computing); Resilience (materials science); Context (archaeology); Health care; Computer security; Artificial intelligence; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3034324",
      "cited_by_count": 116,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2952667803",
      "doi": "10.1109/access.2019.2923736",
      "title": "Visual Analytics: A Comprehensive Overview",
      "abstract": "With the ever-increasing amount of data, the world has stepped into the era of &#x201C;Big Data&#x201D;. Presently, the analysis of massive and complex data and the extraction of relevant information, have been become essential tasks in many fields of studies, such as health, biology, chemistry, social science, astronomy, and physics. However, compared with the development of data storage and management technologies, our ability to gain useful information from the collected data does not match our ability to collect the data. This gap has led to a surge of research activity in the field of visual analytics. Visual analytics employs interactive visualization to integrate human judgment into algorithmic data-analysis processes. In this paper, the aim is to draw a complete picture of visual analytics to direct future research by examining the related research in various application domains. As such, a novel categorization of visual-analytics applications from a technical perspective is proposed, which is based on the dimensionality of visualization and the type of interaction. Based on this categorization, a comprehensive survey of visual analytics is performed, which examines its evolution from visualization and algorithmic data analysis, and investigates how it is applied in various application domains. In addition, based on the observations and findings gained in this survey, the trends, major challenges, and future directions of visual analytics are discussed.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Wenqiang Cui",
      "keywords": "Visual analytics; Computer science; Analytics; Data science; Visualization; Cultural analytics; Data visualization; Human\u2013computer interaction; Artificial intelligence; World Wide Web; Semantic analytics; The Internet",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2923736",
      "cited_by_count": 125,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3027026487",
      "doi": "10.1109/access.2020.2995310",
      "title": "Prediction of Chronic Kidney Disease Using Adaptive Hybridized Deep Convolutional Neural Network on the Internet of Medical Things Platform",
      "abstract": "Chronic Kidney disease is a severe lifelong condition caused either by renal disease or by impaired functions of the kidneys. In the present area of research, Kidney cancer is one of the deadliest and crucial importance for the survival of the patients ' diagnosis and classification. Early diagnosis and proper therapy can stop or delay the development of this chronic disease into the final stage where dialysis or renal transplantation is the only way of saving the life of the patient. The development of automated tools to accurately identify subtypes of kidney cancer is, therefore, an urgent challenge in the recent past. In this paper, to examine the ability of various deep learning methods an Adaptive hybridized Deep Convolutional Neural Network (AHDCNN) has been proposed for the early detection of Kidney disease efficiently and effectively. Classification technology efficiency depends on the role of the data set. To enhance the accuracy of the classification system by reducing the feature dimension an algorithm model has been developed using CNN. These high-level properties help to build a supervised tissue classifier that discriminates between the two types of tissue. The experimental process on the Internet of medical things platform (IoMT)concludes, with the aid of predictive analytics, that advances in machine learning which provides a promising framework for the recognition of intelligent solutions to prove their predictive capability beyond the field of kidney disease.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Guozhen Chen et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Kidney disease; Machine learning; Classifier (UML); Deep learning; Predictive analytics; Artificial neural network; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2995310",
      "cited_by_count": 99,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3107142181",
      "doi": "10.1109/access.2020.3040240",
      "title": "Block Chain Based Internet of Medical Things for Uninterrupted, Ubiquitous, User-Friendly, Unflappable, Unblemished, Unlimited Health Care Services (BC IoMT U<sup>6</sup> HCS)",
      "abstract": "The most burning topic of today, calls for a holistic solution that is reliable, secure, privacy preserved, cost effective Cloud storage that can tide over the turbulent conditions of the rapidly budding digital storage technologies. This send an outcry for a devoted solution, in the form of an individualized, patient-centric care - IoMT that augments precise disease identifications, decrease in errors, reduction in costs of care through the support of technology, allows patients to direct health information data to doctors,manage drugs, keep Personal Health Records, caters to remote medical supports Care, provides proactive approach to preserving Good Health, improves and Accelerates Clinician Workflows, empowers extreme connectivity due to better automation and perceptions in the DNA of IoMT functions. But IoMT adoption is like a rose with thorns like constraints of increased administrative costs, deficiency of universal data access, present-day electronic medical records. The BCT is used in the framework to overcome the security issues of IoMT through the use of latest encryptions. Furthermore, this framework harnesses the benefits of Block Chain like reduced cost, speed, automation, immutability, near-impossible loss of data, permanence, removal of intermediaries, decentralization of consensus, legitimate access to health data, data safekeeping, accrual-based imbursement mechanisms, and medical supply chain efficacy. The outcomes in this paper are (i)A systematic investigation of the current IoMT, Block Chain and Cloud Storage in Health Care;(ii) Explore the challenges and necessities for the confluence of Block Chain (BC), Internet of Medical Things (IoMT), Cloud Computing (CC);(iii)Formulate the requirements necessary for the real-time remote Health Care of one-to-one care structure, which, supports the vital functions that are critical to the Patient Centric Health Care;(iv) Design and develop a novel BC IoMT U6 HCS (Block Chain based Internet of Medical Things for Uninterrupted, Ubiquitous, User-friendly, Unflappable, Unblemished, Unlimited Health Care Services) Layered Architecture, to support the vital functions critical for Patient Centric Health Care and (v) Implement and test with the previous established and proven techniques. The integrity of the Layered Architecture is validated with the already existing ones in terms of audit performances. The results from the Layered Architecture are validated and are proven to be competent in achieving safe auditing and surpass the former ones. The technology is in the sprouting phases, it is perilous that affiliates of the Health Care community realize the rudimentary ideas behind Block Chain, and detect its feasible impact on the future of patient centric medical care. Finally, and most importantly, this paper also gives a panoramic view on the current research status, and imminent directions of Secure Internet of Medical Things Using Block Chain.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "J. Indumathi et al.",
      "keywords": "Cloud computing; Computer science; The Internet; Internet privacy; Computer security; Health care; Block (permutation group theory); World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3040240",
      "cited_by_count": 95,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4322707202",
      "doi": "10.1109/access.2023.3247196",
      "title": "Terahertz Imaging and Sensing for Healthcare: Current Status and Future Perspectives",
      "abstract": "There is a keen interest in the exploration of new generation emitters and detectors due to advancements in innovation of new materials and device processing technologies which have opened up new frontiers in the Terahertz (THz) spectrum. Therefore, it is necessary to review the developments in THz technology for healthcare applications, their impact, implications and prospects for ongoing research and development. This paper provides a broad overview of the current status and prospects of application of THz imaging and sensing for the healthcare domain. We present current knowledge, identify existing challenges for wide scale clinical adoption of THz systems and prospective opinions to facilitate research and development towards optimized and miniaturized THz systems and biosensors that provide real operational convenience through emerging trends. Firstly, we provide an overview of the THz imaging and sensing techniques that exploit properties of THz generation and detection with emphasis on terahertz time domain spectroscopy (THz-TDS) and THz Metamaterials. The mechanisms of tissue image contrast and the application of THz imaging and sensing for biomedical applications in particular, the cancer detection application is reported. Secondly, an outlook toward the advancements in THz technology in the interface of healthcare 4.0 and its enabling technologies is explored for next generation smart and connected healthcare systems. Third, we identify the merits and existing challenges in THz cancer imaging and sensing and suggest prospective opinions to pave way to ongoing and future research. Further, we discuss the recent advances in THz imaging development and the contribution of near-field techniques based on plasmonic, and resonance based metasurfaces, waveguides etc. for breaking the diffraction limit towards development of THz systems that are convenient for point of care. We bring researchers a roadmap for future research scope.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mavis Gezimati et al.",
      "keywords": "Terahertz radiation; Computer science; Exploit; Systems engineering; Health care; Emerging technologies; Nanotechnology; Data science; Materials science; Artificial intelligence; Engineering; Optoelectronics; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3247196",
      "cited_by_count": 119,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W1997876555",
      "doi": "10.1109/mcg.2006.44",
      "title": "NIH-NSF visualization research challenges report summary",
      "abstract": "The US National Science Foundation (NSF) convened a panel to report on the potential of visualization as a new technology. The NSF and US National Institutes of Health (NIH) convened the Visualization Research Challenges (VRC) Executive Committee to write a new report. Here, we summarize that new VRC report. We explore the state of the field, examine the potential impact of visualization on areas of national and international importance, and present our findings and recommendations for the future of our growing discipline. Our audience is twofold: the supporters, sponsors, and application users of visualization research on the one hand, and researchers and practitioners in visualization on the other. We direct our discussion toward solving key problems of national interest and helping this work's sponsors to concentrate resources to the greatest effect. Our findings and recommendations reflect information gathered from visualization and applications scientists during two workshops on VRC, as well as input from the larger visualization community.",
      "year": "2006",
      "journal": "IEEE Computer Graphics and Applications",
      "authors": "Tamara Munzner et al.",
      "keywords": "Visualization; Computer science; Data science; Data visualization; Information visualization; Panel discussion; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mcg.2006.44",
      "cited_by_count": 142,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3181131554",
      "doi": "10.1109/access.2021.3095312",
      "title": "Healthcare Techniques Through Deep Learning: Issues, Challenges and Opportunities",
      "abstract": "In artificial intelligence, deep learning (DL) is a process that replicates the working mechanism of the human brain in data processing, and it also creates patterns for decision making. Deep learning or neural networks have been deployed in several fields, such as computer vision, natural language processing, and speech recognition. It has been used in many healthcare applications for the diagnosis and treatment of many chronic diseases. These algorithms have the power to avoid outbreaks of illness, recognize and diagnose illnesses, minimize running expenses for hospital management and patients. This paper discusses the deep learning methods used in different healthcare fields, i.e., identifying depression, heart diseases, physiological signals, lymph node metastases from breast cancer, etc. These diseases are categorized into the central nervous system, cardiovascular system, and respiratory system. For each category, after summarizing the studies, comparison tables are laid down using some important factors. Different applications, tools, methods, and data sets used for DL models are leveraged. Finally, research opportunities and challenges being faced for deep learning models are discussed.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Dur-e-Maknoon Nisar et al.",
      "keywords": "Computer science; Deep learning; Artificial intelligence; Health care; Machine learning; Artificial neural network; Process (computing); Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3095312",
      "cited_by_count": 90,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3203673826",
      "doi": "10.1109/access.2021.3116974",
      "title": "An Efficient Prediction Method for Coronary Heart Disease Risk Based on Two Deep Neural Networks Trained on Well-Ordered Training Datasets",
      "abstract": "This study proposes an efficient prediction method for coronary heart disease risk based on two deep neural networks trained on well-ordered training datasets. Most real datasets include an irregular subset with higher variance than most data, and predictive models do not learn well from these datasets. While most existing prediction models learned from the whole or randomly sampled training datasets, our suggested method draws up training datasets by separating regular and highly biased subsets to build accurate prediction models. We use a two-step approach to prepare the training dataset: (1) divide the initial training dataset into two groups, commonly distributed and highly biased using Principal Component Analysis, (2) enrich the highly biased group by Variational Autoencoders. Then, two deep neural network classifiers learn from the isolated training groups separately. The well-organized training groups enable a chance to build more accurate prediction models. When predicting the risk of coronary heart disease from the given input, only one appropriate model is selected based on the reconstruction error on the Principal Component Analysis model. Dataset used in this study was collected from the Korean National Health and Nutritional Examination Survey. We have conducted two types of experiments on the dataset. The first one proved how Principal Component Analysis and Variational Autoencoder models of the proposed method improves the performance of a single deep neural network. The second experiment compared the proposed method with existing machine learning algorithms, including Na&#x00EF;ve Bayes, Random Forest, K-Nearest Neighbor, Decision Tree, Support Vector Machine, and Adaptive Boosting. The experimental results show that the proposed method outperformed conventional machine learning algorithms by giving the accuracy of 0.892, specificity of 0.840, precision of 0.911, recall of 0.920, f-measure of 0.915, and AUC of 0.882.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Tsatsral Amarbayasgalan et al.",
      "keywords": "Computer science; Artificial intelligence; Autoencoder; Principal component analysis; Random forest; Machine learning; Artificial neural network; Naive Bayes classifier; Support vector machine; Decision tree; Boosting (machine learning); Deep learning; Pattern recognition (psychology); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3116974",
      "cited_by_count": 68,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380785265",
      "doi": "10.1109/access.2023.3286696",
      "title": "Exploring the Potential of Metaverse Technology in Healthcare: Applications, Challenges, and Future Directions",
      "abstract": "<p dir=\"ltr\">In recent times, the emergence of the Metaverse has garnered worldwide attention as an innovative digital space that holds immense potential to provide a wide range of health services to medical professionals and patients. With increasing stress on healthcare systems, it has become crucial to explore the latest and cost-effective solutions that can provide fast and reliable medical services. The focus of this study, therefore, is to explore applications of metaverse in various health care systems and elaborate on how it can efficiently improve the clinical management of patients. Consequently, an in-depth assessment of the metaverse has been carried out, while covering its core fundamentals, key technologies, and diverse applications in healthcare and medicine, including but not limited to, emergency response learning, hands-on experience in anatomy learning, orthopaedics, paediatrics and so on. To carry out the study, we have used an exploratory approach to analyze qualitative data on healthcare metaverse services in our systematic review. Relevant articles from scientific databases such as Web of Science, Springer, Scopus, and IEEE have been identified, and the analysis has been conducted using the PRISMA reporting guideline to ensure transparent and comprehensive reporting. The results of the study suggest that the metaverse has the potential to transform healthcare systems by introducing novel methods for delivering healthcare services. Metaverse\u2019s AR/VR technologies can enable remote medical consultations and training, benefiting patients and healthcare professionals. Additionally, patients can access health-related information and resources, empowering them to manage their health better and make more informed decisions. <h2>Other Information</h2><p dir=\"ltr\">Published in: IEEE Access<br>License: <a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">https://creativecommons.org/licenses/by/4.0/</a><br>See article on publisher's website: <a href=\"https://dx.doi.org/10.1109/access.2023.3286696\" target=\"_blank\">https://dx.doi.org/10.1109/access.2023.3286696</a>",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Hidayat Ullah et al.",
      "keywords": "Health care; Computer science; Metaverse; Knowledge management; Scopus; Exploratory research; Data science; Variety (cybernetics); MEDLINE; Human\u2013computer interaction; Sociology; Virtual reality; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3286696",
      "cited_by_count": 172,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388052801",
      "doi": "10.1109/access.2023.3328909",
      "title": "A Robust Heart Disease Prediction System Using Hybrid Deep Neural Networks",
      "abstract": "Heart Disease (HD) is recognized as the leading cause of worldwide mortality by the World Health Organization (WHO), resulting in the loss of approximately 17.9 million lives each year. HD prediction is found to be a challenging issue that can provide a computerized estimate of the level of HD so that additional action can be simplified. Early detection and accurate prediction of HD play a critical role in providing timely medical interventions and improving patient outcomes. Thus, HD prediction has expected massive attention worldwide in healthcare environments. Deep Learning (DL) based systems played a significant role in various disease prediction and diagnosis with good efficiency. To this end, the main contribution of this paper is to design a robust HD prediction system using Hybrid Deep Neural Networks (HDNNs) involves combining multiple neural network architectures to extract and learn relevant features from the input data. The HDNN is employed to apply its feature learning capabilities and non-linear technology to capture complex patterns and relationships in HD datasets, leading to enhanced prediction accuracy. For this, three DL models, namely Artificial Neural Networks (ANN), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), and a new HDNN model combining both CNN and LSTM along with additional Dense layers are proposed, to develop the hybrid HD prediction architecture. The proposed models were evaluated on two publicly available HD datasets, including the Cleveland HD dataset, and a large public HD dataset (Switzerland &#x002B; Cleveland &#x002B; Statlog &#x002B; Hungarian &#x002B; Long Beach VA). Additionally, the proposed system was measured through comparison with conventional systems concerning sensitivity, Matthews Correlation Coefficient (MCC), F1-measure, accuracy, precision, AUC, and specificity. The promising accuracy achieved through the proposed system is 98.86&#x0025;. The results demonstrated that this approach proved more accurate in its predictions than previous research. These outcomes suggest that the proposed HDNN system has great potential to be embedded into healthcare systems to develop advanced and reliable HD prediction models that can significantly contribute to medical diagnosis and improve patient care.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mana Saleh Al Reshan et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Artificial neural network; Deep learning; Machine learning; Feature (linguistics); Predictive modelling; Sensitivity (control systems); Data mining; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3328909",
      "cited_by_count": 87,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2974669915",
      "doi": "10.1109/jbhi.2019.2937803",
      "title": "Deep Interpretable Early Warning System for the Detection of Clinical Deterioration",
      "abstract": "Assessment of physiological instability preceding adverse events on hospital wards has been previously investigated through clinical early warning score systems. Early warning scores are simple to use yet they consider data as independent and identically distributed random variables. Deep learning applications are able to learn from sequential data, however they lack interpretability and are thus difficult to deploy in clinical settings. We propose the 'Deep Early Warning System' (DEWS), an interpretable end-to-end deep learning model that interpolates temporal data and predicts the probability of an adverse event, defined as the composite outcome of cardiac arrest, mortality or unplanned ICU admission. The model was developed and validated using routinely collected vital signs of patients admitted to the the Oxford University Hospitals between 21st March 2014 and 31st March 2018. We extracted 45 314 vital-sign measurements as a balanced training set and 359 481 vital-sign measurements as an imbalanced testing set to mimic a real-life setting of emergency admissions. DEWS achieved superior accuracy than the state-of-the-art that is currently implemented in clinical settings, the National Early Warning Score, in terms of the overall area under the receiver operating characteristic curve (AUROC) (0.880 vs. 0.866) and when evaluated independently for each of the three outcomes. Our attention-based architecture was able to recognize 'historical' trends in the data that are most correlated with the predicted probability. With high sensitivity, improved clinical utility and increased interpretability, our model can be easily deployed in clinical settings to supplement existing EWS systems.",
      "year": "2019",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Farah E. Shamout et al.",
      "keywords": "Computer science; Warning system; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2019.2937803",
      "cited_by_count": 85,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3004678548",
      "doi": "10.1109/access.2020.2971208",
      "title": "Computer-Aided Diagnosis of Chronic Kidney Disease in Developing Countries: A Comparative Analysis of Machine Learning Techniques",
      "abstract": "The high incidence and prevalence of chronic kidney disease (CKD), often caused by late diagnoses, is a critical public health problem, especially in developing countries such as Brazil. CKD treatment therapies, such as dialysis and kidney transplantation, increase the morbidity and mortality rates, besides the public health costs. This study analyses the usage of machine learning techniques to assist in the early diagnosis of CKD in developing countries. Qualitative and quantitative comparative analyses are, respectively, conducted using a systematic literature review and an experiment with machine learning techniques, with the k-fold cross-validation method based on the Weka<sup>&#x00A9;</sup> software and a CKD dataset. These analyses enable a discussion on the suitability of machine learning techniques for screening for CKD risk, focusing on low-income and hard-to-reach settings of developing countries, due to the specific problems faced by them, e.g., inadequate primary health care. The study results show that the J48 decision tree is a suitable machine learning technique for such screening in developing countries, due to the easy interpretation of its classification results, with 95.00% accuracy, reaching a nearly perfect agreement with an experienced nephrologist`s opinion. Conversely, random forest, naive Bayes, support vector machine, multilayer perceptron, and k-nearest neighbor techniques, respectively, yield 93.33%, 88.33%, 76.66%, 75.00%, and 71.67% accuracy, presenting at least moderate agreement with the nephrologist, at the cost of a more difficult interpretation of the classification results.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "\u00c1lvaro Sobrinho et al.",
      "keywords": "Machine learning; Kidney disease; Artificial intelligence; Naive Bayes classifier; Computer science; Support vector machine; Multilayer perceptron; Random forest; Developing country; Nephrology; Clinical decision support system; Medicine; Public health; Decision tree; Intensive care medicine; Data mining; Artificial neural network; Internal medicine; Decision support system; Pathology; Economic growth",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2971208",
      "cited_by_count": 76,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206046766",
      "doi": "10.1109/access.2022.3143793",
      "title": "FETCH: A Deep Learning-Based Fog Computing and IoT Integrated Environment for Healthcare Monitoring and Diagnosis",
      "abstract": "These days cloud-based infrastructure is facing many challenges, out of which the major issue is their syncing data before cutover and data migration. Due to the limited scalability in terms of security concerns of cloud computing, the need for a centralized IoTs based environment has been constrained to a limited extent. The sensitivity of device latency emerged during healthy systems such as health monitoring, etc. is the main reason, because healthy systems require computing operations on high-volume data. Fog computing provides an innovative solution to improve the performance of cloud computing, providing the ability to take the necessary resources and those that are closer to the end-users. Existing fog computing models retain several limitations, such as either considering result accuracy or overestimating response time, but managing both together impairs system compatibility. FETCH is a proposed framework that integrates with edge computing devices to work on deep learning technology and automated monitoring and offers a highly useful framework for real-life health care systems such as heart disease and more. The proposed Fog-enabled cloud computing framework uses FogBus, which demonstrates utility in the form of consumption of power, network bandwidth, jitter, latency, process execution time, and their accuracy as well.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Parag Verma et al.",
      "keywords": "Computer science; Health care; Fog computing; Internet of Things; Fetch; Computer security; Oceanography; Geology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3143793",
      "cited_by_count": 89,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2960917605",
      "doi": "10.1109/access.2019.2928020",
      "title": "Sleep Bruxism Detection Using Decision Tree Method by the Combination of C4-P4 and C4-A1 Channels of Scalp EEG",
      "abstract": "Lack of sleep causes many sleep disorders such as nocturnal frontal lobe epilepsy, narcolepsy, bruxism, sleep apnea, insomnia, periodic limb movement disorder, and rapid eye movement behavioral disorder. Out of all, bruxism is a common behavior, which is found in 8&#x2013;31&#x0025; of the population. Bruxism is a sleep disorder in which individuals involuntarily grinds and clenches the teeth. The main aim of this work is to detect sleep bruxism by analyzing the electroencephalogram (EEG) spectrum analysis of the change in the domain of different stages of sleep. The present research was performed in different stages such as collection of the data, preprocessing of the EEG signal, analysis of the C4-P4 and C4-A1 channels, comparison between healthy humans and bruxism patients, and classification using decision tree method. In this study, the channels C4-P4 and C4-A1 of the EEG signal were combined for the detection of bruxism by using Welch technique, which mainly focused on two sleep stages such as S1 and rapid eye movement. The total number of EEG channels of healthy humans and bruxism patients analyzed in this work were 15 and 18, respectively. The results showed that the individual accuracy of the C4-P4 and C4-A1 channels was 81.70&#x0025; and 74.11&#x0025;, respectively. The combined accuracy of both C4-P4 and C4-A1 channels was 81.25&#x0025;. The specificity of combined result was higher than individual. In addition, the value of theta activity during detection is consistent throughout the period, and the accuracy of S1 stage is better than rapid eye movement stage. We proposed that the theta activity of S1 could be taken for the detection of bruxism. The proposed approach in the detection of the bruxism is negligible in noise as it is in mathematical form and has taken very less time as compared with the traditional systems. The present research work would provide a fast and effective detection system of the sleep bruxism with high accuracy for medical big data applications.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Md Belal Bin Heyat et al.",
      "keywords": "Electroencephalography; Sleep Bruxism; Sleep (system call); Sleep Stages; Scalp; Audiology; Narcolepsy; Population; Polysomnography; Epilepsy; Sleep disorder; Medicine; Psychology; Insomnia; Neuroscience; Electromyography; Physical medicine and rehabilitation; Computer science; Psychiatry; Neurology; Surgery",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2928020",
      "cited_by_count": 84,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3088753106",
      "doi": "10.1109/access.2020.3025553",
      "title": "Prediction Model of Dementia Risk Based on XGBoost Using Derived Variable Extraction and Hyper Parameter Optimization",
      "abstract": "With the development of healthcare technologies, the elderly population has grown and therefore populating ageing has emerged as a social issue. It is a cause of rise in patients with geriatric disorders, among which dementia is very fatal to the elderly's activities of daily living. In the studies on dementia risk prediction, a method using deep learning was proposed. It requires a lot of image data and much time to learn. Therefore, this study proposes a prediction model of dementia risk based on XGBoost using derived variable extraction from numericalized dementia data and hyper-parameters optimization. The proposed method extracts variable importance from typical independent variables with the use of gradient boosting and then generates derived variables. The generated derived variables are applied to variable importance analysis and thereby a Top-N group is created. Then, for achieving optimal performance in line with the data characteristics of each Top-N group, hyper-parameter tuning is conducted. With the optimized groups, XGBoost model based performance is evaluated. In addition, for the performance evaluation of the proposed model, goodness-of-fit for machine learning classification models is evaluated. According to the Top-N group performance evaluation with different numbers of derived variables, Top-20 model showed the best performance, and the optimized hyper-parameter values were eta = 0.10, gamma = 0, max_depth = 4, and min_child_weight = 1. As a result, the accuracy of the XGBoost model proposed in this study was 85.61%, and its F1-score was 79.28%. When the proposed model is compared with Decision Tree, Random Forest, SVM, and k-NN models, it has the best performance.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Seongeun Ryu et al.",
      "keywords": "Computer science; Extraction (chemistry); Dementia; Variable (mathematics); Artificial intelligence; Mathematics; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3025553",
      "cited_by_count": 101,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323022376",
      "doi": "10.1109/access.2023.3251919",
      "title": "Missing Value Imputation Methods for Electronic Health Records",
      "abstract": "Electronic health records (EHR) are patient-level information, e.g., laboratory tests and questionnaires, stored in electronic format. Compared to physical records, the EHR alternative allows patients to access their data easily and helps staff with management procedural tasks such as information sharing across different organizations. Moreover, this type of data is commonly used by researchers for predictive and classification purposes, employing statistical and machine learning methods. However, missingness is a phenomenon that is observed very frequently for such measurements. Even though this missingness is often significant, it is usually treated poorly with either case deletion or simple methods, resulting in suboptimal and/or inaccurate predictive results. This happens because the simple methods, e.g., k-nearest neighbors (kNN) and mean/mode imputation, fail in most cases to incorporate the complex relationships that define these medical datasets. To address these limitations, in this paper we test and improve state-of-the-art missing data imputation models and practices. We propose a new missing value imputation method based on denoising autoencoders (DAE) with kNN for the pre-imputation task. We optimize the training methodology by re-applying kNN to the missing data every <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> epochs using a different value for the variable <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula> each time to yield more accurate results. We also revise a state-of-the-art missing data imputation approach based on a generative adversarial network (GAN). Using this as a baseline, we introduce improvements regarding both the architecture and the training procedure. These models are compared with the ones usually employed within clinical research studies for both the task of imputation and post-imputation prediction. Results show that our proposed deep learning approaches outperform the standard baselines, yielding better imputation and predictive results.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Konstantinos Psychogyios et al.",
      "keywords": "Missing data; Imputation (statistics); Computer science; Data mining; Health records; Artificial intelligence; Machine learning; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3251919",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2974827766",
      "doi": "10.1109/access.2019.2941836",
      "title": "Design and Implementation of a Convolutional Neural Network on an Edge Computing Smartphone for Human Activity Recognition",
      "abstract": "Edge computing aims to integrate computing into everyday settings, enabling the system to be context-aware and private to the user. With the increasing success and popularity of deep learning methods, there is an increased demand to leverage these techniques in mobile and wearable computing scenarios. In this paper, we present an assessment of a deep human activity recognition system\u2019s memory and execution time requirements, when implemented on a mid-range smartphone class hardware and the memory implications for embedded hardware. This paper presents the design of a convolutional neural network (CNN) in the context of human activity recognition scenario. Here, layers of CNN automate the feature learning and the in\ufb02uence of various hyper-parameters such as the number of \ufb01lters and \ufb01lter size on the performance of CNN. The proposed CNN showed increased robustness with better capability of detecting activities with temporal dependence compared to models using statistical machine learning techniques.Themodelobtainedanaccuracyof96.4%ina\ufb01ve-classstaticanddynamicactivityrecognition scenario.Wecalculatedtheproposedmodelmemoryconsumptionandexecutiontimerequirementsneeded for using it on a mid-range smartphone. Per-channel quantization of weights and per-layer quantization of activation to 8-bits of precision post-training produces classi\ufb01cation accuracy within 2% of \ufb02oatingpoint networks for dense, convolutional neural network architecture. Almost all the size and execution time reduction in the optimized model was achieved due to weight quantization. We achieved more than four times reduction in model size when optimized to 8-bit, which ensured a feasible model capable of fast on-device inference.<br/>",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Tahmina Zebin et al.",
      "keywords": "Computer science; Convolutional neural network; Edge computing; Edge device; Deep learning; Activity recognition; Quantization (signal processing); Artificial intelligence; Machine learning; Robustness (evolution); Leverage (statistics); Mobile device; Computer engineering; Enhanced Data Rates for GSM Evolution; Cloud computing; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2941836",
      "cited_by_count": 93,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391696963",
      "doi": "10.1109/access.2024.3364755",
      "title": "Cardiotocography Data Analysis for Fetal Health Classification Using Machine Learning Models",
      "abstract": "Pregnancy complications significantly impact women and pose potential threats to the developing child&#x2019;s health. Early identification of these complications is imperative for life-saving interventions. The manual analysis of cardiotocography (CTG) tests, a conventional practice among obstetricians, is both labor-intensive and unreliable. Consequently, the development of efficient fetal health classification models becomes crucial for optimizing medical resources and saving time.This study addresses the imperative for advanced fetal health classification through the application of machine learning (ML) techniques. The objective is to explore, develop, and analyze ML models capable of accurately classifying fetal health based on CTG data. The overarching goal is to enhance diagnostic precision and facilitate timely interventions.Utilizing a freely available cardiotocography data set, despite its relatively small size, the research acknowledges its rich characteristics. Various ML models, including Random Forests, Logistic Regression, Decision Trees, Support Vector Classifiers, Voting Classes, and K-Nearest Neighbors, are deployed on the data set. The analysis involves rigorous training and testing of these models to assess their efficacy in classifying fetal health.The study yields promising outcomes, with the implemented ML models achieving a notable accuracy level of 93&#x0025;, surpassing previous methods. This underscores the effectiveness of the proposed models in elevating the precision of fetal health classification based on CTG data.The findings advocate for the integration of ML models into routine clinical practices, streamlining fetal health assessments. The study not only underscores the significance of early complication detection but also demonstrates the potential of ML in optimizing medical resource allocation and time efficiency. Further research is warranted to refine and expand ML applications in the context of fetal health assessment, promising advancements in prenatal care.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Yalamanchili Salini et al.",
      "keywords": "Cardiotocography; Computer science; Artificial intelligence; Data modeling; Machine learning; Fetus; Pregnancy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3364755",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2887595165",
      "doi": "10.1109/access.2018.2864675",
      "title": "An Ultra Low Power Personalizable Wrist Worn ECG Monitor Integrated With IoT Infrastructure",
      "abstract": "Cardiovascular diseases are the leading cause of death in the U.K., motivating the use of long term wearable devices to monitor the heart in out-of-the-clinic settings. While a wide number of heart rate measuring wearable devices are now available, they are principally based upon photoplethysmography rather than the electrocardiogram (ECG) and are <i>stand-alone</i> devices rather than integrated with Internet-of-Things infrastructures which collect and combine information from a wide range of sensors. This paper presents a wrist worn ECG sensor which integrates with the SPHERE IoT platform-the UK's demonstrator platform for health monitoring in the home environment, combining a range of on-person and ambient sensors. The ECG device integrates ultralow power consumption electronics with personalizable 3-D printed casings which maintain gold standard Ag/AgCl electrodes to provide measurements of the raw ECG waveform, heart rate, and meanNN and SDNN heart rate variability parameters. The end device allows for more than a month of battery life for a weight of &lt;;50 g including the watch straps. The design and heart sensing performance of the device are presented in detail, together with the integration with the SPHERE IoT platform.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Christopher Beach et al.",
      "keywords": "Internet of Things; Computer science; Ultra low power; Power (physics); Wrist; Embedded system; Electrical engineering; Engineering; Power consumption; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2864675",
      "cited_by_count": 89,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2946387978",
      "doi": "10.1109/access.2019.2918625",
      "title": "Diagnosis and Analysis of Diabetic Retinopathy Based on Electronic Health Records",
      "abstract": "Diabetic retinopathy (DR) is an important disease leading to blindness in humans, attracting a lot of research interests. Previous breakthrough research findings rely on deep learning techniques to diagnose diabetic retinopathy in patients with medical imaging. Although the medical imaging achieves reasonable recognition accuracy, the application of mass, easy-to-obtain and free electronic health records (EHR) data in life can make an early diagnosis of the DR more convenient and quick. In this paper, we used a set of five machine learning models to diagnose the DR in patients with the EHR data and formed a set of treatment methods. Our experimental data set is formed by processing the data provided by 301 hospitals. The experimental results show that random forest (RF) in the machine learning model can get 92% accuracy with good performance. Subsequently, the input features were analyzed and their importance graded to find that the predisposing factors triggering the human DR disease were associated with renal and liver function. In addition, disease diagnosis methods based on readily available the EHR data will become an integral part of smart healthcare and mobile healthcare.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yunlei Sun et al.",
      "keywords": "Diabetic retinopathy; Blindness; Computer science; Random forest; Health records; Data set; Artificial intelligence; Medical record; Machine learning; Disease; Retinopathy; Set (abstract data type); Medicine; Health care; Optometry; Diabetes mellitus; Pathology; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2918625",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2958919462",
      "doi": "10.1109/access.2019.2927491",
      "title": "In Search of Big Medical Data Integration Solutions - A Comprehensive Survey",
      "abstract": "In recent years, the radical advancement of technologies has given rise to an abundance of software applications, social media, and smart devices such as smartphone, sensors, and so on. More extensive use of these applications and tools in various industrial domains has led to data deluge, which has fostered enormous challenges and opportunities. However, it is not only the volume of the data but also the speed, variety, and uncertainty, which are promoting a massive challenge for traditional technologies such as data warehouse. These diverse and unprecedented characteristics have engendered the notion of &#x201C;Big Data.&#x201D; The data-intensive industries have been experiencing a wide variety of challenges in terms of processing, managing, and analysis of data. For instance, the healthcare sector is confronting difficulties in respect of integration or fusion of diverse medical data stemming from multiple heterogeneous sources. Data integration is critically important within the healthcare sector because it enriches data, enhances its value, and more importantly paves a solid foundation for highly efficient and effective healthcare analytics such as predicting diseases or an outbreak. Several data integration technologies and tools have been developed over the last two decades. This paper aims at studying data integration technologies, tools, and applications within the healthcare domain. Furthermore, this paper discusses future research directions in the integration of Big healthcare data.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Houssein Dhayne et al.",
      "keywords": "Big data; Data science; Variety (cybernetics); Computer science; Data integration; Health care; Analytics; Domain (mathematical analysis); Social media; Data mining; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2927491",
      "cited_by_count": 80,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3122263456",
      "doi": "10.1109/jsen.2021.3105442",
      "title": "Missing Data Imputation on IoT Sensor Networks: Implications for on-Site Sensor Calibration",
      "abstract": "IoT sensors are becoming increasingly important supplement to traditional monitoring systems, particularly for in-situ based monitoring. Data collected using IoT sensors are often plagued with missing values occurring as a result of sensor faults, network failures, drifts and other operational issues. Missing data can have substantial impact on in-field sensor calibration methods. The goal of this research is to achieve effective calibration of sensors in the context of such missing data. To this end, two objectives are presented in this paper. 1) Identify and examine effective imputation strategy for missing data in IoT sensors. 2) Determine sensor calibration performance using calibration techniques on data set with imputed values. Specifically, this paper examines the performance of Variational Autoencoder (VAE), Neural Network with Random Weights (NNRW), Multiple Imputation by Chain Equations (MICE), Random Forest-based Imputation (missForest) and K-Nearest Neighbour (KNN) for imputation of missing values on IoT sensors. Furthermore, the performance of sensor calibration via different supervised algorithms trained on the imputed dataset were evaluated. The analysis showed VAE technique to outperform the other methods in imputing the missing values at different proportions of missingness on two real-world datasets. Experimental results also showed improved calibration performance with imputed dataset.",
      "year": "2021",
      "journal": "IEEE Sensors Journal",
      "authors": "Nwamaka U. Okafor et al.",
      "keywords": "Imputation (statistics); Missing data; Computer science; Data mining; Calibration; Wireless sensor network; Autoencoder; Artificial neural network; Artificial intelligence; Statistics; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2021.3105442",
      "cited_by_count": 68,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3134089754",
      "doi": "10.1109/access.2021.3062687",
      "title": "Research on Disease Prediction Based on Improved DeepFM and IoMT",
      "abstract": "In recent years, with the increase of computer computing power, Deep Learning has begun to be favored. Its learning of non-linear feature combinations has played a role that traditional machine learning cannot reach in almost every field. The application of Deep Learning has also driven the advancement of Factorization Machine (FM) in the field of recommendation systems, because Deep Learning and FM can learn high-order and low-order features combinations respectively, and FM's hidden vector system enables it to learn information from sparse data. The integration of them has attracted the attention of many scholars. They have researched many classic models such as Factorization-supported Neural Network (FNN), Product-based Neural Networks (PNN), Inner PNN (IPNN), Wide&amp;Deep, Deep&amp;Cross, DeepFM, etc. for the Click-Through-Rate (CTR) problem, and their performance is getting better and better. This kind of model is also suitable for agriculture, meteorology, disease prediction and other fields due to the above advantages. Based on the DeepFM model, we predicts the incidence of hepatitis in each sample in the structured disease prediction data of the 2020 Artificial Intelligence Challenge Preliminary Competition, and make minor improvements and parameter adjustments to DeepFM. Compared with other models, the improved DeepFM has excellent performance in AUC. This research can be applied to electronic medical records to reduce the workload of doctors and make doctors focus on the samples with higher predicted incidence rates. For some changing data, such as blood pressure, height, weight, cholesterol, etc., we can introduce the Internet of Medical Things (IoMT). IoMT's sensors can be used to conduct transmission to ensure that the disease can be predicted in time, just in case. After joining IoMT, a healthcare system is formed, which is superior in forecasting and time performance.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Zengchen Yu et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Machine learning; Artificial neural network; Field (mathematics); Big data; The Internet; Workload; Data science; Data mining; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3062687",
      "cited_by_count": 103,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2948995481",
      "doi": "10.1109/access.2019.2920900",
      "title": "Classification of Atrial Fibrillation Recurrence Based on a Convolution Neural Network With SVM Architecture",
      "abstract": "Although radio frequency ablation is the most effective treatment for atrial fibrillation (AF), there is still a high recurrence rate. The purpose of this paper was to initially assess the probability of the recurrence of AF based on the preoperative body surface potential mapping (BSPM) signals, in other words, to predict the efficiency of ablation and assist physicians in developing more effective treatment options. At present, deep learning methods based on convolutional neural networks (CNNs) do not require complex mathematical abstractions or manual interventions; thus, higher computation efficiency can be obtained in such research. However, the use of the fully connected multi-layer perceptron (MLP) algorithms has shown low classification performance. This paper proposes an improved CNN algorithm (CNN-SVM method) for the recurrence classification in AF patients by combining with the support vector machine (SVM) architecture. The algorithm is validated on the preoperative AF signals of 14 patients for classification. All postoperative patients are followed up for one year; ten of them remain in sinus rhythm, whereas the other four turn back to AF. The ECG data for these patients are obtained through the 128-Lead BSPM system. The results show that the proposed CNN-SVM method can automatically extract the characteristic information through the CNN network. The constructed model ultimately achieved an accuracy of 96%, a sensitivity of 88%, and a specificity of 96%. It is concluded that the CNN-SVM method solves the drawbacks of MLP only for separating linear data. It improves the overall performance of AF recurrence classification, thereby providing a valuable reference for doctors to develop personalized treatment plans.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Zhangjun Li et al.",
      "keywords": "Convolution (computer science); Atrial fibrillation; Computer science; Support vector machine; Pattern recognition (psychology); Artificial intelligence; Artificial neural network; Kernel (algebra); Convolutional neural network; Internal medicine; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2920900",
      "cited_by_count": 56,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295308277",
      "doi": "10.1109/comst.2022.3205184",
      "title": "Adversarial Machine Learning in Wireless Communications Using RF Data: A Review",
      "abstract": "Machine learning (ML) provides effective means to learn from spectrum data and solve complex tasks involved in wireless communications. Supported by recent advances in computational resources and algorithmic designs, deep learning (DL) has found success in performing various wireless communication tasks such as signal recognition, spectrum sensing and waveform design. However, ML in general and DL in particular have been found vulnerable to manipulations thus giving rise to a field of study called adversarial machine learning (AML). Although AML has been extensively studied in other data domains such as computer vision and natural language processing, research for AML in the wireless communications domain is still in its early stage. This paper presents a comprehensive review of the latest research efforts focused on AML in wireless communications while accounting for the unique characteristics of wireless systems. First, the background of AML attacks on deep neural networks is discussed and a taxonomy of AML attack types is provided. Various methods of generating adversarial examples and attack mechanisms are also described. In addition, an holistic survey of existing research on AML attacks for various wireless communication problems as well as the corresponding defense mechanisms in the wireless domain are presented. Finally, as new attacks and defense techniques are developed, recent research trends and the overarching future outlook for AML in next-generation wireless communications are discussed.",
      "year": "2022",
      "journal": "IEEE Communications Surveys & Tutorials",
      "authors": "Damilola Adesina et al.",
      "keywords": "Computer science; Wireless; Adversarial system; Wireless network; Machine learning; Artificial intelligence; Deep learning; Field (mathematics); Telecommunications",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/comst.2022.3205184",
      "cited_by_count": 126,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4360584499",
      "doi": "10.1109/access.2023.3260652",
      "title": "Community Detection Algorithms in Healthcare Applications: A Systematic Review",
      "abstract": "Over the past few years, the number and volume of data sources in healthcare databases has grown exponentially. Analyzing these voluminous medical data is both opportunity and challenge for knowledge discovery in health informatics. In the last decade, social network analysis techniques and community detection algorithms are being used more and more in scientific fields, including healthcare and medicine. While community detection algorithms have been widely used for social network analysis, a comprehensive review of its applications for healthcare in a way to benefit both health practitioners and the health informatics community is still overwhelmingly missing. This paper contributes to fill in this gap and provide a comprehensive and up-to-date literature research. Especially, categorizations of existing community detection algorithms are presented and discussed. Moreover, most applications of social network analysis and community detection algorithms in healthcare are reviewed and categorized. Finally, publicly available healthcare datasets, key challenges, and knowledge gaps in the field are studied and reviewed.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mehrdad Rostami et al.",
      "keywords": "Computer science; Data science; Health care; Health informatics; Field (mathematics); Key (lock); Informatics; Social network analysis; Data mining; Algorithm; Social media; Computer security; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3260652",
      "cited_by_count": 100,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3047276250",
      "doi": "10.1109/access.2020.3014362",
      "title": "A Novel Ensemble Learning Paradigm for Medical Diagnosis With Imbalanced Data",
      "abstract": "With the help of machine learning (ML) techniques, the possible errors made by the pathologists and physicians, such as those caused by inexperience, fatigue, stress and so on can be avoided, and the medical data can be examined in a shorter time and in a more detailed manner. However, while the conventional ML techniques, such as classification, achieved excellent performance in classification accuracy when applied in medical diagnoses, they have a fatal shortcoming of poor performance since the imbalanced dataset, especially for the detection of the minority category. To tackle the shortcomings of conventional classification approaches, this study proposes a novel ensemble learning paradigm for medical diagnosis with imbalanced data, which consists of three phases: data pre-processing, training base classifier and final ensemble. In the first data pre-processing phase, we introduce the extension of Synthetic Minority Oversampling Technique (SMOTE) by integrating it with cross-validated committees filter (CVCF) technique, which can not only synthesize the minority sample and thereby balance the input instances, but also filter the noisy examples so as to perform well in the process of classification. In the classification phase, we introduce ensemble support vector machine (ESVM) classification technique, which were constructed by multiple diversity structures of SVM classifiers and thus has the advantages of strong generalization performance and classification precision. Additionally, in the last phase of the final ensemble strategy, we introduce the weighted majority voting strategy and introduce simulated annealing genetic algorithm (SAGA) to optimize the weight vector and thereby enhance the overall classification performance. The efficiency of our proposed ensemble learning method was tested on nine imbalanced medical datasets and the experimental results clearly indicate that the proposed ensemble learning paradigm outperforms other state-of-the-art classification models. Promisingly, our proposed ensemble learning paradigm can effectively facilitate medical decision making for physicians.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Na Liu et al.",
      "keywords": "Computer science; Ensemble learning; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3014362",
      "cited_by_count": 82,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3215996490",
      "doi": "10.1109/access.2021.3129284",
      "title": "Survey of Interoperability in Electronic Health Records Management and Proposed Blockchain Based Framework: MyBlockEHR",
      "abstract": "Interoperability in Electronic Health Records (EHR) is significant for the seamless sharing of information amongst different healthcare stakeholders. Interoperability in EHR aims to devise agreements in its interpretation, access, and storage with security, privacy, and trust. A study and survey of the state-of-the-art literature, prototypes, and projects in standardization of the EHR structure, privacy-preservation, and EHR sharing are very essential. The presented work conducts a systematic literature review to address four research questions. 1) What are the different standards for common interpretation, representation, and modeling of EHR to achieve semantic interoperability? 2) What are the different privacy-preservation techniques and security standards for EHR data storage? 3) How mature is blockchain technology for building interoperable, privacy-preserving solutions for EHR storage and sharing? 4) What is the state-of-the-art for cross-chain interoperability for EHR sharing? An exhaustive study of these questions establishes the potential of a blockchain-based EHR management framework in privacy preservation, access control and efficient storage. The study also unveils challenges in the adoption of blockchain in EHR management with the state-of-the-art maturity of cross-chain interoperable solutions for sharing EHR amongst stakeholders on different blockchain platforms. The research gaps culminate in proposing a blockchain-based EHR framework called as MyBlockEHR with privacy preservation and access control design. The proposed framework employs partitioning of EHR to on-chain and off-chain storages for performance guarantees with the retrieval of valid off-chain data. The framework is deployed on the Ethereum test network with Solidity smart contracts. It is observed that different test cases on the partitioning of the EHR data, yielded better read-write throughput and effective gas price than fully on-chain storage.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Rahul Ganpatrao Sonkamble et al.",
      "keywords": "Interoperability; Blockchain; Computer science; Cross-domain interoperability; Semantic interoperability; Data sharing; Standardization; Information privacy; Information sharing; Computer security; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3129284",
      "cited_by_count": 86,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3096413426",
      "doi": "10.1109/access.2020.3034032",
      "title": "Explainable Machine Learning for Early Assessment of COVID-19 Risk Prediction in Emergency Departments",
      "abstract": "Between January and October of 2020, the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) virus has infected more than 34 million persons in a worldwide pandemic leading to over one million deaths worldwide (data from the Johns Hopkins University). Since the virus begun to spread, emergency departments were busy with COVID-19 patients for whom a quick decision regarding in- or outpatient care was required. The virus can cause characteristic abnormalities in chest radiographs (CXR), but, due to the low sensitivity of CXR, additional variables and criteria are needed to accurately predict risk. Here, we describe a computerized system primarily aimed at extracting the most relevant radiological, clinical, and laboratory variables for improving patient risk prediction, and secondarily at presenting an explainable machine learning system, which may provide simple decision criteria to be used by clinicians as a support for assessing patient risk. To achieve robust and reliable variable selection, Boruta and Random Forest (RF) are combined in a 10-fold cross-validation scheme to produce a variable importance estimate not biased by the presence of surrogates. The most important variables are then selected to train a RF classifier, whose rules may be extracted, simplified, and pruned to finally build an associative tree, particularly appealing for its simplicity. Results show that the radiological score automatically computed through a neural network is highly correlated with the score computed by radiologists, and that laboratory variables, together with the number of comorbidities, aid risk prediction. The prediction performance of our approach was compared to that that of generalized linear models and shown to be effective and robust. The proposed machine learning-based computational system can be easily deployed and used in emergency departments for rapid and accurate risk prediction in COVID-19 patients.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Elena Casiraghi et al.",
      "keywords": "Decision tree; Artificial intelligence; Machine learning; Computer science; Radiological weapon; Random forest; Triage; Artificial neural network; Coronavirus disease 2019 (COVID-19); Decision tree learning; Medicine; Emergency medicine; Surgery; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3034032",
      "cited_by_count": 81,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3160733781",
      "doi": "10.1109/ojcas.2021.3075302",
      "title": "Electrical Impedance Tomography for Biomedical Applications: Circuits and Systems Review",
      "abstract": "There has been considerable interest in electrical impedance tomography (EIT) to provide low-cost, radiation-free, real-time and wearable means for physiological status monitoring. To be competitive with other well-established imaging modalities, it is important to understand the requirements of the specific application and determine a suitable system design. This paper presents an overview of EIT circuits and systems including architectures, current drivers, analog front-end and demodulation circuits, with emphasis on integrated circuit implementations. Commonly used circuit topologies are detailed, and tradeoffs are discussed to aid in choosing an appropriate design based on the application and system priorities. The paper also describes a number of integrated EIT systems for biomedical applications, as well as discussing current challenges and possible future directions.",
      "year": "2021",
      "journal": "IEEE Open Journal of Circuits and Systems",
      "authors": "Yu Wu et al.",
      "keywords": "Electrical impedance tomography; Electronic circuit; Emphasis (telecommunications); Computer science; Electronic engineering; Implementation; Demodulation; Electrical impedance; Integrated circuit; Electrical engineering; Engineering; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcas.2021.3075302",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2976513180",
      "doi": "10.1109/access.2019.2943351",
      "title": "Detecting At-Risk Students With Early Interventions Using Machine Learning Techniques",
      "abstract": "Massive Open Online Courses (MOOCs) have shown rapid development in recent years, allowing learners to access high-quality digital material. Because of facilitated learning and the flexibility of the teaching environment, the number of participants is rapidly growing. However, extensive research reports that the high attrition rate and low completion rate are major concerns. In this paper, the early identification of students who are at risk of withdrew and failure is provided. Therefore, two models are constructed namely at-risk student model and learning achievement model. The models have the potential to detect the students who are in danger of failing and withdrawal at the early stage of the online course. The result reveals that all classifiers gain good accuracy across both models, the highest performance yield by GBM with the value of 0.894, 0.952 for first, second model respectively, while RF yield the value of 0.866, in at-risk student framework achieved the lowest accuracy. The proposed frameworks can be used to assist instructors in delivering intensive intervention support to at-risk students.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Raghad Al-Shabandar et al.",
      "keywords": "Computer science; Psychological intervention; Attrition; Flexibility (engineering); Quality (philosophy); Identification (biology); At-risk students; Intervention (counseling); Machine learning; Artificial intelligence; Mathematics education; Risk analysis (engineering); Psychology; Medicine; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2943351",
      "cited_by_count": 64,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3185676931",
      "doi": "10.1109/access.2021.3099795",
      "title": "A Stacking Ensemble Prediction Model for the Occurrences of Major Adverse Cardiovascular Events in Patients With Acute Coronary Syndrome on Imbalanced Data",
      "abstract": "The major adverse cardiovascular events (MACE) often occur with high morbidity and mortality globally. It is very important to predict the MACE occurrences accurately in patients with acute coronary syndrome (ACS). Therefore, this paper proposes a stacking ensemble model for the prediction of MACE occurrences in patients with ACS at early stage. Our research contents are summarized as follows. First, we use the Korea Acute Myocardial Infarction Registry National Institutes of Health (KAMIR-NIH) dataset, and our experimental data are extracted from the raw data and preprocessed. Second, we apply three data sampling approaches, such as borderline synthetic minority oversampling technique (Borderline-SMOTE1), cluster centroids undersampling, and synthetic minority oversampling techniques (SMOTE) plus Tomek Links (SMOTETomek) hybrid technique, to solve the class imbalance problem. Third, to develop a stacking ensemble prediction model for the occurrences of MACE, we apply seven widely used machine learning algorithms, such as logistic regression (LR), support vector machine (SVM), K-Nearest Neighbors (KNN), decision tree (DT), random forest (RF), extreme gradient boosting (XGBoost), and adaptive boosting (AdaBoost), as base learners. Fourth, the performance of the proposed stacking ensemble model is compared with the seven base learners using the three data sampling techniques. In the result, the proposed stacking ensemble model with the SMOTETomek shows the best performance with accuracy of 0.9862, precision 0.9976, recall 0.975, F1-score 0.9862, g-mean 0.9863, and AUC 0.9863 and provided a better solution for imbalanced dataset. Consequently, our finding is that the proposed stacking ensemble model with the SMOTETomek outperforms the base learners and improves the accuracy of diagnosis and prediction of the MACE occurrences in patients with ACS at early stage.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Huilin Zheng et al.",
      "keywords": "Undersampling; Random forest; Support vector machine; Oversampling; Computer science; AdaBoost; Stacking; Artificial intelligence; Ensemble learning; Decision tree; Mace; Logistic regression; Boosting (machine learning); Machine learning; Pattern recognition (psychology); Data mining; Myocardial infarction; Medicine; Internal medicine; Bandwidth (computing); Percutaneous coronary intervention",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3099795",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226173998",
      "doi": "10.1109/access.2022.3169284",
      "title": "AI-Based Stroke Disease Prediction System Using ECG and PPG Bio-Signals",
      "abstract": "Since stroke disease often causes death or serious disability, active primary prevention and early detection of prognostic symptoms are very important. Stroke diseases can be divided into ischemic stroke and hemorrhagic stroke, and they should be minimized by emergency treatment such as thrombolytic or coagulant administration by type. First, it is essential to detect in real time the precursor symptoms of stroke, which occur differently for each individual, and to provide professional treatment by a medical institution within the proper treatment window. However, prior studies have focused on developing acute treatment or clinical treatment guidelines after the onset of stroke rather than detecting the prognostic symptoms of stroke. In particular, in recent studies, image analysis such as magnetic resonance imaging (MRI) or computed tomography (CT) has mostly been used to detect and predict prognostic symptoms in stroke patients. Not only are these methodologies difficult to diagnose early in real-time, but they also have limitations in terms of a long test time and a high cost of testing. In this paper, we propose a system that can predict and semantically interpret stroke prognostic symptoms based on machine learning using the multi-modal bio-signals of electrocardiogram (ECG) and photoplethysmography (PPG) measured in real-time for the elderly. To predict stroke disease in real-time while walking, we designed and implemented a stroke disease prediction system with an ensemble structure that combines CNN and LSTM. The proposed system considers the convenience of wearing the bio-signal sensors for the elderly, and the bio-signals were collected at a sampling rate of 1,000Hz per second from the three electrodes of the ECG and the index finger for PPG while walking. According to the experimental results, C4.5 decision tree showed a prediction accuracy of 91.56&amp;#x0025; while RandomForest showed a prediction accuracy of 97.51&amp;#x0025; during walking by the elderly. In addition, the CNN-LSTM model using raw data of ECG and PPG showed satisfactory prediction accuracy of 99.15&amp;#x0025;. As a result, the real-time prediction of the elderly stroke patients simultaneously showed high prediction accuracy and performance.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Jaehak Yu et al.",
      "keywords": "Stroke (engine); Photoplethysmogram; Medicine; Disease; Magnetic resonance imaging; Machine learning; Intensive care medicine; Physical medicine and rehabilitation; Computer science; Internal medicine; Radiology; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3169284",
      "cited_by_count": 81,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3097427031",
      "doi": "10.1109/access.2020.3036072",
      "title": "Improved Threshold Based and Trainable Fully Automated Segmentation for Breast Cancer Boundary and Pectoral Muscle in Mammogram Images",
      "abstract": "&lt;p&gt;Segmentation of the breast region and pectoral muscle are fundamental subsequent steps in the&lt;br&gt;process of Computer-Aided Diagnosis (CAD) systems. Segmenting the breast region and pectoral muscle are&lt;br&gt;considered a difcult task, particularly in mammogram images because of artefacts, homogeneity among the&lt;br&gt;region of the breast and pectoral muscle, and low contrast along the region of breast boundary, the similarity&lt;br&gt;between the texture of the Region of Interest (ROI), and the unwanted region and irregular ROI. This study&lt;br&gt;aims to propose an improved threshold-based and trainable segmentation model to derive ROI. A hybrid&lt;br&gt;segmentation approach for the boundary of the breast region and pectoral muscle in mammogram imageswas&lt;br&gt;established based on thresholding and Machine Learning (ML) techniques. For breast boundary estimation,&lt;br&gt;the region of the breast was highlighted by eliminating bands of the wavelet transform. The initial breast&lt;br&gt;boundary was determined through a new thresholding technique. Morphological operations and masking&lt;br&gt;were employed to correct the overestimated boundary by deleting small objects. In the medical imaging&lt;br&gt;eld, signicant progress to develop effective and accurate ML methods for the segmentation process.&lt;br&gt;In the literature, the imperative role of ML methods in enabling effective and more accurate segmentation&lt;br&gt;method has been highlighted. In this study, an ML technique was built based on the Histogram of Oriented&lt;br&gt;Gradient (HOG) feature with neural network classiers to determine the region of pectoral muscle and&lt;br&gt;ROI. The proposed segmentation approach was tested by utilizing 322, 200, 100 mammogram images from&lt;br&gt;mammographic image analysis society (mini-MIAS), INbreast, Breast Cancer Digital Repository (BCDR)&lt;br&gt;databases, respectively. The experimental results were compared with manual segmentation based on&lt;br&gt;different texture features. Moreover, evaluation and comparison for the boundary of the breast region and&lt;br&gt;pectoral muscle segmentation have been done separately. The experimental results showed that the boundary&lt;br&gt;of the breast region and the pectoral muscle segmentation approach obtained an accuracy of 98.13%&lt;br&gt;and 98.41% (mini-MIAS), 100%, and 98.01% (INbreast), and 99.8% and 99.5% (BCDR), respectively.&lt;br&gt;On average, the proposed study achieved 99.31% accuracy for the boundary of breast region segmentation&lt;br&gt;and 98.64% accuracy for pectoral muscle segmentation. The overall ROI performance of the proposed&lt;br&gt;method showed improving accuracy after improving the threshold technique for background segmentation&lt;br&gt;and building an ML technique for pectoral muscle segmentation. More so, this article also included the&lt;br&gt;ground-truth as an evaluation of comprehensive similarity. In the clinic, this analysis may be provided as a&lt;br&gt;valuable support for breast cancer identication.&lt;/p&gt;",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Dilovan Asaad Zebari et al.",
      "keywords": "Artificial intelligence; Computer science; Thresholding; Segmentation; Computer vision; Image segmentation; Pattern recognition (psychology); Region of interest; Mammography; Pectoral muscle; Breast cancer; Image (mathematics); Medicine; Anatomy; Cancer",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3036072",
      "cited_by_count": 152,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3127596160",
      "doi": "10.1109/jiot.2021.3055804",
      "title": "Trustworthy and Intelligent COVID-19 Diagnostic IoMT Through XR and Deep-Learning-Based Clinic Data Access",
      "abstract": "This article presents a novel extended reality (XR) and deep-learning-based Internet-of-Medical-Things (IoMT) solution for the COVID-19 telemedicine diagnostic, which systematically combines virtual reality/augmented reality (AR) remote surgical plan/rehearse hardware, customized 5G cloud computing and deep learning algorithms to provide real-time COVID-19 treatment scheme clues. Compared to existing perception therapy techniques, our new technique can significantly improve performance and security. The system collected 25 clinic data from the 347 positive and 2270 negative COVID-19 patients in the Red Zone by 5G transmission. After that, a novel auxiliary classifier generative adversarial network-based intelligent prediction algorithm is conducted to train the new COVID-19 prediction model. Furthermore, The Copycat network is employed for the model stealing and attack for the IoMT to improve the security performance. To simplify the user interface and achieve an excellent user experience, we combined the Red Zone's guiding images with the Green Zone's view through the AR navigate clue by using 5G. The XR surgical plan/rehearse framework is designed, including all COVID-19 surgical requisite details that were developed with a real-time response guaranteed. The accuracy, recall, F<sub>1</sub>-score, and area under the ROC curve (AUC) area of our new IoMT were 0.92, 0.98, 0.95, and 0.98, respectively, which outperforms the existing perception techniques with significantly higher accuracy performance. The model stealing also has excellent performance, with the AUC area of 0.90 in Copycat slightly lower than the original model. This study suggests a new framework in the COVID-19 diagnostic integration and opens the new research about the integration of XR and deep learning for IoMT implementation.",
      "year": "2021",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Yonghang Tai et al.",
      "keywords": "Computer science; Deep learning; Telemedicine; The Internet; Artificial intelligence; Cloud computing; Augmented reality; Virtual reality; Human\u2013computer interaction; Machine learning; Multimedia; World Wide Web; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2021.3055804",
      "cited_by_count": 78,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3046496067",
      "doi": "10.1109/access.2020.3013320",
      "title": "A New Hybrid Predictive Model to Predict the Early Mortality Risk in Intensive Care Units on a Highly Imbalanced Dataset",
      "abstract": "&lt;p&gt;Due to the development of biomedical equipment and healthcare level, especially in the Intensive Care Unit (ICU), a considerable amount of data has been collected for analysis. Mortality prediction in the ICUs is considered as one of the most important topics in the healthcare data analysis section. A precise prediction of the mortality risk for patients in ICU could provide us with valuable information about patients' lives and reduce costs at the earliest possible stage. This paper aims to introduce a new hybrid predictive model using the Genetic Algorithm as a feature selection method and a new ensemble classifier based on the combination of Stacking and Boosting ensemble methods to create an early mortality prediction model on a highly imbalanced dataset. The SVM-SMOTE method is used to solve the imbalanced data problem. This paper compares the new model with various machine learning models to validate the efficiency of the introduced model. The achieved results using the shuffle 5-fold cross-validation and random hold-out methods indicate that the new hybrid model has the best performance among other classifiers. Additionally, the Friedman test is applied as a statistical significance test to examine the differences between classifiers. The results of the statistical analysis prove that the proposed model is more effective than other classifiers. Furthermore, the proposed model is compared to APACHE and SAPS scoring systems and is benchmarked against state-of-the-art predictive models applied to the MIMIC dataset for experimental validation and achieved promising results as it outperformed the state-of-the-art models. &lt;/p&gt;",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ramin Ghorbani et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Boosting (machine learning); Support vector machine; Ensemble forecasting; Predictive modelling; Random forest; Intensive care; Data mining; Classifier (UML)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3013320",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312658206",
      "doi": "10.1109/comst.2022.3224644",
      "title": "A Survey on Blockchain for Healthcare: Challenges, Benefits, and Future Directions",
      "abstract": "&lt;p&gt;Continuously generated volumes of health data make healthcare a data-intensive domain. This data needs to be collected, stored, and shared among different healthcare actors for various purposes, such as reporting, analysis, collaborative research, and personalized healthcare services. However, the existing data storage and exchange solutions in the healthcare domain exhibit several challenges related to e.g., data security, patient privacy, and interoperability. Recently, the industry and research community turned its focus to the possible use of blockchain technology to solve some of these challenges in the healthcare domain. The blockchain technology along with the support from smart contracts is considered a salient facilitator for secure and efficient health data sharing. This is due to its unique features, such as decentralization, trustlessness, immutability, traceability, and transparency. In this paper, we provide a comprehensive survey of the state-of-the-art efforts that envision the use of blockchain-based solutions in the healthcare domain. To this end, we introduce a systematic framework for classifying and analyzing such systems. The framework consists of classification in several dimensions: interactions between healthcare entities, functional components of healthcare storage systems, challenges in the healthcare domain that can be overcome by using the blockchain technology, and benefits for healthcare storage systems derived from the fundamental features of the technology. When analyzing over 40 systems and solutions proposed in the state-of-the-art, we perform their rigorous placement by identifying the exact scope of each solution and mapping it to the above taxonomies of interactions, functional components, challenges, and benefits. We additionally provide an extensive discussion of compliance with privacy-related regulations of General Data Protection Regulation (GDPR) in EU, and Health Insurance Portability and Accountability Act (HIPAA). Following the results of the analysis, we have outlined a number of important research gaps and future directions yet to be addressed.&lt;/p&gt;",
      "year": "2022",
      "journal": "IEEE Communications Surveys & Tutorials",
      "authors": "Mohammad Salar Arbabi et al.",
      "keywords": "Blockchain; Health care; Interoperability; Computer science; Data science; Transparency (behavior); Domain (mathematical analysis); Knowledge management; Data sharing; Immutability; Computer security; World Wide Web; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/comst.2022.3224644",
      "cited_by_count": 96,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390187248",
      "doi": "10.1109/access.2023.3346925",
      "title": "Long Short-Term Memory-Deep Belief Network-Based Gene Expression Data Analysis for Prostate Cancer Detection and Classification",
      "abstract": "Prostate cancer (PRC) is the major reason of mortality globally. Early recognition and classification of PRC become essential to enhance the quality of healthcare services. A newly established deep learning (DL) and machine learning (ML) approach with different optimization tools can be employed to classify accurately of PRC accurately using microarray gene expression data (GED). Though the microarray data structures are important to diagnosing different kinds of diseases, the optimum hyperparameter tuning of the DL models poses a major challenge to achieving maximum classification performance. To resolve these issues, this study develops a new Gene Expression Data Analysis using Artificial Intelligence for Prostate Cancer Diagnoses (GEDAAI-PCD) technique. The proposed GEDAAI-PCD technique examines the GED for the identification of PRC. To accomplish this, the GEDAAI-PCD technique initially normalizes the GED into a uniform format. In addition, the long short-term memory-deep belief network (LSTM-DBN) model was applied for PRC classification purposes. The wild horse optimization (EWHO) system was utilized as a hyperparameter tuning strategy to optimize the performance of the LSTM-DBN model. The experimental assessment of the GEDAAI-PCD system occurs on open open-accessed gene expression database. The experimental outcomes emphasized the supremacy of the GEDAAI-PCD method on PRC classification.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Bijaya Kumar Sethi et al.",
      "keywords": "Hyperparameter; Computer science; Artificial intelligence; Deep learning; Machine learning; Deep belief network; Microarray analysis techniques; Hyperparameter optimization; Expression (computer science); Data mining; Support vector machine; Gene; Gene expression",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3346925",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392173952",
      "doi": "10.1109/access.2024.3369673",
      "title": "Innovations in Stroke Identification: A Machine Learning-Based Diagnostic Model Using Neuroimages",
      "abstract": "Cerebrovascular diseases such as stroke are among the most common causes of death and disability worldwide and are preventable and treatable. Early detection of strokes and their rapid intervention play an important role in reducing the burden of disease and improving clinical outcomes. In recent years, machine learning methods have attracted a lot of attention as they can be used to detect strokes. The aim of this study is to identify reliable methods, algorithms, and features that help medical professionals make informed decisions about stroke treatment and prevention. To achieve this goal, we have developed an early stroke detection system based on CT images of the brain coupled with a genetic algorithm and a bidirectional long short-term Memory (BiLSTM) to detect strokes at a very early stage. For image classification, a genetic approach based on neural networks is used to select the most relevant features for classification. The BiLSTM model is then fed with these features. Cross-validation was used to evaluate the accuracy of the diagnostic system, precision, recall, F1 score, ROC (Receiver Operating Characteristic Curve), and AUC (Area Under The Curve). All of these metrics were used to determine the system&#x2019;s overall effectiveness. The proposed diagnostic system achieved an accuracy of 96.5&#x0025;. We also compared the performance of the proposed model with Logistic Regression, Decision Trees, Random Forests, Naive Bayes, and Support Vector Machines. With the proposed diagnosis system, physicians can make an informed decision about stroke.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Muhammad Asim Saleem et al.",
      "keywords": "Computer science; Identification (biology); Artificial intelligence; Stroke (engine); Machine learning; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3369673",
      "cited_by_count": 44,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2906409044",
      "doi": "10.1109/tmi.2018.2888807",
      "title": "Cardiac Phase Detection in Echocardiograms With Densely Gated Recurrent Neural Networks and Global Extrema Loss",
      "abstract": "Accurate detection of end-systolic (ES) and end-diastolic (ED) frames in an echocardiographic cine series can be difficult but necessary pre-processing step for the development of automatic systems to measure cardiac parameters. The detection task is challenging due to variations in cardiac anatomy and heart rate often associated with pathological conditions. We formulate this problem as a regression problem and propose several deep learning-based architectures that minimize a novel global extrema structured loss function to localize the ED and ES frames. The proposed architectures integrate convolution neural networks (CNNs)-based image feature extraction model and recurrent neural networks (RNNs) to model temporal dependencies between each frame in a sequence. We explore two CNN architectures: DenseNet and ResNet, and four RNN architectures: long short-term memory, bi-directional LSTM, gated recurrent unit (GRU), and Bi-GRU, and compare the performance of these models. The optimal deep learning model consists of a DenseNet and GRU trained with the proposed loss function. On average, we achieved 0.20 and 1.43 frame mismatch for the ED and ES frames, respectively, which are within reported inter-observer variability for the manual detection of these frames.",
      "year": "2018",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Fatemeh Taheri Dezaki et al.",
      "keywords": "Computer science; Deep learning; Recurrent neural network; Artificial intelligence; Maxima and minima; Pattern recognition (psychology); Convolutional neural network; Feature extraction; Convolution (computer science); Frame (networking); Feature (linguistics); Artificial neural network; Computer vision; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2018.2888807",
      "cited_by_count": 86,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3203668181",
      "doi": "10.1109/access.2021.3117969",
      "title": "A Benchmark Study of Machine Learning for Analysis of Signal Feature Extraction Techniques for Blood Pressure Estimation Using Photoplethysmography (PPG)",
      "abstract": "Cardiovascular related diseases are the most significant health concern around the globe. The most crucial health indicator is blood pressure because it gives essential information about the health of a patient's heart. Cardiovascular diseases can be detected early and prevented if blood pressure is monitored continuously and regularly. Blood pressure cuffs, which are widely used to control blood flow in the arm or wrist when measuring blood pressure, are not practical for continuous blood pressure measurement. However, biosignals can be used for blood pressure estimation; but it is still critical and challenging. In this paper, we conducted a comprehensive analysis of feature extraction techniques for blood pressure estimation by using PPG signals. The feature extraction techniques were further divided into three subgroups to analyse the significance of each group. Group A includes time-based features; group B presents statistical feature extraction, and group C presents frequency domain-based features. The analysis employed several machine learning algorithms and compared their performance from many perspectives. The experimental results from two publicly available datasets demonstrated that the set of features belonging to group A were more reliable than other techniques for blood pressure estimation. We found that deep learning models achieved better performance than all traditional machine learning methods. We also found that the GRU model and Bi-LSTM achieved the best performance for time-domain features for blood pressure estimation. We believe the findings of this benchmark study will help researchers choose the most appropriate method for feature extraction and machine learning algorithms.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Sumbal Maqsood et al.",
      "keywords": "Photoplethysmogram; Computer science; Feature extraction; Blood pressure; Artificial intelligence; Benchmark (surveying); Feature (linguistics); Pattern recognition (psychology); Machine learning; Medicine; Computer vision; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3117969",
      "cited_by_count": 61,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377093389",
      "doi": "10.1109/tnsre.2023.3277749",
      "title": "Multi-Modal Deep Learning Diagnosis of Parkinson\u2019s Disease\u2014A Systematic Review",
      "abstract": "Parkinson's Disease (PD) is among the most frequent neurological disorders. Approaches that employ artificial intelligence and notably deep learning, have been extensively embraced with promising outcomes. This study dispenses an exhaustive review between 2016 and January 2023 on deep learning techniques used in the prognosis and evolution of symptoms and characteristics of the disease based on gait, upper limb movement, speech and facial expression-related information as well as the fusion of more than one of the aforementioned modalities. The search resulted in the selection of 87 original research publications, of which we have summarized the relevant information regarding the utilized learning and development process, demographic information, primary outcomes, and sensory equipment related information. Various deep learning algorithms and frameworks have attained state-of-the-art performance in many PD-related tasks by outperforming conventional machine learning approaches, according to the research reviewed. In the meanwhile, we identify significant drawbacks in the existing research, including a lack of data availability and interpretability of models. The fast advancements in deep learning and the rise in accessible data provide the opportunity to address these difficulties in the near future and for the broad application of this technology in clinical settings.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Vasileios Skaramagkas et al.",
      "keywords": "Deep learning; Interpretability; Artificial intelligence; Machine learning; Modalities; Computer science; Disease; Parkinson's disease; Data science; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tnsre.2023.3277749",
      "cited_by_count": 85,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2977063526",
      "doi": "10.1109/access.2019.2943197",
      "title": "Dual-Input Neural Network Integrating Feature Extraction and Deep Learning for Coronary Artery Disease Detection Using Electrocardiogram and Phonocardiogram",
      "abstract": "Electrocardiogram (ECG) and phonocardiogram (PCG) signals reflect the electrical and mechanical activities of the heart, respectively. Although studies have documented that some abnormalities in ECG and PCG signals are associated with coronary artery disease (CAD), only few researches have combined the two signals for automatic CAD detection. This paper aims to differentiate between CAD and non-CAD groups using simultaneously collected ECG and PCG signals. To entirely exploit the underlying information in these signals, a novel dual-input neural network that integrates the feature extraction and deep learning methods is developed. First, the ECG and PCG features are extracted from multiple domains, and the information gain ratio is used to select important features. On the other hand, the ECG signal and the decomposed PCG signal (at four scales) are concatenated as a five-channel signal. Then, the selected features and the five-channel signal are fed into the proposed network composed of a fully connected model and a deep learning model. The results show that the classification performance of either feature extraction or deep learning is insufficient when using only ECG or PCG signal, and combining the two signals improves the performance. Further, when using the proposed network, the best result is obtained with accuracy, sensitivity, specificity, and G-mean of 95.62%, 98.48%, 89.17%, and 93.69%, respectively. Comparisons with existing studies demonstrate that the proposed network can effectively capture the combined information of ECG and PCG signals for the recognition of CAD.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Li Han et al.",
      "keywords": "Phonocardiogram; Computer science; Feature extraction; Artificial intelligence; Artificial neural network; Deep learning; Pattern recognition (psychology); Cardiology; Internal medicine; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2943197",
      "cited_by_count": 84,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2133508860",
      "doi": "10.1109/jtehm.2014.2310480",
      "title": "Acoustic Analysis of Inhaler Sounds From Community-Dwelling Asthmatic Patients for Automatic Assessment of Adherence",
      "abstract": "Inhalers are devices which deliver medication to the airways in the treatment of chronic respiratory diseases. When used correctly inhalers relieve and improve patients' symptoms. However, adherence to inhaler medication has been demonstrated to be poor, leading to reduced clinical outcomes, wasted medication, and higher healthcare costs. There is a clinical need for a system that can accurately monitor inhaler adherence as currently no method exists to evaluate how patients use their inhalers between clinic visits. This paper presents a method of automatically evaluating inhaler adherence through acoustic analysis of inhaler sounds. An acoustic monitoring device was employed to record the sounds patients produce while using a Diskus dry powder inhaler, in addition to the time and date patients use the inhaler. An algorithm was designed and developed to automatically detect inhaler events from the audio signals and provide feedback regarding patient adherence. The algorithm was evaluated on 407 audio files obtained from 12 community dwelling asthmatic patients. Results of the automatic classification were compared against two expert human raters. For patient data for whom the human raters Cohen's kappa agreement score was [Formula: see text], results indicated that the algorithm's accuracy was 83% in determining the correct inhaler technique score compared with the raters. This paper has several clinical implications as it demonstrates the feasibility of using acoustics to objectively monitor patient inhaler adherence and provide real-time personalized medical care for a chronic respiratory illness.",
      "year": "2014",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Martin S. Holmes et al.",
      "keywords": "Inhaler; Medicine; Dry-powder inhaler; Physical therapy; Asthma; Intensive care medicine; Medical emergency; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2014.2310480",
      "cited_by_count": 69,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2901208063",
      "doi": "10.1109/access.2018.2881001",
      "title": "Mobile Health Technologies for Diabetes Mellitus: Current State and Future Challenges",
      "abstract": "The prevalence of diabetes is rising globally. Diabetes patients need continuous monitoring, and to achieve this objective, they have to be engaged in their healthcare management process. Mobile health (MH) is an information and communications technology trend to empower chronically ill patients in a smart environment. Discussing the current state of MH technologies is required in order to address their limitations. Existing review articles have evaluated the MH literature based on applicability and level of adoption by patients and healthcare providers. Most of these reviews asserted that MH apps and research have not reached a stable level yet. To the best of our knowledge, there is no clear description of solutions to these problems. In addition, no one has investigated and analyzed MH in its contextual environment in a detailed way. We conducted a comprehensive survey of MH research on diabetes management articles published between 2011 and September 27, 2017. In this survey, we discuss current challenges in MH, along with research gaps, opportunities, and trends. Our literature review searched three academic databases (ScienceDirect, IEEE Xplore, and SpringerLink). A total of 60 articles were analyzed, with 30% from ScienceDirect, 38% from IEEE Xplore, and 32% from SpringerLink. MH was analyzed in the context of the electronic health record (EHR) ecosystem. We consider dimensions such as clinical decision support systems, EHRs, cloud computing, semantic interoperability, wireless body area networks, and big data analytics. We propose specific metrics to analyze and evaluate MH from each of these dimensions. A comprehensive analysis of the literature from this viewpoint is valuable for both theoretical and developmental progress. This paper provides a critical analysis of challenges that have not been fully met and highlights directions for future research that could improve MH applicability.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Shaker El\u2013Sappagh et al.",
      "keywords": "Interoperability; Context (archaeology); Computer science; Analytics; Cloud computing; Health care; Data science; Semantic interoperability; Knowledge management; World Wide Web; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2881001",
      "cited_by_count": 52,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3029498479",
      "doi": "10.1109/mprv.2020.2986767",
      "title": "Leveraging IoTs and Machine Learning for Patient Diagnosis and Ventilation Management in the Intensive Care Unit",
      "abstract": "Future healthcare systems will rely heavily on clinical decision support systems (CDSS) to improve the decision-making processes of clinicians. To explore the design of future CDSS, we developed a research-focused CDSS for the management of patients in the intensive care unit that leverages Internet of Things (IoT) devices capable of collecting streaming physiologic data from ventilators and other medical devices. We then created machine learning (ML) models that could analyze the collected physiologic data to determine if the ventilator was delivering potentially harmful therapy and if a deadly respiratory condition, acute respiratory distress syndrome (ARDS), was present. We also present work to aggregate these models into a mobile application that can provide responsive, real-time alerts of changes in ventilation to providers. As illustrated in the recent COVID-19 pandemic, being able to accurately predict ARDS in newly infected patients can assist in prioritizing care. We show that CDSS may be used to analyze physiologic data for clinical event recognition and automated diagnosis, and we also highlight future research avenues for hospital CDSS.",
      "year": "2020",
      "journal": "IEEE Pervasive Computing",
      "authors": "Gregory B. Rehm et al.",
      "keywords": "Computer science; Intensive care unit; Clinical decision support system; ARDS; Decision support system; Acute respiratory distress; Medical emergency; Intensive care medicine; Artificial intelligence; Medicine; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mprv.2020.2986767",
      "cited_by_count": 44,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3158255125",
      "doi": "10.1109/jsen.2021.3076412",
      "title": "Artificial Olfaction in the 21<sup>st</sup> Century",
      "abstract": "The human olfactory system remains one of the most challenging biological systems to replicate. Humans use it without thinking, where it can measure offer protection from harm and bring enjoyment in equal measure. It is the system\u2019s real-time ability to detect and analyze complex odors that makes it difficult to replicate. The field of artificial olfaction has recruited and stimulated interdisciplinary research and commercial development for several applications that include malodor measurement, medical diagnostics, food and beverage quality, environment and security. Over the last century, innovative engineers and scientists have been focused on solving a range of problems associated with measurement and control of odor. The IEEE Sensors Journal has published Special Issues on olfaction in 2002 and 2012. Here we continue that coverage. In this article, we summarize early work in the 20th Century that served as the foundation upon which we have been building our odor-monitoring instrumental and measurement systems. We then examine the current state of the art that has been achieved over the last two decades as we have transitioned into the 21st Century. Much has been accomplished, but great progress is needed in sensor technology, system design, product manufacture and performance standards. In the final section, we predict levels of performance and ubiquitous applications that will be realized during in the mid to late 21st Century.",
      "year": "2021",
      "journal": "IEEE Sensors Journal",
      "authors": "James A. Covington et al.",
      "keywords": "Replicate; Computer science; Olfaction; Artificial intelligence; Product (mathematics); Psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2021.3076412",
      "cited_by_count": 93,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3027068985",
      "doi": "10.1109/access.2020.2996302",
      "title": "Integrating Co-Clustering and Interpretable Machine Learning for the Prediction of Intravenous Immunoglobulin Resistance in Kawasaki Disease",
      "abstract": "Identifying intravenous immunoglobulin-resistant patients is essential for the prompt and optimal treatment of Kawasaki disease, suggesting the need for effective risk assessment tools. Data-driven approaches have the potential to identify the high-risk individuals by capturing the complex patterns of real-world data. To enable clinically applicable prediction of intravenous immunoglobulin resistance addressing the incompleteness of clinical data and the lack of interpretability of machine learning models, a multi-stage method is developed by integrating data missing pattern mining and intelligible models. First, co-clustering is adopted to characterize the block-wise data missing patterns by simultaneously grouping the clinical features and patients to enable (a) group-based feature selection and missing data imputation and (b) patient subgroup-specific predictive models considering the availability of data. Second, feature selection is performed using the group Lasso to uncover group-specific risk factors. Third, the Explainable Boosting Machine, which is an interpretable learning method based on generalized additive models, is applied for the prediction of each patient subgroup. The experiments using real-world Electronic Health Records demonstrate the superior performance of the proposed framework for predictive modeling compared with a set of benchmark methods. This study highlights the integration of co-clustering and supervised learning methods for incomplete clinical data mining, and promotes data-driven approaches to investigate predictors and effective algorithms for decision making in healthcare.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Haolin Wang et al.",
      "keywords": "Interpretability; Machine learning; Computer science; Cluster analysis; Artificial intelligence; Missing data; Feature selection; Imputation (statistics); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2996302",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3214894867",
      "doi": "10.1109/access.2021.3130889",
      "title": "Fault Identification of Photovoltaic Array Based on Machine Learning Classifiers",
      "abstract": "Fault identification in Photovoltaic (PV) array is a contemporary research topic motivated by the higher penetration levels of PV systems in recent electrical grids. Therefore, this work aims to define an optimal Machine learning (ML) structure of automatic detection and diagnosis algorithm for common PV array faults, namely, permanent (Arc Fault, Line-to-Line, Maximum Power Point Tracking unit failure, and Open-Circuit faults), and temporary (Shading) under a wide range of climate datasets, fault impedances, and shading scenarios. To achieve the best-fit ML structure, three distinct ML classifiers are compared, namely, Decision Tree (DT) based on different splitting criteria, K-Nearest Neighbors (KNN) based on the different metrics of distance and weighting functions, and Support Vector Machine (SVM) based on different Kernel functions and multi-classification approaches. Also, Bayesian Optimization is adopted to assign the optimal hyperparameters to the fault classifiers. To investigate the performance of classifiers reported, both simulation and experimental case studies are carried out and presented.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mohamed M. Badr et al.",
      "keywords": "Photovoltaic system; Computer science; Identification (biology); Fault (geology); Pattern recognition (psychology); Artificial intelligence; Machine learning; Fault detection and isolation; Engineering; Electrical engineering; Actuator",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3130889",
      "cited_by_count": 76,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3108203525",
      "doi": "10.1109/tcds.2021.3079712",
      "title": "Deep Learning in EEG: Advance of the Last Ten-Year Critical Period",
      "abstract": "Deep learning has achieved excellent performance in a wide range of domains,\\nespecially in speech recognition and computer vision. Relatively less work has\\nbeen done for EEG, but there is still significant progress attained in the last\\ndecade. Due to the lack of a comprehensive and topic widely covered survey for\\ndeep learning in EEG, we attempt to summarize recent progress to provide an\\noverview, as well as perspectives for future developments. We first briefly\\nmention the artifacts removal for EEG signal and then introduce deep learning\\nmodels that have been utilized in EEG processing and classification.\\nSubsequently, the applications of deep learning in EEG are reviewed by\\ncategorizing them into groups such as brain-computer interface, disease\\ndetection, and emotion recognition. They are followed by the discussion, in\\nwhich the pros and cons of deep learning are presented and future directions\\nand challenges for deep learning in EEG are proposed. We hope that this paper\\ncould serve as a summary of past work for deep learning in EEG and the\\nbeginning of further developments and achievements of EEG studies based on deep\\nlearning.\\n",
      "year": "2021",
      "journal": "IEEE Transactions on Cognitive and Developmental Systems",
      "authors": "Shu Gong et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcds.2021.3079712",
      "cited_by_count": 101,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2960193895",
      "doi": "10.1109/access.2019.2928363",
      "title": "Deep Learning for Electronic Health Records Analytics",
      "abstract": "Recent technological advancements have led to a deluge of medical data from various domains. However, the recorded data from divergent sources comes poorly annotated, noisy, and unstructured. Hence, the data is not fully leveraged to establish actionable insights that can be used in clinical applications. These data recorded in hospital's Electronic Health Records (EHR) consists of patient information, clinical notes, charted events, medications, procedures, laboratory test results, diagnosis codes, and so on. Traditional machine learning and statistical methods have failed to offer insights that can be used by physicians to treat patients as they need to obtain an expert opinion assisted features before building a benchmark task model. With the rise of deep learning methods, there is a need to understand how deep learning can save lives. The purpose of this study was to offer an intuitive explanation for possible use cases of deep learning with EHR. We reflect on techniques that can be applied by health informatics professionals by giving technical intuitions and blue prints on how each clinical task can be approached by a deep learning algorithm.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Gaspard Harerimana et al.",
      "keywords": "Computer science; Health records; Deep learning; Analytics; Data science; Artificial intelligence; Electronic health record; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2928363",
      "cited_by_count": 52,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2900891490",
      "doi": "10.1109/jsen.2018.2880194",
      "title": "Wrist-Worn Gesture Sensing With Wearable Intelligence",
      "abstract": "This paper presents an innovative wrist-worn device with machine learning capabilities and a wearable pressure sensor array. The device is used for monitoring different hand gestures by tracking tendon movements around the wrist. Thus, an array of PDMS-encapsulated capacitive pressure sensors is attached to the user to capture wrist movement. The sensors are embedded on a flexible substrate and their readout requires a reliable approach for measuring small changes in capacitance. This challenge was addressed by measuring the capacitance via the switched capacitor method. The values were processed using a programme on LabVIEW to visually reconstruct the gestures on a computer. Additionally, to overcome limitations of tendon\u2019s uncertainty when the wristband is re-worn, or the user is changed, a calibration step based on the Support Vector Machine (SVM) learning technique is implemented. Sequential Minimal Optimization (SMO) algorithm is also applied in the system to generate SVM classifiers efficiently in real-time. The working principle and the performance of the SVM algorithms demonstrate through experiments. Three discriminated gestures have been clearly separated by SVM hyperplane and correctly classified with high accuracy (&gt;90%) during real-time gesture recognition.",
      "year": "2018",
      "journal": "IEEE Sensors Journal",
      "authors": "Xiangpeng Liang et al.",
      "keywords": "Gesture; Support vector machine; Wearable computer; Capacitive sensing; Artificial intelligence; Computer science; Computer vision; Gesture recognition; Benchmark (surveying); Capacitance; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2018.2880194",
      "cited_by_count": 64,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4327808499",
      "doi": "10.1109/access.2023.3258549",
      "title": "A Diabetes Monitoring System and Health-Medical Service Composition Model in Cloud Environment",
      "abstract": "Diabetes is a common chronic illness or absence of sugar in the blood. The early detection of this disease decreases the serious risk factor. Nowadays, Machine Learning based cloud environment acts as a vital role in disease detection. The people who belong to the rural areas are not getting the proper health care treatments. So, this research work proposed an automated eHealth cloud system for detecting diabetes in the earlier stage to decrease the mortality rate and provides health treatment facilities to rural peoples. Extreme Learning Machine (ELM) is a type of Artificial Neural Network (ANN) that has a lot of potential for solving classification challenges. This research work is consisting of several activities like feature normalization, feature selection and classification. We have employed principal component analysis (PCA) for feature selection and extreme learning machine (ELM) for classification. Finally, a cloud computing-based environment with three numbers of virtual machines (vCPU-4, vCPU-8, and vCPU-16), is used for the detection of diabetes. The efficacy of the proposed model has been evaluated with the PIMA dataset in both standalone and cloud environments and achieved 90.57 &#x0025; accuracy, 82.24 &#x0025; sensitivity, 73.23 &#x0025; specificity, and 75.03 &#x0025; F-1 score with the virtual machine vCPU-16. The experimental results define the proposed model as superior to other state-of-art models with better classification accuracy and less number of features.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Santosh Kumar Sharma et al.",
      "keywords": "Cloud computing; Computer science; Machine learning; Artificial intelligence; Feature selection; Extreme learning machine; Artificial neural network; Principal component analysis; Virtual machine; Normalization (sociology); Data mining; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3258549",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2945456554",
      "doi": "10.1109/access.2019.2916922",
      "title": "The Neural Network of One-Dimensional Convolution-An Example of the Diagnosis of Diabetic Retinopathy",
      "abstract": "Diabetes is a serious threat to health development, because diabetes is a disease that caused most other diseases (complications). Diabetic retinopathy is the most important manifestation of diabetic microangiopathy and is also one of the most common complications in people with diabetes. At present, the diagnosis of diabetic retinal complications mainly depends on the pictures for diagnosis. The fundus images are the main ways to diagnose retinal diseases at present, but the diagnosis process is complicated. Based on this, this paper uses the electronic medical record information of 301 hospitalized patients with diabetes from 2009 to 2013, mainly using the diabetes diagnostic data, diabetes glycosylation data and diabetes biochemical test data, the depth of learning methods and medical diabetes combined with the application of convolution Neural Network Method (CNN) to build a diagnostic model, and thus draw the diagnosis. The main contribution of this study is twofold: 1) In this paper, we apply the CNN method to one-dimensional unrelated data sets and solve the problem of how to do one-dimensional irrelevant data convolution. 2) In this paper, the CNN model is combined with the BN layer to prevent the dispersion of the gradient, speed up the training speed and improve the accuracy of the model. In addition, this model incorporates an adaptive learning rate algorithm and optimizes the model. The experiments show that this method can achieve a training accuracy of 99.85% and a testing accuracy of 97.56%, which is more than 2% higher than that of using logistic regression. The model methods involved in this study can not only be used for the diagnosis of diabetic retinopathy, but also for the diagnosis of other diseases, such as chronic kidney disease, cardiovascular, and cerebrovascular diseases.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yunlei Sun",
      "keywords": "Diabetic retinopathy; Computer science; Diabetes mellitus; Convolutional neural network; Artificial intelligence; Artificial neural network; Logistic regression; Fundus (uterus); Deep learning; Optometry; Pattern recognition (psychology); Medicine; Machine learning; Ophthalmology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2916922",
      "cited_by_count": 51,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2908591466",
      "doi": "10.1109/access.2019.2890865",
      "title": "A Novel Wearable Electrocardiogram Classification System Using Convolutional Neural Networks and Active Learning",
      "abstract": "Arrhythmias reflect electrical abnormalities of the heart, and they can lead to severe harm to the heart. An electrocardiogram (ECG) is a useful tool to manifest arrhythmias. In this paper, we present an automatic system using a convolutional neural network and active learning to classify ECG signals. To improve the model performance, breaking-ties (BT) and modified BT algorithms are utilized in the active learning. We classify ECG signals in five heartbeat types, i.e., normal (N), ventricular (V), supraventricular (S), fusion of normal and ventricular (F), and unknown heartbeats (Q), using the Association for the Advancement of Medical Instrumentation standard. Our experiments are performed on the MIT-BIH arrhythmia database. To further verify the generalization capability of the system, the ECG data that acquired from our wearable device are also used to conduct in the experiments. Compared with most of the state-of-the-art methods, the obtained results demonstrate that the presented method promotes the classification performance remarkably.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yufa Xia et al.",
      "keywords": "Heartbeat; Computer science; Artificial intelligence; Convolutional neural network; Wearable computer; Generalization; Electrocardiography; Artificial neural network; Machine learning; Deep learning; Pattern recognition (psychology); Supraventricular arrhythmia; Cardiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2890865",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2979602634",
      "doi": "10.1109/access.2019.2946622",
      "title": "Regular Expression Based Medical Text Classification Using Constructive Heuristic Approach",
      "abstract": "Medical text classi_cation assigns medical related text into different categories such as topics or disease types. Machine learning based techniques have been widely used to perform such tasks despite the obvious drawback in such ``black box'' approach, leaving no easy way to _ne-tune the resultant model for better performance. We propose a novel constructive heuristic approach to generate a set of regular expressions that can be used as effective text classi_ers. The main innovation of our approach is that we develop a novel regular expression based text classi_er with both satisfactory classi_cation performance and excellent interpretability.We evaluate our framework on real-world medical data provided by our collaborator, one of the largest online healthcare providers in the market, and observe the high performance and consistency of this approach. Experimental results show that the machine-generated regular expressions can be effectively used in conjunction with machine learning techniques to perform medical text classi_cation tasks. The proposed methodology improves the performance of baseline methods (Naive Bayes and Support Vector Machines) by 9% in precision and 4:5% in recall. We also evaluate the performance of modi_ed regular expressions by human experts and demonstrate the potential of practical applications using the proposed method.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Menglin Cui et al.",
      "keywords": "Computer science; Constructive; Regular expression; Heuristic; Expression (computer science); Artificial intelligence; Natural language processing; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2946622",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2993413119",
      "doi": "10.1109/access.2019.2957367",
      "title": "A New Hybrid XGBSVM Model: Application for Hypertensive Heart Disease",
      "abstract": "The changes in people's life rhythm and improvement in material levels that happened in recent years increased the number of people suffering from high blood pressure in the world. Therefore, as a cardiac complication of hypertension, the prevalence of hypertensive heart disease has increased annually, it has seriously endangered the safety of human life, and the effective prediction of hypertensive heart disease has become a worldwide problem. This paper uses the newly proposed XGBSVM hybrid model to predict whether hypertensive patients will develop hypertensive heart disease within three years. The final experiment proves that through this model, hypertensive patients can learn their risk of hypertensive heart disease within 3 years and then undergo targeted preventive treatment, thereby reducing the psychological, physiological and economic burden. This paper confirms that the machine learning can be successfully applied in the biomedical field, with strong real-world significance and research value.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Wenbing Chang et al.",
      "keywords": "Hypertensive heart disease; Disease; Blood pressure; Medicine; Heart disease; Cardiology; Internal medicine; Intensive care medicine; Heart failure",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2957367",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391342283",
      "doi": "10.1109/access.2024.3359760",
      "title": "Improving Healthcare Prediction of Diabetic Patients Using KNN Imputed Features and Tri-Ensemble Model",
      "abstract": "Objective: Diabetes ranks as the most prevalent ailment in developing nations. Vital steps to mitigate the consequences of diabetes include early detection and expert medical intervention. A highly effective approach for identifying diabetes involves assessing the specific indicators associated with this condition. When it comes to automated diabetes detection, frequently encountered datasets frequently exhibit gaps in data, which can markedly impact the effectiveness of machine learning models. Methods: The aim of this study is to propose an automated method for predicting diabetes, with a focus on appropriately dealing with missing data and improving accuracy. The proposed framework makes use of K-Nearest Neighbour (KNN) imputed features along with a Tri-ensemble voting classifier model. Results: By incorporating the KNN imputer, the presented model demonstrates impressive performance metrics, including an accuracy of 97.49&#x0025;, precision of 98.16&#x0025;, recall of 99.35&#x0025;, and an F1 score of 98.84&#x0025;. The study conducted a thorough comparison of this proposed model against seven alternative machine learning algorithms, assessing them under two conditions: one with omitted missing values and another with the KNN imputer applied. These findings support the proposed model&#x2019;s efficacy, highlighting its superiority over currently established state-of-the-art techniques. Conclusion: This research explores the problem of missing data in diabetes diagnosis and highlights the efficacy of the KNN-imputed technique. The results are promising for healthcare practitioners as they could facilitate early detection and improve the quality of diabetic patient care.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Khaled Alnowaiser",
      "keywords": "Computer science; Ensemble forecasting; Artificial intelligence; Health care; Ensemble learning; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3359760",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3126999565",
      "doi": "10.1109/tbme.2021.3058781",
      "title": "ECG Beat Representation and Delineation by Means of Variable Projection",
      "abstract": "Our method is able to capture linear and nonlinear wave shape changes. Therefore, it provides a novel methodology to understand the origin of morphological variations caused, for instance, by respiration, medication, and abnormalities.",
      "year": "2021",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Carl B\u00f6ck et al.",
      "keywords": "Beat (acoustics); Segmentation; Pattern recognition (psychology); Artificial intelligence; Piecewise; Computer science; Hermite interpolation; Nonlinear system; Noise reduction; Waveform; Speech recognition; Algorithm; Mathematics; Hermite polynomials; Acoustics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2021.3058781",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3150741721",
      "doi": "10.1109/access.2021.3069937",
      "title": "Intelligent Pneumonia Identification From Chest X-Rays: A Systematic Literature Review",
      "abstract": "Chest radiography is a significant diagnostic tool used to detect diseases afflicting the chest. The automatic detection techniques associated with computer vision are being adopted in medical imaging research. Over the last decade, several remarkable advancements have been made in the field of medical diagnostics with the application of deep learning techniques. Various automated systems have been proposed for the rapid detection of pneumonia from chest X-rays. Although several algorithms are currently available for pneumonia detection, a detailed review summarizing the literature and offering guidelines for medical practitioners is lacking. This study will help practitioners to select the most effective and efficient methods from a real-time perspective, review the available datasets, and understand the results obtained in this domain. It will also present an overview of the literature on intelligent pneumonia identification from chest X-rays. The usability, goodness factors, and computational complexities of the algorithms employed for intelligent pneumonia identification are analyzed. Additionally, this study discusses the quality, usability, and size of the available chest X-ray datasets and techniques for coping with unbalanced datasets. A detailed comparison of the available studies reveals that the majority of the applied datasets are highly unbalanced and limited, providing unreliable results and rendering methods that are unsuitable for large-scale use. Large-scale balanced datasets can be obtained via smart techniques, such as generative adversarial networks. Current literature has indicated that deep learning-based algorithms achieve the best results for pneumonia classification with an accuracy of 98.7&#x0025;, a sensitivity of 0.99, and a specificity of 0.98. The higher accuracy offered by deep-learning algorithms in addition to their appropriate class balancing techniques serves as a good reference for further research.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Wasif Khan et al.",
      "keywords": "Usability; Computer science; Artificial intelligence; Machine learning; Identification (biology); Pneumonia; Deep learning; Rendering (computer graphics); Data science; Medicine; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3069937",
      "cited_by_count": 91,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3196807348",
      "doi": "10.1109/access.2021.3110336",
      "title": "Explainable Artificial Intelligence Based Framework for Non-Communicable Diseases Prediction",
      "abstract": "The rapid rise of non-communicable diseases (NCDs) becomes one of the serious health issues and the leading cause of death worldwide. In recent years, artificial intelligence-based systems have been developed to assist clinicians in decision-making to reduce morbidity and mortality. However, a common drawback of these modern studies is related to explanations of their output. In other words, understanding the inner logic behind the predictions is hidden to the end-user. Thus, clinicians struggle to interpret these models because of their black-box nature, and hence they are not acceptable in the medical practice. To address this problem, we have proposed a Deep Shapley Additive Explanations (DeepSHAP) based deep neural network framework equipped with a feature selection technique for NCDs prediction and explanation among the population in the United States. Our proposed framework comprises three components: First, representative features are done based on the elastic net-based embedded feature selection technique; second a deep neural network classifier is tuned with the hyper-parameters and used to train the model with the selected feature subset; third, two kinds of model explanation are provided by the DeepSHAP approach. Herein, (I) explaining the risk factors that affected the model&#x2019;s prediction from the population-based perspective; (II) aiming to explain a single instance from the human-centered perspective. The experimental results indicated that the proposed model outperforms various state-of-the-art models. In addition, the proposed model can improve the medical understanding of NCDs diagnosis by providing general insights into the changes in disease risk at the global and local levels. Consequently, DeepSHAP based explainable deep learning framework contributes not only to the medical decision support systems but also can provide to real-world needs in other domains.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Khishigsuren Davagdorj et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3110336",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3184579817",
      "doi": "10.1109/jtehm.2021.3098173",
      "title": "Using Wearables and Machine Learning to Enable Personalized Lifestyle Recommendations to Improve Blood Pressure",
      "abstract": "<i>Background:</i> Blood pressure (BP) is an essential indicator for human health and is known to be greatly influenced by lifestyle factors, like activity and sleep factors. However, the degree of impact of each lifestyle factor on BP is unknown and may vary between individuals. Our goal is to investigate the relationships between BP and lifestyle factors and provide personalized and precise recommendations to improve BP, as opposed to the current practice of general lifestyle recommendations. <i>Method:</i> Our proposed system consists of automated data collection using home BP monitors and wearable activity trackers and feature engineering techniques to address time-series data and enhance interpretability. We propose Random Forest with Shapley-Value-based Feature Selection to offer personalized BP modeling and top lifestyle factor identification, and subsequent generation of precise recommendations based on the top factors. <i>Result:</i> In collaboration with UC San Diego Health and Altman Clinical and Translational Research Institute, we performed a clinical study, applying our system to 25 patients with elevated BP or stage I hypertension for three consecutive months. Our study results validate our system's ability to provide accurate personalized BP models and identify the top features which can vary greatly between individuals. We also validate the effectiveness of personalized recommendations in a randomized controlled experiment. After receiving recommendations, the subjects in the experimental group decreased their BPs by 3.8 and 2.3 for systolic and diastolic BP, compared to the decrease of 0.3 and 0.9 for the subjects without recommendations. <i>Conclusion:</i> The study demonstrates the potential of using wearables and machine learning to develop personalized models and precise lifestyle recommendations to improve BP.",
      "year": "2021",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Po-Han Chiang et al.",
      "keywords": "Interpretability; Wearable computer; Blood pressure; Medicine; Random forest; Identification (biology); Machine learning; Computer science; Feature selection; Feature engineering; Activity tracker; Artificial intelligence; Physical activity; Physical therapy; Deep learning; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2021.3098173",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2998047037",
      "doi": "10.1109/access.2020.3027497",
      "title": "Unsupervised Domain Adversarial Self-Calibration for Electromyography-Based Gesture Recognition",
      "abstract": "Surface electromyography (sEMG) provides an intuitive and non-invasive interface from which to control machines. However, preserving the myoelectric control system's performance over multiple days is challenging, due to the transient nature of the signals obtained with this recording technique. In practice, if the system is to remain usable, a time-consuming and periodic recalibration is necessary. In the case where the sEMG interface is employed every few days, the user might need to do this recalibration before every use. Thus, severely limiting the practicality of such a control method. Consequently, this paper proposes tackling the especially challenging task of unsupervised adaptation of sEMG signals, when multiple days have elapsed between each recording, by introducing Self-Calibrating Asynchronous Domain Adversarial Neural Network (SCADANN). SCADANN is compared with two state-of-the-art self-calibrating algorithms developed specifically for deep learning within the context of EMG-based gesture recognition and three state-of-the-art domain adversarial algorithms. The comparison is made both on an offline and a dynamic dataset (20 participants per dataset), using two different deep network architectures with two different input modalities (temporal-spatial descriptors and spectrograms). Overall, SCADANN is shown to substantially and systematically improves classification performances over no recalibration and obtains the highest average accuracy for all tested cases across all methods.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ulysse C\u00f4t\u00e9\u2010Allard et al.",
      "keywords": "Computer science; Artificial intelligence; Context (archaeology); Task (project management); Artificial neural network; Pattern recognition (psychology); Gesture; Speech recognition; Asynchronous communication; Domain (mathematical analysis); Gesture recognition; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3027497",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2163211991",
      "doi": "10.1109/tnsre.2014.2360149",
      "title": "Assessing Upper Extremity Motor Function in Practice of Virtual Activities of Daily Living",
      "abstract": "A study was conducted to investigate the criterion validity of measures of upper extremity (UE) motor function derived during practice of virtual activities of daily living (ADLs). Fourteen hemiparetic stroke patients employed a Virtual Occupational Therapy Assistant (VOTA), consisting of a high-fidelity virtual world and a Kinect\u2122 sensor, in four sessions of approximately one hour in duration. An unscented Kalman Filter-based human motion tracking algorithm estimated UE joint kinematics in real-time during performance of virtual ADL activities, enabling both animation of the user's avatar and automated generation of metrics related to speed and smoothness of motion. These metrics, aggregated over discrete sub-task elements during performance of virtual ADLs, were compared to scores from an established assessment of UE motor performance, the Wolf Motor Function Test (WMFT). Spearman's rank correlation analysis indicates a moderate correlation between VOTA-derived metrics and the time-based WMFT assessments, supporting the criterion validity of VOTA measures as a means of tracking patient progress during an UE rehabilitation program that includes practice of virtual ADLs.",
      "year": "2014",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Richard J. Adams et al.",
      "keywords": "Activities of daily living; Virtual reality; Computer science; Physical medicine and rehabilitation; Virtual machine; Kinematics; Motor function; Simulation; Physical therapy; Artificial intelligence; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2014.2360149",
      "cited_by_count": 65,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3194387770",
      "doi": "10.1109/access.2021.3107484",
      "title": "Data Vaults for Blockchain-Empowered Accounting Information Systems",
      "abstract": "When designed, technologies and frameworks are not created to be as dynamic and flexible as to cater to the requirements of other domains, and so is the case with Blockchain technology. Specifically designed for cryptocurrency, Blockchain was not intended to be used in other domains. However, during the past few years, critics argued that Blockchain has the potential to deal with some unique requirements like confidentiality and immutability and can therefore be deployed in several areas other than cryptocurrency. The use of Blockchain to support Accounting Information Systems (AIS) through enterprise resource planning (ERP) is another motivating domain to investigate in this research. ERP is another promising technology that has gained significant attention across the globe. In this research, a hybrid solution is proposed to ensure AIS data integrity against any deliberate attempt or mala-fide intention for alteration or deletion from the database that can be verified at any later stage. Since Blockchain can be used to prevent any mutability in the stored data, the proposed solution presents a concept of Data Vaults backed by the Blockchain. To this end, we apply cryptographic primitives like SHA256 on the data inside the block and then chain that block to secure data vaults. So far, Blockchain has not yet proven itself as an alternative to any traditional database system. However, it can be applied in conjunction with the Relational Database Management Systems (RDBMS) to provide cost-effective yet robust solutions. This research demonstrates the application of a simple and lean version of Blockchain to assist enterprises in storing their financial and accounting data into data vaults, ensuring their data integrity against any alterations. The suggested cost-effective framework can be easily integrated into AIS and ERP systems to identify data breaches.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Muhammad Imran Sarwar et al.",
      "keywords": "Blockchain; Immutability; Cryptocurrency; Computer science; Relational database management system; Cryptography; Computer security; Enterprise resource planning; Data integrity; Database; Block (permutation group theory); Distributed database; Data science; Relational database; Knowledge management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3107484",
      "cited_by_count": 69,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4285229700",
      "doi": "10.1109/access.2022.3178710",
      "title": "New Hybrid Deep Learning Approach Using BiGRU-BiLSTM and Multilayered Dilated CNN to Detect Arrhythmia",
      "abstract": "Deep learning methods have shown early progress in analyzing complicated ECG signals, especially in heartbeat classification and arrhythmia detection. However, there is still a long way to go in terms of health-related data analysis. This research provides a duel structured and bidirectional Recurrent Neural Network(RNN) method for arrhythmia classification that addresses the issues with multilayered dilated convolution neural network (CNN) models. Initially, the data is preprocessed by Chebyshev Type II filtering that is faster and do not use statistical characteristics. Noise from the preprocesed filter is aslo removed by using Daubechies wavelet that can able to solve fractal problems and signal discontinuities. An then Z-normalization is done using Pan-Tompkins normalization technique for handling of different normally distributed samples. Finally, a generative adversarial network (GAN)-based synthetic signal is generated for recreation of signal to handle imbalanced signal class. The proposed Bidirectional RNN with Dilated CNN (BRDC) appears to take advantage of the potentiality of multilayered dilated CNN and bidirectional RNN unit (bidirectional gated recurrent Units, BiGRU - bidirectional long short-term memory, BiLSTM) architecture to generate fusion features. Finally, the signals are classified by fully connected layer and Rectified Linear Unit (ReLU) activation function. The PhysioNet 2017 challenge dataset is used to train and validate the proposed model. By combining fusion features with dilated CNN, the learned model significantly improves the classification performance and interpretability. The experimental findings show that, for MIT-BIH provided ECG (electrocardiogram) data to identify arrhythmia, the proposed BRDC model outperforms existing models with 99.90 % accuracy, 98.41 % F1, 97.96 % precision, and 99.90 % recall during training. One of the significant findings of this study is that the proposed approach can significantly reduce time length when employing RNN networks with multilayered dilated CNN. Overall, our hybrid model using BiGRU-BiLSTM and multi-layered dilated CNN provides a cost-effective ECG signal reduction and high-performance automated recognition technique to identify arrhythmia. Our future improvement will focus on the classification of numerous arrhythmia signal-based data, automatic and cloud based ECG classification.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Md Shofiqul Islam et al.",
      "keywords": "Computer science; Artificial intelligence; Pattern recognition (psychology); Deep learning; Convolutional neural network; Heartbeat; Robustness (evolution)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3178710",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3003566556",
      "doi": "10.1109/access.2020.2970178",
      "title": "A Novel Software Engineering Approach Toward Using Machine Learning for Improving the Efficiency of Health Systems",
      "abstract": "Recently, machine learning has become a hot research topic. Therefore, this study investigates the interaction between software engineering and machine learning within the context of health systems. We proposed a novel framework for health informatics: the framework and methodology of software engineering for machine learning in health informatics (SEMLHI). The SEMLHI framework includes four modules (software, machine learning, machine learning algorithms, and health informatics data) that organize the tasks in the framework using a SEMLHI methodology, thereby enabling researchers and developers to analyze health informatics software from an engineering perspective and providing developers with a new road map for designing health applications with system functions and software implementations. Our novel approach sheds light on its features and allows users to study and analyze the user requirements and determine both the function of objects related to the system and the machine learning algorithms that must be applied to the dataset. Our dataset used in this research consists of real data and was originally collected from a hospital run by the Palestine government covering the last three years. The SEMLHI methodology includes seven phases: designing, implementing, maintaining and defining workflows; structuring information; ensuring security and privacy; performance testing and evaluation; and releasing the software applications.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammed Moreb et al.",
      "keywords": "Computer science; Health informatics; Software engineering; Software system; Informatics; Context (archaeology); Software; Machine learning; Artificial intelligence; Health care; Engineering; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2970178",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4367727818",
      "doi": "10.1109/access.2023.3272556",
      "title": "Bio-Inspired Feature Selection Algorithms With Their Applications: A Systematic Literature Review",
      "abstract": "Based on the principles of the biological evolution of nature, bio-inspired algorithms are gaining popularity in developing robust techniques for optimization. Unlike gradient descent optimization methods, these metaheuristic algorithms are computationally less expensive, and can also considerably perform well with nonlinear and high-dimensional data. Objectives: To understand the algorithms, application domains, effectiveness, and challenges of bio-inspired feature selection techniques. Method: A systematic literature review is conducted on five major digital databases of science and engineering. Results: The primary search included 695 articles. After removing 263 duplicated articles, 432 studies remained to be screened. Among those, 317 irrelevant papers were removed. We then excluded 77 studies according to the exclusion criteria. Finally, 38 articles were selected for this study. Conclusion: Out of 38 studies, 28 papers discussed Swarm-based algorithms, 2 papers studied Genetic Algorithms, and 8 papers covered algorithms in both categories. Considering the application domains, 21 of the articles focused on problems in the healthcare sector, while the rest mainly investigated issues in cybersecurity, text classification, and image processing. Hybridization with other BIAs was employed by approximately 18.5&#x0025; of papers, and 13 out of 38 studies used S-shaped transfer functions. The majority of studies used supervised classification methods such as k-NN and SVM for building fitness functions. Accordingly, we conclude that future research should focus on applying bio-inspired feature selection to a diverse area of applications such as finance and social networks. And further exploration into enhancement techniques such as quantum representation, rough set theory, chaotic maps, and L&#x00E9;vy flight is necessary. Additionally, we suggest investigating other transfer functions besides S-shaped, such as V-shaped and X-shaped. Moreover, clustering and deep learning models for constructing fitness functions in bio-inspired feature selection algorithms need to be investigated further.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Tin H. Pham et al.",
      "keywords": "Computer science; Feature selection; Machine learning; Artificial intelligence; Metaheuristic; Particle swarm optimization; Algorithm; Support vector machine; Feature (linguistics); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3272556",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392173886",
      "doi": "10.1109/access.2024.3370848",
      "title": "Generative Adversarial Networks (GANs) in Medical Imaging: Advancements, Applications, and Challenges",
      "abstract": "Generative Adversarial Networks are a class of artificial intelligence algorithms that consist of a generator and a discriminator trained simultaneously through adversarial training. GANs have found crucial applications in various fields, including medical imaging. In healthcare, GANs contribute by generating synthetic medical images, enhancing data quality, and aiding in image segmentation, disease detection, and medical image synthesis. Their importance lies in their ability to generate realistic images, facilitating improved diagnostics, research, and training for medical professionals. Understanding its applications, algorithms, current advancements, and challenges is imperative for further advancement in the medical imaging domain. However, no study explores the recent state-of-the-art development of GANs in medical imaging. To overcome this research gap, in this extensive study, we began by exploring the vast array of applications of GANs in medical imaging, scrutinizing them within recent research. We then dive into the prevalent datasets and pre-processing techniques to enhance comprehension. Subsequently, an in-depth discussion of the GAN algorithms, elucidating their respective strengths and limitations, is provided. After that, we meticulously analyzed the results and experimental details of some recent cutting-edge research to obtain a more comprehensive understanding of the current development of GANs in medical imaging. Lastly, we discussed the diverse challenges encountered and future research directions to mitigate these concerns. This systematic review offers a complete overview of GANs in medical imaging, encompassing their application domains, models, state-of-the-art results analysis, challenges, and research directions, serving as a valuable resource for multidisciplinary studies.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Showrov Islam et al.",
      "keywords": "Adversarial system; Computer science; Generative grammar; Medical imaging; Artificial intelligence; Generative adversarial network; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3370848",
      "cited_by_count": 105,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3188077261",
      "doi": "10.1109/access.2021.3103047",
      "title": "Discriminative Power of EEG-Based Biomarkers in Major Depressive Disorder: A Systematic Review",
      "abstract": "This work was supported in part by the Project AutoNomous DiscoveRy Of depressIve Disorder Signs (ANDROIDS) through the Program VAnviteLli pEr la RicErca (V:ALERE) 2019 Universita della Campania ``Luigi Vanvitelli'' under Grant D.R.906del4/10/2019 and Grant prot.n.15726417/10/2019; in part by the EU H2020 Research and Innovation Program under Grant 769872 [Empathic, Expressive, Advanced Virtual Coach to Improve Independent Healthy-Life-Years of the Elderly (EMPATHIC)] and Grant 823907 [Mental health monitoring through interactive conversations (MENHIR)]; and in part by the Project SocIal ROBOTics for active and healthy ageing (SIROBOTICS) through Italian Ministero dell'istruzione, dell'universita e della ricerca (MIUR) under Grant PNR2015-2020, Grant D.D.1735, and Grant 13/07/2017.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Claudia Greco et al.",
      "keywords": "Electroencephalography; Scopus; Major depressive disorder; Extant taxon; Psychology; Clinical psychology; Computer science; Medicine; MEDLINE; Psychiatry; Mood",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3103047",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2738293192",
      "doi": "10.1109/tvcg.2017.2785271",
      "title": "KAVAGait: Knowledge-Assisted Visual Analytics for Clinical Gait Analysis",
      "abstract": "In 2014, more than 10 million people in the US were affected by an ambulatory disability. Thus, gait rehabilitation is a crucial part of health care systems. The quantification of human locomotion enables clinicians to describe and analyze a patient's gait performance in detail and allows them to base clinical decisions on objective data. These assessments generate a vast amount of complex data which need to be interpreted in a short time period. We conducted a design study in cooperation with gait analysis experts to develop a novel Knowledge-Assisted Visual Analytics solution for clinical Gait analysis (KAVAGait). KAVAGait allows the clinician to store and inspect complex data derived during clinical gait analysis. The system incorporates innovative and interactive visual interface concepts, which were developed based on the needs of clinicians. Additionally, an explicit knowledge store (EKS) allows externalization and storage of implicit knowledge from clinicians. It makes this information available for others, supporting the process of data inspection and clinical decision making. We validated our system by conducting expert reviews, a user study, and a case study. Results suggest that KAVAGait is able to support a clinician during clinical practice by visualizing complex gait data and providing knowledge of other clinicians.",
      "year": "2018",
      "journal": "IEEE Transactions on Visualization and Computer Graphics",
      "authors": "Markus Wagner et al.",
      "keywords": "Computer science; Gait analysis; Visual analytics; Gait; Knowledge base; Analytics; Human\u2013computer interaction; Process (computing); Data science; Decision tree; Visualization; Artificial intelligence; Physical medicine and rehabilitation; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tvcg.2017.2785271",
      "cited_by_count": 55,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3099007808",
      "doi": "10.1109/access.2020.3037710",
      "title": "A Novel Deep Similarity Learning Approach to Electronic Health Records Data",
      "abstract": "The past decade has seen a tremendous advancement in using Electronic Health Records (EHRs) to offer clinical decision support and provide personalized healthcare to patients. Despite the potential benefits offered by EHR data, it is challenging to represent and analyze large EHRs for predictive modeling due to heterogeneity, high dimensionality, and sparsity. This article proposes a novel supervised Deep Similarity Learning approach that learns the patient representations and also finds the relationship between the patients using pairwise similarity learning to facilitate predictive analysis for personalized healthcare. We develop CNN_Softmax which is a Siamese-based neural network for multi-class classification methods corresponding to the prediction of disease. It uses Convolutional Neural Network (CNN) to study the vector representation of raw EHRs and capture essential information of patient features, and a Softmax-based supervised classification method that learns the similarity between pairs of patients and performs disease prediction using this similarity information. Our approach uses data type mapping to handle heterogeneity and the polynomial interpolation method to handle sparsity existing in EHR data. ORBDA, which is an openEHR (standard) benchmark dataset, is used for evaluating this study. Experimental results show that CNN_Softmax achieves an accuracy of 97.8%, a recall of 98.1%, a precision of 96.02%, and an F1 score of 97.82%. The comparative results show that our proposed novel methodology performs disease prediction with highly promising results and outperforms state-of-the-art similarity learning methods. The current study is the first attempt to perform disease prediction on standardized EHRs, to the best of the authors' knowledge. The deep similarity learning approach provides support for clinical decision making that is more reliable and generalizable than previous approaches and focuses on dealing with heterogeneous and sparse data. The concept also serves as a new implementation of artificial intelligence technologies for the application of clinical big data.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Vagisha Gupta et al.",
      "keywords": "Softmax function; Computer science; Artificial intelligence; Machine learning; Convolutional neural network; Similarity (geometry); Benchmark (surveying); Deep learning; Pairwise comparison; Data mining; Precision and recall; Feature learning; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3037710",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3168324141",
      "doi": "10.1109/jbhi.2021.3088750",
      "title": "Stroke Risk Prediction With Hybrid Deep Transfer Learning Framework",
      "abstract": "Stroke has become a leading cause of death and long-term disability in the world with no effective treatment. Deep learning-based approaches have the potential to outperform existing stroke risk prediction models, but they rely on large well-labeled data. Due to the strict privacy protection policy in health-care systems, stroke data is usually distributed among different hospitals in small pieces. In addition, the positive and negative instances of such data are extremely imbalanced. Transfer learning can solve small data issue by exploiting the knowledge of a correlated domain, especially when multiple source of data are available. In this work, we propose a novel Hybrid Deep Transfer Learning-based Stroke Risk Prediction (HDTL-SRP) scheme to exploit the knowledge structure from multiple correlated sources (i.e., external stroke data, chronic diseases data, such as hypertension and diabetes). The proposed framework has been extensively tested in synthetic and real-world scenarios, and it outperforms the state-of-the-art stroke risk prediction models. It also shows the potential of real-world deployment among multiple hospitals aided with 5 G/B5G infrastructures.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Jie Chen et al.",
      "keywords": "Computer science; Transfer of learning; Stroke (engine); Deep learning; Artificial intelligence; Machine learning; Big data; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3088750",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2947746104",
      "doi": "10.1109/access.2019.2919494",
      "title": "Multi-Label Classification of Microblogging Texts Using Convolution Neural Network",
      "abstract": "Microblogging sites contain a huge amount of textual data and their classification is an imperative task in many applications, such as information filtering, user profiling, topical analysis, and content tagging. Traditional machine learning approaches mainly use a bag of words or n-gram techniques to generate feature vectors as text representation to train classifiers and perform considerably well for many text information processing tasks. Since short texts, such as tweets, contain a very limited number of words, the traditional machine learning approaches suffer from data sparsity and curse of dimensionality problems due to feature representation using a bag of words or n-grams techniques. Nowadays, the use of feature vectors, such as word embeddings, as an input to neural networks for text classification and clustering has shown a remarkable performance gain. In this paper, we present the different neural network models for multi-label classification of microblogging data. The proposed models are based on convolutional neural network (CNN) architectures, which utilize pre-trained word embeddings from generic and domain-specific textual data sources. The word embeddings are used individually and in various combinations through different channels of CNN to predict class labels. We also present a comparative analysis of the proposed CNN models with traditional machine learning models and one of the existing CNN architectures. The proposed models are evaluated over a real Twitter dataset, and the experimental results establish their efficacy to classify microblogging texts with improved accuracy in comparison with the traditional machine learning approaches and the existing CNN models.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Md. Aslam Parwez et al.",
      "keywords": "Computer science; Microblogging; Artificial intelligence; Convolutional neural network; Word2vec; Machine learning; Social media; Feature (linguistics); Curse of dimensionality; Cluster analysis; Artificial neural network; Word (group theory); Feature learning; Natural language processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2919494",
      "cited_by_count": 55,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4319777762",
      "doi": "10.1109/access.2023.3243854",
      "title": "A Systematic Literature Review on Multimodal Machine Learning: Applications, Challenges, Gaps and Future Directions",
      "abstract": "Multimodal machine learning (MML) is a tempting multidisciplinary research area where heterogeneous data from multiple modalities and machine learning (ML) are combined to solve critical problems. Usually, research works use data from a single modality, such as images, audio, text, and signals. However, real-world issues have become critical now, and handling them using multiple modalities of data instead of a single modality can significantly impact finding solutions. ML algorithms play an essential role in tuning parameters in developing MML models. This paper reviews recent advancements in the challenges of MML, namely: representation, translation, alignment, fusion and co-learning, and presents the gaps and challenges. A systematic literature review (SLR) was applied to define the progress and trends on those challenges in the MML domain. In total, 1032 articles were examined in this review to extract features like source, domain, application, modality, etc. This research article will help researchers understand the constant state of MML and navigate the selection of future research directions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Arnab Barua et al.",
      "keywords": "Modalities; Computer science; Modality (human\u2013computer interaction); Artificial intelligence; Machine learning; Domain (mathematical analysis); Systematic review; Multidisciplinary approach; Multimodal learning; Machine translation; Representation (politics); Data science; MEDLINE",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3243854",
      "cited_by_count": 74,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2999832078",
      "doi": "10.1109/tkde.2020.2967670",
      "title": "The Disruptions of 5G on Data-Driven Technologies and Applications",
      "abstract": "With 5G on the verge of being adopted as the next mobile network, there is a need to analyze its impact on the landscape of computing and data management. In this paper, we analyze the impact of 5G on both traditional and emerging technologies and project our view on future research challenges and opportunities. With a predicted increase of 10-100\u00d7 in bandwidth and 5-10x decrease in latency, 5G is expected to be the main enabler for smart cities, smart IoT and efficient healthcare, where machine learning is conducted at the edge. In this context, we investigate how 5G can help the development of federated learning. Network slicing, another key feature of 5G, allows running multiple isolated networks on the same physical infrastructure. However, security remains the main concern in the context of virtualization, multi-tenancy and high device density. Formal verification of 5G networks can be applied to detect security issues in massive virtualized environments. In summary, 5G will make the world even more densely and closely connected. What we have experienced in 4G connectivity will pale in comparison to the vast amounts of possibilities engendered by 5G.",
      "year": "2020",
      "journal": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "Dumitrel Loghin et al.",
      "keywords": "Computer science; Enabling; Edge computing; Virtualization; Cellular network; Context (archaeology); Mobile edge computing; Multitenancy; Mobile broadband; Data science; Computer network; Computer security; Cloud computing; Internet of Things; Telecommunications; Server; Wireless; Software",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tkde.2020.2967670",
      "cited_by_count": 98,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386432022",
      "doi": "10.1109/access.2023.3312046",
      "title": "Enhancing Prognosis Accuracy for Ischemic Cardiovascular Disease Using K Nearest Neighbor Algorithm: A Robust Approach",
      "abstract": "Ischemic Cardiovascular diseases are one of the deadliest diseases in the world. However, the mortality rate can be significantly reduced if we can detect the disease precisely and effectively. Machine Learning (ML) models offer substantial assistance to individuals requiring early treatment and disease detection in the realm of cardiovascular health. In response to this critical need, this study developed a robust system to predict ischemic disease accurately using ML-based algorithms. The dataset obtained from Kaggle encompasses a comprehensive collection of over 918 observations, encompassing 12 essential features crucial for predicting ischemic disease. In contrast, much-existing research relies primarily on datasets comprising only 303 instances from the UCI repository. Six ML-based algorithms, including K Nearest Neighbors (KNN), Random Forest (RF), Logistic Regression (LR), Support Vector Machine (SVM), Gaussian Na&#x00EF;ve Bayes (GNB), and Decision Trees (DT), are trained on the ischemic heart data. The effectiveness of the proposed methodologies is meticulously evaluated and benchmarked against cutting-edge techniques, employing a range of performance criteria. The empirical findings manifest that the KNN classifier produced optimized results with 91.8&#x0025; accuracy, 91.4&#x0025; recall, 91.9&#x0025; F1 score, 92.5&#x0025; precision, and AUC of 90.27&#x0025;.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ghulam Muhammad et al.",
      "keywords": "Naive Bayes classifier; Random forest; Computer science; Support vector machine; Artificial intelligence; Logistic regression; Decision tree; Machine learning; k-nearest neighbors algorithm; Statistical classification; Disease; Pattern recognition (psychology); Algorithm; Data mining; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312046",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392543866",
      "doi": "10.1109/access.2024.3374408",
      "title": "Applying Machine Learning Algorithms for the Classification of Sleep Disorders",
      "abstract": "Sleep disorder classification is crucial in improving human quality of life. Sleep disorders and apnoea can have a significant influence on human health. Sleep-stage classification by experts in the field is an arduous task and is prone to human error. The development of accurate machine learning algorithms (MLAs) for sleep disorder classification requires analysing, monitoring and diagnosing sleep disorders. This paper compares deep learning algorithms and conventional MLAs to classify sleep disorders. This study proposes an optimised method for the Classification of Sleep Disorders and uses the Sleep Health and Lifestyle Dataset publicly available online to evaluate the proposed model. The optimisations were conducted using a genetic algorithm to tune the parameters of different machine learning algorithms. An evaluation and comparison of the proposed algorithm against state-of-the-art machine learning algorithms to classify sleep disorders. The dataset includes 400 rows and 13 columns with various features representing sleep and daily activities. The k-nearest neighbours, support vector machine, decision tree, random forest and artificial neural network (ANN) deep learning algorithms were assessed. The experimental results reveal significant performance differences between the evaluated algorithms. The proposed algorithms obtained a classification accuracy of 83.19&#x0025;, 92.04&#x0025;, 88.50&#x0025;, 91.15&#x0025; and 92.92&#x0025;, respectively. The ANN achieved the highest classification accuracy of 92.92&#x0025;, and its precision, recall and F1-score values on the testing data were 92.01&#x0025;, 93.80&#x0025; and 91.93&#x0025;, respectively. The ANN algorithm that achieved high accuracy than other tested algorithms.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Talal Alshammari",
      "keywords": "Computer science; Sleep (system call); Machine learning; Statistical classification; Artificial intelligence; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3374408",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323338766",
      "doi": "10.1109/access.2023.3252886",
      "title": "Fall Risk Prediction Using Wireless Sensor Insoles With Machine Learning",
      "abstract": "Accidental fall is a significant health risk among the elderly. However, most of the fall detection systems give notification only after a fall occurs. Therefore, medical attention has shifted to fall preventive measures to reduce risks of fall and prevent any damage entirely. As most fall prediction data in previous literature are obtained from inertial sensors or static pressure sensors, in this study, wireless pressure sensors embedded insoles are used to train machine learning (ML) models to predict the risk of fall of an individual. The novelty of this paper is that dynamic walking data is obtained by wearing smart pressure insoles from 1101 subjects. We applied six different ML models, i.e., support vector machine (SVM), random forest (RF), logistic regression (LR), naive bayes (NB), decision tree (DT), and k-nearest neighbor (kNN). Results show that LR model with oversampling techniques achieved the highest area under curve (AUC) of 0.82, whereas the RF model with oversampling achieved the highest accuracy of 0.81 and specificity of 0.88. The results show that such models combined with pressure embedded wireless sensor insoles are capable for fall risk prediction.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Dipak Kumar Agrawal et al.",
      "keywords": "Naive Bayes classifier; Support vector machine; Computer science; Random forest; Machine learning; Artificial intelligence; Decision tree; Oversampling; Logistic regression; Wireless; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3252886",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225705568",
      "doi": "10.1109/tim.2022.3165816",
      "title": "Design and Performance Evaluation of an Ultralow-Power Smart IoT Device With Embedded TinyML for Asset Activity Monitoring",
      "abstract": "This article proposes a proof-of-concept device to continuously assess the usage of handheld power tools and detect construction working tasks (e.g., different drilling works) along with potential misusages, e.g., drops, with an energy-efficient architecture design. The designed device is based on Bluetooth low energy (BLE) and NFC connectivity. BLE is used to exchange data with a gateway, whereas NFC has been chosen as an energy-efficient wake-up mechanism. A temperature and humidity sensor is embedded to monitor storage conditions and an accelerometer for tool usage monitoring. The ARM Cortex-M4 core embedded in the BLE module is exploited to process the information at the edge. A Tiny Machine Learning (TinyML) algorithm is proposed to process the data directly on board and achieve low latency and high energy efficiency. The TinyML algorithm has been developed embedded in the proposed device to detect four different usage classes (tool transportation, no-load, metal, and wood drilling). A dataset containing more than 280 min of three-axis accelerations during different activities has been acquired with the device attached to a construction rotary hammer drill and used to train and validate the algorithm. A neural architecture search has been performed to optimize the trade-off between accuracy and complexity, achieving an accuracy of 90.6% with a model size of roughly 30 kB. The experimental results showed an ultralow power consumption in sleep mode of 550 nA and a peak power consumption of 8 mA while running TinyML on the edge. This results in a balanced combination of edge processing capabilities and low power consumption, enabling to obtain a smart Internet of Things (IoT) device in the field with a long lifetime of up to four years in operation and 17 years in shelf mode with a standard 250-mAh coin battery. This work enables a long battery lifetime operation of device degradation and utility analysis, further closing the gap between edge processing and fine granularity data evaluation.",
      "year": "2022",
      "journal": "IEEE Transactions on Instrumentation and Measurement",
      "authors": "Marco Giordano et al.",
      "keywords": "Computer science; Embedded system; ARM architecture; Sleep mode; Accelerometer; Energy consumption; Mobile device; Efficient energy use; Real-time computing; Power (physics); Computer hardware; Power consumption; Engineering; Electrical engineering; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tim.2022.3165816",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391407122",
      "doi": "10.1109/access.2024.3360691",
      "title": "Ensemble of Autoencoders for Anomaly Detection in Biomedical Data: A Narrative Review",
      "abstract": "In the context of biomedical data, an anomaly could refer to a rare or new type of disease, an aberration from normal behavior, or an unexpected observation requiring immediate attention. The detection of anomalies in biomedical data has a direct impact on the health and safety of individuals. However, anomalous events are rare, diverse, and infrequent. Often, the collection of anomalous data may involve significant loss of human life and healthcare costs. Therefore, traditional supervised machine and deep learning algorithms may not be directly applicable to such problems. Biomedical data are often collected in the form of images, electronic health records, and time series. Typically, an autoencoder (AE) or its corresponding variant is trained on normal data, and an anomaly is identified as a significant deviation from these data based on reconstruction error or other metrics. An Ensemble of AEs (EoAEs) can serve as a robust approach for anomaly detection in biomedical data by combining diverse and accurate views of normal data. An EoAE can provide superior detection to a single encoder; however, its performance can depend on various factors, including the diversity of the created data, the accuracy of the individual AEs, and the combination of their outcomes. Herein, we perform a comprehensive narrative literature review on the use of EoAEs when using different types of biomedical data. Such an ensemble provides a promising approach for anomaly detection in biomedical data, offering the potential for performance improvement by leveraging the strengths of diverse AEs. However, several challenges remain, such as the need for data specification and determination of the optimal number of AEs in the ensemble. By addressing these challenges, researchers can enhance the effectiveness of EoAEs for anomaly detection in various types of biomedical data. Furthermore, through this review, we highlight the significance of evaluating and comparing the performance of an EoAE with that of single AEs by establishing agreed-upon evaluation metrics and investigating normalization techniques for anomaly scores. We conclude the review by presenting challenges and open questions in the field with for future research.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ali Nawaz et al.",
      "keywords": "Anomaly detection; Computer science; Anomaly (physics); Artificial intelligence; Narrative; Pattern recognition (psychology); Linguistics; Philosophy; Physics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3360691",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3107707517",
      "doi": "10.1109/access.2020.3040257",
      "title": "Continuous Non-Invasive Blood Pressure Monitoring: A Methodological Review on Measurement Techniques",
      "abstract": "Continuous measurement of blood pressure is crucial to the assessment of many medical conditions. However, the current clinical gold standard involving an arterial catheter, occluding cuff, and other invasive procedures are performed in hospital settings while home-based devices can provide only intermittent measurement and are not as reliable. Therefore, there is a significant need for continuous non-invasive blood pressure (cNIBP) monitoring in the daily life. Pulse transit time (PTT)/pulse arrival time (PAT) - based blood pressure measurement has proven its potential to address this need. In this article, we present state-of-the-art devices and recent literature related to measurement technologies used in PTT/PAT - based methods for cNIBP monitoring. Various physiological signals which could be used to enable cNIBP in the home setting are categorized into two groups (i.e., proximal waveforms and distal waveforms) and are thoroughly discussed and compared. Given insightful analysis of these waveforms, we highlight their combinations to derive PTT/PAT values for BP measurement then discuss challenges presented from the cuffless and PTT/PAT - based nature of these devices. Finally, we conclude with future directions needed for home-based cNIBP adaptation and present societal broader impacts.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Tai Le et al.",
      "keywords": "Continuous monitoring; Blood pressure; Computer science; Waveform; Remote patient monitoring; Cuff; Medicine; Pressure measurement; Biomedical engineering; Telecommunications; Engineering; Surgery; Internal medicine; Operations management",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3040257",
      "cited_by_count": 72,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3140511580",
      "doi": "10.1109/access.2021.3066383",
      "title": "Phishing Happens Beyond Technology: The Effects of Human Behaviors and Demographics on Each Step of a Phishing Process",
      "abstract": "Prior studies have shown that the behaviours and attitudes of Internet users influence the likelihood of being victimised by phishing attacks. Many scammers design a step-by-step approach to phishing in order to gain the potential victim&#x2019;s trust and convince them to take the desired actions. It is important to understand which behaviours and attitudes can influence following the attacker in each step of a phishing scam. This will enable us to identify the root causes of phishing and to develop specific mitigation plans for each step of the phishing process and to increase prevention points. This study investigates to what extent people&#x2019;s risk-taking and decision-making styles influence the likelihood of phishing victimisation in three specific phishing steps. We asked participants to play a risk-taking game and to answer questions related to two psychological scales to measure their behaviours, and then conducted a simulated phishing campaign to assess their phishability throughout the three phishing steps selected. We find that the attitude to risk-taking and gender can predict users&#x2019; phishability in the different steps selected. There are however other possible direct and indirect behavioural factors that could be investigated in future studies. The results of this study and the model developed can be used to build a comprehensive framework to prevent the success of phishing attempts, starting from their root causes.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hossein Abroshan et al.",
      "keywords": "Phishing; Demographics; Process (computing); Computer science; Internet privacy; Computer security; The Internet; World Wide Web; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3066383",
      "cited_by_count": 77,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3038507111",
      "doi": "10.1109/access.2020.3006346",
      "title": "Security Assured CNN-Based Model for Reconstruction of Medical Images on the Internet of Healthcare Things",
      "abstract": "Medical Imaging is the most significant technique that constitutes information needed to diagnose and make the right decisions for treatment. These images suffer from inadequate contrast and noise that occurs during image acquisition. Thus, denoising and contrast enhancement is crucial in increasing the visual quality of the images for obtaining quantitative measures. In this research, an innovative and improvised denoising technique is implemented that applies a sparse aware with convolution neural network (SA_CNN) for investigating various medical modalities. To evaluate and validate, the convolution neural network utilizes patch creation and dictionary methods for obtaining information. The proposed framework is predominant to other current approaches by employing image assessment quantitative measures like peak signal to noise ratio (PSNR), structural similarity index (SSIM), and mean squared error (MSE). The study also optimizes the computational time to achieve increased efficiency and better visual quality of the image. Furthermore, the widespread use of the Internet of Healthcare Things (IoHT) helps to provide security with vault and challenge schemes between IoT devices and servers.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Sujeet More et al.",
      "keywords": "Computer science; Convolutional neural network; Noise reduction; Artificial intelligence; Peak signal-to-noise ratio; Mean squared error; Noise (video); Image quality; Convolution (computer science); Contrast (vision); Computer vision; Medical imaging; The Internet; Artificial neural network; Pattern recognition (psychology); Data mining; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3006346",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3004101474",
      "doi": "10.1109/access.2020.2970469",
      "title": "Design of an Integrated Wearable Multi-Sensor Platform Based on Flexible Materials for Neonatal Monitoring",
      "abstract": "For infants admitted at neonatal intensive care unit, the continuous monitoring of health parameters is critical for their optimal treatment and outcomes. So it's crucial to provide proper treatment, accurate and comfortable monitoring conditions for newborn infants. In this paper, we propose wearable sensor systems integrated with flexible material based non-invasive sensors for neonatal monitoring. The system aims at providing reliable vital signs monitoring as well as comfortable clinical environments for neonatal care. The system consists of a smart vest and a cloud platform. In the smart vest, a novel stretching sensor based on Polydimethylsiloxane-Graphene (PDMS-Graphene) compound is created to detect newborns' respiration signal; textile-based dry electrodes are developed to measure Electrocardiograph (ECG) signals; inertial measurement units (IMUs) are embedded to obtain movement information including accelerated speed and angular velocity of newborn wrists. Experiments were conducted to systematically test the sensing related characteristics of the aforementioned flexible materials and the performance of the proposed multi-sensor platform. The results show that the proposed system can achieve high quality signals. The wearable sensor platform is promising for continuous long term monitoring of neonates. The multi-modal physiological and behavioral signals measured by the platform can be further processed for clinical decision support on the neonatal health status.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Hongyu Chen et al.",
      "keywords": "Wearable computer; Continuous monitoring; Inertial measurement unit; Computer science; Real-time computing; Remote patient monitoring; Neonatal intensive care unit; Embedded system; Artificial intelligence; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2970469",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3080824426",
      "doi": "10.1109/access.2020.3018124",
      "title": "A Comprehensive Survey of Enabling and Emerging Technologies for Social Distancing\u2014Part II: Emerging Technologies and Open Issues",
      "abstract": "This two-part paper aims to provide a comprehensive survey on how emerging technologies, e.g., wireless and networking, artificial intelligence (AI) can enable, encourage, and even enforce social distancing practice. In Part I, an extensive background of social distancing is provided, and enabling wireless technologies are thoroughly surveyed. In this Part II, emerging technologies such as machine learning, computer vision, thermal, ultrasound, etc., are introduced. These technologies open many new solutions and directions to deal with problems in social distancing, e.g., symptom prediction, detection and monitoring quarantined people, and contact tracing. Finally, we discuss open issues and challenges (e.g., privacy-preserving, scheduling, and incentive mechanisms) in implementing social distancing in practice. As an example, instead of reacting with ad-hoc responses to COVID-19-like pandemics in the future, smart infrastructures (e.g., next-generation wireless systems like 6G, smart home/building, smart city, intelligent transportation systems) should incorporate a <i>pandemic mode</i> in their standard architectures/designs.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Cong T. Nguyen et al.",
      "keywords": "Computer science; Social distance; Emerging technologies; Open research; Data science; Computer security; Internet privacy; Coronavirus disease 2019 (COVID-19); World Wide Web; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3018124",
      "cited_by_count": 90,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312644484",
      "doi": "10.1109/access.2022.3225419",
      "title": "YouTube and Education: A Scoping Review",
      "abstract": "YouTube has evolved to a global platform for formal and informal education. In contrast to traditional sources of learning multimedia, YouTube is a social platform with numerous characteristics that make its real value for education not obvious. We neither know how reliable the learning content on YouTube is, what best-practice strategies for using this platform in education are nor how watching YouTube affects students&#x2019; performance and behavior. To shed light on these questions, we conducted a scoping review of the literature on YouTube and education. A total of 647 publications were included and analyzed thematically. Four research themes could be identified: (1) Content creation and assessment (2) User attitudes and acceptance (3) Usage strategies and behaviors (4) Impact on student learning. The findings of the respective studies were analyzed and compiled theme by theme. The main results of this review are: (1) There is an increasing concern about content quality on YouTube. (2) Despite versatile production and usage strategies, no relationships were established between such strategies and learning. (3) Most studies on the impact of YouTube on student learning reported positive results in terms of enhanced skills, competencies, interest, motivation, engagement levels, or test performance. We conclude that YouTube is a rich, free, easy-to-use, and enjoyable source of learning content. However, the challenges and risks associated with this platform suggest that it is best suitable for guided learning where teachers make or select the content and include it in a well-defined, pedagogy-driven learning context.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Abdulhadi Shoufan et al.",
      "keywords": "Context (archaeology); Computer science; Theme (computing); Quality (philosophy); Social media; Multimedia; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3225419",
      "cited_by_count": 72,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386472912",
      "doi": "10.1109/access.2023.3312531",
      "title": "DFU-SIAM a Novel Diabetic Foot Ulcer Classification With Deep Learning",
      "abstract": "Diabetes affects roughly 537 million people in the world, and it is predicted to reach 783 million by 2045. Diabetic Foot Ulcer (DFU) is a major issue with diabetes that may lead to lower limb amputation. The rapid evolution of DFU demands immediate intervention to prevent the terrible consequences of amputation and related complications.This research introduces a novel approach utilizing deep neural networks and machine learning for the accurate classification of diabetic foot ulcer (DFU) images. The proposed method harnesses the cutting-edge capabilities of Convolutional Neural Networks (CNN) and Vision Image Transformers (ViT) within a Siamese Neural Network (SNN) Architecture. By employing similarity learning, the model efficiently categorizes DFU images into four distinct classes: None, Infection, Ischemia, or Both. The training process involves the use of the DFU2021 dataset, with all ethical clearances duly obtained. Notably, the model exhibits remarkable performance on both the validation and test data, indicating a significant breakthrough in the field of DFU disease image classification. The potential of this innovative model extends beyond classification; it holds promise as an integral component of a comprehensive detection tool and longitudinal treatment protocol validation for DFU disease.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mohammud Shaad Ally Toofanee et al.",
      "keywords": "Artificial intelligence; Convolutional neural network; Deep learning; Diabetic foot ulcer; Diabetic foot; Amputation; Computer science; Machine learning; Artificial neural network; Medicine; Diabetes mellitus; Physical medicine and rehabilitation; Pattern recognition (psychology); Surgery",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312531",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3080318198",
      "doi": "10.1109/access.2020.3019577",
      "title": "Patient Similarity via Joint Embeddings of Medical Knowledge Graph and Medical Entity Descriptions",
      "abstract": "With the prevalence and growing volume of Electronic Health Records (EHRs), there has been increasing interest in mining EHRs for improving clinical decision support. The accurate identification of patients with similar conditions based on EHRs is a key step in personalized healthcare. Existing studies model EHRs by medical knowledge graph embedding to learn the latent embeddings of medical entities (e.g., patients, medications, diagnoses and procedures). However, such precisely structured data is usually limited in quantity and in scope. Therefore, to enhance the quality of the embeddings it is important to consider more widely available medical information such as medical entity descriptions. In this paper we propose a novel framework, called Deep Patient Similarity (DeepPS). Specifically, DeepPS incorporates medical entity descriptions by augmenting the embeddings of medical entities and relations with the embeddings of words, which leverages both information from medical knowledge graph structures and the contexts of medical entity descriptions. Furthermore, DeepPS employs the embeddings to patient similarity learning by leveraging Siamese Convolutional Neural Network (CNN) with Spatial Pyramid Pooling (SPP). Extensive experiments on real datasets are conducted to show superior performance of our proposed framework.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Zhihuang Lin et al.",
      "keywords": "Computer science; Medical diagnosis; Convolutional neural network; Graph; Information retrieval; Embedding; Similarity (geometry); Artificial intelligence; Pooling; Machine learning; Data mining; Data science; Theoretical computer science; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3019577",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3162374488",
      "doi": "10.1109/jtehm.2021.3079714",
      "title": "Backpropagation Neural Network-Based Machine Learning Model for Prediction of Blood Urea and Glucose in CKD Patients",
      "abstract": "Diabetes mellitus and its complication such as heart disease, stroke, kidney failure, etc. is a serious concern all over the world. Hence, monitoring some important blood parameters non-invasively is of utmost importance, that too with high accuracy. This paper presents an in-house developed system, which will be helpful for diabetes patients with Chronic Kidney Disease (CKD) to monitor blood urea and glucose. This manuscript discusses a comparative study for the prediction of blood urea and glucose using Backpropagation Artificial Neural Network (BP- ANN) and Partial Least Square Regression (PLSR) model. The NVIDIA Jetson Nano board controls the five fixed LED wavelengths in the Near Infrared (NIR) region from [Formula: see text] to [Formula: see text] with a constant emission power of 1.2 mW. The spectra for 57 laboratory prepared samples conforming with major blood constituents of the blood sample were recorded. From these samples, 53 spectra were used for training/calibration of the BP-ANN/PLSR model and the remaining 4 samples were used for validating the model. The PLSR model predicts blood urea and glucose with a Root Mean Square Error (RMSE) of 0.88 & 12.01 mg/dL, Coefficient of Determination R<sup>2</sup> = 0.93 & R<sup>2</sup> = 0.97, Accuracy of 94.2 % and 90.14 %, respectively. To improve the prediction accuracy, BP-ANN model is applied. Later the Principal Component Analysis (PCA) technique was applied to these 57 spectra values. These PCA values were used to train and validate the BP-ANN model. After applying the BP-ANN model, the prediction of blood urea & glucose improved remarkably, which achieved RMSE of 0.69 mg/dL, R<sup>2</sup> = 0.96, Accuracy of 95.96 % for urea and RMSE of 2.06 mg/dL, R<sup>2</sup> = 0.99, and Accuracy of 98.65 % for glucose. The system performance is then evaluated with Bland Altman analysis and Clarke Error Grid Analysis (CEGA).",
      "year": "2021",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Jivan S. Parab et al.",
      "keywords": "Backpropagation; Artificial neural network; Mean squared error; Diabetes mellitus; Partial least squares regression; Kidney disease; Glucose meter; Medicine; Artificial intelligence; Urea; Calibration; Mathematics; Computer science; Chemistry; Internal medicine; Machine learning; Endocrinology; Statistics; Biochemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2021.3079714",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388240351",
      "doi": "10.1109/access.2023.3329678",
      "title": "Deep Learning in EEG-Based BCIs: A Comprehensive Review of Transformer Models, Advantages, Challenges, and Applications",
      "abstract": "Brain-computer interfaces (BCIs) have undergone significant advancements in recent years. The integration of deep learning techniques, specifically transformers, has shown promising development in research and application domains. Transformers, which were originally designed for natural language processing, have now made notable inroads into BCIs, offering a unique self-attention mechanism that adeptly handles the temporal dynamics of brain signals. This comprehensive survey delves into the application of transformers in BCIs, providing readers with a lucid understanding of their foundational principles, inherent advantages, potential challenges, and diverse applications. In addition to discussing the benefits of transformers, we also address their limitations, such as computational overhead, interpretability concerns, and the data-intensive nature of these models, providing a well-rounded analysis. Furthermore, the paper sheds light on the myriad of BCI applications that have benefited from the incorporation of transformers. These applications span from motor imagery decoding, emotion recognition, and sleep stage analysis to novel ventures such as speech reconstruction. This review serves as a holistic guide for researchers and practitioners, offering a panoramic view of the transformative potential of transformers in the BCI landscape. With the inclusion of examples and references, readers will gain a deeper understanding of the topic and its significance in the field.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Berdakh Abibullaev et al.",
      "keywords": "Computer science; Interpretability; Transformer; Brain\u2013computer interface; Electroencephalography; Artificial intelligence; Human\u2013computer interaction; Data science; Cognitive science; Neuroscience; Engineering; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3329678",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4380686329",
      "doi": "10.1109/access.2023.3286346",
      "title": "A Machine Learning Approach Using Statistical Models for Early Detection of Cardiac Arrest in Newborn Babies in the Cardiac Intensive Care Unit",
      "abstract": "Cardiac arrest in newborn babies is an alarming yet typical medical emergency. Early detection is critical for providing these babies with the best care and treatment. Recent research has focused on identifying the potential indicators and biomarkers of cardiac arrest in newborn babies and developing accurate and efficient diagnostic tools for early detection. An array of imaging techniques, such as echocardiography and computed tomography may help provide early detection of cardiac arrest. This research aims to develop a Cardiac Machine Learning model (CMLM) using statistical models for the early detection of cardiac arrest in newborn babies in the Cardiac Intensive Care Unit (CICU). The cardiac arrest events were identified using a combination of the neonate&#x2019;s physiological parameters. Statistical modeling techniques, such as logistic regression and support vector machines, were used to construct predictive models for cardiac arrest. The proposed model will be used in the CICU to enable early detection of cardiac arrest in newborn babies. In a training (Tr) comparison region, the proposed CMLA reached 0.912 delta-p value, 0.894 False discovery rate (FDR) value, 0.076 False omission rate (FOR) value, 0.859 prevalence threshold value and 0.842 CSI value. In a testing (Ts) comparison region, the proposed CMLA reached 0.896 delta-p values, 0.878 FDR value, 0.061 FOR value, 0.844 prevalence threshold values and 0.827 CSI value. It will help reduce the mortality and morbidity of newborn babies due to cardiac arrest in the CICU.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ketan Gupta et al.",
      "keywords": "Coronary care unit; Medicine; Logistic regression; Neonatal intensive care unit; Intensive care unit; Intensive care medicine; Internal medicine; Pediatrics; Myocardial infarction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3286346",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3192032012",
      "doi": "10.1109/access.2021.3103897",
      "title": "Machine Learning-Based Asthma Risk Prediction Using IoT and Smartphone Applications",
      "abstract": "In this paper, we present an asthma risk prediction tool based on machine learning (ML). The entire tool is implemented on a smartphone as a mobile-health (m-health) application using the resources of Internet-of-Things (IoT). Peak Expiratory Flow Rates (PEFR) are commonly measured using external instruments such as peak flow meters and are well known asthama risk predictors. In this work, we find a correlation between the particulate matter (PM) found indoors and the outside weather with the PEFR. The PEFR results are classified into three categories such as &#x2018;Green&#x2019; (Safe), &#x2018;Yellow&#x2019; (Moderate Risk) and &#x2018;Red&#x2019; (High Risk) conditions in comparison to the best peak flow value obtained by each individual. Convolutional neural network (CNN) architecture is used to map the relationship between the indoor PM and weather data to the PEFR values. The proposed method is compared with the state-of-the-art deep neural network (DNN) based techniques in terms of the root mean square and mean absolute error accuracy measures. These performance measures are better for the proposed method than other methods discussed in the literature. The entire setup is implemented on a smartphone as an app. An IoT system including a Raspberry Pi is used to collect the input data. This assistive tool can be a cost-effective tool for predicting the risk of asthma attacks.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Gautam Shreedhar Bhat et al.",
      "keywords": "Computer science; Convolutional neural network; Mean squared error; Raspberry pi; Artificial neural network; Machine learning; Artificial intelligence; Internet of Things; Deep learning; Real-time computing; Asthma; Simulation; Statistics; Embedded system; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3103897",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3028925963",
      "doi": "10.1109/access.2020.2997241",
      "title": "ICD-10 Coding of Spanish Electronic Discharge Summaries: An Extreme Classification Problem",
      "abstract": "Objective: Medical coding is used to identify and standardize clinical concepts in the records collected from healthcare services. The tenth revision of the International Classification of Diseases (ICD-10) is the most widely-used coding with more than 11,000 different diagnoses, affecting research, reporting, and funding. Unfortunately, ICD-10 code sets tend to follow biased, unbalanced, and scattered distributions. These distribution attributes, along with high lexical variability, severely restrict performance when coded clinical records are used to infer code sets in uncoded records. To improve that inference, we explore a combination of example-based methods optimized to capture codes with different appearance frequencies in data sets. Materials and Methods: The proposed exploration has been carried out on Spanish hospital discharge reports coded by experts, excluding all sentences without any biomedical concept. Representations based on semantic and lexical features are explored, using both global and label-specific attributes. In turn, algorithms based on binary outputs, groups of subsets and extreme classification are compared. Lists of codes together with their confidence values (certainty probabilities) are suggested by each method. Results: Diverse spectral behaviors are shown for each method. Binary classifiers seem to maximize the capture of more popular codes, while extreme classifiers promote infrequent ones. In order to exploit such differences, ensemble approaches are proposed by weighting every output code according to the method, confidence value and appearance frequency. The rule-based combination reaches a 46&#x0025; Precision at 10 (<inline-formula> <tex-math notation=\"LaTeX\">$P \\text{@} 10$ </tex-math></inline-formula>), which means a 15&#x0025; improvement over the best individual proposal. Conclusion: Assembling methods based on weighting each code according to training frequency and performance can achieve better overall Precision scores on extreme distributions, such as ICD-10 coding.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mario Almagro et al.",
      "keywords": "Computer science; Weighting; Coding (social sciences); Inference; Data mining; Medical classification; Binary number; Code (set theory); Binary classification; Natural language processing; Artificial intelligence; Binary code; Machine learning; Information retrieval; Statistics; Mathematics; Set (abstract data type)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2997241",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295934548",
      "doi": "10.1109/access.2022.3206782",
      "title": "Embedded Machine Learning Using Microcontrollers in Wearable and Ambulatory Systems for Health and Care Applications: A Review",
      "abstract": "The use of machine learning in medical and assistive applications is receiving significant attention thanks to the unique potential it offers to solve complex healthcare problems for which no other solutions had been found. Particularly promising in this field is the combination of machine learning with novel wearable devices. Machine learning models, however, suffer from being computationally demanding, which typically has resulted on the acquired data having to be transmitted to remote cloud servers for inference. This is not ideal from the system\u2019s requirements point of view. Recently, efforts to replace the cloud servers with an alternative inference device closer to the sensing platform, has given rise to a new area of research Tiny Machine Learning (TinyML). In this work, we investigate the different challenges and specifications trade-offs associated to existing hardware options, as well as recently developed software tools, when trying to use microcontroller units (MCUs) as inference devices for health and care applications. The paper also reviews existing wearable systems incorporating MCUs for monitoring, and management, in the context of different health and care intended uses. Overall, this work addresses the gap in literature targeting the use of MCUs as edge inference devices for healthcare wearables. Thus, can be used as a kick-start for embedding machine learning models on MCUs, focusing on healthcare wearables.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Maha S. Diab et al.",
      "keywords": "Microcontroller; Wearable computer; Computer science; Embedded system; Health care; Ambulatory; Wearable technology; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3206782",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2034365110",
      "doi": "10.1109/tetc.2014.2386133",
      "title": "Discover the Expert: Context-Adaptive Expert Selection for Medical Diagnosis",
      "abstract": "In this paper, we propose an expert selection system that learns online the best expert to assign to each patient depending on the context of the patient. In general, the context can include an enormous number and variety of information related to the patient's health condition, age, gender, previous drug doses, and so forth, but the most relevant information is embedded in only a few contexts. If these most relevant contexts were known in advance, learning would be relatively simple but they are not. Moreover, the relevant contexts may be different for different health conditions. To address these challenges, we develop a new class of algorithms aimed at discovering the most relevant contexts and the best clinic and expert to use to make a diagnosis given a patient's contexts. We prove that as the number of patients grows, the proposed context-adaptive algorithm will discover the optimal expert to select for patients with a specific context. Moreover, the algorithm also provides confidence bounds on the diagnostic accuracy of the expert it selects, which can be considered by the primary care physician before making the final decision. While our algorithm is general and can be applied in numerous medical scenarios, we illustrate its functionality and performance by applying it to a real-world breast cancer diagnosis data set. Finally, while the application we consider in this paper is medical diagnosis, our proposed algorithm can be applied in other environments where expertise needs to be discovered.",
      "year": "2014",
      "journal": "IEEE Transactions on Emerging Topics in Computing",
      "authors": "Cem Tekin et al.",
      "keywords": "Computer science; Context (archaeology); Machine learning; Expert system; Set (abstract data type); Variety (cybernetics); Artificial intelligence; Selection (genetic algorithm); Class (philosophy); Medical diagnosis; Health care; Data science; Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tetc.2014.2386133",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3113233691",
      "doi": "10.1109/access.2020.3043732",
      "title": "A Deep Learning-Based Sepsis Estimation Scheme",
      "abstract": "The objective of this research is to design and implement a machine learning (ML) based technique that can predict cases of septic shock and extreme sepsis and assess its effects on medical practice and the patients. The study is a retrospective cohort type, which is used to algorithmic deduction and validation, along with pre- and post-impact assessment. For non-ICU cases, the algorithm was deduced and validated for specific periods. The classifiers used for the study have been deduced and validated by employing electronic health records (EHR), which were silent initially but alerted the clinical personnel concerning the sepsis prediction. For training the classification system, the chosen patients should have had ICD and the latest codes concerning extreme sepsis or septic shock. Moreover, the patients should have had positive blood culture during their interaction with the hospital, where there were indications of either systolic blood pressure (SBP) or lactate levels. The classification algorithms demonstrated a 93.84%, 93.22%, 95.25% accuracy, sensitivity and specificity respectively. The pattern used for clinical detection, in the context of the alerting system, led to a small but statistically significant increase in IV usage and lab tests. The values used for the alerting system were found to have no statistically significant difference in the context of different ICU wards since data from the laboratory tests serve as the primary early indicator of septic shock by confirming the presence of toxins.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Bilal Yaseen Al\u2010Mualemi et al.",
      "keywords": "Sepsis; Septic shock; Context (archaeology); Medicine; Retrospective cohort study; Machine learning; Blood pressure; Shock (circulatory); Medical record; Electronic medical record; Clinical Practice; Vital signs; Emergency medicine; Artificial intelligence; Computer science; Intensive care medicine; Internal medicine; Surgery; Physical therapy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3043732",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382119284",
      "doi": "10.1109/jiot.2023.3288050",
      "title": "Reinforcement Learning for Intelligent Healthcare Systems: A Review of Challenges, Applications, and Open Research Issues",
      "abstract": "&lt;p&gt;The rise of chronic disease patients and the pandemic pose immediate threats to healthcare expenditure and mortality rates. This calls for transforming healthcare systems away from one-on-one patient treatment into intelligent health systems, leveraging the recent advances of Internet of Things and smart sensors. Meanwhile, reinforcement learning (RL) has witnessed an intrinsic breakthrough in solving a variety of complex problems for distinct applications and services. Thus, this article presents a comprehensive survey of the recent models and techniques of RL that have been developed/used for supporting Intelligent-healthcare (I-health) systems. It can guide the readers to deeply understand the state-of-the-art regarding the use of RL in the context of I-health. Specifically, we first present an overview of the I-health systems' challenges, architecture, and how RL can benefit these systems. We then review the background and mathematical modeling of different RL, deep RL (DRL), and multiagent RL models. We highlight important guidelines on how to select the appropriate RL model for a given problem, and provide quantitative comparisons, showing the results of deploying key RL models in two scenarios that can be followed in monitoring applications. After that, we conduct an in-depth literature review on RL's applications in I-health systems, covering edge intelligence, smart core network, and dynamic treatment regimes. Finally, we highlight emerging challenges and future research directions to enhance RL's success in I-health systems, which opens the door for exploring some interesting and unsolved problems.&lt;/p&gt;",
      "year": "2023",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Alaa Awad Abdellatif et al.",
      "keywords": "Reinforcement learning; Computer science; Variety (cybernetics); Context (archaeology); Health care; Intelligent decision support system; Open research; Data science; Healthcare system; Artificial intelligence; Risk analysis (engineering); Management science; Engineering; World Wide Web; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jiot.2023.3288050",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3000965547",
      "doi": "10.1109/access.2020.2968967",
      "title": "Noninvasive Classification of Blood Pressure Based on Photoplethysmography Signals Using Bidirectional Long Short-Term Memory and Time-Frequency Analysis",
      "abstract": "The photoplethysmography (PPG) method for continuous noninvasive measurements of blood pressure (BP) offers a more comfortable solution than conventional methods. The main challenge in using the PPG method is that its accuracy is greatly influenced by motion artifacts. In addition, the characteristics of PPG vary depending on physiological conditions; hence, the system must be calibrated to adjust for such changes. We attempt to address these limitations and propose a novel method for the classification of BP using a bidirectional long short-term memory (BLSTM) network with time-frequency (TF) analysis based on PPG signals. The TF analysis extracts information from PPG signals using a short-time Fourier transform (STFT) in the time domain to produce two features, namely, the instantaneous frequency and spectral entropy. Training the BLSTM network using TF features significantly improves the classification performance and decreases the training time. We classify 900 PPG waveform segment samples from 219 adult subjects into three classification levels: normotension (NT), prehypertension (PHT) and hypertension (HT). The results show that the proposed method is successful in the classification of BP with accuracy, sensitivity, and speciticity values of 97.33%, 100%, and 94.87%, respectively. The F1 scores of three BP classifications were 97.29%, 97.39%, and 93.93%, respectively. A comparison of current and previous approaches to the classification of BP is accomplished. Our proposed method achieves a higher accuracy than convolutional neural networks (CNNs), k-nearest neighbors (KNN), bagged tree, logistic regression, and AdaBoost tree methods.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Hendrana Tjahjadi et al.",
      "keywords": "Photoplethysmogram; Computer science; Pattern recognition (psychology); Short-time Fourier transform; Artificial intelligence; Time\u2013frequency analysis; Frequency domain; Convolutional neural network; Speech recognition; Fourier transform; Mathematics; Fourier analysis; Filter (signal processing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2968967",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4367665547",
      "doi": "10.1109/jbhi.2023.3271858",
      "title": "Analysis of a Deep Learning Model for 12-Lead ECG Classification Reveals Learned Features Similar to Diagnostic Criteria",
      "abstract": "Despite their remarkable performance, deep neural networks remain unadopted in clinical practice, which is considered to be partially due to their lack of explainability. In this work, we apply explainable attribution methods to a pre-trained deep neural network for abnormality classification in 12-lead electrocardiography to open this \"black box\" and understand the relationship between model prediction and learned features. We classify data from two public databases (CPSC 2018, PTB-XL) and the attribution methods assign a \"relevance score\" to each sample of the classified signals. This allows analyzing what the network learned during training, for which we propose quantitative methods: average relevance scores over a) classes, b) leads, and c) average beats. The analyses of relevance scores for atrial fibrillation and left bundle branch block compared to healthy controls show that their mean values a) increase with higher classification probability and correspond to false classifications when around zero, and b) correspond to clinical recommendations regarding which lead to consider. Furthermore, c) visible P-waves and concordant T-waves result in clearly negative relevance scores in atrial fibrillation and left bundle branch block classification, respectively. Results are similar across both databases despite differences in study population and hardware. In summary, our analysis suggests that the DNN learned features similar to cardiology textbook knowledge.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Theresa Bender et al.",
      "keywords": "Artificial intelligence; Relevance (law); Deep learning; Left bundle branch block; Artificial neural network; Computer science; Machine learning; Electrocardiography; Pattern recognition (psychology); Clinical significance; Data set; Internal medicine; Medicine; Heart failure",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3271858",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386124574",
      "doi": "10.1109/access.2023.3308446",
      "title": "An Explainable Artificial Intelligence Model for the Classification of Breast Cancer",
      "abstract": "Breast cancer is the most common cancer among women and globally affects both genders. The disease arises due to abnormal growth of tissue formed of malignant cells. Early detection of breast cancer is crucial for enhancing the survival rate. Therefore, artificial intelligence has revolutionized healthcare and can serve as a promising tool for early diagnosis. The present study aims to develop a machine-learning model to classify breast cancer and to provide explanations for the model results. This could improve the understanding of the diagnosis and treatment of breast cancer by identifying the most important features of breast cancer tumors and the way they affect the classification task. The best-performing machine-learning model has achieved an accuracy of 97.7% using k-nearest neighbors and a precision of 98.2% based on the Wisconsin breast cancer dataset and an accuracy of 98.6% using the artificial neural network with 94.4% precision based on the Wisconsin diagnostic breast cancer dataset. Hence, this asserts the importance and effectiveness of the proposed approach. The present research explains the model behavior using model-agnostic methods, demonstrating that the bare nuclei feature in the Wisconsin breast cancer dataset and the area&#x2019;s worst feature Wisconsin diagnostic breast cancer dataset are the most important factors in determining breast cancer malignancy. The work provides extensive insights into the particular characteristics of the diagnosis of breast cancer and suggests possible directions for expected investigation in the future into the fundamental biological mechanisms that underlie the disease&#x2019;s onset. The findings underline the potential of machine learning to enhance breast cancer diagnosis and therapy planning while emphasizing the importance of interpretability and transparency in artificial intelligence-based healthcare systems.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Tarek Khater et al.",
      "keywords": "Breast cancer; Artificial intelligence; Machine learning; Computer science; Artificial neural network; Malignancy; Cancer; Deep learning; Feature (linguistics); Disease; Medicine; Pathology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3308446",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3037620472",
      "doi": "10.1109/access.2020.3004977",
      "title": "Automated Ischemic Stroke Subtyping Based on Machine Learning Approach",
      "abstract": "Ischemic stroke subtyping was not only highly valuable for effective intervention and treatment, but also important to the prognosis of ischemic stroke. The manual adjudication of disease classification was time-consuming, error-prone, and limits scaling to large datasets. In this study, an integrated machine learning approach was used to classify the subtype of ischemic stroke on The International Stroke Trial (IST) dataset. We considered the common problems of feature selection and prediction in medical datasets. Firstly, the importances of features were ranked by the Shapiro-Wilk algorithm and Pearson correlations between features were analyzed. Then, we used Recursive Feature Elimination with Cross-Validation (RFECV), which incorporated linear SVC, Random-Forest-Classifier, Extra-Trees-Classifier, AdaBoost-Classifier, and Multinomial-Nai&#x0308;ve-Bayes-Classifier as estimator respectively, to select robust features important to ischemic stroke subtyping. Furthermore, the importances of selected features were determined by Extra-Trees-Classifier. Finally, the selected features were used by Extra-Trees-Classifier and a simple deep learning model to classify the ischemic stroke subtype on IST dataset. It was suggested that the described method could classify ischemic stroke subtype accurately. And the result showed that the machine learning approaches outperformed human professionals.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Gang Fang et al.",
      "keywords": "Subtyping; Random forest; Computer science; Artificial intelligence; Classifier (UML); Machine learning; Naive Bayes classifier; AdaBoost; Feature selection; Ischemic stroke; Pattern recognition (psychology); Quadratic classifier; Support vector machine; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3004977",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210258675",
      "doi": "10.1109/tfuzz.2022.3144448",
      "title": "Explainable CNN With Fuzzy Tree Regularization for Respiratory Sound Analysis",
      "abstract": "Auscultation is an important tool for diagnosing respiratory-related diseases. Unfortunately, the quality of auscultation is limited by the professional level of the doctor and the environment of the auscultation. Some studies have focused on automated auscultation techniques. However, existing approaches suffer from two challenges: 1) the models cannot learn from data distributed among multiple hospitals and 2) the predictions of the models are difficult to interpret for physicians. To address this issue, this article proposes a novel explainable respiratory sound analysis framework with fuzzy decision tree regularization. This framework develops an ensemble knowledge distillation technique to learn distributed data and achieves good performance in terms of model efficiency and accuracy. Fuzzy decision trees are used to explain the predictions of the model and produce decision rules that can be well accepted by physicians. The effectiveness of this framework is thoroughly validated on the Respiratory Sound database and compared with other existing approaches.",
      "year": "2022",
      "journal": "IEEE Transactions on Fuzzy Systems",
      "authors": "Jianqiang Li et al.",
      "keywords": "Auscultation; Computer science; Decision tree; Fuzzy logic; Artificial intelligence; Machine learning; Regularization (linguistics); Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tfuzz.2022.3144448",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2977833371",
      "doi": "10.1109/access.2019.2944801",
      "title": "Computational Sleep Behavior Analysis: A Survey",
      "abstract": "Sleep is a key marker of health, as it can either be a cause or a consequence. It is traditionally studied in clinical environments using dedicated medical devices. Recent technological developments, e.g., in sensing and data analysis, have led to new approaches for sleep monitoring and assessment, which are attracting increasing attention in the emerging domain of personalized smart healthcare. Nevertheless, a high-level overview of technology-enabled research on sleep that can inform related communities of the latest developments is lacking. In this paper, we present a comprehensive review to examine the current status of various aspects of technology-based sleep research. We first characterize sleep behavior and key areas of sleep assessment, and we introduce a general review of the methodologies used in this domain. We review the major technological methods and trends associated with sleep monitoring, data collection and sleep behavior analysis, from which strengths and weaknesses are highlighted. Finally, we also discuss challenges and promising directions for future research.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Sarah Fallmann et al.",
      "keywords": "Sleep (system call); Strengths and weaknesses; Computer science; Key (lock); Data science; Domain (mathematical analysis); Data collection; Risk analysis (engineering); Medicine; Psychology; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2944801",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2787059376",
      "doi": "10.1109/thms.2017.2776603",
      "title": "Sensory-Glove-Based Open Surgery Skill Evaluation",
      "abstract": "Manual dexterity is one of the most important surgical skills, and yet there are limited instruments to evaluate this ability objectively. In this paper, we propose a system designed to track surgeons' hand movements during simulated open surgery tasks and to evaluate their manual expertise. Eighteen participants, grouped according to their surgical experience, performed repetitions of two basic surgical tasks, namely single interrupted suture and simple running suture. Subjects' hand movements were measured with a sensory glove equipped with flex and inertial sensors, tracking flexion/extension of hand joints, and wrist movement. The participants' level of experience was evaluated discriminating manual performances using linear discriminant analysis, support vector machines, and artificial neural network classifiers. Artificial neural networks showed the best performance, with a median error rate of 0.61% on the classification of single interrupted sutures and of 0.57% on simple running sutures. Strategies to reduce sensory glove complexity and increase its comfort did not affect system performances substantially.",
      "year": "2018",
      "journal": "IEEE Transactions on Human-Machine Systems",
      "authors": "Laura Sbernini et al.",
      "keywords": "Computer science; Sensory system; Wrist; Linear discriminant analysis; Physical medicine and rehabilitation; Artificial neural network; Simulation; Artificial intelligence; Medicine; Surgery; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/thms.2017.2776603",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3138625890",
      "doi": "10.1109/access.2021.3067503",
      "title": "A Survey of Machine Learning Applications to Handover Management in 5G and Beyond",
      "abstract": "Handover (HO) is one of the key aspects of next-generation (NG) cellular communication networks that need to be properly managed since it poses multiple threats to quality-of-service (QoS) such as the reduction in the average throughput as well as service interruptions. With the introduction of new enablers for fifth-generation (5G) networks, such as millimetre wave (mm-wave) communications, network densification, Internet of things (IoT), etc., HO management is provisioned to be more challenging as the number of base stations (BSs) per unit area, and the number of connections has been dramatically rising. Considering the stringent requirements that have been newly released in the standards of 5G networks, the level of the challenge is multiplied. To this end, intelligent HO management schemes have been proposed and tested in the literature, paving the way for tackling these challenges more efficiently and effectively. In this survey, we aim at revealing the current status of cellular networks and discussing mobility and HO management in 5G alongside the general characteristics of 5G networks. We provide an extensive tutorial on HO management in 5G networks accompanied by a discussion on machine learning (ML) applications to HO management. A novel taxonomy in terms of the source of data to be utilized in training ML algorithms is produced, where two broad categories are considered; namely, visual data and network data. The state-of-the-art on ML-aided HO management in cellular networks under each category is extensively reviewed with the most recent studies, and the challenges, as well as future research directions, are detailed.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Michael S. Mollel et al.",
      "keywords": "Handover; Computer science; Provisioning; Cellular network; Quality of service; Network management; Mobility management; Computer network; Throughput; Service (business); Telecommunications; Wireless",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3067503",
      "cited_by_count": 105,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3090928116",
      "doi": "10.1109/tbcas.2020.3027242",
      "title": "Spintronic Sensors Based on Magnetic Tunnel Junctions for Wireless Eye Movement Gesture Control",
      "abstract": "The tracking of eye gesture movements using wearable technologies can undoubtedly improve quality of life for people with mobility and physical impairments by using spintronic sensors based on the tunnel magnetoresistance (TMR) effect in a human-machine interface. Our design involves integrating three TMR sensors on an eyeglass frame for detecting relative movement between the sensor and tiny magnets embedded in an in-house fabricated contact lens. Using TMR sensors with the sensitivity of 11 mV/V/Oe and ten <1 mm<sup>3</sup> embedded magnets within a lens, an eye gesture system was implemented with a sampling frequency of up to 28 Hz. Three discrete eye movements were successfully classified when a participant looked up, right or left using a threshold-based classifier. Moreover, our proof-of-concept real-time interaction system was tested on 13 participants, who played a simplified Tetris game using their eye movements. Our results show that all participants were successful in completing the game with an average accuracy of 90.8%.",
      "year": "2020",
      "journal": "IEEE Transactions on Biomedical Circuits and Systems",
      "authors": "Asfand Tanwear et al.",
      "keywords": "Spintronics; Gesture; Wireless; Tunnel magnetoresistance; Computer science; Movement (music); Movement control; Engineering; Electrical engineering; Computer vision; Telecommunications; Materials science; Physics; Acoustics; Physical medicine and rehabilitation; Nanotechnology; Ferromagnetism",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbcas.2020.3027242",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2914984468",
      "doi": "10.1109/access.2019.2893877",
      "title": "Detecting Diseases by Human-Physiological-Parameter-Based Deep Learning",
      "abstract": "The application of artificial intelligence in auxiliary diagnosis diseases has become a current research hotspot. The traditional method of diagnosing diabetes circulatory complication, diabetic peripheral neuropathy hyperlipidemia, diabetes mellitus peripheral angiopathy, and the comprehensive diseases is to distinguish an inspection report by a professional doctor. Its implementation of the clinical decision support algorithm for medical text data faces a challenge with the confidence level and accuracy. We proposed an expanding learning system to detect diseases above in our medical text data, which cover many kinds of physiological parameters of human, such as hematologic parameters, urine parameters, and biochemical detection. First, the raw data were expanded and corrected. Second, the processed data were fed into a 1D-convolution neural network with dropout and pooling. Our algorithm achieves 80.43%, 80.85%, 91.49%, 82.61%, and 95.60% with testing datasets (46 subjects). The effect of data quantification on model performance also had been researched, and the different data quantification methods would affect model performance on distinguishing different diseases. The proposed auxiliary diagnostic systems that have a highly accurate and robust performance can be used for preliminary diagnosis and referral; therefore, it is not only saving many human resources but also resulting in improved clinical diagnostic efficiency.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yuliang Liu et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Artificial neural network; Convolutional neural network; Pooling; Data mining; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2893877",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380628262",
      "doi": "10.1109/access.2023.3286311",
      "title": "Leveraging Regression Analysis to Predict Overlapping Symptoms of Cardiovascular Diseases",
      "abstract": "In medical informatics, deep learning-based models are being used to predict and diagnose cardiovascular diseases (CVDs). These models can detect clinical signs, recognize phenotypes, and pick treatment methods for complicated illnesses. One approach to predicting CVDs is to collect a large dataset of patient medical records and use it to train a deep learning model. This study investigated CVDs for early prediction using deep learning-based regression analysis on a dataset of 2621 medical records from UAE hospitals, including age, symptoms, and CVD information. We propose a long short-term memory-based deep neural network for early prediction of CVDs by leveraging the regression analysis. It can be seen that the accuracy level of the diseases increased when they were simulated in pairs of one disease with another due to the overlapping symptoms. The study&#x2019;s results suggest that coronary heart disease has been predicted with an 71.5&#x0025; accuracy level, with 84.4&#x0025; overlapping with Dyspnea; when accuracy measured with a combination of three conditions the accuracy was 86.7&#x0025;, Dyspnea, Chest Pain, and Cyanosis, it has been increased up to 88.9&#x0025;. Weakness, Fatigue, and Emptysis showed a value of 89.8&#x0025;. In our proposed work, the combinations were Dyspnea, Chest Pain, Cyanosis, Weakness and Fatigue, Emptysis, and discomfort pressure in the chest have shown the ideal value of accuracy measured up to 90.6&#x0025;, and with Fever, the accuracy is 91&#x0025;. We show the effectiveness of our proposed method on several evaluation benchmarks.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sara Ghorashi et al.",
      "keywords": "Computer science; Regression analysis; Regression; Artificial intelligence; Machine learning; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3286311",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4315630703",
      "doi": "10.1109/access.2023.3236002",
      "title": "MedAi: A Smartwatch-Based Application Framework for the Prediction of Common Diseases Using Machine Learning",
      "abstract": "Health information technology is one of today&#x2019;s fastest-growing and most powerful technologies. This technology is used predominantly for predicting illness and obtaining medications quickly because visiting a doctor and performing pathological tests can be time-consuming and expensive. This has prompted many researchers to contribute by developing new disease prediction systems or improving existing ones. This paper presents a smartwatch-based prediction system named &#x2018;MedAi&#x2019; for multiple diseases such as ischemic heart disease, hypertension, respiratory disease, hyperthyroidism, hypothyroidism, stroke, myocardial infarction, kidney failure, gallstones, diabetes, dyslipidemia using machine learning algorithms. It comprises three core modules: a prototype smartwatch &#x2018;Sense O&#x2019;Clock&#x2019; equipped with eleven sensors to collect bodily statistics, a machine learning model to analyze the data and make a prediction, and a mobile application to display the prediction result. A dataset consisting of patient bodily statistics was obtained from a local hospital according to ethical guidelines, such as obtaining the prior consent of both patients and doctors. We employ several machine learning algorithms, including Support Vector Machine (SVM), Support Vector Regression (SVR), K-Nearest Neighbor (KNN), Extreme Gradient Boosting (XGBoost), Long Short Term Memory (LSTM), and Random Forest (RF) to investigate the best performing algorithm. Experimentation using our dataset shows that the RF algorithm outperforms other machine learning algorithms such as SVM, KNN, XGBoost, etc., in predicting aforementioned diseases with an accuracy of 99.4&#x0025;. The system provides full-time assistance to the user by reporting his or her body condition and suggesting requisite remedies. It is a notable addition to early disease prediction systems and can predict multiple disease vulnerabilities before they reach an irrecoverable stage. Finally, we compare our method with the related existing methods.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Shinthi Tasnim Himi et al.",
      "keywords": "Smartwatch; Computer science; Machine learning; Artificial intelligence; Wearable computer; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3236002",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312607878",
      "doi": "10.1109/jmw.2022.3223254",
      "title": "Microwave-Enabled Wearables: Underpinning Technologies, Integration Platforms, and Next-Generation Roadmap",
      "abstract": "This paper presents a holistic and authoritative review of the role of microwave technologies in&#13;\\nenabling a new generation of wearable devices. A human-centric Internet of Things (IoT) covering remote&#13;\\nhealthcare, distributed sensing, and consumer electronics, calls for high-performance wearable devices&#13;\\nintegrated into clothing, which require interdisciplinary research efforts to emerge. Microwaves, the \u201cin terconnect\u201d of wireless networks, can enable, rather than solely connect, the next generation of autonomous,&#13;\\nsustainable, and wearable-friendly electronics. First, enabling technologies including wireless power trans mission and RF energy harvesting, backscattering and passive communication, RFID, and electromagnetic&#13;\\nsensing are reviewed. We then discuss the key integration platforms, covering smart fabrics and electronic&#13;\\ntextiles, additive manufacturing, printed electronics, natively-flexible and organic RF semiconductors, and&#13;\\nfully-integrated CMOS systems, where opportunities for hybrid integration are highlighted. The emerging&#13;\\nresearch trends, from mmWave 6G, RF sensing and imaging, to healthcare applications including neural&#13;\\nimplants, drug delivery, and safety upon exposure to microwaves are re-visited and discussed, presenting a&#13;\\nfuture roadmap for interdisciplinary research towards sustainable and reliable next-generation wearables.",
      "year": "2022",
      "journal": "IEEE Journal of Microwaves",
      "authors": "Mahmoud Wagih et al.",
      "keywords": "Wearable computer; Electronics; Wearable technology; Wireless; Underpinning; Computer science; Telecommunications; Engineering; Electrical engineering; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jmw.2022.3223254",
      "cited_by_count": 79,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3134151358",
      "doi": "10.1109/tcsvt.2021.3063952",
      "title": "Cohesive Multi-Modality Feature Learning and Fusion for COVID-19 Patient Severity Prediction",
      "abstract": "The outbreak of coronavirus disease (COVID-19) has been a nightmare to citizens, hospitals, healthcare practitioners, and the economy in 2020. The overwhelming number of confirmed cases and suspected cases put forward an unprecedented challenge to the hospital's capacity of management and medical resource distribution. To reduce the possibility of cross-infection and attend a patient according to his severity level, expertly diagnosis and sophisticated medical examinations are often required but hard to fulfil during a pandemic. To facilitate the assessment of a patient's severity, this paper proposes a multi-modality feature learning and fusion model for end-to-end covid patient severity prediction using the blood test supported electronic medical record (EMR) and chest computerized tomography (CT) scan images. To evaluate a patient's severity by the co-occurrence of salient clinical features, the High-order Factorization Network (HoFN) is proposed to learn the impact of a set of clinical features without tedious feature engineering. On the other hand, an attention-based deep convolutional neural network (CNN) using pre-trained parameters are used to process the lung CT images. Finally, to achieve cohesion of cross-modality representation, we design a loss function to shift deep features of both-modality into the same feature space which improves the model's performance and robustness when one modality is absent. Experimental results demonstrate that the proposed multi-modality feature learning and fusion model achieves high performance in an authentic scenario.",
      "year": "2021",
      "journal": "IEEE Transactions on Circuits and Systems for Video Technology",
      "authors": "Jinzhao Zhou et al.",
      "keywords": "Artificial intelligence; Computer science; Convolutional neural network; Modality (human\u2013computer interaction); Deep learning; Feature (linguistics); Robustness (evolution); Feature learning; Machine learning; Pattern recognition (psychology); Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcsvt.2021.3063952",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392796849",
      "doi": "10.1109/access.2024.3375755",
      "title": "LightGBM: A Leading Force in Breast Cancer Diagnosis Through Machine Learning and Image Processing",
      "abstract": "The early diagnosis of breast cancer (BC), a prominent global cause of mortality, necessitates the development of innovative diagnostic strategies. This study leverages machine learning (ML) and advanced image processing techniques to analyze histopathology images, thereby augmenting the capabilities for BC diagnosis. A robust feature extraction (FE) pipeline is developed, integrating techniques such as color histogram analysis, contour FE, hu moments, and haralick texture features. Ten ML algorithms, including LightGBM (LGBM), CatBoost, and XGBoost, are systematically evaluated across varying magnifications of the BreakHis dataset to assess their diagnostic performance. The research introduces a novel approach by combining distinct FE techniques, enhancing the model&#x2019;s ability to distinguish between benign and malignant tissues with exceptional accuracy. These integrated techniques significantly elevate BC diagnostic accuracy and reliability, holding the potential to positively impact patient outcomes and healthcare systems. Notably, the combination of the FE pipeline and LGBM achieves the highest accuracy, reported in two forms: before augmentation accuracies (0.9598 for <inline-formula> <tex-math notation=\"LaTeX\">$40 \\times $ </tex-math></inline-formula>, 0.9516 for <inline-formula> <tex-math notation=\"LaTeX\">$100 \\times $ </tex-math></inline-formula>, 0.9652 for <inline-formula> <tex-math notation=\"LaTeX\">$200 \\times $ </tex-math></inline-formula>, 0.9535 for <inline-formula> <tex-math notation=\"LaTeX\">$400 \\times $ </tex-math></inline-formula>, and 0.9570 for all magnifications combined) and after augmentation accuracies (0.9949 for <inline-formula> <tex-math notation=\"LaTeX\">$40 \\times $ </tex-math></inline-formula>, 0.9870 for <inline-formula> <tex-math notation=\"LaTeX\">$100 \\times $ </tex-math></inline-formula>, 0.9987 for <inline-formula> <tex-math notation=\"LaTeX\">$200 \\times $ </tex-math></inline-formula>, and 0.9918 for <inline-formula> <tex-math notation=\"LaTeX\">$400 \\times $ </tex-math></inline-formula>) for the classification of magnification histopathological images. Moreover, the study highlights the crucial role of augmentation in further refining classification accuracy. Extending its applicability, the proposed method is also successfully applied to the classification of lung colon cancer images (LC25000 dataset), achieving an impressive accuracy of 0.9983. The model demonstrates its effectiveness and adaptability as a compelling method for histopathological image classification. This research contributes to the evolving field of BC diagnostics, offering a framework for robust and accurate ML-based diagnostic tools that may revolutionize cancer diagnosis and enhance patient care.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Bassam M. Kanber et al.",
      "keywords": "Computer science; Breast cancer; Image processing; Artificial intelligence; Computer vision; Image (mathematics); Cancer; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3375755",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285231429",
      "doi": "10.1109/access.2022.3173643",
      "title": "Key Wearable Device Technologies Parameters for Innovative Healthcare Delivery in B5G Network: A Review",
      "abstract": "The future of healthcare relies heavily on the connection of humans to intelligent devices via communication networks for rapid medical response. Hence, the evaluation of the performance of smart wearable devices as veritable tools for prompt, pervasive, and proactive healthcare delivery to end-users in response to socio-economic dynamics is imperative especially as 5G unwinds and B5G emerges. Despite the boom in the wearable market and significant improvement in communication technologies, the translation of wearable data from clinical trials to valuable assets for practical medical application is burdened with varying challenges. This review provides an introspective analysis of the performance of unobtrusive wearable devices based on identified key performance indicators (KPIs) in relation to evolving generation networks in achieving innovative health care delivery. A total of 2751 articles pooled from 5 digital libraries were screened and 16 were selected for this review using PRISMA. The identified E-DISC wearable KPIs; energy efficiency, discretization, intelligence, secured network, and customizable standards are currently engrossed with both reliability and real-time issues that undermine its performance, perceptibility, and acceptability by end-users. The transformation of smart wearable devices&#x2019; data from clinical trials into intangible resources for medical application is the fulcrum of innovative healthcare actualization. Further insight on how the identified challenges can be streamlined for smooth device alignment and transition to the emerging B5G network and its eco-friendly environment is also discussed. It is hoped that this will serve as a rallying point for research direction in translating prospective wearable solutions into a valuable resource for actualizing p-health.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Simeon Okechukwu Ajakwe et al.",
      "keywords": "Wearable computer; Computer science; Wearable technology; Health care; Key (lock); Digital health; Performance indicator; Reliability (semiconductor); Human\u2013computer interaction; Risk analysis (engineering); Data science; Embedded system; Computer security; Medicine; Business",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3173643",
      "cited_by_count": 44,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3015172426",
      "doi": "10.1109/jtehm.2020.2983156",
      "title": "Monitoring Wound Healing With Contactless Measurements and Augmented Reality",
      "abstract": "The device has proven to be an objective and non-operator-dependent tool for assessing the morphological parameters of the wound. Comparison with non-contact devices shows improved accuracy, offering reliable and rigorous measurements. Clinical Impact: Chronic wounds represent a significant health problem with high recurrence rates due to the ageing of the population and diseases such as diabetes and obesity. The device presented in this work provides an easy-to-use non-invasive tool to obtain useful information for treatment.",
      "year": "2020",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Virginia Mamone et al.",
      "keywords": "Projector; Augmented reality; Computer science; Chronic wound; Imaging phantom; Projection (relational algebra); Repeatability; Biomedical engineering; Population; Artificial intelligence; Computer vision; Wound healing; Medicine; Mathematics; Algorithm; Surgery; Statistics; Nuclear medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2020.2983156",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3083864010",
      "doi": "10.1109/access.2020.3022366",
      "title": "Unsupervised Anomaly Detection in Multivariate Spatio-Temporal Data Using Deep Learning: Early Detection of COVID-19 Outbreak in Italy",
      "abstract": "Unsupervised anomaly detection for spatio-temporal data has extensive use in a wide variety of applications such as earth science, traffic monitoring, fraud and disease outbreak detection. Most real-world time series data have a spatial dimension as an additional context which is often expressed in terms of coordinates of the region of interest (such as latitude - longitude information). However, existing techniques are limited to handle spatial and temporal contextual attributes in an integrated and meaningful way considering both spatial and temporal dependency between observations. In this paper, a hybrid deep learning framework is proposed to solve the unsupervised anomaly detection problem in multivariate spatio-temporal data. The proposed framework works with unlabeled data and no prior knowledge about anomalies are assumed. As a case study, we use the public COVID-19 data provided by the Italian Department of Civil Protection. Northern Italy regions' COVID-19 data are used to train the framework; and then any abnormal trends or upswings in COVID-19 data of central and southern Italian regions are detected. The proposed framework detects early signals of the COVID-19 outbreak in test regions based on the reconstruction error. For performance comparison, we perform a detailed evaluation of 15 algorithms on the COVID-19 Italy dataset including the state-of-the-art deep learning architectures. Experimental results show that our framework shows significant improvement on unsupervised anomaly detection performance even in data scarce and high contamination ratio scenarios (where the ratio of anomalies in the data set is more than 5%). It achieves the earliest detection of COVID-19 outbreak and shows better performance on tracking the peaks of the COVID-19 pandemic in test regions. As the timeliness of detection is quite important in the fight against any outbreak, our framework provides useful insight to suppress the resurgence of local novel coronavirus outbreaks as early as possible.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Y\u0131ld\u0131z Karaday\u0131 et al.",
      "keywords": "Anomaly detection; Computer science; Context (archaeology); Multivariate statistics; Temporal database; Data mining; Unsupervised learning; Artificial intelligence; Anomaly (physics); Deep learning; Pattern recognition (psychology); Machine learning; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3022366",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226032711",
      "doi": "10.1109/access.2022.3164075",
      "title": "Eye-Tracking Assistive Technologies for Individuals With Amyotrophic Lateral Sclerosis",
      "abstract": "Amyotrophic lateral sclerosis, also known as ALS, is a progressive nervous system disorder that affects nerve cells in the brain and spinal cord, resulting in the loss of muscle control. For individuals with ALS, where mobility is limited to the movement of the eyes, the use of eye-tracking-based applications can be applied to achieve some basic tasks with certain digital interfaces. This paper presents a review of existing eye-tracking software and hardware through which eye-tracking their application is sketched as an assistive technology to cope with ALS. Eye-tracking also provides a suitable alternative as control of game elements. Furthermore, artificial intelligence has been utilized to improve eye-tracking technology with significant improvement in calibration and accuracy. Gaps in literature are highlighted in the study to offer a direction for future research.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Hilary O. Edughele et al.",
      "keywords": "Amyotrophic lateral sclerosis; Computer science; Eye tracking; Assistive technology; Eye movement; Tracking (education); Artificial intelligence; Tracking system; Controller (irrigation); Computer vision; Human\u2013computer interaction; Physical medicine and rehabilitation; Medicine; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3164075",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3094625321",
      "doi": "10.1109/access.2020.3032202",
      "title": "Gait Analysis for Early Neurodegenerative Diseases Classification Through the Kinematic Theory of Rapid Human Movements",
      "abstract": "Neurodegenerative diseases are particular diseases whose decline can partially or completely compromise the normal course of life of a human being. In order to increase the quality of patient's life, a timely diagnosis plays a major role. The analysis of neurodegenerative diseases, and their stage, is also carried out by means of gait analysis. Performing early stage neurodegenerative disease assessment is still an open problem. In this paper, the focus is on modeling the human gait movement pattern by using the kinematic theory of rapid human movements and its sigma-lognormal model. The hypothesis is that the kinematic theory of rapid human movements, originally developed to describe handwriting patterns, and used in conjunction with other spatio-temporal features, can discriminate neurodegenerative diseases patterns, especially in early stages, while analyzing human gait with 2D cameras. The thesis empirically demonstrates its effectiveness in describing neurodegenerative patterns, when used in conjunction with state-of-the-art pose estimation and feature extraction techniques. The solution developed achieved 99.1% of accuracy using velocity-based, angle-based and sigma-lognormal features and left walk orientation.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Vincenzo Dentamaro et al.",
      "keywords": "Kinematics; Gait analysis; Physical medicine and rehabilitation; Computer science; Gait; Artificial intelligence; Neuroscience; Medicine; Psychology; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3032202",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3101047706",
      "doi": "10.23919/jsc.2020.0003",
      "title": "Measuring Cities with Software-Defined Sensors",
      "abstract": "The Chicago Array of Things (AoT) project, funded by the US National Science Foundation, created an experimental, urban-scale measurement capability to support diverse scientific studies. Initially conceived as a traditional sensor network, collaborations with many science communities guided the project to design a system that is remotely programmable to implement Artificial Intelligence (AI) within the devices-at the \u201cedge\u201d of the network-as a means for measuring urban factors that heretofore had only been possible with human observers, such as human behavior including social interaction. The concept of \u201csoftware-defined sensors\u201d emerged from these design discussions, opening new possibilities, such as stronger privacy protections and autonomous, adaptive measurements triggered by events or conditions. We provide examples of current and planned social and behavioral science investigations uniquely enabled by software-defined sensors as part of the SAGE project, an expanded follow-on effort that includes AoT.",
      "year": "2020",
      "journal": "Journal of Social Computing",
      "authors": "Charlie Catlett et al.",
      "keywords": "Software; Computer science; Geography; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2020.0003",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3096288315",
      "doi": "10.1109/access.2020.3035540",
      "title": "Stress Reduction Using Bilateral Stimulation in Virtual Reality",
      "abstract": "The goal of this research is to integrate Virtual Reality (VR) with the bilateral stimulation used in EMDR as a tool to relieve stress. We created a 15 minutes relaxation training program for adults in a virtual, relaxing environment in form of a walk in the woods. The target platform for the tool is HTC Vive, however it can be easily ported to other VR platforms. An integral part of this tool is a set of sensors, which serves as physiological measures to evaluate the effectiveness of such system. What is more, the system integrate visual (passing sphere), auditory (surround sound) and tactile signals (vibration of controllers). A pilot treatment programme, incorporating the above mentioned VR system, was carried out. Experimental group consisting of 28 healthy adult volunteers (office workers), participated in three different sessions of relaxation training. Before starting, baseline features such as subjectively perceived stress, mood, heart rate, galvanic skin response and muscle response were registered. The monitoring of physiological indicators is continued during the training session and one minute after its completion. Before and after the session, volunteers were asked to re-fill questionnaires regarding the current stress level and mood. The obtained results were analyzed in terms of variability over time: before, during and after the session.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Dorota Kami\u0144ska et al.",
      "keywords": "Virtual reality; Session (web analytics); Skin conductance; Stress reduction; Computer science; Mood; Relaxation (psychology); Stress (linguistics); Physical stress; Simulation; Set (abstract data type); Human\u2013computer interaction; Audiology; Psychology; Applied psychology; Medicine; Biomedical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3035540",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3088576166",
      "doi": "10.1109/access.2020.3025808",
      "title": "Machine Learning-Based Automatic Detection of Central Sleep Apnea Events From a Pressure Sensitive Mat",
      "abstract": "Polysomnography (PSG) is the standard test for diagnosing sleep apnea. However, the approach is obtrusive, time-consuming, and with limited access for patients in need of sleep apnea diagnosis. In recent years, there have been many attempts to search for an alternative device or approach that avoids the limitations of PSG. Pressure-sensitive mats (PSM) have proven to be able to detect central sleep apneas (CSA) and be a potential alternative for PSG. In the current study, we combine advanced machine learning approaches with a practical unobtrusive home monitoring device (PSM) to detect CSA events from data collected nocturnally and unattended. Two deep learning methods are implemented for the automatic detection of CSA events: a temporal convolutional network (TCN) and a bidirectional long short-term memory (BiLSTM) network. The deep learning models are compared to a classical machine learning approach (linear support vector machine, SVM) and a simple threshold-based algorithm. Considering the characteristics of each method, we choose strategies, including resampling and weighted cost-functions, to optimize the methods and to perform CSA detection as anomaly detection in an imbalanced data set. We evaluate the performance of all models on a database containing 7 days of data from 9 elderly patients. From the resulting 63 days, data from 7 patients (49 days) are devoted to training for optimizing hyperparameters, and data from 2 patients (14 days) are devoted to testing. Experimental results indicate that the best-performing model achieves an accuracy of 95.1% through training an BiLSTM network. Overall, the implemented deep learning methods achieve better performance than the conventional classification approach (SVM) and the simple threshold-based method, and show good potential for the use of PSM for practical unobtrusive monitoring of CSA.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Hilda Azimi et al.",
      "keywords": "Computer science; Artificial intelligence; Support vector machine; Deep learning; Machine learning; Hyperparameter; Polysomnography; Resampling; Sleep apnea; Apnea; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3025808",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3165724572",
      "doi": "10.1109/tim.2021.3083415",
      "title": "Proof of Concept of a Novel Neck-Situated Wearable PPG System for Continuous Physiological Monitoring",
      "abstract": "Continuous overnight vital signs monitoring would be ideal for patients suffering from epilepsy, where life-threatening hypoxemias can occur during sleep. However, the existing physiological monitoring systems suffer from limitations in terms of usability factors and/or limited information of the signals being acquired. The body location of the monitoring system is a crucial consideration, seldom addressed by the wider community. This article presents a proof-of-concept, neck-worn photoplethysmography system, which was developed and tested to assess the feasibility of the neck as a monitoring site for longitudinal sensing of cardiac and respiratory responses during sleep. The novel system was compared against a gold-standard commercial multichannel cardiorespiratory polysomnography (PSG) system during oxygen desaturation cycles, to assess its ability to measure heart rate, respiratory rate (RR), and peripheral blood oxygen saturation (SpO 2 ) on 15 participants. The findings for heart rate showed a marginal mean error of 0.47 beats/min with limits of agreement (LOA) at 95% confidence between \u22123.17 and 4 bpm. RR comparisons had an overall mean error of 0.43 breaths/min, with LOA at 95% confidence between \u22122.73 and 3.3 bpm. Lastly, the system accurately outputs SpO 2 with an overall root-mean-square error of 1.44% between 90 and 100% SpO 2 using a custom calibration method. Moreover, it was observed that the neck made it possible for the system to detect desaturation events on an average 12.6 s prior to the PSG system, which used a peripheral finger-based PPG system. Ultimately, this proof-of-concept study illustrates the viability of neck-based sensing for minimally invasive monitoring of cardiac and respiratory vitals during sleep.",
      "year": "2021",
      "journal": "IEEE Transactions on Instrumentation and Measurement",
      "authors": "Sukhpreet Singh et al.",
      "keywords": "Photoplethysmogram; Heart rate; Cardiorespiratory fitness; Respiratory rate; Confidence interval; Polysomnography; Oxygen saturation; Raspberry pi; Wearable computer; Computer science; Medicine; Artificial intelligence; Physical therapy; Blood pressure; Internet of Things; Anesthesia; Internal medicine; Embedded system; Apnea; Oxygen; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tim.2021.3083415",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391547665",
      "doi": "10.1109/access.2024.3362233",
      "title": "Additive Cross-Modal Attention Network (ACMA) for Depression Detection Based on Audio and Textual Features",
      "abstract": "Detecting depression involves using standardized questionnaires like the Patient Health Questionnaires (PHQ-8/9). Yet, patients might not always provide genuine responses, leading to potential misdiagnoses. Therefore, the need for a means to detect depression in patients without the use of preset questions is of high importance. Addressing this challenge, our study aims to discern telltale symptoms from statements made by the patient. We harness both audio and text data, proposing an Additive cross-modal attention network to learn and pick up the appropriate weights that best capture the cross-modal interactions and relationships between both features using BiLSTM as the backbone of both modalities. We tested our approach on the DAIC-WOZ dataset for depression detection and also evaluated our model performance on the EATD-Corpus. Benchmarked against similar studies on these datasets, our method demonstrates commendable efficacy in both classification and regression models for both unimodal and multimodal approaches. Our findings underscore the potential of our model to effectively detect depression in patients while using textual and speech modalities without the necessary use of preset questions for effective detection.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ngumimi Karen Iyortsuun et al.",
      "keywords": "Modalities; Modal; Computer science; Depression (economics); Artificial intelligence; Machine learning; Natural language processing; Speech recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3362233",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3217120025",
      "doi": "10.1109/access.2021.3129850",
      "title": "Comparison of Machine Learning Techniques Applied to Traffic Prediction of Real Wireless Network",
      "abstract": "Today, the traffic amount is growing inexorably due to the increase in the number of devices on the network. Researchers analyze traffic by identifying sophisticated dependencies, anomalies, and novel traffic patterns to improve the performance of systems as a whole. One of the fast development niches in this domain is related to Classic and Deep Machine Learning techniques that are supposed to improve the network operation in the most complex heterogeneous environment. In this work, we first outline existing applications of Machine Learning in the communications domain and further list the most significant challenges and potential solutions while implementing those. Finally, we compare different classical methods predicting the traffic on the LTE network Edge by utilizing such techniques as Linear Regression, Gradient Boosting, Random Forest, Bootstrap Aggregation (Bagging), Huber Regression, Bayesian Regression, and Support Vector Machines (SVM). We develop the corresponding Machine Learning environment based on a public cellular traffic dataset and present a comparison table of the quality metrics and execution time for each model. After the analysis, the SVM method proved to allow for a much faster training compared to other algorithms. Gradient Boosting showed the best quality of predictions as it has the most efficient data determination. Random forest shows the worst result since it depends on the number of features that may be limited. The probabilistic approach-based Bayesian regression method showed slightly worse results than Gradient Boosting, but its training time was shorter. The performance evaluation demonstrated good results for linear models with the Huber loss function, which optimizes the model parameters better. As a standalone contribution, we offer the source code of the analyzed algorithms in Open Access.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Daria Alekseeva et al.",
      "keywords": "Computer science; Machine learning; Support vector machine; Artificial intelligence; Gradient boosting; Boosting (machine learning); Random forest; Online machine learning; Probabilistic logic; Regression; Data mining; Linear regression; Bayesian network; Artificial neural network; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3129850",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3132900071",
      "doi": "10.1109/ojcs.2021.3052518",
      "title": "Multi-View Deep Learning Framework for Predicting Patient Expenditure in Healthcare",
      "abstract": "Accurately predicting patient expenditure in healthcare is an important task with many applications such as provider profiling, accountable care management, and capitated medical payment adjustment. Existing approaches mainly rely on manually designed features and linear regression-based models, which require massive medical domain knowledge and show limited predictive performance. This paper proposes a multi-view deep learning framework to predict future healthcare expenditure at the individual level based on historical claims data. Our multi-view approach can effectively model the heterogeneous information, including patient demographic features, medical codes, drug usages, and facility utilization. We conducted expenditure forecasting tasks on a real-world pediatric dataset that contains more than 450,000 patients. The empirical results show that our proposed method outperforms all baselines for predicting medical expenditure. These findings help toward better preventive care and accountable care in the healthcare domain.",
      "year": "2021",
      "journal": "IEEE Open Journal of the Computer Society",
      "authors": "Xianlong Zeng et al.",
      "keywords": "Health care; Computer science; Profiling (computer programming); Task (project management); Deep learning; Domain (mathematical analysis); Payment; Artificial intelligence; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcs.2021.3052518",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387951920",
      "doi": "10.1109/access.2023.3327905",
      "title": "The Economic Value and Clinical Impact of Artificial Intelligence in Healthcare: A Scoping Literature Review",
      "abstract": "Artificial Intelligence (AI)-supported healthcare has seen a substantial rise in development in recent years. The health economic impact is a crucial factor in the decision-making process regarding AI adoption. This study aimed to analyze the latest research progress and evidence on the cost-effectiveness and clinical efficiency of healthcare AI software from various perspectives, as well as to identify future opportunities and remaining challenges. A review of global literature was conducted using two key databases, PubMed and Embase, along with other related bibliographic resources. The literature search yielded 1,178 unique articles, of which 31 were included in our analysis. These studies covered a wide variety of clinical use cases and healthcare domains, including disease diagnosis (n&#x003D;13, 41.9&#x0025;), risk analysis (n&#x003D;6, 19.4&#x0025;), screening or patient triage (n&#x003D;6, 19.4&#x0025;), treatment delivery (n&#x003D;5, 16.1&#x0025;), and patient engagement or follow-up (n&#x003D;1, 3.2&#x0025;). Among the included studies, 24 (77.4&#x0025;) examined the cost-effectiveness of AI compared to standard human-based practices from the perspectives of patients, healthcare systems, payors, or society. The remaining 7 studies, including 5 clinical trials, concluded that AI can enhance clinical efficiency by shortening labor time or patient journey in the clinic. The findings of this targeted literature review demonstrated that leveraging AI in human decision-making has the potential to improve multilevel health outcomes. However, there is a shortage of prospective health economic studies, particularly long-term evaluations, highlighting the disparity between the rapid progress of AI and its lagging utilization in real-world practices.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Weiqi Jiao et al.",
      "keywords": "Health care; Triage; Lagging; Applications of artificial intelligence; Medicine; MEDLINE; Clinical trial; Artificial intelligence; Computer science; Medical emergency; Political science; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3327905",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385731885",
      "doi": "10.1109/access.2023.3304236",
      "title": "Machine Learning in ADHD and Depression Mental Health Diagnosis: A Survey",
      "abstract": "This paper explores the current machine learning based methods used to identify Attention Deficit Hyperactivity Disorder (ADHD) and depression in humans. Prevalence of mental ADHD and depression is increasing worldwide, partly due to the devastating impact of the COVID-19 pandemic for the latter but also because of the increasing demand placed on the mental health services. It is known that depression is the most common mental health condition, affecting an estimated 19.7&#x0025; of people aged over 16. ADHD is also a very prevalent mental health condition, affecting approximately 7.2&#x0025; of all age groups, with this being conceived as a conservative estimate. We explore the use of machine learning to identify ADHD and depression using different wearable and non-wearable sensors/modalities for training and testing. These modalities include functional Magnetic Resonance Imagery (fMRI), Electroencephalography (EEG), Medical Notes, Video and Speech. With mental health awareness on the rise, it is necessary to survey the existing literature on ADHD and depression for a machine learning based reliable Artificial Intelligence (AI). With access to in-person clinics limited and a paradigm shift to remote consultations, there is a need for AI-based technology to support the healthcare bodies, particularly in developed countries.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Christian Nash et al.",
      "keywords": "Mental health; Modalities; Depression (economics); Wearable computer; Psychiatry; Attention deficit hyperactivity disorder; Psychology; Electroencephalography; Major depressive disorder; Clinical psychology; Artificial intelligence; Machine learning; Computer science; Mood",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3304236",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3008740022",
      "doi": "10.1109/access.2020.2974911",
      "title": "Engineering Privacy in Smartphone Apps: A Technical Guideline Catalog for App Developers",
      "abstract": "With the rapid growth of technology in recent years, we are surrounded by or even dependent on the use of technological devices such as smartphones as they are now an indispensable part of our life. Smartphone applications (apps) provide a wide range of utilities such as navigation, entertainment, fitness, etc. To provide such context-sensitive services to users, apps need to access users' data including sensitive ones, which in turn, can potentially lead to privacy invasions. To protect users against potential privacy invasions in such a vulnerable ecosystem, legislation such as the European Union General Data Protection Regulation (EU GDPR) demands best privacy practices. Therefore, app developers are required to make their apps compatible with legal privacy principles enforced by law. However, this is not an easy task for app developers to comprehend purely legal principles to understand what needs to be implemented. Similarly, bridging the gap between legal principles and technical implementations to understand how legal principles need to be implemented is another barrier to develop privacy-friendly apps. To this end, this paper proposes a privacy and security design guide catalog for app developers to assist them in understanding and adopting the most relevant privacy and security principles in the context of smartphone apps. The presented catalog is aimed at mapping the identified legal principles to practical privacy and security solutions that can be implemented by developers to ensure enhanced privacy aligned with existing legislation. Through conducting a case study, it is confirmed that there is a significant gap between what developers are doing in reality and what they promise to do. This paper provides researchers and developers of privacy-related technicalities an overview of the characteristics of existing privacy requirements needed to be implemented in smartphone ecosystems, on which they can base their work.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Majid Hatamian",
      "keywords": "Internet privacy; Computer science; Computer security; Legislation; Context (archaeology); Android (operating system); Information privacy; Privacy by Design; Implementation; Bridging (networking); European union; World Wide Web; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2974911",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226300832",
      "doi": "10.1109/access.2022.3168045",
      "title": "Prediction of Length of Stay in the Emergency Department for COVID-19 Patients: A Machine Learning Approach",
      "abstract": "The coronavirus disease (COVID-19) outbreak has become a global public health threat. The influx of COVID-19 patients has prolonged the length of stay (LOS) in the emergency department (ED) in the United States. Our objective is to develop a reliable prediction model for COVID-19 patient ED LOS and identify clinical factors, such as age and comorbidities, associated with LOS within a '4-hour target.' Data were collected from an urban, demographically diverse hospital in Detroit for all COVID-19 patients' ED presentations from March 16 to December 29, 2020. We trained four machine learning models, namely logistic regression (LR), gradient boosting (GB), decision tree (DT), and random forest (RF), across different data processing stages to predict COVID-19 patients with an ED LOS of less than or greater than 4 hours. The analysis is inclusive of 3,301 COVID-19 patients with known ED LOS, and 16 significant clinical factors were incorporated. The GB model outperformed the baseline classifier (LR) and tree-based classifiers (DT and RF) with an accuracy of 85% and F1-score of 0.88 for predicting ED LOS in the testing data. No significant accuracy gains were achieved through further splitting. This study identified key independent factors from a combination of patient demographics, comorbidities, and ED operational data that predicted ED stay in patients with prolonged COVID-19. The prediction framework can serve as a decision-support tool to improve ED and hospital resource planning and inform patients about better ED LOS estimations.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Egbe-Etu Etu et al.",
      "keywords": "Emergency department; Logistic regression; Random forest; Coronavirus disease 2019 (COVID-19); Gradient boosting; Machine learning; Decision tree; Artificial intelligence; Medicine; Predictive modelling; Computer science; Emergency medicine; Triage; Outbreak; Medical emergency; Disease; Internal medicine; Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3168045",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3115192336",
      "doi": "10.1109/access.2020.3047186",
      "title": "A Novel and Reliable Framework of Patient Deterioration Prediction in Intensive Care Unit Based on Long Short-Term Memory-Recurrent Neural Network",
      "abstract": "The clinical investigation explored that early recognition and intervention are crucial for preventing clinical deterioration in patients in Intensive Care units (ICUs). Deterioration of patients is predictable and can be preventable if early risk factors are recognized and developed in the clinical setting. Timely detection of deterioration in ICU patients may also lead to better health management. In this paper, a new model was proposed based on Long Short-Term Memory-Recurrent Neural Network (LSTM-RNN) to predict deterioration of ICU patients. An optimisation model based on a modified genetic algorithm (GA) has also been proposed in this study to optimize the observation window, prediction window, and the number of neurons in hidden layers to increase accuracy, AUROC, and minimize test loss. The experimental results demonstrate that the prediction model proposed in this study acquired a significantly better classification performance compared with many other studies that used deep learning models in their works. Our proposed model was evaluated for two tasks: mortality and sudden transfer of patients to ICU. Our results show that the proposed model could predict deterioration before one hour of onset and outperforms other models. In this study, the proposed predictive model is implemented using the state-of-the-art graphical processing unit (GPU) virtual machine provided by Google Colaboratory. Moreover, the study uses a novel time-series approach, which is minute-by-minute. This novel approach enables the proposed model to obtain highly accurate results (i.e., an AUROC of 0.933 and an accuracy of 0.921). This study utilizes the individual and combined effectiveness of different types of variables (i.e., vital signs, laboratory measurements, GCS, and demographic data). In this study, data was extracted from MIMIC-III database. The ad-hoc frameworks proposed by previous studies can be improved by the novel and reliable prediction framework proposed in this research, which will result in predictions of more accurate performance. The proposed predictive model could reduce the required observation window (i.e., a reduction of 83%) for the prediction task while improving the performance. In fact, the proposed significant small size of observation window could obtain higher results which outperformed all previous works that utilize different sizes of observation window (i.e., 48 hours and 24 hours). Moreover, this research demonstrates the ability of the proposed predictive model to achieve accurate results (&gt;80%) on `raw' data in an experimental work. This shows that the rule-based pre-processing of clinical features is unnecessary for deep learning predictive models.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Tariq Ibrahim Al-Shwaheen et al.",
      "keywords": "Computer science; Recurrent neural network; Artificial intelligence; Artificial neural network; Machine learning; Deep learning; Intensive care unit; Long short term memory; Medicine; Intensive care medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3047186",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2930439125",
      "doi": "10.1109/access.2019.2908662",
      "title": "Prediction of Ecological Pressure on Resource-Based Cities Based on an RBF Neural Network Optimized by an Improved ABC Algorithm",
      "abstract": "Resource-based cities are those where resource-based industries comprise a large proportion of all industries. Sustainable development implies that cities make full use of their own resources to support current development initiatives and take sustainability into account both during and after resource consumption. To promote investment in the sustainable development of resource-based cities and to a provide a decision system for these cities, this paper uses an ecological footprint model to evaluate and analyze the per capita ecological footprint, per capita ecological carrying capacity and per capita ecological deficit of a representative resource-based city, Yulin. The data are collected from 2001 to 2015. In addition, due to the complexity of the influencing factors for ecological carrying capacity and the variety of situations that are difficult to accurately predict, this paper proposes a new urban ecological carrying capacity prediction model, which consists of a radial basis function (RBF) neural network that is optimized by an improved artificial bee colony algorithm. The prediction results show that energy consumption is the major factor affecting the urban ecosystem; moreover, the model precision of the training results and the simulation accuracy of the test results achieved by the RBF neural network model are 97.91% and 94.16%, respectively, and in 2020, the per capita ecological footprint, biocapacity, and ecological deficit of Yulin are predicted to reach 4.892 hm<sup>2</sup>, 3.317 hm<sup>2</sup>, and 1.575 hm<sup>2</sup>, respectively. Accordingly, effective proactive measures should be taken in advance to maintain or reduce the ecological pressure on this resource-dependent city. This paper strives to provide a scientific basis for local government decision-making to realize the healthy, stable, and rapid sustainable development of resource-based cities.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Song Jiang et al.",
      "keywords": "Ecological footprint; Per capita; Artificial neural network; Sustainability; Resource (disambiguation); Carrying capacity; Sustainable development; Computer science; Environmental economics; Consumption (sociology); Resource consumption; Ecology; Environmental resource management; Artificial intelligence; Machine learning; Environmental science; Economics; Population",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2908662",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386453684",
      "doi": "10.1109/access.2023.3312183",
      "title": "HDLNET: A Hybrid Deep Learning Network Model With Intelligent IOT for Detection and Classification of Chronic Kidney Disease",
      "abstract": "Over 10&#x0025; of the world&#x2019;s population now suffers from chronic kidney disease (CKD), and millions die yearly. CKD should be detected early to extend the lives of those suffering and lower the cost of therapy. Building such a multimedia-driven model is necessary to detect the illness effectively and accurately before it worsens the situation. It is challenging for doctors to identify the various conditions connected to CKD early to prevent the condition. This study introduces a novel hybrid deep learning network model (HDLNet) for CKD early detection and prediction. A deep learning-based technique called the Deep Separable Convolution Neural Network (DSCNN) has been suggested in this research for the early detection of CKD. More processing attributes of characteristics chosen to indicate a kidney issue are extracted by the Capsule Network (CapsNet). The pertinent characteristics are selected using the Aquila Optimization Algorithm (AO) method to speed up the categorization process. The necessary features improve classification effectiveness while needing less computational effort. The DSCNN technique is optimized to diagnose kidney illness as CKD or non-CKD using the Sooty Tern Optimization Algorithm (STOA). The CKD dataset, found in the UCI machine learning repository, is then used to test the dataset. Accuracy, sensitivity, MCC, PPV, FPR, FNR, and specificity are the performance metrics for the suggested CKD classification approach. Additional experimental findings demonstrate that the suggested method produces a better categorization of CKD than the present state-of-the-art method.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Kommuri Venkatrao et al.",
      "keywords": "Kidney disease; Computer science; Artificial intelligence; Deep learning; Categorization; Machine learning; Population; Artificial neural network; Data mining; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312183",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3132796384",
      "doi": "10.1109/access.2021.3059469",
      "title": "Risk Factors and Comorbidities Associated to Cardiovascular Disease in Qatar: A Machine Learning Based Case-Control Study",
      "abstract": "&lt;p&gt;Cardiovascular disease (CVD) is reported to be the leading cause of mortality in the middle eastern countries, including Qatar. But no comprehensive study has been conducted on the Qatar specific CVD risk factors identification. The objective of this case-control study was to develop machine learning (ML) model distinguishing healthy individuals from people having CVD, which could ultimately reveal the list of potential risk factors associated to CVD in Qatar. To the best of our knowledge, this study considered the largest collection of biomedical measurements representing the anthropometric measurements, clinical biomarkers, bioimpedance, spirometry, VICORDER readings, and behavioral factors of the CVD group from Qatar Biobank (QBB). CatBoost model achieved 93% accuracy, thereby outperforming the existing model for the same purpose. Interestingly, combining multimodal datasets into the proposed ML model outperformed the ML model built upon currently known risk factors for CVD, emphasizing the importance of incorporating other clinical biomarkers into consideration for CVD diagnosis plan. The ablation study on the multimodal dataset from QBB revealed that physio-clinical and bioimpedance measurements have the most distinguishing power to classify these two groups irrespective of gender and age of the participants. Multiple feature subset selection techniques confirmed known CVD risk factors (blood pressure, lipid profile, smoking, sedentary life, and diabetes), and identified potential novel risk factors linked to CVD-related comorbidities such as renal disorder (e.g., creatinine, uric acid, homocysteine, albumin), atherosclerosis (intima media thickness), hypercoagulable state (fibrinogen), and liver function (e.g., alkaline phosphate, gamma-glutamyl transferase). Moreover, the inclusion of the proposed novel factors into the ML model provides better performance than the model with traditional known risk factors for CVD. The association of the proposed risk factors and comorbidities are required to be investigated in clinical setup to understand their role in CVD bette&lt;/p&gt;&lt;h2&gt;Other Information&lt;/h2&gt;&lt;p&gt;Published in: IEEE Access&lt;br&gt;License: &lt;a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\" target=\"_blank\"&gt;https://creativecommons.org/licenses/by/4.0/&lt;/a&gt;&lt;br&gt;See article on publisher's website: &lt;a href=\"https://dx.doi.org/10.1109/access.2021.3059469\" target=\"_blank\"&gt;https://dx.doi.org/10.1109/access.2021.3059469&lt;/a&gt;&lt;/p&gt;",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hamada R. H. Al-Absi et al.",
      "keywords": "Medicine; Disease; Diabetes mellitus; Uric acid; Anthropometry; Internal medicine; Physical therapy; Endocrinology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3059469",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226509287",
      "doi": "10.1109/access.2022.3169893",
      "title": "Three-Heartbeat Multilead ECG Recognition Method for Arrhythmia Classification",
      "abstract": "Electrocardiogram (ECG) is the primary basis for the diagnosis of cardiovascular diseases. However, the amount of ECG data of patients makes manual interpretation time-consuming and onerous. Therefore, the intelligent ECG recognition technology is an important means to decrease the shortage of medical resources. This study proposes a novel classification method for arrhythmia that uses for the very first time a three-heartbeat multi-lead (THML) ECG data in which each fragment contains three complete heartbeat processes of multiple ECG leads. The THML ECG data pre-processing method is formulated which makes use of the MIT-BIH arrhythmia database as training samples. Four arrhythmia classification models are constructed based on one-dimensional convolutional neural network (1D-CNN) combined with a priority model integrated voting method to optimize the integrated classification effect. The experiments followed the recommended inter-patient scheme of the Association for the Advancement of Medical Instrumentation (AAMI) recommendations, and the practicability and effectiveness of THML ECG data are proved with ablation experiments. Results show that the average accuracy of the N, V, S, F, and Q classes is 94.82&amp;#x0025;, 98.10&amp;#x0025;, 97.28&amp;#x0025;, 98.70&amp;#x0025;, and 99.97&amp;#x0025;, respectively, with the positive predictive value of the N, V, S, and F classes being 97.0&amp;#x0025;, 90.5&amp;#x0025;, 71.9&amp;#x0025;, and 80.4&amp;#x0025;, respectively. Compared with current studies, the THML ECG data can effectively improve the morphological integrity and time continuity of ECG information and the 1D-CNN model of ECG sequence has a higher accuracy for arrhythmia classification. The proposed method alleviates the problem of insufficient samples, meets the needs of medical ECG interpretation and contributes to the intelligent dynamic research of cardiac disease.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Liang-Hung Wang et al.",
      "keywords": "Heartbeat; Computer science; Artificial intelligence; Convolutional neural network; Pattern recognition (psychology); Artificial neural network; Cardiac arrhythmia; Deep learning; Data mining; Medicine; Cardiology; Atrial fibrillation",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3169893",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3124975525",
      "doi": "10.1109/access.2021.3054236",
      "title": "A Novel Technique for Non-Invasive Measurement of Human Blood Component Levels From Fingertip Video Using DNN Based Models",
      "abstract": "Blood components such as hemoglobin, glucose, creatinine measuring are essential for monitoring one's health condition. The current blood component measurement approaches still depend on invasive techniques that are painful, and uncomfortable for the patients. To facilitate measurement at home, we proposed a novel non-invasive technique to measure blood hemoglobin, glucose, and creatinine level based on PPG signal using Deep Neural Networks (DNN). Fingertip videos from 93 subjects have been collected using a smartphone. The PPG signal is generated from each video, and 46 characteristic features are then extracted from the PPG signal, its derivatives (1<sup>st</sup> and 2<sup>nd</sup>) and from Fourier analysis. Additionally, age and gender are also included to feature because of the significant effects on hemoglobin, glucose, and creatinine. A correlation-based feature selection (CFS) using genetic algorithms (GA) has been used to select the optimal features to avoid redundancy and over-fitting. Finally, DNN based models have been developed to estimate the blood Hemoglobin (Hb), Glucose (Gl), and Creatinine (Cr) levels from the selected features. The approach provides the best-estimated accuracy of R<sup>2</sup> = 0.922 for Hb, R<sup>2</sup> = 0.902 for Gl, and R<sup>2</sup> = 0.969 for Cr. Experimental aftermaths show that the proposed method is a suitable technique to be used clinically to measure human blood component levels without taking blood samples. This paper also reveals that smartphone-based PPG signal has a great potential to measure the different blood components.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Md. Rezwanul Haque et al.",
      "keywords": "Artificial intelligence; Hemoglobin; Computer science; Redundancy (engineering); Artificial neural network; Creatinine; Pattern recognition (psychology); Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3054236",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4307091673",
      "doi": "10.1109/rbme.2022.3216531",
      "title": "Systematic Review of Advanced AI Methods for Improving Healthcare Data Quality in Post COVID-19 Era",
      "abstract": "At the beginning of the COVID-19 pandemic, there was significant hype about the potential impact of artificial intelligence (AI) tools in combatting COVID-19 on diagnosis, prognosis, or surveillance. However, AI tools have not yet been widely successful. One of the key reason is the COVID-19 pandemic has demanded faster real-time development of AI-driven clinical and health support tools, including rapid data collection, algorithm development, validation, and deployment. However, there was not enough time for proper data quality control. Learning from the hard lessons in COVID-19, we summarize the important health data quality challenges during COVID-19 pandemic such as lack of data standardization, missing data, tabulation errors, and noise and artifact. Then we conduct a systematic investigation of computational methods that address these issues, including emerging novel advanced AI data quality control methods that achieve better data quality outcomes and, in some cases, simplify or automate the data cleaning process. We hope this article can assist healthcare community to improve health data quality going forward with novel AI development.",
      "year": "2022",
      "journal": "IEEE Reviews in Biomedical Engineering",
      "authors": "Monica Isgut et al.",
      "keywords": "Standardization; Computer science; Data quality; Data collection; Data science; Quality (philosophy); Coronavirus disease 2019 (COVID-19); Software deployment; Health care; Pandemic; Big data; Artifact (error); Risk analysis (engineering); Artificial intelligence; Data mining; Engineering; Medicine; Operations management",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/rbme.2022.3216531",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387717422",
      "doi": "10.1109/access.2023.3325323",
      "title": "Big Data-Based Smart Health Monitoring System: Using Deep Ensemble Learning",
      "abstract": "Human life has become smarter by utilizing big data, telecommunication technologies, and wearable sensors over pervasive computing to give better healthcare services. Big data is built with the possibility to improve the healthcare industry. Big data makes the interconnection between patients, wearable sensors, healthcare caregivers, and providers through the utilization of Information and Communication Technology (ICT) and software. Most of the economic challenges in developing countries are caused by the healthcare sector, which occurs predominantly due to the increasing population requiring more quality of care concerning older people. Older people need great attention and care as they lead with irreparable damages when a minor accident or insignificant disease occurs. Therefore, the necessity of implementing new technologies and tools has arisen to support senior citizens regarding their healthcare. Various advancements in wireless technology, miniaturization, computing power, and processing made diverse healthcare innovations that led to developing the connected medical devices. Hence, this proposal develops a new healthcare monitoring system for tracking the activities of elderly people, where the Hadoop MapReduce technique for parallel processing the large-sized data. The data collected as mentioned in the available datasets is performed by using the numerous wearable sensors fixed on the &#x201C;subject&#x2019;s left ankle, right arm, and chest&#x201D; that are transformed to the cloud platform and also to the data analytics layer according to the Internet of Medical Things (IoMT) devices. The given input undergoes data splitting to produce tiny chunks. These small chunks of the input files are then considered as Map tasks. Here, in the map phase, the features are optimally selected by the Hybrid Dingo Coyote Optimization (HDCO). The combiner phase classifies the physical activities using the developed Deep Ensemble Learning (DEL) consisting of classifiers such as &#x201C;Extreme Learning Machine (ELM), deep Convolutional Neural Network (CNN), Long short-term memory (LSTM), Deep Belief Network (DBN), and Deep Neural Network (DNN)&#x201D;. The parameter tuning in these classifiers is done by the same HDCO. The reducer phase extracts data from different chunks by merging the same classes. The developed HDCO-DEL has secured 13.66&#x0025;, 16.01&#x0025;, 17.33&#x0025;, 13.6&#x0025;, and 14.01&#x0025; better accuracy than ELM, CNN, LSTM, DBN, DNN, and HealthFog, respectively on second dataset. The comparison with existing methods shows its better performance and also predicts physical activities with overall high accuracy.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mustufa Haider Abidi et al.",
      "keywords": "Wearable computer; Big data; Computer science; Health care; Cloud computing; Wearable technology; Data science; Population; Computer security; Embedded system; Medicine; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3325323",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3161430317",
      "doi": "10.1109/access.2021.3080085",
      "title": "Transformers for Clinical Coding in Spanish",
      "abstract": "Automatic clinical coding is an essential task in the process of extracting relevant information from unstructured documents contained in electronic health records (EHRs). However, most research in the development of computer-based methods for clinical coding focuses on texts written in English due to the limited availability of medical linguistic resources in languages other than English. With nearly 500 million native speakers, there is a worldwide interest in processing healthcare texts in Spanish. In this study, we systematically analyzed transformer-based models for automatic clinical coding in Spanish. Using a transfer-learning-based approach, the three existing transformer architectures that support the Spanish language, namely, multilingual BERT (mBERT), BETO and XLM-RoBERTa (XLM-R), were first pretrained on a corpus of real-world oncology clinical cases with the goal of adapting transformers to the particularities of Spanish medical texts. The resulting models were fine-tuned on three distinct clinical coding tasks, following a multilabel sentence classification strategy. For each analyzed transformer, the domain-specific version outperformed the original general domain model across those tasks. Moreover, the combination of the developed strategy with an ensemble approach leveraging the predictive capacities of the three distinct transformers yielded the best obtained results, with MAP scores of 0.662, 0.544 and 0.884 on CodiEsp-D, CodiEsp-P and Cantemist-Coding shared tasks, which remarkably improved the previous state-of-the-art performance by 11.6%, 10.3% and 4.4%, respectively. We publicly release the mBERT, BETO and XLMR transformers adapted to the Spanish clinical domain at https://github.com/guilopgar/ClinicalCodingTransformerES, providing the clinical natural language processing community with advanced deep learning methods for performing medical coding and other tasks in the Spanish clinical domain.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Guillermo L\u00f3pez-Garc\u00eda et al.",
      "keywords": "Transformer; Computer science; Coding (social sciences); Sentence; Natural language processing; Named-entity recognition; Language model; Artificial intelligence; Transfer of learning; Task (project management)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3080085",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386825087",
      "doi": "10.1109/access.2023.3316508",
      "title": "A Novel Digital Twin (DT) Model Based on WiFi CSI, Signal Processing and Machine Learning for Patient Respiration Monitoring and Decision-Support",
      "abstract": "Digital Twin (DT) in Healthcare 4.0 (H4.0) presents a digital model of the patient with all its biological properties and characteristics. One of the application areas is patient respiration monitoring for enhanced patient care and decision support to healthcare professionals. Obtrusive methods of patient monitoring create hindrances in the patient&#x2019;s daily routine. This research presents a novel Respiration DT (ResDT) model based on Wi-Fi Carrier State Information (CSI), improved signal processing, and Machine Learning (ML) algorithms for monitoring and classification (binary and multi-class) of patient respiration. A Wi-Fi sensor ESP32 with Wi-Fi CSI was utilized for the collection of respiration data. This provides an added advantage of unobtrusive monitoring of patient vital signs. The Patient&#x2019;s Breaths Per Minute (BPM) is estimated from raw sensor data through the integration of multiple signal processing methodologies for denoising (smoothing and filtering) and dimensionality reduction (PCA, SVM, EMD, EMD-PCA). Multiple filters and dimensionality reduction methodologies are compared for accurate BPM estimation. The elliptical filter provides a relatively better estimation of the BPM with 87.5&#x0025; accurate estimation as compared to other bandpass filters such as Butterworth (BF), Chebyshev type 1 Filter (CH1), Chebyshev type 2 Filter (CH2), and wavelet Decomposition (62.5&#x0025;, 75&#x0025;, 68.75&#x0025;, and 75&#x0025; respectively). Principal Component Analysis (PCA) was performed to provide better dimensionality reduction with 87.5&#x0025; accurate BPM values compared to EMD, SVD, and EMD-PCA (57&#x0025;, 44&#x0025;, and 44&#x0025; respectively). Additionally, the fine tree algorithm, from the implemented 21 ML supervised classification algorithms with K-fold cross-validation, was observed to be the optimal choice for multi-class and binary-class classification problems in the presented ResDT model with 96.9&#x0025; and 95.8&#x0025; accuracy respectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sagheer Khan et al.",
      "keywords": "Artificial intelligence; Computer science; Dimensionality reduction; Smoothing; Principal component analysis; Machine learning; Remote patient monitoring; Filter (signal processing); Support vector machine; Chebyshev filter; Pattern recognition (psychology); Medicine; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3316508",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3116803305",
      "doi": "10.1109/access.2020.3047195",
      "title": "Predicting Stroke Risk With an Interpretable Classifier",
      "abstract": "Predicting an individual's risk of getting a stroke has been a research subject for many authors&#13;\\nworldwide since it is a frequent illness and there is strong evidence that early awareness of having that risk can&#13;\\nbe bene cial for prevention and treatment. Many Governments have been collecting medical data about their&#13;\\nown population with the purpose of using arti cial intelligence methods for making those predictions. The&#13;\\nmost accurate ones are based on so called black-box methods which give little or no information about why&#13;\\nthey make a certain prediction. However, in the medical eld the explanations are sometimes more important&#13;\\nthan the accuracy since they allow specialists to gain insight about the factors that in uence the risk level.&#13;\\nIt is also frequent to nd medical information records with some missing data. In this work, we present the&#13;\\ndevelopment of a prediction method which not only outperforms some other existing ones but it also gives&#13;\\ninformation about the most probable causes of a high stroke risk and can deal with incomplete data records.&#13;\\nIt is based on the Dempster-Shafer theory of plausibility. For the testing we used data provided by the regional&#13;\\nhospital in Okayama, Japan, a country in which people are compelled to undergo annual health checkups&#13;\\nby law. This article presents experiments comparing the results of the Dempster-Shafer method with the&#13;\\nones obtained using other well-known machine learning methods like Multilayer perceptron, Support Vector&#13;\\nMachines and Naive Bayes. Our approach performed the best in these experiments with some missing data.&#13;\\nIt also presents an analysis of the interpretation of rules produced by the method for doing the classi cation.&#13;\\nThe rules were validated by both medical literature and human specialists.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Sergio Pe\u00f1afiel et al.",
      "keywords": "Computer science; Dempster\u2013Shafer theory; Artificial intelligence; Naive Bayes classifier; Machine learning; Support vector machine; Multilayer perceptron; Population; Bayes' theorem; Medical record; Artificial neural network; Data mining; Medicine; Bayesian probability",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3047195",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391547780",
      "doi": "10.1109/access.2024.3361943",
      "title": "Lung Sound Classification With Multi-Feature Integration Utilizing Lightweight CNN Model",
      "abstract": "Detecting respiratory diseases is of utmost importance, considering that respiratory ailments represent one of the most prevalent categories of diseases globally. The initial stage of lung disease detection involves auscultation conducted by specialists, relying significantly on their expertise. Therefore, automating the auscultation process for the detection of lung diseases can yield enhanced efficiency. Artificial intelligence (AI) has shown promise in improving the accuracy of lung sound classification by extracting features from lung sounds that are relevant to the classification task and learning the relationships between these features and the different pulmonary diseases. This paper utilizes two publicly available respiratory sound recordings namely, ICBHI 2017 challenge dataset and another lung sound dataset available at Mendeley Data. Foremost in this paper, we provide a detailed exposition about employing a Convolutional Neural Network (CNN) that utilizes feature extraction from Mel spectrograms, Mel frequency cepstral coefficients (MFCCs), and Chromagram. The highest accuracy achieved in the developed classification is 91.04&#x0025; for 10 classes. Extending the contribution, this paper elaborates on the explanation of the classification model prediction by employing Explainable Artificial Intelligence (XAI). The novel contribution of this study is a CNN model that classifies lung sounds into 10 classes by combining audio-specific features to enhance the classification process.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Thinira Wanasinghe et al.",
      "keywords": "Auscultation; Computer science; Convolutional neural network; Respiratory sounds; Mel-frequency cepstrum; Artificial intelligence; Feature extraction; Pattern recognition (psychology); Speech recognition; Feature (linguistics); Process (computing); Artificial neural network; Deep learning; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3361943",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389610258",
      "doi": "10.1109/access.2023.3341419",
      "title": "EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring: A Comprehensive Review",
      "abstract": "<p dir=\"ltr\">EEG is a common and safe test that uses small electrodes to record electrical signals from the brain. It has a broad range of applications in medical diagnosis, including diagnosis of epileptic seizure, Alzheimer\u2019s, brain tumors, head injury, sleep disorders, stroke, and other seizure and neurological disorders. EEG can also be used to help diagnose death in people who are in a persistent coma. The use of digital signal processing and machine learning to improve EEG analysis for medical diagnosis has gained traction in recent years. This is because EEG visual analysis can be complex and time-consuming, as it mostly involves high dimensions and consists of large datasets. The development of novel sensors for EEG recording, digital signal processing algorithms, feature engineering, and detection algorithms increases the need for efficient diagnostic systems. An extensive review of the recent approaches for EEG preprocessing, extraction of features, and diagnosis of brain disorders is provided. In this paper, the main focus is to identify reliable algorithms for preprocessing, feature engineering, and classification of EEG, applied to medical healthcare and diagnosis, providing practitioners with insights into the most effective strategies, as well as potential future directions for improving accuracy of the automatic diagnostic systems. The study of reliable feature extraction and classification algorithms is crucial for a more accurate analysis of EEG signals. This paper can provide valuable information to researchers and practitioners working in the fields of EEG analysis and machine learning, as it provides a summary of recent developments and highlights key areas for future research. This paper can help researchers and clinicians to stay up-to-date on the latest developments in this field. <h2>Other Information</h2><p dir=\"ltr\">Published in: IEEE Access<br>License: <a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">https://creativecommons.org/licenses/by/4.0/</a><br>See article on publisher's website: <a href=\"https://dx.doi.org/10.1109/access.2023.3341419\" target=\"_blank\">https://dx.doi.org/10.1109/access.2023.3341419</a>",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nisreen Said Amer et al.",
      "keywords": "Electroencephalography; Computer science; Health care; Signal processing; Remote patient monitoring; Speech recognition; Medicine; Digital signal processing; Neuroscience; Psychology; Computer hardware",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3341419",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323519173",
      "doi": "10.1109/jiot.2023.3253602",
      "title": "The Internet of Sounds: Convergent Trends, Insights, and Future Directions",
      "abstract": "Current sound-based practices and systems developed in both academia and industry point to convergent research trends that bring together the field of Sound and Music Computing with that of the Internet of Things. This paper proposes a vision for the emerging field of the Internet of Sounds (IoS), which stems from such disciplines. The IoS relates to the network of Sound Things, i.e., devices capable of sensing, acquiring, processing, actuating, and exchanging data serving the purpose of communicating sound-related information. In the IoS paradigm, which merges under a unique umbrella the emerging fields of the Internet of Musical Things and the Internet of Audio Things, heterogeneous devices dedicated to musical and non-musical tasks can interact and cooperate with one another and with other things connected to the Internet to facilitate sound-based services and applications that are globally available to the users. We survey the state of the art in this space, discuss the technological and non-technological challenges ahead of us and propose a comprehensive research agenda for the field.",
      "year": "2023",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Luca Turchet et al.",
      "keywords": "Computer science; The Internet; Telecommunications; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2023.3253602",
      "cited_by_count": 72,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3198454955",
      "doi": "10.1109/access.2021.3108551",
      "title": "Associating Measles Vaccine Uptake Classification and its Underlying Factors Using an Ensemble of Machine Learning Models",
      "abstract": "Measles is one of the significant public health issues responsible for the high mortality rate around the globe, especially for developing countries. Using nationally representative demographic and health survey data, measles vaccine utilization has been classified, and its underlying factors are identified through an ensemble Machine Learning (ML) approach. Firstly, missing values are imputed employing various approaches, and then several feature selection techniques have been applied to identify the crucial attributes for predicting measles vaccination. A grid search hyperparameter optimization technique has been applied for tuning the critical hyperparameters of different ML models, such as Naive Bayes, random forest, decision tree, XGboost, and lightgbm. The individual optimized ML model&#x2019;s categorization performance as all their ensembles have been reported utilizing our proposed BDHS dataset. Individually, the optimized lightgbm provides the highest precision and AUC of 79.90&#x0025; and 77.80&#x0025;, respectively. This result improved when the optimized lightgbm is ensembled with XGboost, providing the precision and AUC of 84.60&#x0025; and 80.0&#x0025;, respectively. Our result reveals that the statistical median imputation technique with the XGboost-based attribute selection method and the lightgbm classifier provides the best individual result. The performance improved when the proposed weighted ensemble of the XGboost and lightgbm approach was adapted with the same preprocessing and recommended for measles vaccine utilization. The significance of our proposed approach is that it utilizes minimum attributes collected from the child and their family members and yielded 80.0&#x0025; accuracy, making it easily explainable by caregivers and healthcare personnel. Finally, our predictive model provides an early detection procedure to help national policymakers enforce new policies with specific rules and regulations. The data and source codes that support the findings of this study are available at <uri>https://github.com/kamruleee51/measles_vaccine_uptake</uri>.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Md. Kamrul Hasan et al.",
      "keywords": "Naive Bayes classifier; Artificial intelligence; Hyperparameter; Machine learning; Random forest; Support vector machine; Computer science; Feature selection; Measles vaccine; Ensemble learning; Decision tree; Hyperparameter optimization; Imputation (statistics); Data mining; Missing data; Measles; Vaccination; Medicine; Immunology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3108551",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3033386593",
      "doi": "10.1109/access.2020.2999915",
      "title": "Automatic Identification of Insomnia Based on Single-Channel EEG Labelled With Sleep Stage Annotations",
      "abstract": "Monitoring single-channel EEG is a promising home-based approach for insomnia identification. Currently, many automatic sleep stage scoring approaches based on single-channel EEG have been developed, whereas few studies research on automatic insomnia identification based on single-channel EEG labelled with sleep stage annotations. In this paper, we propose a one-dimensional convolutional neural network (1D-CNN) model for automatic insomnia identification based on single-channel EEG labelled with sleep stage annotations, and further investigate the identification performance based on different sleep stages EEG epochs. Single-channel EEG on 9 insomnia patients and 9 healthy subjects was used in this study. We constructed 4 subdatasets from EEG epochs based on the sleep stage annotations: All sleep stage dataset (ALL-DS), REM sleep stage dataset (REM-DS), light sleep stage dataset (LSS-DS), and SWS sleep stage dataset (SWS-DS). Subsequently, 4 subdatasets were fed into our 1D-CNN. We conducted experiments under intra-patient and inter-patient paradigms, respectively. Our experiments demonstrated that our 1D-CNN leveraging 3 subdatasets composed of REM, LSS and SWS epochs, respectively, achieved higher average accuracies in comparison with baseline methods under both intra-patient and inter-patient paradigms. The experimental results also indicated that amongst all the sleep stages, 1D-CNN leveraging REM and SWS epochs exhibited the best insomnia identification average accuracies in intra-patient paradigm, which are 98.98% and 99.16% respectively, whereas no statistically significant difference was found in inter-patient paradigm. For automatic insomnia identification based on single-channel EEG labelled with sleep stage annotations, 1D-CNN model introduced in this paper could achieve superior performance than traditional methods.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Bufang Yang et al.",
      "keywords": "Electroencephalography; Sleep Stages; Insomnia; Sleep (system call); Convolutional neural network; Computer science; Artificial intelligence; Identification (biology); Slow-wave sleep; Stage (stratigraphy); Pattern recognition (psychology); Polysomnography; Speech recognition; Psychology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2999915",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389665128",
      "doi": "10.1109/tuffc.2023.3342150",
      "title": "Clinical, Safety, and Engineering Perspectives on Wearable Ultrasound Technology: A Review",
      "abstract": "Wearable ultrasound has the potential to become a disruptive technology enabling new applications not only in traditional clinical settings, but also in settings where ultrasound is not currently used. Understanding the basic engineering principles and limitations of wearable ultrasound is critical for clinicians, scientists, and engineers to advance potential applications and translate the technology from bench to bedside. Wearable ultrasound devices, especially monitoring devices, have the potential to apply acoustic energy to the body for far longer durations than conventional diagnostic ultrasound systems. Thus, bioeffects associated with prolonged acoustic exposure as well as skin health need to be carefully considered for wearable ultrasound devices. This article reviews emerging clinical applications, safety considerations, and future engineering and clinical research directions for wearable ultrasound technology.",
      "year": "2023",
      "journal": "IEEE Transactions on Ultrasonics Ferroelectrics and Frequency Control",
      "authors": "Pengfei Song et al.",
      "keywords": "Wearable computer; Engineering; Systems engineering; Computer science; Embedded system",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tuffc.2023.3342150",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2104879654",
      "doi": "10.1109/tsmca.2010.2048022",
      "title": "Application of Digital Ecosystem Design Methodology Within the Health Domain",
      "abstract": "We define a digital ecosystem (DES) as the dynamic and synergetic complex of digital communities consisting of interconnected, interrelated, and interdependent digital species situated in a digital environment that interact as a functional unit and are linked together through actions, information, and transaction flows. The design of DESs requires the integration of a number of different and complementary technologies, including agent-based and self-organizing systems, ontologies, swarm intelligence, ambient intelligence, data mining, genetic algorithms, etc. The integration of multiple technologies and the resulting synergetic effects contribute to the creation of highly complex, dynamic, and powerful systems. The application of DESs within different domains has the power to transform these domains by giving them a more intelligent and a more dynamic nature. In this paper, we illustrate how a DES design methodology can be used to systematically create a Digital Health Ecosystem (DHES). We address the key steps associated with the DES design and focus specifically on the use of the electronic health records within the DHES. The design methodology framework illustrated in this paper serves as a navigating tool during the design of DHESs.",
      "year": "2010",
      "journal": "IEEE Transactions on Systems Man and Cybernetics - Part A Systems and Humans",
      "authors": "Maja Hadzic et al.",
      "keywords": "Computer science; Interdependence; Digital ecosystem; Situated; Digital health; Data science; Key (lock); Domain (mathematical analysis); Systems engineering; Distributed computing; Knowledge management; Human\u2013computer interaction; Artificial intelligence; Computer security; Engineering; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tsmca.2010.2048022",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226456923",
      "doi": "10.1109/access.2022.3163758",
      "title": "Ontology-Based Knowledge Management Tools for Knowledge Sharing in Organization\u2014A Review",
      "abstract": "Knowledge management (KM) comprises several processes, and one of the most important is the knowledge sharing activities. The ability of an organization to manage its organizational knowledge, specifically in the context of knowledge sharing, may enhance the organization&#x2019;s overall performance. Various approaches and technologies have been introduced to assist the process in achieving that target. Ontology as one of the knowledge representation methods has been becoming popular to assist knowledge sharing in the organization. Previous reviews have mainly focused on general KM issues, with little emphasis on the use of ontology in knowledge sharing. Thus, this article reviews several ontology-based KM tools that can support knowledge-sharing activities to provide some insight into future research in this area. Thirteen ontology-based KM tools were reviewed using ten elements&#x2019; comparison criteria: the motivation, domain, source of knowledge, type of knowledge, knowledge extraction, knowledge input process, knowledge retrieval process, knowledge sharing technology, source of ontology component, and ontology methodology. The review found that several elements can be further studied to improve KM implementation in the organization, especially on the knowledge sharing dimension. This includes simplifying the knowledge extraction and retrieval process to explore various knowledge domains from implicit knowledge sources. The review&#x2019;s outcome also includes proposed components and functions of an ideal ontology-based KM tool.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mohamad Amin Osman et al.",
      "keywords": "Computer science; Ontology; Knowledge management; Open Knowledge Base Connectivity; Knowledge sharing; Domain knowledge; Knowledge extraction; Knowledge organization; Personal knowledge management; Knowledge engineering; Knowledge representation and reasoning; Knowledge value chain; Knowledge-based systems; Knowledge integration; Body of knowledge; Context (archaeology); Knowledge retrieval; Data science; Organizational learning; Data mining; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3163758",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312510915",
      "doi": "10.1109/access.2022.3223704",
      "title": "Deep Learning Based Image Processing for Robot Assisted Surgery: A Systematic Literature Survey",
      "abstract": "The recent advancements in the surging field of Deep Learning (DL) have revolutionized every sphere of life, and the healthcare domain is no exception. The enormous success of DL models, particularly with image data, has led to the development of image-guided Robot Assisted Surgery (RAS) systems. By and large, the number of studies concerning image-driven computer assisted surgical systems using DL has increased exponentially. Additionally, the contemporary availability of surgical datasets has also boosted the DL applications in RAS. Inspired by the latest trends and contributions in surgery, this literature survey presents a summarized analysis of recent innovations of DL in image-guided RAS systems. After a thorough review, a sum of 184 articles are selected and grouped into four categories, based on the literature and the relevancy of the task in the articles, comprising 1) Surgical Tools, 2) Surgical Processes, 3) Surgical Surveillance, and 4) Surgical Performance. The survey also discusses publicly available surgical datasets and highlights the basics of the DL models. Furthermore, the legal, ethical, and technological challenges together with the intuitive predictions and recommendations related to the autonomous RAS systems are also presented. The study reveals that Convolutional Neural Network (CNN) is most widely adopted architecture, whereas, the JIGSAWS is most employed dataset in RAS. The study suggests fusing kinematic data along with image data, which produces better accuracy and precision, particularly in gesture and trajectory segmentation tasks. Additionally, CNN and long short term memory networks have shown remarkable performance, however, authors recommend employing these gigantic architectures only when simpler models have failed to produce satisfactory results. The simpler models, despite their limitations, are time and cost effective and yield considerable outcomes even on the smaller datasets.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Sardar Mehboob Hussain et al.",
      "keywords": "Computer science; Deep learning; Convolutional neural network; Artificial intelligence; Segmentation; Image segmentation; Robot; Image processing; Gesture; Image (mathematics); Data science; Machine learning; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3223704",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382813647",
      "doi": "10.1109/tim.2023.3276528",
      "title": "Inertial Sensors for Human Motion Analysis: A Comprehensive Review",
      "abstract": "Inertial motion analysis is having a growing interest during the last decades\\ndue to its advantages over classical optical systems. The technological\\nsolution based on inertial measurement units allows the measurement of\\nmovements in daily living environments, such as in everyday life, which is key\\nfor a realistic assessment and understanding of movements. This is why research\\nin this field is still developing and different approaches are proposed. This\\npresents a systematic review of the different proposals for inertial motion\\nanalysis found in the literature. The search strategy has been carried out on\\neight different platforms, including journal articles and conference\\nproceedings, which are written in English and published until August 2022. The\\nresults are analyzed in terms of the publishers, the sensors used, the\\napplications, the monitored units, the algorithms of use, the participants of\\nthe studies, and the validation systems employed. In addition, we delve deeply\\ninto the machine learning techniques proposed in recent years and in the\\napproaches to reduce the estimation error. In this way, we show an overview of\\nthe research carried out in this field, going into more detail in recent years,\\nand providing some research directions for future work\\n",
      "year": "2023",
      "journal": "IEEE Transactions on Instrumentation and Measurement",
      "authors": "Sara Garc\u00eda-de-Villa et al.",
      "keywords": "Inertial frame of reference; Field (mathematics); Inertial measurement unit; Computer science; Motion (physics); Work (physics); Units of measurement; Inertial navigation system; Motion analysis; Key (lock); Artificial intelligence; Data science; Systems engineering; Human\u2013computer interaction; Engineering; Mechanical engineering; Computer security; Mathematics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tim.2023.3276528",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392449562",
      "doi": "10.1109/access.2024.3373910",
      "title": "A Survey of Wearable Sensors and Machine Learning Algorithms for Automated Stroke Rehabilitation",
      "abstract": "Stroke is one of the leading causes of disability among the elderly population and is a significant public health problem worldwide. The main impact of stroke is functional disabilities due to motor impairment after stroke. Advances in modern medicine and technology have significantly improved diagnosis and treatment; however, most post-stroke care is based on the effectiveness of rehabilitation. Stroke rehabilitation depends on two main components: (i) training (or therapy) to restore the patient to pre-stroke mobility and (ii) assessing motor functionality of affected patients performing activities to track motor recovery. This article highlights how combining wearable devices and machine learning (ML) produces new pathways for effective stroke rehabilitation. While wearable devices help capture patient movements at much finer time resolutions, ML allows us to build predictive models from wearable data to assist clinicians in diagnosis and treatments. Specifically, we expand on how wearable devices and ML can improve monitoring quality in training intervention, assessment, and remote monitoring. In addition, we provide our main findings from the literature, research challenges, and future directions in post-stroke therapies using wearable devices and ML.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Nandini Sengupta et al.",
      "keywords": "Wearable computer; Rehabilitation; Stroke (engine); Physical medicine and rehabilitation; Wearable technology; Computer science; Population; Motor learning; Machine learning; Medicine; Artificial intelligence; Physical therapy; Psychology; Engineering; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3373910",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285120632",
      "doi": "10.1109/jiot.2022.3177256",
      "title": "Bindi: Affective Internet of Things to Combat Gender-Based Violence",
      "abstract": "The main research motivation of this article is the fight against gender-based violence and achieving gender equality from a technological perspective. The solution proposed in this work goes beyond currently existing panic buttons, needing to be manually operated by the victims under difficult circumstances. Instead, Bindi, our end-to-end autonomous multimodal system, relies on artificial intelligence methods to automatically identify violent situations, based on detecting fear-related emotions, and trigger a protection protocol, if necessary. To this end, Bindi integrates modern state-of-the-art technologies, such as the Internet of Bodies, affective computing, and cyber-physical systems, leveraging: 1) affective Internet of Things (IoT) with auditory and physiological commercial off-the-shelf smart sensors embedded in wearable devices; 2) hierarchical multisensorial information fusion; and 3) the edge-fog-cloud IoT architecture. This solution is evaluated using our own data set named WEMAC, a very recently collected and freely available collection of data comprising the auditory and physiological responses of 47 women to several emotions elicited by using a virtual reality environment. On this basis, this work provides an analysis of multimodal late fusion strategies to combine the physiological and speech data processing pipelines to identify the best intelligence engine strategy for Bindi. In particular, the best data fusion strategy reports an overall fear classification accuracy of 63.61% for a subject-independent approach. Both a power consumption study and an audio data processing pipeline to detect violent acoustic events complement this analysis. This research is intended as an initial multimodal baseline that facilitates further work with real-life elicited fear in women.",
      "year": "2022",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Jos\u00e9 Miranda et al.",
      "keywords": "Computer science; Cloud computing; Wearable computer; Sensor fusion; Edge computing; The Internet; Wearable technology; Computer security; Human\u2013computer interaction; Artificial intelligence; Data science; Enhanced Data Rates for GSM Evolution; World Wide Web; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2022.3177256",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3216785339",
      "doi": "10.1109/access.2021.3131613",
      "title": "Deep Learning-Based Multimodal Abnormal Gait Classification Using a 3D Skeleton and Plantar Foot Pressure",
      "abstract": "Classification of pathological gaits has an important role in finding a weakened body part and diagnosing a disease. Many machine learning-based approaches have been proposed that automatically classify abnormal gait patterns using various sensors, such as inertial sensors, depth cameras and foot pressure plates. In this paper, we present a deep learning-based abnormal gait classification method employing both a 3D skeleton (obtained with a depth camera) and plantar foot pressure. We collected skeleton and foot pressure data simultaneously for 1 normal and 5 pathological (antalgic, lurching, steppage, stiff-legged, and Trendelenburg) gaits and classified them by using a multimodal hybrid model fed both data types together. In the proposed method, we fed the sequential skeleton and average foot pressure data into recurrent neural network (RNN)-based encoding layers and convolutional neural network (CNN)-based encoding layers, respectively, to effectively extract features from different data types. Their output features were concatenated and fed to fully connected layers for classification. The pressure-based and skeleton-based single-modal models achieved classification accuracies of 68.82&#x0025; and 93.40&#x0025;, respectively. The proposed multimodal hybrid model showed improved performance with an accuracy of 95.66&#x0025;. We fine-tuned the hybrid model by applying a 3-step training methodology and ultimately increased the accuracy to 97.60&#x0025;. This study indicates that the integrated features of the skeleton and foot pressure data represent both the spatiotemporal motion information and weight distribution, so data fusion can generate a positive effect in pathological gait classification.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Kooksung Jun et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Gait; Pattern recognition (psychology); Skeleton (computer programming); Deep learning; Foot pressure; Artificial neural network; Encoding (memory); Computer vision; Pressure sensor; Engineering; Physical medicine and rehabilitation; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3131613",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2971690570",
      "doi": "10.1109/access.2019.2939822",
      "title": "An Automatic System for Real-Time Identifying Atrial Fibrillation by Using a Lightweight Convolutional Neural Network",
      "abstract": "A lightweight convolutional neural network (CNN) is presented in this study to automatically indentify atrial fibrillation (AF) from single-lead ECG recording. In contrast to existing methods employing a deeper architecture or complex feature-engineered inputs, this work presents an attempt to employ a lightweight CNN to confront current drawbacks such as higher computational requirement and inadequate training dataset, by using representative rhythms features of AF rather than raw ECG signal or hand-crafted features without any electrophysiological considerations. The experimental results suggested that this method presents the following significant advantages: (1) higher performances for indentifying AF in terms of accuracy, sensitivity, and specificity that are 97.5%, 97.8%, and 97.2%, respectively; (2) It is capable of automatically extracting the shared features of AF episodes of different patients and would be much robust and reliable; (3) with the cardiac rhythm features as input dataset, rather than complex transforming and classifying the raw data, thus requiring a lower computational resource. In conclusion, this automated method could analyze large amounts of data in a short time while assuring a relative high accuracy, and thus would potentially serve to provide a comfortable single-lead monitoring for patients and a clinical useful tool for doctors.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Dakun Lai et al.",
      "keywords": "Computer science; Convolutional neural network; Atrial fibrillation; Artificial intelligence; Pattern recognition (psychology); Feature (linguistics); Deep learning; Raw data; Sensitivity (control systems); Feature extraction; Artificial neural network; Machine learning; Cardiology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2939822",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312444877",
      "doi": "10.1109/access.2022.3210518",
      "title": "Recent Advancement in Sleep Technologies: A Literature Review on Clinical Standards, Sensors, Apps, and AI Methods",
      "abstract": "This is a literature review paper covering state-of-the-art sleep technologies to measure sleep and clinical sleep disorders. This paper addresses an interdisciplinary audience from a variety of subdomains in engineering and medicine. We reviewed 120 scientific papers, 15 commercial mobile apps, and 4 commercial devices. We selected the papers from scientific publishers including Institute of Electrical and Electronics Engineers (IEEE), Nature, Association for Computing Machinery (ACM), Proceedings of Machine Learning Research, Journal of Informatics in Health and Biomedicine, Plos One, PubMed, and Elsevier and Nature digital libraries. We used Google Scholar with keywords including &#x201C;sleep monitoring&#x201D;, &#x201C;sleep monitoring technologies&#x201D;, &#x201C;non-contact sleep monitoring&#x201D;, &#x201C;mobile apps for sleep monitoring&#x201D;, &#x201C;AI in sleep technologies&#x201D;, and &#x201C;automated sleep staging.&#x201D; The manuscript reviews sleep technologies, including sleep lab technologies such as polysomnography and consumer sleep technologies categorized as ambient room sensors, wearable sensors, bed sensors, mobile apps, and artificial intelligence. We primarily focused on validation and comparison studies of the reviewed technologies. The manuscript also provides an overview of several clinical datasets for sleep staging and taxonomizes the different learning methods. Finally, the manuscript offers our insights and recommendations about the application of the reviewed sleep technologies.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Gozde Cay et al.",
      "keywords": "Polysomnography; Computer science; Sleep (system call); Sleep medicine; Health informatics; Wearable computer; Informatics; Data science; Wearable technology; Emerging technologies; Mobile device; Multimedia; Artificial intelligence; Medicine; Sleep disorder; World Wide Web; Engineering; Embedded system; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3210518",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2999825330",
      "doi": "10.1109/access.2020.2964237",
      "title": "C2FHAR: Coarse-to-Fine Human Activity Recognition With Behavioral Context Modeling Using Smart Inertial Sensors",
      "abstract": "Smart sensing devices are furnished with an array of sensors, including locomotion sensors, which enable continuous and passive monitoring of human activities for the ambient assisted living. As a result, sensor-based human activity recognition has earned significant popularity in the past few years. A lot of successful research studies have been conducted in this regard. However, the accurate recognition of in-the-wild human activities in real-time is still a fundamental challenge to be addressed as human physical activity patterns are adversely affected by their behavioral contexts. Moreover, it is essential to infer a user's behavioral context along with the physical activity to enable context-aware and knowledge-driven applications in real-time. Therefore, this research work presents &#x201C;C2FHAR&#x201D;, a novel approach for coarse-to-fine human activity recognition in-the-wild, which explicitly models the user's behavioral contexts with activities of daily living to learn and recognize the fine-grained human activities. For addressing real-time activity recognition challenges, the proposed scheme utilizes a multi-label classification model for identifying in-the-wild human activities at two different levels, i.e., coarse or fine-grained, depending upon the real-time use-cases. The proposed scheme is validated with extensive experiments using heterogeneous sensors, which demonstrate its efficacy.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Muhammad Ehatisham-ul-Haq et al.",
      "keywords": "Activity recognition; Computer science; Context (archaeology); Assisted living; Popularity; Human\u2013computer interaction; Scheme (mathematics); Artificial intelligence; Smart environment; Ubiquitous computing; Behavioral pattern; Activity detection; Machine learning; Embedded system; Internet of Things",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2964237",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387789514",
      "doi": "10.1109/access.2023.3325896",
      "title": "Deep Learning Technologies for Time Series Anomaly Detection in Healthcare: A Review",
      "abstract": "Medical time series data often exhibit intricate and dynamic patterns. With the rapid advancement of medical digitization, deep learning-based time series anomaly detection techniques have found extensive applications in the healthcare field, such as detecting irregular heart rhythms and monitoring patients&#x2019; vital signs. To fully leverage digitized medical records to identify anomalies in healthcare and address key challenges in precise anomaly detection, this paper provides a comprehensive review of deep learning-based anomaly detection techniques applied to medical time series data. By reviewing and summarizing the relevant research, this paper explores the deep learning-based time series anomaly detection techniques within the medical and health domain, analyzing the strengths and limitations of different deep learning architectures and algorithms in tackling specific medical tasks. Lastly, we discuss the challenges faced by this field and outline future research directions. By reviewing and summarizing advanced deep learning methods for time series anomaly detection in medical applications in recent years, this study contributes to the advancement of healthcare analytics, aiming to enhance patient treatment outcomes.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Xue Yang et al.",
      "keywords": "Deep learning; Computer science; Anomaly detection; Field (mathematics); Artificial intelligence; Digitization; Data science; Time series; Series (stratigraphy); Anomaly (physics); Domain (mathematical analysis); Machine learning; Computer vision",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3325896",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2979771966",
      "doi": "10.1109/access.2020.2968440",
      "title": "Physiological Closed-Loop Control (PCLC) Systems: Review of a Modern Frontier in Automation",
      "abstract": "Over the past decade, there has been an unprecedented international focus on\\nimproved quality and availability of medical care, which has reignited interest\\nin clinical automation and drawn researchers toward novel solutions in the\\nfield of physiological closed-loop control systems (PCLCs). Today,\\nmultidisciplinary groups of expert scientists, engineers, clinicians,\\nmathematicians, and policy-makers are combining their knowledge and experience\\nto develop both the next generation of PCLC-based medical equipment and a\\ncollaborative commercial/academic infrastructure to support this rapidly\\nexpanding frontier. In the following article, we provide a robust introduction\\nto the various aspects of this growing field motivated by the recent and\\nongoing work supporting two leading technologies: the artificial pancreas (AP)\\nand automated anesthesia. Following a brief high-level overview of the main\\nconcepts in automated therapy and some relevant tools from systems and control\\ntheory, we explore -- separately -- the developments, challenges,\\nstate-of-the-art, and probable directions for AP and automated anesthesia\\nsystems. We then close the review with a consideration of the common lessons\\ngleaned from these ventures and the implications they present for future\\ninvestigations and adjacent research.\\n",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammad Javad Khodaei et al.",
      "keywords": "Frontier; Automation; Multidisciplinary approach; Computer science; Field (mathematics); Control (management); Engineering management; Management science; Engineering ethics; Data science; Engineering; Artificial intelligence; Political science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.2968440",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3045063674",
      "doi": "10.1109/access.2020.3011721",
      "title": "A Clinical Prediction Model in Health Time Series Data Based on Long Short-Term Memory Network Optimized by Fruit Fly Optimization Algorithm",
      "abstract": "Aiming the problems that the clinical data of different patients is difficult for reasonable representation and the time interval between medical events is different, which lead to the difficulty of clinical prediction, a clinical prediction model based on the long short-term memory (LSTM) network optimized by fruit fly optimization algorithm in health time series data is proposed. First, FastText method is used to represent the interpretable vector of medical events, which can extract the concept relationship rich in medical information more effectively. Then, considering the strong dependence of clinical data on time stamp, LSTM network is used to model clinical events for better extraction of long-term and short-term information, so as to improve the prediction performance of the model. Finally, the fruit fly optimization algorithm is used to find the optimal super parameters of LSTM network, which can improve the training efficiency and prediction precision of the network. Experimental results on MIMIC datasets show that the prediction precision, Recall@k and MAP@k of the proposed model are better than those of other models. The validity of the model is proved.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Weijia Lu et al.",
      "keywords": "Computer science; Term (time); Time series; Representation (politics); Artificial intelligence; Data mining; Optimization algorithm; Series (stratigraphy); Recall; Long short term memory; Algorithm; Machine learning; Artificial neural network; Recurrent neural network; Mathematics; Mathematical optimization",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3011721",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3026998650",
      "doi": "10.1109/access.2020.2996404",
      "title": "Virtual Coaches for Older Adults\u2019 Wellbeing: A Systematic Review",
      "abstract": "&lt;p&gt;Virtual Coaches, also known as e-coaches, are a disruptive technology in healthcare. Indeed, among other usages, they might provide cost-effective solutions for increasing human wellbeing in different domains, such as physical, nutritional, cognitive, social, and emotional. This paper presents a systematic review of virtual coaches specifically aimed at improving or maintaining older adults' health in the aforementioned domains. Such digital systems assume various forms, from classic apps, to more advanced conversational agents or robots. Fifty-six articles describing a virtual coach for older adults and aimed at improving their wellbeing were identified and further analyzed. In particular, we presented how previous studies defined their virtual coaches, which behavioral change models and techniques they adopted and the overall system architecture, in terms of monitoring solutions, processing methods and modalities for intervention delivery. Our results show that few thorough evaluations of e-coaching systems have been conducted, especially regarding multi-domain coaching approaches. Through our analysis, we identified the wellbeing domains that should be addressed in future studies as well as the most promising behavior change models and techniques and coaching interfaces. Previous work illustrates that older adults often appreciate conversational agents and robots. However, the lack of a multidomain intervention approach in the current literature motivates us to seek to define future solutions.&lt;/p&gt;",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mira El Kamali et al.",
      "keywords": "Computer science; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.2996404",
      "cited_by_count": 61,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2990288623",
      "doi": "10.1109/access.2019.2954985",
      "title": "A Fusion Model-Based Label Embedding and Self-Interaction Attention for Text Classification",
      "abstract": "Text classification is a pivotal task in NLP (Natural Language Processing), which has received widespread attention recently. Most of the existing methods leverage the power of deep learning to improve the performance of models. However, these models ignore the interaction information between all the sentences in a text when generating the current text representation, which results in a partial semantics loss. Labels play a central role in text classification. And the attention learned from text-label in the joint space of labels and words is not leveraged, leaving enough room for further improvement. In this paper, we propose a text classification method based on Self-Interaction attention mechanism and label embedding. Firstly, our method introduce BERT (Bidirectional Encoder Representation from Transformers) to extract text features. Then Self-Interaction attention mechanism is employed to obtain text representations containing more comprehensive semantics. Moreover, we focus on the embedding of labels and words in the joint space to achieve the dual-label embedding, which further leverages the attention learned from text-label. Finally, the texts are classified by the classifier according to the weighted labels representations. The experimental results show that our method outperforms other state-of-the-art methods in terms of classification accuracy.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yanru Dong et al.",
      "keywords": "Computer science; Embedding; Artificial intelligence; Natural language processing; Encoder; Leverage (statistics); Classifier (UML); Transformer; Word embedding; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2954985",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391407170",
      "doi": "10.1109/access.2024.3360930",
      "title": "Terahertz Data Extraction and Analysis Based on Deep Learning Techniques for Emerging Applications",
      "abstract": "Following the recent progress in the development of Terahertz (THz) generation and detection, THz technology is being widely used to characterize test sample properties in various applications including nondestructive testing, security inspection and medical applications. In this paper, we have presented a broad review of the recent usage of artificial intelligence (AI) particularly, deep learning techniques in various THz sensing, imaging, and spectroscopic applications with emphasis on their implementation for medical imaging of cancerous cells. Initially, the fundamentals principles and techniques for THz generation and detection, imaging and spectroscopy are introduced. Subsequently, a brief overview of AI &#x2013; machine learning and deep learning techniques is summarized, and their performance is compared. Further, the usage of deep learning algorithms in various THz applications is reported, with focus on metamaterials design and classification, detection, reconstruction, segmentation, parameter extraction and denoising tasks. Moreover, we also report the metrics used to evaluate the performance of deep learning models and finally, the existing research challenges in the application of deep learning in THz cancer imaging applications are identified and possible solutions are suggested through emerging trends. With the continuous increase of acquired THz data &#x2013; sensing, spectral and imaging, artificial intelligence has emerged as a dominant paradigm for embedded data extraction, understanding, perception, decision making and analysis. Towards this end, the integration of state-of-the-art machine learning techniques such as deep learning with THz applications enable detailed computational and theoretical analysis for better validation and verification than modelling techniques that precede the era of machine learning. The study will facilitate the large-scale clinical applications of deep learning enabled THz imaging systems for the development of smart and connected next generation healthcare systems as well as provide a roadmap for future research direction.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mavis Gezimati et al.",
      "keywords": "Artificial intelligence; Computer science; Deep learning; Terahertz radiation; Machine learning; Feature extraction; Materials science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3360930",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388486512",
      "doi": "10.1109/access.2023.3331092",
      "title": "Animal Behavior for Chicken Identification and Monitoring the Health Condition Using Computer Vision: A Systematic Review",
      "abstract": "126601",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Md Roman Bhuiyan et al.",
      "keywords": "Computer science; Risk analysis (engineering); Productivity; Poultry farming; Automation; Best practice; Identification (biology); Business; Engineering; Medicine; Veterinary medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3331092",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2976051362",
      "doi": "10.1109/access.2019.2943817",
      "title": "Medical Data Stream Distribution Pattern Association Rule Mining Algorithm Based on Density Estimation",
      "abstract": "The traditional data mining method is featured by no analysis over the data distribution and incomplete derived association rule. As a result, the data mining results have the deficiencies of large redundancy probability, large root-mean-square error of approximation (RMSEA) and long consumption time. To handle these issues, this paper proposes a medical data stream distribution pattern association rule mining algorithm based on density estimation. This paper collects medical data, selects the distance method to detect abnormal orphan data in the data stream, detects the duplicate data in the data stream by the similar field matching degree, and eliminates the abnormal data and the duplicate data. Then, the data stream density is estimated based on the histogram estimation samples. According to the data density estimation results, this paper analyzes the distribution of medical data stream from perspectives of concentration, dispersion and morphological characteristics of data distribution. Afterwards, the data distribution pattern association rule mining model is constructed based on compound neural network, data distribution parameters are entered into model&#x2019;s clustering layer, and in-depth training is conducted over the BP (Back Propagation) neural network at the model&#x2019;s mining layer. Meanwhile, all rules under the combination of hidden layer&#x2019;s neuron activity value and corresponding output value, and all rules under the combination of hidden layer&#x2019;s neuron activity value and corresponding input value are derived, so as to complete association rule mining of medical data stream distribution pattern. The experimental results show that the proposed algorithm has a contour curve closest to the true probability density curve; the dispersion degree of medical data is within a reasonable range, and the medical data has high stability; the data redundancy probability is smaller; the mining result&#x2019;s RMSEA is small; data mining takes less time.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Xiaofeng Li et al.",
      "keywords": "Data mining; Association rule learning; Computer science; Data stream; Cluster analysis; Density estimation; Algorithm; Histogram; Pattern recognition (psychology); Mean squared error; Data redundancy; Artificial intelligence; Statistics; Mathematics; Estimator",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2943817",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4376602921",
      "doi": "10.1109/access.2023.3276468",
      "title": "Gradient Boosting Based Model for Elderly Heart Failure, Aortic Stenosis, and Dementia Classification",
      "abstract": "Cardiovascular diseases, specifically heart failure and aortic stenosis, are considered common and deadly, with the additional risk of developing dementia in the elderly population. Early diagnosis can help prevent or alleviate these diseases and potentially reduce mortality rates. Machine learning algorithms, especially gradient boosting (GB), can effectively predict the presence of these diseases through binary classification using demographic and medical data. However, research has yet to combine data from all three diseases for multiclass classification, which is the purpose of the present study. Using a dataset collected from Chiang Rai Prachanukroh Hospital, Chiang Rai, Thailand, a GB-based model is proposed for the multiclass classification of elderly people with heart failure, aortic stenosis, and dementia, with the inclusion of feature engineering techniques for maximum accuracy. Other existing methods, including decision tree, support vector machine, k-nearest neighbors, random forest, and extra trees were applied for comparison. The Optuna framework was used with the tree-structured Parzen estimator for hyperparameter optimization. The results produced by each classifier were compared using various performance metrics, namely precision, recall, F1 score, accuracy, the area under the receiver operating characteristic curve, the area under the precision-recall curve, and the Matthews correlation coefficient. The results are presented separately for each machine learning algorithm for comparison. Based on these metrics, it can be concluded that our proposed GB-based model outperformed other comparative models after applying feature engineering techniques.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Khomkrit Yongcharoenchaiyasit et al.",
      "keywords": "Artificial intelligence; Computer science; Support vector machine; Random forest; Decision tree; Machine learning; Receiver operating characteristic; Precision and recall; Binary classification; Matthews correlation coefficient; Pattern recognition (psychology); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3276468",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4381715962",
      "doi": "10.1109/jbhi.2023.3288768",
      "title": "A Transformer-Based Model Trained on Large Scale Claims Data for Prediction of Severe COVID-19 Disease Progression",
      "abstract": "In situations like the COVID-19 pandemic, healthcare systems are under enormous pressure as they can rapidly collapse under the burden of the crisis. Machine learning (ML) based risk models could lift the burden by identifying patients with a high risk of severe disease progression. Electronic Health Records (EHRs) provide crucial sources of information to develop these models because they rely on routinely collected healthcare data. However, EHR data is challenging for training ML models because it contains irregularly timestamped diagnosis, prescription, and procedure codes. For such data, transformer-based models are promising. We extended the previously published Med-BERT model by including age, sex, medications, quantitative clinical measures, and state information. After pre-training on approximately 988 million EHRs from 3.5 million patients, we developed models to predict Acute Respiratory Manifestations (ARM) risk using the medical history of 80,211 COVID-19 patients. Compared to Random Forests, XGBoost, and RETAIN, our transformer-based models more accurately forecast the risk of developing ARM after COVID-19 infection. We used Integrated Gradients and Bayesian networks to understand the link between the essential features of our model. Finally, we evaluated adapting our model to Austrian in-patient data. Our study highlights the promise of predictive transformer-based models for precision medicine.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Manuel Lentzen et al.",
      "keywords": "Machine learning; Computer science; Artificial intelligence; Random forest; Predictive modelling; Lift (data mining); Coronavirus disease 2019 (COVID-19); Transformer; Disease; Big data; Medicine; Pandemic; Data mining; Infectious disease (medical specialty); Engineering; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3288768",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285820492",
      "doi": "10.1109/access.2022.3192390",
      "title": "Classification Techniques for Arrhythmia Patterns Using Convolutional Neural Networks and Internet of Things (IoT) Devices",
      "abstract": "The rise of Telemedicine has revolutionized how patients are being treated, leading to several advantages such as enhanced health analysis tools, accessible remote healthcare, basic diagnostic of health parameters, etc. The advent of the Internet of Things (IoT), Artificial Intelligence (AI) and their incorporation into Telemedicine extends the potential of health benefits of Telemedicine even further. Therefore, the synergy between AI, IoT, and Telemedicine creates diverse innovative scenarios for integrating cyber-physical systems into medical health to provide remote monitoring and interactive assistance to patients. Data from World Health Organization reports that 7.4 million people died because of Atrial Fibrillation (AF), recognizing the most common arrhythmia associated with human heart rate. Causes like unhealthy diet, smoking, poor resources to go to the doctor and based on research studies, about 12 and 17.9 million of people will be suffering the AF in the USA and Europe, in 2050 and 2060, respectively. The AF as a cardiovascular disease is becoming an important public health issue to tackle. By using a systematic approach, this paper reviews recent contributions related to the acquisition of heart beats, arrhythmia detection, IoT, and visualization. In particular, by analysing the most closely related papers on Convolutional Neural Network (CNN) and IoT devices in heart disease diagnostics, we present a summary of the main research gaps with suggested directions for future research.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Michael Opoku Agyeman et al.",
      "keywords": "Telemedicine; Convolutional neural network; Computer science; The Internet; Internet of Things; Health care; Cardiac arrhythmia; Data science; Artificial intelligence; Internet privacy; Medical emergency; Atrial fibrillation; Computer security; Medicine; World Wide Web; Cardiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3192390",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2806031689",
      "doi": "10.1109/jbhi.2018.2842717",
      "title": "A Decision Support System for Diagnostics and Treatment Planning in Traumatic Brain Injury",
      "abstract": "Traumatic brain injury (TBI) occurs when an external force causes functional or structural alterations in the brain. Clinical characteristics of TBI vary greatly from patient to patient, and a large amount of data is gathered during various phases of clinical care in these patients. It is hard for clinicians to efficiently integrate and interpret all of these data and plan interventions in a timely manner. This paper describes the technical architecture and functionality of a web-based decision support system (DSS), which not only provides advanced support for visualizing complex TBI data but also predicts a possible outcome by using a state-of-the-art Disease State Index machine-learning algorithm. The DSS is developed by using a three-layered architecture and by employing modern programming principles, software design patterns, and using robust technologies (C#, ASP.NET MVC, HTML5, JavaScript, Entity Framework, etc.). The DSS is comprised of a patient overview module, a disease-state prediction module, and an imaging module. After deploying it on a web-server, the DSS was made available to two hospitals in U.K. and Finland. Afterwards, we conducted a validation study to evaluate its usability in clinical settings. Initial results of the study indicate that especially less experience clinicians may benefit from this type of decision support software tool.",
      "year": "2018",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Adil Umer et al.",
      "keywords": "Computer science; Clinical decision support system; HTML5; Decision support system; Traumatic brain injury; Usability; JavaScript; Software; Software architecture; Web application; Artificial intelligence; Medicine; Human\u2013computer interaction; World Wide Web; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2018.2842717",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4283206075",
      "doi": "10.1109/tts.2022.3179756",
      "title": "Machine Learning, Convergence Digitalization, and the Concentration of Power: Enslavement by Design Using Techno-Biological Behaviors",
      "abstract": "The dawn of electronic business (e-business) changed the way that individuals interact not only with one another but also with the companies that supply them with goods and services, as well as with the government agencies on which they depend for welfare and security. We can speak of \u201cdigital business\u201d as the (re)design or (re)definition of new or existing business models, and as the creation of increased flows and connectivity between customers and other entities, both internal and external to the business, among other defining features. In this editorial, we explore three interrelated levels of sociological and economic practice\u2014micro, meso, and macro\u2014as they pertain to advances in digital business <xref ref-type=\"bibr\" rid=\"ref1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[1]</xref> , with the intention of revealing hidden dynamics and implications resulting from interactions between these levels. At the micro level, we consider the individual user. This can be interpreted as the \u201cself\u201d or the individual level (e.g., a person or person in singular interaction with another). At the meso level, we reflect on technological systems (e.g., information systems, biometrics, and data analysis through machine learning (ML), for the purposes of this article). This level is about groups and how they communicate in building knowledge, with a particular emphasis on what that knowledge means. The groups are made up of organizations, whether business or government agencies, or other collectives. And finally, at the macro level, we consider the societal context inclusive of communities (e.g., local/regional/national or international levels).",
      "year": "2022",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Roba Abbas et al.",
      "keywords": "Government (linguistics); Convergence (economics); Macro; Power (physics); Welfare; Computer science; Artificial intelligence; Business; Political science; Economics; Law; Linguistics; Philosophy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2022.3179756",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285065830",
      "doi": "10.1109/access.2022.3187406",
      "title": "Sentiment Analysis of Public Social Media as a Tool for Health-Related Topics",
      "abstract": "For decades, researchers have experimented with the possibility that machines can equal human linguistic capabilities. Recently, advances in the field of natural language processing (NLP) as well as a substantial increase in available naturally occurring linguistic data on social media platforms have made more advanced methodologies such as sentiment analysis (SA) gain substantial momentum on contemporary applications. This document compiles what the authors consider to be some of the most important concepts related to SA, as well as techniques and processes necessary for the various stages of its implementation. Furthermore, specific applications related to the extraction and classification of social media data using novel SA techniques are presented and quantified, with an emphasis on those used for the identification of mental health degradation during the COVID-19 pandemic. Finally, the authors present several conclusions highlighting the most prominent benefits and drawbacks of the methods discussed, followed by a brief discussion of possible future applications of certain methods of interest.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Fernando Arias et al.",
      "keywords": "Sentiment analysis; Computer science; Social media; Field (mathematics); Data science; Identification (biology); Coronavirus disease 2019 (COVID-19); Artificial intelligence; Natural language processing; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3187406",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380359173",
      "doi": "10.1109/access.2023.3285396",
      "title": "Wearable Obstacle Avoidance Electronic Travel Aids for Blind and Visually Impaired Individuals: A Systematic Review",
      "abstract": "Background Wearable obstacle avoidance electronic travel aids (ETAs) have been developed to assist the safe displacement of blind and visually impaired individuals (BVIs) in indoor/outdoor spaces. This systematic review aimed to understand the strengths and weaknesses of existing ETAs in terms of hardware functionality, cost, and user experience. These elements may influence the usability of the ETAs and are valuable in guiding the development of superior ETAs in the future. Methods Formally published studies designing and developing the wearable obstacle avoidance ETAs were searched for from six databases from their inception to April 2023. The PRISMA 2020 and APISSER guidelines were followed. Results Eighty-nine studies were included for analysis, 41 of which were judged to be of moderate to high quality. Most wearable obstacle avoidance ETAs mainly depend on camera- and ultrasonic-based techniques to achieve perception of the environment. Acoustic feedback was the most common human-computer feedback form used by the ETAs. According to user experience, the efficacy and safety of the device was usually their primary concern. Conclusions Although many conceptualised ETAs have been designed to facilitate BVIs' independent navigation, most of these devices suffer from shortcomings. This is due to the nature and limitations of the various processors, environment detection techniques and human-computer feedback those ETAs are equipped with. Integrating multiple techniques and hardware into one ETA is a way to improve performance, but there is still a need to address the discomfort of wearing the device and the high-cost. Developing an applicable systematic review guideline along with a credible quality assessment tool for these types of studies is also required. \u00a9 2013 IEEE.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Peijie Xu et al.",
      "keywords": "Wearable computer; Visually impaired; Human\u2013computer interaction; Computer science; Obstacle; Obstacle avoidance; Blind spot; Wearable technology; Physical medicine and rehabilitation; Psychology; Artificial intelligence; Medicine; Embedded system; Robot; Mobile robot",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3285396",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3000265600",
      "doi": "10.1109/access.2020.2966819",
      "title": "Robots, AI, and Cognitive Training in an Era of Mass Age-Related Cognitive Decline: A Systematic Review",
      "abstract": "Developing countries world-wide are witnessing historical growth in their elderly populations, and with it, importantly, a steady rise in the number of people experiencing age-related cognitive decline. This reality has the potential to produce an unprecedented strain on affected families, healthcare systems and taxpayers in the very near future. This study: a) examines the present limits and predicted capacity of Artificial Intelligence (AI) as they relate to the various and complex needs of those hoping to optimize the positive benefits of cognitive training, and b) systematically reviews the efficacy of Human Robot Interaction (HRI) as an intervention strategy for elderly individuals confronting cognitive challenges along the spectrum from Mild Cognitive Impairment (MCI) to Advanced Cognitive Impairment (ACI). The results of this systematic review suggest that, overall, the utilization of humanoid and pet robots, such as NAO and PARO, respectively, produce improvements in cognition and markers of social and emotional health and engagement; however, when embedded with AI with the capacity for Deep Learning the potential of robotic technology to aggressively meet the needs of individuals experiencing age-related cognitive decline will be significant.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Alistair A. Vogan et al.",
      "keywords": "Cognition; Computer science; Training (meteorology); Robot; Artificial intelligence; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.2966819",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2900421934",
      "doi": "10.1109/jtehm.2018.2878534",
      "title": "Improving Detection of Rapid Cystic Fibrosis Disease Progression\u2013Early Translation of a Predictive Algorithm Into a Point-of-Care Tool",
      "abstract": "The clinical course of cystic fibrosis (CF) lung disease is marked by acute drops of lung function, defined clinically as rapid decline. As such, lung function is monitored routinely through pulmonary function testing, producing hundreds of measurements over the lifespan of an individual patient. Point-of-care technologies aimed at improving detection of rapid decline have been limited. Our aim in this early translational study is to develop and translate a predictive algorithm into a prototype prognostic tool for improved detection of rapid decline. The predictive algorithm was developed, validated and checked for 6-month, 1-year, and 2-year forecast accuracies using data on demographic and clinical characteristics from 30 879 patients aged 6 years and older who were followed in the U.S. Cystic Fibrosis Foundation Patient Registry from 2003 to 2015. Predictions of rapid decline based on the algorithm were compared to a detection algorithm currently being used at a CF center with 212 patients who received care between 2012-2017. The algorithm was translated into a prototype web application using RShiny, which resulted from an iterative development and refinement based on clinician feedback. The study showed that the algorithm had excellent predictive accuracy and earlier detection of rapid decline, compared to the current approach, and yielded a prototype platform with the potential to serve as a viable point-of-care tool. Future work includes implementation of this clinical prototype, which will be evaluated prospectively under real-world settings, with the aim of improving the pre-visit planning process for CF point of care. Likely extensions to other point-of-care settings are discussed.",
      "year": "2018",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Rhonda D. Szczesniak et al.",
      "keywords": "Algorithm; Cystic fibrosis; Medicine; Point of care; Machine learning; Disease; Internal medicine; Computer science; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2018.2878534",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3166909423",
      "doi": "10.1109/access.2021.3085771",
      "title": "Classification of Pediatric Posterior Fossa Tumors Using Convolutional Neural Network and Tabular Data",
      "abstract": "Posterior fossa tumors (PFT) are the most common tumors in children. Differentiation between the various PFT types is critical, as different tumors have diverse treatment approaches. This study proposes the use of fused architecture comprising two neural networks, a pre-trained ResNet-50 Convolutional Neural Network (CNN) and a tabular based network for the classification of PFT. The study included data for 158 MRI scans of 22 healthy controls and 136 pediatric patients with newly diagnosed PFT (63 Pilocytic Astrocytoma, 57 Medulloblastoma and 16 Ependymoma). The input data for classification were from magnetic resonance imaging: post contrast T1-weighted, fluid attenuated inversion recovery and diffusion Trace images, and tabular data: subject&#x2019;s age. Evaluation of the model was performed in a stratified 5-fold cross-validation manner, based on accuracy, precision, recall and F1 score metrics. Model explanation was performed in terms of visual explanation of the CNN by Gradient-weighted Class Activation Mapping (Grad-CAM) and by testing the contribution to the classification results of the different imaging input data sets and the proposed fused architectures relative to CNN only and tabular only architectures. The best classification results were obtained with the fused CNN &#x002B; tabular data architecture, and based on diffusion Trace images, achieving mean cross-validation accuracy of 0.88 &#x00B1; 0.04 for the validation and 0.87 &#x00B1; 0.02 for the test dataset. Overall, the proposed architecture achieved improvement in accuracy and F1 score compared to CNN method for this dataset. The source code is available on the GitHub repository: <uri>https://github.com/artzimy/CNNTabular</uri>.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Moran Artzi et al.",
      "keywords": "Computer science; Convolutional neural network; Pattern recognition (psychology); Artificial intelligence; Deep learning; Contextual image classification; Cross-validation; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3085771",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3203484264",
      "doi": "10.1109/access.2021.3116148",
      "title": "A Framework for IoT Based Appliance Recognition in Smart Homes",
      "abstract": "Internet of Things (IoT) technologies will play an important role in enabling the smart grid achieving its goals in monitoring, protecting, and controlling by incorporating sensors, actuators, and metering devices while supporting various network functions and system automation. In this regard, home energy management systems (HEMS) enable customers efficiently use energy by managing their consumption, providing feedback information and improving control of major appliances. This work proposes a novel framework for IoT based appliance recognition in smart homes. It consists of two parts: training framework and inference framework. The proposed framework allows incorporating different loads in the monitoring system and enables selecting and testing specific parameters related to dataset configuration, feature extraction, and classifier model setting. The work contributes by developing an easy-to-use tool that allows customization of the training/prediction parameters according to the user criterion. Once the data and all its parameters are loaded, a novel feature extraction algorithm is used to obtain a total of ten statistical features. For the classification task, three machine learning models are included: a feed-forward neural network, a long short-term memory and a support vector machine. In addition, the user can apply a set of techniques to handle imbalanced classes, and also measure the influence of the selected features in the classifiers&#x2019; prediction by performing a feature importance analysis.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Patricia Franco et al.",
      "keywords": "Computer science; Machine learning; Smart grid; Feature extraction; Home automation; Support vector machine; Artificial intelligence; Energy consumption; Artificial neural network; Data mining; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3116148",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2908654015",
      "doi": "10.1109/access.2019.2891710",
      "title": "Intelligent Health Diagnosis Technique Exploiting Automatic Ontology Generation and Web-Based Personal Health Record Services",
      "abstract": "Growing interest in healthcare has promoted the use of symptom checkers, which are online health applications that provide diagnostic information on users&#x2019; health. However, their diagnostic accuracy remains low because the existing symptom checkers rely on manually constructed knowledge models through labor-intensive processes or perform diagnoses based on simple pairwise relationships between diseases and symptoms without considering personal health conditions. In this paper, we propose an intelligent health diagnosis technique that exploits automatically generated ontology and Web-based personal health record services. The proposed technique first automatically generates a human disease diagnosis ontology by exploiting two well-established ontologies for diseases and symptoms: a large-scale medical bibliographic database and an open biomedical repository. When a user enters the symptom-based queries, possible diagnoses are identified by analyzing the user&#x2019;s queries and their health record data via semantic inferences of the automatically generated ontology. Subsequently, the ranked diagnostic results are provided to the user via ranking methods that consider the user&#x2019;s symptoms, personal health attributes, and multi-level diagnosis. The proposed technique also provides the user&#x2019;s diagnostic progress information, which can be used to track or monitor the progress of diseases by considering changes in symptoms over time. The proposed technique was evaluated through a comparison with the existing well-known symptom checkers and other related approaches. The evaluation results show that the proposed technique can feasibly help to improve diagnostic accuracy and deliver appropriate diagnostic information for healthcare action by users.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Gun-Woo Kim et al.",
      "keywords": "Computer science; Ontology; World Wide Web; Web service; Information retrieval",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2891710",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3157606464",
      "doi": "10.1109/access.2021.3074791",
      "title": "A Multi-Agent Approach for Personalized Hypertension Risk Prediction",
      "abstract": "Hypertension is a global health problem and a leading factor in severe and life-threatening cardiovascular diseases (CVD) and stroke. The onset is dependent on individual lifestyle choices, and no single root cause of the condition exists. Various machine learning solutions are proposed for the early diagnosis of hypertension and its prediction, but they are based on standard guidelines and do not provide personalized solutions. Current models mainly rely on batch learning methods and do not readily learn the new incoming data. There is also a lack of an intelligent technique for handling anomalies in data, which leads to unreliable prediction results. In this paper, an integrated multi-agent-based hypertension risk prediction system is proposed that detects and computes missing values in the time series and provides personalized hypertension risk predictions. The proposed solution incorporates Gaussian mixture models for enhancing the input data, and an Online Infinite Echo State Gaussian Process (OIESGP) is used to obtain real-time prediction distribution of blood pressure. The prediction system readily absorbs new incoming data, and the model is updated to learn any new patterns in the data. The hypertension risk score is estimated using the Framingham hypertension risk estimator, and a 4-year hypertension risk is computed. The prediction performance of the proposed model is evaluated on blood pressure data gathered from the Malaysian population using mean absolute error, mean square error, and root-mean-square errors. The experimental results indicate that the proposed prediction model exhibits greater prediction accuracy than existing state-of-the-art online prediction methods.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Sundus Abrar et al.",
      "keywords": "Computer science; Estimator; Mean squared error; Random forest; Population; Data mining; Gaussian; Artificial intelligence; Blood pressure; Time series; Machine learning; Predictive modelling; Statistics; Medicine; Mathematics; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3074791",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394804877",
      "doi": "10.1109/access.2024.3388841",
      "title": "Raman Spectroscopy and AI Applications in Cancer Grading: An Overview",
      "abstract": "Raman spectroscopy (RS) is a label-free molecular vibrational spectroscopy technique that is able to identify the molecular fingerprint of various samples making use of the inelastic scattering of monochromatic light. Because of its advantages of non-destructive and accurate detection, RS is finding more and more use for benign and malignant tissues, tumor differentiation, tumor subtype classification, and section pathology diagnosis, operating either in vivo or in vitro. However, the high specificity of RS comes at a cost. The acquisition rate is low, depth information cannot be directly accessed, and the sampling area is limited. Such limitations can be contained if data pre- and post-processing methods are combined with current methods of Artificial Intelligence (AI), essentially, Machine Learning (ML) and Deep Learning (DL). The latter is modifying the approach to cancer diagnosis currently used to automate many cancer data analyses, and it has emerged as a promising option for improving healthcare accuracy and patient outcomes by abiliting prediction diseases tools. In a very broad context, Artificial Intelligence applications in oncology include risk assessment, early diagnosis, patient prognosis estimation, and treatment selection based on deep knowledge. The application of autonomous methods to datasets generated by RS analysis of benign and malignant tissues could make RS a rapid and stand-alone technique to help pathologists diagnose cancer with very high accuracy. This review describes the current milestones achieved by applying AI-based algorithms to RS analysis, grouped according to seven major types of cancers (Pancreatic, Breast, Skin, Brain, Prostate, Ovarian and Oral cavity). Additionally, it provides a theoretical foundation to tackle both present and forthcoming challenges in this domain. By exploring the current achievements and discussing the relative methodologies, this review offers recapitulative insights on recent and ongoing efforts to position RS as a rapid and effective cancer screening tool for pathologists. Accordingly, we aim to encourage future research endeavors and to facilitate the realization of the full potential of RS and AI applications in cancer grading.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Pietro Manganelli Conforti et al.",
      "keywords": "Raman spectroscopy; Computer science; Grading (engineering); Spectroscopy; Optics; Physics; Engineering; Astronomy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3388841",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2912141246",
      "doi": "10.1109/access.2019.2894421",
      "title": "Towards a Knowledge-Based Recommender System for Linking Electronic Patient Records With Continuing Medical Education Information at the Point of Care",
      "abstract": "Given the limits of human memory, clinicians have trouble recalling therapeutic recommendations, even when the clinician previously judged that the information relevant for the care of a specific patient. To tackle this problem, we present a knowledge-based recommender system prototype that links the electronic patient records to clinical information, previously delivered to the target physician and judged to be potentially beneficial. We developed this prototype within the context of RxTx, a Canadian continuing medical education program. We apply a constraint-based recommendation strategy as follows: (1) clinical experts (taggers) map a set of therapeutic recommendations (called Highlights) to a requirement statement built from the standard clinical codes and supplementary demographic information, when applicable; (2) a matching system identifies patient-Highlights recommendation pairs through requirement satisfaction; and (3) given a patient record being examined, the recommended Highlights can be retrieved online at the point of care. We tested this prototype using electronic medical records from the Canadian Primary Care Sentinel Surveillance Network and 87 therapeutic Highlights from the RxTx collection, evaluating the system's performance against a gold standard consisting of a two-expert consolidated patient-Highlight matching set for 150 patient records. The requirements-based recommendation system exhibits very high precision (mode: 1.0, 89% of the time; average precision: 0.95) and moderate recall (mode 1.0, 48.7% of the time; average recall: 0.61). The near-perfect precision minimizes the possibility of generating alert fatigue in physicians using the system. We note that more than half of the false negative results from the information being available in the text of the electronic medical records, but unavailable as a clinical code. The near-perfect precision over the tested patient set suggests that the system has the potential to deliver high-quality recommendations of clinical information at the point of care while being easily integrated within a continuing medical education program and the clinician's workflow.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Manuel Lizalde Gil et al.",
      "keywords": "Computer science; Context (archaeology); Matching (statistics); Set (abstract data type); Recall; Medical record; Precision and recall; Point of care; Information retrieval; Recommender system; Point (geometry); Artificial intelligence; Medicine; Nursing; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2894421",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392902463",
      "doi": "10.1109/access.2024.3377232",
      "title": "Transformer-Based Named Entity Recognition in Construction Supply Chain Risk Management in Australia",
      "abstract": "In the Australian construction industry, effective supply chain risk management (SCRM) is critical due to its complex networks and susceptibility to various risks. This study explores the application of transformer models like BERT, RoBERTa, DistilBERT, ALBERT, and ELECTRA for Named Entity Recognition (NER) in this context. Utilizing these models, we analyzed news articles to identify and classify entities related to supply chain risks, providing insights into the vulnerabilities within this sector. Among the evaluated models, RoBERTa achieved the highest average F1 score of 0.8580, demonstrating its superior balance in precision and recall for NER in the Australian construction supply chain context. Our findings highlight the potential of NLP-driven solutions to revolutionize SCRM, particularly in geo-specific settings.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Milad Baghalzadeh Shishehgarkhaneh et al.",
      "keywords": "Computer science; Supply chain; Transformer; Risk management; Supply chain management; Named-entity recognition; Supply chain risk management; Service management; Business; Engineering; Finance; Systems engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3377232",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387197159",
      "doi": "10.1109/ojim.2023.3320765",
      "title": "Conv-Random Forest-Based IoT: A Deep Learning Model Based on CNN and Random Forest for Classification and Analysis of Valvular Heart Diseases",
      "abstract": "Cardiovascular diseases are growing rapidly in this world. Around 70&#x0025; of the world&#x2019;s population is suffering from the same. The entire research work is grouped into the classification and analysis of heart sound. We defined a new squeeze network-based deep learning model&#x2014;convolutional random forest (RF) for real-time valvular heart sound classification and analysis using industrial Raspberry Pi 4B. The proposed electronic stethoscope is Internet enabled using ESP32, and Raspberry Pi. The said Internet of Things (IoT)-based model is also low cost, portable, and can be reachable to distant remote places where doctors are not available. As far as the classification part is concerned, the multiclass classification is done for seven types of valvular heart sounds. The RF classifier scored a good accuracy among other ensemble methods in small training set data. The CNN-based squeeze net model achieved a decent accuracy of 98.65&#x0025; after its hyperparameters were optimized for heart sound analysis. The proposed IoT-based model overcomes the drawbacks faced individually in both squeeze network and RF. CNN-based squeeze net model and RF classifier combined together improved the performance of classification accuracy. The squeeze net model plays a pivotal part in the feature extraction of heart sound, and an RF classifier acts as a classifier in the class prediction layer for predicting class labels. Experimental results on several datasets like the Kaggle dataset, the Physio net challenge, and the Pascal Challenge showed that the Conv-RF model works the best. The proposed IoT-based Conv-RF model is also applied on the selected subjects with different age groups and genders having a history of heart diseases. The Conv-RF method scored an accuracy of 99.37 &#x00B1; 0.05&#x0025; on the different test datasets with a sensitivity of 99.5 &#x00B1; 0.12&#x0025; and specificity of 98.9 &#x00B1; 0.03&#x0025;. The proposed model is also examined with the current state-of-the-art models in terms of accuracy.",
      "year": "2023",
      "journal": "IEEE Open Journal of Instrumentation and Measurement",
      "authors": "Tanmay Sinha Roy et al.",
      "keywords": "Random forest; Computer science; Artificial intelligence; Classifier (UML); Convolutional neural network; Machine learning; Deep learning; Pattern recognition (psychology); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojim.2023.3320765",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312797450",
      "doi": "10.1109/access.2022.3215154",
      "title": "The State of the Art of Information Integration in Space Applications",
      "abstract": "This paper aims to present a comprehensive survey on information integration (II) in space informatics. With an ever-increasing scale and dynamics of complex space systems, II has become essential in dealing with the complexity, changes, dynamics, and uncertainties of space systems. The applications of space II (SII) require addressing some distinctive functional requirements (FRs) of heterogeneity, networking, communication, security, latency, and resilience; while limited works are available to examine recent advances of SII thoroughly. This survey helps to gain the understanding of the state of the art of SII in sense that (1) technical drivers for SII are discussed and classified; (2) existing works in space system development are analyzed in terms of their contributions to space economy, divisions, activities, and missions; (3) enabling space information technologies are explored at aspects of sensing, communication, networking, data analysis, and system integration; (4) the importance of first-time right (FTR) for implementation of a space system is emphasized, the limitations of digital twin (DT-I) as technological enablers are discussed, and a concept digital-triad (DT-II) is introduced as an information platform to overcome these limitations with a list of fundamental design principles; (5) the research challenges and opportunities are discussed to promote SII and advance space informatics in future.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Zhuming Bi et al.",
      "keywords": "Computer science; Space (punctuation); Data science; Information space; Informatics; Resilience (materials science); Information system; Systems engineering; World Wide Web; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3215154",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386432235",
      "doi": "10.1109/tnsre.2023.3311458",
      "title": "Multi-Granularity Graph Convolution Network for Major Depressive Disorder Recognition",
      "abstract": "Major depressive disorder (MDD) is the most common psychological disease. To improve the recognition accuracy of MDD, more and more machine learning methods have been proposed to mining EEG features, i.e. typical brain functional patterns and recognition methods that are closely related to depression using resting EEG signals. Most existing methods typically utilize threshold methods to filter weak connections in the brain functional connectivity network (BFCN) and construct quantitative statistical features of brain function to measure the BFCN. However, these thresholds may excessively remove weak connections with functional relevance, which is not conducive to discovering potential hidden patterns in weak connections. In addition, statistical features cannot describe the topological structure features and information network propagation patterns of the brain's different functional regions. To solve these problems, we propose a novel MDD recognition method based on a multi-granularity graph convolution network (MGGCN). On the one hand, this method applies multiple sets of different thresholds to build a multi-granularity functional neural network, which can remove noise while fully retaining valuable weak connections. On the other hand, this method utilizes graph neural network to learn the topological structure features and brain saliency patterns of changes between brain functional regions on the multi-granularity functional neural network. Experimental results on the benchmark datasets validate the superior performance and time complexity of MGGCN. The analysis shows that as the granularity increases, the connectivity defects in the right frontal(RF) and right temporal (RT) regions, left temporal(LT) and left posterior(LP) regions increase. The brain functional connections in these regions can serve as potential biomarkers for MDD recognition.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Xiaofang Sun et al.",
      "keywords": "Granularity; Pattern recognition (psychology); Computer science; Artificial intelligence; Functional connectivity; Graph; Benchmark (surveying); Machine learning; Theoretical computer science; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3311458",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385299462",
      "doi": "10.1109/access.2023.3299332",
      "title": "Exploring Hyper-Parameters and Feature Selection for Predicting Non-Communicable Chronic Disease Using Stacking Classifier",
      "abstract": "Non-communicable disease, especially chronic disease, is the most common factor of complication of deteriorating physical health and the state of one&#x2019;s mind. It is also a prominent cause of illness and mortality around the world. Primarily chronic disease is preventable at a particular stage though its occurrence is critical. To make clinical decisions, these illness prediction models were created to assist clinicians and patients. A chronic disease prediction model takes into account many risk variables to determine an individual&#x2019;s illness risk. Machine learning approaches have made it possible to predict chronic disease early by collecting Electronic Health Record (EHR) data. This paper focuses on the diabetes dataset extracted from Kaggle and two unseen real datasets. In this paper, we have implemented Synthetic Minority Over-Sampling Technique (SMOTE) algorithm to balance the dataset. We have also explored Boruta as the feature selection method. To tune hyper-parameters of different algorithms, we have proposed an improved technique by combining the Grid Search method with the Grey Wolf Optimization algorithm. The Grid Search method requires extensive searching, while the Grey Wolf Optimization algorithm is easily linked, rapid to seek, and extremely exact. Nine conventional classification techniques have been evaluated in this paper. This research concentrates on the Stacking Classifier to assess the performance of the prediction model that produces the best results. The Proposed Model gave the highest F1-Score 98.84&#x0025; on PIMA dataset, 98&#x0025; after validation on the Synthetic dataset, 97.3&#x0025; on ADRC dataset, 96.20&#x0025; on FHD dataset. To the best of our knowledge, no previous work has focused on such a sort of technique and these two datasets. The outcomes of the comparison experiment on the PIMA dataset reveals that the proposed strategy performs better. This study also provides the interpretation of the proposed model. It conducts an ethical assessment of what explainability means for the use of Machine Learning models in clinical practice.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Pooja Yadav et al.",
      "keywords": "Feature selection; Computer science; Stacking; Artificial intelligence; Pattern recognition (psychology); Non-communicable disease; Classifier (UML); Machine learning; Data mining; Disease; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3299332",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384499185",
      "doi": "10.1109/access.2023.3296221",
      "title": "TransAMR: An Interpretable Transformer Model for Accurate Prediction of Antimicrobial Resistance Using Antibiotic Administration Data",
      "abstract": "Antimicrobial Resistance (AMR) is a growing public and veterinary health concern, and the ability to accurately predict AMR from antibiotics administration data is crucial for effectively treating and managing infections. While genomics-based approaches can provide better results, sequencing, assembling, and applying Machine Learning (ML) methods can take several hours. Therefore, alternative approaches are required. This study focused on using ML for antimicrobial stewardship by utilising data extracted from hospital electronic health records, which can be done in real-time, and developing an interpretable 1D-Transformer model for predicting AMR. A multi-baseline Integrated Gradient pipeline was also incorporated to interpret the model, and quantitative validation metrics were introduced to validate the model. The performance of the proposed 1D-Transformer model was evaluated using a dataset of urinary tract infection (UTI) patients with four antibiotics. The proposed 1D-Transformer model achieved 10&#x0025; higher area under curve (AUC) in predicting AMR and outperformed traditional ML models. The Explainable Artificial Intelligence (XAI) pipeline also provided interpretable results, identifying the signatures contributing to the predictions. This could be used as a decision support tool for personalised treatment, introducing AMR-aware food and management of AMR, and it could also be used to identify signatures for targeted interventions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mukunthan Tharmakulasingam et al.",
      "keywords": "Antibiotic resistance; Antimicrobial; Transformer; Computer science; Antibiotics; Data mining; Microbiology; Engineering; Voltage; Electrical engineering; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3296221",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4220750123",
      "doi": "10.1109/tnsre.2022.3161272",
      "title": "Federated Deep Learning for the Diagnosis of Cerebellar Ataxia: Privacy Preservation and Auto-Crafted Feature Extractor",
      "abstract": "Cerebellar ataxia (CA) is concerned with the incoordination of movement caused by cerebellar dysfunction. Movements of the eyes, speech, trunk, and limbs are affected. Conventional machine learning approaches utilizing centralised databases have been used to objectively diagnose and quantify the severity of CA. Although these approaches achieved high accuracy, large scale deployment will require large clinics and raises privacy concerns. In this study, we propose an image transformation-based approach to leverage the advantages of state-of-the-art deep learning with federated learning in diagnosing CA. We use motion capture sensors during the performance of a standard neurological balance test obtained from four geographically separated clinics. The recurrence plot, melspectrogram, and poincar\u00e9 plot are three transformation techniques explored. Experimental results indicate that the recurrence plot yields the highest validation accuracy (86.69%) with MobileNetV2 model in diagnosing CA. The proposed scheme provides a practical solution with high diagnosis accuracy, removing the need for feature engineering and preserving data privacy for a large-scale deployment.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Thang Ngo et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3161272",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205208636",
      "doi": "10.1109/jbhi.2021.3139773",
      "title": "A Time-Series Feature-Based Recursive Classification Model to Optimize Treatment Strategies for Improving Outcomes and Resource Allocations of COVID-19 Patients",
      "abstract": "This paper presents a novel Lasso Logistic Regression model based on feature-based time series data to determine disease severity and when to administer drugs or escalate intervention procedures in patients with coronavirus disease 2019 (COVID-19). Advanced features were extracted from highly enriched and time series vital sign data of hospitalized COVID-19 patients, including oxygen saturation readings, and with a combination of patient demographic and comorbidity information, as inputs into the dynamic feature-based classification model. Such dynamic combinations brought deep insights to guide clinical decision-making of complex COVID-19 cases, including prognosis prediction, timing of drug administration, admission to intensive care units, and application of intervention procedures like ventilation and intubation. The COVID-19 patient classification model was developed utilizing 900 hospitalized COVID-19 patients in a leading multi-hospital system in Texas, United States. By providing mortality prediction based on time-series physiologic data, demographics, and clinical records of individual COVID-19 patients, the dynamic feature-based classification model can be used to improve efficacy of the COVID-19 patient treatment, prioritize medical resources, and reduce casualties. The uniqueness of our model is that it is based on just the first 24 hours of vital sign data such that clinical interventions can be decided early and applied effectively. Such a strategy could be extended to prioritize resource allocations and drug treatment for futurepandemic events.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Lin Wang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3139773",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313028954",
      "doi": "10.1109/access.2022.3227437",
      "title": "Whole Slide Image Quality in Digital Pathology: Review and Perspectives",
      "abstract": "International audience",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Romain Brixtel et al.",
      "keywords": "Computer science; Digitization; Pipeline (software); Digital pathology; Focus (optics); Quality (philosophy); Process (computing); Artificial intelligence; Image quality; Sample (material); Visualization; Computer vision; Data science; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3227437",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388676552",
      "doi": "10.1109/access.2023.3332762",
      "title": "PredictEYE: Personalized Time Series Model for Mental State Prediction Using Eye Tracking",
      "abstract": "Mental health is vital for emotional, psychological, and social well-being. Mental illness can affect thoughts, feelings, and behaviors. Early intervention and specialized care can manage major mental illnesses. Predicting mental state accurately can facilitate behavioral changes and promote overall well-being. The paper proposes a novel personalized time series model called PredictEYE, which aims to predict a person&#x2019;s mental state and identify the specific scene responsible for that mental state. The model achieves this by analyzing individuals&#x2019; eye-tracking time series data while watching calm and stressful videos. The model utilizes a deep learning time-series univariate regression model based on Long Short-Term Memory for predicting the future sequence of each feature and a machine learning-based Random Forest algorithm for the mental state prediction. The model&#x2019;s performance was compared across the state-of-the-art literature survey. The predictEYE model could achieve an accuracy of 86.4&#x0025; accuracy in predicting mental state. Tailoring eye tracking models to individual differences is more effective in comprehending mental states than models that make comparisons across multiple participants, given eye tracking data&#x2019;s unique and distinctive idiosyncratic nature. The eye tracking features play a crucial role in predicting the mental state, and the model is adaptable to work with webcam-based eye tracking and can relate to applications where continuous and non-invasive monitoring is required.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "C. Jyotsna et al.",
      "keywords": "Computer science; Eye tracking; Artificial intelligence; Univariate; Machine learning; Feature (linguistics); Mental health; Tracking (education); Random forest; Time series; Feeling; Psychology; Multivariate statistics; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3332762",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295679781",
      "doi": "10.1109/access.2022.3197756",
      "title": "A Systematic Literature Review on Latest Keystroke Dynamics Based Models",
      "abstract": "The purpose of this study is to conduct a comprehensive evaluation and analysis of the most recent studies on the implications of keystroke dynamics (KD) patterns in user authentication, identification, and the determination of useful information. Another aim is to provide an extensive and up-to-date survey of the recent literature and potential research directions to understand the present state-of-the-art methodologies in this particular domain that are expected to be beneficial for the KD research community. From January 1st, 2017 to March 13th, 2022, the popular six electronic databases have been searched using a search criterion (&#x201C;keystroke dynamics&#x201D; OR &#x201C;typing pattern&#x201D;) AND (&#x201C;authentication&#x201D; OR &#x201C;verification&#x201D; OR &#x201C;identification&#x201D;). With this criterion, a total of nine thousand three hundred forty-eight results, including duplicates, were produced. However, one thousand five hundred forty-seven articles have been chosen after removing duplicates and preliminary screening. Due to insufficient information, only one hundred twenty-seven high-quality quantitative research articles have been included in the article selection process. We compared and summarised several factors with multiple tables to comprehend the various methodologies, experimental settings, and findings. In this study, we have identified six unique KD-based designs and presented the status of findings toward an effective solution in authentication, identification, and prediction. We have also discovered considerable heterogeneity across studies in each KD-based design for desktops and smartphones separately. Finally, this paper found a few open research challenges and provided some indications for a deeper understanding of the issues and further study.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Soumen Roy et al.",
      "keywords": "Keystroke dynamics; Computer science; Identification (biology); Authentication (law); Keystroke logging; Data science; Selection (genetic algorithm); Artificial intelligence; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3197756",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4221130735",
      "doi": "10.1109/access.2022.3161392",
      "title": "Longevity Foundation: Perspective on Decentralized Autonomous Organization for Special-Purpose Financing",
      "abstract": "Decentralized autonomous organizations (DAO) launched on a blockchain and governed by a smart contract promises to bring self-organization to a new technological level. Crisis management has no standard decentralized solution within DAO yet. A central authority is a natural component due to compliance reasons in certain domains, for example, special-purpose financing, in which the DAO governance model could be reasonably applied. More generally, a centralized DAO representative could streamline implementing DAO decisions that involve interactions with legacy systems. The article presents a perspective of modern technologies for organizing a foundation for special-purpose financing and considers longevity as a model example of the purpose.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Evelyne Bischof et al.",
      "keywords": "Foundation (evidence); Perspective (graphical); Corporate governance; Longevity; Business; Blockchain; Computer science; Finance; Political science; Computer security; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3161392",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3080087223",
      "doi": "10.1109/access.2020.3018704",
      "title": "Shock Decision Algorithms for Automated External Defibrillators Based on Convolutional Networks",
      "abstract": "Automated External Defibrillators (AED) incorporate a shock decision algorithm that analyzes the patient's electrocardiogram (EKG), allowing lay persons to provide life saving defibrillation therapy to out-of-hospital cardiac arrest (OHCA) patients. The most accurate shock decision algorithms are based on deep learning, but these algorithms have not been trained and tested using OHCA data. In this study we propose novel deep learning architectures for shock decision algorithms based on convolutional and residual networks. EKG electronic recordings from a cohort of 852 OHCA cases (4216 AED EKG analyses) were used in the study. EKGs were annotated by a pool of six expert clinicians resulting in 3718 nonshockable and 498 shockable EKGs. Data were partitioned patient wise in a stratified way to train and test the models using 10-fold cross validation, and the procedure was repeated 100 times for statistical evaluation. Performance was assessed using sensitivity (shockable), specificity (non-shockable) and accuracy, and the analysis was conducted for EKG segments of decreasing duration. The best model had median (interdecile range) accuracies of 98.6 (98.5-98.7)%, 98.4 (98.2-98.6)%, 98.2 (97.9-98.4)%, and 97.6 (97.4-97.8)%, for 4, 3, 2 and 1 second EKG segments, respectively. The minimum 90% sensitivity and 95% specificity requirements established by the American Heart Association for shock decision algorithms were met, and the best model presented significantly greater accuracy (p&lt;; 0.05 McNemar test) than previous deep learning solutions for all segment durations. Moreover, the first AHA compliant shock decision algorithm using 1-s segments was demonstrated. This should contribute to a combined optimization of defibrillation and cardiopulmonary resuscitation therapy to improve OHCA survival.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Xabier Jaureguibeitia et al.",
      "keywords": "McNemar's test; Medicine; Algorithm; Automated external defibrillator; Defibrillation; Computer science; Machine learning; Shock (circulatory); Artificial intelligence; Cardiology; Internal medicine; Emergency medicine; Statistics; Cardiopulmonary resuscitation; Resuscitation; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3018704",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391853733",
      "doi": "10.1109/tem.2024.3366313",
      "title": "How Can Technological Resources Improve the Quality of Healthcare Service? The Enabling Role of Big Data Analytics Capabilities",
      "abstract": "International audience",
      "year": "2024",
      "journal": "IEEE Transactions on Engineering Management",
      "authors": "Luigi Jesus Basile et al.",
      "keywords": "Big data; Analytics; Health care; Data science; Quality (philosophy); Computer science; Healthcare service; Service (business); Knowledge management; Business; Process management; Marketing; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tem.2024.3366313",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4285144400",
      "doi": "10.1109/access.2022.3174368",
      "title": "Choosing YouTube Videos for Self-Directed Learning",
      "abstract": "YouTube provides a vital source for self-directed learning. YouTube&#x2019;s search engine, however, ranks videos according to popularity, relevancy, and view history rather than quality. The effect of this ranking on learners&#x2019; behavior and experience is not clear: Do learners tend to choose from the top of the returned search list? Does the choosing behavior affect their learning? Is the type of sought knowledge relevant in this process? To answer these questions, we conducted two experiments with sophomore-level students in electrical and computer engineering programs. The students were asked to learn about two new topics by watching YouTube videos of their choice. The first topic conveys procedural knowledge about using the Quine McCluskey algorithm for minimizing logical functions. The second topic relates to the concept of the set-reset latch. In each learning session, the students had to report their watching behavior and experience by responding to an online questionnaire as well as to solve a problem related to the respective topic. The results show a clear tendency to choose from the top of the returned list. However, students&#x2019; performance in problem-solving was found to be uncorrelated with the choosing behavior. These results were similar for procedural and conceptual learning although the students&#x2019; performance in solving the conceptual problem was significantly lower. These findings indicate that university students who seek YouTube for self-directed learning can freely choose from the top of the returned search list without concern. There is no evident harm in doing so. However, students need to be thoughtful when using YouTube for conceptual learning. They should use different strategies such as watching multiple videos, selecting videos with higher viewer ratings, or watching videos with related procedural knowledge to support the learning of new concepts.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Fatma Mohamed et al.",
      "keywords": "Computer science; Popularity; Set (abstract data type); Ranking (information retrieval); Session (web analytics); Quality (philosophy); Semantics (computer science); CLIPS; Process (computing); Mathematics education; Information retrieval; Multimedia; World Wide Web; Artificial intelligence; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3174368",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3125700472",
      "doi": "10.1109/jbhi.2021.3054592",
      "title": "Machine Learning Models for Classification of Cushing's Syndrome Using Retrospective Data",
      "abstract": "Accurate classification of Cushing's Syndrome (CS) plays a critical role in providing the early and correct diagnosis of CS that may facilitate treatment and improve patient outcomes. Diagnosis of CS is a complex process, which requires careful and concurrent interpretation of signs and symptoms, multiple biochemical test results, and findings of medical imaging by physicians with a high degree of specialty and knowledge to make correct judgments. In this article, we explore the state of the art machine learning algorithms to demonstrate their potential as a clinical decision support system to analyze and classify CS to facilitate the diagnosis, prognosis, and treatment of CS. Prominent algorithms are compared using nested cross-validation and various class comparison strategies including multiclass, one vs. all, and one vs. one binary classification. Our findings show that Random Forest (RF) algorithm is most suitable for the classification of CS. We demonstrate that the proposed approach can classify CS with an average accuracy of 92% and an average F1 score of 91.5%, depending on the class comparison strategy and selected features. RF-based one vs. all binary classification model achieves sensitivity of 97.6%, precision of 91.1%, and specificity of 87.1% to discriminate CS from non-CS on the test dataset. RF-based multiclass classification model achieves average per class sensitivity of 91.8%, average per class specificity of 97.1%, and average per class precision of 92.1% to classify different subtypes of CS on the test dataset. Clinical performance evaluation suggests that the developed models can help improve physicians' judgment in diagnosing CS.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Senol Isci et al.",
      "keywords": "Artificial intelligence; Multiclass classification; Machine learning; Computer science; Random forest; Binary classification; Class (philosophy); Medical diagnosis; Sensitivity (control systems); Statistical classification; Binary number; Pattern recognition (psychology); Support vector machine; Medicine; Mathematics; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3054592",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380785307",
      "doi": "10.1109/access.2023.3286661",
      "title": "Automated Cardiovascular Disease Diagnosis Using Honey Badger Optimization With Modified Deep Learning Model",
      "abstract": "The leading cause of death among people around the world is cardiovascular disease (CVD). In order to prevent patients from other damages, precise diagnostics of CVD on time is a crucial factor. Researcher workers are inspired to apply machine learning (ML) for accurate and quick diagnosis of CVD. ML algorithm extracts patterns and hidden relationships in the medical dataset for detecting or predicting disease development. But the prediction of CVD is a challenging task. The increasing size of healthcare dataset has made it a complex task for practitioners to make disease predictions and understand the feature relations. And so, selection of crucial features in a dataset plays a key role in optimizing the performance of ML algorithm. This study develops an Automated Cardiovascular Disease Diagnosis using Honey Badger Optimization with Modified Deep Learning (ACVD-HBOMDL) Model. The major aim of the ACVD-HBOMDL technique lies in the classification of CVD using feature selection (FS) and hyperparameter tuning strategies. Initially, the ACVD-HBOMDL technique applies min-max scaler to preprocess the medical data. To elect an optimal subset of features, the HBO algorithm is used in this work. For CVD classification, deep learning modified neural network (DLMNN) classifier is used and its hyperparameters can be optimally chosen by Bayesian optimization. The experimental results of the ACVD-HBOMDL technique can be tested on benchmark medical dataset and the obtained results demonstrate the significant outcomes of the ACVD-HBOMDL technique over other existing techniques.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Marwa Obayya et al.",
      "keywords": "Hyperparameter; Machine learning; Computer science; Artificial intelligence; Feature selection; Classifier (UML); Deep learning; Artificial neural network; Benchmark (surveying); Task (project management); Pattern recognition (psychology); Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3286661",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3011175576",
      "doi": "10.1109/access.2020.2980292",
      "title": "Breast Benign and Malignant Tumors Rapidly Screening by ARFI-VTI Elastography and Random Decision Forests Based Classifier",
      "abstract": "Breast cancer is the most common cancer among women in Taiwan, and the number of breast cancer cases reported annually continues to increase. In 2018, breast cancer ranked fourth in terms of mortality. Early stages (stages 0-2) of malignant breast lesions can be diagnosed during regular screening, and early treatment via advanced medical therapies increases survival rates. Ultrasound imaging, including acoustic radiation force impulse (ARFI) imaging, is the first-line examination technique used to locate breast lesion tissue, which can then be quantitated by virtual touch tissue imaging (VTI). ARFI-VTI elastography is a breast imaging modality that creates two-dimensional (2D) images to visualize the texture details, elasticity, and morphological features of a region of interest (ROI). The 2D Harris corner convolution is applied during digital imaging to remove speckle noise and enhance the ARFI-VTI images for extrapolation of lesion tissue in a ROI. Then, 2D Harris corner convolution, maximum pooling, and random decision forests (RDF) are integrated into a machine vision classifier to screen subjects with benign or malignant tumors. A total of 320 ARFI-VTI images were collected for experiments. In training stages, 122 images were randomly selected to train the RDF-based classifiers and the remaining images were randomly selected for performance evaluation via cross-validation in recalling stages. In a 10-fold cross-validation, promising results with mean sensitivity, mean specificity, and mean accuracy of 86.02%, 87.63%, and 86.97%, respectively, are achieved for quantifying the performance of the proposed classifier. Breast tumors visualized on ARFI-VTI images can be used for rapid screening of malignant or benign lesions by using the proposed machine vision classifier.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jian\u2010Xing Wu et al.",
      "keywords": "Elastography; Breast cancer; Artificial intelligence; Random forest; Medicine; Breast imaging; Region of interest; Ultrasound; Radiology; Computer science; Mammography; Cancer; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2980292",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3086793563",
      "doi": "10.1109/access.2020.3020892",
      "title": "Retracted: Aided Image Acquisition System for Aerobics Training Based on Motion Recognition Technology",
      "abstract": "The image acquisition system is the main part of acquiring image information, and its performance largely determines the accuracy and difficulty of subsequent planning. The main purpose of this article is to design an image acquisition system for aerobics training based on motion recognition technology. This article mainly introduces the teaching experiments based on the design of aerobics courses. Through the empirical investigation and analysis of the impact of relevant experimental data on aviation training courses, attempts to establish the connection between aerobics social adaptability and various dimensions The cultivation of student's social adaptability. In this paper, the GMM algorithm is mainly used to distinguish the rest time when the action occurs, and the subsequent rest period is used as the basis for segmenting multiple events in the action sequence. Finally, the characteristics of the action coding mapping of each event are derived, and the support vector machine is used to complete the energy recognition process of the existence of a single energy. The experimental results of this paper show that the designed embedded image acquisition system has high integration and stability, the acquired image resolution is 640x480, and the wireless transmission rate is 5MbPs, which has wide application prospects.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Haiying Guo et al.",
      "keywords": "Computer science; Adaptability; Artificial intelligence; Event (particle physics); Process (computing); Data acquisition; Computer vision; Action (physics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3020892",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3203546474",
      "doi": "10.1109/tmi.2021.3089292",
      "title": "Guest Editorial Annotation-Efficient Deep Learning: The Holy Grail of Medical Imaging",
      "abstract": "Annotation-efficient deep learning refers to methods and practices that yield high-performance deep learning models without the use of massive carefully labeled training datasets. This paradigm has recently attracted attention from the medical imaging research community because (1) it is difficult to collect large, representative medical imaging datasets given the diversity of imaging protocols, imaging devices, and patient populations, (2) it is expensive to acquire accurate annotations from medical experts even for moderately sized medical imaging datasets, and (3) it is infeasible to adapt data-hungry deep learning models to detect and diagnose rare diseases whose low prevalence hinders data collection.",
      "year": "2021",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Nima Tajbakhsh et al.",
      "keywords": "Deep learning; Computer science; Annotation; Artificial intelligence; Medical imaging; Holy Grail; Machine learning; Data science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "editorial",
      "url": "https://doi.org/10.1109/tmi.2021.3089292",
      "cited_by_count": 35,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393638643",
      "doi": "10.1109/access.2024.3384359",
      "title": "PainMeter: Automatic Assessment of Pain Intensity Levels From Multiple Physiological Signals Using Machine Learning",
      "abstract": "Pain assessment traditionally relies on self-report, but it is subjective and influenced by various factors. To address this, there&#x2019;s a need for an affordable and scalable objective pain identification method. Current research suggests that pain has physiological markers beyond the brain, such as changes in cardiovascular activity and electrodermal responses. Utilizing these markers, real-time pain detection algorithms were developed using the BioVid Heat Pain dataset, consisting of 86 healthy individuals experiencing acute pain. Three physiological signals were collected (ECG, GSR, EMG). Various machine learning models were employed to lay the foundation for future advancements in creating sophisticated pain categorization algorithms. The goal is to develop a machine learning model capable of accurately classifying levels of pain experienced based solely on physiological signals. The proposed method produced an accuracy score of 87&#x0025; for binary classification and 52&#x0025; accuracy for multi-class classification, with the highest-performing machine learning model being Random Forests. These results suggest that the PainMeter can be deployed in field settings using wearable sensors, offering real-time, unbiased pain sensing and management capabilities.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Da\u2019ad Albahdal et al.",
      "keywords": "Computer science; Machine learning; Categorization; Artificial intelligence; Random forest; Wearable computer; Identification (biology); Pain assessment; Binary classification; Deep learning; Support vector machine; Field (mathematics); Scalability; Class (philosophy); Pain management; Medicine; Physical therapy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3384359",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3161462672",
      "doi": "10.1109/jsen.2021.3078336",
      "title": "Spatiotemporal Analysis by Deep Learning of Gait Signatures From Floor Sensors",
      "abstract": "The recognition of gait pattern variation is of high importance to various industrial and commercial applications, including security, sport, virtual reality, gaming, robotics, medical rehabilitation, mental illness diagnosis, space exploration, and others. The purpose of this paper is to study the nature of gait variability in more detail, by identifying gait intervals responsible for gait pattern variations in individuals, as well as between individuals, using cognitive demanding tasks. This work uses deep learning methods for sensor fusion of 116 plastic optical fiber (POF) distributed sensors for gait recognition. The floor sensor system captures spatiotemporal samples due to varying ground reaction force (GRF) in multiples of up to 4 uninterrupted steps on a continuous 2x1 m area. We demonstrate classifications of gait signatures, achieving up to 100% F1-score with Convolutional Neural Networks (CNN), in the context of gait recognition of 21 subjects, with imposters and clients. Classifications under cognitive load, induced by 4 different dual tasks, manifested lower F1-scores. Layer-Wise Relevance Propagation (LRP) methods are employed to decompose a trained neural network prediction to relevant standard events in the gait cycle, by generating a \u201cheat map\u201d over the input used for classification. This allows valuable insight into which parts of the gait spatiotemporal signal have the heaviest influence on the gait classification and consequently, which gait events, such as heel strike or toe-off, are mostly affected by cognitive load.",
      "year": "2021",
      "journal": "IEEE Sensors Journal",
      "authors": "Abdullah Alharthi et al.",
      "keywords": "Gait; Context (archaeology); Artificial intelligence; Computer science; Gait analysis; Cognition; Convolutional neural network; Pattern recognition (psychology); Machine learning; Physical medicine and rehabilitation; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2021.3078336",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3135723415",
      "doi": "10.1109/access.2021.3063028",
      "title": "Vision-Based Human Detection Techniques: A Descriptive Review",
      "abstract": "Cameras are being used everywhere for the safety and security of citizens in different countries. Using a machine to detect humans in a photo or a video frame is a very complicated and challenging task. Various techniques have been developed for this purpose, which mainly rely on Artificial Intelligence. This paper aims to provide a comprehensive review and analysis of the literatures from a descriptive perspective, which is its main differentiator from the existing survey papers in this area. Firstly, the vision-based human detection techniques and classifiers are elucidated in conjunction with the variants of feature extraction techniques. Secondly, various pros and cons of such techniques are discussed. Then, an investigation has been conducted and reported based on the state-of-the-art human detection descriptors (e.g. Log-Average Miss Rate and accuracy). Although techniques such as Viola-Jones and Speeded-Up Robust Features can detect objects in real-time and overcome Scale-Invariant Feature Transform (SIFT) limitations, they are still sensitive to illuminated conditions. Other techniques such as SIFT, Bag of Words, Orthogonal Moments, and Histogram of oriented Gradients provide other interesting benefits which include insensitivity to occlusion and clutters, simplicity, low-order element construction and invariance to illuminated conditions; nevertheless, they are computationally expensive and sensitive to image rotation. A meticulous review along similar lines revealed that the Deformable Part-based Model performs relatively better due to its ability to deal with particular pose variations and multiple views, occlusion handling (partial) and is application-free while its counterparts focus on only a single aspect. This article highlights and provides a brief description of each available data-sets for human detection research. Various use-cases of human detection systems are also elaborated. Finally, various conclusions are derived based on the conducted review followed by recommendations for future directions and possibilities to further improve the speed and accuracy of human detection systems.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Shahriar Shakir Sumit et al.",
      "keywords": "Computer science; Scale-invariant feature transform; Artificial intelligence; Histogram; Computer vision; Feature extraction; Pedestrian detection; Focus (optics); Pattern recognition (psychology); Histogram of oriented gradients; Biometrics; Machine learning; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3063028",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4327852040",
      "doi": "10.1109/tbcas.2023.3254453",
      "title": "A Multi-Site, Multi-Wavelength PPG Platform for Continuous Non-Invasive Health Monitoring in Hospital Settings",
      "abstract": "This article presents a novel PPG acquisition platform capable of synchronous multi-wavelength signal acquisition from two measurement locations with up to 4 independent wavelengths from each in parallel. The platform is fully configurable and operates at 1ksps, accommodating a wide variety of transmitters and detectors to serve as both a research tool for experimentation and a clinical tool for disease monitoring. The sensing probes presented in this work acquire 4 PPG channels from the wrist and 4 PPG channels from the fingertip, with wavelengths such that surrogates for pulse wave velocity and haematocrit can be extracted. For conventional PPG sensing, we have achieved the mean error of 4.08 \u00b1 3.72 bpm for heart-rate and a mean error of 1.54 \u00b1 1.04% for SpO <sub>2</sub> measurement, with the latter lying within the FDA limits for commercial pulse oximeters. We have further evaluated over 700 individual peak-to-peak time differences between wrist and fingertip signals, achieving a normalized weighted average PWV of 5.80 \u00b1 1.58 m/s, matching with values of PWV found for this age group in literature. Lastly, we introduced and computed a haematocrit ratio ( R<sub>hct</sub>) between the deep IR and deep red wavelength from the fingertip sensor, finding a significant difference between male and female values (median of 1.9 and 2.93 respectively) pointing to devices sensitivity to Hct.",
      "year": "2023",
      "journal": "IEEE Transactions on Biomedical Circuits and Systems",
      "authors": "Stefan Karolcik et al.",
      "keywords": "Photoplethysmogram; Wavelength; Pulse (music); Computer science; SIGNAL (programming language); Sensitivity (control systems); Biomedical engineering; Detector; Artificial intelligence; Real-time computing; Electronic engineering; Medicine; Physics; Engineering; Telecommunications; Optics; Wireless",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbcas.2023.3254453",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393864958",
      "doi": "10.1109/access.2024.3384496",
      "title": "Evaluation and Analysis of Large Language Models for Clinical Text Augmentation and Generation",
      "abstract": "A major challenge in deep learning (DL) model training is data scarcity. Data scarcity is commonly found in specific domains, such as clinical or low-resource languages, that are not vastly explored in AI research. In this paper, we investigate the generation capability of large language models such as Text-To-Text Transfer Transformer (T5) and Bidirectional and Auto-Regressive Transformers (BART) for Clinical Health-Aware Reasoning across Dimensions (CHARDAT) dataset by applying the ChatGPT augmentation technique. We employed ChatGPT to rephrase each instance of the training set into conceptually similar but semantically different samples and augmented them to the dataset. This study aims to investigate the utilization of large language models, ChatGPT in particular, for data augmentation to overcome the limited availability in the clinical domain. In addition to the ChatGPT augmentation, we applied other augmentation techniques, such as easy data augmentation (EDA) and an easier data augmentation (AEDA), to clinical data. ChatGPT comprehended the contextual significance of sentences within the dataset and successfully modified English terms but not clinical terms. The original CHARDAT datasets represent 52 health conditions across three clinical dimensions, i.e., Treatments, Risk Factors, and Preventions. We compared the outputs for different augmentation techniques and evaluated their relative performance. Additionally, we examined how these techniques perform with different pre-trained language models, assessing their sensitivity in various contexts. Despite the relatively small size of the CHARDAT dataset, our results demonstrated that augmentation methods like ChatGPT augmentation surpassed the efficiency of the previously employed back-translation augmentation. Specifically, our findings revealed that the BART model resulted in superior performance, achieving a rouge score of 52.35 for ROUGE-1, 41.59 for ROUGE-2, and 50.71 for ROUGE-L.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Atif Latif et al.",
      "keywords": "Computer science; Transformer; Language model; Artificial intelligence; Natural language processing; Machine learning; Training set",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3384496",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312445551",
      "doi": "10.1109/access.2022.3213676",
      "title": "Bi-LSTM-CRF Network for Clinical Event Extraction With Medical Knowledge Features",
      "abstract": "Extracting clinical event expressions and their types from clinical text is a fundamental task for many applications in clinical NLP. State-of-the-art systems need handcraft features and do not take into account the representation of the low-frequency words. To address these issues, a Bi-LSTM-CRF neural network architecture based on medical knowledge features is proposed. First, we employ convolutional neural networks (CNNs) to encode character-level information of a word and extract medical knowledge features from an open-source clinical knowledge system. Then, we concatenate character-level and word-level embedding and the medical knowledge features of words together, and feed them into bi-directional long short-term memory (Bi-LSTM) to build context information of each word. Finally, we jointly use a conditional random field (CRF) to decode labels for the whole sentence. We evaluate our model on two publicly available clinical datasets, namely THYME corpus and 2012 i2b2 dataset. Experimental results show that our model outperforms previous state-of-the-art systems with different methodologies, including machine learning-based methods, deep learning-based methods, and Bert-based methods.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Shunli Zhang et al.",
      "keywords": "Computer science; Conditional random field; Artificial intelligence; Word embedding; Natural language processing; Context (archaeology); Sentence; Deep learning; ENCODE; Convolutional neural network; Word (group theory); Recurrent neural network; Task (project management); Event (particle physics); Artificial neural network; Information extraction; Embedding",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3213676",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393305507",
      "doi": "10.1109/access.2024.3383140",
      "title": "Deep Learning and Artificial Intelligence in Action (2019\u20132023): A Review on Brain Stroke Detection, Diagnosis, and Intelligent Post-Stroke Rehabilitation Management",
      "abstract": "Brain stroke is a complicated disease that is one of the foremost reasons of long-term debility and mortality. Because of breakthroughs in Deep Learning (DL) and Artificial Intelligence (AI) which enable the automated detection and diagnosis of brain stroke as well as intelligently assisting post-brain stroke patients for rehabilitation, is more favorable than a manual diagnosis. Many publications on automated brain stroke detection, diagnosis, and robotic management using DL and AI approaches are now being published. This review provides a study of the detection, diagnosis of brain stroke and robotic management techniques of post-brain stroke rehabilitation from six different perspectives, namely, brain stroke datasets and modalities of brain stroke data collection, pre-processing approaches, DL-based detection and diagnosis of brain stroke, Al-based intelligent post brain stroke rehabilitation assistant, and performance measures. It also examines the conclusions and the consequences of the findings. There are also three ongoing research challenges in the fields of brain stroke detection and diagnosis, as well as post-brain stroke robotic treatment. For this investigation, 130 key papers from the Scopus, PubMed and Web of Science archives were chosen after a comprehensive screening method. This study gives a comprehensive overview of brain stroke detection and post-brain stroke robotic management strategies that may be useful to the scientist&#x2019;s community working in the field of automatic brain stroke detection and robotic rehabilitation management.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Jyotismita Chaki et al.",
      "keywords": "Stroke (engine); Rehabilitation; Action (physics); Computer science; Physical medicine and rehabilitation; Artificial intelligence; Machine learning; Medicine; Physical therapy; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3383140",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285255793",
      "doi": "10.1109/access.2022.3172319",
      "title": "Missing Value Imputation Designs and Methods of Nature-Inspired Metaheuristic Techniques: A Systematic Review",
      "abstract": "Missing values are highly undesirable in real-world datasets. The missing values should be&#13;\\nestimated and treated during the preprocessing stage. With the expansion of nature-inspired metaheuristic&#13;\\ntechniques, interest in missing value imputation (MVI) has increased. The main goal of this literature is to&#13;\\nidentify and review the existing research on missing value imputation (MVI) in terms of nature-inspired&#13;\\nmetaheuristic approaches, dataset designs, missingness mechanisms, and missing rates, as well as the most&#13;\\nused evaluation metrics between 2011 and 2021. This study ultimately gives insight into how the MVI plan&#13;\\ncan be incorporated into the experimental design. Using the systematic literature review (SLR) guidelines&#13;\\ndesigned by Kitchenham, this study utilizes renowned scienti c databases to retrieve and analyze all relevant&#13;\\narticles during the search process. A total of 48 related articles from 2011 to 2021 were selected to assess&#13;\\nthe review questions. This review indicated that the synthetic missing dataset is the most popular baseline&#13;\\ntest dataset to evaluate the effectiveness of the imputation strategy. The study revealed that missing at&#13;\\nrandom (MAR) is the most common proposed missing mechanism in the datasets. This review also indicated&#13;\\nthat the hybridizations of metaheuristics with clustering or neural networks are popular among researchers.&#13;\\nThe superior performance of the hybrid approaches is signi cantly attributed to the power of optimized&#13;\\nlearning in MVI models. In addition, perspectives, challenges, and opportunities in MVI are also addressed&#13;\\nin this literature. The outcome of this review serves as a toolkit for the researchers to develop effective MVI&#13;\\nmodels.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Po Chan Chiu et al.",
      "keywords": "Missing data; Imputation (statistics); Computer science; Data mining; Metaheuristic; Preprocessor; Data pre-processing; Machine learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3172319",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2903635323",
      "doi": "10.1109/access.2018.2885586",
      "title": "What Clinics are Expecting From Data Scientists? A Review on Data Oriented Studies Through Qualitative and Quantitative Approaches",
      "abstract": "Ensuring healthy lives and promoting well-being for all, at all ages, is one main objective for sustainable development proposed by the United Nations. The concept of connected health (CH) has been proposed to achieve that goal by connecting all the stakeholders through enabling Telehealth technologies. This paper has first presented an overview of the whole picture of CH along with the data collection process in CH. In the whole picture of CH, translational medicine (TM), as a rapidly growing discipline in biomedical research, aims to expedite the discovery of new diagnostic tools and treatments by using a multi-disciplinary and highly collaborative approach. It has been introduced to bridge the technique gap between the clinics and data scientists, particularly targeting on health related data analysis and evidence medicine. What clinicians are expecting and what researchers can offer will/should all be defined and clarified through TM. To further facilitate the communication between the clinicians and the researchers, electronic health records (EHRs) are often applied in place. This paper first reviews the evolution history of EHR and its current status and standards. Then a detailed and comprehensive discussion on data analysis techniques applied in TM through both quantitative and qualitative approaches is elaborated. We reveal that future work in TM should put an emphasis on data oriented qualitative analysis, using advanced techniques from the artificial intelligence domain to predict health risk, such as heart attacks and early stages of cancers. Multidisciplinary research in the Internet of Medical Things across health science, data science, and engineering will be the main challenge in TM.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Lina Xu et al.",
      "keywords": "Data science; Computer science; Domain (mathematical analysis); Multidisciplinary approach; Process (computing); Telehealth; Data collection; The Internet; Big data; Health care; Engineering ethics; Telemedicine; Engineering; World Wide Web; Political science; Data mining",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2018.2885586",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4292347933",
      "doi": "10.1109/access.2022.3199691",
      "title": "Toward Autonomous Vehicles and Machinery in Mill Yards of the Forest Industry: Technologies and Proposals for Autonomous Vehicle Operations",
      "abstract": "Publisher Copyright: \u00a9 2013 IEEE.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ahmed K. Abdelsalam et al.",
      "keywords": "Yard; Mill; Automation; Computer science; Risk analysis (engineering); Systems engineering; Manufacturing engineering; Engineering; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3199691",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4312818640",
      "doi": "10.1109/access.2022.3231884",
      "title": "Diagnosis of Depression Based on Four-Stream Model of Bi-LSTM and CNN From Audio and Text Information",
      "abstract": "Recent development trends in artificial intelligence applications have seen increasing interest in the design of automated systems for depression detection and diagnosis among the affective computing community. Particularly, active research has been conducted in depression diagnosis, based on multi-modal approaches in deep learning technology, which enable utilization of various information through fusion of varied data types. This study proposes a four-stream-based depression diagnosis model consisting of Bidirectional Long Short-Term Memory (Bi-LSTM) and convolutional neural networks (CNN), using speech and text data. One-dimensional features of audio signals are extracted using Mel Frequency Cepstral Coefficients and Gammatone Cepstral Coefficients, and two-dimensional features are extracted from Bark, equivalent rectangular bandwidth, and Log-Mel spectrograms, based on time-frequency transform. The extracted features are applied to Bi-LSTM and CNN-based transfer learning models. Word encoding was used for mapping of text to sequences with numeric indices, and word embedding used for representation of all words in numeric dense vectors. These were applied to Bi-LSTM and n-gram-based CNN models. Finally, an ensemble of the softmax values output from the four deep learning models was used to perform depression diagnosis, based on the proposed four-stream model. Using the proposed model, experiments were performed with the Extended Distress Analysis Interview Corpus Wizard of Oz depression database and other datasets. Experimental results showed improved performance by 10.7&#x0025; to 11.9&#x0025; over two-stream-based state-of-the-art methods. This demonstrates that the proposed model is effective for depression diagnosis.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "A-Hyeon Jo et al.",
      "keywords": "Computer science; Natural language processing; Artificial intelligence; Speech recognition; Depression (economics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3231884",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3202811270",
      "doi": "10.1109/access.2021.3115263",
      "title": "Cognitive and Affective Brain\u2013Computer Interfaces for Improving Learning Strategies and Enhancing Student Capabilities: A Systematic Literature Review",
      "abstract": "Brain&#x2013;computer interface (BCI) technology has the potential to positively contribute to the educational learning environment, which faces many challenges and shortcomings. Cognitive and affective BCIs can offer a deep understanding of brain mechanisms, which may improve learning strategies and increase brain-based skills. They can offer a better empirical foundation for teaching&#x2013;learning methodologies, including adjusting learning content based on brain workload, measuring student interest of a topic, or even helping students focus on specific tasks. The latest findings from emerging BCI technology, neuroscience, cognitive sciences, and psychology could be used in learning and teaching strategies to improve student abilities in education. This study investigates and analyzes the research on BCI patterns and its implementation for enhancing cognitive capabilities of students. The results showed that there is insufficient literature on BCI that addresses students with disabilities in the learning process. Further, our analysis revealed a bias toward the significance of cognitive process factors compared with other influential factors, such as the learning environment and emotions that influence learning. Finally, we concluded that BCI technology could improve students&#x2019; learning and cognitive skills&#x2014;when consistently associated with the different pedagogical teaching&#x2013;learning strategies&#x2014;for better academic achievement.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Nuraini Jamil et al.",
      "keywords": "Computer science; Cognition; Human\u2013computer interaction; Systematic review; Psychology; MEDLINE; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3115263",
      "cited_by_count": 63,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387885972",
      "doi": "10.1109/access.2023.3327091",
      "title": "A Fall Risk Assessment Model for Community-Dwelling Elderly Individuals Based on Gait Parameters",
      "abstract": "Assessing fall risk accurately is vital for the older adult population. However, existing fall risk assessments mainly depend on scales, which are inconvenient, subjective, and imprecise. The aim of this study was to explore a machine learning model based on gait parameters to evaluate the risk of falls in older adults living in the community over a one-year period. A total of 46 elderly subjects were recruited in this study. Information on demographics, disease history, and fall history was collected via questionnaire. Moreover, this study used a gait analysis system based on inertial measurement unit and Azure Kinect to acquire the spatiotemporal parameters of the subjects&#x2019; gait. Based on the above data, various machine learning models, including k-nearest neighbor, support vector machine, gradient boosting decision tree, and voting classifier, were built to estimate the fall risk level of elderly individuals. K-nearest neighbor performed best among all the models with an accuracy of 0.80 on the individual test set, an F1 score of 0.67, and an area under the receiver operating characteristic curve of 0.83. Gait frequency was found to be the most significant feature associated with fall risk, followed by body mass index and gait cycle variability. The findings suggest that the k-nearest neighbor model can provide a quantitative and objective evaluation of fall risk for older adults living in the community and that the evaluation is more accurate when both gait parameters and disease history are taken into account.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ke Zhang et al.",
      "keywords": "Decision tree; Gait; Artificial intelligence; Receiver operating characteristic; Support vector machine; Gait analysis; Machine learning; Physical medicine and rehabilitation; Decision tree learning; Gradient boosting; Population; Computer science; Medicine; Random forest",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3327091",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205326546",
      "doi": "10.1109/access.2021.3138167",
      "title": "E-Pilots: A System to Predict Hard Landing During the Approach Phase of Commercial Flights",
      "abstract": "More than half of all commercial aircraft operation accidents could have been prevented by executing a go-around. Making timely decision to execute a go-around manoeuvre can potentially reduce overall aviation industry accident rate. In this paper, we describe a cockpit-deployable machine learning system to support flight crew go-around decision-making based on the prediction of a hard landing event. This work presents a hybrid approach for hard landing prediction that uses features modelling temporal dependencies of aircraft variables as inputs to a neural network. Based on a large dataset of 58177 commercial flights, the results show that our approach has 85&#x0025; of average sensitivity with 74&#x0025; of average specificity at the go-around point. It follows that our approach is a cockpit-deployable recommendation system that outperforms existing approaches.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "D\u00e9bora Gil et al.",
      "keywords": "Cockpit; Crew; Computer science; Aviation; Artificial neural network; Sensitivity (control systems); Aeronautics; Event (particle physics); Point (geometry); Real-time computing; Simulation; Artificial intelligence; Aerospace engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3138167",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4287889731",
      "doi": "10.1109/access.2022.3193494",
      "title": "Learning and Assessing Optimal Dynamic Treatment Regimes Through Cooperative Imitation Learning",
      "abstract": "Dynamic Treatment Regimes (DTRs) are sets of sequential decision rules that can be adapted over time to treat patients with a specific pathology. DTR consists of alternative treatment paths and any of these treatments can be adapted depending on the patient's characteristics. Reinforcement Learning (RL) and Imitation Learning (IL) approaches have been deployed for obtaining optimal treatment for a patient but, these approaches rely only on positive trajectories (i.e., treatments that concluded with positive responses of the patient). In contrast, negative trajectories (i.e., samples of non-responding treatments) are discarded, although these have valuable information content. We propose a Cooperative Imitation Learning (CIL) method that exploits information from both negative and positive trajectories to learn the optimal DTR. The proposed method reduces the chance of selecting any treatment which results in a negative outcome (negative response of the patient) during the medical examination. To validate our approach, we have considered a well-known DTR which is defined for the treatment of patients with alcohol addiction. Results show that our approach outperforms those that rely only on positive trajectories.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Syed Ihtesham Hussain Shah et al.",
      "keywords": "Imitation; Computer science; Reinforcement learning; Outcome (game theory); Artificial intelligence; Exploit; Contrast (vision); Machine learning; Medical treatment; Psychology; Social psychology; Mathematics; Medicine; Intensive care medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3193494",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3111276288",
      "doi": "10.1109/access.2020.3045603",
      "title": "Respiratory Volume Monitoring: A Machine-Learning Approach to the Non-Invasive Prediction of Tidal Volume and Minute Ventilation",
      "abstract": "Continuous monitoring of ventilatory parameters such as tidal volume (TV) and minute ventilation (MV) has shown to be effective in the prevention of respiratory compromise events in hospitalized patients. However, the non-invasive estimation of respiratory volume in non-intubated patients remains an outstanding challenge. In this work, we present a novel approach to respiratory volume monitoring (RVM) that continuously predicts TV and MV in normal subjects. Respiratory flow in 19 volunteers under spontaneous breathing was recorded using respiratory inductance plethysmography and a temperature-based wearable sensor. Temperature signals were processed to identify features such as temperature amplitude and mean value, among others. The feature datasets were then used to train and validate three machine-learning (ML) algorithms for the prediction of respiratory volume based on temperature-related features. A model based on Random-Forest regression resulted in the lowest root mean-square error and was subsequently chosen to predict ventilatory parameters on subject test data not used in the construction of the model. Our predictions achieve a bias (mean error) in TV and MV of 16.04 mL and 0.19 L/min, respectively, which compare well with performance metrics reported in commercially-available RVM systems based on electrical impedance. Our results show that the combination of novel respiratory temperature sensors and machine-learning algorithms can deliver accurate and continuous estimates of TV and MV in healthy subjects.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Daniel E. Hurtado et al.",
      "keywords": "Tidal volume; Computer science; Respiratory minute volume; Ventilation (architecture); Mean squared error; Respiratory rate; Respiratory monitoring; Plethysmograph; Respiratory system; Wearable computer; Volume (thermodynamics); Artificial intelligence; Machine learning; Medicine; Statistics; Mathematics; Anesthesia; Engineering; Internal medicine; Heart rate",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3045603",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3043897777",
      "doi": "10.1109/tnsre.2020.3010625",
      "title": "Evaluating Reachable Workspace and User Control Over Prehensor Aperture for a Body-Powered Prosthesis",
      "abstract": "Using a shoulder harness and control cable, a person can control the opening and closing of a body-powered prosthesis prehensor. In many setups the cable does not pass adjacent to the shoulder joint center allowing shoulder flexion on the prosthetic side to be used for prehensor control. However, this makes cable setup a difficult compromise as prosthesis control is dependent on arm posture; too short and the space within which a person can reach may be unduly restricted, too long and the user may not be able to move their shoulder sufficiently to take up the inevitable slack at some postures and hence have no control over prehensor movement. Despite the fundamental importance of reachable workspace to users, to date there have been no studies in prosthetics on this aspect. Here, a methodology is presented to quantify the reduction in the reachable volume due to the harness, and to record the range-of-motion of the prehensor at a series of locations within the reachable workspace. Ten anatomically intact participants were assessed using a body-powered prosthesis simulator. Data was collected using a 3D motion capture system and an electronic goniometer. The harnessed reachable workspace was 38-85% the size of the unharnessed volume with participants struggling to reach across the body and above the head. Across all arm postures assessed, participants were only able to achieve full prehensor range-of-motion in 9%. The methodologies presented could be used to evaluate future designs of both body-powered and myoelectric prostheses.",
      "year": "2020",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Alix Chadwell et al.",
      "keywords": "Workspace; Prosthesis; Computer science; Control (management); Aperture (computer memory); Human\u2013computer interaction; Engineering; Artificial intelligence; Mechanical engineering; Robot",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2020.3010625",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2957188486",
      "doi": "10.1109/access.2019.2921568",
      "title": "Simultaneous Human Health Monitoring and Time-Frequency Sparse Representation Using EEG and ECG Signals",
      "abstract": "In the field of human health monitoring, intelligent diagnostic methods have drawn much attention recently to tackle the health problems and challenges faced by patients. In this paper, an efficient and flexible diagnostic method is proposed, which enables the simultaneous use of a machine learning method and sparsity-based representation technique. Specifically, the proposed method is based on a convolutional neural network (CNN) and generalized minimax-concave (GMC) method. First, measured potential signals, for instance, electroencephalogram (EEG) and electrocardiogram (ECG) signals are directly inputted into the designed network based on CNN for health conditions classification. The designed network adopts small convolution kernels to enhance the performance of feature extraction. In the training process, small batch samples are applied to improve the generalization of the model. Meanwhile, the &#x201C;Dropout&#x201D; strategy is applied to overcome the overfitting problem in fully connected layers. Then, for a record of the interested EEG or ECG signal, the sparse representation of useful time-frequency features can be estimated via the GMC method. Case studies of seizure detection and arrhythmia signal analysis are adopted to verify the performance of the proposed method. The experimental results demonstrate that the proposed method can effectively identify different health conditions and maximally enhance the sparsity of time-frequency features.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Wangpeng He et al.",
      "keywords": "Overfitting; Computer science; Artificial intelligence; Pattern recognition (psychology); Convolutional neural network; Sparse approximation; Feature extraction; Electroencephalography; Representation (politics); Feature (linguistics); Generalization; Feature learning; Convolution (computer science); Machine learning; Speech recognition; Artificial neural network; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2921568",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3100894039",
      "doi": "10.1109/access.2020.3037086",
      "title": "Relation Extraction for Chinese Clinical Records Using Multi-View Graph Learning",
      "abstract": "Relation extraction is a necessary step in obtaining information from clinical medical records. In the medical domain, there have been several studies on relation extraction in modern medicine clinical notes written in English. However, very limited relation extraction research has been conducted on clinical notes written in Chinese, especially traditional Chinese medicine (TCM) clinical records (e.g., herb-symptom, herb-disease). Instead of independently extracting each relation from a single sentence or text, we propose to globally and reasonably extract multiple types of relations from the Chines clinical records with a novel heterogeneous graph representation learning method. Specifically, we first construct multiple view medical entity graphs based on the co-occurring relations, knowledge obtained from the clinic, and domain texts with the corresponding information of two medical entities from the Chinese clinical records, in which each edge is a candidate relation; we then build a Graph Convolutional Network (GCN)-based representation learning with the attention mechanism to simultaneously infer the existence of all the edges via classification. The experimental data were obtained from the Chinese medical records and literature provided by previous work. The main experimental results on Chinese clinical records show that our proposed model's precision, recall, and F1-score reach 10.2%, 13.5%, 12.6%, demonstrating significant improvements over state-of-the-art.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Chunyang Ruan et al.",
      "keywords": "Relationship extraction; Computer science; Sentence; Graph; Relation (database); Natural language processing; Medical record; Artificial intelligence; Convolutional neural network; Information extraction; Information retrieval; Data mining; Theoretical computer science; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3037086",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3197849793",
      "doi": "10.1109/access.2021.3110773",
      "title": "A Systematic Review of Sensing and Differentiating Dichotomous Emotional States Using Audio-Visual Stimuli",
      "abstract": "Recognition of dichotomous emotional states such as happy and sad play important roles in many aspects of human life. Existing literature has recorded diverse attempts in extracting physiological and non-physiological traits to record these emotional states. Selection of the right instrumental approach for measuring these traits plays a critical role in emotion recognition. Moreover, various stimuli have been used to induce emotions. Therefore, there is a current need to perform a comprehensive overview of instrumental approaches and their outcomes for the new generation of researchers. In this direction, this study surveys the instrumental approaches in discriminating happy and sad emotional states that are elicited using audio-visual stimuli. A comprehensive literature review is performed using PubMed, Scopus, and ACM digital library repositories. The reviewed articles are classified with respect to the i) stimulation modality, ii) acquisition protocol, iii) instrumentation approaches, iv) feature extraction, and v) classification methods. In total, 39 research articles were published on the selected topic of instrumental approaches in differentiating dichotomous emotional states using audio-visual stimuli between January 2011 and April 2021. The majority of the papers used physiological traits, namely electrocardiogram, electrodermal activity, heart rate variability, photoplethysmogram, and electroencephalogram based instrumental approaches for recognizing the emotional states. The results show that only a few articles have focused on audio-visual stimuli for the elicitation of happy and sad emotional states. This review is expected to seed research in the areas of standardization of protocols, enhancing the diagnostic relevance of these instruments, and extraction of more reliable biomarkers.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Yedukondala Rao Veeranki et al.",
      "keywords": "Cognitive psychology; Relevance (law); Scopus; Psychology; Data extraction; Computer science; Psychophysiology; MEDLINE",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3110773",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4377966829",
      "doi": "10.1109/access.2023.3279735",
      "title": "Handwritten Digits Recognition From sEMG: Electrodes Location and Feature Selection",
      "abstract": "Objective: Despite hand gesture recognition is a widely investigated field, the design of myoelectric architectures for detecting finer motor task, like the handwriting, is less studied. However, writing tasks involving cognitive loads represent an important aspect toward the generalization of myoelectric-based human-machine interfaces (HMI), and also for many rehabilitative tasks. In this study, the handwriting recognition of the ten digits was faced under the myoelectric control perspective, considering the probes setup and the feature extraction step. Methods: Time and frequency domain features were extracted from surface electromyography (sEMG) signals of 11 subjects who wrote the ten digits following a standardized template and 8 sEMG probes were equally distributed between forearm and wrist. Feature class separability was investigated and an aggregated feature set was built to train pattern recognition architectures, i.e. linear discriminant analysis (LDA) and quadratic support vector machine (QSVM). Also, four reduced probes setups were investigated. Results: LDA and QSVM showed mean accuracy of about 97%, with all the forearm and wrist sEMG information. A significant reduction of performances was observed considering the wrist or the forearm only (\u226492%) and when LDA and QSVM were trained with two electrodes information (\u226490%). Conclusions: For the reliable classification performances in a motor task involving high cognitive demands, like the handwriting, it is required the use of probes fully covering forearm and wrist. Outcomes support the methodological transfer from myoelectric hand gesture to the handwriting recognition, which represents a key aspect in the development of new HMI for rehabilitation tasks.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Andrea Tigrini et al.",
      "keywords": "Linear discriminant analysis; Feature extraction; Handwriting; Pattern recognition (psychology); Computer science; Speech recognition; Artificial intelligence; Feature selection; Feature (linguistics); Discriminant",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3279735",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3114052947",
      "doi": "10.1109/access.2020.3046190",
      "title": "Benchmarking Small-Dataset Structure-Activity-Relationship Models for Prediction of Wnt Signaling Inhibition",
      "abstract": "Quantitative structure-activity relationship (QSAR) models based on machine learning algorithms are powerful tools to expedite drug discovery processes and therapeutics development. Given the cost in acquiring large-sized training datasets, it is useful to examine if QSAR analysis can reasonably predict drug activity with only a small-sized dataset (size < 100) and benchmark these small-dataset QSAR models in application-specific studies. To this end, here we present a systematic benchmarking study on small-dataset QSAR models built for prediction of effective Wnt signaling inhibitors, which are essential to therapeutics development in prevalent human diseases (e.g., cancer). Specifically, we examined a total of 72 two-dimensional (2D) QSAR models based on 4 best-performing algorithms, 6 commonly used molecular fingerprints, and 3 typical fingerprint lengths. We trained these models using a training dataset (56 compounds), benchmarked their performance on 4 figures-of-merit (FOMs), and examined their prediction accuracy using an external validation dataset (14 compounds). Our data show that the model performance is maximized when: 1) molecular fingerprints are selected to provide sufficient, unique, and not overly detailed representations of the chemical structures of drug compounds; 2) algorithms are selected to reduce the number of false predictions due to class imbalance in the dataset; and 3) models are selected to reach balanced performance on all 4 FOMs. These results may provide general guidelines in developing high-performance small-dataset QSAR models for drug activity prediction.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mahtab Kokabi et al.",
      "keywords": "Quantitative structure\u2013activity relationship; Benchmarking; Computer science; Benchmark (surveying); Machine learning; Predictive modelling; Artificial intelligence; Drug discovery; Data mining; Bioinformatics; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3046190",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394564234",
      "doi": "10.1109/access.2024.3386220",
      "title": "An Improved Concatenation of Deep Learning Models for Predicting and Interpreting Ischemic Stroke",
      "abstract": "Early detection of stroke warning symptoms can help reduce the severity of ischemic stroke, the leading cause of mortality and disability worldwide. This study aims to develop a model to predict the disease by leveraging machine learning-based models. A model that concatenates a convolutional neural network and a long short-term memory was developed as the proposed model. Seven other classifiers were treated as the baseline models: logistic regression, random forest, extreme gradient boosting, k-nearest neighbor, artificial neural network, long short-term memory, and convolutional neural network. All models were trained using a healthcare dataset of 5110 patients&#x2019; health profiles. A synthetic minority oversampling technique was deployed to balance the data. Metrics such as accuracy, precision, F1-score, recall, area under the curve, and confusion metrics were used to evaluate the models&#x2019; performance. With a 95.9% accuracy, the proposed model outperformed the models employed in this study and improved the accuracy of prior studies that used the same dataset. The Shapley Additive Explanations method was applied to explain the result obtained by the best model. The proposed model was created to predict ischemic stroke. It considers each patient&#x2019;s profile, allowing for personalized decision-making in resource-constrained settings.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Sapiah Sakri et al.",
      "keywords": "Concatenation (mathematics); Computer science; Artificial intelligence; Deep learning; Machine learning; Mathematics; Arithmetic",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3386220",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366083992",
      "doi": "10.1109/jbhi.2023.3267521",
      "title": "Real-Time Prediction for Neonatal Endotracheal Intubation Using Multimodal Transformer Network",
      "abstract": "Neonates admitted to neonatal intensive care units (NICUs) are at risk for respiratory decompensation and may require endotracheal intubation. Delayed intubation is associated with increased morbidity and mortality, particularly in urgent unplanned intubation. By accurately predicting the need for intubation in real-time, additional time can be made available for preparation, thereby increasing the safety margins by avoiding high-risk late intubation. In this study, the probability of intubation in neonatal patients with respiratory problems was predicted using a deep neural network. A multimodal transformer model was developed to simultaneously analyze time-series data (1-3 h of vital signs and Fi[Formula: see text] setting value) and numeric data including initial clinical information. Over a dataset including information of 128 neonatal patients who underwent noninvasive ventilation, the proposed model successfully predicted the need for intubation 3 h in advance (area under the receiver operator characteristic curve = 0.880 \u00b1 0.051, F1-score = 0.864 \u00b1 0.031, sensitivity = 0.886 \u00b1 0.041, specificity = 0.849 \u00b1 0.035, and accuracy = 0.857 \u00b1 0.032). Moreover, the proposed model showed high generalization ability by achieving AUROC 0.890, F1-score 0.893, specificity 0.871, sensitivity 0.745, and accuracy 0.864 with an additional 91 dataset for testing.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Jueng-Eun Im et al.",
      "keywords": "Endotracheal intubation; Computer science; Intubation; Medicine; Anesthesia",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3267521",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2912754914",
      "doi": "10.1109/access.2019.2897217",
      "title": "Analyzing Objective and Subjective Data in Social Sciences: Implications for Smart Cities",
      "abstract": "The ease of deployment of digital technologies and the Internet of Things gives us the opportunity to carry out large-scale social studies and to collect vast amounts of data from our cities. In this paper, we investigate a novel way of analyzing data from social sciences studies by employing machine learning and data science techniques. This enables us to maximize the insight gained from this type of studies by fusing both objective (sensor information) and subjective data (direct input from the users). The pilot study is concerned with better understanding the interactions between citizens and urban green spaces. A field experiment was carried out in Sheffield, U.K., involving 1870 participants for two different time periods (7 and 30 days). With the help of a smartphone app, both objective and subjective data were collected. Location tracking was recorded as people entered any of the publicly accessible green spaces. This was complemented by textual and photographic information that users could insert spontaneously or when prompted (when entering a green space). By employing data science and machine learning techniques, we identify the main features observed by the citizens through both text and images. Furthermore, we analyze the time spent by people in parks as well as the top interaction areas. This paper allows us to gain an overview of certain patterns and the behavior of the citizens within their surroundings and it proves the capabilities of integrating technology into large-scale social studies.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Laura Erhan et al.",
      "keywords": "Computer science; Data science; Field (mathematics); Software deployment; Scale (ratio); Tracking (education); Citizen science; Space (punctuation); Social media; Location tracking; The Internet; World Wide Web; Human\u2013computer interaction; Multimedia; Internet privacy; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2897217",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393405243",
      "doi": "10.1109/access.2024.3383847",
      "title": "Open-Loop Neuroadaptive System for Enhancing Student\u2019s Cognitive Abilities in Learning",
      "abstract": "Neuroeducation seeks to implement knowledge about neural mechanisms of learning into educational practice and to understand the impact of learning itself. The crucial tasks in this field are to evaluate and to enhance cognitive abilities, that are used in monitoring educational performance, but also known to greatly impact learning process. Contemporary neuroscience achieved significant progress in measuring brain cognitive abilities through mental state assessment. Popular approach to this task based on brain-computer interface can be difficult to implement in the context of education, but general concept of neuroadaptation is still plausible. In this study, we propose open-loop neuroadaptive system for enhancing student&#x2019;s cognitive abilities in learning. Assessment of cognitive abilities is based on the concept of executive functions. We design EEG study with special tests and use combined analysis of behavioral and brain activity to assess the level of development of cognitive abilities. Feedback in this system is implemented in the form of recommendations aimed to develop and enhance underdeveloped cognitive abilities and skills. Recommendations have form of various types of extracurricular activities and are based on extensive literature search. This is the system with open-loop adaptation, as it can assess cognitive abilities, provide feedback aimed to enhance these abilities and then after a period of time it can assess cognitive abilities again as a part of the next loop. We believe that developed neuroadaptive system has a potential to be used in educational institutes.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Vadim Grubov et al.",
      "keywords": "Computer science; Cognitive systems; Cognition; Artificial intelligence; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3383847",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3210566337",
      "doi": "10.1109/access.2021.3123297",
      "title": "A Feasible Fall Evaluation System via Artificial Intelligence Gesture Detection of Gait and Balance for Sub-Healthy Community- Dwelling Older Adults in Taiwan",
      "abstract": "In Taiwan, falls are one of the major causes of permanent disability and seeking medical care in older adults. One in seven people in the Taiwanese population exceeds the age of 65 years, and there are roughly 4 million community-dwelling older adults. One in six older adults have fallen or been diagnosed with Sarcopenia, which can lead to a loss of mobility. The major identified risk factors are impaired balance and gait. Implementing an early-stage prevention system is already an urgent requirement. The primary objective of this study is to propose an artificial intelligence (AI) Internet of Things (IoT) program and to develop an easy-access fall prevention system. This study took the criteria of the Asian Working Group for Sarcopenia (AWGS) and implemented it in field practice. Field experts reviewed data from the combination of gait parameters and gesture parameters and adaptively modified the training course bi-weekly. With 3 months of field practice and intervention, sub-healthy older adults&#x2019; average increase in gait speed was 29.83&#x0025; for male participants and 34.06&#x0025; for female participants. The results of this study demonstrate that rehabilitation of older adults can significantly improve mobility. This helps to understand the relationship of gait and gesture patterns to walking stability and strategies and adaptive interventions that could be taught in expertise programs to minimize the risk of fall.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Kai-Chih Lin et al.",
      "keywords": "Fall prevention; Gait; Balance (ability); Sarcopenia; Population; Physical medicine and rehabilitation; Psychological intervention; Rehabilitation; Medicine; Intervention (counseling); Gerontology; Physical therapy; Computer science; Injury prevention; Poison control; Medical emergency; Nursing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3123297",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285140660",
      "doi": "10.1109/thms.2022.3176212",
      "title": "A Neural-Inspired Architecture for EEG-Based Auditory Attention Detection",
      "abstract": "10.1109/THMS.2022.3176212",
      "year": "2022",
      "journal": "IEEE Transactions on Human-Machine Systems",
      "authors": "Siqi Cai et al.",
      "keywords": "Computer science; Brain\u2013computer interface; Convolutional neural network; Artificial intelligence; Artificial neural network; Neural coding; Latency (audio); Electroencephalography; Coding (social sciences); Pattern recognition (psychology); Speech recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/thms.2022.3176212",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2989750099",
      "doi": "10.1109/access.2019.2954707",
      "title": "Feature Selection and Rule Generation Integrated Learning for Takagi-Sugeno-Kang Fuzzy System and its Application in Medical Data Classification",
      "abstract": "The rule-based fuzzy systems have successfully applied for numerous medical data classification problems. However, structuring the concise and interpretable fuzzy rules with good classification performance is still a big challenge. To address this issue, a novel feature selection and rule generation integrated learning for Takagi-Sugeno-Kang fuzzy system (called FSRG-IL-TSK) in this paper. FSRG-IL-TSK represents feature selection, structure identification and parameter learning into a Bayesian model, and uses the sequential importance resampling (SIR) algorithm to obtain the optimal parameters simultaneously, including the optimal features for each fuzzy rule, number of rules, and antecedent/consequent parameter of rules. Due to an integrated learning mechanism, it can select a small set of useful features and obtain a small number of rules. The effectiveness and advantages of FSRG-IL-TSK are validated experimentally on real-world medical data classification tasks.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Xiaoqing Gu et al.",
      "keywords": "Fuzzy rule; Computer science; Feature selection; Artificial intelligence; Data mining; Machine learning; Feature (linguistics); Fuzzy logic; Fuzzy classification; Fuzzy control system; Selection (genetic algorithm); Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2954707",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390660407",
      "doi": "10.1109/access.2024.3351570",
      "title": "A Noise-Robust Heart Sound Segmentation Algorithm Based on Shannon Energy",
      "abstract": "Heart sound segmentation has been shown to improve the performance of artificial intelligence (AI)-based auscultation decision support systems increasingly viewed as a solution to compensate for eroding auscultatory skills and the associated subjectivity. Various segmentation approaches with demonstrated performance can be utilized for this task, but their robustness can suffer in the presence of noise. A noise-robust heart sound segmentation algorithm was developed and its accuracy was tested using two datasets: the CirCor DigiScope Phonocardiogram dataset and an in-house dataset - a heart murmur library collected at the Children's National Hospital (CNH). On the CirCor dataset, our segmentation algorithm marked the boundaries of the primary heart sounds S1 and S2 with an accuracy of 0.28 ms and 0.29 ms, respectively, and correctly identified the actual positive segments with a sensitivity of 97.44%. The algorithm also executed four times faster than a logistic regression hidden semi-Markov model. On the CNH dataset, the algorithm succeeded in 87.4% cases, achieving a 6% increase in segmentation success rate demonstrated by our original Shannon energy-based algorithm. Accurate heart sound segmentation is critical to supporting and accelerating AI research in cardiovascular diseases. The proposed algorithm increases the robustness of heart sound segmentation to noise and viability for clinical use.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Youness Arjoune et al.",
      "keywords": "Computer science; Noise (video); Sound (geography); Algorithm; Energy (signal processing); Speech recognition; Artificial intelligence; Acoustics; Mathematics; Statistics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3351570",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388936634",
      "doi": "10.1109/access.2023.3336424",
      "title": "New Hybrid Deep Learning Models to Predict Cost From Healthcare Providers in Smart Hospitals",
      "abstract": "Accurate cost prediction of healthcare resources is challenging as diverse factors affect the overall prediction. The cost of healthcare providers is increasing exponentially as different healthcare providers charge differently for the same service due to various factors, majorly the sky rocketing inflation and increased population. It increases the importance of predicting healthcare costs to avoid unpleasant surprises. This study aims to provide the expected cost of healthcare providers that helps the patients in resource allocation and strengthens decision-making according to their resources. This paper proposes three hybrid Deep Learning (DL) models, Visual Geometry Group and Stacked Autoencoder (VGG-SAE), Visual Geometry Group and Deep Neural Network (VGG-DNN), and Stacked Autoencoder and Deep Neural Network (SAE-DNN), which optimize learning the hidden patterns from the given data more efficiently than individual models. The three hybrid DL models estimate the cost of healthcare providers effectively. The preprocessing is performed using the mode imputation for handling the missing values, Z-score for removing the outliers and standard scaler for standardizing the data. To train the hybrid models on optimum parameters, the Random Search technique is used that provides the best hyper-parameters of each hybrid model. The interpretation of the hybrid models&#x2019; output is achieved using the SHapley Additive ExPlanations (SHAP) technique. The performances of VGG-SAE, VGG-DNN, and SAE-DNN are compared with the baseline DL models such as SAE, DNN, and VGG. To assess the robustness of the proposed approach, the hybrid models are trained on two different datasets of healthcare such as Healthcare Providers and Hospital Inpatient Cost Transparency. With the hyper-parameter tuning of the Healthcare Providers Dataset, VGG-SAE achieved MSE of 0.01, RMSE of 0.13, MAE of 0.02, and R-squared of 0.98. VGG-DNN achieved MSE of 0.01, RMSE of 0.12, MAE of 0.02, and R-squared of 0.99. SAE-DNN achieved MSE of 0.01, RMSE of 0.11, MAE of 0.02, and R-squared of 0.99. With the hyper-parameter tuning of the Hospital Inpatient Cost Transparency Dataset, VGG-SAE achieved MSE of 0.007, RMSE of 0.08, MAE of 0.03, R-squared of 0.99, and execution time of 1680 seconds. VGG-DNN achieved MSE of 0.0006, RMSE of 0.08, MAE of 0.03, R-squared of 0.99, and execution time of 645 seconds. SAE-DNN achieved MSE of 0.003, RMSE of 0.06, MAE of 0.02, R-squared of 0.99, and execution time of 850 seconds. Our proposed hybrid combinations outperformed other deep models and Machine Learning (ML) techniques such as SAE, DNN, VGG, SVR and GBR, which ensures high efficiency of the proposed models in terms of healthcare providers cost.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Muhammad Hamza Bhatti et al.",
      "keywords": "Computer science; Health care; Deep learning; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3336424",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2958924538",
      "doi": "10.1109/tbme.2019.2927709",
      "title": "A Time-Frequency Approach for Cerebral Embolic Load Monitoring",
      "abstract": "Using only single-channel, single-frequency Doppler ultrasound, the proposed method enables sensitive detection and segmentation of embolic signatures. Our approach paves the way toward accurate real-time cerebral emboli monitoring.",
      "year": "2019",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Syed M. Imaduddin et al.",
      "keywords": "Medicine; Cardiology; Internal medicine; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2019.2927709",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2965119433",
      "doi": "10.1109/access.2019.2932101",
      "title": "Physiological Function Assessment Based on Kinect V2",
      "abstract": "This paper presented a framework based on fog computing for convenient and efficient Physiological Function Assessment, which consists of three parts: 1)measuring the degree of joint mobility; 2) investigating the abnormality of actions of upper limbs; and 3) abnormal gait detection for lower limbs. Especially, we introduced semi-automatic Rapid Upper Limb Assessment (RULA) using Kinect v2 for the upper limb motion evaluation. Since a specific action can be described by action sequences of different length, we used dynamic time warping (DTW) to find the similarity between action sequences with different length. Traditional DTW algorithm does not work well when the action sequences are long and complex. To address this problem, we improved the DTW method by modifying the mapping relationship and limiting the computation space. Our modified DTW algorithm was evaluated on a standard 3D action dataset (SYSU 3D HOI) and Human Upper Action dataset (HUA), achieving the accuracy of 83.75%, 89.50%, respectively. The result is significantly better than the traditional DTW and the reported methods. In our previous work, we described the framework and how to make physiological function assessment. The goal of this paper is to 1) enrich the experiments of previous work and 2) introduce the framework of using RULA for physiological function assessment. All the tests have been done in this framework based on fog computing.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Wenming Cao et al.",
      "keywords": "Dynamic time warping; Computer science; Function (biology); Action (physics); Computation; Artificial intelligence; Limiting; Similarity (geometry); Pattern recognition (psychology); Computer vision; Algorithm; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2932101",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4210306204",
      "doi": "10.1109/access.2022.3146008",
      "title": "A Comprehensive Literature Review on Children\u2019s Databases for Machine Learning Applications",
      "abstract": "The COVID-19 pandemic can be attributed as a main factor to accelerate the current digital transformation and to encourage innovation and technological adoption. Consequently, the care provided to our children, one of the significant aspects of life, needs to be adapted with the life&#x2019;s changes. Children are our future and our most precious resources. They need our attention in all life domains including health, education, safety and social interaction. Nowadays, technologies have been incorporated with machine learning and it has been proven that they are more powerful, reliable and profitable. Machine learning methods have been applied by many children-related studies to generate predictive models for different applications. The efficacy of the generated models mainly relies on the constructed databases. This article carries out a comprehensive survey on available children&#x2019;s databases constructed for machine-learning-based solutions with their methodologies, characteristics, challenges, and applications. First, it provides an overview of the available studies and classifies them based on their applications. Next, it defines a set of attributes and evaluates them while also shedding light on their pros and cons. The primary concerns related to collection, development and distribution of children&#x2019;s databases are also discussed. This study can be considered as a guideline for researchers in multidisciplinary fields to construct reliable databases and to develop more advanced techniques.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Sadam Al-Azani et al.",
      "keywords": "Computer science; Construct (python library); Multidisciplinary approach; Set (abstract data type); Data science; Machine learning; Artificial intelligence; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3146008",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391305419",
      "doi": "10.1109/ojemb.2023.3347479",
      "title": "Optimized Clinical Feature Analysis for Improved Cardiovascular Disease Risk Screening",
      "abstract": "<i>Objective:</i> To develop a clinical decision support tool that can predict cardiovascular disease (CVD) risk with high accuracy while requiring minimal clinical feature input, thus reducing the time and effort required by clinicians to manually enter data prior to obtaining patient risk assessment. <i>Results:</i> In this study, we propose a robust feature selection approach that identifies five key features strongly associated with CVD risk, which have been found to be consistent across various models. The machine learning model developed using this optimized feature set achieved state-of-the-art results, with an AUROC of 91.30%, sensitivity of 89.01%, and specificity of 85.39%. Furthermore, the insights obtained from explainable artificial intelligence techniques enable medical practitioners to offer personalized interventions by prioritizing patient-specific high-risk factors. <i>Conclusion:</i> Our work illustrates a robust approach to patient risk prediction which minimizes clinical feature requirements while also generating patient-specific insights to facilitate shared decision-making between clinicians and patients.",
      "year": "2024",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Sofiya Vyshnya et al.",
      "keywords": "Feature selection; Computer science; Feature (linguistics); Machine learning; Artificial intelligence; Disease; Set (abstract data type); Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2023.3347479",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3034471254",
      "doi": "10.1109/access.2020.3002075",
      "title": "Just Find It: The Mymo Approach to Recommend Running Shoes",
      "abstract": "Wearing inappropriate running shoes may lead to unnecessary injury through continued strain upon the lower extremities; potentially damaging a runner's performance. Many technologies have been developed for accurate shoe recommendation, which centre on running gait analysis. However, these often require supervised use in the laboratory/shop or exhibit too high a cost for personal use. This work addresses the need for a deployable, inexpensive product with the ability to accurately assess running shoe-type recommendation. This was achieved through quantitative analysis of the running gait from 203 individuals through use of a tri-axial accelerometer and tri-axial gyroscope-based wearable (Mymo). In combination with a custom neural network to provide the shoe-type classifications running within the cloud, we experience an accuracy of 94.6% in classifying the correct type of shoe across unseen test data.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Fraser Young et al.",
      "keywords": "Accelerometer; Computer science; Gyroscope; Gait; Gait analysis; Wearable computer; Wearable technology; Artificial intelligence; Work (physics); Artificial neural network; Machine learning; Simulation; Physical medicine and rehabilitation; Embedded system; Engineering; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3002075",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4379805195",
      "doi": "10.1109/access.2023.3283982",
      "title": "A Survey on Artificial Intelligence-Based Acoustic Source Identification",
      "abstract": "The concept of Acoustic Source Identification (ASI), which refers to the process of identifying noise sources has attracted increasing attention in recent years. The ASI technology can be used for surveillance, monitoring, and maintenance applications in a wide range of sectors, such as defence, manufacturing, healthcare, and agriculture. Acoustic signature analysis and pattern recognition remain the core technologies for noise source identification. Manual identification of acoustic signatures, however, has become increasingly challenging as dataset sizes grow. As a result, the use of Artificial Intelligence (AI) techniques for identifying noise sources has become increasingly relevant and useful. In this paper, we provide a comprehensive review of AI-based acoustic source identification techniques. We analyze the strengths and weaknesses of AI-based ASI processes and associated methods proposed by researchers in the literature. Additionally, we did a detailed survey of ASI applications in machinery, underwater applications, environment/event source recognition, healthcare, and other fields. We also highlight relevant research directions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ruba Zaheer et al.",
      "keywords": "Identification (biology); Computer science; Noise (video); Data science; Process (computing); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3283982",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3129293921",
      "doi": "10.1109/tbme.2021.3061998",
      "title": "A Multifactorial Model of Multiple Sclerosis Gait and Its Changes Across Different Disability Levels",
      "abstract": "The new model, built with metrics that represent gait impairment in pwMS, highlighted clinically relevant changes across different disability levels, including those with no clinically observable walking disability. This shows the clear potential as a monitoring biomarker in pwMS.",
      "year": "2021",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Lorenza Angelini et al.",
      "keywords": "Gait; Physical medicine and rehabilitation; Multiple sclerosis; Gait analysis; Medicine; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2021.3061998",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2995127995",
      "doi": "10.1109/access.2019.2960037",
      "title": "Bioinformatics Methodologies to Identify Interactions Between Type 2 Diabetes and Neurological Comorbidities",
      "abstract": "Type 2 diabetes (T2D) is a chronic metabolic disorder characterised by high blood sugar and insulin insensitivity which greatly increases the risk of developing neurological diseases (NDs). The co-existence of T2D and comorbidities such as NDs can complicate or even cause the failure of standard treatments for those diseases. Comorbidities can be both causally linked and influence each other's development through genetic, molecular, environmental or lifestyle-based risk factors that they share. For T2D and NDs, such underlying common molecular mechanisms remain elusive but large amounts of molecular data accumulated on these diseases enable analytical approaches to identify their interconnected pathways. Here, we propose a framework to explore possible comorbidity interactions between a pair of diseases using a bioinformatic examination of the cellular pathways involved and explore this framework for T2D and NDs with analyses of a large number of publicly available gene expression datasets from tissues affected by these diseases. We designed a bioinformatics pipeline to analyse, utilize and combine gene expression, Gene Ontology (GO) and molecular pathway data by incorporating Gene Set Enrichment Analysis and Semantic Similarity. Our bioinformatics methodology was implemented in R, available at https://github.com/HabibUCAS/T2D_Comorbidity. We identified genes with altered expression shared by T2D and NDs as well as GOs and molecular pathways these diseases share. We also computed the proximity between T2D and neurological pathologies using these genes and GO term semantic similarity. Thus, our method has generated new insights into disease mechanisms important for both T2D and NDs that may mediate their interaction. Our bioinformatics pipeline could be applied to other co-morbidities to identify possible interactions and causal relationships between them.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Md Habibur Rahman et al.",
      "keywords": "Comorbidity; Computational biology; Type 2 diabetes; Bioinformatics; Computer science; Gene; Disease; Gene ontology; Diabetes mellitus; Gene expression; Medicine; Biology; Genetics; Internal medicine; Endocrinology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2960037",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3109945530",
      "doi": "10.1109/jsen.2020.3041023",
      "title": "A Systematic Review of Sensor-Based Methodologies for Food Portion Size Estimation",
      "abstract": "Food portion size estimation (FPSE) is critical in dietary assessment and energy intake estimation. Traditional methods such as visual estimation are now replaced by faster, more accurate sensor-based methods. This article presents a comprehensive review of the use of sensor methodologies for portion size estimation. The review was conducted using the PRISMA guidelines and full texts of 67 scientific articles were reviewed. The contributions of this article are three-fold: i) A taxonomy for sensor-based (SB) FPSE methods was identified, classifying the sensors (as wearable, portable and stationary) and the methodology (as direct and indirect). ii) A novel comprehensive review of the state-of-the-art SB-FPSE methods was conducted and 5 sensor modalities (Acoustic, Strain, Imaging, Weighing, and Motion sensors) were identified. iii) The accuracy of portion size estimation and the applicability to free-living conditions of these SB-FPSE methods were assessed. This article concludes with a discussion of challenges and future trends of SB-FPSE.",
      "year": "2020",
      "journal": "IEEE Sensors Journal",
      "authors": "Viprav B. Raju et al.",
      "keywords": "Estimation; Computer science; Modalities; Wearable computer; Engineering; Embedded system; Systems engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jsen.2020.3041023",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3118375266",
      "doi": "10.1109/jmw.2020.3034988",
      "title": "Micrometer Sensing With Microwaves: Precise Radar Systems for Innovative Measurement Applications",
      "abstract": "Radar sensors have been widely used to estimate speed and displacement of remote targets. A novel market for contactless radar sensing is emerging in the field of automatization and process analysis, where non destructive testing and evaluation methods are desired. Here, modern radar systems offer various advantages over conventional sensors since they enable the contactless, continuous, and cost-efficient measurement of static or dynamic ranges. These can further be used for vibration and vital sign characterization. Advances in microwave technology, an increasing integration density, and the development of novel algorithms keep boosting the performance of the systems. After introducing the most common operation principles, such as unmodulated and frequency-modulated continuous-wave radar, different design aspects and building blocks of cutting-edge systems are explained in detail. In the second part, selected applications are described in detail. These include the sheet thickness monitoring of metallic foils, and the measurement of the ground speed of vehicles with the latest approaches. Exemplary low-power radar systems are presented to show the limits in terms of power consumption while still offering a high measurement precision. In addition, the topics of mechanical vibration sensing and vital sign sensing are addressed by introducing tailored systems.",
      "year": "2021",
      "journal": "IEEE Journal of Microwaves",
      "authors": "Fabian Michler et al.",
      "keywords": "Radar; Computer science; Radar engineering details; Electronic engineering; Vibration; Engineering; Radar imaging; Acoustics; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jmw.2020.3034988",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3157368957",
      "doi": "10.1109/access.2021.3077073",
      "title": "Combining Readability Formulas and Machine Learning for Reader-oriented Evaluation of Online Health Resources",
      "abstract": "Websites are rich resources for the public to access health information, and readability ensures whether the information can be comprehended. Apart from the linguistic features originated in traditional readability formulas, the reading ability of an individual is also influenced by other factors such as age, morbidities, cultural and linguistic background. This paper presents a reader-oriented readability assessment by combining readability formula scores with machine learning techniques, while considering reader background. Machine learning algorithms are trained by a dataset of 7 readability formula scores for 160 health articles in official health websites. Results show that the proposed assessment tool can provide a reader-oriented assessment to be more effective in proxy the health information readability. The key significance of the study includes its reader centeredness, which incorporates the diverse backgrounds of readers, and its clarification of the relative effectiveness and compatibility of different medical readability tools via machine learning.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Yanmeng Liu et al.",
      "keywords": "Readability; Computer science; Artificial intelligence; Proxy (statistics); Natural language processing; Reading (process); Machine learning; Health information; Information retrieval; Multimedia; Data science; Health care; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3077073",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2981306906",
      "doi": "10.1109/access.2019.2948231",
      "title": "A Seizure-Based Power Reduction SoC for Wearable EEG in Epilepsy",
      "abstract": "Epilepsy is one of the most common serious brain disorders affecting 1% of the world population. Epileptic seizure events are caused by abnormal excessive neuronal activity in the brain, which may be associated with behavioural changes that severely affect the patients\u2019 quality of life. These events are manifested as abnormal activity in electroencephalography (EEG) recordings of individuals with epilepsy. This paper presents the on-chip implementation of an algorithm that, operating on the principle of data selection applied to seizures, would be able to reduce the power consumption of EEG devices, and consequently their size, thereby significantly increasing their usability. In order to reduce the power consumed by the on-chip implementation of the algorithm, mathematical approximations have been carried out to allow for an analog implementation, resulting in the power consumed by the system to be negligible in comparison to other blocks in an EEG device. The system has been fabricated in a 0.18 \u00b5m CMOS process, consumes 1.14 \u00b5W from a 1.25 V supply and achieves a sensitivity of 98.5% while only selecting 52.5% of the EEG data for transmission.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Saam Iranmanesh et al.",
      "keywords": "Electroencephalography; Epilepsy; Computer science; Wearable computer; Chip; Population; Usability; Sensitivity (control systems); Power (physics); EEG-fMRI; Electronic engineering; Psychology; Embedded system; Neuroscience; Medicine; Engineering; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2948231",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3093463288",
      "doi": "10.1109/mic.2020.3031769",
      "title": "Semantics of the Black-Box: Can Knowledge Graphs Help Make Deep Learning Systems More Interpretable and Explainable?",
      "abstract": "The recent series of innovations in deep learning (DL) have shown enormous potential to impact individuals and society, both positively and negatively. The DL models utilizing massive computing power and enormous datasets have significantly outperformed prior historical benchmarks on increasingly difficult, well-defined research tasks across technology domains such as computer vision, natural language processing, signal processing, and human-computer interactions. However, the Black-Box nature of DL models and their over-reliance on massive amounts of data condensed into labels and dense representations poses challenges for interpretability and explainability of the system. Furthermore, DLs have not yet been proven in their ability to effectively utilize relevant domain knowledge and experience critical to human understanding. This aspect is missing in early data-focused approaches and necessitated knowledge-infused learning and other strategies to incorporate computational knowledge. This article demonstrates how knowledge, provided as a knowledge graph, is incorporated into DL methods using knowledge-infused learning, which is one of the strategies. We then discuss how this makes a fundamental difference in the interpretability and explainability of current approaches, and illustrate it with examples from natural language processing for healthcare and education applications.",
      "year": "2021",
      "journal": "IEEE Internet Computing",
      "authors": "Manas Gaur et al.",
      "keywords": "Interpretability; Computer science; Semantics (computer science); Knowledge graph; Black box; Domain knowledge; Deep learning; Artificial intelligence; Domain (mathematical analysis); Data science; Knowledge extraction; Big data; Machine learning; Natural language processing; Data mining; Programming language",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/mic.2020.3031769",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386524193",
      "doi": "10.1109/access.2023.3312948",
      "title": "Deep Learning-Based Feature Engineering to Detect Anterior and Inferior Myocardial Infarction Using UWB Radar Data",
      "abstract": "Cardiovascular disease is the main cause of death worldwide. The World Health Organization (WHO) reports that 17.9 million individuals die yearly due to complications from heart disease and other heart-related ailments. ECG monitoring and early detection are critical to decreasing myocardial infarction (MI) mortality. Thus, a non-invasive method to accurately classify different types of MI would be extremely beneficial. Our proposed study aims to detect and classify Anterior and Inferior MI infarction with advanced deep and machine learning techniques. A newly created UWB radar signal-based image dataset is used to conduct our study experiments. A novel Convolutional spatial Feature Engineering (CSFE) technique is proposed to extract the spatial features from the image dataset. The spatial features consist of both spatial and temporal information which allows machine learning models to leverage both the spatial and temporal relationships present in the data. Study results show that using the proposed CSFE technique, the advanced machine learning techniques achieved high-performance accuracy scores. The K-Neighbors Classifier (KNC) outperformed with a high-performance accuracy score of 98&#x0025; for detecting Anterior and Inferior patients. The applied methods are fully hyperparametric tuned, and performance is validated using the k-fold cross-validation method.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Kainat Zafar et al.",
      "keywords": "Artificial intelligence; Computer science; Leverage (statistics); Feature extraction; Deep learning; Feature engineering; Pattern recognition (psychology); Myocardial infarction; Feature (linguistics); Machine learning; Medicine; Cardiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312948",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206427013",
      "doi": "10.1109/access.2021.3137082",
      "title": "Robotic Technologies in ADHD Care: Literature Review",
      "abstract": "Robotics has made it possible to change and improve many support processes for vulnerable people in different settings. In recent years, its use has been oriented toward supporting therapeutic interventions of neurodevelopmental disorders (NDD), including attention deficit hyperactivity disorder (ADHD). This review of the literature highlights how advances in robotics have evolved in different scenarios of ADHD treatment, its collaboration with other emerging technologies, its results, its limitations, and the research challenges for the future development of robotics in the field of supporting children with ADHD. The authors conducted a literature review based on the location of keywords &amp;#x2018;robotics&amp;#x2019; and several NNDs such as &amp;#x2018;ADHD&amp;#x2019;, &amp;#x2019;Autism Spectrum Disorder (ASD)&amp;#x2019;, &amp;#x2018;cerebral palsy&amp;#x2019;, and &amp;#x2018;dementia&amp;#x2019; in titles, abstracts, and introduction of scientific articles in the Scopus and Web of Science (WoS) database. The reviewed literature was classified according to the type of therapy supported by the robots, the type of robot and the associated technologies. From this analysis, we can solve the research question: Which types of robots have the potential for specific applications in ADHD treatment? Furthermore, this article shows that despite favorable technical results, robotic technologies that support ADHD therapies require significant improvements in terms of scalability, human-machine interaction, and treatment and processing of acquired information to be applied effectively in real-world therapies. The most significant research challenges are proposed to drive research efforts to develop new approaches to enable robotic assistants to participate in ADHD therapies.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Jonnathan Berrezueta-Guzm\u00e1n et al.",
      "keywords": "Artificial intelligence; Robotics; Scopus; Computer science; Attention deficit hyperactivity disorder; Robot; Scalability; Psychological intervention; Data science; Psychology; MEDLINE; Psychiatry; Database; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3137082",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312803890",
      "doi": "10.1109/access.2022.3226583",
      "title": "IoT-Based Patient Health Data Using Improved Context-Aware Data Fusion and Enhanced Recursive Feature Elimination Model",
      "abstract": "The Internet of Things (IoT) in the healthcare market is propelled forward by the implementation of digital systems for monitoring and analysing health problems. IoT and smart devices can contribute to a highly smart environment. Smart medical devices interconnected with smartphone apps can collect medical and other required health data. &#x201C;Data Fusion (DF)&#x201D; refers to integrating data and knowledge from multiple sources. However, these techniques are also applied to other domains, including text processing. Using data from multiple distributed sources, the objective of DF in multisensory contexts is to reduce the chance of detection errors and increase their reliability. The objective is to increase scalability, performance efficiency, and identification. A medical device&#x2019;s ability to scale up or down demonstrates its capacity to respond to environmental factors. A more scalable system performs as expected, with no interruptions, and makes the best available use of the resource management it has. To ensure that these tracking devices all work the same way, it is essential to form a specialised group to develop uniformity in areas such as communication channels, aggregation of data, and smart interfaces. The main contribution of this research is pre-processing, DF using the Improved Context-aware Data Fusion (ICDF) algorithm, feature extraction via Improved Principal Component Analysis (IPCA), feature selection through the Enhanced Recursive Feature Elimination (ERFE) algorithm, and a classifier using an ensemble-based Machine Learning (ML) model. The Improved Dynamic Bayesian Network (IDBN) is a good trade-off for tractability, becoming a tool for ICDF operations. The simulation results show that the proposed ICDF model achieves higher performance in terms of 97&#x0025; accuracy, 96&#x0025; precision, 97&#x0025; recall, and 97&#x0025; F1 score in the healthcare system.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "S. S. Saranya et al.",
      "keywords": "Computer science; Scalability; Machine learning; Sensor fusion; Feature selection; Feature extraction; Context (archaeology); Artificial intelligence; Big data; Data mining; Classifier (UML); Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3226583",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3126643490",
      "doi": "10.1109/access.2021.3056629",
      "title": "An Algorithmic Approach for Quantitative Evaluation of Parkinson\u2019s Disease Symptoms and Medical Treatment Utilizing Wearables and Multi-Criteria Symptoms Assessment",
      "abstract": "The paper presents a novel sensor-based disease symptoms evaluation method which can be applied in the domain of neurological treatment monitoring and efficiency analysis. The main purpose of the method is to provide a quantitative approach for symptoms recognition and their intensity, which can be used for efficient medicine intake planning for Parkinson's Disease patients. This work presents an innovative method, which enables to objectify the process of clinical trials. The developed solution implements sensor data fusion method, which analyses time correlated wearable sensor biomedical data and symptoms survey. We have merged two separate methods of recognizing and assessing the intensity of Parkinson's Disease (PD) symptoms using time-constrained survey as well as sensor and interaction-based algorithms, which enable to objectively assess the intensity of disease symptoms. Based on process-based analysis and clinical trials observations, a set of requirements for validating symptoms of neurological diseases have been formulated. Proposed solution concentrates on PD indicators connected with arms movement and mental reaction delays, which can be registered using wearable sensors. Since 2017 the tool has been tested by a group of four selected neurologists and 10 users, 3 of which are PD patients. To meet the project's supplementary (efficiency, security) requirements, a test clinical trial has been performed involving 3 patients executing trials which lasted two weeks and was supported by the continuous application usage. After successful deployment the method and software tools has been presented for commercial use and further development in order to adjust its usage for other neurological disorders.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Tomasz Gutowski et al.",
      "keywords": "Wearable computer; Computer science; Clinical trial; Software deployment; Sensor fusion; Process (computing); Software; Set (abstract data type); Wearable technology; Machine learning; Medicine; Embedded system; Software engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3056629",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393252960",
      "doi": "10.1109/access.2024.3382574",
      "title": "The Detection of Dysarthria Severity Levels Using AI Models: A Review",
      "abstract": "Dysarthria, a speech disorder stemming from neurological conditions, affects communication and life quality. Precise classification and severity assessment are pivotal for therapy but are often subjective in traditional speech-language pathologist evaluations. Machine learning models offer objective assessment potential, enhancing diagnostic precision. This systematic review aims to comprehensively analyze current methodologies for classifying dysarthria based on severity levels, highlighting effective features for automatic classification and optimal AI techniques. We systematically reviewed the literature on the automatic classification of dysarthria severity levels. Sources of information will include electronic databases and grey literature. Selection criteria will be established based on relevance to the research questions. The findings of this systematic review will contribute to the current understanding of dysarthria classification, inform future research, and support the development of improved diagnostic tools. The implications of these findings could be significant in advancing patient care and improving therapeutic outcomes for individuals affected by dysarthria.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Afnan Al-Ali et al.",
      "keywords": "Dysarthria; Computer science; Speech recognition; Artificial intelligence; Medicine; Audiology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3382574",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386523337",
      "doi": "10.1109/access.2023.3312729",
      "title": "GastroNet: Gastrointestinal Polyp and Abnormal Feature Detection and Classification With Deep Learning Approach",
      "abstract": "The early detection of digestive problems is essential for lowering the chance of acquiring any form of gastrointestinal cancer, including esophageal cancer. Endoscopy is the method that is used the majority of the time for the purpose of examining and taking photos of this sort of illness. The application of artificial intelligence is now proving to be very efficient in enhancing the identification of gastrointestinal polyps and other abnormal features located inside the gastrointestinal system. As a direct consequence of this development, the use of AI within this sector has seen substantial growth. In the framework of artificial intelligence, this research investigates how well various types of algorithms perform in terms of polyp and abnormal feature recognition accuracy, efficiency, and detection. And introduced a model in this work that is GastroNet. It is developed by doing hyperparameter fine-tuning on YOLOv5 in order to find specific polyps and abnormal characteristics, particularly esophagitis. In this method, a single neural network is used to do an analysis on the whole picture before it is disassembled into its component parts and the bounding boxes and probabilities for each one are calculated independently. The goal of the hyperparameter fine-tuning is to further enhance the overall optimization of the model. Two different methods of annotation were used on a collection of data that consisted of one thousand separate images that needed to be labelled. In addition to implementing the fine-tuned SSD model, this study used three distinct backbone networks: MobileNet v2, MobileNet v2 FPN Lite, and Resnet50 v1 FPN. Additionally, this study has used CSPdarknet53 to create the improved YOLOv4 model. The results of the studies demonstrate that the proposed model, GastroNet was effective in correctly recognizing polyps and aberrant characteristics, reaching a high mAP (mean Average Precision), F1 score, and precision with a value of 0.99 and recall with a value of 1.00. The findings of this research will be a great help to physicians in the proper identification and diagnosis of abnormal features and gastrointestinal polyps.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Farhana Yasmin et al.",
      "keywords": "Computer science; Artificial intelligence; Feature (linguistics); Pattern recognition (psychology); Feature extraction; Contextual image classification; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312729",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394994563",
      "doi": "10.1109/access.2024.3392015",
      "title": "GlucoBreath: An IoT, ML, and Breath-Based Non-Invasive Glucose Meter",
      "abstract": "Diabetes is a metabolic disorder often diagnosed late and requires continuous monitoring of blood glucose. We introduce GlucoBreath, a user-centric, cost-effective, and portable pre-diagnostic solution to address this global challenge. GlucoBreath addresses the urgent need for an accessible and non-intrusive diabetes detection device, offering affordability, mobility, and comfortable non-invasive diabetes testing, especially among economically weaker sections of society. GlucoBreath comprises (i) a non-intrusive multi-sensor Internet of Things device comprising multiple sensors detecting volatile organic compounds in breath, (ii) BreathProfiles dataset encompasses information from 492 patients, which includes demographic details, physiological measurements, and sensor readings derived by analysing breath samples with our device, (iii) an innovative Machine Learning-based diabetes prediction system trained on the BreathProfiles dataset, and (iv) a user-friendly web interface for seamless device interaction and viewing diabetes reports. Given a person&#x2019;s breath sample, demographic data, and body vitals as input, GlucoBreath predicts (a) whether the person has diabetes. (b) If the person has diabetes, then the blood glucose level (BGL) of the person is moderate or high. GlucoBreath&#x2019;s groundbreaking approach supersedes current methods, achieving an impressive mean accuracy of 98.4&#x0025; using a Logistic Regression-AdaBoost stack-metamodel, marking a substantial 43.3&#x0025; improvement over an existing method. Due to its portability, non-intrusiveness, and rapid response, GlucoBreath is a valuable pre-diagnostic tool that can facilitate the early detection of diabetes in many individuals. Furthermore, GlucoBreath&#x2019;s prediction of BGL can help alert people to control their sugar consumption in the case of moderate BGL or see a doctor for high BGL.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Ritu Kapur et al.",
      "keywords": "Computer science; Software portability; Diabetes mellitus; Machine learning; Artificial intelligence; Naive Bayes classifier; Keystroke dynamics; Real-time computing; Medicine; Operating system; Support vector machine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3392015",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3183158983",
      "doi": "10.1109/access.2021.3098777",
      "title": "A Versatile Multichannel Instrument for Measurement of Ratiometric Fluorescence Intensity and Phosphorescence Lifetime",
      "abstract": "Optical biosensing is being actively investigated for minimally-invasive monitoring of key biomarkers both <i>in vitro</i> and <i>in vivo</i>. However, typical benchtop instruments are not portable and are not well suited to high-throughput, real-time analysis. This paper presents a versatile multichannel instrument for measurement of emission intensity and lifetime values arising from luminescent biosensor materials. A detailed design description of the opto-electronic hardware as well as the control software is provided, elaborating a flexible, user-configurable system that may be customized or duplicated for a wide range of applications. This article presents experimental measurements that prove the <i>in vitro</i> and <i>in vivo</i> functionality of the system. Such tools may be adopted for many research and development purposes, including evaluation of new biosensor materials, and may also serve as prototypes for future miniaturized handheld or wearable devices.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Amir Tofighi Zavareh et al.",
      "keywords": "Computer science; Biosensor; Phosphorescence; Wearable computer; Software; Computer hardware; Throughput; Embedded system; Materials science; Fluorescence; Nanotechnology; Telecommunications; Wireless; Optics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3098777",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4206934971",
      "doi": "10.1109/access.2022.3145951",
      "title": "Recurrent Neural Network-Augmented Locally Adaptive Interpretable Regression for Multivariate Time-Series Forecasting",
      "abstract": "Explaining dynamic relationships between input and output variables is one of the most important issues in time dependent domains such as economic, finance and so on. In this work, we propose a novel locally adaptive interpretable deep learning architecture that is augmented by recurrent neural networks to provide model explainability and high predictive accuracy for time-series data. The proposed model relies on two key aspects. First, the base model should be a simple interpretable model. In this step, we obtain our base model using a simple linear regression and statistical test. Second, we use recurrent neural networks to re-parameterize our base model to make the regression coefficients adaptable for each time step. Our experimental results on public benchmark datasets showed that our model not only achieves better predictive performance than the state-of-the-art baselines, but also discovers the dynamic relationship between input and output variables.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Lkhagvadorj Munkhdalai et al.",
      "keywords": "Benchmark (surveying); Computer science; Artificial neural network; Time series; Regression; Series (stratigraphy); Artificial intelligence; Multivariate statistics; Machine learning; Simple (philosophy); Regression analysis; Recurrent neural network; Linear regression; Base (topology); Statistics; Mathematics; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3145951",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3127448558",
      "doi": "10.1109/access.2021.3055195",
      "title": "Technological Evolvement in AAC Modalities to Foster Communications of Verbally Challenged ASD Children: A Systematic Review",
      "abstract": "Augmentative and Alternative Communication (AAC) emerged as a combination of methods or strategies that constitute any device, such as Speech Generating Device (SGD), Program (mobile applications), Procedure (PECS, Picture Exchange Communication System), which enhances individual&#x2019;s communication ability. Autism Spectrum Disorder (ASD) is a spectrum of comprehensive neurodevelopment disorder that leads to speech impairments, repetitive behavior, and social communication difficulties; therefore, it is imperative to underscore that at the core of all impediments are communication impairment. This article represents a systematic review of research initiatives that investigate multi-modal AAC strategies and functionality, features of mobile applications to reinforce communication and communal skills in verbally challenged ASD children because other researches are focused only on low or high-tech AAC or interventions to provide insights on ASD children respond to a particular approach. Following the PRISMA method, a total of 60 (January 2015 to October 2020) research articles were reviewed, indexed by Springer, Science Direct, Scopus, ACM, IEEE databases, and published in the AAC journal. The selected research articles are categorized into different themes where most of them focused on interactive mobile applications to improve emotional, social, learning, and overall communication skills in verbally challenged ASD children. This systematic review provides an outline of the paradigm shift in AAC modalities from PECS to Artificial Intelligence (AI), Machine Learning (ML), and Augmented Reality (AR) based applications. It opens up underline future opportunities to integrate intelligent analytics features in mobile applications to strengthen communication skills in verbally undermined ASD children.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Walia Farzana et al.",
      "keywords": "Augmentative and alternative communication; Modalities; Autism spectrum disorder; Systematic review; Psychological intervention; Computer science; Autism; Augmentative; Psychology; Multimedia; Applied psychology; Developmental psychology; MEDLINE",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3055195",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4377009229",
      "doi": "10.1109/jtehm.2023.3276943",
      "title": "Predicting Visit Cost of Obstructive Sleep Apnea Using Electronic Healthcare Records With Transformer",
      "abstract": "The proposed method makes prediction with the most of the available high-quality data by carefully exploiting details, which are not directly relevant for answering the question of the next year's likely expenditure. Clinical and Translational Impact Statement: Public Health- Lack of high-quality source data hinders data-driven analytics-based research in healthcare. The paper presents a method that couples data augmentation and prediction in cases of scant healthcare data.",
      "year": "2023",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Zhaoyang Chen et al.",
      "keywords": "Obstructive sleep apnea; Health care; Computer science; Analytics; Transformer; Scarcity; Medicine; Data science; Engineering; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2023.3276943",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3108012619",
      "doi": "10.1109/access.2020.3040914",
      "title": "Secure IoT Analytics for Fast Deterioration Detection in Emergency Rooms",
      "abstract": "FIGURE 5. Lateral, apex and basal view of Pilosphaera shells. A\u2013C: Holotype of Pilosphaera yentoensis n. sp. NMNS5635-001 (28\u00b018'32.7\" N; 120\u00b032'30\" E); D\u2013F: Paratype of Pilosphaera yentoensis n. sp. NMNS5635-002 (28\u00b0 18' 32.7\" N; 120\u00b032'30\" E); H\u2013J: Pilosphaera zebra from Wu-Lai, Taipei, Taiwan (24\u00b050'57.1\" N; 121\u00b034'11.5\" E). Scale bar = 1 mm.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Loredana Caruccio et al.",
      "keywords": "Computer science; Analytics; Computer security; Internet of Things; Task (project management); Access control; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3040914",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3081570468",
      "doi": "10.1109/access.2020.3020151",
      "title": "Variance Analysis and Handling of Clinical Pathway: An Overview of the State of Knowledge",
      "abstract": "Clinical pathway is a multi-disciplinary treatment plan and work mode, which is favorable for improving healthcare service quality and reducing medical costs. Most of references demonstrate that variance analysis and handling is the key to clinical pathway management. Thus, the clinical pathway variance has become the focus of scholars. This paper uses the text mining technique to present a literature review of 496 academic articles in the field of clinical pathway variance analysis and handling, which published between 1994 and 2018. Moreover, this paper conducts a bibliometric analysis to visualize the clinical pathway variance research. In variance analysis and handling, there are a lot of imprecise knowledge and fuzzy relations to be reasoned with knowledge of different domains. In this study, methods of clinical pathway variance analysis and handling are illustrated. In addition, this paper points out the limitations of each method. Based on the results, the future prospects of clinical pathway variance analysis and handling research is proposed.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Gang Du et al.",
      "keywords": "Variance (accounting); Computer science; Clinical pathway; Data mining; Data science; Knowledge management; Artificial intelligence; Operations management; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3020151",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3157062552",
      "doi": "10.1109/jsen.2021.3077698",
      "title": "Gait Activity Classification Using Multi-Modality Sensor Fusion: A Deep Learning Approach",
      "abstract": "Floor Sensors (FS) are used to capture information from the force induced on the contact surface by feet during gait. On the other hand, the Ambulatory Inertial Sensors (AIS) are used to capture the velocity, acceleration and orientation of the body during different activities. In this paper, fusion of the stated modalities is performed to overcome the challenge of gait classification from wearable sensors on the lower portion of human body not in contact with ground as in FS. Deep learning models are utilized for the automatic feature extraction of the ground reaction force obtained from a set of 116 FS and body movements from AIS attached at 3 different locations of lower body, which is novel. Spatio-temporal information of disproportionate inputs obtained from the two modalities is balanced and fused within deep learning network layers whilst reserving the categorical content for each gait activity. Our approach of fusion compensates the degradation in spatio-temporal accuracies in individual modalities and makes the overall classification outcomes more accurate. Further assessment of multi-modality based results show significant improvements in f-scores using different deep learning models i.e., LSTM (99.90%), 2D-CNN (88.73%), 1D-CNN (94.97%) and ANN (89.33%) respectively.",
      "year": "2021",
      "journal": "IEEE Sensors Journal",
      "authors": "Syed U. Yunas et al.",
      "keywords": "Artificial intelligence; Modality (human\u2013computer interaction); Deep learning; Computer science; Wearable computer; Modalities; Gait; Ground reaction force; Pattern recognition (psychology); Feature extraction; Orientation (vector space); Gait analysis; Computer vision; Sensor fusion; Mathematics; Physical medicine and rehabilitation; Kinematics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2021.3077698",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3154003974",
      "doi": "10.1109/access.2021.3070618",
      "title": "AEP-DLA: Adverse Event Prediction in Hospitalized Adult Patients Using Deep Learning Algorithms",
      "abstract": "Early prediction of clinical deterioration such as adverse events (AEs), improves patient safety. National Early Warning Score (NEWS) is widely used to predict AEs based on the aggregation of 6 physiological parameters. We took the same parameters as the features for AE prediction using deep learning algorithms (AEP-DLA) among hospitalized adult patients. The aim of this study is to get better performance than traditional na&#x00EF;ve mathematical calculations by introducing novel vital sign data preprocessing schemes. We retrospectively collected the data from our electronic medical record data warehouse (2007 &#x007E; 2017). AE rate of all 99,861 admissions was 6.2&#x0025;. The dataset was divided into training and testing datasets from 2007&#x2013;2015 and 2016&#x2013;2017 respectively. In real-life clinical care, physiological parameters were not recorded every hour and missed frequently, for example, Glasgow Coma Scale (GCS). The expert domain suggested that missed GCS was rated as 15. We took two strategies (stack series records and align by hour) in the data preprocessing and tripling the values of negative samples for class balancing (CB). We used the last 28 hours&#x2019; serial data to predict AEs 3 hours later with Random Forest, XGBoost, Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN). It is shown that CNN with CB and align by hour got the best results comparing to the other methods. The precision, recall and area under curve were 0.841, 0.928 and 0.995 respectively. The performance of the model is also better than those proposed in the published literatures.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Chieh\u2010Liang Wu et al.",
      "keywords": "Computer science; Recurrent neural network; Glasgow Coma Scale; Deep learning; Artificial intelligence; Early warning score; Machine learning; Convolutional neural network; Algorithm; Random forest; Warning system; Preprocessor; Vital signs; Artificial neural network; Medicine; Emergency medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3070618",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382751181",
      "doi": "10.1109/access.2023.3290997",
      "title": "Recent Advances in Applying Machine Learning and Deep Learning to Detect Upper Gastrointestinal Tract Lesions",
      "abstract": "The clinical application of a real-time artificial intelligence (AI) image processing system to diagnose upper gastrointestinal (GI) malignancies remains an experimental research and engineering problem. Understanding these commonly used technical techniques is required to appreciate the scientific quality and novelty of AI studies. Clinicians frequently lack this technical background, and AI experts may be unaware of such clinical relevance and implications in daily practice. As a result, there is a growing need for a multidisciplinary, international assessment of how to conduct high-quality AI research in upper GI malignancy detection. This research will help endoscopists build approaches or models to increase diagnosis accuracy for upper GI malignancies despite variances in experience, education, personnel, and resources, as it offers real-time and retrospective chances to improve upper GI malignancy diagnosis and screening. This comprehensive review sheds light on potential enhancements to computer-aided diagnostic (CAD) systems for GI endoscopy. The survey includes 65 studies on automatic upper GI malignancy diagnosis and evaluation, which are compared by endoscopic modalities, image counts, models, validation methods, and results. The main goal of this research is to assess and compare each AI method\u2019s current stage and potential improvement to boost performance, maturity, and the possibility to open new research areas for the application of a real-time AI image recognition system that diagnoses upper GI malignancies. The findings of this study suggest that Support Vector Machines (SVM) are frequently utilized in gastrointestinal (GI) image processing within the context of machine learning (ML). Moreover, the analysis reveals that CNN-based supervised learning object detection models are widely employed in GI image analysis within the deep learning (DL) context. The results of this study also suggest that RGB is the most commonly used image modality for GI analysis, with color playing a vital role in detecting bleeding locations. Researchers rely on public datasets from 2018\u20132019 to develop AI systems, but combining them is challenging due to their unique classes. To overcome the problem of insufficient data to train a new DL model, a standardized database is needed to hold different datasets for the development of AI-based GI endoscopy systems.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Malinda Vania et al.",
      "keywords": "Computer science; Deep learning; Artificial intelligence; Gastrointestinal tract; Machine learning; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3290997",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4317496730",
      "doi": "10.1109/tnsre.2023.3237916",
      "title": "Detection of Brain Abnormalities in Parkinson\u2019s Rats by Combining Deep Learning and Motion Tracking",
      "abstract": "Parkinson's disease (PD) is a chronic neurodegenerative disease that affects the central nervous system. PD mainly affects the motor nervous system and may cause cognitive and behavioral problems. One of the best tools to investigate the pathogenesis of PD is animal models, among which the 6-OHDA-treated rat is a widely employed rodent model. In this research, three-dimensional motion capture technology was employed to obtain real-time three-dimensional coordinate information about sick and healthy rats freely moving in an open field. This research also proposes an end-to-end deep learning model of CNN-BGRU to extract spatiotemporal information from 3D coordinate information and perform classification. The experimental results show that the model proposed in this research can effectively distinguish sick rats from healthy rats with a classification accuracy of 98.73%, providing a new and effective method for the clinical detection of Parkinson's syndrome.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Houchi Li et al.",
      "keywords": "Parkinson's disease; Neuroscience; Disease; Artificial intelligence; Cognition; Motion (physics); Computer science; Animal model; Physical medicine and rehabilitation; Central nervous system; Medicine; Machine learning; Psychology; Pathology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3237916",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391341955",
      "doi": "10.1109/access.2024.3359701",
      "title": "Benchmarking Deep Learning Frameworks for Automated Diagnosis of Ocular Toxoplasmosis: A Comprehensive Approach to Classification and Segmentation",
      "abstract": "Diagnosis of Ocular toxoplasmosis (OT) usually involves clinical examination and imaging, which can be expensive and require specialized personnel. The use of artificial intelligence (AI) to analyze fundus images for diagnosing ocular diseases is gaining traction. Despite that, there has not been much work done focusing on the detection of OT. To address this issue, we conducted a benchmark study that evaluates the effectiveness of existing pre-trained networks using transfer learning techniques to detect and segment OT lesions from fundus images. The goal of this study is to provide insights for future researchers interested in harnessing deep learning (DL) techniques for automated, easy-to-use, and precise diagnostic approaches of OT using retinal fundus images. Along with that, we have performed an in-depth analysis of different feature extraction techniques to find the most optimal one for the classification and segmentation of lesions. For classification tasks, we have evaluated pre-trained models such as VGG16, MobileNetV2, InceptionV3, ResNet50, and DenseNet121 models. Among them, MobileNetV2 outperformed all other models in terms of Accuracy (Acc.), Recall, and F1-Score outperforming the second-best InceptionV3 by 0.7&#x0025; higher Acc. However, DenseNet121 achieved the best result in terms of Precision, which was 0.1&#x0025; higher than MobileNetV2. For the segmentation task, we replaced the encoder block of the U-Net with pre-trained MobileNetV2, InceptionV3, ResNet34, and VGG16 and trained with two different loss functions (Dice loss and Jaccard loss). The MobileNetV2/U-Net outperformed ResNet34 by 0.5&#x0025; and 2.1&#x0025; in terms of Acc. and Dice Score, respectively when the most optimum Jaccard loss function is employed during the training. The results mentioned in this study verify the effectiveness of the DL techniques in the diagnosis of OT.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Syed Samiul Alam et al.",
      "keywords": "Artificial intelligence; Computer science; Segmentation; Deep learning; Pattern recognition (psychology); Contextual image classification; Machine learning; Image segmentation; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3359701",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393170716",
      "doi": "10.1109/access.2024.3381034",
      "title": "Anonymization and Pseudonymization of FHIR Resources for Secondary Use of Healthcare Data",
      "abstract": "Along with the creation of medical profiles of patients, Electronic Health Records have several secondary missions, such as health economy and research. The recent, increasing adoption of a common standard, i.e., the Fast Healthcare Interoperability Resources (FHIR), makes it easier to exchange medical data among the several parties involved, for example, in an epidemiological research activity. However, this exchange process is hindered by regulatory frameworks due to privacy issues related to the presence of personal information, which allows patients to be identified directly (or indirectly) from their medical data. When properly used, de-identification techniques can provide crucial support in overcoming these problems. FHIR-DIET aims to bring flexibility and concreteness to the implementation of de-identification of health data, supporting many customised data-processing behaviours that can be easily configured and tailored to match specific use case requirements. Our solution enables faster and easier cooperation between legal and IT professionals to establish and implement de-identification rules. The performance evaluation demonstrates the viability of processing hundreds of FHIR patient information data per second using standard hardware. We believe FHIR-DIET can be a valuable tool to satisfy the current regulation requirements and help to create added-value for the secondary use of healthcare data.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Emanuele Raso et al.",
      "keywords": "Computer science; Health care; Data science; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3381034",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4385626854",
      "doi": "10.1109/access.2023.3303342",
      "title": "Cesarean Section Classification Using Machine Learning With Feature Selection, Data Balancing, and Explainability",
      "abstract": "Disease samples are naturally fewer than healthy samples which introduces bias in the training of machine learning (ML) models. Current study focuses in learning discriminating patterns between cesarean and non-cesarean phenomena based on a dataset consisting of 161 features of total 692 cesarean and 5465 non-cesarean samples which comes as four folds based on four different hospitals (hospital A, B, C and D). The dataset is noisy, contains missing values, features are at different scales and above all, 161 features are quite a large in number and risks containing unnecessary information with respect to learning to separate the C-section class from non-cesarean.This study introduced a data pre-processing pipeline, resolving issues with data imbalance, handling missing values, identifying and deleting outliers, etc. A novel ensemble model is proposed which is able to consistently perform better irrespective of data volumes (data fold A, A&#x002B;B, A&#x002B;B&#x002B;C and A&#x002B;B&#x002B;C&#x002B;D) and pre-processing pipeline and achieved 96-99&#x0025; accuracy across data volumes. Finally, the proposed model&#x2019;s decision-making was explained in terms of prominent features where higher values of features like Episiotomy, age of women and Fetal intrapartum pH accounts for causing C-section.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nahid Sultan et al.",
      "keywords": "Computer science; Artificial intelligence; Outlier; Feature selection; Pipeline (software); Missing data; Section (typography); Feature (linguistics); Machine learning; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3303342",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4406754095",
      "doi": "10.1109/access.2025.3533145",
      "title": "A Systematic Review of Access Control Models: Background, Existing Research, and Challenges",
      "abstract": "Data security has become paramount, especially with the exponential growth of data, the rise of cyber threats, and the increasing prevalence of remote work. Data confidentiality, integrity, and availability are crucial, particularly in sensitive domains like healthcare and cloud computing. While robust access control (AC) is essential, it must be balanced with maintaining operational efficiency. In access control models, there is a general lack of a comprehensive cross-domain overview, insufficient focus on evolving access control requirements, and inadequate analysis of challenges and issues. This paper comprehensively analyzes access control models (ACMs) through a two-pronged approach. First, we conduct a Narrative Literature Review(NLR) to classify traditional ACMs, evaluating their security strengths and weaknesses and compatible security protocols. Second, we perform a Systematic Literature Review (SLR) of emerging ACMs developed over the past decade across various domains. This systematic review has three primary objectives: (1) to introduce and analyze these emerging ACMs, (2) to present their current technological status, and (3) to identify key challenges and promising research directions. By combining these approaches, this paper offers a comprehensive overviewofACMapplications and techniques, identifies existing challenges, and explores future research directions to guide advancements in access control.",
      "year": "2025",
      "journal": "IEEE Access",
      "authors": "Nastaran Farhadighalati et al.",
      "keywords": "Computer science; Systematic review; MEDLINE",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2025.3533145",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4213437941",
      "doi": "10.1109/jphot.2022.3153506",
      "title": "Wearable Wrist Photoplethysmography for Optimal Monitoring of Vital Signs: A Unified Perspective on Pulse Waveforms",
      "abstract": "To track vital signs on the wrist, a wearable system, named WrisTee, has been developed for remote health monitoring. Using three optical sensors with four light sources, WrisTee allows users to measure 12 photoplethysmogram (PPG) signals at three locations on the radial artery. Two types of PPG signals with opposite polarities were discovered and designated as in-phase and invert-phase signals. We provided a unified viewpoint regarding their differences based on the Beer <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math></inline-formula> Lambert law, and showed that both signals can be used for heart monitoring using data analyzed from a selected subject. Using reflective pulse-transition time (R-PTT) and the standard deviation of R-PTT (<inline-formula><tex-math notation=\"LaTeX\">$\\sigma _{R\\text{-}PTT}$</tex-math></inline-formula>), we proposed a method for selecting the optimal wavelength to achieve the best quality signal, thus minimizing storage requirements, power resources, and computational costs. We conducted an experiment on ten subjects to evaluate the feasibility of the proposed method. Our results demonstrated that WrisTee is capable of finding the optimal positions and wavelengths for monitoring vital signs. To automatically detect the PPG phases, six machine learning (ML) models were explored to assess their accuracy for PPG-phase classification. The experimental results show that a convolutional neural network can be the best candidate for phase classification. Hence, it can be integrated into WrisTee for noninvasive health monitoring such as heart rate, heart rate variability, or blood pressure. Our work paves a new direction in bio-signal medical researches by adopting in-phase and invert-phase PPGs for healthcare monitoring.",
      "year": "2022",
      "journal": "IEEE photonics journal",
      "authors": "Nguyen Mai Hoang Long et al.",
      "keywords": "Photoplethysmogram; Wearable computer; Computer science; Pulse (music); Convolutional neural network; Artificial intelligence; Speech recognition; Computer vision; Embedded system; Filter (signal processing); Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jphot.2022.3153506",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387042177",
      "doi": "10.1109/access.2023.3319452",
      "title": "An Adaptive Sleep Apnea Detection Model Using Multi Cascaded Atrous-Based Deep Learning Schemes With Hybrid Artificial Humming Bird Pity Beetle Algorithm",
      "abstract": "Obstructive Sleep Apnea (OSA) is the cessation in breathing that must be identified as early&#13;\\nas possible to save the patient\u2019s life. Apart from physical diagnosis, a deep learning model can serve the&#13;\\npurpose of detecting the apnea swiftly. The detection largely depends upon biological signals such as ECG,&#13;\\nEEG, EMG, etc. Because of the high dimensionality nature of the bio signals, feature extraction is very&#13;\\ncritical in detecting sleep apnea. Many such feature extraction models were fragile to resolve the complexity&#13;\\nissue and failed to reduce the non-robustness nature. To surmount all these issues, a novel adaptive deep&#13;\\nlearning-based model is designed for detecting the sleep apnea. Here two feature sets have been extracted&#13;\\nfrom the ECG signals: Spectral features through Short Term Fourier Transform (STFT) and QRS analysis&#13;\\nfollowed by an auto encoder to extract the deep temporal features. The novel Artificial Hummingbird&#13;\\nPity Beetle Algorithm (AHPBA) is proposed to choose the optimal features and weight parameters, which&#13;\\nassists in concatenation of the two feature sets. Then these fused features were given into Multi Cascaded&#13;\\nAtrous based Deep Learning Schemes (MCA-DLS) for classification purpose, then it is further optimized by&#13;\\nAHPBA by maximizing the variance. MCA-DLS have performed well compared to classifying the signals&#13;\\nindividually using One Dimensional Convolutional Neural Networks (1DCNN), Long Short-Term Memory&#13;\\n(LSTM) and Deep Neural Networks (DNN) as the average accuracy of MCA-DLS is 94.51% whereas the&#13;\\nother three provides an average accuracy of 90.83%, 91.98%, and 93.25% respectively for the considered&#13;\\ndatasets. By using AHPBA the average accuracy of MCA-DLS was enhanced to 96.4%, which is higher than&#13;\\nthe conventional optimization techniques which are discussed in the result section.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "S. Aswath et al.",
      "keywords": "Artificial intelligence; Computer science; Deep learning; Feature extraction; Pattern recognition (psychology); Robustness (evolution); Convolutional neural network; Artificial neural network; Speech recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3319452",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394564385",
      "doi": "10.1109/access.2024.3385787",
      "title": "Detecting and Classifying Myocardial Infarction in Echocardiogram Frames With an Enhanced CNN Algorithm and ECV-3D Network",
      "abstract": "Myocardial infarction is a serious medical condition that requires prompt and accurate diagnosis for effective treatment. In this paper, we present a novel approach for detecting and classifying MI in echocardiogram frames using an enhanced CNN algorithm and an ECV-3D network. The proposed method aims to improve the accuracy and efficiency of MI diagnosis by leveraging advanced deep learning techniques. Through extensive experimentation, we demonstrated the effectiveness of our approach in achieving high accuracy and robustness in MI detection and classification. These results indicate the potential of our method to aid in the early and precise diagnosis of MI, thereby contributing to improved patient outcomes and clinical decision-making. After conducting thorough experimentation, our proposed approach achieved an impressive accuracy of 97.05&#x0025; in the detection and classification of myocardial infarction in echocardiogram frames. This shows the robustness and reliability of our method, indicating its potential to significantly impact the accurate diagnosis of MI and subsequently improve patient outcomes. Furthermore, the area under the curve attained by our model is 0.82, reaffirming the efficacy of the enhanced CNN algorithm and ECV-3D network in accurately detecting and classifying MI. It is noteworthy that all the parameters utilized in our approach have demonstrated a high level of accuracy, emphasizing the effectiveness of our deep learning techniques in enhancing the diagnostic process for MI. Moreover, the proposed method efficiently process large volumes of echocardiogram frames, making it suitable for real-time clinical applications.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "S Deepika et al.",
      "keywords": "Computer science; Algorithm; Artificial intelligence; Myocardial infarction; Pattern recognition (psychology); Cardiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3385787",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394564224",
      "doi": "10.1109/access.2024.3386362",
      "title": "Exploring Public Response to ChatGPT With Sentiment Analysis and Knowledge Mapping",
      "abstract": "Information about artificial intelligence generated content (AIGC) has attracted great attention from the public. ChatGPT has gained attention from many countries due to its powerful functionality and efficiency. However, there are still many countries, such as China, that refuse to introduce ChatGPT into their own countries. This article aims to study the attention that ChatGPT has attracted in China, further investigate the reasons for the obstruction of ChatGPT&#x2019;s dissemination, and provide prospects and suggestions for the global development of artificial intelligence. First, we apply the Latent Dirichlet Allocation (LDA) topic modeling algorithm to analyze the 28,122 web tweets and comments from China regarding ChatGPT. The results show that there are more negative emotions compared to positive and neutral emotions. The attention on ChatGPT rapidly increased twice between March and May 2023. We find the audience interest and concern words:&#x201C;improvement&#x201D;, &#x201C;company&#x201D; and &#x201C;technology&#x201D;. The analysis reveals three main themes: social, technological, and educational. Additionally, we conduct knowledge mapping to analyze the publication time, research hotspots, and subject distribution of Chinese scholars&#x2019; literature. In conclusion, this paper highlights several key issues that need to be addressed for the further advancement of AIGC, including the evolution of job roles, the changing technological landscape, the pursuit of artificial general intelligence, and ethical concerns.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Jinqiao Zhou et al.",
      "keywords": "Computer science; Data science; Knowledge management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3386362",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4212778108",
      "doi": "10.1109/access.2022.3153059",
      "title": "Deep-Precognitive Diagnosis: Preventing Future Pandemics by Novel Disease Detection With Biologically-Inspired Conv-Fuzzy Network",
      "abstract": "Deep learning-based Computer-Aided Diagnosis has gained immense attention in recent years due to its capability to enhance diagnostic performance and elucidate complex clinical tasks. However, conventional supervised deep learning models are incapable of recognizing novel diseases that do not exist in the training dataset. Automated early-stage detection of novel infectious diseases can be vital in controlling their rapid spread. Moreover, the development of a conventional CAD model is only possible after disease outbreaks and datasets become available for training (viz. COVID-19 outbreak). Since novel diseases are unknown and cannot be included in training data, it is challenging to recognize them through existing supervised deep learning models. Even after data becomes available, recognizing new classes with conventional models requires a complete extensive re-training. The present study is the <i>first</i> to report this problem and propose a novel solution to it. In this study, we propose a new class of CAD models, i.e., Deep-Precognitive Diagnosis, wherein artificial agents are enabled to identify unknown diseases that have the potential to cause a pandemic in the future. A <i>de novo</i> biologically-inspired Conv-Fuzzy network is developed. Experimental results show that the model trained to classify Chest X-Ray (CXR) scans into normal and bacterial pneumonia detected a novel disease during testing, unseen by it in the training sample and confirmed to be COVID-19 later. The model is also tested on SARS-CoV-1 and MERS-CoV samples as unseen diseases and achieved state-of-the-art accuracy. The proposed model eliminates the need for model re-training by creating a new class in real-time for the detected novel disease, thus classifying it on all subsequent occurrences. <i>Second,</i> the model addresses the challenge of limited labeled data availability, which renders most supervised learning techniques ineffective and establishes that modified fuzzy classifiers can achieve high accuracy on image classification tasks.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Aviral Chharia et al.",
      "keywords": "Fuzzy logic; Computer science; Biological network; Artificial intelligence; Computational biology; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3153059",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3086504551",
      "doi": "10.1109/access.2020.3023915",
      "title": "Studying the Effects of Compression in EEG-Based Wearable Sleep Monitoring Systems",
      "abstract": "Long-term sleep monitoring through the use of wearable EEG-based systems generates large volumes of data that need to be either locally stored or wireless transmitted. Compression of data can play a vital role to reduce the power consumption of these already resource-constrained systems. While compression methods can result in significantly reduced data storage and transmission requirements, the loss in signal information can have an impact on the algorithms used to extract the key sleep parameters. This paper studies the impact of six different state-of-the-art compression methods, including wavelet, SPIHT, filter and predictor-based methods, analysing their effects on the reconstructed signal quality particularly for automatic sleep staging applications. It looks at how the overall sleep staging accuracy as well as the detection accuracy of different sleep stages is reduced as a result of different EEG compression methods. It shows that the SPIHT and predictor-based compression methods outperform wavelet and filter-based methods in preserving the relevant signal features. It also shows that compression ratios of up to 65 can be achieved using the QSPIHT method with less than 10% loss in overall sleep staging accuracy.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Deland Hu Liu et al.",
      "keywords": "Computer science; Data compression; Sleep (system call); Wearable computer; Compression (physics); Electroencephalography; Wavelet; Filter (signal processing); Artificial intelligence; Data compression ratio; Image compression; Real-time computing; Speech recognition; Computer vision; Embedded system; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3023915",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319990329",
      "doi": "10.1109/jtehm.2023.3241635",
      "title": "Adaptation of Autoencoder for Sparsity Reduction From Clinical Notes Representation Learning",
      "abstract": "The proposed approach provided overall performance gains of up to 3% for each test set evaluation. Finally, the classifier achieved 92% accuracy, 91% recall, 91% precision, and 91% f1-score in detecting the patient's condition. Furthermore, the compression working mechanism and the autoencoder prediction process were demonstrated by applying the theoretic information bottleneck framework. Clinical and Translational Impact Statement- An autoencoder learning algorithm effectively tackles the problem of sparsity in the representation feature space from a small clinical narrative dataset. Significantly, it can learn the best representation of the training data because of its lossless compression capacity compared to other approaches. Consequently, its downstream classification ability can be significantly improved, which cannot be done using deep learning models.",
      "year": "2023",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Thanh-Dung Le et al.",
      "keywords": "Autoencoder; Artificial intelligence; Computer science; Feature learning; Pattern recognition (psychology); Feature selection; Dimensionality reduction; Machine learning; Feature vector; Classifier (UML); Linear classifier; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2023.3241635",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394711311",
      "doi": "10.1109/access.2024.3387462",
      "title": "A Hybrid Network Analysis and Machine Learning Model for Enhanced Financial Distress Prediction",
      "abstract": "Financial distress prediction is crucial to financial planning, particularly amid emerging uncertainties. This study introduces a novel methodology for predicting financial distress by amalgamating network analysis and machine learning techniques. The approach involves establishing two company networks based on their similarity and correlation in crucial financial indicators. The first network reflects similarity across five features, while the second captures correlation in the most critical feature. Subsequently, seven network-centric features are extracted and integrated into the dataset as new variables. Community detection algorithms are also applied to cluster companies, with the resulting labels added as categorical variables. This process yields a modified dataset comprising both initial and network-based variables. Five classification algorithms are employed to forecast financial distress across three scenarios. Initially, models are trained using only the initial features. In subsequent scenarios, network-centric features from similarity and correlation networks are incorporated, enhancing the predictive accuracy of machine learning models. Notably, features from the similarity network play a pivotal role in this improvement. The proposed model showcases superior predictive capabilities and offers a holistic understanding of the dynamic interactions among financial entities. The results underscore the efficacy of network-based strategies in refining financial distress prediction models, providing valuable insights for decision-makers.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Saba Taheri Kadkhoda et al.",
      "keywords": "Computer science; Financial distress; Machine learning; Artificial intelligence; Financial system; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3387462",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3141886321",
      "doi": "10.1109/access.2021.3069684",
      "title": "Cluster Analysis of Mixed and Missing Chronic Kidney Disease Data in KwaZulu-Natal Province, South Africa",
      "abstract": "Real-world datasets, particularly Electronic Health Records, are routinely found to be mixed (comprised of both categorical and continuous variables) and/or missing in nature. Such datasets present peculiar challenges related both to their clustering and the evaluation of the clusterings obtained. In this paper, we discuss these challenges in detail, as well as the solution approaches applied to them in the literature. We then apply some of these approaches to a multi-racial Chronic Kidney Disease (CKD) dataset comprising of 20 continuous and 12 categorical variables with an over 30&#x0025; missingness ratio, evaluating our results through external and internal validation as well as cluster stability testing. From the results of our study, the Ahmad-Dey distance measure consistently outperformed Gower&#x2019;s distance on our mixed and missing dataset. In addition, our results show that advanced imputation methods like multiple imputation, which take into consideration the uncertainty inherent in imputation, should be explored when clustering missing datasets. Three clusters were identified from our dataset which were significantly differentiated by age, sex, estimated Glomerular Filtration Rate (eGFR), creatinine, urea, and hemoglobin, but not by race or blood pressure. The fact that, through proper cluster analysis, we were unable to identify five clusters corresponding to the five CKD stages usually used to classify CKD patients indicates that datasets with more than the usual four/six variables used for computing eGFR may contain a latent structure different from this five-group structure, the identification of which will provide valuable insights peculiar to each cohort for medical practitioners.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Peter Ayokunle Popoola et al.",
      "keywords": "Categorical variable; Missing data; Imputation (statistics); Cluster analysis; Computer science; Hierarchical clustering; Kidney disease; Data mining; Statistics; Medicine; Artificial intelligence; Mathematics; Machine learning; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3069684",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313429454",
      "doi": "10.1109/jtehm.2022.3227204",
      "title": "Identification of Coronary Culprit Lesion in ST Elevation Myocardial Infarction by Using Deep Learning",
      "abstract": "Our study demonstrated that deep learning with a CNN could facilitate the identification of the culprit coronary artery in patients with STEMI. Preprocessing ECG signals with CWT was demonstrated to be superior to doing so with STFT.",
      "year": "2022",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Li-Ming Tseng et al.",
      "keywords": "Culprit; Myocardial infarction; Identification (biology); Cardiology; Internal medicine; Medicine; Lesion; Artificial intelligence; Coronary angiography; Computer science; Pathology; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2022.3227204",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3111837814",
      "doi": "10.1109/mis.2020.3044944",
      "title": "Argumentation-Based Health Information Systems: A Design Methodology",
      "abstract": "In this article, we present a design methodology for argumentation-based health information systems. With a focus on the application of formal argumentation, the methodology aims at eliciting requirements in regard to argumentation reasoning behavior, knowledge and user models, and business logic on levels below and above the argumentation layer. We highlight specific considerations that need to be made dependent on the system type, i.e., for clinical decision-support systems, patient-facing systems, and administration systems. In addition, we outline challenges in regards to the design of argumentation-based intelligent systems for healthcare, considering the state of the art of argumentation research, health information systems, and software design methods. For each challenge, we outline a mitigation strategy.",
      "year": "2020",
      "journal": "IEEE Intelligent Systems",
      "authors": "Helena Lindgren et al.",
      "keywords": "Argumentation theory; Computer science; Information system; Focus (optics); Management science; Knowledge management; Intelligent decision support system; Data science; Artificial intelligence; Epistemology; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mis.2020.3044944",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386470317",
      "doi": "10.1109/jbhi.2023.3312597",
      "title": "Markov-Based Neural Networks for Heart Sound Segmentation: Using Domain Knowledge in a Principled Way",
      "abstract": "This work considers the problem of segmenting heart sounds into their fundamental components. We unify statistical and data-driven solutions by introducing Markov-based Neural Networks (MNNs), a hybrid end-to-end framework that exploits Markov models as statistical inductive biases for an Artificial Neural Network (ANN) discriminator. We show that an MNN leveraging a simple one-dimensional Convolutional ANN significantly outperforms two recent purely data-driven solutions for this task in two publicly available datasets: PhysioNet 2016 (Sensitivity: 0.947 \u00b10.02; Positive Predictive Value : 0.937 \u00b10.025) and the CirCor DigiScope 2022 (Sensitivity: 0.950 \u00b10.008; Positive Predictive Value: 0.943 \u00b10.012). We also propose a novel gradient-based unsupervised learning algorithm that effectively makes the MNN adaptive to unseen datum sampled from unknown distributions. We perform a cross dataset analysis and show that an MNN pre-trained in the CirCor DigiScope 2022 can benefit from an average improvement of 3.90% Positive Predictive Value on unseen observations from the PhysioNet 2016 dataset using this method.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Miguel L. Martins et al.",
      "keywords": "Notation; Artificial intelligence; Artificial neural network; Computer science; Machine learning; Algorithm; Mathematics; Arithmetic",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3312597",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387623943",
      "doi": "10.1109/access.2023.3324459",
      "title": "Comprehensive Performance Assessment of Multi-Neural Ensemble Model for Mortality Prediction in ICU",
      "abstract": "The development of models to estimate the mortality rate of critically ill patients in the intensive care unit(ICU) is significantly enhanced by technologies based on artificial intelligence. But it can be quite difficult because most medical data are typically unbalanced and incomplete. This paper aims to address the missing data using advanced imputation algorithm like single center imputation from multiple chained equation (SICE) and synthetic minority oversampling technique with edited nearest neighbor (SMOTE-ENN) method is used to solve the imbalanced data problem. Wrapper-based genetic feature selection method is used for the feature selection. With a highly skewed dataset, the objective of this work is to propose an improved ensemble classifier that utilizes a combination of boosting and stacking ensemble strategies. Our work proposed a Stacking-based multi-layer perceptron ensemble learning method on bench-marking dataset namely 2020 WiDS (Women in Data Science) Challenge and got an accuracy of 93.67%. The results obtained using randomized five-fold cross-validation and hold-out techniques reveal that the performance of the proposed ensemble algorithm was better than that of all other predictors. In comparison to prior deep learning-driven mortality classification research, we designed a comprehensive structure that encompasses a novel feature pre-processing methods and stacking ensemble algorithm for classification.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Fathima Begum M et al.",
      "keywords": "Computer science; Artificial intelligence; Boosting (machine learning); Feature selection; Machine learning; Ensemble learning; Artificial neural network; Data mining; Multilayer perceptron; Oversampling; Missing data; Perceptron; Ensemble forecasting; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3324459",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4310706094",
      "doi": "10.1109/jtehm.2022.3217428",
      "title": "Res-SE-ConvNet: A Deep Neural Network for Hypoxemia Severity Prediction for Hospital In-Patients Using Photoplethysmograph Signal",
      "abstract": "Determining the severity level of hypoxemia, the scarcity of saturated oxygen (SpO2) in the human body, is very important for the patients, a matter which has become even more significant during the outbreak of Covid-19 variants. Although the widespread usage of Pulse Oximeter has helped the doctors aware of the current level of SpO2 and thereby determine the hypoxemia severity of a particular patient, the high sensitivity of the device can lead to the desensitization of the care-givers, resulting in slower response to actual hypoxemia event. There has been research conducted for the detection of severity level using various parameters and bio-signals and feeding them in a machine learning algorithm. However, in this paper, we have proposed a new residual-squeeze-excitation-attention based convolutional network (Res-SE-ConvNet) using only Photoplethysmography (PPG) signal for the comfortability of the patient. Unlike the other methods, the proposed method has outperformed the standard state-of-art methods as the result shows 96.5% accuracy in determining 3 class severity problems with 0.79 Cohen Kappa score. This method has the potential to aid the patients in receiving the benefit of an automatic and faster clinical decision support system, thus handling the severity of hypoxemia.",
      "year": "2022",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Talha Ibn Mahmud et al.",
      "keywords": "Photoplethysmogram; Hypoxemia; Alertness; Medicine; SIGNAL (programming language); Computer science; Cardiology; Artificial intelligence; Intensive care medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2022.3217428",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312592222",
      "doi": "10.1109/access.2022.3217904",
      "title": "A Review of Facial Thermography Assessment for Vital Signs Estimation",
      "abstract": "Estimated vital signs might include a variety of measurements that can be used in detecting any abnormal conditions by analyzing facial images from continuous monitoring with a thermal video camera. To overcome the limitless human visual perceptions, thermal infrared has proven to be the most effective technique for visualizing facial colour changes that could have been reflected by changes in oxygenation levels and blood volume in facial arteries. This study investigated the possibility of vital signs estimation using physiological function images converted from thermal infrared images in the same ways that visible images are used, with a need for an efficient extractor method as correction procedures that have used datasets that include images with and without wearing glasses or protective face masks. This paper, summarize thermal images using advanced machine learning and deep learning methods with satisfactory performance. Also, we presented the evaluation matrices that were included in the assessment based on statistical analysis, accuracy measures and error measures. Finally, to discuss future gaps and directions for further evaluations.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Syaidatus Syahira Ahmad Tarmizi et al.",
      "keywords": "Computer science; Thermography; Artificial intelligence; Computer vision; Vital signs; Face (sociological concept); Facial recognition system; Extractor; Feature (linguistics); Pattern recognition (psychology); Infrared; Optics; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3217904",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285166146",
      "doi": "10.1109/access.2022.3178409",
      "title": "Joint Modality Features in Frequency Domain for Stress Detection",
      "abstract": "Rich feature extraction is essential to train a good machine learning (ML) framework. These features are generally extracted separately from each modality. We hypothesize that richer features can be learned when modalities are jointly explored. These joint modality features can perform better than those extracted from individual modalities. We study two modalities, physiological signals&#x2013;Electrodermal activity (EDA) and electrocardiogram (ECG) to investigate this hypothesis. We investigate our hypothesis to achieve three objectives for subject-independent stress detection. For the first time in the literature, we apply our proposed framework in the frequency domain. The frequency-domain decomposition of the signal effectively separates it into periodic and aperiodic components. We can correlate their behaviour by focusing on each band of the signal spectrum. Second, we show that our framework outperforms late fusion, early fusion and other notable works in the field. Finally, we validate our approach on four benchmark datasets to show its generalization ability.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "K Radhika et al.",
      "keywords": "Computer science; Modalities; Modality (human\u2013computer interaction); Artificial intelligence; Benchmark (surveying); Generalization; Pattern recognition (psychology); Feature extraction; Feature (linguistics); Frequency domain; Joint (building); SIGNAL (programming language); Aperiodic graph; Field (mathematics); Domain (mathematical analysis); Speech recognition; Machine learning; Mathematics; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3178409",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3017915994",
      "doi": "10.1109/jbhi.2020.2987323",
      "title": "Errors-in-Variables Modeling of Personalized Treatment-Response Trajectories",
      "abstract": "Estimating the impact of a treatment on a given response is needed in many biomedical applications. However, methodology is lacking for the case when the response is a continuous temporal curve, treatment covariates suffer extensively from measurement error, and even the exact timing of the treatments is unknown. We introduce a novel method for this challenging scenario. We model personalized treatment-response curves as a combination of parametric response functions, hierarchically sharing information across individuals, and a sparse Gaussian process for the baseline trend. Importantly, our model accounts for errors not only in treatment covariates, but also in treatment timings, a problem arising in practice for example when data on treatments are based on user self-reporting. We validate our model with simulated and real patient data, and show that in a challenging application of estimating the impact of diet on continuous blood glucose measurements, accounting for measurement error significantly improves estimation and prediction accuracy.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Guangyi Zhang et al.",
      "keywords": "Covariate; Computer science; Gaussian process; Parametric statistics; Observational error; Baseline (sea); Data mining; Process (computing); Machine learning; Statistics; Artificial intelligence; Gaussian; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2020.2987323",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391128507",
      "doi": "10.1109/access.2024.3357533",
      "title": "A Comprehensive Bibliometric Analysis of Missing Value Imputation",
      "abstract": "Data quality plays a crucial role in tasks, such as enhancing the accuracy of data analytics and avoiding the accumulation of redundant data. One of the significant challenges in data quality is dealing with missing data, which has been extensively explored by the scholarly community and has resulted in a significant increase in related publications. It is important to recognize that the landscape of missing data in computer science offers numerous opportunities for further research. However, upon closer examination of existing studies, it becomes evident that many have not fully utilized bibliometric analysis tools and software for comprehensive literature reviews. Therefore, this study aims to explore the essential characteristics, trends, and prevailing themes in the field of missing data imputation. Through a thorough bibliometric analysis, this study demonstrated the evolution of knowledge and key focal points in the field of missing data imputation. The analysis consisted of 352 journal papers in computer science published between 2012 and 2023, all centered on missing data imputation. Among these publications, &#x201C;IEEE Access&#x201D; has become a highly respected source. To systematically explore various aspects of missing data imputation, a conceptual framework was used to uncover potential research directions and underlying themes. Ultimately, a thematic map serves as a valuable tool for providing a comprehensive understanding, categorizing significant concepts into basic or overarching, developing, or declining, central, highly developed, and isolated themes. These overarching and underlying themes offer valuable insights and pave the way for prospective directions and critical areas of study.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Heru Nugroho et al.",
      "keywords": "Missing data; Data science; Imputation (statistics); Computer science; Data quality; Field (mathematics); Thematic analysis; Data mining; Qualitative research; Sociology; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3357533",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4295854924",
      "doi": "10.1109/access.2022.3204694",
      "title": "PregnancyLine: A Visual Analysis System for Pregnancy Care and Risk Communication",
      "abstract": "Pregnancy is a long and critical period for most women and a period that has significant impacts for newborns. Many pregnancies have an increased risk for complications for a variety of reasons. Fortunately, early prenatal care and regular examination can help women have healthy pregnancies and deliver with fewer complications. However, current research shows that many expectant mothers do not have a clear understanding of the pregnancy process due to the complexity of medical information and inadequate attention from caregivers. Therefore, in this work, we collected data on expectant mothers&#x2019; requirements and investigated the various medical treatments during pregnancy and the correlations between possible symptoms and newborn diseases. Based on the above knowledge, we then developed a visual analytic system named PregnancyLine, which presents a pregnancy care plan and information on the medical examinations at each pregnancy stage using a series of vivid visual metaphors. This system is designed to improve communication between pregnant women and doctors and help doctors identify patients with abnormalities and abnormal events. The results of the evaluation and case studies indicate that our system is effective in helping pregnant women understand pregnancy risk and the importance of examinations and that it is very useful in the detection and understanding of abnormalities.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Li Li et al.",
      "keywords": "Pregnancy; Medicine; Obstetrics; Family medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3204694",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4394730883",
      "doi": "10.1109/access.2024.3387562",
      "title": "Study of the Acute Stress Effects on Decision Making Using Electroencephalography and Functional Near-Infrared Spectroscopy: A Systematic Review",
      "abstract": "This systematic review provides a comprehensive analysis of studies that use electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) to investigate how acute stress affects decision-making processes. The primary goal of this systematic review was to examine the influence of acute stress on decision making in challenging or stressful situations. Furthermore, we aimed to identify the specific brain regions affected by acute stress and explore the feature extraction and classification methods employed to enhance the detection of decision making under pressure. Five academic databases were carefully searched and 27 papers that satisfied the inclusion criteria were found. Overall, the results indicate the potential utility of EEG and fNIRS as techniques for identifying acute stress during decision-making and for gaining knowledge about the brain mechanisms underlying stress reactions. However, the varied methods employed in these studies and the small sample sizes highlight the need for additional studies to develop more standardized approaches for acute stress effects in decision-making tasks. The implications of the findings for the development of stress induction and technology in the decision-making process are also explained.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Abdualrhman Abdalhadi et al.",
      "keywords": "Electroencephalography; Stress (linguistics); Functional near-infrared spectroscopy; Spectroscopy; Computer science; Psychology; Neuroscience; Cognition; Physics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3387562",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285182715",
      "doi": "10.1109/jiot.2022.3188914",
      "title": "A Sensor Network Utilizing Consumer Wearables for Telerehabilitation of Post-Acute COVID-19 Patients",
      "abstract": "A considerable number of patients with COVID-19 suffer from respiratory problems in the post-acute phase of the disease (the second-third month after disease onset). Individual telerehabilitation and telecoaching are viable, effective options for treating these patients. To treat patients individually, medical staff must have detailed knowledge of their physical activity and condition. A sensor network that utilizes medical-grade devices can be created to collect these data, but the price and availability of these devices might limit such a network's scalability to larger groups of patients. Hence, the use of low-cost commercial fitness wearables is an option worth exploring. This article presents the concept and technical infrastructure of such a telerehabilitation program that started in April 2021 in the Czech Republic. A pilot controlled study with 14 patients with COVID-19 indicated the program's potential to improve patients' physical activity, (85.7% of patients in telerehabilitation versus 41.9% educational group) and exercise tolerance (71.4% of patients in telerehabilitation versus 42.8% of the educational group). Regarding the accuracy of collected data, the used commercial wristband was compared with the medical-grade device in a separate test. Evaluating [Formula: see text]-scores of the intensity of participants' physical activity in this test, the difference in data is not statistically significant at level [Formula: see text]. Hence, the used infrastructure can be considered sufficiently accurate for the telerehabilitation program examined in this study. The technical and medical aspects of the problem are discussed, as well as the technical details of the solution and the lessons learned, regarding using this approach to treat COVID-19 patients in the post-acute phase.",
      "year": "2022",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Miroslav Bure\u0161 et al.",
      "keywords": "Telerehabilitation; Wearable computer; Computer science; Scalability; Telemedicine; Test (biology); Multimedia; Coronavirus disease 2019 (COVID-19); Wearable technology; Physical therapy; Medicine; Health care; Disease; Database; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2022.3188914",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2999635021",
      "doi": "10.1109/access.2020.2964050",
      "title": "The Effectiveness Assessment of Massage Therapy Using Entropy-Based EEG Features Among Lumbar Disc Herniation Patients Comparing With Healthy Controls",
      "abstract": "Massage therapy (MT) is a useful complementary and alternative therapy widely used in treating low back pain (LBP), including lumbar disc herniation (LDH). However, few studies revealed the quantitative entropy-based features of electroencephalography (EEG) for the MT effectiveness for the LDH patients. This study investigated the immediate effects of Chinese massage on four EEG rhythms, using the eight entropy-based features (approximation entropy (ApEn), Sample Entropy (SampEn), wavelet entropy (WaveEn), Hilbert-Huang Transform Marginal spectrum entropy (HHTMSEn), normalized energy, permutation entropy (PE), Fuzzy entropy (FuzzyEn), and Inherent fuzzy entropy (IFE)) in the 26 LDH patients and 24 healthy controls. Results showed that after MT in LDH group, ApEn, SampEn, WaveEn, PE, FuzzyEn, and IFE features of the delta rhythm decreased, the normalized energy of delta rhythm significantly increased in the left hemisphere and theta/alpha rhythms significantly decreased. Furthermore, HHTMSEn feature of theta and beta rhythms showed the significant difference for two groups (LDH and control group) in two states (before and after massage). Ten classifiers were applied in classifying two groups or two states in one group, and most of them reached high averaged accuracies and the area under the curve (AUC), even with different length per epoch (1024, 512, and 256 points). It indicated that the entropy-based features and permutation disalignment index (PDI) of EEG rhythms could be promising indices of the massage effectiveness for LDH patients and control group. Rhythms' SampEn scalp topography in two groups showed the significant different complexity change between two states (before and after massage).",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Huihui Li et al.",
      "keywords": "Massage; Sample entropy; Electroencephalography; Delta Rhythm; Approximate entropy; Rhythm; Mathematics; Entropy (arrow of time); Medicine; Beta Rhythm; Pattern recognition (psychology); Physical therapy; Artificial intelligence; Computer science; Internal medicine; Physics; Alpha rhythm; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2964050",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3016216508",
      "doi": "10.1109/access.2020.2987073",
      "title": "Research on the Relationship Between Perceived Social Support and Exercise Behavior of User in Social Network",
      "abstract": "A growing number of information technology systems and services have occurred to change users&#x2019; attitudes or behaviors or both in the rapid development of mobile social media platforms. It is a new topic in the field of health communication whether the digitization and socialization of individual exercise behavior can stimulate health behavior. WeRun is a typical platform for the digitization and socialization of individual exercise. Based on 689 WeRun users&#x2019; questionnaires, this study first repairs the missing and abnormal data by BP neural network. Then, the decision tree is used to evaluate the relationship between the perceived social support and exercise behavior under different intervention conditions, and detects the heterogeneous intervention effects for different pre-intervention profiles. In addition, this study further discusses the performances of social support features of persuasion technology in the WeRun. The data-driven method used in this study is beneficial to reducing self-selection bias and evaluate the intervention effect. The decision tree does not require decision-makers to have much expertise or to make parameter hypotheses while evaluating the intervention effect, and the results are more direct and intelligible. The results show that the decision tree can detect the heterogeneous intervention effect. In some cases, there is not a perfectly positive correlation between the degree of perceived social support and the number of average daily steps, and the relationship with friends has a great impact on the user&#x2019;s perceived social support. In addition, it also reveals the relationship between social comparison and perceived social support, and their interaction on exercise behavior. Finally, this study provides practical suggestions for the design and operation of e-health social network platform. The platforms are supposed to take corresponding persuasive strategies according to the various characteristics of users, so as to improve the continuous attention and participation of users.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Licai Lei et al.",
      "keywords": "Computer science; Social network (sociolinguistics); Social network service; Human\u2013computer interaction; World Wide Web; Social media",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2987073",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2996789296",
      "doi": "10.1109/access.2019.2962515",
      "title": "Evaluation of Acute Tonic Cold Pain From Microwave Transcranial Transmission Signals Using Multi-Entropy Machine Learning Approach",
      "abstract": "This study aims to improve the accuracy of detecting acute tonic cold pain (CP) perception from microwave transcranial transmission (MTT) signals. Two different types of CP and no-pain (NP) MTT signals are obtained from 15 subjects. Four features, namely, power spectral exponential entropy, improved multiscale permutation entropy, refined composite multiscale dispersion entropy, and refined composite multiscale fuzzy entropy, are extracted in the variational modal decomposition domain. The feature datasets are divided into training datasets and test datasets in a 3:1 ratio. Random forest (RF) and support vector machine (SVM) are selected as classifiers. The training datasets are imported into the classifier, and the optimal training dataset is obtained with a 10-fold cross validation strategy. The feature dimension reduction algorithm of the principal component analysis is used to reduce the complexity of the feature datasets and select the most recognizable features. The classification performance of the test datasets is evaluated by the optimal classifiers. Results showed that the RF classifier performs better than the SVM classifier. The RF classifier provides high values of specificity (91.67%), sensitivity (95.83%), positive predictive value (92.00%), accuracy (93.75%), and area under curve (0.867). The combination of the microwave detection approach and machine learning algorithm can effectively detect brain activity induced by nociceptive stimulation. This approach is important in improving the accuracy of pain detection.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Daoshuang Geng et al.",
      "keywords": "Artificial intelligence; Support vector machine; Pattern recognition (psychology); Computer science; Approximate entropy; Sample entropy; Feature extraction; Entropy (arrow of time); Classifier (UML); Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2962515",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3121447748",
      "doi": "10.1109/access.2021.3052025",
      "title": "Systematic Mapping of Open Data Studies: Classification and Trends From a Technological Perspective",
      "abstract": "The objective of this paper is to classify and analyse all research on open data performed in the scientific community from a technological viewpoint, providing a detailed exploration based on six key facets: publication venue, impact, subject, domain, life-cycle phases and type of research. This paper therefore provides a consolidated overview of the open data arena that allows readers to identify well-established topics, trends, and open research issues. Additionally, we provide an extensive qualitative discussion of the most interesting findings to pave the way for future research. Our first identification phase resulted in 893 relevant peer-reviewed articles, published between 2006 and 2019 in a wide variety of venues. Analysis of the results shows that open data research grew slowly from 2006 but increased significantly as from 2009. In 2019, research interest in open data from a technological perspective overall decreased. This fact could indicate that research is beginning to stabilise, i.e., the open data research hype is over, and the research field is reaching maturity. Main findings are (i) increasing effort in researching on Semantic Web technologies as a mechanism to publish and reuse linked open data, (ii) software systems are proposed to solve open data technical problems; and (iii) considering technological aspects of legislation and standardization is needed to widely introduce open data in society. Finally, we provide complementary insights regarding open data innovation projects, with special emphasis on publication (e.g., open data portals) and consumption (e.g., open data as business enabler) of open data.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Robert Enr\u00edquez-Reyes et al.",
      "keywords": "Computer science; Data science; Open data; Open research; Standardization; Metadata; Linked data; Variety (cybernetics); Identification (biology); Publication; World Wide Web; Open science; Open innovation; Knowledge management; Semantic Web; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3052025",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394863050",
      "doi": "10.1109/access.2024.3389669",
      "title": "Applications of Deep Learning Models on the Medical Images of Osteonecrosis of the Femoral Head (ONFH): A Comprehensive Review",
      "abstract": "Deep learning models have demonstrated promising results in the early and accurate diagnosis of osteonecrosis of the femoral head (ONFH), enabling early detection and informed surgical decision-making. The objective of this review is to summarize the applications of deep learning models on the medical images of ONFH. English papers were searched from CINAHL via EBSCOhost, Embase, IEEE Xplore&#x00AE; Digital Library, PubMed, Scopus, and Web of Science. Sixteen studies (n =16) were eligible for data synthesis. Among these, five studies (n =5) focusing on radiographs, ten studies (n =10) focusing on magnetic resonance imaging, and one study (n =1) focusing on computed tomographic images. The applications of these studies included identifying ONFH from normal or other hip pathologies, classifying severity, segmenting, and detecting femoral head and necrotic regions, predicting signs and symptoms of ONFH, and predicting potential ONFH after fracture fixation. Generally, the models demonstrated good to excellent classification performance and excellent discriminatory power; and generally comparable to that of experienced physicians and superior to that of less experienced physicians. However, the external validity of these studies demonstrated only moderate, as evidenced by the performance on the external testing set and might be attributed to the relatively small data size used during model training. we observed a shift from CNN-based models to U-Net-based models (i.e., with encoder-decoder architecture). In addition to streamlining the segmentation, detection, and classification procedures, future studies will explore multimodal attention, self-supervised learning, explainable models, and data augmentation through generative models.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Jiao Wang et al.",
      "keywords": "Artificial intelligence; Femoral head; Deep learning; Machine learning; Computer science; Magnetic resonance imaging; Medical imaging; Segmentation; Medicine; Medical physics; Radiology; Surgery",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3389669",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392581078",
      "doi": "10.1109/ojcoms.2024.3373698",
      "title": "Multivariate Forecasting of Network Traffic in SDN-Based Ubiquitous Healthcare System",
      "abstract": "The emerging 5G network has been revolutionizing the data transfer across the networks. Recently, advanced technologies transform the healthcare industry. With the emergence of 5G technology, smart and ubiquitous healthcare systems are interconnected with high speed and low latency. As ubiquitous healthcare applications require stringent network requirements, managing network traffic and resources becomes difficult. Internet of Medical Things (IoMT) devices generates a large volume and variety of data, including physiological signals, images, and videos. As many medical applications require real-time communication and data transfer, this puts high demands on the network, which needs handle low latency, high availability, and high reliability. Achieving consistent QoS is challenging due to the inherent limitations of conventional methods which are susceptible to network congestion and latency issues. The next generation of Software Defined Networking (SDN) in IoMT can play a vital role in supporting traffic management. Reliable classification and forecasting will enable the SDN controller to make optimal routing decisions dynamically. Therefore in this paper, a novel Medical Traffic Forecasting framework based on Weighted Multivariate Singular Spectrum Analysis (MTF-WMSSA) is proposed for an SDN-enabled IoMT healthcare network to analyze and forecast network traffic and ensure accurate real-time medical data transfer. The evaluation was conducted on the EHMS dataset to study the performance of the proposed method. The comparison of the proposed MTF-WMSSA is made with classical methods such as SVR and LSTM. The result shows that the proposed MTF-WMSSA exhibits improved classification accuracy of 93&#x0025;. The network parameters that are forecasted are average traffic load, average packet arrival rate and average jitter. The MAPE of the multi-step ahead forecast is 13.64 and 11.41 for short and long intervals respectively. The forecasting algorithm proposed in this paper can efficiently determine future flow parameters which help to implement adaptive traffic engineering. The evaluation was conducted on the dataset to study the performance of the proposed method. The result shows that the proposed MTF-WMSSA exhibits better accuracy for multi-step ahead forecast and outperforms the classical methods.",
      "year": "2024",
      "journal": "IEEE Open Journal of the Communications Society",
      "authors": "Deva Priya Isravel et al.",
      "keywords": "Multivariate statistics; Health care; Computer science; Multivariate analysis; Healthcare system; Computer network; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcoms.2024.3373698",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206999255",
      "doi": "10.1109/tbme.2022.3144634",
      "title": "Assessing the Feasibility of Acoustic Based Seizure Detection",
      "abstract": "The results of this paper validate the feasibility of using internal physiological sounds for seizure detection, which could potentially be of use for the development of novel, wearable, very simple to use, long term monitoring, or seizure detection systems; circumventing the practical limitations of EEG monitoring outside hospital settings, or systems based on sensing modalities that work on convulsive seizures only.",
      "year": "2022",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Xuen Hoong Kok et al.",
      "keywords": "Computer science; Wearable computer; Ictal; Electroencephalography; Epilepsy; Latency (audio); Modalities; Speech recognition; Epileptic seizure; Artificial intelligence; Feature extraction; Remote patient monitoring; Pattern recognition (psychology); Medicine; Embedded system; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2022.3144634",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3211912490",
      "doi": "10.1109/jbhi.2021.3129461",
      "title": "Clustering Demographics and Sequences of Diagnosis Codes",
      "abstract": "A Relational-Sequential dataset (or RS-dataset for short) contains records comprised of a patient's values in demographic attributes and their sequence of diagnosis codes. The task of clustering an RS-dataset is helpful for analyses ranging from pattern mining to classification. However, existing methods are not appropriate to perform this task. Thus, we initiate a study of how an RS-dataset can be clustered effectively and efficiently. We formalize the task of clustering an RS-dataset as an optimization problem. At the heart of the problem is a distance measure we design to quantify the pairwise similarity between records of an RS-dataset. Our measure uses a tree structure that encodes hierarchical relationships between records, based on their demographics, as well as an edit-distance-like measure that captures both the sequentiality and the semantic similarity of diagnosis codes. We also develop an algorithm which first identifies k representative records (centers), for a given k, and then constructs k clusters, each containing one center and the records that are closer to the center compared to other centers. Experiments using two Electronic Health Record datasets demonstrate that our algorithm constructs compact and well-separated clusters, which preserve meaningful relationships between demographics and sequences of diagnosis codes, while being efficient and scalable.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Haodi Zhong et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3129461",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286377453",
      "doi": "10.1109/access.2022.3192866",
      "title": "Named Entity Recognition for Chinese Electronic Medical Records Based on Multitask and Transfer Learning",
      "abstract": "Current work on named entities for Chinese electronic medical records requires training a separate model for each different type of electronic medical record, the performance of which depends on the amount of training data available for each dataset. However, different types of electronic medical records share similar semantic information with each other, while current models do not take full advantage of this potentially common knowledge. To overcome the mentioned problem, we propose a multi-task learning framework to transfer multiple types of electronic medical records through a shared encoder. Experiments demonstrate that our model achieves substantially better performance compared with the single-task model based on BERT. F1 scores improved by more than 1&#x0025; on average across the four datasets, with individual datasets improving precision by more than 3.5&#x0025;. Further analysis shows that our model still achieves better F1 scores on long tail datasets and small size datasets.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Wenming Guo et al.",
      "keywords": "Computer science; Task (project management); Encoder; Transfer of learning; Artificial intelligence; Machine learning; F1 score; Multi-task learning; Training set; Medical record; Data mining; Information retrieval",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3192866",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3126968529",
      "doi": "10.1109/access.2021.3057770",
      "title": "A Resampling Univariate Analysis Approach to Ovarian Cancer From Clinical and Genetic Data",
      "abstract": "Ovarian cancer (OC) is the second most common gynecological malignancy and the gynecological tumor with the worst prognosis. To try to improve this situation, Data Science technologies could be a useful tool to help clinicians to know more about the disease. In our case, we are interested in exploring OC data to discover relationships between clinical and genetic factors and the disease progression. For it, we propose an analysis framework for simple and univariate statistical descriptions of features of different types, based on bootstrap resampling. Foremost, we define the framework for metric, categorical, and dates variables and determine what are the advantages and disadvantages of using different bootstrap resampling strategies, based on their statistical basis. Then, we use it to perform a univariate analysis over an OC dataset that allows to explore how is the disease progression, having platinum-free interval as indicator, in relation to clinical and genetic features of different types. Also, it provides a first set of variables possibly relevant for survival prediction. Results obtained show that some features have led to individual differences between both platinum resistant (&lt;; 6 months) and platinum sensitive(&gt;6 months) groups. It can be concluded that this could be an indicator that the database could be discriminatory for the hypotheses studied, though it is convenient to make multivariate analyses to check how relationships among features are influenced.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Luis Bote-Curiel et al.",
      "keywords": "Univariate; Resampling; Categorical variable; Computer science; Metric (unit); Ovarian cancer; Multivariate statistics; Multivariate analysis; Data mining; Statistics; Oncology; Artificial intelligence; Machine learning; Medicine; Cancer; Internal medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3057770",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386609141",
      "doi": "10.1109/access.2023.3314380",
      "title": "Radiology Decision Support System for Selecting Appropriate CT Imaging Titles Using Machine Learning Techniques Based on Electronic Medical Records",
      "abstract": "Radiologists use an imaging order from the ordering physician, which includes a radiology title, to select the most suitable imaging protocol. Inappropriate radiology titles can disrupt protocol selection and result in mistaken or delayed diagnosis. The objective of this work is to develop an algorithm to predict correct radiology titles from incoming exam order data. The proposed instrument is an ensemble of five decision tree-based machine learning (ML) techniques (Light Gradient Boosting Machine, eXtreme Gradient Boosting Machine, Random Forest, Adaptive Boosting, and Random UnderSampling Boosting Model) trained to recommend radiology titles of computed tomography imaging examinations based on electronic medical records. Issues of imbalanced data and generalization were addressed. The tuned models were used to predict the top three radiology titles for the radiologist revision. The models were evaluated using a 10-fold cross-validation method, yielding an approximate average accuracy of <inline-formula> <tex-math notation=\"LaTeX\">$80.5\\% \\pm 2.02\\%$ </tex-math></inline-formula> and F1-score of <inline-formula> <tex-math notation=\"LaTeX\">$80.3\\% \\pm 1.67\\%$ </tex-math></inline-formula> for all models, while the ensemble classifier (~83% F1-score) outperformed individual models. An accumulated average accuracy of ~92% was obtained for the top three predictions. ML techniques can predict radiology titles and identify highly important features. The proposed system can guide physicians toward selecting appropriate radiology titles and alert radiologists to inconsistencies between the radiology title in the exam order and the patient&#x2019;s underlying conditions, thereby improving imaging utility and increasing diagnostic accuracy, which favors better patient outcomes.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Peyman Shokrollahi et al.",
      "keywords": "Artificial intelligence; Machine learning; Gradient boosting; Random forest; Boosting (machine learning); Computer science; Classifier (UML); Decision tree; Medical imaging; Notation; Algorithm; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3314380",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319459176",
      "doi": "10.1109/access.2023.3243178",
      "title": "Technological Evolution in the Instrumentation of Ataxia Severity Measurement",
      "abstract": "Cerebellar ataxia is the poorly coordinated movement that results from injury or disease affecting the cerebellum. The diagnosis and assessment of ataxia are significantly challenging due to dependency on clinicians&#x2019; experience and the attendant subjectivity of such a process. In recent years, neuroimaging and sensor-based approaches, supported by effective machine learning techniques have made advances in the pursuit of addressing these clinical challenges. In this work, we present an outline of approaches to applying machine learning to this clinical challenge. We first provide a fundamental clinical overview with practical problems and then from a machine learning perspective, outline possible approaches with which to address these clinical challenges. Also discussed are the limitations in existing methods, the provision of cross disciplinary approaches and the current state-of-the-art as a potential basis for future research.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Thang Ngo et al.",
      "keywords": "Instrumentation (computer programming); Computer science; Ataxia; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3243178",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3106629539",
      "doi": "10.1109/access.2020.3041895",
      "title": "Prediction of Cocaine Inpatient Treatment Success Using Machine Learning on High-Dimensional Heterogeneous Data",
      "abstract": "The high prevalence of drug addiction is a major health challenge that pressures healthcare systems to respond with cost-effective treatments. To improve the treatment success of drug-dependent patients, it is necessary to identify the main associated risk factors for dropping out of treatment. Previous research shows disparate results due to the wide variety of approaches employed, the different and/or poorly defined metrics used, and the different target populations under study. This article presents the design and selection of a predictive model to estimate success of inpatient cocaine treatment based on a high-dimensional heterogeneous set of characteristics, with the aim of learning new associations between independent characteristics. We evaluated different feature selection techniques and machine learning algorithms to design the best predictive model in terms of accuracy, area under the receiver operating characteristic curve, recall, specificity, F1-score, and Matthews correlation coefficient. Random Forest was the top-performing model with a characteristic set consisting of 11 features selected with a wrapper evaluator and the Best First algorithm, achieving 82% accuracy, 0.81 of area under the receiver operating characteristic curve, 0.96 of recall, 0.47 of specificity, 0.89 of F1-measure and 0.53 of Matthews correlation coefficient. The predictive model's performance was enhanced by combining multiple dimensions with variables referring to previous treatments, mental exploration, cognitive functioning, personality, consumption habits, and pharmacological treatment. We have refined the use of machine learning techniques to predict drug addiction treatment success, which could represent a new step in treatment management especially when included in clinical decision support systems.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jos\u00e9 Antonio Rivera Tapia et al.",
      "keywords": "Feature selection; Machine learning; Receiver operating characteristic; Computer science; Artificial intelligence; Random forest; Recall; Addiction; Feature (linguistics); Set (abstract data type); Correlation; Matthews correlation coefficient; Data mining; Medicine; Support vector machine; Mathematics; Psychiatry; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3041895",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385453076",
      "doi": "10.1109/access.2023.3300951",
      "title": "Testing the Validity of a Spatiotemporal Gait Model Using Inertial Measurement Units in Early Parkinson\u2019s Patients",
      "abstract": "The subtle gait characteristics of early Parkinson&#x2019;s disease (EPD) patients are currently difficult to detect or require expensive, experimentally demanding testing equipment. The use of machine learning (ML) models in conjunction with inertial measurement unit (IMU) algorithms opens up new possibilities for the assessment of EPD patients. The aim of this study is to measure EPD gait using the IMU algorithm, select gait features using Recursive Feature Elimination (RFE), and classify EPD patients with healthy (HT) older adults using ML on the selected features. Firstly, 10 healthy subjects were recruited and the system parameters were validated using the double gold standard to ensure the reliability of the system. Second, 60 subjects (30 EPD patients and 30 HT elderly) were recruited to wear the system for linear walking activities and to obtain gait parameters. The results show that this system has good reliability, i.e. the best intraclass correlation coefficient (ICC) is between 0.521 and 0.941. The six best features of stride length, stance phase, stance time, swing phase variability, step speed and cadence were selected by REF and classified by decision tree (DT) with a model accuracy of 91.6&#x0025;, sensitivity and specificity of 91&#x0025; and 83&#x0025; respectively, and an ROC value of 0.92. Our results show that the use of the IMU algorithm with precise accuracy can detect subtle gait features and that the use of optimal gait features can well assess patients with EPD, providing a new way to detect EPD.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Shuai Tao et al.",
      "keywords": "Inertial measurement unit; Gait; Intraclass correlation; Cadence; STRIDE; Reliability (semiconductor); Computer science; Gait analysis; Gold standard (test); Artificial intelligence; Parkinson's disease; Physical medicine and rehabilitation; Pattern recognition (psychology); Mathematics; Medicine; Statistics; Reproducibility; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3300951",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2955172707",
      "doi": "10.1109/access.2019.2925706",
      "title": "Visualizing Literature Review Theme Evolution on Timeline Maps: Comparison Across Disciplines",
      "abstract": "Data-driven visualization techniques can be utilized to enhance the literature review process across different disciplines. In our work, 910 articles were retrieved using keyword search from bibliographic databases of two different disciplines (computer science: DBLP and medicine: MEDLINE) between 2001 and 2016. These articles' titles were processed using dynamic latent Dirichlet allocation to generate a set of themes/topics, which were subsequently classified and assigned to regions in a spatiotemporal geographical map. Resulting data visualizations from both repositories were manually reviewed by independent annotators. The results from the DBLP and MEDLINE were comparable and, taken together, suggest potential benefits of increased future interaction amongst multidisciplinary fields. Our findings indicate that spiral timeline maps have the potential to help researchers acquire or compare knowledge efficiently without prior domain knowledge.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Chunlei Tang et al.",
      "keywords": "Timeline; Computer science; Latent Dirichlet allocation; Information retrieval; Visualization; Data science; Multidisciplinary approach; Set (abstract data type); Process (computing); Theme (computing); Data visualization; Topic model; World Wide Web; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2925706",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4225504861",
      "doi": "10.1109/access.2022.3159025",
      "title": "Contribution of Deep-Learning Techniques Toward Fighting COVID-19: A Bibliometric Analysis of Scholarly Production During 2020",
      "abstract": "COVID-19 has dramatically affected various aspects of human society with worldwide repercussions. Firstly, a serious public health issue has been generated, resulting in millions of deaths. Also, the global economy, social coexistence, psychological status, mental health, and the human-environment relationship/dynamics have been seriously affected. Indeed, abrupt changes in our daily lives have been enforced, starting with a mandatory quarantine and the application of biosafety measures. Due to the magnitude of these effects, research efforts from different fields were rapidly concentrated around the current pandemic to mitigate its impact. Among these fields, Artificial Intelligence (AI) and Deep Learning (DL) have supported many research papers to help combat COVID-19. The present work addresses a bibliometric analysis of this scholarly production during 2020. Specifically, we analyse quantitative and qualitative indicators that give us insights into the factors that have allowed papers to reach a significant impact on traditional metrics and alternative ones registered in social networks, digital mainstream media, and public policy documents. In this regard, we study the correlations between these different metrics and attributes. Finally, we analyze how the last DL advances have been exploited in the context of the COVID-19 situation.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Janneth Chicaiza et al.",
      "keywords": "Mainstream; Coronavirus disease 2019 (COVID-19); Context (archaeology); Pandemic; Production (economics); Social media; Computer science; Data science; Political science; Public relations; Social science; Sociology; Economics; Geography; Law",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3159025",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394862720",
      "doi": "10.1109/access.2024.3390008",
      "title": "Health-Related Data Analysis Using Metaheuristic Optimization and Machine Learning",
      "abstract": "Health-related data has a decisive role in disease diagnosis. Collecting relevant information from health-related data in medical records has been facilitated by evaluating the features of the data. Relevant research has shown that outcomes are significantly impacted by the use of feature selection (FS) in different medical domain data. FS provides an analysis of the most significant features to improve classification accuracy. The FS technique aims at minimizing the number of input variables and computational overload to maximize classification performance results. However, identifying the optimal features poses issues due to the high dimensionality of large features and the small sample size of health-related data. The metaheuristics optimization algorithm (MOA) plays an important role in generating the best subset features with exploration and exploitation phases. This study experiments with well-known MOAs and supervised learning from the UC Irvine Machine Learning Repository, PhysioNet, Kent Ridge Bio-Medical Dataset, and MIMIC-III v1.4 Repository with varying feature dimensions. To increase the quality of health-related data, this study proposes missing data imputation based on a deep learning approach, an autoencoder (AE). With AE imputation, the performance results obtain 0.0167 mean squared error (MSE) and 0.129 root mean squared error (RMSE). As a result, MOA shows its excellence in achieving minimal features, but still outstanding performance in low- and high-dimensional data. MOA is successfully applied to varying diverse health-related datasets with low- and high-dimensional data.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Annisa Darmawahyuni et al.",
      "keywords": "Metaheuristic; Computer science; Machine learning; Artificial intelligence; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3390008",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4360584309",
      "doi": "10.1109/access.2023.3260215",
      "title": "Distributed Neural Network System for Multimodal Sleep Stage Detection",
      "abstract": "Existing automatic sleep stage detection methods predominantly use convolutional neural network classifiers (CNNs) trained on features extracted from single-modality signals such as electroencephalograms (EEG). On the other hand, multimodal approaches propose very complexly stacked network structures with multiple CNN branches merged by a fully connected layer. It leads to very high computational and data requirements. This study proposes replacing a stacked network with a distributed neural network system for multimodal sleep stage detection. It has relatively low computational and training data requirements while providing highly competitive results. The proposed multimodal classification and decision-making system (MM-DMS) method applies a fully connected shallow neural network, arbitrating between classification outcomes given by an assembly of independent convolutional neural networks (CNNs), each using a different single-modality signal. Experiments conducted on the CAP Sleep Database data, including the EEG-, ECG-, and EMG modalities representing six stages of sleep, show that the MM-DMS significantly outperforms each single-modality CNN. The fully-connected shallow network arbitration included in the MM-DMS outperforms the traditional majority voting-, average probability-, and maximum probability decision-making methods.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Yi-Hsuan Cheng et al.",
      "keywords": "Computer science; Modality (human\u2013computer interaction); Convolutional neural network; Artificial intelligence; Artificial neural network; Pattern recognition (psychology); Deep learning; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3260215",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2271080377",
      "doi": "10.1109/tmm.2016.2589160",
      "title": "ConfidentCare: A Clinical Decision Support System for Personalized Breast Cancer Screening",
      "abstract": "Breast cancer screening policies attempt to achieve timely diagnosis by the regular screening of apparently healthy women. Various clinical decisions are needed to manage the screening process; those include: selecting the screening tests for a woman to take, interpreting the test outcomes, and deciding whether or not a woman should be referred to a diagnostic test. Such decisions are currently guided by clinical practice guidelines (CPGs), which represent a one-size-fits-all approach that are designed to work well on average for a population, without guaranteeing that it will work well uniformly over that population. Since the risks and benefits of screening are functions of each patients features, personalized screening policies that are tailored to the features of individuals are needed in order to ensure that the right tests are recommended to the right woman. In order to address this issue, we present ConfidentCare: a computer-aided clinical decision support system that learns a personalized screening policy from the electronic health record (EHR) data. ConfidentCare operates by recognizing clusters of similar patients, and learning the best screening policy to adopt for each cluster. A cluster of patients is a set of patients with similar features (e.g. age, breast density, family history, etc.), and the screening policy is a set of guidelines on what actions to recommend for a woman given her features and screening test scores. ConfidentCare algorithm ensures that the policy adopted for every cluster of patients satisfies a predefined accuracy requirement with a high level of confidence. We show that our algorithm outperforms the current CPGs in terms of cost-efficiency and false positive rates.",
      "year": "2016",
      "journal": "IEEE Transactions on Multimedia",
      "authors": "Ahmed M. Alaa et al.",
      "keywords": "Test (biology); Set (abstract data type); Breast cancer screening; Population; Medicine; Breast cancer; Cluster (spacecraft); Clinical decision support system; Cancer screening; Screening test; Personalized medicine; Computer science; Family medicine; Mammography; Decision support system; Cancer; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tmm.2016.2589160",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385819885",
      "doi": "10.1109/access.2023.3305256",
      "title": "A Multi-Spectral Image Database for In-Vivo Hand Perfusion Evaluation",
      "abstract": "The increasing prevalence of vascular diseases encourages the development of minimally invasive approaches to assess tissue perfusion. A significant challenge facing current state-of-the-art methods is their validation against clinical data. In this study, we introduce an open-source database designed to evaluate tissue perfusion during the application of an occlusion protocol. The database comprises sequences of multi-spectral images (visible and near-infrared region) from the subjects&#x2019; predominant hand and their photoplethysmography data for validation. Our study recruited 45 healthy participants, including 21 females, with an age range between 18&#x2013;24 years old (standard deviation equal to 1.73). The database was evaluated using two methods for estimating skin perfusion parameters based on multi-spectral images: a Kubelka-Munk model, and a linear regression. Meanwhile, for validation purposes, the changes in oxygenated and deoxygenated hemoglobin were evaluated by photoplethysmography data as baseline perfusion parameters. The Pearson correlation between plethysmography-based perfusion parameters and those extracted from multi-spectral images was evaluated in all cases as a validation metric. Our findings demonstrated a strong Pearson correlation (<inline-formula> <tex-math notation=\"LaTeX\">$\\rho &gt;0.7$ </tex-math></inline-formula>) between changes in oxygenated and deoxygenated hemoglobin and multi-spectral based perfusion parameters, suggesting that the database is useful for further research related to in-vivo perfusion assessment. The primary objective of this database is to provide open-source data from a controlled occlusion protocol to evaluate new approaches based on multi-spectral images in the visible and near-infrared regions. In addition, the validation by photoplethysmography data facilitates the development and assessment of innovative tissue perfusion estimation techniques.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Omar Guti\u00e9rrez-Navarro et al.",
      "keywords": "Photoplethysmogram; Perfusion; Database; Computer science; Pearson product-moment correlation coefficient; Metric (unit); Biomedical engineering; Artificial intelligence; Pattern recognition (psychology); Medicine; Mathematics; Computer vision; Radiology; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3305256",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391935969",
      "doi": "10.1109/ojemb.2024.3367236",
      "title": "A Reinforcement Learning Model for Optimal Treatment Strategies in Intensive Care: Assessment of the Role of Cardiorespiratory Features",
      "abstract": "<i>Goal:</i> The purpose of this study is to evaluate the importance of cardiorespiratory variables within a Reinforcement Learning (RL) recommendation system aimed at establishing optimal strategies for drug treatment of septic patients in the intensive care unit (ICU). <i>Methods:</i> We developed a RL model in order to establish drug administration strategies for septic patients using only a set of cardiorespiratory variables. We then compared this model with other RL models trained with a different set of features. We selected patients meeting the Sepsis-3 criteria from the Multi-parameter Intelligent Monitoring in Intensive Care (MIMIC III) database, resulting in a total of 20,496 ICU admissions. A Markov Decision Process (MDP) was built on the extracted discrete time-series. A policy iteration algorithm was used to obtain the optimal AI policy for the MDP. The policy performance was then evaluated using the WIS estimator. The process was repeated for each set of variables and compared to a set of baseline benchmark policies. <i>Results:</i> The model trained with cardiorespiratory variables outperformed all other models considered, resulting in a 95% confidence lower bound score of 97.48. This finding highlights the importance of cardiovascular variables in the clinical RL recommendation system. <i>Conclusions:</i> We established an efficient RL model for sepsis treatment in the ICU and demonstrated that cardiorespiratory variables provides critical information in devising optimal policies. Given the potentially continuous availability of cardiorespiratory features extracted from bedside physiological waveform monitoring, the proposed framework paves the way for a real time recommendation system for sepsis treatment.",
      "year": "2024",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Cristian Drudi et al.",
      "keywords": "Reinforcement learning; Computer science; Estimator; Intensive care; Benchmark (surveying); Artificial intelligence; Set (abstract data type); Machine learning; Intensive care unit; Medicine; Mathematics; Statistics; Intensive care medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2024.3367236",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3118244687",
      "doi": "10.22489/cinc.2020.389",
      "title": "Machine Learning to Predict 30 days and 1-year Mortality in STEMI and Turndown Patients",
      "abstract": "Primary percutaneous coronary intervention (PPCI) is a minimally invasive procedure to unblock the arteries which carry blood to the heart. Referred patients are accepted or turned down for PPCI mainly based on the presence of ST segment elevation on the surface electrocardiogram. We explored the features which predict 30 days and 1-year mortality in accepted and turndown patients and report the performance of machine learning (ML) algorithms. Different ML algorithms, namely multiple logistic regression (MLR), decision tree (DT), and a support vector machine (SVM) were used for the prediction of 30 days and 1-year mortality. Upon significance of various features to predict the 30 days and 1-year mortality, the accuracy, sensitivity, and specificity were compared between algorithms. DT outperformed the other algorithms (SVM and MLR) to predict mortality of patients referred to the PPCI service. Greater sensitivity is achieved in predicting 30 days mortality in the accepted group compared to the turndown group, however, the former model included more features.",
      "year": "2020",
      "journal": "Computing in cardiology",
      "authors": "Aleeha Iftikhar et al.",
      "keywords": "Internal medicine; Cardiology; Medicine; Computer science; Emergency medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.22489/cinc.2020.389",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388820041",
      "doi": "10.1109/access.2023.3334678",
      "title": "Breast Cancer Classification Based on DNA Microarray Analysis",
      "abstract": "Objective: Predicting the ability of a breast cancer patient to survive was a difficult research problem for many scholars. Since the early dates of the relevant research, significant progress has been recorded in many related areas. For example, with pioneering biomedical technologies, credits to low-cost computer hardware and software, high-quality data is gathered and stored automatically, and lastly, with better analytical methods, that massive data is processed efficiently and effectively. Therefore, the objective of this document is to submit a report on a research project in which we have benefited from the technological developments available to develop predictive models of breast cancer and whether it exists or not. Methods and materials: artificial neural network, support vector machine, decision trees, na&#x00EF;ve bayes, and random forest algorithms are used along with the most common statistical method (logistic regression) to build prediction models using a large data set. We also used the Holdout method. To avoid the unbalanced nature of the classes, the parameters of the performance evaluation are predefined. Results: The results show that the Decision Tree (DT) is the top predictor with 89.1% accuracy on the holdout sample, surpassing all prediction accuracy reported in the literature; Artificial Neural Networks (ANN) came out to be the second with 88.9% accuracy; Na&#x00EF;ve Bayes (NB) came out to be the third with 83.3% accuracy, Support Vector Machines (SVM) came out to be the fourth with 83.2% accuracy, and the Random Forest (RF) models came out to be the lowest of the five with 71.2% accuracy. Conclusion: A comparative study of multiple predictive models for breast cancer survival using a large set of data and 5-fold cross-validation gave us an insight into the relative ability to predict different data extraction methods. After analyzing the data, we have reached this conclusion: the model is able to help those who need it by predicting whether they have breast cancer or not. Furthermore, the proposed framework is valuable tool in cancer research and clinical practice.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sahar A. El-Rahman et al.",
      "keywords": "Random forest; Decision tree; Support vector machine; Computer science; Machine learning; Artificial neural network; Artificial intelligence; Naive Bayes classifier; Data mining; Tree (set theory); Logistic regression; Software; Data set; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3334678",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387886329",
      "doi": "10.1109/access.2023.3327126",
      "title": "Ensemble Learning to Identify Depression Indicators for Korean Farmers",
      "abstract": "Understanding the factors contributing to depression in farmers is crucial for ensuring their well-being and productivity. To address this issue, our study delves into depression factors among farmers, employing advanced tree-based machine learning (ML) algorithms, specifically focusing on the Category Boosting (CatB) algorithm. Applying the Patient Health Questionnaire-9 (PHQ-9) criteria, 2,446 individuals among 14,810 repondents were classified into depression including mild symptoms. In the classification, CatB achieved an impressive 79.7&#x0025; accuracy and 81.4&#x0025; F1 score compared to the other tree-based ensemble models (Random Forest - RF, Extra Trees - ET, and XGBoost - XGB). RF showed the highest sensitivity at 90.0&#x0025; and the 81.3&#x0025; F1 score followed by CatB. For the feature importances, the Gini impurity was predominantly used to assess in the RF and ET models. Through the analysis of feature importances, &#x2018;Health&#x2019;, &#x2018;Sleep time&#x2019;, &#x2018;Busyness&#x2019;, &#x2018;Income&#x2019;, and &#x2018;Frequency of wearing protective gear&#x2019; were identified as significant features. These results highlighted the significance of treatment strategies for individuals at high risk. and developing treatment strategies for high-risk individuals in the agricultural sector. Empowering healthcare providers by giving them access to this tool can lead to more effective interventions, potentially reducing the burden of depression and enhancing farmers&#x2019; productivity.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jinwoo Park et al.",
      "keywords": "Psychological intervention; Random forest; Machine learning; Artificial intelligence; Boosting (machine learning); Mental health; Depression (economics); Patient Health Questionnaire; Productivity; Computer science; Decision tree; Medicine; Environmental health; Psychiatry; Economics; Depressive symptoms",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3327126",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389332134",
      "doi": "10.1109/access.2023.3339610",
      "title": "Chinese Medical Named Entity Recognition Based on Fusion of Global Features and Multi-Local Features",
      "abstract": "Chinese medical Named Entity Recognition (NER) is a task of Natural Language Processing (NLP), which aims to extract key information from Chinese medical texts. Recently, Transformer becomes the mainstream approach for NLP due to its powerful capability for global feature extraction. However, entities usually appear in the form of subsequences in NER, therefore the local features are not negligible, and the uncertainty of Chinese word segmentation increases the difficulty of this task. In this paper, we propose a network structure that combines global feature extraction and multi-local feature extraction to enhance the performance of Chinese medical NER. Based on the global feature extracted by the Transformer, Bi-LSTM is used to extract the multi-local features, and a context integration mechanism is used to enhance local features by integrating both forward and backward global contexts in each cell. This allows for a more comprehensive representation of individual cells. And a feature fusion method based on attention mechanism is proposed, which allows the decoder to better focus on the more important information for predicting the current character. During the global feature extraction, the flat-lattice structure is introduced to generate all the potential results of Chinese word segmentation. And the span-based relative positional encoding integrates direction and distance perception, which overcomes the shortcoming of Transformer&#x2019;s inability to capture sequential characteristics. Finally, a CRF with conditional constraints is used as the decoder of the model. Experimental results on two benchmark datasets show the effectiveness of our model, and the method significantly outperforms the state-of-the-art methods in the medical NER task, achieving <inline-formula> <tex-math notation=\"LaTeX\">$F1$ </tex-math></inline-formula> value of 93.64&#x0025; on CCKS2017 and 85.01&#x0025; on CCKS2019.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Huarong Sun et al.",
      "keywords": "Computer science; Artificial intelligence; Feature extraction; Conditional random field; Named-entity recognition; Segmentation; Natural language processing; Classifier (UML); Information extraction; Text segmentation; CRFS; Encoder; Sequence labeling; Feature (linguistics); Pattern recognition (psychology); Task (project management)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3339610",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4315778391",
      "doi": "10.1109/access.2023.3236506",
      "title": "Designing Very Fast and Accurate Convolutional Neural Networks With Application in ICD and Smart Electrocardiograph Devices",
      "abstract": "An implantable cardioverter-defibrillator (ICD) is a device that must detect VT and VF arrhythmias on time and treat them. In this project, three CNN networks are designed to introduce the practical methods of using deep learning in heart electrophysiology signals processing. This project presents two speedy intelligent detection methods of ventricular fibrillation and ventricular tachycardia arrhythmias for ICD devices. It also provides another quick, innovative diagnosis method for use in intelligent electrocardiograph devices to detect abnormal cardiac signals. The first network is 1D-CNN for smart electrocardiographic devices to detect abnormal ECG signals. Dataset MIT-BIH has been used to train this network. This network with the most optimal number of parameters due to high detection speed has a high accuracy of 91&#x0025;. The second and third networks are 2D-CNNs for use in implantable defibrillators. For the second network, a data set of 20 patients with cardiac arrhythmia and 20 patients without cardiac arrhythmia in an 8-month period of ICD check-up has been prepared. The third network is trained using the Spontaneous Ventricular Tachyarrhythmia Database. The second and third networks are designed to detect EGM signals in VF and VT modes with the optimal number of parameters and 100&#x0025; accuracy in the second network and 90&#x0025; in the third network. All three designed networks are in an optimal condition regarding the number of parameters and layers, so they have optimal speed and energy consumption.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Alireza Keyanfar et al.",
      "keywords": "Ventricular tachycardia; Computer science; Convolutional neural network; Ventricular fibrillation; Artificial neural network; Deep learning; Artificial intelligence; Pattern recognition (psychology); Medicine; Cardiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3236506",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389076602",
      "doi": "10.1109/access.2023.3337658",
      "title": "Out-of-Distribution Data Generation for Fault Detection and Diagnosis in Industrial Systems",
      "abstract": "The emergence of Industry 4.0 has transformed modern-day factories into high-tech industrial sites through rapid automation and increased access to real-time data. Deep learning approaches possessing superior capabilities for intelligent, data-driven fault diagnosis have become critical in ensuring process safety and reliability in these industrial sites. However, such applications trained exclusively on in-distribution process data face challenges in the wake of previously unseen out-of-distribution (OOD) data in the real world. This paper addresses the challenge of out-of-distribution data detection for deep learning-based fault diagnosis models by generating synthetic data to simulate real-world anomalies not present in the training set. We propose Manifold Guided Sampling (MGS), a data-driven method for generating synthetic OOD samples from the in-distribution data-supporting manifold estimated through a deep generative model. Synthetic data from MGS enhances the model capacity for prediction uncertainty quantification, resulting in safe and reliable models for real-world industrial process monitoring. Furthermore, the MGS algorithm maintains the in-distribution data feature space as a reference point during data generation to ensure the resulting synthetic OOD data is realistic. We analyze the effectiveness of MGS through experiments conducted on the steel plates faults dataset and demonstrate that augmenting training data with synthetic data from MGS enhances the model performance in OOD detection tasks and provides robustness against dataset distributional shifts. The findings underscore the effectiveness of utilizing synthetic MGS-generated OOD data in scenarios where real-world OOD data is limited, enabling better generalization and more reliable fault detection in practical applications.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jefkine Kafunah et al.",
      "keywords": "Computer science; Robustness (evolution); Data modeling; Fault detection and isolation; Data mining; Artificial intelligence; Generative model; Machine learning; Synthetic data; Data set; Process (computing); Generative grammar; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3337658",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391759526",
      "doi": "10.1109/tnnls.2024.3360641",
      "title": "Learning Ordinal\u2013Hierarchical Constraints for Deep Learning Classifiers",
      "abstract": "Real-world classification problems may disclose different hierarchical levels where the categories are displayed in an ordinal structure. However, no specific deep learning (DL) models simultaneously learn hierarchical and ordinal constraints while improving generalization performance. To fill this gap, we propose the introduction of two novel ordinal-hierarchical DL methodologies, namely, the hierarchical cumulative link model (HCLM) and hierarchical-ordinal binary decomposition (HOBD), which are able to model the ordinal structure within different hierarchical levels of the labels. In particular, we decompose the hierarchical-ordinal problem into local and global graph paths that may encode an ordinal constraint for each hierarchical level. Thus, we frame this problem as simultaneously minimizing global and local losses. Furthermore, the ordinal constraints are set by two approaches [ordinal binary decomposition (OBD) and cumulative link model (CLM)] within each global and local function. The effectiveness of the proposed approach is measured on four real-use case datasets concerning industrial, biomedical, computer vision, and financial domains. The extracted results demonstrate a statistically significant improvement to state-of-the-art nominal, ordinal, and hierarchical approaches.",
      "year": "2024",
      "journal": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Riccardo Rosati et al.",
      "keywords": "Ordinal regression; Ordinal optimization; Ordinal data; Generalization; Computer science; Artificial intelligence; Hierarchical database model; Constraint (computer-aided design); Binary number; Ordinal Scale; Set (abstract data type); Machine learning; Theoretical computer science; Mathematics; Data mining; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnnls.2024.3360641",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3207494651",
      "doi": "10.1109/ojies.2021.3121549",
      "title": "Blockchain for Development in the Era of the COVID-19 Pandemic",
      "abstract": "In the context of Informationand Communication Technologies (ICT) for Development (ICT4D), several efforts have been carried out over the last decades to help developing countries address their challenges. In times of a pandemic, such as the COVID-19, several of these challenges gain higher priority in development as they may become unmanageable with the developing world&#x0027;s resources. Blockchain is a disruptive technology that could potentially enable the sustainable addressing of some of them, and COVID-19 offers a unique and timely opportunity to operationalize it. Driven by the research question &#x201C;In what areas can Blockchain help address development challenges during a pandemic?&#x201D; we aim to understand its applicability in addressing crucial social problems in developing countries. While the literature analysis points towards several promising areas, there are also significant concerns that need to be understood and carefully addressed when considering Blockchain in the context of developing countries. The critical discourse in this work is expected to benefit a wide variety of technology, policy, and research stakeholders.",
      "year": "2021",
      "journal": "IEEE Open Journal of the Industrial Electronics Society",
      "authors": "Stamatis Karnouskos",
      "keywords": "Operationalization; Pandemic; Blockchain; Context (archaeology); Developing country; Variety (cybernetics); Coronavirus disease 2019 (COVID-19); Work (physics); Political science; Business; Economic growth; Computer science; Computer security; Economics; Geography; Engineering; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojies.2021.3121549",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389332157",
      "doi": "10.1109/access.2023.3339530",
      "title": "Exploring the Impact of Signal Quality Enhancement on Heart Sound Classification Models",
      "abstract": "Limited cardiology resources increase the urgency for automated heart disease screening for the general public. Heart sound diagnostic models have been recently employed as a cost-effective solution for the initial screening of heart disease. Noise in heart sound recordings, however, can reduce the performance of such data-driven models. Various quality enhancement approaches have been adopted to alleviate the destructive impact of noise on model performance. One approach is universal noise reduction which applies denoising techniques to recordings, irrespective of their noise level. The second approach is targeted noise reduction, which applies denoising solely to recordings deemed to need it, based on an assessment of signal noise level. The third approach is filtering where instead of noise reduction, the quality of recordings is assessed and the signals falling below a minimum threshold of quality are discarded. This study aims to understand which quality enhancement approach leads to a more accurate heart sound classification. We developed multiple data-driven models using different classifiers and feature representations and analyzed the impact of quality enhancement on the accuracy of those models. The results indicate that noise reduction is associated with an overall performance drop in classification models. We observe that both universal and targeted noise reduction have a destructive impact on models\u2019 performance. However, filtering improves the accuracy of the models, in particular, for the clinically important abnormal class. The findings of this study can be leveraged to inform the design decisions for the pre-processing of heart sound recordings and consequently optimize downstream classification performance.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Davoud Shariat Panah et al.",
      "keywords": "Computer science; Quality (philosophy); Sound quality; Speech recognition; Sound (geography); Bioacoustics; Acoustics; Telecommunications; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3339530",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226203977",
      "doi": "10.1109/access.2022.3159653",
      "title": "Modeling Neonatal EEG Using Multi-Output Gaussian Processes",
      "abstract": "Neonatal seizures are sudden events in brain activity with detrimental effects in neurological functions usually related to epileptic fits. Though neonatal seizures can be identified from electroencephalography (EEG), this is a challenging endeavour since expert visual inspection of EEG recordings is time consuming and prone to errors due the data's nonstationarity and low signal-to-noise ratio. Towards the greater aim of automatic clinical decision making and monitoring, we propose a multi-output Gaussian process (MOGP) framework for neonatal EEG modelling. In particular, our work builds on the multi-output spectral mixture (MOSM) covariance kernel and shows that MOSM outperforms other commonly-used covariance functions in the literature when it comes to data imputation and hyperparameter-based seizure detection. To the best of our knowledge, our work is the first attempt at modelling and classifying neonatal EEG using MOGPs. Our main contributions are: i) the development of an MOGP-based framework for neonatal EEG analysis; ii) the experimental validation of the MOSM covariance kernel on real-world neonatal EEG for data imputation; and iii) the design of features for EEG based on MOSM hyperparameters and their validation for seizure detection (classification) in a patient specific approach.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Victor Caro et al.",
      "keywords": "Computer science; Electroencephalography; Gaussian process; Gaussian; Neuroscience; Physics; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3159653",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210840000",
      "doi": "10.1109/access.2022.3149349",
      "title": "Towards Data Driven Spatio-Temporal Threshold Identification Based on Cost Effective Public Health Information Management Framework",
      "abstract": "Appropriate public health action comes from data driven decision support systems. While sophisticated health information exchange framework may be costly in developing countries, the health care delivery system in place may provide a promising infrastructure that spans all parts in a region. Therefore, while digital and non digital data is constantly being generated from variety of sources including public and private health sectors, the health care delivery systems remain the primary and most fundamental source for data on population health status. For low and middle income countries with minimum digitization and resource constraints, traditional existing health care delivery system can be taken advantage of, for efficient production and timely transmission and utilisation of data to identify thresholds for disease outbreak in order to improve health status and health system performance. Due to lack of appropriate universally agreed criteria for threshold, defining local thresholds for infectious disease is not only crucial but also more appropriate. In this paper, we present a low cost data driven framework called Health Data Driven Framework (HDDF) through which data generated at health care facilities may be used for threshold detection and alarm generation. We also identify a localized method based on spatio-temporal mining of available data for appropriate threshold identification.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Muhammad Nazakat et al.",
      "keywords": "Health care; Computer science; Identification (biology); Risk analysis (engineering); Digitization; Public health; Data science; Business; Data mining; Medicine; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3149349",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210906858",
      "doi": "10.1109/access.2022.3149477",
      "title": "A Calibrated Ensemble Algorithm to Address Data Heterogeneity in Machine Learning: An Application to Identify Severe SLE Flares in Lupus Patients",
      "abstract": "Motivated to address the inconsistency between the essential i.i.d. assumption in machine learning theory and the data heterogeneity in real-world applications, we propose a novel calibrated ensemble (CE) algorithm to facilitate learning with diverse data subgroups. Unlike the traditional ensemble framework in which each learner is trained independently using the entire dataset, our method exploits the strengths of various machine learning models by training them simultaneously and forming model-ergonomic data subgroups as part of the training process. Consequently, each learner is calibrated to a unique subset of data based on their individualized predictive strength. Clinically, we can interpret each model as an expert specializing in treating patients with particular disease manifestations. We evaluate the CE model in our motivating domain of identifying lupus patients with severe SLE flares using 1541 clinical encounters in the Mass General Brigham (MGB) Lupus Cohort. Our experimental results demonstrate the efficacy of our CE model across seven performance evaluation metrics compared to five individual machine learning models and regular ensemble approaches. We further utilize ANOVA and Tukey HSD post-hoc statistical analysis to discover characteristic features of individual model clusters for clinical interpretations.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Yijun Zhao et al.",
      "keywords": "Machine learning; Artificial intelligence; Computer science; Ensemble learning; Systemic lupus erythematosus; Post hoc; Process (computing); Support vector machine; Exploit; Ensemble forecasting; Algorithm; Disease; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3149477",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2974376069",
      "doi": "10.1109/access.2019.2942764",
      "title": "Detection of Acute Tonic Cold Pain From Microwave Transcranial Transmission Signals Obtained via the Microwave Scattering Approach",
      "abstract": "To investigate the feasibility of detecting acute tonic cold pain (CP) perception from recordable microwave transcranial transmission (MTT) signals by using machine learning techniques. CP and no-pain (NP) MTT signals collected from 15 young subjects are analyzed in the wavelet packet transformation (WPT) and variational mode decomposition (VMD) domains. In addition, features such as relative energy change, refined composite multiscale dispersion entropy, refined composite multiscale fuzzy entropy, and autoregressive model coefficients are extracted in the WPD, VMD, VMD-WPD, and WPD-VMD domains. Simultaneously, support vector machine (SVM) is selected as the classifier, and feature indexes are input into the classifier by using the 10-fold cross validation method to obtain the best training and test datasets. Principal component analysis is used to reduce the feature dimensions of the training and test datasets and to improve classification accuracy. Then, the test dataset is imported into the trained classifier for the calculation and evaluation of the model's classification performance. In the validation of the SVM classifier, feature extraction in the WPD-VMD domain is the best pain detection algorithm. It provides high values of sensitivity (91.30%), specificity (90.47%), positive predictive value (91.30%), accuracy (90.90%), and area under curve (0.806). The microwave scattering technique can be used as a direct, objective, and experimentally stable method to detect acute CP perception, this approach has a high application prospect for clinical real-time diagnosis.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Daoshuang Geng et al.",
      "keywords": "Artificial intelligence; Support vector machine; Pattern recognition (psychology); Feature extraction; Computer science; Approximate entropy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2942764",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3043658497",
      "doi": "10.1109/access.2020.3009412",
      "title": "Application of Massive Parallel Deep Learning Algorithm in the Prediction of Colorectal Carcinogenesis of Familial Polyposis",
      "abstract": "Based on the massively parallel deep learning algorithm, this paper studies familial polyposis colorectal carcinogenesis, and proposes a semi-supervised multi-task survival analysis method based on deep learning, which transforms the survival analysis problem into multi-timepoint survival probability prediction. The multi-task learning model is composed of semi-supervised learning problems. We use semi-supervised loss and sorting loss to deal with data of censorship and the non-increasing probability of survival probability. It established a prognostic risk prediction model for familial polyposis colorectal cancer based on a semi-supervised logistic regression method and learns from supervised learning from five aspects of discriminating ability, interpretability, and clinical practicality. The method comparison expands the current understanding of the generalization capabilities of different models and provides a reference for the establishment of clinical prediction models. The effectiveness of this method was verified by external data and provided technical support for constructing a prognostic model with application value for multi-center real clinical data. This model has demonstrated better prediction performance than common models in the prognostic task of familial polyposis colorectal cancer, and successfully described the mechanism of action of predictors.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Fuqiang Zhang et al.",
      "keywords": "Interpretability; Artificial intelligence; Computer science; Machine learning; Logistic regression; Colorectal cancer; Deep learning; Medicine; Cancer; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3009412",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2972568547",
      "doi": "10.1109/access.2019.2940772",
      "title": "A Systematic Literature Review of the Pain Management Mobile Applications: Toward Building a Conceptual Model",
      "abstract": "In healthcare, mobile-based interventions support the improvement of clinical process and result in a positive behavioral change and improve the patients' health condition. This study aims at reviewing mobile applications documented for pain management in the scientific databases, to identify the key factors that are vital for pain management. In this research, a systematic literature review was conducted on the selected studies collected from five scientific databases: Medline, PubMed, EMBASE, Web of Science and Scopus. After applying the inclusion and exclusion criteria and performing the quality assessment, twenty-five studies were finalized. It has been observed that the apps were not all-inclusive in features to provide an effective pain self-management solution. As found from the review, the general features of the pain management mobile applications are pain information, pain coping strategy, social support, sub-goals and achievements, self-reporting, feedback, and patient report. Some apps involved psychological interventions. A prominent technique found was cognitive behavior therapy. This study has contributed to the body of knowledge by proposing a conceptual model in guiding the development of pain management mobile applications. The conceptual model was evaluated by a panel of experts to evaluate comprehensiveness, accuracy, and dependencies among the elements of the model, and the appropriateness of the proposed model. Experts recognized the importance of pain management and provided positive feedback to the proposed model.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Umm e Mariya Shah et al.",
      "keywords": "Psychological intervention; Scopus; MEDLINE; Computer science; Conceptual model; Cognition; Systematic review; Conceptual framework; Knowledge management; Pain management; Applied psychology; Psychology; Medicine; Physical therapy; Nursing; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2940772",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3216157363",
      "doi": "10.1109/access.2021.3130937",
      "title": "A Personality Mining System for German Twitter Posts With Global Vectors Word Embedding",
      "abstract": "People&#x2019;s personality influences their behaviors, attitudes, beliefs, and feelings. Therefore, many scientific studies already benefit from easy ways of measuring personality. By analyzing the written text of a person, it is possible to derive Big Five personality traits. One approach to this is to apply the unsupervised learning algorithm Global Vectors Word Embedding (or Representation), abbreviated GloVe, to English Twitter posts. The overall objective of our research is to show that this algorithm can also be applied to German Twitter posts. Therefore, we built a framework for training and applying machine learning models for personality predictions. We tested if a working prediction model for English Twitter users can be adapted for German users. This could reduce efforts for collecting training data. We evaluated our models based on a personality survey with a sample of German users. The method of adapting an existing model does not perform as well as expected but helps prepare the framework for higher volumes of data. In the end, the final model is based on the evaluation data, which results in an acceptable performance. Via a web application (<uri>https://www.miping.de</uri>) anyone can easily retrieve personality scores for any public German Twitter user. Altogether, it is shown that GloVe is suitable to predict personality based on German language. The published framework and source code allow for independent improvements to and easy application of the trained model. Now, scientific studies and other applications, e.g., chatbots, could easily incorporate personality data.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Henning Usselmann et al.",
      "keywords": "German; Word embedding; Personality; Computer science; Embedding; Artificial intelligence; Natural language processing; Word (group theory); Web application; Code (set theory); Big Five personality traits; Sample (material); Feeling; Machine learning; Data science; World Wide Web; Psychology; Linguistics; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3130937",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392007260",
      "doi": "10.1109/access.2024.3368504",
      "title": "Multilevel Multimodal Framework for Automatic Collateral Scoring in Brain Stroke",
      "abstract": "In patients with ischemic brain stroke, collateral circulation plays a crucial role in selecting patients suitable for endovascular therapy. The presence of well-developed collaterals improves the patient&#x2019;s chances of recovery. In clinical practice, the presence of collaterals is diagnosed on a Computed Tomography Angiography scan. The radiologist grades it on the basis of subjective visual assessment, which is prone to interobserver and intraobserver variability. Computer-based methods of collateral assessment face the challenge of non-uniform scan volume, leading to manual selection of slices, meaning that the most imperative slices have to be manually selected by the radiologist. This paper proposes a multilevel multimodal hierarchical framework for automated collateral scoring. Specifically, we propose deploying a Convolutional Neural Network for image selection based on the visibility of collaterals and a multimodal model for comparing the occluded and contralateral sides of the brain for collateral scoring. We also generate a patient-level prediction by integrating automated machine learning in the proposed framework. While the proposed multimodal predictor contributes to Artificial Intelligence, the proposed end-to-end framework is an application in engineering. The proposed framework has been trained and tested on 116 patients, with five-fold cross-validation, achieving an accuracy of 91.17&#x0025; for multi-class collateral scores and 94.118&#x0025; for binary class collateral scores. The proposed multimodal predictor achieved a weighted F1 score of 0.86 and 0.95 on multi-class and binary-class collateral scores, respectively. The proposed framework is fast, efficient, and scalable for real-world deployments. Automated evaluation of collaterals with attention maps for explainability would complement radiologists&#x2019; efforts. Code for the proposed framework is available at: <uri>https://github.com/rishiraj-cs/collaterals_ML_MM</uri>.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Rishi Raj et al.",
      "keywords": "Collateral; Convolutional neural network; Computer science; Artificial intelligence; Collateral circulation; Class (philosophy); Machine learning; Radiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3368504",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3209570656",
      "doi": "10.1109/access.2021.3131949",
      "title": "Applications of Generative Adversarial Networks in Anomaly Detection: A Systematic Literature Review",
      "abstract": "Anomaly detection has become an indispensable tool for modern society, applied in a wide range of applications, from detecting fraudulent transactions to malignant brain tumours. Over time, many anomaly detection techniques have been introduced. However, in general, they all suffer from the same problem: a lack of data that represents anomalous behaviour. As anomalous behaviour is usually costly (or dangerous) for a system, it is difficult to gather enough data that represents such behaviour. This, in turn, makes it difficult to develop and evaluate anomaly detection techniques. Recently, generative adversarial networks (GANs) have attracted a great deal of attention in anomaly detection research, due to their unique ability to generate new data. In this paper, we present a systematic literature review of the applications of GANs in anomaly detection, covering 128 papers on the subject. The goal of this review paper is to analyze and summarize: (1) which anomaly detection techniques can benefit from certain types of GANs, and how, (2) in which application domains GAN-assisted anomaly detection techniques have been applied, and (3) which datasets and performance metrics have been used to evaluate these techniques. Our study helps researchers and practitioners to find the most suitable GAN-assisted anomaly detection technique for their application. In addition, we present a research roadmap for future studies in this area.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mikael Sabuhi et al.",
      "keywords": "Anomaly detection; Computer science; Anomaly (physics); Adversarial system; Generative grammar; Data mining; Data science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2021.3131949",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4324292617",
      "doi": "10.1109/jtehm.2023.3257179",
      "title": "Evaluating Risk-Adjusted Hospital Performance Using Large-Scale Data on Mortality Rates of Patients in Intensive Care Units: A Flexible Semi-Nonparametric Modeling Approach",
      "abstract": "Our research findings highlight how constructing advanced assessment tools for hospital performance could support better decision-making at the administrative and public levels. The proposed hospital compare models are comprehensive in their capacity to identify patterns of hospital random effects and to convey the variability in healthcare quality with powerful accuracy and interpretability.",
      "year": "2023",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Yakun Liang et al.",
      "keywords": "Nonparametric statistics; Computer science; Medicaid; Intensive care; Robustness (evolution); Random effects model; Scale (ratio); Medicine; Health care; Statistics; Mathematics; Intensive care medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2023.3257179",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2971134353",
      "doi": "10.1109/access.2019.2937805",
      "title": "Feature Fusion and Voiceprint-Based Access Control for Wireless Insulin Pump Systems",
      "abstract": "Without effective cryptographic mechanisms, the wireless channel between the USB/uploader and insulin pump frequently suffers from vulnerabilities. Either eavesdropping or therapy manipulation attacks would put the patients in a life-threatening situation. Towards tackling this problem, we propose an access control scheme by introducing feature fusion and voiceprint. Featured by the anti-replay speaker verification and voiceprint-based key agreement, it secures communications over the wireless channel. Through a cascaded fusion of speaker verification and anti-replay countermeasure, the anti-replay speaker verification guarantees that the pump can only be accessed after the verification. When defending against zero-effort and replay impostors with our scheme, the equal error rate can be reduced to 2.22%. Furthermore, to generate a common key for the wireless channel, in the voiceprint-based key agreement, we present a non-interactive energy-difference-based voiceprint extraction and adaptive Reed-Solomon coding based fuzzy extractor. Thus, it enhances the communication encryption which protects the pump from eavesdropping and therapy manipulation attacks. Also, with an appropriate constraint on voiceprints similarity, the key agreement lowers the risk of channel establishment from device locating outside the pump's close proximity.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yuan Ping et al.",
      "keywords": "Computer science; Wireless; Eavesdropping; Encryption; Replay attack; Computer network; Channel (broadcasting); Key (lock); Computer security; Password; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2937805",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4283700766",
      "doi": "10.1109/rbme.2022.3186828",
      "title": "Hypertension Diagnosis and Management in Africa Using Mobile Phones: A Scoping Review",
      "abstract": "Target 3.4 of the third Sustainable Development Goal (SDG) of the United Nations (UN) General Assembly proposes to reduce premature mortality from non-communicable diseases (NCDs) by one-third. Epidemiological data presented by the World Health Organization (WHO) in 2016 show that out of a total of 57 million deaths worldwide, approximately 41 million deaths occurred due to NCDs, with 78% of such deaths occurring in low-and-middle-income countries (LMICs). The majority of investigations on NCDs agree that the leading risk factor for mortality worldwide is hypertension. Over 75% of the world's mobile phone subscriptions reside in LMICs, hence making the mobile phone particularly relevant to mHealth deployment in Africa. This study is aimed at determining the scope of the literature available on hypertension diagnosis and management in Africa, with particular emphasis on determining the feasibility, acceptability and effectiveness of interventions based on the use of mobile phones. The bulk of the evidence considered overwhelmingly shows that SMS technology is yet the most used medium for executing interventions in Africa. Consequently, the need to define novel and superior ways of providing effective and low-cost monitoring, diagnosis, and management of hypertension-related NCDs delivered through artificial intelligence and machine learning techniques is clear.",
      "year": "2022",
      "journal": "IEEE Reviews in Biomedical Engineering",
      "authors": "Iyabosola Busola Oronti et al.",
      "keywords": "Psychological intervention; Mobile phone; mHealth; Software deployment; Medicine; Scope (computer science); Business; Developing country; Environmental health; Epidemiological transition; Medical emergency; Risk analysis (engineering); Economic growth; Computer science; Telecommunications; Nursing; Population",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/rbme.2022.3186828",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2947294222",
      "doi": "10.1109/access.2019.2919998",
      "title": "Estimation of Key Comorbidities for Osteoarthritis Progression Based on the EMR-Claims Dataset",
      "abstract": "Currently, some serious comorbidity-impacted chronic diseases have high incidence among older people in the U.S. Due to the incompleteness of the related clinical data, it is difficult to refine these diseases' staging and quantitatively assess risk effects of comorbidities on symptom progressions. Here, we used both electronic medical records (EMRs) and claims data to obtain a comprehensive data source in this paper. We adopted osteoarthritis (OA) as a demonstrated major disease. The key comorbidities and their risks for various OA stage-related progressions were estimated. We utilized the linked EMR-claims dataset of OA from 2007 to 2014. The EMR data provided pain scores and laboratory data, while claims data provided costs as a proxy for disease severity. Although both datasets contained diagnoses, procedures, and medications, the linked dataset included more distinct codes. We established a prototype to combine our developed relational dependency network (RDN) approach with Cox proportional models to extract and estimate key comorbidities' impacts on OA progression. We identified the key OA stage-related comorbidities. Our studies indicate that the combination of the EMR with claims data is a useful strategy for obtaining more accurate medical data sources from patients. The analyses of the impact of clinical factors on OA staging clarify the associations between key covariates and OA progression. These approaches can be generalized to summarize the impact of comorbidities on the development of various chronic diseases.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Wei Chen et al.",
      "keywords": "Comorbidity; Medicine; Osteoarthritis; Proxy (statistics); Disease; Medical record; Intensive care medicine; Computer science; Internal medicine; Machine learning; Alternative medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2919998",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2995380320",
      "doi": "10.1109/mprv.2019.2926656",
      "title": "CHI 2019",
      "abstract": "The 2019 ACM CHI Conference on Human Factors in Computing was themed around \"weaving the threads of CHI ... people from different disciplines, cultures, sectors, communities, backgrounds ... weaving together into one community, with the common purpose of technology that works for people and society.\" The conference took place on May 4-9 in Glasgow, UK This year's CHI was the biggest to date, with over 3800 participants from 68 countries. It included workshops, papers, demos, and presentations that touched on new technologies and societal themes, which will impact current and emerging trends in pervasive and ubiquitous computing. We highlight several of these trends in this paper, including Internet of Things (IoT) in smarthomes, privacy and security, AR/VR, health, and new interaction modalities. We also focus on several cross-cutting areas, including an increasing focus on understanding and supporting varied populations and platforms.",
      "year": "2019",
      "journal": "IEEE Pervasive Computing",
      "authors": "Frederik Brudy et al.",
      "keywords": "Computer science; Ubiquitous computing; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mprv.2019.2926656",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3006658660",
      "doi": "10.1109/access.2020.2968717",
      "title": "EEG Functional Connection Analysis Based on the Weight Distribution of Convolutional Neural Network",
      "abstract": "Functional connections are commonly used when exploring the human brain, especially in brain data analysis. However, most of the studies concentrate on traditional statistical analysis. In this paper, we innovatively combined the functional connection with the deep learning algorithms and analysed the matrices after the weight distribution of each layer of the convolutional neural network (CNN) to obtain the connections that play a vital role in the classification. The electroencephalogram (EEG) data used in this paper was acquired through a visual mismatch negativity (MMN) experiment. When dealing with this data, each electrode was regarded as a node in the network, and the phase lag index (PLI) was calculated to construct the functional connection matrices, which were used as inputs for the CNN classification and feature extraction. The matrices after the weight distribution were further analysed by means of graph theory. In this paper, the classification accuracy for deviation and standard stimuli are over 95%, and the theta band achieved the highest accuracy. Through the distributed matrices, we found that there are two regions that obtained larger weights from the convolutional layers, i.e., the temporal lobe and the occipital region. The occipital region is related to our visual experiment, and the temporal lobe region is connected with MMN mechanism. We also considered the strategy of the three-layer CNN according to weight distribution processing.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jinglong Wu et al.",
      "keywords": "Convolutional neural network; Computer science; Pattern recognition (psychology); Artificial intelligence; Electroencephalography; Feature extraction; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2968717",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3163084581",
      "doi": "10.1109/access.2021.3081449",
      "title": "Sensorimotor Skill Communication: A Literature Review",
      "abstract": "A sensorimotor skill is a sequence of motions generated in response to external stimuli and aiming to accomplish a particular task. It can be communicated to reproduce the task in a distant environment with similar settings. In this work, we conceptualize a multi-modal sensorimotor skill communication system that incorporates modeling, simulation, and evaluation of the sensorimotor skill. The proposed sensorimotor skill communication system can be applied for learning a specific style of human sensorimotor skill and teaching the skill to distant learners, which can be implemented in a variety of applications such as Tele-consultation, Tele-diagnosis, Tele-treatment, Tele-monitoring, and Tele-support. To understand the processes behind the communication of sensorimotor skill we review the representation of a human sensorimotor system from the neurobiological perspective. Then we analyze the existing literature on sensorimotor skill communication systems and propose a taxonomy of currently available methods for sensorimotor skill modeling, simulation, and evaluation. Furthermore, we propose a benchmark for evaluating the quality of the sensorimotor skill communication system. We present a case study aiming to demonstrate modeling the dental sensorimotor skill of periodontal probing. Lastly, we discuss challenges and limitations and provide perspectives for future research in developing sensorimotor skill communication systems.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Vahan Babushkin et al.",
      "keywords": "Computer science; Task (project management); Human\u2013computer interaction; Variety (cybernetics); Perspective (graphical); Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3081449",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206454170",
      "doi": "10.1109/access.2021.3132728",
      "title": "Ontological Model for Contextual Data Defining Time Series for Emotion Recognition and Analysis",
      "abstract": "One of the major challenges facing the field of Affective Computing is the reusability of datasets. Existing affective-related datasets are not consistent with each other, they store a variety of information in different forms, different formats, and the terms used to describe them are not unified. This paper proposes a Recording Ontology for Affective-related Datasets (ROAD) as a solution to this problem, by formally describing the datasets and unifying the terms used. The developed ontology allows information about the origin and meaning of the data to be modeled, i.e., time series, representing both emotional states and features derived from biosignals. Furthermore, the ROAD ontology is extensible and not application-oriented, thus it can be used to store data from a wide range of Affective Computing experiments. The ontology was validated by modeling data obtained from one experiment on AMIGOS dataset (A dataset for Multimodal research of affect, personality traits and mood on Individuals and GrOupS). The approach proposed in the paper can be used both by researchers who create new datasets or want to reuse existing ones, and for those who want to process data from experiments in a more automated way.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Teresa Zawadzka et al.",
      "keywords": "Computer science; Time series; Series (stratigraphy); Data modeling; Artificial intelligence; Data mining; Natural language processing; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3132728",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394896973",
      "doi": "10.1109/jtehm.2024.3390589",
      "title": "Application of Statistical Analysis and Machine Learning to Identify Infants\u2019 Abnormal Suckling Behavior",
      "abstract": "By analyzing non-nutritive suckling using computational methods, we demonstrate the ability to detect abnormal and normal behavior in infant suckling that can inform breastfeeding intervention pathways in clinic.Clinical and Translational Impact Statement: The work serves to shed light on the lack of consensus for determining appropriate intervention pathways for infant oral dysfunction. We demonstrate using statistical analysis and machine learning that normal and abnormal infant suckling can be identified and used in determining if surgical intervention is a necessary solution to resolve infant feeding difficulties.",
      "year": "2024",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Phuong Truong et al.",
      "keywords": "Computer science; Statistical analysis; Artificial intelligence; Statistical learning; Machine learning; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2024.3390589",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3117228565",
      "doi": "10.1109/jphot.2020.3048015",
      "title": "Multi-Spectral Optimization for Tissue Probing Using Machine Learning",
      "abstract": "An optical approach for pigmented lesions detection in human skin is presented. As differences between normal skin tissue and pigmentation tissue (and even a change in pigmentation development) can be detected by their optical properties, this paper presents a new, potentially noninvasive approach for skin cancer detection. Since each wavelength has different penetration depth into the tissue and different absorption, the goal was to check whether a combination of information obtained from five different wavelengths, can increase the detection probability and reduce the false positive probability, compared to using only one wavelength. Temporal tracking of back-reflected secondary speckle patterns generated while illuminating the tested area with several lasers and applying periodic vibrations to the surface via a controlled vibration source at several stimulation frequencies. As a sequel to the previous work conducted in our laboratory which investigated pigmented lesions interaction with one light source, this work deals with increasing the number of parameters that are being looked at and considered at the same time. Using five wavelengths, 9 vibration frequencies and 19 signal analysis parameters, ex-vivo experiments were performed on porcine skin tissues and were analyzed using artificial intelligence tools which could detect the strong features for each wavelength individually. Combining the wavelengths produced impressive results compared to the results by each wavelength separately: both types of errors, false positive and false negative, decreased to less than 2&#x0025;. Such a significant change in its impact on patients shows the value of this method. This paper shows the possibility of optically separating normal skin from pigmentation tissue, by using the advantages of multi-spectral optimization. This is a necessary proof of concept as a preliminary step toward our future experiments, which may differentiate between different types of pigmentation, and even malignancy and benign tissues.",
      "year": "2020",
      "journal": "IEEE photonics journal",
      "authors": "Yarden Tzabari Kelman et al.",
      "keywords": "Wavelength; Speckle pattern; Optics; Laser; Computer science; Penetration depth; Materials science; Artificial intelligence; Biomedical engineering; Physics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jphot.2020.3048015",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393305472",
      "doi": "10.1109/access.2024.3383143",
      "title": "3D Pain Face Expression Recognition Using a ML-MIMO Radar Profiler",
      "abstract": "This study proposes a new method for the detection of facial expressions of pain using a 3D profiler that combines a multiple-input-multiple-output (MIMO) radar system with a machine learning (ML) model (ML-MIMO radar profiler). It offers a solution for pain detection of facial expressions in a non-invasive, non-intrusive, and cost-effective manner. The ML-MIMO radar profiler employs six radars behind a lens to monitor changes in six facial regions and build a 3D facial profile with real-time facial activity information. A dielectric lens was used to ensure an optimal beam size to effectively illuminate each facial region. Signal processing is performed using dynamic time deformation to determine the longitudinal distance and a discrete stationary wavelet transform to filter the signal and improve accuracy. The information from the 3D profiler was compared with the facial action coding system (FACS) to determine actual facial expressions. A machine learning algorithm was trained to learn action units from the FACS and compare them with the information provided by the ML-MIMO radar profiler, thereby performing facial expression classification. In this study, we analyzed four facial expressions: hapiness, sadness, anger, and pain. Identification and classification were performed using a machine-learning model based on multilayer perceptrons. The results revealed 92% accuracy of the system for pain expression, whereas expressions of happiness, sadness, and anger were detected with 88, 86, and 87% accuracy, respectively.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mar\u00eda-Jos\u00e9 L\u00f3pez et al.",
      "keywords": "Computer science; Radar; Face (sociological concept); Artificial intelligence; Computer vision; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3383143",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392902322",
      "doi": "10.1109/access.2024.3379140",
      "title": "Pilot Experiments and Hardware Design of Smart Electrooculographic Headband for People With Muscular Paralysis",
      "abstract": "Millions of individuals worldwide suffer from a motor disability, impeding their ability to perform daily tasks independently. Modern technologies, such as electrooculography (EOG), offer tools to enhance their quality of life. EOG, an electrophysiological method, detects DC potentials influenced by eye movements, making it particularly advantageous for individuals with motor impairments who retain ocular mobility. This article describes pilot experiments that includes the basic design of an electrodes configuration for peripheral solutions, their optimization, and the addition of sensors to measure other vital physiological parameters such as photoplethysmography (PPG) and electrocardiography (ECG) on demand. We tested all the EOG methodologies and connections that our device should contain, using the Mindmedia Nexus-10 MKII for EOG, the Analog Devices MAXM86146 optical biosensor module for PPG signals, the Texas Instruments ADS1299 biopotential circuit for ECG. The evaluation and filtering of the collected data were carried out in the MATLAB environment. Finally, we present a hardware concept based on a new approach that, unlike standard EOG, incorporates three large-area conductive fabric electrodes in a headband for practical and comfortable long-term non-manual human-machine interface (HMI). Our measurements are crucial for monitoring the patients&#x2019; health status, mood variations, and can help prevent complications or speed up treatment. The primary goal of this research was to present our innovative concept and confirm its feasibility, bringing us closer to the realization of a fully developed and functional device.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Helena Svobodov\u00e1 et al.",
      "keywords": "Computer science; Paralysis; Physical medicine and rehabilitation; Computer hardware; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3379140",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389040816",
      "doi": "10.1109/access.2023.3337117",
      "title": "Survival-Based Treatment Planning Using Stage-Specific Machine Learning Models",
      "abstract": "The significance of prognostic survivability in determining optimal treatment strategies for critical illnesses is widely acknowledged. However, there has been a lack of emphasis on the advancement of treatment planning models based on survival outcomes within clinical decision support systems. The research presented in this paper proposes an innovative framework for the planning of treatment strategies based on survival outcomes in the context of multi-stage diseases, with the aim of effectively tackling this issue. Our proposed system aims to predict a comprehensive list of treatment combinations for cancer patients, specifically focusing on their expected survival outcomes. The proposed solution aims to enhance the decision-making process of medical professionals by providing them with comprehensive and comprehensible treatment recommendations. To conduct survivability classification and regression analysis for patients with identical cancer stages, a two-step approach is employed. This involves the development of stage-specific Machine Learning models using breast cancer data that includes treatment information. Based on a real dataset on cancer patients, we aim to investigate the performance of the models under different balancing strategies. Our contribution in this work is the formulation of a treatment planning inference system, which focuses on prognostic considerations. This system utilizes patient data and estimates the survivability associated with each treatment plan in order to predict the recommended course of action. This facilitates the integration of the developed survival prediction models into the process of treatment planning. Ultimately, the system generates visual representations that illustrate the comparative significance of different features, as well as the decision-making process employed by the model in order to yield easily comprehensible outcomes for a specific patient. The study presents experimental findings that illustrate the efficacy of our proposed framework in the domains of treatment planning and survival estimation.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Aya Farrag et al.",
      "keywords": "Survivability; Computer science; Context (archaeology); Machine learning; Process (computing); Artificial intelligence; Inference; Radiation treatment planning; Predictive modelling; Decision support system; Risk analysis (engineering); Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3337117",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391853555",
      "doi": "10.1109/access.2024.3366490",
      "title": "Prediction of Mortality in Inpatients of Covid-19 Using Statistical and Artificial Intelligence Approaches: A Case Study in Sakarya",
      "abstract": "The virus SARS-Cov-2 speared rapidly as pandemic disease and cause serious respiratory distress and death. The parameters such as D-dimer, fibrinogen, C-reactive protein, and serum ferritin become higher indicators for acute inflammation. It is vital to understand whether the disease will progress severely or result in death by using laboratory findings. In this way, a doctor concentrating on the patient can make faster and more accurate decisions about the prognosis of the disease and survey patients using artificial intelligence and statistical methods. Therefore, this study aims to determine the attributes associated with deteriorating prognosis by analyzing the laboratory findings of patients who are followed in Sakarya U. Training and Res. Hospital with Covid-19 by using artificial intelligence and statistical methods. More precisely the general aim of this study is to leverage artificial intelligence and statistical methods to identify specific laboratory markers associated with Covid-19 patient deterioration and mortality, enabling more accurate prognosis and clinical decision-making. Our results demonstrated that high fibrinogen, troponin, albumin, d-dimer, ferritin, intubation, and uric acid level were directly related to mortality in Covid-19 patients. The Random Forest technique yielded the highest average accuracy, precision, F1 values, sensitivity, and specificity (all above 0.99), making it the most successful. Additionally, the training-based models give higher accuracy results than statistical methods. Thus, these laboratory findings of Covid-19 patients and the training-based models may potentially provide doctors make easier and more accurate decisions about mortality and survey predicting.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "M. Fatih Adak et al.",
      "keywords": "Fibrinogen; Coronavirus disease 2019 (COVID-19); Medicine; Disease; Artificial intelligence; Intensive care medicine; Computer science; Internal medicine; Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3366490",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384304014",
      "doi": "10.1109/access.2023.3295500",
      "title": "Toward Large-Scale Test for Certifying Autonomous Driving Software in Collaborative Virtual Environment",
      "abstract": "Virtual simulation environments are widely used to test autonomous driving software by creating highly complex driving scenarios that are non-trivial to set up in a physical environment. However, the current practice of using the virtual test still does not fully utilize its potential to build a much larger scale test. We propose a perspective and research vision to build a large-scale test architecture in which participants collaboratively construct, execute and analyze complex test scenarios at scale in the virtual world. In particular, the architectural concept is built on the existing concept of the Collaborative Virtual Environment (CVE) that has been successfully applied in other domains, such as entertainment or military training applications. The proposed domain-specific architectural requirements extend the CVE to include the following necessary properties - selective sharing and collaboration - to test autonomous driving software. In addition, the test architectural concept is explained as to how a large number of participants interact with each other collaboratively to build and execute diverse test scenarios at scale. Finally, we explain the new research directions to make this test architectural concept realized for testing autonomous driving software.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "BaekGyu Kim et al.",
      "keywords": "Computer science; Software engineering; Software architecture; Human\u2013computer interaction; Test (biology); Software; Scenario testing; Scale (ratio); Architecture; Virtual machine; Domain (mathematical analysis); Artificial intelligence; Operating system; Variety (cybernetics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3295500",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4378715286",
      "doi": "10.1109/access.2023.3281194",
      "title": "SentiTrust: A New Trust Model for Decentralized Online Social Media",
      "abstract": "[EN] Online Social Media (OSM) are dominating the wide range of Internet services. Due to their\\nvast audience, it is crucial to evaluate the interpersonal trust among OSM users that can identify reliable\\nsources of information, the meaningfulness of a relationship, or the trustworthiness of other users. SentiTrust\\nis an innovative trust model for Decentralized Online Social Networks that is based on AI-powered Sentiment\\nAnalysis. It enriches the trust definition by exploiting important features that are enabled because of the\\nadoption of Social Media through mobile devices. The model can be easily extended and customized\\naccording to the scenario of interest. The sentiment analysis component has been tested by involving\\n30 participants who completed several guided tasks using a social media application while their electrodermal\\nactivity and rate responses were measured. The results suggest that low arousal states are related to receiving\\nhappy faces and to sending more messages per minute. Furthermore, positive interactions result in shorter\\ninteractions and multimedia exchanges.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Barbara Guidi et al.",
      "keywords": "Computer science; Social media; Trustworthiness; Interpersonal communication; Component (thermodynamics); Microblogging; Internet privacy; The Internet; World Wide Web; Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3281194",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3108206410",
      "doi": "10.1109/access.2020.3044858",
      "title": "Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19. A Thoughtful Evaluation Approach",
      "abstract": "Current standard protocols used in the clinic for diagnosing COVID-19 include molecular or antigen tests, generally complemented by a plain chest X-Ray. The combined analysis aims to reduce the significant number of false negatives of these tests and provide complementary evidence about the presence and severity of the disease. However, the procedure is not free of errors, and the interpretation of the chest X-Ray is only restricted to radiologists due to its complexity. With the long term goal to provide new evidence for the diagnosis, this paper presents an evaluation of different methods based on a deep neural network. These are the first steps to develop an automatic COVID-19 diagnosis tool using chest X-Ray images to differentiate between controls, pneumonia, or COVID-19 groups. The paper describes the process followed to train a Convolutional Neural Network with a dataset of more than 79, 500 X-Ray images compiled from different sources, including more than 8, 500 COVID-19 examples. Three different experiments following three preprocessing schemes are carried out to evaluate and compare the developed models. The aim is to evaluate how preprocessing the data affects the results and improves its explainability. Likewise, a critical analysis of different variability issues that might compromise the system and its effects is performed. With the employed methodology, a 91.5% classification accuracy is obtained, with an 87.4% average recall for the worst but most explainable experiment, which requires a previous automatic segmentation of the lung region.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Juli\u00e1n D. Arias-Londo\u00f1o et al.",
      "keywords": "Preprocessor; Computer science; Coronavirus disease 2019 (COVID-19); Artificial intelligence; Convolutional neural network; Artificial neural network; Pattern recognition (psychology); Machine learning; Data mining; Medicine; Pathology; Disease",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2020.3044858",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389474239",
      "doi": "10.1109/access.2023.3341229",
      "title": "CECNet: Coordinate Encoding Competitive Neural Network For Palm Vein Recognition by Soft Large Margin Centralized Cosine Loss",
      "abstract": "Palm vein recognition plays a crucial role in identity verification, requiring highly discriminative features. However, for touchless palm vein datasets, selecting a suitable and fixed Region of Interest (ROI) is challenging due to variations in capture scales and anisotropy. Moreover, manually annotating ROIs for each palm vein image is a time-consuming and labor-intensive task. To address these challenges, the method based on competitive mechanism is currently a popular approach for palm vein recognition. However, traditional competitive mechanisms only focus on selecting winners from different channels without considering the spatial information of features. In this paper, we reformulate the traditional competition mechanism and propose a Coordinate Encoding Competitive Neural Network (CECNet). Our method takes into account the spatial competition relationship between features, which means we pay attention to features of different directions and scales. We also perform spatial encoding on the competitive features to extract a more comprehensive set of competitive features. To extract the textures, the CECNet employs three parallel Adaptive Gabor Filter Encoders (AGFEs) to learn features of different directions and scales, effectively capturing the variations present in palm vein images. To enhance feature discrimination, the Soft Large Margin Centralized Cosine Loss (SLMCCL) function is utilized, taking into account with inter-class separation and introducing centralized cosine similarity to achieve better intra-class similarity. By optimizing this loss function, the network learns to prioritize and rank features based on their importance. Experimental results on public palm vein datasets demonstrate the effectiveness of the proposed approach.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Menghan Zhang et al.",
      "keywords": "Computer science; Artificial intelligence; Margin (machine learning); Pattern recognition (psychology); Feature (linguistics); Feature extraction; Distortion (music); Filter (signal processing); Similarity (geometry); Discriminative model; Computer vision; Machine learning; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3341229",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3164949737",
      "doi": "10.1109/access.2021.3083523",
      "title": "Data Science Analysis and Profile Representation Applied to Secondary Prevention of Acute Coronary Syndrome",
      "abstract": "The analysis oflarge amounts of data from electronic medical records (EMRs) and daily clinical practice data sources has received increasing attention in the last years. However, few systematic approaches have been proposed to support the extraction of the wealth and diversity of information from these data sources. Specifically, Acute Coronary Syndrome (ACS) data are available in many hospitals and health units because ACS shows elevated morbidity and mortality. This work propases a method called Data Science Analysis and Represen tation (DSAR) to scrutinize and exploit, in a univ aiiate way, scientific information content in limited ACS samples. DSAR us es Bootstrap Resampl ing to provide robust, cross-sectional, and non-parametric statis tical tests on categorical and metric variables. lt also constructs an informative graphical representation of the database variables, which helps to interpret the results and to identify the relevant variables. Our objectives were to validate DSAR by comparing it to conventional statistical methods when looking for the most relevant variables in the secondary prevention of ACS, and to determine the degree of correlation between them and the Exitus event (associated with patient death). To achieve this objective, we applied DSAR on an anonymized sample of 270 variables from 2377 patients diagnosed with ACS. The results showed that DSAR identified 44% significant variables while conventional methods offered weak correlation results. Then, the scientific literature was reviewed for a set of these variables, validating the agreement with clinical experience and previous ACS research. The conclusion is that DSAR is a valuable anda useful method for clinicians in the identification of potentially predictive variables and, overall, a good starting point for future multivariate secondary analyzes in the clinical field of ACS, or fields with similai\u00b7 information characteristics.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Antonio Garc\u00eda-Garc\u00eda et al.",
      "keywords": "Categorical variable; Computer science; Metric (unit); Data mining; Univariate; Resampling; Medicine; Statistics; Machine learning; Mathematics; Artificial intelligence; Multivariate statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3083523",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3163303564",
      "doi": "10.1109/access.2021.3119630",
      "title": "Origins of ECG and Evolution of Automated DSP Techniques: A Review",
      "abstract": "Over the years researchers have studied the evolution of Electrocardiogram (ECG) and the complex classification of cardiovascular diseases. This review focuses on the evolution of the ECG, and covers the most recent signal processing schemes with milestones over last 150 years in a systematic manner. Development phases of ECG, ECG leads, portable ECG monitors, Signal Processing Schemes and the Complex Transformations are discussed. It also provides recommendations for the inclusion of certain important points based on the review.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Neha Arora et al.",
      "keywords": "Digital signal processing; Computer science; Signal processing; SIGNAL (programming language); Data science; Artificial intelligence; Data mining; Machine learning; Computer hardware",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3119630",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389352619",
      "doi": "10.1109/access.2023.3339752",
      "title": "Blockchain and Artificial Intelligence: Scientometric Analysis and Visualization",
      "abstract": "Integrating Artificial Intelligence (AI) with Blockchain Technology (BT) is deemed the fourth generation of BT applications (Blockchain 4.0). This generation has gained considerable attention from the research community. Such attention has led to a vast amount of scientific literature. However, a comprehensive quantitative analysis of this literature is still missing. The present study conducts a scientometric analysis to explore and characterize the development track and trends of BT-AI research. Using the Web of Science (WoS) Core Collection database, a total of 2615 peer-reviewed journal articles were identified between 2017&#x2013;2023 and extracted for analysis, while employing VOSviewer and Biblioshiny as software tools. First, the publication trend was analyzed, and the pivotal articles were identified. Second, the scientific collaboration networks were analyzed and mapped to identify the key researchers, countries, and organizations. Third, the sources&#x2019; productivity and citation were analyzed and mapped to identify the dependable sources of information and the best-fit sources for publishing the BT-AI studies. Fourth, the conceptual structure for the BT-AI literature was analyzed and visualized using keywords co-occurrence and keywords thematic evolution to explore and identify the research hotspots and emerging themes. The findings of this study can help in further familiarizing new researchers with BT-AI literature and assist practitioners, policy-makers, and editors to focus on the promising and arising BT-AI trends for further development.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Kareem Adel et al.",
      "keywords": "Computer science; Data science; Visualization; Thematic analysis; Knowledge management; Artificial intelligence; Qualitative research",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3339752",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312369844",
      "doi": "10.1109/access.2022.3224426",
      "title": "From Frequency Content to Signal Dynamics Using DNNs",
      "abstract": "This study developed a novel method for analyzing and decomposing a signal into its main dynamics for small and large timescales. Our proposal is based on a decoupled hybrid system of convolutional and recurrent neural networks that uses as inputs the power spectrum and spectrogram of a given signal, giving as output the dynamic behavior. We define the dynamic classification predicted of the signal using previously known dynamics characterized through training signals: periodic, quasi-periodic, aperiodic, chaotic, and randomness. We created a synthetic dataset comprising more than 50 training signals from different categories. For the real-world dataset, we used photoplethysmographic signals from 40 students obtained from a Spanish medical study. We tested the developed system&#x2019;s performance in real biological and synthetical signals, obtaining noteworthy results. All the results are evaluated qualitatively and quantitatively. Still, given the novelty and the lack of similar works, we cannot compare reliably and rigorously our results with other works, at least quantitatively. We can retrieve from the exposed results in this work three key ideas: the DNN-based solutions are capable of learning and generalizing the dynamics behavior of signals; the proposal learned correctly to distinguish between the reference dynamics provided and find some unidirectional similarities in the aperiodicity cases; and the results obtained using real-world PPG signals reveal that biological signals seem to exhibit a multi-dynamic behavior that changes depending on the used timescale, being quasi-periodically dominant in the short-term and aperiodically dominant in the long-term.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Javier de Pedro-Carracedo et al.",
      "keywords": "Computer science; Dynamics (music); SIGNAL (programming language); Signal processing; Content (measure theory); Speech recognition; Mathematics; Digital signal processing; Acoustics; Physics; Mathematical analysis",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3224426",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285241177",
      "doi": "10.1109/access.2022.3172970",
      "title": "A Joint Model for Hierarchical Nested Information Extraction",
      "abstract": "During the long-term power construction process, the power dispatching department has saved many notification texts related to adjustment of grid operation mode. There is an urgent need to study named entity recognition techniques to automatically recognize the power equipment and operation mode, in order to support automatic verification of grid operation mode. By analyzing the characteristics of notification texts, a classification method of hierarchical nested named entities is proposed for the first time in power domain. The entities are divided into two layers with nested relationships, and the corpus of grid operation mode is constructed. We further propose a joint model based on character-word feature fusion and attention mechanism. The model is based on the parameter sharing approach for joint recognition of hierarchical nested entities in the corpus and further introduces an attention mechanism to optimize the feature interaction between hierarchical nested entities. In addition, we splice embeddings of characters and words as feature input to obtain richer semantic features. Experimental results show that our model achieves state-of-the-art results. Eventually, the recognition results can be stored as a standardized verification information chain, providing effective data support for automatic verification of the grid operation mode and ensuring safe and stable operation of the grid.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ruyang Yin et al.",
      "keywords": "Computer science; Mode (computer interface); Grid; Data mining; Feature (linguistics); Word (group theory); Artificial intelligence; Feature extraction; Process (computing); Pattern recognition (psychology); Human\u2013computer interaction; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3172970",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4322710786",
      "doi": "10.23919/jsc.2022.0018",
      "title": "Characterizing and Understanding Development of Social Computing Through DBLP: A Data-Driven Analysis",
      "abstract": "During the past decades, the term \u201csocial computing\u201d has become a promising interdisciplinary area in the intersection of computer science and social science. In this work, we conduct a data-driven study to understand the development of social computing using the data collected from Digital Bibliography and Library Project (DBLP), a representative computer science bibliography website. We have observed a series of trends in the development of social computing, including the evolution of the number of publications, popular keywords, top venues, international collaborations, and research topics. Our findings will be helpful for researchers and practitioners working in relevant fields.",
      "year": "2022",
      "journal": "Journal of Social Computing",
      "authors": "Jiaqi Wu et al.",
      "keywords": "Computer science; Data science; Intersection (aeronautics); Big data; Work (physics); Bibliography; World Wide Web; Library science; Data mining; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2022.0018",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2996949923",
      "doi": "10.1109/access.2019.2961101",
      "title": "IEEE Access Special Section Editorial: Human-Centered Smart Systems and Technologies",
      "abstract": "In the past several years, we have seen dramatic advancements in many sectors enabled by the use of computing and networking technologies. This development has resulted in many emerging, highly multi-disciplinary research areas typically termed as smart- technologies, including smart-healthcare, smart-home, smart-grid, as well as smart vehicles and intelligent transportation systems. These new technologies are transforming our society and have an enormous economic impact.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Wenbing Zhao et al.",
      "keywords": "Special section; Smart grid; Computer science; Emerging technologies; Telecommunications; Intelligent transportation system; Data science; Engineering; Transport engineering; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2961101",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3120107141",
      "doi": "10.22489/cinc.2020.476",
      "title": "Knowledge, Machine Learning and Atrial Fibrillation: More Ingredients for a Tastier Cocktail",
      "abstract": "Fifty years after the publication of the first algorithms for the automatic detection of Atrial Fibrillation (AF), this cardiac condition is still the most studied from the computer science and engineering perspectives. Machine learning techniques are widely applied to a variety of problems, including detection, characterization, prediction and simulation, in general with promising results. In the last years, the Big Data + Deep Learning binomial is getting most of the attention in academia and industry, but on many occasions this approach fails on capitalizing all the knowledge acquired in previous decades of research. This article, written as a companion to the keynote with the same title presented in the CinC 2020 conference, tries to illustrate the importance of exploiting expert knowledge and classical approaches in synergy with the most advanced deep learning methods, which by themselves have fundamental limitations. The discussion is built around the AF detection problem and the conclusions extracted from the Physionet/CinC Challenge 2017, but the main points can be relevant in other problems for which humans have a better answer than computers, and this answer can be described.",
      "year": "2020",
      "journal": "Computing in cardiology",
      "authors": "Tom\u00e1s Teijeiro",
      "keywords": "Atrial fibrillation; Computer science; Artificial intelligence; Internal medicine; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.22489/cinc.2020.476",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3046025021",
      "doi": "10.1109/access.2021.3099996",
      "title": "Improving Recurrent Neural Network Responsiveness to Acute Clinical Events",
      "abstract": "Predictive models in acute care settings must be able to immediately recognize precipitous changes in a patient's status when presented with data reflecting such changes. Recurrent neural networks (RNNs) have become common for training and deploying clinical decision support models. They frequently exhibit a delayed response to acute events. New information must propagate through the RNN's cell state memory before the total impact is reflected in the model's predictions. This work presents input data perseveration as a method of training and deploying an RNN model to make its predictions more responsive to newly acquired information: input data is replicated during training and deployment. Each replication of the data input impacts the cell state and output of the RNN, but only the output at the final replication is maintained and broadcast as the prediction for evaluation and deployment purposes. When presented with data reflecting acute events, a model trained and deployed with input perseveration responds with more pronounced immediate changes in predictions and maintains globally robust performance. Such a characteristic is crucial in predictive models for an intensive care unit.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "David Ledbetter et al.",
      "keywords": "Recurrent neural network; Replication (statistics); Perseveration; Computer science; Software deployment; Artificial neural network; Artificial intelligence; Machine learning; Intensive care unit; Psychology; Medicine; Intensive care medicine; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2021.3099996",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4287064571",
      "doi": "10.1109/access.2022.3197279",
      "title": "Unstructured Handwashing Recognition Using Smartwatch to Reduce Contact Transmission of Pathogens",
      "abstract": "Current guidelines from the World Health Organization indicate that the SARS-CoV-2 coronavirus, which results in the novel coronavirus disease (COVID-19), is transmitted through respiratory droplets or by contact. Contact transmission occurs when contaminated hands touch the mucous membrane of the mouth, nose, or eyes so hands hygiene is extremely important to prevent the spread of the SARSCoV-2 as well as of other pathogens. The vast proliferation of wearable devices, such as smartwatches, containing acceleration, rotation, magnetic field sensors, etc., together with the modern technologies of artificial intelligence, such as machine learning and more recently deep-learning, allow the development of accurate applications for recognition and classification of human activities such as: walking, climbing stairs, running, clapping, sitting, sleeping, etc. In this work, we evaluate the feasibility of a machine learning based system which, starting from inertial signals collected from wearable devices such as current smartwatches, recognizes when a subject is washing or rubbing its hands. Preliminary results, obtained over two different datasets, show a classification accuracy of about 95% and of about 94% for respectively deep and standard learning techniques.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Emanuele Lattanzi et al.",
      "keywords": "Smartwatch; Wearable computer; Artificial intelligence; Computer science; Wearable technology; Transmission (telecommunications); Machine learning; Human\u2013computer interaction; Embedded system",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2022.3197279",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3161052267",
      "doi": "10.1109/jiot.2021.3075477",
      "title": "Multistream Temporal Convolutional Network for Correct/Incorrect Patient Transfer Action Detection Using Body Sensor Network",
      "abstract": "The development of body sensor networks (BSNs) with rich multimodal signals has enabled highly accurate fine-grained action detection, which is the cornerstone of many humancomputer interaction applications. However, in the case of consecutive fine-grained actions, most existing wearable sensor-based detection methods are constrained by sliding windows because of their limited temporal receptive fields, and existing sequence-to-sequence detection methods cannot effectively leverage the potential of multimodal information of wearable sensors. Herein, to give multimodal signals full play in fine-grained action detection, we propose a novel temporal convolutional network by designing a channel attention-based multistream structure. We apply it to a promising application for correct and incorrect patient transfer nursing action detection. A dataset is collected from a BSN on a patient when nurses perform patient transfer. Extensive experiments on our dataset and public dataset (C-MHAD) demonstrate that the proposed method is superior to the state-of-the-art methods, because it can strengthen the utilization of prediction features from the more convincing modal stream at each time frame.",
      "year": "2021",
      "journal": "IEEE Internet of Things Journal",
      "authors": "Zhihang Zhong et al.",
      "keywords": "Computer science; Wearable computer; Transfer of learning; Leverage (statistics); Wireless sensor network; Artificial intelligence; Convolutional neural network; Deep learning; Machine learning; Real-time computing; Pattern recognition (psychology); Embedded system; Computer network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jiot.2021.3075477",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4249485313",
      "doi": "10.1109/jproc.2018.2884160",
      "title": "2016-2018 Index|Proceedings of the IEEE Vol. 104-106",
      "abstract": "",
      "year": "2018",
      "journal": "Proceedings of the IEEE",
      "authors": "O Andrisano et al.",
      "keywords": "Index (typography); Computer science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2018.2884160",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4315630493",
      "doi": "10.1109/tbme.2023.3236219",
      "title": "2022 Index IEEE Transactions on Biomedical Engineering Vol. 69",
      "abstract": "",
      "year": "2022",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "F Gagnadoux et al.",
      "keywords": "Index (typography); Computer science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2023.3236219",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4292263242",
      "doi": "10.1109/access.2022.3199613",
      "title": "Recent Advances in Diagnosis of Skin Lesions Using Dermoscopic Images Based on Deep Learning",
      "abstract": "Skin cancer is one of the most threatening cancers, which spreads to the other parts of the body if not caught and treated early. During the last few years, the integration of deep learning into skin cancer has been a milestone in health care, and dermoscopic images are right at the center of this revolution. This review study focuses on the state-of-the-art automatic diagnosis of skin cancer from dermoscopic images based on deep learning. This work thoroughly explores the existing deep learning and its application in diagnosing dermoscopic images. This study aims to present and summarize the latest methodology in melanoma classification and the techniques to improve this. We discuss advancements in deep learning-based solutions to diagnose skin cancer, along with some challenges and future opportunities to strengthen these automatic systems to support dermatologists and enhance their ability to diagnose skin cancer.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Yali Nie et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Computer vision; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3199613",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3166931362",
      "doi": "10.1109/access.2021.3087593",
      "title": "A Predictive Text System for Medical Recommendations in Telemedicine: A Deep Learning Approach in the Arabic Context",
      "abstract": "We are currently witnessing an immense proliferation of natural language processing (NLP) applications. Natural language generation (NLG) has emerged from NLP and is now commonly utilized in various applications, including chatting applications. The objective of this paper is to propose a deep learning-based language generation model that simplifies the process of writing medical recommendations for doctors in an Arabic context, to improve service satisfaction and patient-doctor interactions. The developed language generation model is a predictive text system intended for next word prediction in a telemedicine service. Altibbi&#x2014;a digital platform for telemedicine and teleconsultations services in the Middle East and the North Africa (MENA) region&#x2014;was utilized as a case study for the textual prediction process. The proposed model was trained using data obtained from Altibbi databases related to medical recommendations, particularly gynecology, dermatology, psychiatric diseases, urology, and internist diseases. Variants of deep learning models were implemented and optimized for next word prediction, based on the unidirectional and bidirectional long short-term memory (LSTM and BiLSTM), the one-dimensional convolutional neural network (CONV1D), and a combination of LSTM and CONV1D (LSTM-CONV1D). The algorithms were trained using two versions of the datasets (i.e., 3-gram and 4-gram representations) and evaluated in terms of their training accuracy and loss, validation accuracy and loss, and testing accuracy per their matching scores. The proposed models&#x2019; performances were comparable. CONV1D produced the most promising matching score.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Maria Habib et al.",
      "keywords": "Computer science; Artificial intelligence; Context (archaeology); Natural language processing; Deep learning; Convolutional neural network; Machine learning; Telemedicine; Matching (statistics); Artificial neural network; Arabic; Recurrent neural network; Process (computing); Health care; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3087593",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4296079414",
      "doi": "10.1109/access.2022.3207177",
      "title": "A Data Augmentation Pipeline to Generate Synthetic Labeled Datasets of 3D Echocardiography Images Using a GAN",
      "abstract": "Due to privacy issues and limited amount of publicly available labeled datasets in the domain of medical imaging, we propose an image generation pipeline to synthesize 3D echocardiographic images with corresponding ground truth labels, to alleviate the need for data collection and for laborious and error-prone human labeling of images for subsequent Deep Learning (DL) tasks. The proposed method utilizes detailed anatomical segmentations of the heart as ground truth label sources. This initial dataset is combined with a second dataset made up of real 3D echocardiographic images to train a Generative Adversarial Network (GAN) to synthesize realistic 3D cardiovascular Ultrasound images paired with ground truth labels. To generate the synthetic 3D dataset, the trained GAN uses high resolution anatomical models from Computed Tomography (CT) as input. A qualitative analysis of the synthesized images showed that the main structures of the heart are well delineated and closely follow the labels obtained from the anatomical models. To assess the usability of these synthetic images for DL tasks, segmentation algorithms were trained to delineate the left ventricle, left atrium, and myocardium. A quantitative analysis of the 3D segmentations given by the models trained with the synthetic images indicated the potential use of this GAN approach to generate 3D synthetic data, use the data to train DL models for different clinical tasks, and therefore tackle the problem of scarcity of 3D labeled echocardiography datasets.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Cristiana Tiago et al.",
      "keywords": "Ground truth; Computer science; Segmentation; Artificial intelligence; Pipeline (software); Synthetic data; Deep learning; Image segmentation; Pattern recognition (psychology); Generative adversarial network; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3207177",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285058664",
      "doi": "10.1109/access.2022.3183604",
      "title": "Development of the Osteosarcoma Lung Nodules Detection Model Based on SSD-VGG16 and Competency Comparing With Traditional Method",
      "abstract": "Osteosarcoma nodule that metastasized to the patient&#x2019;s lungs was difficult to detect due to limited cases caused by its rarity. The traditional method for finding lung nodules is manually done by radiologists by looking at CT-scanned images. As a result, the error rate for reading lung metastasized nodules ranged from 29 to 42 percent, while the permissible mistake rate for reading should be less than 29 percent. Advanced computer-aid techniques such as image processing and machine learning can help doctors to identify the Osteosarcoma lung nodules easier and more accurately. Convolutional Neural Networks (CNNs) are promising techniques since they could be trained by experienced radiologists. Nodule location and size information was critical for treatments that were obtained by object detector CNNs models. In this research, the Single Shot Detection (SSD) framework combined with the VGG16 backbone, SSD-VGG16, was implemented to obtain bounding box locations and sizes when each box represents one Osteosarcoma nodule with the confidence score. The SSD-VGG16 was selected due to its superior performance. The patient&#x2019;s CT-scanned images dataset collected from 202 patient cases was provided by Lerdsin hospital and used for training and validating the SSD-VGG16 model. The trained SSD-VGG16 model was trained based on two loss functions which are class confidence and location losses. Then, the trained model experimented with unseen CT-scanned images. The performance scores were calculated. The Result was analyzed and concluded. Finally, SSD-VGG16 shows the ability to detect and locate the nodules efficiently and has less error compared to the traditional method.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Chanunya Loraksa et al.",
      "keywords": "Computer science; Nodule (geology); Artificial intelligence; Osteosarcoma; Convolutional neural network; Image quality; Lung; Medicine; Nuclear medicine; Radiology; Pathology; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3183604",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386275534",
      "doi": "10.1109/access.2023.3310245",
      "title": "Fusion of Textural and Visual Information for Medical Image Modality Retrieval Using Deep Learning-Based Feature Engineering",
      "abstract": "Medical image retrieval is essential to modern medical treatment because it enables doctors to diagnose and treat a variety of illnesses. In this study, we present an innovative technique for selecting the methodology of medical images by combining textural and visual information. Knowing the imaging process behind an idea, such as a chest X-ray, skin dermatology, or breast histopathology image, may be extremely helpful to healthcare professionals since it can aid in image investigation and provide important information about the imaging technique used. We use deep learning-based feature engineering to do this, using both the textural and visual components of healthcare images. We extract detailed visual information from the images using a predefined Convolutional Neural Network (CNN). The Global-Local Pyramid Pattern (GLPP), Zernike moments, and Haralick are also used to physically separate the pertinent parts from the images&#x2019; other visual and factual aspects. These essential characteristics, such as image modality and imaging technique-specific characteristics, provide additional information about the technology. We employ a feature fusion method that incorporates the depictions obtained from the two modalities in order to combine the textural and visual elements. This fusion process, which improves the discrimination capacity of the feature vectors, makes accurate modality classification possible. We conducted trials on a sizable dataset consisting of various medical images to assess the effectiveness of our proposed method. The results indicate that, in comparison to conventional methods, our technique outperforms modality retrieval, with a precision of 95.89 and a recall of 96.31. The accuracy and robustness of the classification task are greatly creased by the combination of textural and visual data. Through the integration of textural and visual information, our work offers a unique method for recovering the modality of medical images. This method has the potential to greatly improve the speed and accuracy of medical image processing and diagnosis by helping experts rapidly and accurately identify the imaging technology being utilized.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Saeed Iqbal et al.",
      "keywords": "Computer science; Artificial intelligence; Modality (human\u2013computer interaction); Convolutional neural network; Visualization; Medical imaging; Pattern recognition (psychology); Feature (linguistics); Deep learning; Image retrieval; Robustness (evolution); Computer vision; Pooling; Modalities; Feature vector; Feature extraction; Image fusion; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3310245",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226444381",
      "doi": "10.1109/access.2022.3163311",
      "title": "Investigation of a Web-Based Explainable AI Screening for Prolonged Grief Disorder",
      "abstract": "Losing a loved one through death is known to be one of the most challenging life events. To help the bereaved and their therapists monitor and better understand the factors that contribute to Prolonged Grief Disorder (PGD), we co-designed and studied a web-based explainable AI screening system named \u201cGrief Inquiries Following Tragedy (GIFT).\u201d We used an initial iteration of the system to collect PGD-related data from 611 participants. Using this data, we developed a model that could be used to screen and explain the different factors contributing to PGD. Our results showed that a Random Forest model using Bereavement risk and outcome features performed best in detecting PGD (AUC=0.772), with features such as a negative intepretation of grief and the ability to integrate stressful life events contributing strongly to the model. Afterwards, five grief experts were asked to provide feedback on a mock-up of the results generated by the GIFT model, and discuss the potential value of the explanatory AI model in real-world PGD care. Overall, the grief experts were generally receptive towards using such a tool in a clinical setting and acknowledged the benefit of offering a personalized result to the users based on the explainable AI model. Our results also showed that, in addition to the explainability of the model, the grief experts also preferred a more \u201cempathetic\u201d and \u201cactionable\u201d AI system, especially, when designing for patient end-users.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Wan Jou She et al.",
      "keywords": "Grief; Complicated grief; Tragedy (event); Computer science; Psychology; Psychotherapist; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3163311",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388676639",
      "doi": "10.1109/jtehm.2023.3332618",
      "title": "Applying Machine Learning and Point-Set Registration to Automatically Measure the Severity of Spinal Curvature on Radiographs",
      "abstract": "The developed method measured Cobb angles on radiographs automatically with high accuracy, quick measurement time, and interpretability, suggesting clinical feasibility.",
      "year": "2023",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Jason Wong et al.",
      "keywords": "Radiography; Artificial intelligence; Measure (data warehouse); Computer science; Curvature; Set (abstract data type); Point (geometry); Image registration; Computer vision; Pattern recognition (psychology); Medicine; Mathematics; Radiology; Data mining; Geometry; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2023.3332618",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3199382795",
      "doi": "10.1109/access.2021.3113812",
      "title": "Optimization in the Context of COVID-19 Prediction and Control: A Literature Review",
      "abstract": "This paper presents an overview of some key results from a body of optimization studies that are specifically related to COVID-19, as reported in the literature during 2020-2021. As shown in this paper, optimization studies in the context of COVID-19 have been used for many aspects of the pandemic. From these studies, it is observed that since COVID-19 is a multifaceted problem, it cannot be studied from a single perspective or framework, and neither can the related optimization models. Four new and different frameworks are proposed that capture the essence of analyzing COVID-19 (or any pandemic for that matter) and the relevant optimization models. These are: (i) microscale vs. macroscale perspective; (ii) early stages vs. later stages perspective; (iii) aspects with direct vs. indirect relationship to COVID-19; and (iv) compartmentalized perspective. To limit the scope of the review, only optimization studies related to the prediction and control of COVID-19 are considered (public health focused), and which utilize formal optimization techniques or machine learning approaches. In this context and to the best of our knowledge, this survey paper is the first in the literature with a focus on the prediction and control related optimization studies. These studies include optimization of screening testing strategies, prediction, prevention and control, resource management, vaccination prioritization, and decision support tools. Upon reviewing the literature, this paper identifies current gaps and major challenges that hinder the closure of these gaps and provides some insights into future research directions.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Elizabeth Jordan et al.",
      "keywords": "Computer science; Context (archaeology); Perspective (graphical); Scope (computer science); Coronavirus disease 2019 (COVID-19); Management science; Risk analysis (engineering); Optimization problem; Data science; Operations research; Artificial intelligence; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3113812",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387789899",
      "doi": "10.1109/access.2023.3325844",
      "title": "Metaverse Key Requirements and Platforms Survey",
      "abstract": "The growing interest in the metaverse has led to an abundance of platforms, each with its own unique features and limitations. This paper&#x2019;s objective is two-fold. First, we aim at providing an objective analysis of requirements that need to be fulfilled by metaverse platforms. We survey a broad set of criteria including interoperability, immersiveness, persistence, multimodal and social interaction, scalability, level of openness, configurability, market access, security, and blockchain integration, among others. Second, we review a wide range of existing metaverse platforms, and we critically evaluate their ability to meet the requirements listed. We identify their limitations, which must be addressed to establish fair, trustworthy, and interactive experiences within the metaverse ecosystem. Looking forward, we highlight the need for further research and development in areas such as decentralization, improved security and privacy measures, and the integration of emerging technologies like blockchain and AI, as essential building blocks for a resilient and secure metaverse.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Akbobek Abilkaiyrkyzy et al.",
      "keywords": "Computer science; Metaverse; Interoperability; Scalability; Interoperation; Key (lock); Data science; Trustworthiness; World Wide Web; Computer security; Human\u2013computer interaction; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3325844",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391559430",
      "doi": "10.1109/access.2024.3363165",
      "title": "A Bibliometric Analysis of Technology in Digital Health: Exploring Health Metaverse and Visualizing Emerging Healthcare Management Trends",
      "abstract": "The digital economy has engendered Health Metaverse, an innovative technology with vast potential to transform healthcare through immersive experiences. The Health Metaverse serves as a convergence point for a multitude of technologies, including artificial intelligence (AI), virtual reality in heath, augmented reality in health, internet-connected medical devices, quantum computing, and more. This convergence opens up possibilities, for advancing quality healthcare. Therefore, reviewing recent influential literature is critical to understand current methods and envision future improvements. This study utilizes a hybrid bibliometric-structured methodology combining descriptive and bibliometric network analysis. To gather information we conducted searches on the Web of Science database and reviewed references. Our inclusion criteria focused on articles and reviews published between January 2012 and June 2023. We used keyword groups for our searches. Then performed bibliometric analysis followed by content analysis. Papers were reviewed, analyzed and categorized into focuses on multimodal medical information standards, medical/social data fusion, telemedicine, online health management, and medical AI. This bibliometric analysis of 34 thousand publications over 10 years proposes medical and health informatics in the Metaverse. Five future research direction clusters were identified. It delineates intelligent solutions bridging healthcare barriers. In conclusion, this review examines the Metaverse, in healthcare explores cutting edge technologies, applications, projects and highlights areas where adaptation may be needed. It identifies adaptation issues and suggests solutions warranting further research.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Hoang-Sy Nguyen et al.",
      "keywords": "Computer science; Metaverse; Data science; Health care; Health informatics; Adaptation (eye); Big data; Bibliometrics; Knowledge management; Virtual reality; World Wide Web; Human\u2013computer interaction; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3363165",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3011290843",
      "doi": "10.1109/tts.2020.2976425",
      "title": "Dealing With Technological Trajectories: Where We Have Come From and Where We Are Going",
      "abstract": "Technological progress is widely recognized as having considerable impact on human societies, which have become more and more dependent on human-made tools that entail intricate scientific processes, considered <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">technology</i> [item 1) in the Related Works]. The adoption of such tools is borne out of the necessity of survival at first [item 2) in the Related Works], and subsequently as a means to improve access to food, shelter, and clothing; arguably things that we cannot live without. Nevertheless, the urgency of understanding the role of technology in human life has never been as vital as today. Indeed, one could say that technological progress is the key ingredient driving human civilization: the invention of ever more complex tools traces the history of human civilization and its development. Each generation of technology lays the foundation for the next, the invention of simple machines, such as the wheel, for example, enabled the invention of the wheelbarrow, which enabled in turn building larger structures. In parallel, the wheel enabled the construction of gears to transmit power from crankshaft to driveshaft and also the rotation of magnetic tapes permitting the capture of binary data leading to the spinning hard disk drives and their superior digital data storage capacity.",
      "year": "2020",
      "journal": "IEEE Transactions on Technology and Society",
      "authors": "Katina Michael et al.",
      "keywords": "Civilization; Clothing; Computer science; Data science; Law; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tts.2020.2976425",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3089028909",
      "doi": "10.1109/jproc.2021.3052449",
      "title": "A Unifying Review of Deep and Shallow Anomaly Detection",
      "abstract": "Deep learning approaches to anomaly detection (AD) have recently improved the state of the art in detection performance on complex data sets, such as large collections of images or text. These results have sparked a renewed interest in the AD problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review, we aim to identify the common underlying principles and the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic \u201cshallow\u201d and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that are enriched by the use of recent explainability techniques and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in AD.",
      "year": "2021",
      "journal": "Proceedings of the IEEE",
      "authors": "Lukas Ruff et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2021.3052449",
      "cited_by_count": 747,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2797568851",
      "doi": "10.1109/tkde.2018.2885515",
      "title": "Utilizing Neural Networks and Linguistic Metadata for Early Detection of Depression Indications in Text Sequences",
      "abstract": "Depression is ranked as the largest contributor to global disability and is also a major reason for suicide. Still, many individuals suffering from forms of depression are not treated for various reasons. Previous studies have shown that depression also has an effect on language usage and that many depressed individuals use social media platforms or the internet in general to get information or discuss their problems. This paper addresses the early detection of depression using machine learning models based on messages on a social platform. In particular, a convolutional neural network based on different word embeddings is evaluated and compared to a classification based on user-level linguistic metadata. An ensemble of both approaches is shown to achieve state-of-the-art results in a current early detection task. Furthermore, the currently popular ERDE score as metric for early detection systems is examined in detail and its drawbacks in the context of shared tasks are illustrated. A slightly modified metric is proposed and compared to the original score. Finally, a new word embedding was trained on a large corpus of the same domain as the described task and is evaluated as well.",
      "year": "2018",
      "journal": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "Marcel Trotzek et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tkde.2018.2885515",
      "cited_by_count": 199,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3099098707",
      "doi": "10.1109/access.2020.3038605",
      "title": "A Gentle Introduction to Reinforcement Learning and its Application in Different Fields",
      "abstract": "Due to the recent progress in Deep Neural Networks, Reinforcement Learning (RL) has become one of the most important and useful technology. It is a learning method where a software agent interacts with an unknown environment, selects actions, and progressively discovers the environment dynamics. RL has been effectively applied in many important areas of real life. This article intends to provide an in-depth introduction of the Markov Decision Process, RL and its algorithms. Moreover, we present a literature review of the application of RL to a variety of fields, including robotics and autonomous control, communication and networking, natural language processing, games and self-organized system, scheduling management and configuration of resources, and computer vision.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Muddasar Naeem et al.",
      "keywords": "Reinforcement learning; Computer science; Markov decision process; Artificial intelligence; Scheduling (production processes); Variety (cybernetics); Robotics; Process (computing); Robot; Partially observable Markov decision process; Software; Software agent; Human\u2013computer interaction; Markov process; Machine learning; Distributed computing; Markov chain; Markov model; Engineering; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3038605",
      "cited_by_count": 221,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3132259035",
      "doi": "10.1109/jbhi.2021.3062322",
      "title": "Limitations of Transformers on Clinical Text Classification",
      "abstract": "Bidirectional Encoder Representations from Transformers (BERT) and BERT-based approaches are the current state-of-the-art in many natural language processing (NLP) tasks; however, their application to document classification on long clinical texts is limited. In this work, we introduce four methods to scale BERT, which by default can only handle input sequences up to approximately 400 words long, to perform document classification on clinical texts several thousand words long. We compare these methods against two much simpler architectures - a word-level convolutional neural network and a hierarchical self-attention network - and show that BERT often cannot beat these simpler baselines when classifying MIMIC-III discharge summaries and SEER cancer pathology reports. In our analysis, we show that two key components of BERT - pretraining and WordPiece tokenization - may actually be inhibiting BERT's performance on clinical text classification tasks where the input document is several thousand words long and where correctly identifying labels may depend more on identifying a few key words or phrases rather than understanding the contextual meaning of sequences of text.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Shang Gao et al.",
      "keywords": "Computer science; Natural language processing; Artificial intelligence; Lexical analysis; Transformer; Encoder; Convolutional neural network; Document classification",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3062322",
      "cited_by_count": 147,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225510469",
      "doi": "10.1109/access.2022.3163384",
      "title": "A Review on Bayesian Deep Learning in Healthcare: Applications and Challenges",
      "abstract": "In the last decade, Deep Learning (DL) has revolutionized the use of artificial intelligence, and it has been deployed in different fields of healthcare applications such as image processing, natural language processing, and signal processing. DL models have also been intensely used in different tasks of healthcare such as disease diagnostics and treatments. Deep learning techniques have surpassed other machine learning algorithms and proved to be the ultimate tools for many state-of-the-art applications. Despite all that success, classical deep learning has limitations and their models tend to be very confident about their predicted decisions because it does not know when it makes mistake. For the healthcare field, this limitation can have a negative impact on models predictions since almost all decisions regarding patients and diseases are sensitive. Therefore, Bayesian deep learning (BDL) has been developed to overcome these limitations. Unlike classical DL, BDL uses probability distributions for the model parameters, which makes it possible to estimate the whole uncertainties associated with the predicted outputs. In this regard, BDL offers a rigorous framework to quantify all sources of uncertainties in the model. This study reviews popular techniques of using Bayesian deep learning with their benefits and limitations. It also reviewed recent deep learning architecture such as Convolutional Neural Networks and Recurrent Neural Networks. In particular, the applications of Bayesian deep learning in healthcare have been discussed such as its use in medical imaging tasks, clinical signal processing, medical natural language processing, and electronic health records. Furthermore, this paper has covered the deployment of Bayesian deep learning for some of the widespread diseases. This paper has also discussed the fundamental research challenges and highlighted some research gaps in both the Bayesian deep learning and healthcare perspective.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Abdullah A. Abdullah et al.",
      "keywords": "Deep learning; Artificial intelligence; Machine learning; Computer science; Convolutional neural network; Health care; Bayesian probability",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3163384",
      "cited_by_count": 117,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4383751808",
      "doi": "10.1109/access.2023.3293857",
      "title": "A Hybrid Deep Learning Model to Predict the Impact of COVID-19 on Mental Health From Social Media Big Data",
      "abstract": "The novel coronavirus disease (COVID-19) pandemic is provoking a prevalent consequence on mental health because of less interaction among people, economic collapse, negativity, fear of losing jobs, and death of the near and dear ones. To express their mental state, people often are using social media as one of the preferred means. Due to reduced outdoor activities, people are spending more time on social media than usual and expressing their emotion of anxiety, fear, and depression. On a daily basis, about 2.5 quintillion bytes of data are generated on social media. Analyzing this big data can become an excellent means to evaluate the effect of COVID-19 on mental health. In this work, we have analyzed data from Twitter microblog (tweets) to find out the effect of COVID-19 on people&#x2019;s mental health with a special focus on depression. We propose a novel pipeline, based on recurrent neural network (in the form of long short-term memory or LSTM) and convolutional neural network, capable of identifying depressive tweets with an accuracy of 99.42&#x0025;. Preprocessed using various natural language processing techniques, the aim was to find out depressive emotion from these tweets. Analyzing over 571 thousand tweets posted between October 2019 and May 2020 by 482 users, a significant rise in depressing tweets was observed between February and May of 2020, which indicates as an impact of the long ongoing COVID-19 pandemic situation.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Md. Hasan Al Banna et al.",
      "keywords": "Mental health; Social media; Computer science; Depression (economics); Convolutional neural network; Anxiety; Deep learning; Big data; Artificial intelligence; Pandemic; Coronavirus disease 2019 (COVID-19); Sentiment analysis; Psychology; Machine learning; Internet privacy; Psychiatry; Medicine; World Wide Web; Data mining; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3293857",
      "cited_by_count": 63,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3033346947",
      "doi": "10.1109/access.2020.3000075",
      "title": "Application of Machine Learning and Word Embeddings in the Classification of Cancer Diagnosis Using Patient Anamnesis",
      "abstract": "Currently, one of the main challenges for information systems in healthcare is focused on support for health professionals regarding disease classifications. This work presents an innovative method for a recommendation system for the diagnosis of breast cancer using patient medical histories. In this proposal, techniques of natural language processing (NLP) were implemented on real datasets: one comprised 160, 560 medical histories of anonymous patients from a hospital in Chile for the following categories: breast cancer, cysts and nodules, other cancer, breast cancer surgeries and other diagnoses; and the other dataset was obtained from the MIMIC III dataset. With the application of word-embedding techniques, such as word2vec's skip-gram and BERT, and machine learning techniques, a recommendation system as a tool to support the physician's decision-making was implemented. The obtained results demonstrate that using word embeddings can define a good-quality recommendation system. The results of 20 experiments with 5-fold cross-validation for anamnesis written in Spanish yielded an F1 of 0.980 &#x00B1; 0.0014 on the classification of `cancer' versus `not cancer' and 0.986 &#x00B1; 0.0014 for `breast cancer' versus `other cancer'. Similar results were obtained with the MIMIC III dataset.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Andr\u00e9s Ramos Magna et al.",
      "keywords": "Word2vec; Medical diagnosis; Anamnesis; Computer science; Artificial intelligence; Breast cancer; Cancer; Word embedding; Machine learning; Natural language processing; Embedding; Medicine; Radiology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3000075",
      "cited_by_count": 51,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3114200511",
      "doi": "10.1109/access.2020.3048172",
      "title": "A Review on Traditional Machine Learning and Deep Learning Models for WBCs Classification in Blood Smear Images",
      "abstract": "In computer vision, traditional machine learning (TML) and deep learning (DL) methods have significantly contributed to the advancements of medical image analysis (MIA) by enhancing prediction accuracy, leading to appropriate planning and diagnosis. These methods substantially improved the diagnoses of automatic brain tumor and leukemia/blood cancer detection and can assist the hematologist and doctors by providing a second opinion. This review provides an in-depth analysis of available TML and DL techniques for MIA with a significant focus on leukocytes classification in blood smear images and other medical imaging domains, i.e., magnetic resonance imaging (MRI), CT images, X-ray, and ultrasounds. The proposed review's main impact is to find the most suitable TML and DL techniques in MIA, especially for leukocyte classification in blood smear images. The advanced DL techniques, particularly the evolving convolutional neural networks-based models in the MIA domain, are deeply investigated in this review article. The related literature study reveals that mainstream TML methods are vastly applied to microscopic blood smear images for white blood cells (WBC) analysis. They provide valuable information to medical specialists and help diagnose various hematic diseases such as AIDS and blood cancer (Leukaemia). Based on WBC related literature study and its extensive analysis presented in this study, we derive future research directions for scientists and practitioners working in the MIA domain.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Siraj M. Khan et al.",
      "keywords": "Hematologist; Medical diagnosis; Convolutional neural network; Artificial intelligence; Deep learning; Computer science; Blood smear; Medicine; Domain (mathematical analysis); Magnetic resonance imaging; Medical imaging; Machine learning; Medical physics; Pathology; Radiology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3048172",
      "cited_by_count": 126,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3216626696",
      "doi": "10.1109/access.2021.3130956",
      "title": "A Survey on Event Extraction for Natural Language Understanding: Riding the Biomedical Literature Wave",
      "abstract": "Motivation: The scientific literature embeds an enormous amount of relational knowledge, encompassing interactions between biomedical entities, like proteins, drugs, and symptoms. To cope with the ever-increasing number of publications, researchers are experiencing a surge of interest in extracting valuable, structured, concise, and unambiguous information from plain texts. With the development of deep learning, the granularity of information extraction is evolving from entities and pairwise relations to events. Events can model complex interactions involving multiple participants having a specific semantic role, also handling nested and overlapping definitions. After being studied for years, automatic event extraction is on the road to significantly impact biology in a wide range of applications, from knowledge base enrichment to the formulation of new research hypotheses. Results: This paper provides a comprehensive and up-to-date survey on the link between event extraction and natural language understanding, focusing on the biomedical domain. First, we establish a flexible event definition, summarizing the terminological efforts conducted in various areas. Second, we present the event extraction task, the related challenges, and the available annotated corpora. Third, we deeply explore the most representative methods and present an analysis of the current state-of-the-art, accompanied by performance discussion. To help researchers navigate the avalanche of event extraction works, we provide a detailed taxonomy for classifying the contributions proposed by the community. Fourth, we compare solutions applied in biomedicine with those evaluated in other domains, identifying research opportunities and providing insights for strategies not yet explored. Finally, we discuss applications and our envisions about future perspectives, moving the needle on explainability and knowledge injection.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Giacomo Frisoni et al.",
      "keywords": "Computer science; Event (particle physics); Natural (archaeology); Extraction (chemistry); Natural language processing; Data science; History; Physics; Chemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3130956",
      "cited_by_count": 68,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312704644",
      "doi": "10.1109/access.2022.3227208",
      "title": "An AI-Based Medical Chatbot Model for Infectious Disease Prediction",
      "abstract": "The purpose of this paper is to show concisely how we can promote chatbots in the medical sector and cure infectious diseases. We can create awareness through the users and the users can get proper medical solutions to prevent disease. We created a preliminary training model and a study report to improve human interaction in databases in 2021. Through natural language processing, we describe the human behaviors and characteristics of the chatbot. In this paper, we propose an AI Chatbot interaction and prediction model using a deep feedforward multilayer perceptron. Our analysis discovered a gap in knowledge about theoretical guidelines and practical recommendations for creating AI chatbots for lifestyle improvement programs. A brief comparison of our proposed model concerning the time complexity and accuracy of testing is also discussed in this paper. In our work, the loss is a minimum of 0.1232 and the highest accuracy is 94.32&#x0025;. This study describes the functionalities and possible applications of medical chatbots and explores the accompanying challenges posed by the use of these emerging technologies during such health crises mainly posed by pandemics. We believe that our findings will help researchers get a better understanding of the layout and applications of these revolutionary technologies, which will be required for continuous improvement in medical chatbot functionality and will be useful in avoiding COVID-19.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Sanjay Chakraborty et al.",
      "keywords": "Chatbot; Computer science; Artificial intelligence; Data science; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3227208",
      "cited_by_count": 61,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3193740800",
      "doi": "10.1109/access.2021.3106443",
      "title": "Bloom\u2019s Learning Outcomes\u2019 Automatic Classification Using LSTM and Pretrained Word Embeddings",
      "abstract": "Bloom\u2019s taxonomy is a popular model to classify educational learning objectives into different learning levels for three domains including cognitive, affective and psycho motor. Each domain is further detailed into different levels. The cognitive domain includes knowledge, comprehension, application, analysis, synthesis and evaluation levels. In educational institutions, designing course learning outcomes (CLOs) as per different levels of Bloom and mapping of assessment items on designed CLOs is an important task \u2014 every semester, faculty and administrators read thousands of statements to complete the tedious task of such mapping of CLOs and assessment items into Bloom\u2019s levels for an improved student learning. This paper proposes LSTM based deep learning model to perform classification of CLOs and assessment items in different levels of Bloom in cognitive domain. Although, there has been some attempts in the literature to automatically assign Bloom\u2019s taxonomy category using keywords-based approach but it suffers from the problem of low accuracy and overlapping of keywords. Initially, when we performed keywords-based approach on our datasets we achieved an overall accuracy of 55% for classification of CLOs and assessment items into Bloom\u2019s taxonomy. The proposed model predicts Bloom\u2019s level for CLO and assessment question item, respectively. The proposed model is simple in terms of the architecture as compared to other deep learning models reported in literature and achieves classification accuracy of 87% and 74% on CLOs and assessment question items, respectively. The proposed model obtained 3% increase in overall accuracy comparing to an existing study for the same task. To the best of our knowledge, this is first attempt towards applying deep learning on classifying educational objectives in Bloom\u2019s levels.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Sarang Shaikh et al.",
      "keywords": "Clos network; Computer science; Taxonomy (biology); Artificial intelligence; Task (project management); Domain (mathematical analysis); Machine learning; Natural language processing; Bloom's taxonomy; Deep learning; Cognition; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3106443",
      "cited_by_count": 56,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3166117684",
      "doi": "10.1109/access.2021.3086530",
      "title": "Deep Neural Architectures for Medical Image Semantic Segmentation: Review",
      "abstract": "Deep learning has an enormous impact on medical image analysis. Many computer-aided diagnostic systems equipped with deep networks are rapidly reducing human intervention in healthcare. Among several applications, medical image semantic segmentation is one of the core areas of active research to delineate the anatomical structures and other regions of interest. It has a significant contribution to healthcare and provides guided interventions, radiotherapy, and improved radiological diagnostics. The underlying article provides a brief overview of deep convolutional neural architecture, the platforms and applications of deep neural networks, metrics used for empirical evaluation, state-of-the-art semantic segmentation architectures based on a foundational convolution concept, and a review of publicly available medical image datasets highlighting four distinct regions of interest. The article also analyzes the existing work and provides open-ended potential research directions in deep medical image semantic segmentation.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Muhammad Zubair Khan et al.",
      "keywords": "Computer science; Deep learning; Convolutional neural network; Artificial intelligence; Segmentation; Image segmentation; Medical imaging; Health care; Data science; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3086530",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2905315292",
      "doi": "10.1109/access.2018.2886311",
      "title": "GrEDeL: A Knowledge Graph Embedding Based Method for Drug Discovery From Biomedical Literatures",
      "abstract": "Drug discovery is the process by which new candidate medications are discovered. Developing a new drug is a lengthy, complex, and expensive process. Here, in this paper, we propose a biomedical knowledge graph embedding-based recurrent neural network method called GrEDeL, which discovers potential drugs for diseases by mining published biomedical literature. GrEDeL first builds a biomedical knowledge graph by exploiting the relations extracted from biomedical abstracts. Then, the graph data are converted into a low dimensional space by leveraging the knowledge graph embedding methods. After that, a recurrent neural network model is trained by the known drug therapies which are represented by graph embeddings. Finally, it uses the learned model to discover candidate drugs for diseases of interest from biomedical literature. The experimental results show that our method could not only effectively discover new drugs by mining literature, but also could provide the corresponding mechanism of actions for the candidate drugs. It could be a supplementary method for the current traditional drug discovery methods.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Shengtian Sang et al.",
      "keywords": "Computer science; Embedding; Knowledge graph; Drug discovery; Graph; Graph theory; Artificial intelligence; Theoretical computer science; Bioinformatics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2886311",
      "cited_by_count": 67,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3107358227",
      "doi": "10.1109/access.2021.3068392",
      "title": "Trends in Deep Learning for Medical Hyperspectral Image Analysis",
      "abstract": "Deep learning algorithms have seen acute growth of interest in their\\napplications throughout several fields of interest in the last decade, with\\nmedical hyperspectral imaging being a particularly promising domain. So far, to\\nthe best of our knowledge, there is no review paper that discusses the\\nimplementation of deep learning for medical hyperspectral imaging, which is\\nwhat this review paper aims to accomplish by examining publications that\\ncurrently utilize deep learning to perform effective analysis of medical\\nhyperspectral imagery. This paper discusses deep learning concepts that are\\nrelevant and applicable to medical hyperspectral imaging analysis, several of\\nwhich have been implemented since the boom in deep learning. This will comprise\\nof reviewing the use of deep learning for classification, segmentation, and\\ndetection in order to investigate the analysis of medical hyperspectral\\nimaging. Lastly, we discuss the current and future challenges pertaining to\\nthis discipline and the possible efforts to overcome such trials.\\n",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Uzair Khan et al.",
      "keywords": "Hyperspectral imaging; Deep learning; Computer science; Artificial intelligence; Medical imaging; Machine learning; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3068392",
      "cited_by_count": 80,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4214839262",
      "doi": "10.1109/access.2022.3156894",
      "title": "Medical Image Segmentation Using Transformer Networks",
      "abstract": "Deep learning models represent the state of the art in medical image segmentation. Most of these models are fully-convolutional networks (FCNs), namely each layer processes the output of the preceding layer with convolution operations. The convolution operation enjoys several important properties such as sparse interactions, parameter sharing, and translation equivariance. Because of these properties, FCNs possess a strong and useful inductive bias for image modeling and analysis. However, they also have certain important shortcomings, such as performing a fixed and pre-determined operation on a test image regardless of its content and difficulty in modeling long-range interactions. In this work we show that a different deep neural network architecture, based entirely on self-attention between neighboring image patches and without any convolution operations, can achieve more accurate segmentations than FCNs. Our proposed model is based directly on the transformer network architecture. Given a 3D image block, our network divides it into non-overlapping 3D patches and computes a 1D embedding for each patch. The network predicts the segmentation map for the block based on the self-attention between these patch embeddings. Furthermore, in order to address the common problem of scarcity of labeled medical images, we propose methods for pre-training this model on large corpora of unlabeled images. Our experiments show that the proposed model can achieve segmentation accuracies that are better than several state of the art FCN architectures on two datasets. Our proposed network can be trained using only tens of labeled images. Moreover, with the proposed pre-training strategies, our network outperforms FCNs when labeled training data is small.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Davood Karimi et al.",
      "keywords": "Computer science; Artificial intelligence; Segmentation; Embedding; Convolution (computer science); Deep learning; Image segmentation; Transformer; Convolutional neural network; Block (permutation group theory); Pattern recognition (psychology); Image (mathematics); Network architecture; Artificial neural network; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3156894",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3202316099",
      "doi": "10.1109/tcds.2021.3115228",
      "title": "Conversational Affective Social Robots for Ageing and Dementia Support",
      "abstract": "Socially assistive robots (SAR) hold significant potential to assist older adults and people with dementia in human engagement and clinical contexts by supporting mental health and independence at home. While SAR research has recently experienced prolific growth, long-term trust, clinical translation and patient benefit remain immature. Affective human-robot interactions are unresolved and the deployment of robots with conversational abilities is fundamental for robustness and humanrobot engagement. In this paper, we review the state of the art within the past two decades, design trends, and current applications of conversational affective SAR for ageing and dementia support. A horizon scanning of AI voice technology for healthcare, including ubiquitous smart speakers, is further introduced to address current gaps inhibiting home use. We discuss the role of user-centred approaches in the design of voice systems, including the capacity to handle communication breakdowns for effective use by target populations. We summarise the state of development in interactions using speech and natural language processing, which forms a baseline for longitudinal health monitoring and cognitive assessment. Drawing from this foundation, we identify open challenges and propose future directions to advance conversational affective social robots for: 1) user engagement, 2) deployment in real-world settings, and 3) clinical translation.",
      "year": "2021",
      "journal": "IEEE Transactions on Cognitive and Developmental Systems",
      "authors": "Maria R. Lima et al.",
      "keywords": "Software deployment; Computer science; Dementia; Robot; Human\u2013computer interaction; Human\u2013robot interaction; Social robot; Mental health; Robustness (evolution); Psychology; Artificial intelligence; Mobile robot; Medicine; Disease; Psychiatry; Robot control",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcds.2021.3115228",
      "cited_by_count": 58,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4362702150",
      "doi": "10.1109/trpms.2023.3265863",
      "title": "Current and Emerging Trends in Medical Image Segmentation With Deep Learning",
      "abstract": "In recent years, the segmentation of anatomical or pathological structures using deep learning has experienced a widespread interest in medical image analysis. Remarkably successful performance has been reported in many imaging modalities and for a variety of clinical contexts to support clinicians in computer-assisted diagnosis, therapy, or surgical planning purposes. However, despite the increasing amount of medical image segmentation challenges, there remains little consensus on which methodology performs best. Therefore, we examine in this article the numerous developments and breakthroughs brought since the rise of U-Net-inspired architectures. Especially, we focus on the technical challenges and emerging trends that the community is now focusing on, including conditional generative adversarial and cascaded networks, medical Transformers, contrastive learning, knowledge distillation, active learning, prior knowledge embedding, cross-modality learning, multistructure analysis, federated learning, or semi-supervised and self-supervised paradigms. We also suggest possible avenues to be further investigated in future research efforts.<br/><br/>",
      "year": "2023",
      "journal": "IEEE Transactions on Radiation and Plasma Medical Sciences",
      "authors": "Pierre-Henri Conze et al.",
      "keywords": "Deep learning; Artificial intelligence; Computer science; Modalities; Adversarial system; Segmentation; Generative grammar; Machine learning; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/trpms.2023.3265863",
      "cited_by_count": 112,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3028573817",
      "doi": "10.1109/access.2020.2996022",
      "title": "Unsupervised Deep Learning CAD Scheme for the Detection of Malaria in Blood Smear Microscopic Images",
      "abstract": "Recent advances in deep learning, coupled with the onslaught of unlabelled medical data have drawn ever-increasing research interests by discovering multiple levels of distributed representations and solving complex medical related problems. Malaria disease detection in early stage requires an accurate and precise diagnosis in order to achieve successful patient remission. This paper proposes a comprehensive computer-aided diagnosis (CAD) scheme for identifying the presence of malaria parasites in thick blood smear images. The parameters of the scheme are pre-trained by functional link artificial neural network followed by sparse stacked autoencoder. The optimum size of the CAD scheme used in this research is 12500-2500-100-50-2, where the input layer has 12500 nodes and Softmax classifier output layer has 2 nodes. Moreover, the 10- fold cross validation reflects that the classification is reliable and is applicable to new patient blood smear images. The proposed CAD scheme has been evaluated using malaria blood smear image data set, achieving a detection accuracy of 89.10%, a sensitivity of 93.90% and specificity of 83.10%. The extensive comparative experiment suggests that the proposed CAD scheme provides richer effectiveness and efficiency for malaria data set compared to other deep learning techniques for better diagnosis decision and management. This work implements a novel approach to fast processing and will be a beneficial tool in disease identification.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Priyadarshini Adyasha Pattanaik et al.",
      "keywords": "Softmax function; Artificial intelligence; Computer science; CAD; Autoencoder; Deep learning; Classifier (UML); Machine learning; Pattern recognition (psychology); Scheme (mathematics); Malaria; Artificial neural network; Computer-aided diagnosis; Data mining; Mathematics; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2996022",
      "cited_by_count": 73,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285191586",
      "doi": "10.1109/access.2022.3182498",
      "title": "Pneumonia Detection Proposing a Hybrid Deep Convolutional Neural Network Based on Two Parallel Visual Geometry Group Architectures and Machine Learning Classifiers",
      "abstract": "Pneumonia is an acute respiratory infection that has led to significant deaths of people worldwide. This lung disease is more common in people older than 65 and children under five years old. Although the treatment of pneumonia can be challenging, it can be prevented by early diagnosis using Computer-Aided Diagnosis (CAD) systems. Chest X-Rays (CXRs) are currently the primary imaging tool for detection of pneumonia, which are widely used by radiologists. While the standard approach of detecting pneumonia is based on clinicians&#x2019; decisions, various Deep Learning (DL) methods have been developed for detection of pneumonia considering CAD system. In this regard, a novel hybrid Convolutional Neural Network (CNN) model is proposed using three classification approaches. In the first classification approach, Fully-Connected (FC) layers are utilized for the classification of CXR images. This model is trained for several epochs and the weights that result in the highest classification accuracy are saved. In the second classification approach, the trained optimized weights are utilized to extract the most representative CXR image features and Machine Learning (ML) classifiers are employed to classify the images. In the third classification approach, an ensemble of the proposed classifiers is created to classify CXR images. The results suggest that the proposed ensemble classifier using Support Vector Machine (SVM) with Radial Basis Function (RBF) and Logistic Regression (LR) classifiers has the best performance with 98.55&#x0025; accuracy. Ultimately, this model is deployed to create a web-based CAD system to assist radiologists in pneumonia detection with a significant accuracy.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mohammad Yaseliani et al.",
      "keywords": "Support vector machine; Artificial intelligence; Computer science; Convolutional neural network; CAD; Classifier (UML); Machine learning; Pattern recognition (psychology); Pneumonia; Contextual image classification; Computer-aided diagnosis; Deep learning; Feature extraction; Logistic regression; Artificial neural network; Image (mathematics); Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3182498",
      "cited_by_count": 71,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384284191",
      "doi": "10.1109/access.2023.3295694",
      "title": "Real-Time Analytics: Concepts, Architectures, and ML/AI Considerations",
      "abstract": "With the advancement in intelligent devices, social media, and the Internet of Things, staggering amounts of new data are being generated, and the pace is continuously accelerating. Real-time analytics (RTA) has emerged as a distinct branch of big data analytics focusing on the velocity aspect of big data, in which data is prepared, processed, and analyzed as it arrives, intending to generate insights and create business value in near real-time. The objective of this paper is to provide an overview of key concepts and architectural approaches for designing RTA solutions, including the relevant infrastructure, processing, and analytics platforms, as well as analytics techniques and tools with the most up-to-date machine learning and artificial intelligence considerations, and position these in the context of the most prominent platforms and analytics techniques. The paper develops a logical analytics stack to support the description of key functionality and relationships between relevant components in RTA solutions based on a thorough literature review and industrial practice. This provides practitioners with guidance in selecting the most appropriate solutions for their RTA problems, including the application of emerging AI technologies in this context. The paper discusses the complex event processing technology that has influenced many recent data streaming solutions in the analytics stack and highlights the integration of machine learning and artificial intelligence into RTA solutions. Some real-life application scenarios in the finance and health domains are presented, including several of the authors&#x2019; earlier contributions, to demonstrate the utilization of the techniques and technologies discussed in this paper. Future research directions and remaining challenges are discussed.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Weisi Chen et al.",
      "keywords": "Computer science; Big data; Data science; Analytics; Business intelligence; Context (archaeology); Data analysis; Key (lock); Business analytics; Software analytics; Knowledge management; Data mining; Computer security; Business model",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3295694",
      "cited_by_count": 64,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3128640753",
      "doi": "10.1109/access.2021.3056175",
      "title": "Automatic Report Generation for Chest X-Ray Images via Adversarial Reinforcement Learning",
      "abstract": "An adversarial reinforced report-generation framework for chest x-ray images is proposed. Previous medical-report-generation models are mostly trained by minimizing the cross-entropy loss or further optimizing the common image-captioning metrics, such as CIDEr, ignoring diagnostic accuracy, which should be the first consideration in this area. Inspired by the generative adversarial network, an adversarial reinforcement learning approach is proposed for report generation of chest x-ray images considering both diagnostic accuracy and language fluency. Specifically, an accuracy discriminator (AD) and fluency discriminator (FD) are built that serve as the evaluators by which a report based on these two aspects is scored. The FD checks how likely a report originates from a human expert, while the AD determines how much a report covers the key chest observations. The weighted score is viewed as a &#x201C;reward&#x201D; used for training the report generator via reinforcement learning, which solves the problem that the gradient cannot be passed back to the generative model when the output is discrete. Simultaneously, these two discriminators are optimized by maximum-likelihood estimation for better assessment ability. Additionally, a multi-type medical concept fused encoder followed by a hierarchical decoder is adopted as the report generator. Experiments on two large radiograph datasets demonstrate that the proposed model outperforms all methods to which it is compared.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Daibing Hou et al.",
      "keywords": "Discriminator; Computer science; Reinforcement learning; Generator (circuit theory); Artificial intelligence; Fluency; Closed captioning; Machine learning; Encoder; Chest radiograph; Adversarial system; Image (mathematics); Pattern recognition (psychology); Radiography; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3056175",
      "cited_by_count": 38,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226154421",
      "doi": "10.1109/access.2022.3157854",
      "title": "How Do Your Biomedical Named Entity Recognition Models Generalize to Novel Entities?",
      "abstract": "The number of biomedical literature on new biomedical concepts is rapidly increasing, which necessitates a reliable biomedical named entity recognition (BioNER) model for identifying new and unseen entity mentions. However, it is questionable whether existing models can effectively handle them. In this work, we systematically analyze the three types of recognition abilities of BioNER models: memorization, synonym generalization, and concept generalization. We find that although current best models achieve state-of-the-art performance on benchmarks based on overall performance, they have limitations in identifying synonyms and new biomedical concepts, indicating they are overestimated in terms of their generalization abilities. We also investigate failure cases of models and identify several difficulties in recognizing unseen mentions in biomedical literature as follows: (1) models tend to exploit dataset biases, which hinders the models' abilities to generalize, and (2) several biomedical names have novel morphological patterns with weak name regularity, and models fail to recognize them. We apply a statistics-based debiasing method to our problem as a simple remedy and show the improvement in generalization to unseen mentions. We hope that our analyses and findings would be able to facilitate further research into the generalization capabilities of NER models in a domain where their reliability is of utmost importance.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Hyunjae Kim et al.",
      "keywords": "Generalization; Computer science; Artificial intelligence; Exploit; Machine learning; Synonym (taxonomy); Domain (mathematical analysis); Natural language processing; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3157854",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2946532037",
      "doi": "10.1109/access.2019.2917719",
      "title": "The Application of Artificial Intelligence Technologies as a Substitute for Reading and to Support and Enhance the Authoring of Scientific Review Articles",
      "abstract": "To gain a comprehensive overview of new scientific findings with the enormous, ever-increasing amount of published information, we apply a new combinatorial approach that complements the process of reading scientific articles by supplementing artificial intelligence technologies. We present a combinatorial approach, which we illustrate in the form of a \u201cdouble funnel of artificial intelligence.\u201d Our approach suggests to largely increase the amount of data at the beginning of the data collection process and to subsequently clean and enrich the data set in order to gain much more knowledge at the end of the procedure compared to a \u201cclassical\u201d literature review. We use natural language processing and text visualization techniques to uncover findings that are generally unbeknown to the human reader due to the inability to process very large amounts of text. By illustrating the individual steps using practical examples taken from use cases, we demonstrate the merits of our approach. With our methodology, we are able to reproduce findings from \u201cregular\u201d review papers; however, we discover additional and new findings in different fields, such as data science or medicine. We also point out the limitations of our approach. Finally, we make suggestions as to how the methodology could be further developed.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "R\u00fcdiger Buchkremer et al.",
      "keywords": "Computer science; Process (computing); Reading (process); Data science; Set (abstract data type); Point (geometry); Visualization; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2917719",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3136188880",
      "doi": "10.1109/rbme.2021.3069213",
      "title": "A Survey on Mathematical, Machine Learning and Deep Learning Models for COVID-19 Transmission and Diagnosis",
      "abstract": "COVID-19 is a life threatening disease which has a enormous global impact. As the cause of the disease is a novel coronavirus whose gene information is unknown, drugs and vaccines are yet to be found. For the present situation, disease spread analysis and prediction with the help of mathematical and data driven model will be of great help to initiate prevention and control action, namely lockdown and qurantine. There are various mathematical and machine-learning models proposed for analyzing the spread and prediction. Each model has its own limitations and advantages for a particluar scenario. This article reviews the state-of-the art mathematical models for COVID-19, including compartment models, statistical models and machine learning models to provide more insight, so that an appropriate model can be well adopted for the disease spread analysis. Furthermore, accurate diagnose of COVID-19 is another essential process to identify the infected person and control further spreading. As the spreading is fast, there is a need for quick auotomated diagnosis mechanism to handle large population. Deep-learning and machine-learning based diagnostic mechanism will be more appropriate for this purpose. In this aspect, a comprehensive review on the deep learning models for the diagnosis of the disease is also provided in this article.",
      "year": "2021",
      "journal": "IEEE Reviews in Biomedical Engineering",
      "authors": "Christopher Clement John et al.",
      "keywords": "Machine learning; Artificial intelligence; Computer science; Mechanism (biology); Deep learning; Coronavirus disease 2019 (COVID-19); Population; Online machine learning; Transmission (telecommunications); Disease; Risk analysis (engineering); Artificial neural network; Infectious disease (medical specialty); Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/rbme.2021.3069213",
      "cited_by_count": 79,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2947317866",
      "doi": "10.1109/access.2019.2919121",
      "title": "A Hybrid Method to Extract Clinical Information From Chinese Electronic Medical Records",
      "abstract": "Narrative reports in medical records contain abundant clinical information that may be converted into structured data for managing patient information and predicting trends in diseases. Though various rule-based and machine-learning methods are available in electronic medical records (EMRs), a few works have explored the hybrid methods in extracting information from the Chinese EMRs. In this paper, we developed a novel hybrid approach which integrates the rules and bidirectional long short-term memory with a conditional random field layer (BiLSTM-CRF) model to extract clinical entities and attributes. A corpus of 1509 electronic notes (discharge summaries and operation notes) was annotated. Annotation from three clinicians was reconciled to form a gold standard dataset. The performance of our method was assessed by calculating the precision, recall, and F-measure for two boundary matching strategies. The experimental results demonstrate the effectiveness of our method in clinical information extraction from the Chinese EMRs.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Ming Cheng et al.",
      "keywords": "Computer science; Conditional random field; Recall; Matching (statistics); Information extraction; Medical record; Annotation; Information retrieval; Precision and recall; Artificial intelligence; Medical information; Natural language processing; Field (mathematics); Mutual information; Gold standard (test); Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2919121",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2980895577",
      "doi": "10.1109/access.2019.2948155",
      "title": "A Deep Learning Approach With Deep Contextualized Word Representations for Chemical\u2013Protein Interaction Extraction From Biomedical Literature",
      "abstract": "Mining interactions between chemicals and proteins/genes is of crucial relevance for clinical medicine, adverse drug effects, and pharmacological research. Although chemical-protein interactions (CPIs) can be manually extracted, this process is expensive and time-consuming. Therefore, it is of considerable significance to automatically extract CPIs from biomedical literature. Currently, the popular methods for CPI extraction are based on deep learning to avoid sophisticated handcrafted features derived from linguistic analyses. However, the performance of existing methods is usually unsatisfactory. The reasons may be that (1) traditional word-embedding methods cannot adequately model context information, and (2) it is difficult to effectively distinguish which words play critical roles in long biomedical sentences. In this study, we propose a novel Deep-contextualized Stacked Bi-LSTM model (DS-LSTM) to tackle the drawbacks of existing methods. Specifically, our model mainly consists of three components: deep contextualized word representations, the entity attention mechanism, and stacked bidirectional long short-term memory networks (Bi-LSTMs). The deep contextualized word representations are introduced to effectively model complex characteristics of word use (e.g., syntax and semantics) and the variations of these words in the context (i.e., to model polysemy), thereby generating context information. The entity attention mechanism is applied to prioritize the weights of words associated with target entities to distinguish which words play critical roles in long biomedical sentences. We evaluate our model on the CHEMPROT corpus. Our approach achieves a micro-averaged F-score of 69.44%, which is significantly higher than existing state-of-the-art methods. Experimental results show that our approach can adequately model context information, effectively distinguish which words play critical roles in long biomedical sentences and, therefore, improve the overall performance.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Cong Sun et al.",
      "keywords": "Computer science; Polysemy; Natural language processing; Artificial intelligence; Relevance (law); Context (archaeology); Deep learning; Word (group theory); Semantics (computer science); Word embedding; Syntax; Process (computing); Information extraction; Embedding; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2948155",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312636974",
      "doi": "10.1109/access.2022.3219455",
      "title": "Exploring Natural Language Processing in Model-To-Model Transformations",
      "abstract": "In this paper, we explore the possibility to apply natural language processing in visual model-to-model (M2M) transformations. Therefore, we present our research results on information extraction from text labels in process models modeled using Business Process Modeling Notation (BPMN) and use case models depicted in Unified Modeling Language (UML) using the most recent developments in natural language processing (NLP). Here, we focus on three relevant tasks, namely, the extraction of verb/noun phrases that would be used to form relations, parsing of conjunctive/disjunctive statements, and the detection of abbreviations and acronyms. Techniques combining state-of-the-art NLP language models with formal regular expressions grammar-based structure detection were implemented to solve relation extraction task. To achieve these goals, we benchmark the most recent state-of-the-art NLP tools (CoreNLP, Stanford Stanza, Flair, Spacy, AllenNLP, BERT, ELECTRA), as well as custom BERT-BiLSTM-CRF and ELMo-BiLSTM-CRF implementations, trained with certain data augmentations to improve performance on the most ambiguous cases; these tools are further used to extract noun and verb phrases from short text labels generally used in UML and BPMN models. Furthermore, we describe our attempts to improve these extractors by solving the abbreviation/acronym detection problem using machine learning-based detection, as well as process conjunctive and disjunctive statements, due to their relevance to performing advanced text normalization. The obtained results show that the best phrase extraction and conjunctive phrase processing performance was obtained using Stanza based implementation, yet, our trained BERT-BiLSTM-CRF outperformed it for the verb phrase detection task. While this work was inspired by our ongoing research on partial model-to-model transformations, we believe it to be applicable in other areas requiring similar text processing capabilities as well.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Paulius Dan\u0117nas et al.",
      "keywords": "Computer science; Natural language processing; Artificial intelligence; Noun phrase; Information extraction; WordNet; Noun",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3219455",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391147975",
      "doi": "10.1109/access.2024.3357662",
      "title": "Detection and Analysis of Stress-Related Posts in Reddit\u2019s Acamedic Communities",
      "abstract": "Nowadays, the significance of monitoring stress levels and recognizing early signs of mental illness cannot be overstated. Automatic stress detection in text can proactively help manage stress and protect mental well-being. In today&#x2019;s digital era, social media platforms reflect various communities&#x2019; psychological well-being and stress levels. This study focuses on detecting and analyzing stress-related posts in Reddit&#x2019;s academic communities. Due to online education and remote work, these communities have become central for academic discussions and support. We classify text as stressed or not using natural language processing and machine learning classifiers, with Dreaddit as our training dataset containing labeled Reddit data. Next, we collect and analyze posts from various academic subreddits. We identified that the most effective individual feature for stress detection is the Bag of Words, paired with the Logistic Regression classifier, achieving a 77.78&#x0025; accuracy rate and an F1 score of 0.79 on the pre-labeled DReaddit dataset. To validate our model&#x2019;s applicability to detect stress in the specific context of academia, we conducted a supplementary experiment by manually annotating 100 posts from academic subreddits, achieving a 72&#x0025; accuracy rate. Our key findings reveal that the overall stress level in academic texts is 29&#x0025;. Posts and comments in professors&#x2019; Reddit communities are the most stressful compared to other academic levels, including bachelor&#x2019;s, graduate&#x2019;s, and Ph.D. students. This research contributes to our understanding of the stress levels within academic communities. It can help academic institutions and online communities effectively develop measures and interventions to address this issue.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Nazzere Oryngozha et al.",
      "keywords": "Computer science; Stress (linguistics); Classifier (UML); Bachelor; Context (archaeology); Social media; Psychological intervention; Psychology; World Wide Web; Applied psychology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3357662",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4320713008",
      "doi": "10.1109/access.2023.3245128",
      "title": "Deep Learning for the Detection of Acute Lymphoblastic Leukemia Subtypes on Microscopic Images: A Systematic Literature Review",
      "abstract": "Computer vision research in detecting and classifying the subtype Acute Lymphoblastic Leukemia (ALL) has contributed to computer-aided diagnosis with improved accuracy. Another contribution is to serve as an assistant and second opinion for doctors and hematologists in diagnosing the ALL subtype. Early detection can also rely on computer-aided diagnosis to determine initial treatment. The purpose of this study is to review the progress of research in the detection and classification of ALL subtypes. The method&#x2019;s discussion focuses on the application of deep learning to the domain of object detection and classification. Motivations, challenges, and future research recommendations are thoroughly discussed to improve understanding and progress in this field of study. The study was carried out methodically by analyzing a collection of papers on the detection and classification of ALL subtypes published in science direct, IEEE, and PubMed from 2018 to 2022. The analysis of this paper field is included in the results of the selected paper. The paper selection from among 65 papers was based on inclusion and exclusion methods. Based on research methods and objectives, papers are divided into two large groups. The first group discusses the classification of ALL subtypes, while the second group discusses the detection of ALL subtypes. The discussion of prior research reveals some challenging issues and future work, such as the limited availability of the ALL subtypes dataset, the high computational complexity of the deep learning model, and further exploration of transformers in computer vision as a reference for research gaps that can contribute to future research.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Tanzilal Mustaqim et al.",
      "keywords": "Lymphoblastic Leukemia; Computer science; Artificial intelligence; Deep learning; Medicine; Pathology; Leukemia; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3245128",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312822299",
      "doi": "10.1109/access.2022.3223681",
      "title": "HSI-LFS-BERT: Novel Hybrid Swarm Intelligence Based Linguistics Feature Selection and Computational Intelligent Model for Alzheimer\u2019s Prediction Using Audio Transcript",
      "abstract": "Alzheimer&amp;#x2019;s dementia (AD) affects memory, language, and cognition and worsens over time. Therefore, it is critical to develop a reliable method for early detection of permanent brain atrophy and cognitive impairment. This study used clinical transcripts, a text-based adaptation of the original audio recordings of Alzheimer&amp;#x2019;s patients. This audio transcript data were taken from DementiaBank, which is the largest public dataset of AD transcripts. This study aims to show how Transfer Learning-based models and swarm intelligence optimization techniques can be used to predict Alzheimer&amp;#x2019;s disease. To enhance the prediction performance for Alzheimer&amp;#x2019;s disease, a hybrid swarm intelligence linguistic feature selection (HSI-LFS) approach is proposed that extracts a combined feature set using Particle Swarm Optimization (PSO), Dragonfly Optimization (DO), and Grey Wolf Optimization (GWO) algorithms. In addition, a transfer learning-based model called HSI-LFS-BERT, a combination of the HSI-LFS feature selection method and Bidirectional Encoder Representations from Transformer (BERT) algorithm, is proposed. The proposed model was compared using two feature sets: the first set consisted of the initial feature set and the second set contained a hybrid feature set that was extracted using the suggested HSI-LFS method. BERT embedding with HSI-LFS outperformed the conventional feature set, providing the most accurate modeling parameters while reducing the computations by 27.19&amp;#x0025;. The proposed HSI-LFS-BERT model outperformed state-of-the-art models, achieving 98.24&amp;#x0025; accuracy, 91.56&amp;#x0025; precision, and 98.78&amp;#x0025; recall.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Yusera Farooq Khan et al.",
      "keywords": "Computer science; Feature selection; Artificial intelligence; Particle swarm optimization; Feature (linguistics); Pattern recognition (psychology); Swarm intelligence; Speech recognition; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3223681",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3114786469",
      "doi": "10.1109/access.2020.3047452",
      "title": "Design and Implementation of the Traditional Chinese Medicine Constitution System Based on the Diagnosis of Tongue and Consultation",
      "abstract": "The standardization and digitalization of nine constitutions of traditional Chinese medicine (TCM) have promoted the development of TCM automation. The keys to constitution identification are tongue diagnosis and consultation diagnosis. In this paper, a tongue detection method based on the combination of the histogram of oriented gradients (HOG) and the support vector machine (SVM) is proposed. To separate the tongue body and tongue coating, a k-means segmentation method based on the Lab color space is proposed. Based on the clustering analysis of the difference between the color components of the tongue body and tongue coating in the Lab color space, the separation is realized. Thus, the relationship between the tongue image and constitution can be analyzed. The method for consultation diagnosis is divided into a questionnaire scale and a question answering system. The questionnaire includes 29 quantified items with corresponding weights and answer scores, so the final score of each type of constitution is calculated. The final constitution type is determined on the basis of the scores of both diagnoses. In addition, the key of question answering system is text similarity calculation. First, a sentence similarity calculation method combining the n-gram language model and word2vec is proposed. Then, a multifeature fusion sentence similarity calculation method combining the Word Mover's Distance (WMD) and editing distance is proposed. Finally, the experimental results show the effectiveness of the proposed method, and a constitution identification application is developed based on the content of this paper.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ye Yuan et al.",
      "keywords": "Computer science; Tongue; Artificial intelligence; Medical diagnosis; Similarity (geometry); Support vector machine; Feature extraction; Natural language processing; Pattern recognition (psychology); Constitution; Image (mathematics); Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3047452",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4297094598",
      "doi": "10.1109/access.2022.3210119",
      "title": "Chinese Named Entity Recognition of Epidemiological Investigation of Information on COVID-19 Based on BERT",
      "abstract": "The named entity recognition based on the epidemiological investigation of information on COVID-19 can help analyze the source and route of transmission of the epidemic to control the spread of the epidemic better. Therefore, this paper proposes a Chinese named entity recognition model BERT-BiLSTM-IDCNN-ELU-CRF (BBIEC) based on the epidemiological investigation of information on COVID-19 of the BERT pre-training model. The model first processes the unlabeled epidemiological investigation of information on COVID-19 into the character-level corpus and annotates it with artificial entities according to the BIOES character-level labeling system and then uses the BERT pre-training model to obtain the word vector with position information; then, through the bidirectional long-short term memory neural network (BiLSTM) and the improved iterated dilated convolutional neural network (IDCNN) extract global context and local features from the generated word vectors and concatenate them serially; output all possible label sequences to the conditional random field (CRF); finally pass the condition random The airport decodes and generates the entity tag sequence. The experimental results show that the model is better than other traditional models in recognizing the entity of the epidemiological investigation of information on COVID-19.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Chongluo Yang et al.",
      "keywords": "Computer science; Conditional random field; Artificial intelligence; Convolutional neural network; Named-entity recognition; Context (archaeology); Hidden Markov model; Natural language processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3210119",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4395017642",
      "doi": "10.1109/tnsre.2024.3391908",
      "title": "BlazePose-Seq2Seq: Leveraging Regular RGB Cameras for Robust Gait Assessment",
      "abstract": "Evaluation of human gait through smartphone-based pose estimation algorithms provides an attractive alternative to costly lab-bound instrumented assessment and offers a paradigm shift with real time gait capture for clinical assessment. Systems based on smart phones, such as OpenPose and BlazePose have demonstrated potential for virtual motion assessment but still lack the accuracy and repeatability standards required for clinical viability. Seq2seq architecture offers an alternative solution to conventional deep learning techniques for predicting joint kinematics during gait. This study introduces a novel enhancement to the low-powered BlazePose algorithm by incorporating a Seq2seq autoencoder deep learning model. To ensure data accuracy and reliability, synchronized motion capture involving an RGB camera and ten Vicon cameras were employed across three distinct self-selected walking speeds. This investigation presents a groundbreaking avenue for remote gait assessment, harnessing the potential of Seq2seq architectures inspired by natural language processing (NLP) to enhance pose estimation accuracy. When comparing BlazePose alone to the combination of BlazePose and 1D convolution Long Short-term Memory Network (1D-LSTM), Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM), the average mean absolute errors decreased from 13.4\u00b0 to 5.3\u00b0 for fast gait, from 16.3\u00b0 to 7.5\u00b0 for normal gait, and from 15.5\u00b0 to 7.5\u00b0 for slow gait at the left ankle joint angle respectively. The strategic utilization of synchronized data and rigorous testing methodologies further bolsters the robustness and credibility of these findings.",
      "year": "2024",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Abdul Aziz Hulleck et al.",
      "keywords": "RGB color model; Computer science; Gait; Computer vision; Artificial intelligence; Physical medicine and rehabilitation; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2024.3391908",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388642332",
      "doi": "10.1109/access.2023.3332289",
      "title": "Extracting Mental Health Indicators From English and Spanish Social Media: A Machine Learning Approach",
      "abstract": "This study examines the communications of English- and Spanish-speaking Twitter users through traditional and deep learning algorithms to automatically recognize whether they live with one of nine mental health conditions. We created two datasets in English and Spanish. The &#x201C;diagnosed&#x201D; set comprises the timeline of 1,500 users who explicitly reported in one or more of their posts having been diagnosed with one of the following: ADHD, Anxiety, Autism, Bipolar, Depression, Eating disorders, OCD, PTSD, and Schizophrenia. The &#x201C;control&#x201D; set comprises the timeline of 1,700 randomly selected users who had not disclosed a diagnosis. We extracted a variety of text features from the collected data, such as n-grams, q-grams, Part-of-speech (POS) tags, topic modeling, Linguistic Inquiry and Word Count (LIWC), and word embeddings, and trained traditional machine-learning and deep learning classifiers for two tasks: binary classification, to distinguish between diagnosed and non-diagnosed users, and multiclass classification, to identify the specific diagnosis. Overall, XGBoost and convolutional neural network (CNN) performed the best in the two classification tasks. Moreover, lexical attributes based on n-grams and q-grams are the ones that performed well in both datasets. Using our collected datasets, for binary classification, we achieved an AUC of 0.835 on the Spanish Twitter dataset using n-grams of words from one to three (UBT) and 0.846 on the English Twitter dataset with a 5-gram characters (C5) model. In multiclass classification, we obtained an AUC of 0.712 and 0.697 in the Spanish and English Twitter datasets, respectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Miryam Elizabeth Villa-P\u00e9rez et al.",
      "keywords": "Computer science; Social media; Mental health; Artificial intelligence; Natural language processing; Machine learning; Psychology; World Wide Web; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3332289",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389076508",
      "doi": "10.1109/access.2023.3337669",
      "title": "Digital Transformation in Nursing Education: A Systematic Review on Computer-Aided Nursing Education Pedagogies, Recent Advancements and Outlook on the Post-COVID-19 Era",
      "abstract": "The COVID-19 pandemic has transformed nursing education worldwide. Due to the globally applied restrictions of interpersonal interactions, many educational institutions transitioned from traditional to computer-aided nursing education pedagogies. However, an obligatory change, this digital transformation in nursing education, has been deemed promising by students and academics, yet raising concerns about the effectiveness of innovative nursing pedagogies. Hence, this systematic literature review aims to investigate the state of the art of computer-aided nursing pedagogies in the post-COVID-19 era and provide recommendations for further research investigation. Specifically, it utilises a mixed methods approach to examine (1) the evolution of computer-aided nursing pedagogies before and after COVID-19; (2) their effectiveness against traditional methods in terms of knowledge, skills acquisition and self-efficiency; and (3) nursing students&#x2019; experiences and opinions when exposed to computer-aided nursing education pedagogies. For this purpose, several databases (PubMed, MEDLINE, CINAHL Complete, Academic Search Elite, IEEE, ACM, Scopus, ERIC and Cochrane Library (Controlled trial requests) were searched, initially retrieving 802 articles published between 2013-2023. After removing duplicates, exclusion criteria and assessment for eligibility, the number of articles assessed for eligibility was reduced to 78 conducted in 20 different countries. The articles comprised quantitative research (n=37), including Randomised Control Trials (n=14) and Quasi-experimental studies (n=23), and qualitative research (n=41) including observational studies (n=14), mixed-methods methodological design (n=15), pilot studies (n=7) and conference papers (n=5). Moreover, this SLR utilised the Joanna Briggs Institute (JBI) methodological approach for conducting a mixed-methods systematic review (MMSR) and provided a narrative synthesis of all studies. The results of this mixed-methods SLR suggested that the post-COVID-19 era has enabled the implementation of a variety of computerised systems in nursing education, including desktop-based systems, mobile applications, Virtual Reality, Augmented Reality, Mixed Reality and holograms, haptics, Artificial Intelligence-enabled chatbots and systems, smart glasses and multimodal systems. The authors found that these computer-aided nursing education pedagogies were superior to traditional nursing pedagogies regarding acquiring knowledge, skills, and self-efficiency. However, the generalisability of the above findings should be interpreted with caution due to variations in sample size and effect size established via Hedges&#x2019; g calculations among the 35 quantitative articles. Nevertheless, nursing students&#x2019; experiences and opinions were encouragingly positive. Further research is needed to incorporate more realistic and memorable scenarios and examine the effects of computer-aided nursing educational pedagogies on long-term knowledge gains and the effective learning domain.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nevena Dicheva et al.",
      "keywords": "CINAHL; Nurse education; MEDLINE; Nursing; Medicine; Cochrane Library; Medical education; Randomized controlled trial; Political science; Psychological intervention",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3337669",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3043581285",
      "doi": "10.1109/access.2020.3009292",
      "title": "A Novel Emotion Lexicon for Chinese Emotional Expression Analysis on Weibo: Using Grounded Theory and Semi-Automatic Methods",
      "abstract": "As one of the most popular social media platforms in China, Weibo has aggregated huge numbers of texts containing people&#x2019;s thoughts, feelings, and experiences. Analyzing emotions expressed on Weibo has attracted a great deal of academic attention. Emotion lexicon is a vital foundation of sentiment analysis, but the existing lexicons still have defects such as a limited variety of emotions, poor cross-scenario adaptability, and confusing written and online expressions and words. By combining grounded theory and semi-automatic methods, we built a Weibo-based emotion lexicon for sentiment analysis. We first took a bottom-up approach to derive a theoretical model for emotions expressed on Weibo, and the substantive coding led to eight core emotion categories: joy, expectation, love, anger, anxiety, disgust, sadness, and surprise. Second, we built a new emotion lexicon containing 2,964 words by manually selecting seed words, constructing a word vector model to expand words, and making rules to filter words. Finally, we tested the effectiveness of our lexicon by using a lexicon-based approach to recognize the emotions expressed in Weibo text. The results showed that our lexicon performed better in Weibo emotion recognition than five other Chinese emotion lexicons. This study proposed a method to construct an emotion lexicon that considered both theory and application by combining qualitative research and artificial intelligence methods. Our work also provided a reference for future research in the field of social media sentiment analysis.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Liang Xu et al.",
      "keywords": "Lexicon; Sentiment analysis; Computer science; Emotion classification; Sadness; Artificial intelligence; Natural language processing; Disgust; Social media; Microblogging; Anger; Construct (python library); Feeling; Surprise; Trigram; Psychology; Social psychology; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3009292",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391164144",
      "doi": "10.1109/tpami.2024.3358168",
      "title": "Human Versus Machine Intelligence: Assessing Natural Language Generation Models Through Complex Systems Theory",
      "abstract": "The introduction of Transformer architectures - with the self-attention mechanism - in automatic Natural Language Generation (NLG) is a breakthrough in solving general task-oriented problems, such as the simple production of long text excerpts that resemble ones written by humans. While the performance of GPT-X architectures is there for all to see, many efforts are underway to penetrate the secrets of these black-boxes in terms of intelligent information processing whose output statistical distributions resemble that of natural language. In this work, through the complexity science framework, a comparative study of the stochastic processes underlying the texts produced by the English version of GPT-2 with respect to texts produced by human beings, notably novels in English and programming codes, is offered. The investigation, of a methodological nature, consists first of all of an analysis phase in which the Multifractal Detrended Fluctuation Analysis and the Recurrence Quantification Analysis - together with Zipf's law and approximate entropy - are adopted to characterize long-term correlations, regularities and recurrences in human and machine-produced texts. Results show several peculiarities and trends in terms of long-range correlations and recurrences in the last case. The synthesis phase, on the other hand, uses the complexity measures to build synthetic text descriptors - hence a suitable text embedding - which serve to constitute the features for feeding a machine learning system designed to operate feature selection through an evolutionary technique. Using multivariate analysis, it is then shown the grouping tendency of the three analyzed text types, allowing to place GTP-2 texts in between natural language texts and computer codes. Similarly, the classification task demonstrates that, given the high accuracy obtained in the automatic discrimination of text classes, the proposed set of complexity measures is highly informative. These interesting results allow us to add another piece to the theoretical understanding of the surprising results obtained by NLG systems based on deep learning and let us to improve the design of new informetrics or text mining systems for text classification, fake news detection, or even plagiarism detection.",
      "year": "2024",
      "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Enrico De Santis et al.",
      "keywords": "Zipf's law; Computer science; Artificial intelligence; Natural language processing; Natural language; Entropy (arrow of time); Stylometry; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tpami.2024.3358168",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3028061987",
      "doi": "10.1109/access.2020.2994252",
      "title": "TBLC-rAttention: A Deep Neural Network Model for Recognizing the Emotional Tendency of Chinese Medical Comment",
      "abstract": "In the current paper, a hybrid depth neural network model, TBLC-rAttention, aiming at Chinese text emotion recognition, is proposed to identify the emotional tendency of the Chinese medical reviews. The model includes the following steps: acquiring and preprocessing the Chinese corpus; mapping the preprocessed text into the word vectors; using Bi-directional Long Short-Term Memory network (Bi-LSTM) with the attention mechanism to acquire the context semantic features of the text; using Convolutional Neural Network (CNN) to obtain local semantics features on the basis of the context semantic features; and inputting the final feature vectors into the classification layer to complete the task of emotion recognition and the classification of the Chinese medical reviews. In this experiment, the corpus data is the comments of 999 cold medicine on a large e-commerce platform. All corpus are divided into three types, including high praise, medium praise and bad review. Classical machine learning models (SVM, NB) and neural network models (CNN, LSTM, Bi-LSTM, BiLSTM-Attention and RCNN) are performed as the comparison benchmarks to assess the category performance of TBLC-rAttention model. All the results were obtained when the training accuracy and test accuracy were stable after 1000 cycles of repeated calculation. The results show that TBLC-rAttention can get better text feature than the reference models, and the text classification accuracy reaches to 99%. In conclusion, the TBLC-rAttention model can identify semantic feature information to the greatest extent. In addition, this study also completes the numerical quantification of the predicted results.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Qibing Jin et al.",
      "keywords": "Computer science; Artificial neural network; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2994252",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3040562930",
      "doi": "10.1109/access.2020.3005684",
      "title": "Information Extraction for Intestinal Cancer Electronic Medical Records",
      "abstract": "The data generated by the structured electronic medical records is helpful for mining and extracting medical data, and it is an effective way to make effective use of valuable data resources. However, the hospitals have accumulated a large number of unstructured data in electronic medical records, which cannot be effectively searched, resulting in serious waste of resources. In this paper, we study the problem of extracting attribute values from the unstructured text in electronic medical records. By observing intestinal cancer diagnostic texts, our attributes have two categories - discriminative attributes and extractive attributes, which use the text classification and the sequence labeling to tackle attribute values extraction problems. For discriminative attributes, we firstly divide the text into sentences/segments as instances. Secondly, we fine-tune the pre-trained word embedding to capture domain-specific semantics/knowledge. Thirdly, we also use an attention mechanism to select the most important instance for different attribute extractors. Finally, multi-tasking learning is used to share useful information to get better experimental results. For extractive attributes, we propose a novel model to get attribute values, including the BiLSTM layer, the CNN layer and the CRF layer. In particular, we use BiLSTM and CNN to learn text features and CRF as the last layer of the model. Experiments have shown that our method is superior to several competitive baseline methods.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Sufen Wang et al.",
      "keywords": "Computer science; Discriminative model; Word embedding; Information extraction; Semantics (computer science); Sequence labeling; Information retrieval; Word (group theory); Artificial intelligence; Layer (electronics); Data mining; Embedding",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3005684",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3197131793",
      "doi": "10.1109/access.2021.3109069",
      "title": "A Novel Approach of Transcriptomic microRNA Analysis Using Text Mining Methods: An Early Detection of Multiple Sclerosis Disease",
      "abstract": "Multiple sclerosis is an autoimmune disease that causes psychological impacts and severe physical disabilities, including motor disabilities and partial blindness. This work introduces an early detection method for multiple sclerosis disease by analyzing transcriptomic microRNA data. By transforming this phenotype classification problem into a text mining problem, multiple sclerosis disease biomarkers can be obtained. To our knowledge, text mining methods have not been introduced previously in transcriptomic data analysis of multiple sclerosis disease. Hence, this work presents a complete predictive model by combining consecutive transcriptomic data preprocessing procedures, followed by the proposed <italic>KmerFIDF</italic> method as a feature extraction method and linear discriminant analysis for dimensionality reduction. Predictive machine learning methods can then be obtained accordingly. This study describes experimental work on a transcriptomic dataset of noncoding microRNA sequences denoted from relapsing-remitting multiple sclerosis patients before fingolimod treatment and after six consecutive months of treatment. The experimental results of the predictive methods with the proposed model report sensitivity, specificity, F1-score, and average accuracy scores of 96.4, 96.47, 95.6, and 97&#x0025; with random forest, 92.89, 92.78, 93.2, and 94&#x0025; with support vector machine and 91.95, 92.2, 93.1, and 94&#x0025; with logistic regression, respectively. These promising results support the introduced model and the proposed KmerFIDF method in transcriptomic data analysis. Moreover, comparative experiments are conducted with two referenced studies. The obtained results show that the average reported accuracy scores of the proposed model outperform the referenced literature work.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Nehal M. Ali et al.",
      "keywords": "Random forest; Support vector machine; Computer science; Artificial intelligence; Feature extraction; Logistic regression; Multiple sclerosis; Linear discriminant analysis; Transcriptome; Medical diagnosis; Machine learning; Preprocessor; Pattern recognition (psychology); Medicine; Pathology; Biology; Immunology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3109069",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285121030",
      "doi": "10.1109/access.2022.3179808",
      "title": "Identifying COVID-19 Personal Health Mentions From Tweets Using Masked Attention Model",
      "abstract": "Twitter has been an important platform for people to discuss and share health-related information. It provides a massive amount of data for real-time monitoring of infectious diseases (such as COVID-19) and freeing disease-prevention organizations from the tedious labor involved in public health surveillance. Personal health mention (PHM) detection is one of the critical methods to keep up-to-date on an epidemic&#x2019;s condition; it attempts to identify a person&#x2019;s health condition based on online text information. This paper explores PHM identification for COVID-19 through Twitter. We built a COVID-19 PHM data set containing tweets annotated with four types of COVID-19-related health conditions. A masked attention model was devised to classify the tweets as self-mention, other-mention, awareness, and non-health. We obtained promising results on the PHM identification task. The classification results facilitate timely health monitoring and surveillance for digital epidemiology. We also evaluate how the attention mechanism and training method affect the model&#x2019;s predictive performance.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Linkai Luo et al.",
      "keywords": "Computer science; Identification (biology); Coronavirus disease 2019 (COVID-19); Public health; Internet privacy; Data science; Medicine; Disease; Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3179808",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4289821942",
      "doi": "10.1109/access.2022.3195212",
      "title": "An NLP-Inspired Data Augmentation Method for Adverse Event Prediction Using an Imbalanced Healthcare Dataset",
      "abstract": "This paper proposes a data augmentation method for imbalanced healthcare datasets. This method was inspired by a data augmentation method in natural language processing (NLP) that generates synthetic sentences for training by replacing some words with similar words. The proposed method generates synthetic patient records by replacing patient backgrounds with similar backgrounds. In this paper, the cosine similarity of the distributed representations was used as the similarity metric between patient backgrounds. The distributed representations of the patient backgrounds were generated by the skip-gram model. To confirm the performance improvement with the proposed data augmentation method, the prediction performance of adverse events (AEs) caused by drug administration was experimentally evaluated on a real-world medical dataset with 1,510,137 records. The combination of the proposed data augmentation method and a conventional undersampling method resulted in an 80.0&#x0025; improvement in accuracy and a 40.0&#x0025; improvement in the precision and F1-score. The multifaceted evaluation demonstrated that the proposed method is effective, especially for predicting AEs with positive ratios ranging from 1.0&#x0025; to 2.1&#x0025;, which are difficult to predict with conventional machine learning methods but should be predictable in the medical field.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Tomoki Ishikawa et al.",
      "keywords": "Undersampling; Computer science; Metric (unit); Cosine similarity; Artificial intelligence; Similarity (geometry); F1 score; Machine learning; Performance improvement; Data mining; Natural language processing; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3195212",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225727651",
      "doi": "10.1109/access.2022.3164419",
      "title": "Speech Recording for Dietary Assessment: A Systematic Literature Review",
      "abstract": "Traditional methods of capturing people&#x2019;s dietary intake are complex and labour-intensive, requiring a high level of literacy and time. Speech recording has potential to reduce these barriers, and recent technological advances have greatly increased the viability of this approach. The aim of this paper is to establish the current state of research on the usage of speech records in dietary assessment. To this end, we performed a systematic literature review and summarised the current state of research along a conceptual framework that captures the components involved in using speech records for dietary assessment. Six databases from the nutrition and computing domains were interrogated, resulting in 21 relevant papers. Speech recording in an unstructured format was preferred when compared against other methods by all three studies reporting comparisons. High technological satisfaction and ease of use were noted by all eight studies reporting user acceptance. When recording data, 78&#x0025; of studies focused on collecting prospective food records. The choice of device reflected this, with 15 of 18 studies reporting a form of handheld, portable collection device intended to be always available. To process data, nine studies performed automated speech transcription achieving an average accuracy of 83&#x0025;, seven of which utilized a readily available commercial service. Of the five studies that used natural language processing to further automate analysis, an average accuracy of 82&#x0025; was reported. Further research is required to adapt these prototypes to address practical challenges in dietary assessment and monitoring (e.g. self-monitoring for low-literacy users).",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Connor T. Dodd et al.",
      "keywords": "Computer science; Systematic review; Literacy; Process (computing); Data collection; Mobile device; Usability; Data science; MEDLINE; Human\u2013computer interaction; World Wide Web; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3164419",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4212986460",
      "doi": "10.1109/access.2022.3151830",
      "title": "Design Guidelines for Mammogram-Based Computer-Aided Systems Using Deep Learning Techniques",
      "abstract": "Breast cancer is the second fatal disease among cancers patients both in Canada and across the globe. However, when detected early, a patients&#x2019; survival rate can be raised. Thus, researchers and scientists have been practicing to develop Computer-Aided Detection (CADe) and Computer-Aided Diagnosis (CADx) systems. Traditional CAD systems depend on manual feature extraction, which has provided radiologists with poor detection and diagnosis tools. Nevertheless, recently, the powerful application of Convolutional Neural Networks (CNN)s as one of the deep learning-based methods has revolutionized these systems&#x2019; accuracy and development. This article proposes categorizing the current deep learning research on mammogram types based on researchers&#x2019; techniques for their empirical studies. Also, we provide an overview of different publicly available data resources and available datasets for breast imaging. This critical review of the state-of-the-art techniques is presented, which we believe can serve as a valuable source for research scientists investigating deep learning-based breast mammogram classification.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Farnoosh Azour et al.",
      "keywords": "Computer science; Deep learning; Artificial intelligence; Convolutional neural network; Feature extraction; Machine learning; Computer-aided diagnosis; Mammography; CAD; Feature (linguistics); Artificial neural network; Breast cancer; Cancer; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3151830",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3149303815",
      "doi": "10.1109/access.2021.3070375",
      "title": "An LSTM&amp;Topic-CNN Model for Classification of Online Chinese Medical Questions",
      "abstract": "In recent years, people&#x2019;s interest in health question and answer (Q&#x0026;A) websites has been growing with the development of the internet technologies. How to seek appropriate professional medical information among the massive data has become the focus of all patients. Therefore, it is vital to obtain reasonable predictions and automatic recommendations on the basis of patients&#x2019; keyword descriptions of their health status and question intention. The key to solving this problem is to achieve automatic text classification of health questions. This paper considered a feature fusion model for the classification of Chinese short texts on medical health Q&#x0026;A websites by combining the text features and topic features. Firstly, we generated the text word vector by word embedding method and obtained the text features under Long Short-Term Memory (LSTM) model. Given the difficulty in determination of topic numbers, we conducted a sub-sample experiment to obtain the few optimal topic numbers under which the classification performances were good. Then we extracted the topic features and used the one-dimensional convolution idea of the Convolutional Neural Network (CNN) model for topic feature filtering. Finally, we combined the two features together subtly for text classification. Two experiments were conducted to illustrate our model in terms of recall rate, precision, and F1 value when the datasets were from different online medical Q&#x0026;A websites. Results showed that the LSTM&#x0026;Topic-CNN model could efficiently enhance the classification effect of Chinese medical health question texts.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Song Mao et al.",
      "keywords": "Computer science; Word embedding; Convolutional neural network; Artificial intelligence; Feature (linguistics); Word (group theory); Key (lock); Deep learning; Recall; The Internet; Topic model; Focus (optics); Natural language processing; Information retrieval; Embedding; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3070375",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3196318080",
      "doi": "10.1109/access.2021.3108445",
      "title": "Re-Ranking System with BERT for Biomedical Concept Normalization",
      "abstract": "In recent years, various neural network architectures have been successfully applied to natural language processing (NLP) tasks such as named entity normalization. Named entity normalization is a fundamental task for extracting information in free text, which aims to map entity mentions in a text to gold standard entities in a given domain-specific ontology; however, the normalization task in the biomedical domain is still challenging because of multiple synonyms, various acronyms, and numerous lexical variations. In this study, we regard the task of biomedical entity normalization as a ranking problem and propose an approach to rank normalized concepts. We additionally employ two factors that can notably affect the performance of normalization, such as task-specific pre-training (Task-PT) and calibration approach. Among five different biomedical benchmark corpora, our experimental results show that our proposed model achieved significant improvements over the previous methods and advanced the state-of-the-art performance for biomedical entity normalization, with up to 0.5&#x0025; increase in accuracy and 1.2&#x0025; increase in F-score.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Hyejin Cho et al.",
      "keywords": "Normalization (sociology); Computer science; Artificial intelligence; Natural language processing; Learning to rank; Named-entity recognition; Task (project management); Ranking (information retrieval); Information retrieval; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3108445",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285820252",
      "doi": "10.1109/access.2022.3192417",
      "title": "Sentiment-Based Spatiotemporal Prediction Framework for Pandemic Outbreaks Awareness Using Social Networks Data Classification",
      "abstract": "According to the World Health Organization, several factors have affected the accurate reporting of SARS-CoV-2 outbreak status, such as limited data collection resources, cultural and educational diversity, and inconsistent outbreak reporting from different sectors. Driven by this challenging situation, this study investigates the potential expediency of using social network data to develop reliable early information surveillance and warning system for pandemic outbreaks. As such, an enhanced framework of three inherently interlinked subsystems is proposed. The first subsystem includes data collection and integration mechanisms, data preprocessing, and hybrid sentiment analysis tools to identify tweet sentiment taxonomies and quantitatively estimate public awareness. The second subsystem comprises the feature extraction unit that identifies, selects, embeds, and balances feature vectors and the classifier fitting and training unit. This subsystem is designed to capture the most effective linguistic feature combinations with more spatial evidence by using a variety of approaches, including linear classifiers, MLPs, RNNs, and CNNs, as well as pre-trained word embedding algorithms. The last is the modeling and situational awareness evaluation subsystem, which measures temporal associations between pandemic-relevant social network activities and officially announced infection counts in the most hazardous geolocations. The proposed framework was developed and tested using a combination of static datasets and real-time scraped Twitter data. The results of these experiments showed the remarkable performance of the framework in assessing the temporal associations between public awareness and outbreak status. It also showed that the Decision Tree Classifier with Unigram&#x002B;TF-IDF feature vectors outperformed other conventional models for sentiment classification and geolocation classification with an accuracy of 94.3&#x0025; and 80.8, respectively. As indicated, conventional machine learning algorithms didn&#x2019;t achieve a precision of more than 80&#x0025;, while, for instance, MLP with self-embedding layer, Word2Vec, and GloVe pre-trained word embedding resulted in very poor accuracy of 10&#x0025;, 36&#x0025;, and 32&#x0025;, respectively. However, adding the PoS tag one-hot encoding embedding increased the validation accuracy from 36&#x0025; to approximately 89&#x0025;, while the best performance for the second subsystem was achieved by Bi-LSTM with RoBERTa word embedding, with an accuracy of 96&#x0025;. The achieved results reveal that the proposed framework can proactively capture the potential hazards associated with the prevalence of infectious diseases as an effective early detection and info-surveillance awareness system.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Noha Gamal et al.",
      "keywords": "Computer science; Sentiment analysis; Word embedding; Classifier (UML); Situation awareness; Artificial intelligence; Data mining; Data pre-processing; Preprocessor; Social media; Machine learning; Decision tree; Social network (sociolinguistics); Data science; Embedding; Engineering; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3192417",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390822127",
      "doi": "10.1109/tai.2024.3353164",
      "title": "Self-Supervised Forecasting in Electronic Health Records With Attention-Free Models",
      "abstract": "| openaire: EC/H2020/101016775/EU//INTERVENE",
      "year": "2024",
      "journal": "IEEE Transactions on Artificial Intelligence",
      "authors": "Yogesh Kumar et al.",
      "keywords": "Scalability; Computer science; Machine learning; Artificial intelligence; Health records; Transfer of learning; Transformer; Deep learning; Health care; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tai.2024.3353164",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312796343",
      "doi": "10.1109/access.2022.3232721",
      "title": "A Novel Lightweight Swin-Unet Network for Semantic Segmentation of COVID-19 Lesion in CT Images",
      "abstract": "The Corona Virus Disease 2019 (COVID-19) is highly infectious, has been spread worldwide, caused a global pandemic, and seriously endangered human health and life. The most effective methods for halting and stopping the transmission of the Corona Virus include early detection, quarantine, and successful treatment. Because it exhibits significant imaging characteristics for COVID-19 lesions in chest computed tomography (CT), it can be used to diagnose COVID-19. Aiming at the inaccuracies of uneven gray distribution, irregular regions, multi-scale, and multi-region segmentation in COVID-19 CT images. This paper proposed a novel Swin-Unet network to improve the accuracy of multi-scale lesion segmentation in COVID-19 CT images. First, in the double-layer Swin Transformer blocks of the Swin-Unet, a residual multi-layer perceptron (ResMLP) module was introduced and replaced the multi-layer perceptron (MLP) module to reduce the loss of features during the transmission process, thereby improving the segmentation precision of multi-scale lesion areas. Second, the uncertain region inpainting module (URIM) was added after Linear Projection, which can refine the uncertain regions in the segmentation features map, thereby improving the segmentation accuracy of different lesion regions. Third, a new loss function DF was designed. It can effectively improve the small target segmentation effect and thus improve the multi-scale segmentation result. Finally, the proposed method was compared to other methods on the public dataset. The Dice, Precision, Recall, and IOU of the proposed method are 0.812, 0.780, 0.848, and 0.683, respectively, which are better than the other models. Moreover, our model has fewer parameters and faster reasoning speed. The proposed method achieves excellent segmentation results for multi-scale and multi-region lesions, and it will be more beneficial in aiding COVID-19 diagnosis and treatment.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Zhijun Gao et al.",
      "keywords": "Computer science; Coronavirus disease 2019 (COVID-19); Segmentation; Artificial intelligence; Image segmentation; Lesion; Computer vision; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3232721",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388642349",
      "doi": "10.1109/access.2023.3332479",
      "title": "RNN-CNN Based Cancer Prediction Model for Gene Expression",
      "abstract": "One of those illnesses that is most deadly to people is cancer. The only way to prevent any harm to humanity is by its early discovery and treatment. Various types of tests are conducted in the medical labs for the detection of cancer. Cancer can also be detected at the genetic level. For this distinct machine learning and deep learning methods already exist. This paper proposes a hybrid method based on Recurrent Neural Network (RNN) and Convolution Neural Network (CNN) to predict different types of cancer such as Breast, Lung, Uterine, Kidney, Prostate and colon cancer from gene expression data. The bottleneck features are extracted using the sandwich stacked method based on VGG16 and VGG19 pre-trained models. Afterward, the proposed hybrid classifier based on RNN-CNN has been used to classify the data into various classes. The proposed model performs better than the other existing methods such as VGG16, VGG19, ResNet50, Inception V3 and MobileNet classifier in terms of various performance metrics such as accuracy, Mean Square Error (MSE), precision, recall, and F1 score. RNN-CNN classifier provides the highest accuracy of 0.978 among all the other existing methods for Dataset 1 and the highest accuracy of 0.994 for Dataset 2 at 80&#x0025; training data. On the other hand, RNN-CNN classifier provides the lowest MSE of 0.101 among all the other existing methods for Dataset 1 and the lowest MSE of 0.006 for Dataset 2 at 80&#x0025; training data.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Tanima Thakur et al.",
      "keywords": "Computer science; Artificial intelligence; Expression (computer science)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3332479",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391992303",
      "doi": "10.1109/access.2024.3368170",
      "title": "BGRD-TransUNet: A Novel TransUNet-Based Model for Ultrasound Breast Lesion Segmentation",
      "abstract": "Breast UltraSound (BUS) imaging is a commonly used diagnostic tool in the field of counter fighting breast diseases, especially for early detection and diagnosis of breast cancer. Due to the inherent characteristics of ultrasound images such as blurry boundaries and diverse tumor morphologies, it is challenging for doctors to manually segment breast tumors. In recent years, the Convolutional Neural Network (CNN) technology has been widely applied to automatically segment BUS images. However, due to the inherent limitations of CNNs in capturing global contextual information, it is difficult to capture the full context. To address this issue, the paper proposes a novel BGRD-TransUNet model for breast lesion segmentation, based on TransUNet. The proposed model, first, replaces the original ResNet50 backbone network of TransUNet with DenseNet121 for initial feature extraction. Next, newly designed Residual Multi-Scale Feature Modules (RMSFMs) are employed to extract features from various layers of DenseNet121, thus capturing richer features within specific layers. Thirdly, a Boundary Guidance (BG) network is added to enhance the contour information of BUS images. Additionally, newly designed Boundary Attentional Feature Fusion Modules (BAFFMs) are used to integrate edge information and features extracted through RMSFMs. Finally, newly designed Parallel Channel and Spatial Attention Modules (PCSAMs) are used to refine feature extraction using channel and spatial attention. An extensive experimental testing performed on two public datasets demonstrates that the proposed BGRD-TransUNet model outperforms all state-of-the-art medical image segmentation models, participating in the experiments, according to all evaluation metrics used (except for few separate cases), including the two most important and widely used metrics in the field of medical image segmentation, namely the Intersection over Union (IoU) and Dice Similarity Coefficient (DSC). More specifically, on the BUSI dataset and dataset B, BGRD-TransUNet achieves IoU values of 76.77% and 86.61%, and DSC values of 85.08% and 92.47%, respectively, which are higher by 7.27 and 3.64, and 5.81 and 2.54 percentage points, than the corresponding values achieved by the baseline (TransUNet).",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Zhanlin Ji et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Convolutional neural network; Context (archaeology); Feature extraction; Breast ultrasound; Pattern recognition (psychology); Feature (linguistics); Deep learning; Image segmentation; Artificial neural network; Computer vision; Breast cancer; Mammography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3368170",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384521537",
      "doi": "10.1109/taffc.2023.3295806",
      "title": "Fake News, Real Emotions: Emotion Analysis of COVID-19 Infodemic in Weibo",
      "abstract": "The proliferation of COVID-19 fake news on social media poses a severe threat to the health information ecosystem. We show that affective computing can make significant contributions to combat this infodemic. Given that fake news is often presented with emotional appeals, we propose a new perspective on the role of emotion in the attitudes, perceptions, and behaviors of the dissemination of information. We study emotions in conjunction with fake news, and explore different aspects of their interaction. To process both emotion and \u2018falsehood\u2019 based on the same set of data, we auto-tag emotions on existing COVID-19 fake news datasets following an established emotion taxonomy. More specifically, based on the distribution of seven basic emotions (e.g. Happiness, Like, Fear, Sadness, Surprise, Disgust, Anger ), we find across domains and styles that COVID-19 fake news is dominated by emotions of Fear (e.g., of coronavirus), and Disgust (e.g., of social conflicts). In addition, the framing of fake news in terms of gain-versus-loss reveals a close correlation between emotions, perceptions, and collective human reactions. Our analysis confirms the significant role of emotion Fear in the spreading of the fake news, especially when contextualized in the loss frame. Our study points to a future direction of incorporating emotion footprints in models of automatic fake news detection, and establishes an affective computing approach to information quality in general and fake news detection in particular.",
      "year": "2023",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Mingyu Wan et al.",
      "keywords": "Sentiment analysis; Coronavirus disease 2019 (COVID-19); Emotion detection; Negative emotion; Computer science; Emotion recognition; Psychology; Emotional contagion; Fake news; Cognitive psychology; Internet privacy; Artificial intelligence; Social psychology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taffc.2023.3295806",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3092208147",
      "doi": "10.1109/access.2020.3029907",
      "title": "Predicting Prodromal Dementia Using Linguistic Patterns and Deficits",
      "abstract": "Language deficiency is evident in the onset of several neurodegenerative disorders yet has barely been investigated when first occurs on the continuum of cognitive impairment for the purpose of early diagnoses. Alzheimer's disease (AD) is a neurodegenerative pathology that develops years prior to clinical manifestations and typically preceded by prodromal stages such as Mild Cognitive Impairment (MCI). Currently, the manual diagnostic procedures of both types are time consuming, following certain clinical criteria and neuropsychological examinations. Our study aims to establish state-of-the-art performance in the automatic identification of different dementia etiologies, including AD, MCI, and Possible AD (PoAD), and to determine whether patients with initial cognitive declines exhibit language deficits through the analysis of language samples deduced with the cookie theft picture description task. Data was derived from the cookie theft picture corpus of DementiaBank, from which all language samples of the identified etiologies were used, with a random subsampling technique that handles the skewness of the classes. Several original lexical and syntactic (i.e., lexicosyntactic) features were introduced and used alongside previously established lexicosyntactics to train machine learning (ML) classifiers against these etiologies. Further, a statistical analysis was conducted to uncover the deficiency across these etiologies. Our models resulted in benchmarks for differentiating all the identified classes with accuracies ranging between 95 to 98% and corresponding F1 values falling between 94 and 98%. The statistical analysis of our lexicosyntactic biomarkers shows that linguistic deviations are associated with prodromal as well as advanced neurodegenerative pathologies, being greatly impacted as cognitive decline increases and suggesting that language biomarkers may aid the early diagnosis of these pathologies.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ahmed H. Alkenani et al.",
      "keywords": "Dementia; Neuropsychology; Etiology; Cognition; Medical diagnosis; Cognitive impairment; Psychology; Disease; Skewness; Cognitive psychology; Medicine; Artificial intelligence; Computer science; Pathology; Psychiatry; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3029907",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382468076",
      "doi": "10.1109/access.2023.3289952",
      "title": "AMSeg: A Novel Adversarial Architecture Based Multi-Scale Fusion Framework for Thyroid Nodule Segmentation",
      "abstract": "The thyroid gland is an important and essential endocrine organ for the human body that regulates metabolism, growth and development by secreting thyroid hormones. Thyroid nodules are irregular masses caused by lesions that can reflect the main clinical manifestation of thyroid abnormalities. Delineating the boundaries of thyroid nodules from ultrasound images is an indispensable part of computer-aided diagnosis systems and medical imaging diagnosis for thyroid diseases. However, automatic segmentation of thyroid nodules is still a challenging task because of the similarity between the heterogeneous appearance and its background. In this study, we propose a novel framework for thyroid nodule segmentation that exploits multiscale anatomical features to build a late-stage fusion method based on adversarial training. The introduced architecture can handle blurred and uneven tissue regions during the thyroid nodule segmentation process. By adversarial training approaches, our segmentation block S adopts a framework with three different fusion scales, and discrimination block D employs a fully convolutional encoder-decoder architecture. Extensive experimental results demonstrate that AMSeg outperforms popular methods in terms of thyroid nodule segmentation. The proposed framework achieves Dice, Hd95 (95&#x0025; Hausdorff distance), Jaccard, and precision values of 83.06&#x0025;, 23.13, 74.18&#x0025;, and 87.82&#x0025;, respectively. As an end-to-end network, the AMSeg can effectively replace manual segmentation methods and has great prospects in clinical applications.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Xiaoxuan Ma et al.",
      "keywords": "Computer science; Segmentation; Artificial intelligence; Thyroid nodules; Thyroid; Nodule (geology); Pattern recognition (psychology); Image segmentation; Computer vision; Medicine; Internal medicine; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3289952",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313182760",
      "doi": "10.1109/access.2022.3230688",
      "title": "Self-Supervised Learning of Neural Speech Representations From Unlabeled Intracranial Signals",
      "abstract": "Neuroprosthetics have demonstrated the potential to decode speech from intracranial brain signals, and hold promise for one day returning the ability to speak to those who have lost it. However, data in this domain is scarce, highly variable, and costly to label for supervised modeling. In order to address these constraints, we present brain2vec, a transformer-based approach for learning feature representations from intracranial electroencephalogram data. Brain2vec combines a self-supervised learning methodology, neuroanatomical positional embeddings, and the contextual representations of transformers to achieve three novelties: (1) learning from unlabeled intracranial brain signals, (2) learning from multiple participants simultaneously, all while (3) utilizing only raw unprocessed data. To assess our approach, we use a leave-one-participant-out validation procedure to separate brain2vec&#x2019;s feature learning from the holdout participant&#x2019;s speech-related supervised classification tasks. With only two linear layers, we achieve 90&#x0025; accuracy on a canonical speech detection task, 42&#x0025; accuracy on a more challenging 4-class speech-related behavior recognition, and 53&#x0025; accuracy when applied to a 10-class, few-shot word classification task. Combined with the visualizations of unsupervised class separation in the learned features, our results evidence brain2vec&#x2019;s ability to learn highly generalized representations of neural activity without the need for labels or consistent sensor location.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Srdjan Lesaja et al.",
      "keywords": "Computer science; Artificial intelligence; Transformer; Supervised learning; Machine learning; Speech recognition; Task (project management); Labeled data; Class (philosophy); Pattern recognition (psychology); Semi-supervised learning; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3230688",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4214846422",
      "doi": "10.1109/access.2022.3156278",
      "title": "TinyCowNet: Memory- and Power-Minimized RNNs Implementable on Tiny Edge Devices for Lifelong Cow Behavior Distribution Estimation",
      "abstract": "Precision livestock farming promises substantial advantages in terms of animal welfare, product quality and reducing methane emissions, but requires continuous and reliable data on the animal's behavior. While systems suitable for use within the barn exist, grazing over long distances poses challenges. Here, we address this issue by proposing an ultra low-power Edge AI device, minimizing data transmission requirements and potentially improving accuracy as compared to classification-based solutions. Namely, we propose cow behavior distribution regression with Recurrent Neural Networks (RNNs), dubbed TinyCowNet, to estimate mixed-label sample spaces. Without quantization, the random search to minimize resources and maximize accuracy shows networks requiring a memory of 76kB on average and offering an accuracy up to 95.7&#x0025;. These are implementable on a wide range of low-power Micro Controller Units (MCU) and Field Programmable Gate Arrays (FPGA). Furthermore, our proposed post-training full-integer quantization for RNNs combined with power estimation on 45nm CMOS using experimental literature shows a TinyCowNet occupying a memory around <inline-formula> <tex-math notation=\"LaTeX\">$\\approx 2$ </tex-math></inline-formula>kB, having a hypothetical power consumption on the order of 200nW, delivering an accuracy of 95.2&#x0025; and a Matthews correlation coefficient of 0.86. This work paves the way for the future creation of low-cost, highly accurate cow behavior estimation devices with long battery life that reduce the entry barriers currently hindering precision livestock farming outside the barn.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Jim Bartels et al.",
      "keywords": "Computer science; Quantization (signal processing); Learning vector quantization; Recurrent neural network; Computer engineering; Artificial neural network; Real-time computing; Mathematical optimization; Artificial intelligence; Algorithm; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3156278",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2903778898",
      "doi": "10.1109/access.2018.2885640",
      "title": "Smart Information Retrieval: Domain Knowledge Centric Optimization Approach",
      "abstract": "In the age of Internet of Things (IoT), online data has witnessed significant growth in terms of volume and diversity, and research into information retrieval has become one of the important research themes in the Internet oriented data science research. In information retrieval, machine-learning techniques have been widely adopted to automate the challenging process of relation extraction from text data, which is critical to the accuracy and efficiency of information retrieval-based applications including recommender systems and sentiment analysis. In this context, this paper introduces a novel, domain knowledge centric methodology aimed at improving the accuracy of using machine-learning methods for relation classification, and then utilise Genetic Algorithms (GAs) to optimise the feature selection for the learning algorithms. The proposed methodology makes significant contribution to the processes of domain knowledge-based relation extraction including interrogating Linked Open Datasets to generate the relation classification training-data, addressing the imbalanced classification in the training datasets, determining the probability threshold of the best learning algorithm, and establishing the optimum parameters for the genetic algorithm utilised in feature selection. The experimental evaluation of the proposed methodology reveals that the adopted machine-learning algorithms exhibit higher precision and recall in relation extraction in the reduced feature space optimised by the implementation. The considered machine learning includes Support Vector Machine, Perceptron Algorithm Uneven Margin and K-Nearest Neighbours. The outcome is verified by comparing against the Random Mutation Hill-Climbing optimisation algorithm using Wilcoxon signed-rank statistical analysis.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Abduladem Aljamel et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Relation (database); Data mining; Domain knowledge; Support vector machine; Perceptron; Feature selection; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2885640",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385486267",
      "doi": "10.1109/access.2023.3301160",
      "title": "Efficient Scopeformer: Toward Scalable and Rich Feature Extraction for Intracranial Hemorrhage Detection",
      "abstract": "The quality and richness of feature maps extracted by convolution neural networks (CNNs) and vision Transformers (ViTs) directly relate to the robust model performance. In medical computer vision, these information-rich features are crucial for detecting rare cases within large datasets. This work presents the \u201cScopeformer,\u201d a novel multi-CNN-ViT model for intracranial hemorrhage classification in computed tomography (CT) images. The Scopeformer architecture is scalable and modular, which allows utilizing various CNN architectures as the backbone with diversified output features and pre-training strategies. We propose effective feature projection methods to reduce redundancies among CNN-generated features and to control the input size of ViTs. Extensive experiments with various Scopeformer models show that the model performance is proportional to the number of convolutional blocks employed in the feature extractor. Using multiple strategies, including diversifying the pre-training paradigms for CNNs, different pre-training datasets, and style transfer techniques, we demonstrate an overall improvement in the model performance at various computational budgets. Later, we propose smaller compute-efficient Scopeformer versions with three different types of input and output ViT configurations. Efficient Scopeformers use four different pre-trained CNN architectures as feature extractors to increase feature richness. Our best Efficient Scopeformer model achieved an accuracy of 96.94% and a weighted logarithmic loss of 0.083 with an eight times reduction in the number of trainable parameters compared to the base Scopeformer. Another version of the Efficient Scopeformer model further reduced the parameter space by almost 17 times with negligible performance reduction. In summary, our work showed that the hybrid architectures consisting of CNNs and ViTs might provide the desired feature richness for developing accurate medical computer vision models.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Yassine Barhoumi et al.",
      "keywords": "Computer science; Convolutional neural network; Pattern recognition (psychology); Scalability; Feature extraction; Artificial intelligence; Convolution (computer science); Feature (linguistics); Feature vector; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3301160",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386609270",
      "doi": "10.1109/access.2023.3313608",
      "title": "A Dynamic Optimization-Based Ensemble Learning Method for Traditional Chinese Medicine Named Entity Recognition",
      "abstract": "The importance of named entity identification in traditional Chinese medicine (TCM) as the basis for supporting downstream tasks is receiving increasing attention. Deep learning-based methods have been widely used for related tasks. However, most current methods do not deal well with two common TCM entity recognition problems: an unbalanced number of entities and sparse entities. To solve these problems, we propose an ensemble learning method based on dynamic optimization. In this study, we first use bidirectional encoder representations from transformers (BERT) to extract word vectors and then further extract features based on BERT-bidirectional long short-term memory (BiLSTM). Then, we dynamically adjust the entity class and fusion weights of ensemble learning according to the entity distribution and sparsity of each batch. Finally, the prediction results are output through the conditional random field (CRF) layer. This approach allows the model to dynamically focus on difficult samples and to improve the update weights of the most beneficial learning tasks. In addition, we introduce a reduction factor to reduce the magnitude of the parameter updates when the entities are sparse. This prevents the model from being unduly disrupted by nonentity information. Therefore, our model can effectively reduce the negative impact of unbalanced numbers of entities and sparse entities. The experimental results show that our model achieves the best results on a publicly available TCM entity recognition dataset and has a faster convergence rate than the baseline model. Compared to the baseline model BERT-BiLSTM-CRF, our method improves the F1-score by 0.56, further demonstrating its effectiveness.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Zongyao Zhao et al.",
      "keywords": "Computer science; Conditional random field; Named-entity recognition; Artificial intelligence; Machine learning; Transformer; Encoder; Deep learning; Identification (biology); Pattern recognition (psychology); Task (project management)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3313608",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393305446",
      "doi": "10.1109/access.2024.3383020",
      "title": "Advancing Tinnitus Therapeutics: GPT-2 Driven Clustering Analysis of Cognitive Behavioral Therapy Sessions and Google T5-Based Predictive Modeling for THI Score Assessment",
      "abstract": "Cognitive Behavioral Therapy (CBT) for tinnitus alleviates psychological discomfort caused by severe tinnitus symptoms. During CBT, the patients will have various homework assignments, including writing daily diaries and self-monitoring. Most of these homework assignments are hand-written, textual data. This paper proposes that tinnitus therapeutics can utilize Large Language Models (LLMs) to analyze CBT and predict the outcomes of CBT treatments to manage high caseloads. We anonymized patient data and examined it with GPT-2-based-embedding, dimensionality reduction, and clustering process to observe how patients themselves changed their misconceptions and developed less unnecessary excessive emotional discomfort and how their Tinnitus Handicap Inventory (THI) scores were improved after the CBT treatment. We also discussed clustering results as a part of the demonstrations that LLMs can give us insights into the CBT. Then, we augmented textual patient data in three ways to minimize augmentation bias with a corresponding penalty to overcome the constraints of limitation of the number of datasets. We trained the Google T5 Transformer with the augmented data to predict the THI score outcomes at the end of the CBT sessions. We measured the performance using the ROUGE-L metric during the training and validation. The generated THI scores by Google T5 were converted from strings to floats to measure RMSE performance, which proved that the LLM could predict the outcome of CBT treatment with CBT data. Even though there is a risk of overfitting issues, this work demonstrated that tinnitus therapeutics experts can employ LLMs to manage caseloads.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Y. Jeong et al.",
      "keywords": "Cognitive behavioral therapy; Cluster analysis; Tinnitus; Medicine; Cognition; Computer science; Machine learning; Audiology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3383020",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388819879",
      "doi": "10.1109/access.2023.3335216",
      "title": "A Critical Analysis of Benchmarks, Techniques, and Models in Medical Visual Question Answering",
      "abstract": "This paper comprehensively reviews medical VQA models, structures, and datasets, focusing on combining vision and language. Over 75 models and their statistical and SWOT (Strengths, Weaknesses, Opportunities, Threats) analyses were compared and analyzed. The study highlights whether the researchers in the general field influence those in the medical field. According to an analysis of text encoding techniques, LSTM is the approach that is utilized the most (42&#x0025;), followed by non-text methods (14&#x0025;) and BiLSTM (12&#x0025;), whereas VGGNet (40&#x0025;) and ResNet (22&#x0025;) are the most often used vision methods, followed by Ensemble approaches (16&#x0025;). Regarding fusion techniques, 14&#x0025; of the models employed non-specific methods, while SAN (13&#x0025;) and concatenation (10&#x0025;) were frequently used. The study identifies LSTM-VGGNet and LSTM-ResNet combinations as the primary approaches in medical VQA, with 18&#x0025; and 15&#x0025; usage rates, respectively. The statistical analysis of medical VQA from 2018 to 2023 and individual yearly analyses reveals consistent preferences for LSTM and VGGNet, except in 2018 when ResNet was more commonly used. The SWOT analysis provides insights into the strengths and weaknesses of medical VQA research, highlighting areas for future exploration. These areas include addressing limited dataset sizes, enhancing question diversity, mitigating unimodal bias, exploring multi-modal datasets, leveraging external knowledge, incorporating multiple images, ensuring practical medical application integrity, improving model interpretation, and refining evaluation methods. This paper&#x2019;s findings contribute to understanding medical VQA and offer valuable guidance for future researchers aiming to make advancements in this field.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Suheer Al-Hadhrami et al.",
      "keywords": "Computer science; Strengths and weaknesses; Concatenation (mathematics); Field (mathematics); SWOT analysis; Data science; Artificial intelligence; Machine learning; Residual neural network; Question answering; Topic model; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3335216",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3118829256",
      "doi": "10.1109/access.2020.3048932",
      "title": "Semantic-Aware Graph Convolutional Networks for Clinical Auxiliary Diagnosis and Treatment of Traditional Chinese Medicine",
      "abstract": "Traditional Chinese Medicine (TCM) clinical informatization focuses on serving user-oriented health knowledge and facilitating online diagnosis. Regularities are hidden in clinical knowledge play a significant role in the improvement of the TCM informatization service. However, many regularities can hardly be discovered because of specific data-challenges in TCM prescriptions at present. Therefore, in this article, we propose an end-to-end model, called Semantic-aware Graph Convolutional Networks (SaGCN) model, to learn the latent regularities in three steps: (1) We first construct a heterogeneous graph based on prescriptions; (2) We stack Semantic-aware graph convolution to learn effective low-dimensional representations of nodes by meta-graphs and self-attention; (3) With the learned representations, we can detect regularities accurately by clustering and linked prediction. To the best of our knowledge, this is the first study to use metagraph and graph convolutional networks for modeling TCM clinical data and diagnosis prediction. Experimental results on three real datasets demonstrate SaGCN outperforms the state-of-the-art models for clinical auxiliary diagnosis and treatment.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Chunyang Ruan et al.",
      "keywords": "Computer science; Graph; Informatization; Artificial intelligence; Construct (python library); Knowledge graph; Big data; Machine learning; Data mining; Information retrieval; Data science; Theoretical computer science; Natural language processing; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3048932",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387623887",
      "doi": "10.1109/access.2023.3324376",
      "title": "Automatic Diagnosis of Medical Conditions Using Deep Learning With Symptom2Vec",
      "abstract": "In this paper, a medical examination algorithm is proposed that can collect users&#x2019; symptoms and automatically issue a diagnosis. The proposed algorithm makes use of &#x201C;Symptom2Vec&#x201D; and the &#x201C;analysis model of responses on self-diagnosis questions&#x201D; (AMoRSD) for real-time interviews with users. Symptom2Vec can learn about the relationship between terms related to the symptoms and disease, and establish questioning criteria to be used in patient health checkups, as well as general appropriate follow-up questions based on patient symptomology. AMoRSD analyzes the patient&#x2019;s emotional expressions and responses to self-diagnostic questions, classifying them into &#x201C;Sick,&#x201D; &#x201C;Not Sick,&#x201D; and &#x201C;Neutral&#x201D; categories based on patterns. Compared to traditional models, Symptom2Vec earned the highest mean symptom similarity score of 0.983. Furthermore, compared to other models that only learn from patient responses, AMoRSD demonstrates an area under curves (AUC) of 0.99&#x0025;, indicating that jointly learning the relationship between emotions and patient responses improves the accuracy of user response classification. The combined algorithm of Symptom2Vec and AMoRSD enhances the efficiency and accuracy of user symptom collection and appropriate diagnosis generation. The data were collected from reliable medical sources such as WebMD Dictionary, NHS inform, Snomed Ct, and Cleveland Clinic, encompassing 526 disease names and 2078 symptoms. Additional data were obtained for AMoRSD, focusing on conversations within a hospital context, and effectively trained and evaluated the model using diverse and representative datasets. This research addresses the importance of medical history-taking and contributes to the field by providing a robust framework for real-time symptom-based diagnosis in clinical environments.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Minji Kim et al.",
      "keywords": "Context (archaeology); Computer science; Artificial intelligence; Machine learning; Medical history; Similarity (geometry); Disease; Natural language processing; Medicine; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3324376",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3017033364",
      "doi": "10.1109/access.2020.2987568",
      "title": "Head Concepts Selection for Verbose Medical Queries Expansion",
      "abstract": "Semantic concepts and relations encoded in domain-specific ontologies and other medical semantic resources play a crucial role in deciphering terms in medical queries and documents. The exploitation of these resources for tackling the semantic gap issue has been widely studied in the literature. However, there are challenges that hinder their widespread use in real-world applications. Among these challenges is the insufficient knowledge individually encoded in existing medical ontologies, which is magnified when users express their information needs using long-winded natural language queries. In this context, many of the users' query terms are either unrecognized by the used ontologies, or cause retrieving false positives that degrade the quality of current medical information search approaches. In this article, we explore the combination of multiple extrinsic semantic resources in the development of a full-fledged medical information search framework to: i) highlight and expand head medical concepts in verbose medical queries (i.e. concepts among query terms that significantly contribute to the informativeness and intent of a given query), ii) build semantically-enhanced inverted index documents, and iii) contribute to a heuristical weighting technique in the query-document matching process. To demonstrate the effectiveness of the proposed approach, we conducted several experiments over the CLEF e-Health 2014 dataset. Findings indicate that the proposed method combining several extrinsic semantic resources proved to be more effective than related approaches in terms of precision measure.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohammed Maree et al.",
      "keywords": "Computer science; Information retrieval; Semantic matching; Semantic similarity; Semantic query; Context (archaeology); eHealth; Query expansion; Semantic search; Semantics (computer science); Semantic Web; Matching (statistics); Web search query; Search engine; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2987568",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392173803",
      "doi": "10.1109/access.2024.3369900",
      "title": "Fast and Efficient Lung Abnormality Identification With Explainable AI: A Comprehensive Framework for Chest CT Scan and X-Ray Images",
      "abstract": "A novel automated multi-classification approach is proposed for the anticipation of lung abnormalities using chest X-ray and CT images. The study leverages a publicly accessible dataset with an insufficient and unbalanced number of images, addressing this issue by employing the data augmentation approach DCGAN to balance the dataset. Various preprocessing procedures are applied to improve features and reduce noise in lung pictures. As the base for the model, the vision trans-former and convolution-based compact convolutional transformer (CCT) model is utilized. To determine the best model configuration, an ablation study is performed on the original CCT model using a CT scan dataset with image dimensions of <inline-formula> <tex-math notation=\"LaTeX\">$32\\times32$ </tex-math></inline-formula>. Following that, this model is trained on the X-ray dataset to evaluate performance on an entirely other modality. The performances are compared to six pre-trained models with <inline-formula> <tex-math notation=\"LaTeX\">$32\\times 32$ </tex-math></inline-formula> images. While traditional models achieved modest performance, with test accuracies ranging from 43&#x0025; to 77&#x0025; and 49&#x0025; to 73&#x0025; requiring lengthy training times, the suggested model performed exceptionally well, obtaining test accuracies of 99.77&#x0025; and 95.37&#x0025; for CT and X-ray, respectively with a short training duration of 10&#x2013;12 and 40&#x2013;42 seconds/epoch. Robustness is demonstrated through the progressive reduction of the number of training images, with findings indicating that the model maintains good performance even on a reduced dataset. An explainable AI technique Grad-CAM is used to explain the model&#x2019;s judgment. Grad-CAM-based color visualization is shown to explain model assessments and help health specialists make quick, confident decisions. This study used image preprocessing and deep learning techniques to detect lung anomalies, and it addressed the challenges of training time and computational complexity.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Md. Zahid Hasan et al.",
      "keywords": "Abnormality; Identification (biology); Computer science; Lung; Radiology; Computed tomography; Artificial intelligence; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3369900",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394862548",
      "doi": "10.1109/access.2024.3389655",
      "title": "Detecting Reported Side Effects of COVID-19 Vaccines From Arabic Twitter (X) Data",
      "abstract": "Vaccines might potentially cause side effects as any other drugs, which needs to be investigated and analyzed to identify the public safety concerns. The massive vaccination rollout against COVID-19 provoked discussion among people through social media platforms. Twitter (X), a popular social media platform, plays a significant role in disseminating information about COVID-19 vaccines and monitoring people&#x2019;s reports regarding vaccination side effects. The aim of this study is to mine Twitter (X) to identify self-reported side effects related to COVID-19 vaccines in Arabic language, compare their distribution among six vaccine types, and construct Arabic lexicon of symptoms. We collected the tweets posts in Arabic language after the distribution of COVID-19 vaccines, then we developed a workflow for identifying self-report symptoms using biterm topic modeling (BTM) and support vector machine (SVM) to extract the symptoms then cluster them in groups based on their co-occurrence. A total of 51 symptoms were extracted from 65,387 tweets that were reported 148,324 times. We performed a more in-depth analysis to investigate the symptoms that tend to occur simultaneously. The results show that the symptoms that more likely to occur together may indicate to a particular connection. The findings suggested that the social media conversation can provide a comprehensive depiction of symptoms that may complement what identified in clinical studies.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Maram K. Alhumayani et al.",
      "keywords": "Coronavirus disease 2019 (COVID-19); Arabic; Computer science; Virology; 2019-20 coronavirus outbreak; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3389655",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4390423546",
      "doi": "10.1109/access.2023.3348123",
      "title": "Enhancing Low Carbon Awareness in Social Media Discourse: A Fuzzy Clustering Approach",
      "abstract": "The frequent occurrence of extreme weather makes people pay more attention to environmental protection. To cope with the global climate problem, various countries re-plan social development through the concept of low-carbon. As greatly popularized by the Internet, the topic of low carbon concept is spread more through online social media, so it is urgent to understand the user&#x2019;s attention to low carbon topics in a more intelligent way for subsequent relevant publicity and policy guidance. This paper studies the low-carbon topic of attention in the context of social media. First, the BERT (Bidirectional Encoder Representation from Transformers) model is used to complete the word vector feature extraction of acquired data; Secondly, the FCM method was used to complete the clustering analysis of the main topics in the low-carbon concept, and the PSO method was used to optimize the model. After optimization, the accuracy of clustering for various topics was higher than 80&#x0025;. For the Esse index of cluster center variance, the method proposed in this article is also close to 10&#x0025; due to other classic methods; Finally, this paper carried out an application test of low-carbon topics in the region, achieved good results, and made a detailed analysis of the distribution of various topics. It can be predicted that this method will provide more public opinion references for low-carbon development paths in various countries and regions in the future, and provide technical support for information dissemination and analysis under social media.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Chao Han et al.",
      "keywords": "Computer science; Fuzzy logic; Social media; Cluster analysis; Artificial intelligence; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3348123",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226001346",
      "doi": "10.1109/access.2022.3166150",
      "title": "Exploration on Automatic Management of GIS Using TL-CNN and IoT",
      "abstract": "The research aims to effectively monitor the state of complex industrial equipment in real time, diagnose the internal Partial Discharge (PD) pattern of Gas Insulated Metal Enclosed Switchgear (GIS), implement effective health management, and change the traditional model optimization route of increasing training time in exchange for performance improvement. This paper studies the complex equipment-oriented Health Management System (HMS) based on Internet of Things (IoT) technology and Transfer Learning. Firstly, the principles of Transfer Learning and Deep Learning (DL) technology are introduced. Secondly, the requirements of GIS internal status recognition and management are studied. Furthermore, a GIS-oriented HMS based on Transfer Learning-optimized Convolutional Neural Networks (CNN) is proposed, and the training dataset is constructed. Finally, the proposed model is tested. The results show that the complex equipment-oriented HMS based on IoT technology, CNN, and Transfer Learning can detect the internal status of GIS in real time. Compared with the traditional DL algorithm and expert system, the proposed model has a shorter training time of only 16min, faster convergence speed, high testing recognition rate, and over 96&#x0025; recognition rate. Compared with other mainstream algorithms, it has higher identification, the storage parameter volume is 408, and the storage space is 12.8MB. Moreover, the proposed Transfer Learning-optimized CNN model can accurately detect the status of GIS, identify abnormal statuses, and help prolong the service life of GIS. The proposed complex equipment-oriented HMS contributes to the intelligent manufacturing industry and provides a new direction for applying emerging Computer Technology in the intelligent industry.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Miao Wang et al.",
      "keywords": "Computer science; Transfer of learning; Convolutional neural network; Deep learning; Artificial intelligence; Switchgear; Machine learning; Data mining; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3166150",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391559421",
      "doi": "10.1109/access.2024.3363410",
      "title": "RotU-Net: An Innovative U-Net With Local Rotation for Medical Image Segmentation",
      "abstract": "In recent years, both convolutional neural networks (CNN) and transformers have demonstrated impressive feature extraction capabilities in the field of medical image segmentation. A common approach is to utilize a combination of CNN and transformer encoders to efficiently learn both local and global features, making them widely adopted techniques in semantic segmentation of medical images. However, challenges remain due to the limited sample size of medical image datasets and the intricate foreground edge information in these images. These challenges make it difficult for models to capture key structures and information related to foreground edge details, especially when trained on smaller datasets. To address these issues, we propose a U-Net-based model called &#x201C;Rotate U-Net&#x201D; (RotU-Net). Our model design is inspired by the successful U-Net architecture, which is characterized by direct connections between encoders and decoders, and skipping connections at multiple resolutions. Meanwhile, we propose weight rotator as a feature extraction module, which enhances network to discriminate edge information in the foreground region by computing partial element correlations to improve the network to focus on the foreground region while reducing redundant information in the features. Finally, we have validated RotU-Net on the Synapse Multi-Organ Segmentation Dataset (Synapse) and the Segmentation of Multiple Myeloma Plasma Cells in Microscopic Images (SegPC). The experimental results show that RotU-Net with a very small number of parameters achieves impressive performance, which demonstrates the effectiveness and efficiency of RotU-Net.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Fuxiang Zhang et al.",
      "keywords": "Computer science; Artificial intelligence; Segmentation; Convolutional neural network; Image segmentation; Encoder; Feature extraction; Pattern recognition (psychology); Deep learning; Feature (linguistics); Feature learning; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3363410",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4383503555",
      "doi": "10.1109/access.2023.3293421",
      "title": "A Systematic Review of Electroencephalography Open Datasets and Their Usage With Deep Learning Models",
      "abstract": "Data are the main headache for machine learning, both because of their varied nature and their limited availability. The medical field brings together both situations: tables, images, text, or signals that are difficult to acquire due to the number of patients, the complexity and time of acquisition, or ethical constraints. The existence of open datasets is the best option for researchers in this field. Electroencephalograms are a good example of this situation. This paper identifies the primary open datasets of electroencephalography tests and how they are used in deep learning models. The aim is to provide structured information that can be consulted by researchers in the field (both physicians and computer scientists) to know which datasets are available, which characteristics they have, or which deep learning models could be applied to them. The process followed the PRISMA methodology for systematic reviews applying different inclusion and exclusion criteria to obtain a set of high-quality papers on which the data sets used were analyzed. The databases included in the searches were Scopus, PubMed, Web of Science (WOS), Science Direct, IEEE Explorer, and SpringerLink. In total, 37 papers were selected which included 30 datasets that have been considered. Then, the DL models used in the papers and the different characteristics of the datasets have been statistically analyzed by obtaining different measures and graphs. The most relevant conclusions are the widespread use of convolutional neural networks (the less innovative among the different models) as the main tool for EEG data analysis. Against this position, we found the use of hybrid models and the family of RNNs as techniques to use in cases of brain stimuli, classification of levels of fatigue, and diagnosis of diseases. Related to the datasets\u2019 features, we demonstrate the difficulty in compiling this data due to the number of tests and that the minimum of channels or sampling frequency recommended to obtain good accuracies in the model should be studied.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Alberto Nogales et al.",
      "keywords": "Electroencephalography; Computer science; Artificial intelligence; Deep learning; Machine learning; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2023.3293421",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386472869",
      "doi": "10.1109/access.2023.3312622",
      "title": "A Novel Two-Fold Loss Function for Data Clustering and Reconstruction: Application to Document Analysis",
      "abstract": "<p dir=\"ltr\">In the midst of the ongoing COVID-19 pandemic, there has been a surge in scientific literature aimed at understanding the virus and its impact. However, it has become challenging for a researcher to deal with thousands of articles published daily. This paper proposes a novel deep-learning architecture to organize a large dataset of COVID-19-related scientific literature and provides a clear overview of the current state of knowledge. The proposed model is developed based on two main bases to ensure robustness and efficiency. In particular, we trained a denoising autoencoder with clean and noisy data to make the model can balance, preserving the underline structure and generalizing the new unseen data. Furthermore, the cornerstone of the proposed architecture lies in training the autoencoder using a two-fold objective function that jointly incorporates the data\u2019s reconstruction and clustering. The advantage behind this combination is to avoid the distortion of the latent space and to improve the model efficiency. Afterward, we use the Latent Dirichlet Allocation (LDA) to analyze the document\u2019s topics. For the sake of computational efficiency, instead of feeding the LDA with the whole dataset of documents, we fed it with the clusters produced in the phase of dimensionality reduction and clustering to count the frequency of topics in each cluster. The model was trained on a large public corpus of COVID-19-related articles and evaluated using a set of evaluation metrics. Experimental results indicate the superiority of our proposed model compared to several recent studies. <h2>Other Information</h2><p dir=\"ltr\">Published in: IEEE Access<br>License: <a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">https://creativecommons.org/licenses/by/4.0/</a><br>See article on publisher's website: <a href=\"https://dx.doi.org/10.1109/access.2023.3312622\" target=\"_blank\">https://dx.doi.org/10.1109/access.2023.3312622</a>",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mebarka Allaoui et al.",
      "keywords": "Latent Dirichlet allocation; Computer science; Cluster analysis; Autoencoder; Robustness (evolution); Topic model; Dimensionality reduction; Artificial intelligence; Data mining; Machine learning; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312622",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389105055",
      "doi": "10.1109/access.2023.3337426",
      "title": "Unveiling Key Drivers of Industry 4.0 Adaptation in CKD Automotive Manufacturing Companies: Evidence From Asia and South America",
      "abstract": "The paper investigates the drivers of Industry 4.0 adaptation in the CKD automotive industry. The methodology is based on a cross-sectional empirical study, where the samples were drawn using simple random sampling. Four hypotheses were developed, and the data were collected using an online survey and a standardised questionnaire. Survey responses were received from white-collar employees at a CKD automotive manufacturer encompassing multiple CKD plants in Asia and South America. One hundred fifty survey responses were received and next analysed using Structural Equation Modelling (SEM) in SmartPLS software. Based on the findings, three drivers, namely, business competitiveness, customer satisfaction, and operational improvement, positively affect the Industry 4.0 adaptation in CKD manufacturing companies. However, the financial benefit factor does not affect the adaptation of Industry 4.0 in manufacturing industries. This study contributes to the existing knowledge in understanding the drivers for Industry 4.0 adaptation. In addition, these findings might aid the practitioners and government in tailoring the policy related to Industry 4.0 in CKD automotive manufacturing industries.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Norhana Mohd Aripin et al.",
      "keywords": "Automotive industry; Adaptation (eye); Business; Structural equation modeling; Government (linguistics); Manufacturing; Marketing; Affect (linguistics); Industrial organization; Operations management; Engineering; Computer science; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3337426",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2949767632",
      "doi": "10.1109/access.2019.2923707",
      "title": "Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques",
      "abstract": "Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM).",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Senthilkumar Mohan et al.",
      "keywords": "Computer science; Machine learning; Random forest; Heart disease; Artificial intelligence; Predictive modelling; Disease; Internet of Things; Support vector machine; The Internet; Data mining; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2923707",
      "cited_by_count": 1773,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3091468319",
      "doi": "10.1109/ojemb.2020.3026928",
      "title": "COVID-19 Artificial Intelligence Diagnosis Using Only Cough Recordings",
      "abstract": "<i>Goal:</i> We hypothesized that COVID-19 subjects, especially including asymptomatics, could be accurately discriminated only from a forced-cough cell phone recording using Artificial Intelligence. To train our MIT Open Voice model we built a data collection pipeline of COVID-19 cough recordings through our website (opensigma.mit.edu) between April and May 2020 and created the largest audio COVID-19 cough balanced dataset reported to date with 5,320 subjects. <i>Methods:</i> We developed an AI speech processing framework that leverages acoustic biomarker feature extractors to pre-screen for COVID-19 from cough recordings, and provide a personalized patient saliency map to longitudinally monitor patients in real-time, non-invasively, and at essentially zero variable cost. Cough recordings are transformed with Mel Frequency Cepstral Coefficient and inputted into a Convolutional Neural Network (CNN) based architecture made up of one Poisson biomarker layer and 3 pre-trained ResNet50's in parallel, outputting a binary pre-screening diagnostic. Our CNN-based models have been trained on 4256 subjects and tested on the remaining 1064 subjects of our dataset. Transfer learning was used to learn biomarker features on larger datasets, previously successfully tested in our Lab on Alzheimer's, which significantly improves the COVID-19 discrimination accuracy of our architecture. <b><i>Results:</i> When validated with subjects diagnosed using an official test, the model achieves COVID-19 sensitivity of 98.5% with a specificity of 94.2% (AUC: 0.97). For asymptomatic subjects it achieves sensitivity of 100% with a specificity of 83.2%</b>. <i>Conclusions:</i> AI techniques can produce a free, non-invasive, real-time, any-time, instantly distributable, large-scale COVID-19 asymptomatic screening tool to augment current approaches in containing the spread of COVID-19. Practical use cases could be for daily screening of students, workers, and public as schools, jobs, and transport reopen, or for pool testing to quickly alert of outbreaks in groups. General speech biomarkers may exist that cover several disease categories, as we demonstrated using the same ones for COVID-19 and Alzheimer's.",
      "year": "2020",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Jordi Laguarta et al.",
      "keywords": "Artificial intelligence; Convolutional neural network; Computer science; Coronavirus disease 2019 (COVID-19); Biomarker; Speech recognition; Transfer of learning; Sensitivity (control systems); Feature (linguistics); Binary classification; Pattern recognition (psychology); Machine learning; Medicine; Support vector machine; Pathology; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2020.3026928",
      "cited_by_count": 589,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2941702032",
      "doi": "10.1109/access.2019.2911031",
      "title": "Security, Performance, and Applications of Smart Contracts: A Systematic Survey",
      "abstract": "Blockchain is the promising technology of recent years, which has attracted remarkable attention in both academic studies and practical industrial applications. The smart contract is a programmable transaction that can perform a sophisticated task, execute automatically, and store on the blockchain. The smart contract is the key component of the blockchain, which has made blockchain a technology beyond the scope of the cryptocurrencies and applicable for a variety of applications such as healthcare, IoT, supply chain, digital identity, business process management, and more. Although in recent years the progress toward improving blockchain technology with the focus on the smart contract has been impressive, there is a lack of reviewing the smart contract topic. This paper systematically reviews the key concepts and proposes the direction of recent studies and developments regarding the smart contract. The research studies are presented in three main categories: 1) security methods and tools; 2) performance improvement approaches; and 3) decentralized applications based on smart contracts.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Sara Rouhani et al.",
      "keywords": "Blockchain; Computer science; Smart contract; Cryptocurrency; Computer security; Key (lock); Scope (computer science); Database transaction; Supply chain; Process management; Engineering management; Business; Database; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2911031",
      "cited_by_count": 300,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3004825562",
      "doi": "10.1109/access.2020.2971576",
      "title": "Human Digital Twin for Fitness Management",
      "abstract": "Our research work describes a team of human Digital Twins (DTs), each tracking fitness-related measurements describing an athlete's behavior in consecutive days (e.g. food income, activity, sleep). After collecting enough measurements, the DT firstly predicts the physical twin performance during training and, in case of non-optimal result, it suggests modifications in the athlete's behavior. The athlete's team is integrated into SmartFit, a software framework for supporting trainers and coaches in monitoring and manage athletes' fitness activity and results. Through IoT sensors embedded in wearable devices and applications for manual logging (e.g. mood, food income), SmartFit continuously captures measurements, initially treated as the dynamic data describing the current physical twins' status. Dynamic data allows adapting each DT's status and triggering the DT's predictions and suggestions. The analyzed measurements are stored as the historical data, further processed by the DT to update (increase) its knowledge and ability to provide reliable predictions. Results show that, thanks to the team of DTs, SmartFit computes trustable predictions of the physical twins' conditions and produces understandable suggestions which can be used by trainers to trigger optimization actions in the athletes' behavior. Though applied in the sport context, SmartFit can be easily adapted to other monitoring tasks.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Barbara Rita Barricelli et al.",
      "keywords": "Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2971576",
      "cited_by_count": 249,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W1994514622",
      "doi": "10.1109/tmi.2015.2415453",
      "title": "Fast Volume Reconstruction From Motion Corrupted Stacks of 2D Slices",
      "abstract": "Capturing an enclosing volume of moving subjects and organs using fast individual image slice acquisition has shown promise in dealing with motion artefacts. Motion between slice acquisitions results in spatial inconsistencies that can be resolved by slice-to-volume reconstruction (SVR) methods to provide high quality 3D image data. Existing algorithms are, however, typically very slow, specialised to specific applications and rely on approximations, which impedes their potential clinical use. In this paper, we present a fast multi-GPU accelerated framework for slice-to-volume reconstruction. It is based on optimised 2D/3D registration, super-resolution with automatic outlier rejection and an additional (optional) intensity bias correction. We introduce a novel and fully automatic procedure for selecting the image stack with least motion to serve as an initial registration target. We evaluate the proposed method using artificial motion corrupted phantom data as well as clinical data, including tracked freehand ultrasound of the liver and fetal Magnetic Resonance Imaging. We achieve speed-up factors greater than 30 compared to a single CPU system and greater than 10 compared to currently available state-of-the-art multi-core CPU methods. We ensure high reconstruction accuracy by exact computation of the point-spread function for every input data point, which has not previously been possible due to computational limitations. Our framework and its implementation is scalable for available computational infrastructures and tests show a speed-up factor of 1.70 for each additional GPU. This paves the way for the online application of image based reconstruction methods during clinical examinations. The source code for the proposed approach is publicly available.",
      "year": "2015",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Bernhard Kainz et al.",
      "keywords": "Volume (thermodynamics); Computer vision; Motion (physics); Iterative reconstruction; Computer science; Artificial intelligence; Computer graphics (images); Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2015.2415453",
      "cited_by_count": 211,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2906455801",
      "doi": "10.1109/access.2018.2888639",
      "title": "Diagnosis of Diabetic Retinopathy Using Deep Neural Networks",
      "abstract": "Diabetic retinopathy (DR) is a common eye disease and a significant cause of blindness in diabetic patients. Regular screening with fundus photography and timely intervention is the most effective way to manage the disease. The large population of diabetic patients and their massive screening requirements have generated interest in a computer-aided and fully automatic diagnosis of DR. Deep neural networks, on the other hand, have brought many breakthroughs in various tasks in the recent years. To automate the diagnosis of DR and provide appropriate suggestions to DR patients, we have built a dataset of DR fundus images that have been labeled by the proper treatment method that is required. Using this dataset, we trained deep convolutional neural network models to grade the severities of DR fundus images. We were able to achieve an accuracy of 88.72&#x0025; for a four-degree classification task in the experiments. We deployed our models on a cloud computing platform and provided pilot DR diagnostic services for several hospitals; in the clinical evaluation, the system achieved a consistency rate of 91.8&#x0025; with ophthalmologists, demonstrating the effectiveness of our work.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Zhentao Gao et al.",
      "keywords": "Diabetic retinopathy; Computer science; Convolutional neural network; Artificial intelligence; Fundus (uterus); Population; Deep learning; Fundus photography; Consistency (knowledge bases); Blindness; Optometry; Task (project management); Medicine; Machine learning; Diabetes mellitus; Ophthalmology; Retinal",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2888639",
      "cited_by_count": 216,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W1993909392",
      "doi": "10.1109/tse.2014.2360674",
      "title": "Investigating Country Differences in Mobile App User Behavior and Challenges for Software Engineering",
      "abstract": "Mobile applications (apps) are software developed for use on mobile devices and made available through app stores. App stores are highly competitive markets where developers need to cater to a large number of users spanning multiple countries. This work hypothesizes that there exist country differences in mobile app user behavior and conducts one of the largest surveys to date of app users across the world, in order to identify the precise nature of those differences. The survey investigated user adoption of the app store concept, app needs, and rationale for selecting or abandoning an app. We collected data from more than 15 countries, including USA, China, Japan, Germany, France, Brazil, United Kingdom, Italy, Russia, India, Canada, Spain, Australia, Mexico, and South Korea. Analysis of data provided by 4,824 participants showed significant differences in app user behaviors across countries, for example users from USA are more likely to download medical apps, users from the United Kingdom and Canada are more likely to be influenced by price, users from Japan and Australia are less likely to rate apps. Analysis of the results revealed new challenges to market-driven software engineering related to packaging requirements, feature space, quality expectations, app store dependency, price sensitivity, and ecosystem effect.",
      "year": "2014",
      "journal": "IEEE Transactions on Software Engineering",
      "authors": "Soo Ling Lim et al.",
      "keywords": "App store; Mobile apps; Download; Computer science; Order (exchange); World Wide Web; Software; China; Quality (philosophy); Internet privacy; Business; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tse.2014.2360674",
      "cited_by_count": 184,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4283322378",
      "doi": "10.1109/jproc.2022.3180350",
      "title": "Robot-Assisted Minimally Invasive Surgery\u2014Surgical Robotics in the Data Age",
      "abstract": "Telesurgical robotics, as a technical solution for robot-assisted minimally invasive surgery (RAMIS), has become the first domain within medicosurgical robotics that achieved a true global clinical adoption. Its relative success (still at a low single-digit percentile total market penetration) roots in the particular human-in-the-loop control, in which the trained surgeon is always kept responsible for the clinical outcome achieved by the robot-actuated invasive tools. Nowadays, this paradigm is challenged by the need for improved surgical performance, traceability, and safety reaching beyond the human capabilities. Partially due to the technical complexity and the financial burden, the adoption of telesurgical robotics has not reached its full potential, by far. Apart from the absolutely market-dominating da Vinci surgical system, there are already 60+ emerging RAMIS robot types, out of which 15 have already achieved some form of regulatory clearance. This article aims to connect the technological advancement with the principles of commercialization, particularly looking at engineering components that are under development and have the potential to bring significant advantages to the clinical practice. Current RAMIS robots often do not exceed the functionalities deriving from their mechatronics, due to the lack of data-driven assistance and smart human\u2013machine collaboration. Computer assistance is gradually gaining more significance within emerging RAMIS systems. Enhanced manipulation capabilities, refined sensors, advanced vision, task-level automation, smart safety features, and data integration mark together the inception of a new era in telesurgical robotics, infiltrated by machine learning (ML) and artificial intelligence (AI) solutions. Observing other domains, it is definite that a key requirement of a robust AI is the good quality data, derived from proper data acquisition and sharing to allow building solutions in real time based on ML. Emerging RAMIS technologies are reviewed both in a historical and a future perspective.",
      "year": "2022",
      "journal": "Proceedings of the IEEE",
      "authors": "Tam\u00e1s Haidegger et al.",
      "keywords": "Robotics; Artificial intelligence; Robot; Automation; Mechatronics; Commercialization; Traceability; Robotic surgery; Computer science; Engineering; Software engineering; Mechanical engineering; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2022.3180350",
      "cited_by_count": 184,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2915622774",
      "doi": "10.1109/taffc.2019.2901456",
      "title": "An EEG-Based Brain Computer Interface for Emotion Recognition and Its Application in Patients with Disorder of Consciousness",
      "abstract": "Recognizing human emotions based on electroencephalogram (EEG) signals has received a great deal of attentions. Most of the existing studies focused on offline analysis, and real-time emotion recognition using a brain computer interface (BCI) approach remains to be further investigated. In this paper, we proposed an EEG-based BCI system for emotion recognition. Specifically, two classes of video clips that represented positive and negative emotions were presented to the subjects one by one, while the EEG data were collected and processed simultaneously, and instant feedback was provided after each clip. Ten healthy subjects participated in the experiment and achieved a high average online accuracy of 91.5 <inline-formula><tex-math notation=\"LaTeX\">$\\pm$</tex-math></inline-formula> 6.34 percent. The experimental results demonstrated that the subjects emotions had been sufficiently evoked and efficiently recognized by our system. Clinically, patients with disorder of consciousness (DOC), such as coma, vegetative state, minimally conscious state and emergence minimally conscious state, suffer from motor impairment and generally cannot provide adequate emotion expressions. Consequently, doctors have difficulty in detecting the emotional states of these patients. Therefore, we applied our emotion recognition BCI system to patients with DOC. Eight DOC patients participated in our experiment, and three of them achieved significant online accuracy. The experimental results show that the proposed BCI system could be a promising tool to detect the emotional states of patients with DOC.",
      "year": "2019",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Haiyun Huang et al.",
      "keywords": "Brain\u2013computer interface; Electroencephalography; Minimally conscious state; Persistent vegetative state; Consciousness; Psychology; Interface (matter); Emotion recognition; CLIPS; Coma (optics); Motor imagery; Cognitive psychology; Speech recognition; Computer science; Artificial intelligence; Audiology; Neuroscience; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taffc.2019.2901456",
      "cited_by_count": 167,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312251513",
      "doi": "10.1109/access.2022.3217217",
      "title": "A Deep Learning Approach Based on Explainable Artificial Intelligence for Skin Lesion Classification",
      "abstract": "The skin lesion types result in delayed diagnosis due to high similarity in early stages of the skin cancer. In this regard, deep learning algorithms are well-recognized solutions; however, these black box approaches result in lack of trust as dermatologists are unable to interpret and validate the decisions made by the models. In this paper, an explainable artificial intelligence (XAI) based skin lesion classification system is proposed to improve the skin lesion classification accuracy. This will help the dermatologists to make rational diagnosis in the early stages of skin cancer. The proposed XAI model is validated using International Skin Imaging Collaboration (ISIC) 2019 dataset. The developed model correctly identifies the eight types of skin lesions (dermatofibroma, squamous cell carcinoma, benign keratosis, melanocytic nevus, vascular lesion, actinic keratosis, basal cell carcinoma and melanoma) with classification accuracy, precision, recall and F1 score as 94.47&#x0025;, 93.57&#x0025;, 94.01&#x0025;, and 94.45&#x0025; respectively. These predictions are further analyzed using the local interpretable model-agnostic explanations (LIME) framework to generate visual explanations that match a prior belief and general explanation best practices. The explainability integrated within our model will enhance its applicability in real clinical practice.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Natasha Nigar et al.",
      "keywords": "Seborrheic keratosis; Actinic keratosis; Skin cancer; Basal cell carcinoma; Dermatofibroma; Computer science; Lesion; Artificial intelligence; Skin lesion; Dermatology; Basal cell; Precision and recall; Medicine; Pattern recognition (psychology); Cancer; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3217217",
      "cited_by_count": 125,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W1991370230",
      "doi": "10.1109/tmi.2013.2276943",
      "title": "Evaluation and Comparison of Current Fetal Ultrasound Image Segmentation Methods for Biometric Measurements: A Grand Challenge",
      "abstract": "This paper presents the evaluation results of the methods submitted to Challenge US: Biometric Measurements from Fetal Ultrasound Images, a segmentation challenge held at the IEEE International Symposium on Biomedical Imaging 2012. The challenge was set to compare and evaluate current fetal ultrasound image segmentation methods. It consisted of automatically segmenting fetal anatomical structures to measure standard obstetric biometric parameters, from 2D fetal ultrasound images taken on fetuses at different gestational ages (21 weeks, 28 weeks, and 33 weeks) and with varying image quality to reflect data encountered in real clinical environments. Four independent sub-challenges were proposed, according to the objects of interest measured in clinical practice: abdomen, head, femur, and whole fetus. Five teams participated in the head sub-challenge and two teams in the femur sub-challenge, including one team who tackled both. Nobody attempted the abdomen and whole fetus sub-challenges. The challenge goals were two-fold and the participants were asked to submit the segmentation results as well as the measurements derived from the segmented objects. Extensive quantitative (region-based, distance-based, and Bland-Altman measurements) and qualitative evaluation was performed to compare the results from a representative selection of current methods submitted to the challenge. Several experts (three for the head sub-challenge and two for the femur sub-challenge), with different degrees of expertise, manually delineated the objects of interest to define the ground truth used within the evaluation framework. For the head sub-challenge, several groups produced results that could be potentially used in clinical settings, with comparable performance to manual delineations. The femur sub-challenge had inferior performance to the head sub-challenge due to the fact that it is a harder segmentation problem and that the techniques presented relied more on the femur's appearance.",
      "year": "2013",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Sylvia Rueda et al.",
      "keywords": "Fetal head; Segmentation; Ground truth; Computer science; Biometrics; Artificial intelligence; Ultrasound; Computer vision; Image segmentation; Medical imaging; 3D ultrasound; Medical physics; Medicine; Radiology; Fetus; Pregnancy",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2013.2276943",
      "cited_by_count": 184,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385819962",
      "doi": "10.1109/access.2023.3304628",
      "title": "A Hybrid Dependable Deep Feature Extraction and Ensemble-Based Machine Learning Approach for Breast Cancer Detection",
      "abstract": "Breast cancer is a prevalent and life-threatening disease that requires effective detection and diagnosis methods to improve patient outcomes. Deep learning (DL) and machine learning (ML) techniques have emerged as powerful tools in breast cancer detection, offering benefits such as improved accuracy and efficiency. However, existing methods have scalability and performance limitations, emphasizing the need for further research. In this paper, we propose a hybrid dependable breast cancer detection approach that combines the power of DL using a pre-trained ResNet50V2 model and ensemble-based ML methods. The integration of DL enables the approach to learn and extract hidden patterns from complex breast cancer images, while ML algorithms contribute interpretability and generalization capabilities. We conducted extensive experiments using a breast histopathology image-based publicly available Invasive Ductal Carcinoma (IDC) dataset comprising samples of different sizes. The results obtained from our rigorous experiments provide compelling evidence for our hybrid model&#x2019;s robustness and high performance. We achieved a higher accuracy rate of 95&#x0025;, precision of 94.86&#x0025;, recall of 94.32&#x0025;, and F1 score of 94.57&#x0025; compared to state-of-the-art models. We also identified Light Boosting Classifier (LGB) as the most suitable ML model in conjunction with the ResNet50V2 architecture. The results of this research offer significant contributions to breast cancer detection through an innovative approach, comprehensive performance analysis, and dependable assessment. Moreover, it has the potential to assist medical professionals in making informed decisions, improving patient care, and enhancing outcomes for breast cancer patients.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Selina Sharmin et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Breast cancer; Interpretability; Boosting (machine learning); Feature extraction; Scalability; Support vector machine; Mammography; Deep learning; Robustness (evolution); Cancer; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3304628",
      "cited_by_count": 122,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2948909602",
      "doi": "10.1109/access.2019.2920708",
      "title": "A Neural Named Entity Recognition and Multi-Type Normalization Tool for Biomedical Text Mining",
      "abstract": "The amount of biomedical literature is vast and growing quickly, and accurate text mining techniques could help researchers to efficiently extract useful information from the literature. However, existing named entity recognition models used by text mining tools such as tmTool and ezTag are not effective enough, and cannot accurately discover new entities. Also, the traditional text mining tools do not consider overlapping entities, which are frequently observed in multi-type named entity recognition results. We propose a neural biomedical named entity recognition and multi-type normalization tool called BERN. The BERN uses high-performance BioBERT named entity recognition models which recognize known entities and discover new entities. Also, probability-based decision rules are developed to identify the types of overlapping entities. Furthermore, various named entity normalization models are integrated into BERN for assigning a distinct identifier to each recognized entity. The BERN provides a Web service for tagging entities in PubMed articles or raw text. Researchers can use the BERN Web service for their text mining tasks, such as new named entity discovery, information retrieval, question answering, and relation extraction. The application programming interfaces and demonstrations of BERN are publicly available at https://bern.korea.ac.kr.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Donghyeon Kim et al.",
      "keywords": "Computer science; Named-entity recognition; Identifier; Information retrieval; Biomedical text mining; Normalization (sociology); Named entity; Information extraction; Artificial intelligence; Relationship extraction; Text mining; Natural language processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2920708",
      "cited_by_count": 131,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285248702",
      "doi": "10.1109/tse.2022.3174092",
      "title": "SEGRESS: Software Engineering Guidelines for REporting Secondary Studies",
      "abstract": "Context : Several tertiary studies have criticized the reporting of software engineering secondary studies. Objective : Our objective is to identify guidelines for reporting software engineering (SE) secondary studies which would address problems observed in the reporting of software engineering systematic reviews (SRs). Method : We review the criticisms of SE secondary studies and identify the major areas of concern. We assess the PRISMA 2020 (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) statement as a possible solution to the need for SR reporting guidelines, based on its status as the reporting guideline recommended by the Cochrane Collaboration whose SR guidelines were a major input to the guidelines developed for SE. We report its advantages and limitations in the context of SE secondary studies. We also assess reporting guidelines for mapping studies and qualitative reviews, and compare their structure and content with that of PRISMA 2020. Results : Previous tertiary studies confirm that reports of secondary studies are of variable quality. However, ad hoc recommendations that amend reporting standards may result in unnecessary duplication of text. We confirm that the PRISMA 2020 statement addresses SE reporting problems, but is mainly oriented to quantitative reviews, mixed-methods reviews and meta-analyses. However, we show that the PRISMA 2020 item definitions can be extended to cover the information needed to report mapping studies and qualitative reviews. Conclusions : In this paper and its Supplementary Material, we present and illustrate an integrated set of guidelines called SEGRESS (Software Engineering Guidelines for REporting Secondary Studies), suitable for quantitative systematic reviews (building upon PRISMA 2020), mapping studies (PRISMA-ScR), and qualitative reviews (ENTREQ and RAMESES), that addresses reporting problems found in current SE SRs.",
      "year": "2022",
      "journal": "IEEE Transactions on Software Engineering",
      "authors": "Barbara Kitchenham et al.",
      "keywords": "Context (archaeology); Systematic review; Computer science; MEDLINE; Library science; Information retrieval; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tse.2022.3174092",
      "cited_by_count": 121,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2036373650",
      "doi": "10.1109/jproc.2014.2322103",
      "title": "Trustworthiness of Medical Devices and Body Area Networks",
      "abstract": "Implantable and wearable medical devices (IWMDs) are commonly used for diagnosing, monitoring, and treating various medical conditions. A general trend in these medical devices is toward increased functional complexity, software programmability, and connectivity to body area networks (BANs). However, as IWMDs become more \"intelligent,\" they also become less trustworthy-less reliable and more prone to attacks. Various shortcomings-hardware failures, software errors, wireless attacks, malware and software exploits, and side-channel attacks-could undermine the trustworthiness of IWMDs and BANs. While these concerns have been recognized for some time, recent demonstrations of security attacks on commercial products, e.g., pacemakers and insulin pumps, have elevated medical device security from the realm of theoretical possibility to an immediate concern. The trustworthiness of IWMDs must be addressed aggressively and proactively due to the potential for catastrophic consequences. Conventional fault tolerance and information security solutions, e.g., redundancy and cryptography, that have been employed in general-purpose and embedded computing systems cannot be applied to many IWMDs due to their extreme size and power constraints and unique usage models. While several recent efforts address defense of IWMDs against specific security attacks, a holistic strategy that considers all concerns and types of threats is required. This paper discusses trustworthiness concerns in IWMDs and BANs through a comprehensive identification and analysis of potential threats and, for each threat, provides a discussion of the merits and inadequacies of current solutions.",
      "year": "2014",
      "journal": "Proceedings of the IEEE",
      "authors": "Meng Zhang et al.",
      "keywords": "Computer security; Computer science; Exploit; Malware; Trustworthiness; Identification (biology); Wearable computer; Redundancy (engineering); Wearable technology; Software; Risk analysis (engineering); Cryptography; Threat model; Internet privacy; Embedded system; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2014.2322103",
      "cited_by_count": 132,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3083483148",
      "doi": "10.1109/access.2020.3015757",
      "title": "Clinical Implication of Machine Learning in Predicting the Occurrence of Cardiovascular Disease Using Big Data (Nationwide Cohort Data in Korea)",
      "abstract": "Machine learning (ML) and large-scale big data are key factors in developing an accurate prediction model for cardiovascular disease (CVD). Although the CVD risk often depends on the race and ethnicity, most previous studies considered only US or European populations for the CVD risk prediction. In this work, to complement previous researches, we analyzed the Korean National Health Insurance Service-National Health Sample Cohort (KNHSC) data and studied the characteristics of ML and big data for predicting the CVD risk. More specifically, we assessed the effectiveness of various ML methods in predicting the 2-year and 10-year risk of CVD such as atrial fibrillation, coronary artery disease, heart failure, and strokes. To develop prediction models, we considered the usual medical examination data, questionnaire survey results, comorbidities, and past medication information available in the KNHSC data. We developed various ML-based prediction models using logistic regression, deep neural networks, random forests, and LightGBM, and validated them using various metrics such as receiver operating characteristic curves, precision-recall curves, sensitivity, specificity, and F1 score. Experimental results showed that all ML models outperformed the baseline method derived from the ACC/AHA guidelines for estimating the 10-year CVD risk, demonstrating the usefulness of ML methods. In addition, in our analysis, whether we included the past medication information as a feature or not, the prediction accuracy of all ML models was comparable to each other. Since the use of medications by the physicians provided important information on the occurrence of diseases, when we included it as a feature, all prediction models achieved a slightly higher prediction accuracy.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Gihun Joo et al.",
      "keywords": "Random forest; Machine learning; Logistic regression; Medicine; Receiver operating characteristic; Artificial intelligence; Big data; Computer science; Cohort; Disease; Atrial fibrillation; Predictive modelling; Data mining; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3015757",
      "cited_by_count": 69,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4288062238",
      "doi": "10.1109/access.2022.3193938",
      "title": "AI-Based Personalized E-Learning Systems: Issues, Challenges, and Solutions",
      "abstract": "A personalized e-learning system is effective in imparting enhanced learning to its users. As compared to a conventional e-learning system, which provides similar contents to each learner, a personalized learning system provides specific learning contents and assessments to the learners. Personalization is based on Artificial Intelligence (AI) based techniques in which appropriate contents for each learner are determined using the level of comprehension of the learner and the preferred modes of learning. This paper presents requirements and challenges for a personalized e-learning system. The paper is focused in elaborating four research questions, which are related to identifying key factors of personalized education, elaborating on state of the art research in the domain, utilizing benefits of AI in personalized education, and determining future research directions. The paper utilizes an in-depth survey of current research papers in answering these questions. It provides a comprehensive review of existing solutions in offering personalized e-learning solutions. It also elaborates on different learning models and learning theories, which are significant in providing personalized education. It proposes an efficient framework, which can offer personalized e-learning to each learner. The proposed framework includes five modules i.e Data Module, Adaptive Learning Module, Adaptable Learning Module, Recommender Module, Content and Assessment Delivery Module. Our work also identifies significant directions for future research. The paper is beneficial for academicians and researchers in understanding the requirements of such a system, comprehending its methodologies, and identifying challenges which are needed to be addressed.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mir Murtaza et al.",
      "keywords": "Personalization; Personalized learning; Computer science; Key (lock); Comprehension; E learning; Artificial intelligence; Knowledge management; Data science; World Wide Web; Open learning; Teaching method; Cooperative learning; The Internet; Mathematics education; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3193938",
      "cited_by_count": 286,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3160122175",
      "doi": "10.1109/taslp.2021.3078364",
      "title": "The Detection of Parkinson's Disease From Speech Using Voice Source Information",
      "abstract": "Developing automatic methods to detect Parkinson's disease (PD) from speech has attracted increasing interest as these techniques can potentially be used in telemonitoring health applications. This article studies the utilization of voice source information in the detection of PD using two classifier architectures: traditional pipeline approach and end-to-end approach. The former consists of feature extraction and classifier stages. In feature extraction, the baseline acoustic features-consisting of articulation, phonation, and prosody features-were computed and voice source information was extracted using glottal features that were estimated by iterative adaptive inverse filtering (IAIF) and quasi-closed phase (QCP) glottal inverse filtering methods. Support vector machine classifiers were developed utilizing the baseline and glottal features extracted from every speech utterance and the corresponding healthy/PD labels. The end-to-end approach uses deep learning models which were trained using both raw speech waveforms and raw voice source waveforms. In the latter, two glottal inverse filtering methods (IAIF and QCP) and zero frequency filtering method were utilized. The deep learning architecture consists of a combination of convolutional layers followed by a multilayer perceptron. Experiments were performed using PC-GITA speech database. From the traditional pipeline systems, the highest classification accuracy (67.93%) was given by combination of baseline and QCP-based glottal features. From the end-to-end-systems, the highest accuracy (68.56%) was given by the system trained using QCP-based glottal flow signals. Even though classification accuracies were modest for all systems, the study is encouraging as the extraction of voice source information was found to be most effective in both approaches.",
      "year": "2021",
      "journal": "IEEE/ACM Transactions on Audio Speech and Language Processing",
      "authors": "N. P. Narendra et al.",
      "keywords": "Computer science; Speech recognition; Prosody; Phonation; Feature extraction; Classifier (UML); Artificial intelligence; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taslp.2021.3078364",
      "cited_by_count": 109,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2950879898",
      "doi": "10.1109/access.2019.2923270",
      "title": "Blending Big Data Analytics: Review on Challenges and a Recent Study",
      "abstract": "With the collection of massive amounts of data every day, big data analytics has emerged as an important trend for many organizations. These collected data can contain important information that may be key to solving wide-ranging problems, such as cyber security, marketing, healthcare, and fraud. To analyze their large volumes of data for business analyses and decisions, large companies, such as Facebook and Google, adopt analytics. Such analyses and decisions impact existing and future technology. In this paper, we explore how big data analytics is utilized as a technique for solving problems of complex and unstructured data using such technologies as Hadoop, Spark, and MapReduce. We also discuss the data challenges introduced by big data according to the literature, including its six V's. Moreover, we investigate case studies of big data analytics on various techniques of such analytics, namely, text, voice, video, and network analytics. We conclude that big data analytics can bring positive changes in many fields, such as education, military, healthcare, politics, business, agriculture, banking, and marketing, in the future. \u00a9 2013 IEEE.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Fairuz Amalina et al.",
      "keywords": "Big data; Data science; SPARK (programming language); Analytics; Computer science; Business analytics; Web analytics; Business intelligence; Data analysis; Software analytics; World Wide Web; Knowledge management; Data mining; Business; Business model; Software; Web intelligence; Software development; Business analysis; The Internet; Marketing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2923270",
      "cited_by_count": 124,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4214677181",
      "doi": "10.1109/access.2022.3154776",
      "title": "Personas for Artificial Intelligence (AI) an Open Source Toolbox",
      "abstract": "Personas have successfully supported the development of classical user interfaces for more than two decades by mapping users&#x2019; mental models to specific contexts. The rapid proliferation of Artificial Intelligence (AI) applications makes it necessary to create new approaches for future human-AI interfaces. Human-AI interfaces differ from classical human-computer interfaces in many ways, such as gaining some degree of human-like cognitive, self-executing, and self-adaptive capabilities and autonomy, and generating unexpected outputs that require non-deterministic interactions. Moreover, the most successful AI approaches are so-called &#x201C;black box&#x201D; systems, where the technology and the machine learning process are opaque to the user and the AI output is far not intuitive. This work shows how the personas method can be adapted to support the development of human-centered AI applications, and we demonstrate this on the example of a medical context. This work is - to our knowledge - the first to provide personas for AI using an openly available <italic>Personas for AI toolbox</italic>. The toolbox contains guidelines and material supporting persona development for AI as well as templates and pictures for persona visualisation. It is ready to use and freely available to the international research and development community. Additionally, an example from medical AI is provided as a best practice use case. This work is intended to help foster the development of novel human-AI interfaces that will be urgently needed in the near future.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Andreas Holzinger et al.",
      "keywords": "Persona; Computer science; Toolbox; Human\u2013computer interaction; Artificial intelligence; Context (archaeology); Human intelligence; User interface; Process (computing); Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3154776",
      "cited_by_count": 82,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2986934761",
      "doi": "10.1109/jproc.2019.2949575",
      "title": "Deep-Learning-Based Image Reconstruction and Enhancement in Optical Microscopy",
      "abstract": "In recent years, deep learning has been shown to be one of the leading machine learning techniques for a wide variety of inference tasks. In addition to its mainstream applications, such as classification, it has created transformative opportunities for image reconstruction and enhancement in optical microscopy. Some of these emerging applications of deep learning range from image transformations between microscopic imaging systems to adding new capabilities to existing imaging techniques, as well as solving various inverse problems based on microscopy image data. Deep learning is helping us move toward data-driven instrument designs that blend microscopy and computing to achieve what neither can do alone. This article provides an overview of some of the recent work using deep neural networks to advance computational microscopy and sensing systems, also covering their current and future biomedical applications.",
      "year": "2019",
      "journal": "Proceedings of the IEEE",
      "authors": "Kevin de Haan et al.",
      "keywords": "Deep learning; Artificial intelligence; Transformative learning; Computer science; Microscopy; Inference; Artificial neural network; Deep neural networks; Machine learning; Optics; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2019.2949575",
      "cited_by_count": 134,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3192474593",
      "doi": "10.1109/tnsre.2021.3103210",
      "title": "An Effective Dual Self-Attention Residual Network for Seizure Prediction",
      "abstract": "As one of the most challenging data analysis tasks in chronic brain diseases, epileptic seizure prediction has attracted extensive attention from many researchers. Seizure prediction, can greatly improve patients' quality of life in many ways, such as preventing accidents and reducing harm that may occur during epileptic seizures. This work aims to develop a general method for predicting seizures in specific patients through exploring the time-frequency correlation of features obtained from multi-channel EEG signals. We convert the original EEG signals into spectrograms that represent time-frequency characteristics by applying short-time Fourier transform (STFT) to the EEG signals. For the first time, we propose a dual self-attention residual network (RDANet) that combines a spectrum attention module integrating local features with global features, with a channel attention module mining the interdependence between channel mappings to achieve better forecasting performance. Our proposed approach achieved a sensitivity of 89.33%, a specificity of 93.02%, an AUC of 91.26% and an accuracy of 92.07% on 13 patients from the public CHB-MIT scalp EEG dataset. Our experiments show that different EEG signal prediction segment lengths are an important factor affecting prediction performance. Our proposed method is competitive and achieves good robustness without patient-specific engineering.",
      "year": "2021",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Xinwu Yang et al.",
      "keywords": "Electroencephalography; Computer science; Short-time Fourier transform; Robustness (evolution); Residual; Artificial intelligence; Spectrogram; Pattern recognition (psychology); Time\u2013frequency analysis; Epilepsy; Sensitivity (control systems); Machine learning; Fourier transform; Algorithm; Psychology; Mathematics; Fourier analysis; Neuroscience; Electronic engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2021.3103210",
      "cited_by_count": 134,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380143013",
      "doi": "10.1109/access.2023.3281484",
      "title": "Effective Feature Engineering Technique for Heart Disease Prediction With Machine Learning",
      "abstract": "Heart failure is a chronic disease affecting millions worldwide. An efficient machine learning-based technique is needed to predict heart failure health status early and take necessary actions to overcome this worldwide issue. While medication is the primary treatment, exercise is increasingly recognized as an effective adjunct therapy in managing heart failure. In this study, we developed an approach to enhance heart failure detection based on patient health parameter data involving machine learning. Our study helps improve heart failure detection at its early stages to save patients&#x2019; lives. We employed nine machine learning-based algorithms for comparison and proposed a novel Principal Component Heart Failure (PCHF) feature engineering technique to select the most prominent features to enhance performance. We optimized the proposed PCHF mechanism by creating a new feature set as an innovation to achieve the highest accuracy scores. The newly created dataset is based on the eight best-fit features. We conducted extensive experiments to assess the efficiency of several algorithms. The proposed decision tree method outperformed the applied machine learning models and other state-of-the-art studies, achieving a high accuracy score of 100&#x0025;, which is admirable. All applied methods were successfully validated using the cross-validation technique. Our proposed research study has significant scientific contributions to the medical community.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Azam Mehmood Qadri et al.",
      "keywords": "Computer science; Feature engineering; Machine learning; Feature (linguistics); Artificial intelligence; Deep learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3281484",
      "cited_by_count": 83,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3106819668",
      "doi": "10.1109/access.2020.3040486",
      "title": "3D CNN Design for the Classification of Alzheimer\u2019s Disease Using Brain MRI and PET",
      "abstract": "Attempt to diagnose Alzheimer's disease (AD) using imaging modalities is one of the scopes of deep learning. While considering the theoretical background from past studies, we are trying to identify convolutional neural network (CNN) behaviors moving from 2D to 3D architecture. This study aims to explore the output from a variety of CNN models implemented in the MRI or/and PET classification tasks for AD prediction while trying to summarize its characteristics with a variety of parameters that are tuned and changed. There are many architectures available; however, we are testing a basic architecture with a change in the reception area based on the convolutional layer's kernel size and its strides. The architecture has been categorized as converging, diverging, or equivalent if the filter kernel size is unchanged. This investigation studies a simple encoder based CNN with a sequential flow of features from low-level to high-level feature extraction. The idea is to present a diverging reception area by increasing the filter size and stride from a lower to a higher level. As a result, the feature redundancy is reduced and the trivial features keep on diminishing. The proposed architecture is referred to as `divNet', and several experiments were performed to determine how effective the architecture is in terms of the consumed memory, the number of parameters, running time, classification error, and the generalization error. This study surveys several related experiments by changing the hyper-parameters setting, the architecture selection based on the depth and area of the reception feature, and the data size.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Bijen Khagi et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Pattern recognition (psychology); Deep learning; Feature extraction; Feature selection; Feature (linguistics); Redundancy (engineering); Kernel (algebra); Contextual image classification; Machine learning; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3040486",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3014001067",
      "doi": "10.1109/access.2020.2983186",
      "title": "A Survey for Cervical Cytopathology Image Analysis Using Deep Learning",
      "abstract": "Cervical cancer is one of the most common and deadliest cancers among women. Despite that, this cancer is entirely treatable if it is detected at a precancerous stage. Pap smear test is the most extensively performed screening method for early detection of cervical cancer. However, this hand-operated screening approach suffers from a high false-positive result because of human errors. To improve the accuracy and manual screening practice, computer-aided diagnosis methods based on deep learning is developed widely to segment and classify the cervical cytology images automatically. In this survey, we provide a comprehensive study of the state of the art approaches based on deep learning for the analysis of cervical cytology images. Firstly, we introduce deep learning and its simplified architectures that have been used in this field. Secondly, we discuss the publicly available cervical cytopathology datasets and evaluation metrics for segmentation and classification tasks. Then, a thorough review of the recent development of deep learning for the segmentation and classification of cervical cytology images is presented. Finally, we investigate the existing methodology along with the most suitable techniques for the analysis of pap smear cells.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Md Mamunur Rahaman et al.",
      "keywords": "Cytopathology; Deep learning; Cervical cancer; Artificial intelligence; Segmentation; Computer science; Cervical cancer screening; Image segmentation; Medicine; Pattern recognition (psychology); Cytology; Cancer; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2983186",
      "cited_by_count": 138,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2746891030",
      "doi": "10.1109/rbme.2017.2739801",
      "title": "Advances in Monte Carlo Simulation for Light Propagation in Tissue",
      "abstract": "Monte Carlo (MC) simulation for light propagation in tissue is the gold standard for studying the light propagation in biological tissue and has been used for years. Interaction of photons with a medium is simulated based on its optical properties. New simulation geometries, tissue-light interaction methods, and recording techniques recently have been designed. Applications, such as whole mouse body simulations for fluorescence imaging, eye modeling for blood vessel imaging, skin modeling for terahertz imaging, and human head modeling for sinus imaging, have emerged. Here, we review the technical advances and recent applications of MC simulation.",
      "year": "2017",
      "journal": "IEEE Reviews in Biomedical Engineering",
      "authors": "Vijitha Periyasamy et al.",
      "keywords": "Monte Carlo method; Biological tissue; Photon; Terahertz radiation; Computer science; Optics; Biomedical engineering; Medical physics; Physics; Engineering",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/rbme.2017.2739801",
      "cited_by_count": 93,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3089168043",
      "doi": "10.1109/ojemb.2020.3026468",
      "title": "SARS-CoV-2 Detection From Voice",
      "abstract": "Automated voice-based detection of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) could facilitate the screening for COVID19. A dataset of cellular phone recordings from 88 subjects was recently collected. The dataset included vocal utterances, speech and coughs that were self-recorded by the subjects in either hospitals or isolation sites. All subjects underwent nasopharyngeal swabbing at the time of recording and were labelled as SARS-CoV-2 positives or negative controls. The present study harnessed deep machine learning and speech processing to detect the SARS-CoV-2 positives. A three-stage architecture was implemented. A self-supervised attention-based transformer generated embeddings from the audio inputs. Recurrent neural networks were used to produce specialized sub-models for the SARS-CoV-2 classification. An ensemble stacking fused the predictions of the sub-models. Pre-training, bootstrapping and regularization techniques were used to prevent overfitting. A recall of 78% and a probability of false alarm (PFA) of 41% were measured on a test set of 57 recording sessions. A leave-one-speaker-out cross validation on 292 recording sessions yielded a recall of 78% and a PFA of 30%. These preliminary results imply a feasibility for COVID19 screening using voice.",
      "year": "2020",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Gadi Pinkas et al.",
      "keywords": "Computer science; Speech recognition; False positive paradox; Phone; ALARM; Artificial intelligence; Overfitting; Test set; Machine learning; Pattern recognition (psychology); Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2020.3026468",
      "cited_by_count": 93,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4282918440",
      "doi": "10.1109/jbhi.2022.3181205",
      "title": "5G in Healthcare: From COVID-19 to Future Challenges",
      "abstract": "Worldwide up to May 2022 there have been 515 million cases of COVID-19 infection and over 6 million deaths. The World Health Organization estimated that 115,000 healthcare workers died from COVID-19 from January 2020 to May 2021. This toll on human lives prompted this review on 5G based networking primarily on major components of healthcare delivery: diagnosis, patient monitoring, contact tracing, diagnostic imaging tests, vaccines distribution, emergency medical services, telesurgery and robot-assisted tele-ultrasound. The positive impact of 5G as core technology for COVID-19 applications enabled exchange of huge data sets in fangcang (cabin) hospitals and real-time contact tracing, while the low latency enhanced robot-assisted tele-ultrasound, and telementoring during ophthalmic surgery. In other instances, 5G provided a supportive technology for applications related to COVID-19, e.g., patient monitoring. The feasibility of 5G telesurgery was proven, albeit by a few studies on real patients, in very low samples size in most instances. The important future applications of 5G in healthcare include surveillance of elderly people, the immunosuppressed, and nano- oncology for Internet of Nano Things (IoNT). Issues remain and these require resolution before routine clinical adoption. These include infrastructure and coverage; health risks; security and privacy protection of patients' data; 5G implementation with artificial intelligence, blockchain, and IoT; validation, patient acceptance and training of end-users on these technologies.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Andrea Moglia et al.",
      "keywords": "Telemedicine; Health care; Coronavirus disease 2019 (COVID-19); Medical emergency; Medicine; Telehealth; Contact tracing; Pathology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/jbhi.2022.3181205",
      "cited_by_count": 93,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3138118097",
      "doi": "10.1109/ojemb.2021.3066097",
      "title": "Deep Learning Classification of Systemic Sclerosis Skin Using the MobileNetV2 Model",
      "abstract": "<i>Goal:</i> Systemic sclerosis (SSc) is a rare autoimmune, systemic disease with prominent fibrosis of skin and internal organs. Early diagnosis of the disease is crucial for designing effective therapy and management plans. Machine learning algorithms, especially deep learning, have been found to be greatly useful in biology, medicine, healthcare, and biomedical applications, in the areas of medical image processing and speech recognition. However, the need for a large training data set and the requirement for a graphics processing unit (GPU) have hindered the wide application of machine learning algorithms as a diagnostic tool in resource-constrained environments (e.g., clinics). <i>Methods:</i> In this paper, we propose a novel mobile deep learning network for the characterization of SSc skin. The proposed network architecture consists of the UNet, a dense connectivity convolutional neural network (CNN) with added classifier layers that when combined with limited training data, yields better image segmentation and more accurate classification, and a mobile training module. In addition, to improve the computational efficiency and diagnostic accuracy, the highly efficient training model called \"MobileNetV2,\" which is designed for mobile and embedded applications, was used to train the network. <i>Results:</i> The proposed network was implemented using a standard laptop (2.5 GHz Intel Core i7). After fine tuning, our results showed the proposed network reached 100% accuracy on the training image set, 96.8% accuracy on the validation image set, and 95.2% on the testing image set. The training time was less than 5 hours. We also analyzed the same normal vs SSc skin image sets using the CNN using the same laptop. The CNN reached 100% accuracy on the training image set, 87.7% accuracy on the validation image set, and 82.9% on the testing image set. Additionally, it took more than 14 hours to train the CNN architecture. We also utilized the MobileNetV2 model to analyze an additional dataset of images and classified them as normal, early (mid and moderate) SSc or late (severe) SSc skin images. The network reached 100% accuracy on the training image set, 97.2% on the validation set, and 94.8% on the testing image set. Using the same normal, early and late phase SSc skin images, the CNN reached 100% accuracy on the training image set, 87.7% accuracy on the validation image set, and 82.9% on the testing image set. These results indicated that the MobileNetV2 architecture is more accurate and efficient compared to the CNN to classify normal, early and late phase SSc skin images. <i>Conclusions:</i> Our preliminary study, intended to show the efficacy of the proposed network architecture, holds promise in the characterization of SSc. We believe that the proposed network architecture could easily be implemented in a clinical setting, providing a simple, inexpensive, and accurate screening tool for SSc.",
      "year": "2021",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Metin Akay et al.",
      "keywords": "Medicine; Dermatology; Artificial intelligence; Deep learning; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2021.3066097",
      "cited_by_count": 92,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3083914698",
      "doi": "10.1109/access.2020.3022818",
      "title": "Latest Research Trends in Gait Analysis Using Wearable Sensors and Machine Learning: A Systematic Review",
      "abstract": "Gait is the locomotion attained through the movement of limbs and gait analysis examines the patterns (normal/abnormal) depending on the gait cycle. It contributes to the development of various applications in the medical, security, sports, and fitness domains to improve the overall outcome. Among many available technologies, two emerging technologies that play a central role in modern day gait analysis are: A) wearable sensors which provide a convenient, efficient, and inexpensive way to collect data and B) Machine Learning Methods (MLMs) which enable high accuracy gait feature extraction for analysis. Given their prominent roles, this paper presents a review of the latest trends in gait analysis using wearable sensors and Machine Learning (ML). It explores the recent papers along with the publication details and key parameters such as sampling rates, MLMs, wearable sensors, number of sensors, and their locations. Furthermore, the paper provides recommendations for selecting a MLM, wearable sensor and its location for a specific application. Finally, it suggests some future directions for gait analysis and its applications.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Abdul Saboor et al.",
      "keywords": "Wearable computer; Gait; Computer science; Gait analysis; Key (lock); Wearable technology; Artificial intelligence; Gait cycle; Machine learning; Feature extraction; Human\u2013computer interaction; Physical medicine and rehabilitation; Embedded system; Computer security; Medicine; Kinematics",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3022818",
      "cited_by_count": 136,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3119307757",
      "doi": "10.1109/jtehm.2021.3050925",
      "title": "A Deep Convolutional Neural Network Method to Detect Seizures and Characteristic Frequencies Using Epileptic Electroencephalogram (EEG) Data",
      "abstract": "Thus our developed deep convolutional neural network models are useful to detect seizures and characteristic frequencies using EEG data collected from the patients and this model could be clinically applicable for the automated seizures detection.",
      "year": "2021",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Md. Rashed-Al-Mahfuz et al.",
      "keywords": "Convolutional neural network; Artificial intelligence; Electroencephalography; Pattern recognition (psychology); Computer science; Deep learning; Classifier (UML); Feature extraction; Artificial neural network; Time domain; Epileptic seizure; Epilepsy; Frequency domain; Speech recognition; Computer vision; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2021.3050925",
      "cited_by_count": 126,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3014253013",
      "doi": "10.1109/access.2020.2985646",
      "title": "An Optimally Configured and Improved Deep Belief Network (OCI-DBN) Approach for Heart Disease Prediction Based on Ruzzo\u2013Tompa and Stacked Genetic Algorithm",
      "abstract": "A rapid increase in heart disease has occurred in recent years, which might be the result of unhealthy food, mental stress, genetic issues, and a sedentary lifestyle. There are many advanced automated diagnosis systems for heart disease prediction proposed in recent studies, but most of them focus only on feature preprocessing, some focus on feature selection, and some only on improving the predictive accuracy. In this study, we focus on every aspect that may have an influence on the final performance of the system, i.e., to avoid overfitting and underfitting problems or to solve network configuration issues and optimization problems. We introduce an optimally configured and improved deep belief network named OCI-DBN to solve these problems and improve the performance of the system. We used the Ruzzo-Tompa approach to remove those features that are not contributing enough to improve system performance. To find an optimal network configuration, we proposed a stacked genetic algorithm that stacks two genetic algorithms to give an optimally configured DBN. An analysis of a RBM and DBN trained is performed to give an insight how the system works. Six metrics were used to evaluate the proposed method, including accuracy, sensitivity, specificity, precision, F1 score, and Matthew's correlation coefficient. The experimental results are compared with other state-of-the-art methods, and OCI-DBN shows a better performance. The validation results assure that the proposed method can provide reliable recommendations to heart disease patients by improving the accuracy of heart disease predictions by up to 94.61%.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Syed Arslan Ali et al.",
      "keywords": "Deep belief network; Overfitting; Computer science; Artificial intelligence; Genetic algorithm; Machine learning; Preprocessor; Focus (optics); Feature selection; Feature (linguistics); Deep learning; Data mining; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2985646",
      "cited_by_count": 101,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3121612669",
      "doi": "10.1109/access.2021.3052477",
      "title": "DiaNet: A Deep Learning Based Architecture to Diagnose Diabetes Using Retinal Images Only",
      "abstract": "&lt;p&gt;Diabetes is one of the leading fatal diseases globally, putting a huge burden on the global healthcare system. Early diagnosis of diabetes is hence, of utmost importance and could save many lives. However, current techniques to determine whether a person has diabetes or has the risk of developing diabetes are primarily reliant upon clinical biomarkers. In this article, we propose a novel deep learning architecture to predict if a person has diabetes or not from a photograph of his/her retina. Using a relatively small-sized dataset, we develop a multi-stage convolutional neural network (CNN)-based model DiaNet that can reach an accuracy level of over 84% on this task, and in doing so, successfully identifies the regions on the retina images that contribute to its decision-making process, as corroborated by the medical experts in the field. This is the first study that highlights the distinguishing capability of the retinal images for diabetes patients in the Qatari population to the best of our knowledge. Comparing the performance of DiaNet against the existing clinical data-based machine learning models, we conclude that the retinal images contain sufficient information to distinguish the Qatari diabetes cohort from the control group. In addition, our study reveals that retinal images may contain prognosis markers for diabetes and other comorbidities like hypertension and ischemic heart disease. The results led us to believe that the inclusion of retinal images into the clinical setup for the diagnosis of diabetes is warranted in the near future.&lt;/p&gt;&lt;h2&gt;Other Information&lt;/h2&gt;&lt;p&gt;Published in: IEEE Access&lt;br&gt;License: &lt;a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\" target=\"_blank\"&gt;https://creativecommons.org/licenses/by/4.0/&lt;/a&gt;&lt;br&gt;See article on publisher's website: &lt;a href=\"https://dx.doi.org/10.1109/access.2021.3052477\" target=\"_blank\"&gt;https://dx.doi.org/10.1109/access.2021.3052477&lt;/a&gt;&lt;/p&gt;",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mohammad Tariqul Islam et al.",
      "keywords": "Diabetes mellitus; Computer science; Artificial intelligence; Convolutional neural network; Deep learning; Diabetic retinopathy; Population; Retinal; Disease; Medicine; Process (computing); Optometry; Machine learning; Ophthalmology; Pathology; Environmental health",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3052477",
      "cited_by_count": 74,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3188564437",
      "doi": "10.1109/access.2021.3100890",
      "title": "A Systematic Review of the Effects of Automatic Scoring and Automatic Feedback in Educational Settings",
      "abstract": "Automatic scoring and feedback tools have become critical components of online learning proliferation. These tools range from multiple-choice questions to grading essays using machine learning (ML). Learning environments such as massive open online courses (MOOCs) would not be possible without them. The usage of this mechanism has brought many exciting areas of study, from the design of questions to the ML grading tools' precision and accuracy. This paper analyzes the findings of 125 studies published in journals and proceedings between 2016 and 2020 on the usages of automatic scoring and feedback as a learning tool. This analysis gives an overview of the trends, challenges, and open questions in this research area. The results indicate that automatic scoring and feedback have many advantages. The most important benefits include enabling scaling the number of students without adding a proportional number of instructors, improving the student experience by reducing the time between submission grading and feedback, and removing bias in scoring. On the other hand, these technologies have some drawbacks. The main problem is creating a disincentive to develop innovative answers that do not match the expected one or have not been considered when preparing the problem. Another drawback is potentially training the student to answer the question instead of learning the concepts. With this, given the existence of a correct answer, such an answer could be leaked to the internet, making it easier for students to avoid solving the problem. Overall, each of these drawbacks presents an opportunity to look at ways to improve technologies to use these tools to provide a better learning experience to students. \u00a9 2013 IEEE.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Marcelo Guerra Hahn et al.",
      "keywords": "Grading (engineering); Computer science; The Internet; Artificial intelligence; Data science; Machine learning; Multimedia; World Wide Web",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2021.3100890",
      "cited_by_count": 78,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3044129898",
      "doi": "10.1109/access.2020.3010274",
      "title": "Anomalous Example Detection in Deep Learning: A Survey",
      "abstract": "Deep Learning (DL) is vulnerable to out-of-distribution and adversarial examples resulting in incorrect outputs. To make DL more robust, several posthoc (or runtime) anomaly detection techniques to detect (and discard) these anomalous samples have been proposed in the recent past. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection for DL based applications. We provide a taxonomy for existing techniques based on their underlying assumptions and adopted approaches. We discuss various techniques in each of the categories and provide the relative strengths and weaknesses of the approaches. Our goal in this survey is to provide an easier yet better understanding of the techniques belonging to different categories in which research has been done on this topic. Finally, we highlight the unsolved research challenges while applying anomaly detection techniques in DL systems and present some high-impact future research directions.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Saikiran Bulusu et al.",
      "keywords": "Anomaly detection; Computer science; Strengths and weaknesses; Adversarial system; Deep learning; Taxonomy (biology); Artificial intelligence; Data science; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3010274",
      "cited_by_count": 175,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3012214439",
      "doi": "10.1109/access.2020.2980290",
      "title": "Comparison Study of Radiomics and Deep Learning-Based Methods for Thyroid Nodules Classification Using Ultrasound Images",
      "abstract": "Thyroid nodules have a high prevalence and a small percentage is malignant. Many non-invasive methods have been developed with the help of the Internet of Things to improve the detection rate of malignant nodules. These methods can be roughly categorized into two classes: radiomics based and deep learning based approaches. In general, convolutional neural networks based deep learning methods have achieved promising performance in many medical image analysis and classification applications; however, no existing comparison has been done between radiomics based and deep learning based approaches. Therefore, in this paper, we aim to compare the performance of radiomics and deep learning based methods for the classification of thyroid nodules from ultrasound images. On one hand, we developed a radiomics based method, which consists of extracting high throughput 302-dimensional statistical features from pre-processed images. Then dimension reduction was performed using mutual information and linear discriminant analysis respectively to achieve the final classification. On the other hand, a deep learning based method was also developed and tested by pre-training a VGG16 model with fine-tuning. Ultrasound images including 3120 images (1841 benign nodules and 1393 malignant nodules) from 1040 cases were retrospectively collected. The dataset was divided into 80% training and 20% testing data. The highest accuracies yielded on the testing data for radiomics and deep learning based methods were 66.81% and 74.69%, respectively. A comparison result demonstrated that the deep learning based method can achieve a better performance than using radiomics.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Yongfeng Wang et al.",
      "keywords": "Radiomics; Thyroid nodules; Computer science; Artificial intelligence; Ultrasound; Thyroid; Radiology; Deep learning; Pattern recognition (psychology); Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2980290",
      "cited_by_count": 89,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2993687209",
      "doi": "10.1109/access.2019.2955555",
      "title": "Automated Detection of Myocardial Infarction Using a Gramian Angular Field and Principal Component Analysis Network",
      "abstract": "Myocardial infarction (MI) is a deadly disease that threatens human life worldwide, and it is essential to save threatened lives with early detection of MI. The electrocardiogram (ECG), which records the electrical activity presented in the heart, is used for the prevention and treatment of heart disease such as MI. However, it remains a challenge to visually interpret the ECG signals because of their small amplitude and duration. Inspired by the development in computer vision, we try to explore a novel approach for automatic detection of MI by imaging ECG signals without noise removal. In this paper, the ECG time series is first transformed into images using the Gramian Angular Difference Field (GADF) method. Subsequently, the processed images are subjected to the principal component analysis network (PCANet) to extract sparse high-dimensional features, which are easy to perform well in linear classifiers. We carried out several sets of experiments to test the effectiveness of our algorithm. The overall accuracy of 99.49%, the sensitivity of 99.78%, and the specificity of 98.08% are achieved in class-oriented experiments using original ECG beats. The accuracy even rises over 1% compared with the denoising one; Moreover, we also achieved favorable performance for the patient-specific experiment (accuracy of 93.17%, sensitivity of 93.91%, and specificity of 89.20%). The results of the experiments indicate that our model is an effective way to detect MI using raw ECG signals.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Gong Zhang et al.",
      "keywords": "Computer science; Artificial intelligence; Principal component analysis; Pattern recognition (psychology); Sensitivity (control systems); Noise reduction; Noise (video); Gramian matrix; Myocardial infarction; Electrocardiography; Cardiology; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2955555",
      "cited_by_count": 96,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3049612666",
      "doi": "10.1109/access.2020.3016653",
      "title": "Improving Skin-Disease Classification Based on Customized Loss Function Combined With Balanced Mini-Batch Logic and Real-Time Image Augmentation",
      "abstract": "International audience",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Tri-Cong Pham et al.",
      "keywords": "Computer science; Artificial intelligence; Skin cancer; Deep learning; Contextual image classification; Class (philosophy); Function (biology); Standard deviation; Image (mathematics); Pattern recognition (psychology); Machine learning; Cancer; Medicine; Mathematics; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3016653",
      "cited_by_count": 88,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2976551287",
      "doi": "10.1109/access.2019.2942937",
      "title": "Intelligent Analysis of Medical Big Data Based on Deep Learning",
      "abstract": "With the wide application of computer technology, medical health data has also increased dramatically, and data-driven medical big data analysis methods have emerged as the times require, providing assistance for intelligent identification of medical health. However, due to the mixed medical big data format, many incomplete records, and a lot of noise, it is still difficult to analyze medical big data. Traditional machine learning methods can't effectively mine the rich information contained in medical big data, while deep learning builds a hierarchical model by simulating the human brain. It has powerful automatic feature extraction, complex model construction and efficient feature expression, and more important. It is a deep learning method that extracts features from the bottom to the top level from the original medical image data. Therefore, this paper constructs a data analysis model based on deep learning for medical images and transcripts, and is used for intelligent identification and diagnosis of diseases. The model uses massive medical big data to select and optimize model parameters, and automatically learns the pathological analysis process of doctors or medical researchers through the model, and finally intelligently conducts disease judgment and effective decision based on the analysis results of medical big data. The experimental results show that the method can analyze the medical big data, and can realize the early diagnosis of the disease. At the same time, it can analyze the physical health status according to the patient's physical examination records and predict the risk of a certain disease in the future. Greatly reduce the work pressure of doctors or medical researchers and improve their work efficiency.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Hanqing Sun et al.",
      "keywords": "Big data; Computer science; Deep learning; Artificial intelligence; Identification (biology); Machine learning; Feature extraction; Data modeling; Data mining; Process (computing); Data science; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2942937",
      "cited_by_count": 52,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3094055136",
      "doi": "10.1109/mc.2020.3007297",
      "title": "The Edge-to-Cloud Continuum",
      "abstract": "Computer hosts a virtual roundtable with three experts to discuss the opportunities and obstacles regarding edge-to-cloud technology.",
      "year": "2020",
      "journal": "Computer",
      "authors": "Dejan Miloji\u010di\u0107",
      "keywords": "Cloud computing; Computer science; Enhanced Data Rates for GSM Evolution; Operating system; Telecommunications",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mc.2020.3007297",
      "cited_by_count": 71,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2972996185",
      "doi": "10.1109/access.2019.2940198",
      "title": "Diagnosis of Autism Spectrum Disorder Based on Eigenvalues of Brain Networks",
      "abstract": "Autism spectrum disorder (ASD) is a neuro dysfunction which causes the repetitive behavior and social instability of patients. Diagnosing ASD has been of great interest. However, due to the lack of discriminate differences between neuroimages of healthy persons and ASD patients, there has been no powerful diagnosis approach. In this study, we have designed brain network-based features for the diagnosis of ASD. Specifically, we have used the 264 regions based parcellation scheme to construct a brain network from a brain functional magnetic resonance imaging (fMRI). Then we have defined 264 raw brain features by the 264 eigenvalues of the Laplacian matrix of the brain network and another three features by network centralities. By applying a feature selection algorithm, we have obtained 64 discriminate features. Furthermore, we have trained several machine learning models for diagnosing ASD with our obtained features on ABIDE (Autism Brain Imaging Data Exchange) dataset. With our derived features, the linear discriminant analysis has achieved the classification accuracy of 77.7%, which is better than the state-of-the-art results.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Sakib Mostafa et al.",
      "keywords": "Autism spectrum disorder; Computer science; Linear discriminant analysis; Artificial intelligence; Autism; Eigenvalues and eigenvectors; Pattern recognition (psychology); Feature selection; Feature (linguistics); Feature extraction; Psychology; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2940198",
      "cited_by_count": 80,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3031339873",
      "doi": "10.1109/tbcas.2020.2998290",
      "title": "Ultrasensitive Magnetoelectric Sensing System for Pico-Tesla MagnetoMyoGraphy",
      "abstract": "Magnetomyography (MMG) with superconducting quantum interference devices (SQUIDs) enabled the measurement of very weak magnetic fields (femto to pico Tesla) generated from the human skeletal muscles during contraction. However, SQUIDs are bulky, costly, and require working in a temperature-controlled environment, limiting wide-spread clinical use. We introduce a low-profile magnetoelectric (ME) sensor with analog frontend circuitry that has sensitivity to measure pico-Tesla MMG signals at room temperature. It comprises magnetostrictive and piezoelectric materials, FeCoSiB/AlN. Accurate device modelling and simulation are presented to predict device fabrication process comprehensively using the finite element method (FEM) in COMSOL Multiphysics. The fabricated ME chip with its readout circuit was characterized under a dynamic geomagnetic field cancellation technique. The ME sensor experiment validate a very linear response with high sensitivities of up to 378 V/T driven at a resonance frequency of f<sub>res</sub> = 7.76 kHz. Measurements show the sensor limit of detections of down to 175 pT/\u221aHz at resonance, which is in the range of MMG signals. Such a small-scale sensor has the potential to monitor chronic movement disorders and improve the end-user acceptance of human-machine interfaces.",
      "year": "2020",
      "journal": "IEEE Transactions on Biomedical Circuits and Systems",
      "authors": "Siming Zuo et al.",
      "keywords": "Multiphysics; Sensitivity (control systems); Materials science; Magnetostriction; Optoelectronics; Dynamic range; Finite element method; Acoustics; Electronic engineering; Magnetic field; Physics; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbcas.2020.2998290",
      "cited_by_count": 77,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3037834680",
      "doi": "10.1109/jsen.2020.3004568",
      "title": "Detection of Respiratory Infections Using RGB-Infrared Sensors on Portable Device",
      "abstract": "Coronavirus Disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronaviruses 2 (SARS-CoV-2) has become a serious global pandemic in the past few months and caused huge loss to human society worldwide. For such a large-scale pandemic, early detection and isolation of potential virus carriers is essential to curb the spread of the pandemic. Recent studies have shown that one important feature of COVID-19 is the abnormal respiratory status caused by viral infections. During the pandemic, many people tend to wear masks to reduce the risk of getting sick. Therefore, in this paper, we propose a portable non-contact method to screen the health conditions of people wearing masks through analysis of the respiratory characteristics from RGB-infrared sensors. We first accomplish a respiratory data capture technique for people wearing masks by using face recognition. Then, a bidirectional GRU neural network with an attention mechanism is applied to the respiratory data to obtain the health screening result. The results of validation experiments show that our model can identify the health status of respiratory with 83.69% accuracy, 90.23% sensitivity and 76.31% specificity on the real-world dataset. This work demonstrates that the proposed RGB-infrared sensors on portable device can be used as a pre-scan method for respiratory infections, which provides a theoretical basis to encourage controlled clinical trials and thus helps fight the current COVID-19 pandemic. The demo videos of the proposed system are available at: https://doi.org/10.6084/m9.figshare.12028032.",
      "year": "2020",
      "journal": "IEEE Sensors Journal",
      "authors": "Zheng Jiang et al.",
      "keywords": "Pandemic; Coronavirus disease 2019 (COVID-19); Computer science; RGB color model; Respiratory system; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); Isolation (microbiology); Medicine; Artificial intelligence; Disease; Infectious disease (medical specialty); Bioinformatics; Pathology; Biology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2020.3004568",
      "cited_by_count": 66,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2967879902",
      "doi": "10.1109/access.2019.2933473",
      "title": "Interpretability Analysis of Heartbeat Classification Based on Heartbeat Activity\u2019s Global Sequence Features and BiLSTM-Attention Neural Network",
      "abstract": "Arrhythmia is a disease that threatens human life. Therefore, timely diagnosis of arrhythmia is of great significance in preventing heart disease and sudden cardiac death. The BiLSTM-Attention neural network model with heartbeat activity's global sequence features can effectively improve the accuracy of heartbeat classification. Firstly, the noise is removed by the continuous wavelet transform method. Secondly, the peak of the R wave is detected by the tagged database, and then the P-QRS-T wave morphology and the RR interval are extracted. This feature set is heartbeat activity's global sequence features, which combines single heartbeat morphology and 21 consecutive RR intervals. Finally, the Bi-LSTM algorithm and the BiLSTM-Attention algorithm are used to identify heartbeat category respectively, and the MIT-BIH arrhythmia database is used to verify the algorithm. The results show that the BiLSTM-Attention model combined with heartbeat activity's global sequence features has higher interpretability than other methods discussed in this paper.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Runchuan Li et al.",
      "keywords": "Heartbeat; Interpretability; Artificial intelligence; Artificial neural network; Pattern recognition (psychology); Computer science; Feature (linguistics); Noise (video); Wavelet transform; Machine learning; Data mining; Wavelet",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2933473",
      "cited_by_count": 60,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285195386",
      "doi": "10.1109/access.2022.3187502",
      "title": "Multimodal Educational Data Fusion for Students\u2019 Mental Health Detection",
      "abstract": "Mental health issues can lead to serious consequences like depression, self-mutilation, and worse, especially for university students who are not physically and mentally mature. Not all students with poor mental health are aware of their situation and actively seek help. Proactive detection of mental problems is a critical step in addressing this issue. However, accurate detections are hard to achieve due to the inherent complexity and heterogeneity of unstructured multi-modal data generated by campus life. Against this background, we propose a detection framework for detecting students' mental health, named CASTLE (educational data fusion for mental health detection). Three parts are involved in this framework. First, we utilize representation learning to fuse data on social life, academic performance, and physical appearance. An algorithm, named MOON (multi-view social network embedding), is proposed to represent students' social life in a comprehensive way by fusing students' heterogeneous social relations effectively. Second, a synthetic minority oversampling technique algorithm (SMOTE) is applied to the label imbalance issue. Finally, a DNN (deep neural network) model is utilized for the final detection. The extensive results demonstrate the promising performance of the proposed methods in comparison to an extensive range of state-of-the-art baselines. \u00a9 2013 IEEE.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Teng Guo et al.",
      "keywords": "Computer science; Sensor fusion; Mental health; Fusion; Artificial intelligence; Data science; Psychology; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3187502",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3126154634",
      "doi": "10.1109/access.2021.3057196",
      "title": "An Ensemble Learning Approach for Enhanced Classification of Patients With Hepatitis and Cirrhosis",
      "abstract": "Hepatitis C is an infectious disease that affects more than 70 million people worldwide, even killing 400 thousand of them annually. To better understand this disease and its prognosis, medical doctors can take advantage of the electronic health records (EHRs) of patients, which contain data that computer-based approaches built on statistics and computational intelligence can process to unveil new discoveries and trends otherwise unnoticeable by physicians. In this study, we analyze EHRs of 540 healthy controls and 75 patients diagnosed with hepatitis C, and use machine learning classifiers to predict their diagnosis. We employ the top classifier (Random Forests) to detect the most diagnostic variables for hepatitis C, that result being aspartate aminotransferase (AST) and alanine aminotransferase (ALT). These two enzyme levels are also employed by physicians in the AST/ALT ratio, a traditional measure commonly employed in gastroenterology and hepatology. We apply the same approach to a validation dataset of 123 patients with hepatitis C and cirrhosis, and the same two variables arose as most relevant. We therefore compared our approach with the AST/ALT ratio, and noticed that our two-features ensemble learning model outperforms the traditional AST/ALT ratio on both datasets. Our results confirm the usefulness of ensemble machine learning for hepatitis C and cirrhosis diagnosis prediction. Moreover, our discoveries can have an impact on clinical practice, helping physicians predict diagnoses of patients at risk of hepatitis C and cirrhosis more precisely.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Davide Chicco et al.",
      "keywords": "Cirrhosis; Hepatology; Medical diagnosis; Alanine aminotransferase; Artificial intelligence; Medicine; Machine learning; Internal medicine; Ensemble learning; Hepatitis; Random forest; Liver disease; Health records; Hepatitis C; Gastroenterology; Computer science; Pathology; Health care",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3057196",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3022921518",
      "doi": "10.1109/jbhi.2020.2990797",
      "title": "Knowledge Graph-Enabled Cancer Data Analytics",
      "abstract": "Cancer registries collect unstructured and structured cancer data for surveillance purposes which provide important insights regarding cancer characteristics, treatments, and outcomes. Cancer registry data typically (1) categorize each reportable cancer case or tumor at the time of diagnosis, (2) contain demographic information about the patient such as age, gender, and location at time of diagnosis, (3) include planned and completed primary treatment information, and (4) may contain survival outcomes. As structured data is being extracted from various unstructured sources, such as pathology reports, radiology reports, medical records, and stored for reporting and other needs, the associated information representing a reportable cancer is constantly expanding and evolving. While some popular analytic approaches including SEER*Stat and SAS exist, we provide a knowledge graph approach to organizing cancer registry data. Our approach offers unique advantages for timely data analysis and presentation and visualization of valuable information. This knowledge graph approach semantically enriches the data, and easily enables linking with third-party data which can help explain variation in cancer incidence patterns, disparities, and outcomes. We developed a prototype knowledge graph based on the Louisiana Tumor Registry dataset. We present the advantages of the knowledge graph approach by examining: i) scenario-specific queries, ii) links with openly available external datasets, iii) schema evolution for iterative analysis, and iv) data visualization. Our results demonstrate that this graph based solution can perform complex queries, improve query run-time performance by up to 76%, and more easily conduct iterative analyses to enhance researchers' understanding of cancer registry data.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Shohedul Hasan et al.",
      "keywords": "Computer science; Schema (genetic algorithms); Graph database; Categorization; Graph; Information retrieval; Cancer registry; Data visualization; Data science; Visualization; Data mining; Analytics; Unstructured data; Cancer; Big data; Medicine; Artificial intelligence; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2020.2990797",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3217378117",
      "doi": "10.1109/access.2021.3131741",
      "title": "An Improved LeNet-Deep Neural Network Model for Alzheimer\u2019s Disease Classification Using Brain Magnetic Resonance Images",
      "abstract": "Alzheimer&#x2019;s Disease (AD) is a psychological disorder in elderly people which causes severe intellectual disabilities. Proper processing of neuro-images can provide differences in brain tissues which may help in diagnosing the disease more effectively. But, due to the complex structures, this is a challenge in differentiating the brain tissues and classifying AD using traditional classification mechanisms. Deep Neural Network (DNN) is a machine learning technique that has the ability to absorb the most important information for classifying an object accurately. LeNet is a popular DNN based model with a simple and effective architecture that also consumes very less implementation time. As like most of the DNN models, LeNet also uses MaxPooling layer for dimensionality reduction by eliminating the information of minimum valued elements. In brain images low intensity valued pixels also may contain very important features. To keep the minimum valued elements too in the network, we have created a separate layer that performs Min-Pooling operation. MinPooling and MaxPooling layers are then concatenated together. Finally, we have replaced all MaxPooling Layers in LeNet by the concatenated layers. We have analysed and compared the performances of modified LeNet model with 20 other most commonly used DNN models, and some of the related works. It is observed that, the modified LeNet model achieved the highest performances. It is also observed that, original LeNet model can classify AD with a performance rate of 80&#x0025;, whereas, the proposed modified LeNet model achieved an average performance rate of 96.64&#x0025;.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Ruhul Amin Hazarika et al.",
      "keywords": "Computer science; Artificial intelligence; Pattern recognition (psychology); Artificial neural network; Convolutional neural network; Pooling; Deep learning; Curse of dimensionality",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3131741",
      "cited_by_count": 63,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2917055433",
      "doi": "10.1109/jtehm.2019.2900628",
      "title": "Cardiac-DeepIED: Automatic Pixel-Level Deep Segmentation for Cardiac Bi-Ventricle Using Improved End-to-End Encoder-Decoder Network",
      "abstract": "Accurate segmentation of cardiac bi-ventricle (CBV) from magnetic resonance (MR) images has a great significance to analyze and evaluate the function of the cardiovascular system. However, the complex structure of CBV image makes fully automatic segmentation as a well-known challenge. In this paper, we propose an improved end-to-end encoder-decoder network for CBV segmentation from the pixel level view (Cardiac-DeepIED). In our framework, we explicitly solve the high variability of complex cardiac structures through an improved encoder-decoder architecture which consists of Fire dilated modules and D-Fire dilated modules. This improved encoder-decoder architecture has the advantages of being capable of obtaining semantic task-aware representation and preserving fine-grained information. In addition, our method can dynamically capture potential spatiotemporal correlations between consecutive cardiac MR images through specially designed convolutional long-term and short-term memory structure; it can simulate spatiotemporal contexts between consecutive frame images. The combination of these modules enables the entire network to get an accurate, robust segmentation result. The proposed method is evaluated on the 145 clinical subjects with leave-one-out cross-validation. The average dice metric (DM) is up to 0.96 (left ventricle), 0.89 (myocardium), and 0.903 (right ventricle). The performance of our method outperforms state-of-the-art methods. These results demonstrate the effectiveness and advantages of our method for CBV regions segmentation at the pixel-level. It also reveals the proposed automated segmentation system can be embedded into the clinical environment to accelerate the quantification of CBV and expanded to volume analysis, regional wall thickness analysis, and three LV dimensions analysis.",
      "year": "2019",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Xiuquan Du et al.",
      "keywords": "Computer science; Segmentation; Encoder; Artificial intelligence; Computer vision; Pixel; Convolutional neural network; Deep learning; Image segmentation; End-to-end principle; Pattern recognition (psychology); Metric (unit)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2019.2900628",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3137206040",
      "doi": "10.1109/access.2021.3065965",
      "title": "Glioma Survival Analysis Empowered With Data Engineering\u2014A Survey",
      "abstract": "Survival analysis is a critical task in glioma patient management due to the inter and intra tumor heterogeneity. In clinical practice, clinicians estimate the survival with their experience, which can be biased and optimistic. Over the past decades, diverse survival analysis approaches were proposed incorporating distinct data such as imaging and genetic information. The remarkable advancements in imaging and high throughput omics and sequencing technologies have enabled the acquisition of this information of glioma patients efficiently, providing novel insights for survival estimation in the present day. Besides, in the past years, machine learning techniques and deep learning have emerged into the field of survival analysis of glioma patients trading off the traditional statistical analysis-based survival analysis approaches. In this survey paper, we explore the prognostic parameters acquired, utilizing diagnostic imaging techniques and genomic platforms for survival or risk estimation of glioma patients. Further, we review the techniques, learning and statistical analysis algorithms, along with their benefits and limitations used for prognosis prediction. Consequently, we highlight the challenges of the existing state-of-the-art survival prediction studies and propose future directions in the field of research.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Navodini Wijethilake et al.",
      "keywords": "Computer science; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3065965",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3087889038",
      "doi": "10.1109/access.2020.3026080",
      "title": "Efficient Lung Nodule Classification Using Transferable Texture Convolutional Neural Network",
      "abstract": "Lung nodules are vital indicators for the presence of lung cancer. An early detection enhances the survival rate of the patient by starting treatment at the right time. The detection and classification of malignancy in Computed Tomography (CT) images is a very time-consuming and difficult task for radiologists which lead the researchers to develop algorithms for Computer-Aided Diagnosis (CAD) systems to mitigate this burden. The performance of CAD systems is continuously improving by using various deep learning techniques for screening of lung cancer. In this paper, we proposed transferable texture Convolutional Neural Networks (CNN) to improve the classification performance of pulmonary nodules in CT scans. An Energy Layer (EL) is incorporated in our scheme, which extracts texture features from the convolutional layer. The inclusion of EL reduces the number of learnable parameters of the network, which further reduces the memory requirements and computational complexity. The proposed model has only three convolutional layers and one EL, instead of pooling layer. Overall proposed CNN architecture comprises of nine layers for automatic feature extraction and classification of pulmonary nodule candidates as malignant or benign. Furthermore, the pre-trained model of proposed CNN is also used to handle the smaller dataset classification problem by using transfer learning. This work has been evaluated on publicly available LIDC-IDRI and the LUNGx Challenge database through different evaluation matrices, such as; the accuracy, specificity, error rate and AUC. The proposed model is trained by six-fold cross-validation and achieved an accuracy score of 96.69&#x0025;&#x00B1;0.72&#x0025; with only 3.30&#x0025;&#x00B1;0.72&#x0025; error rate. Whereas, the measured AUC and recall is 99.11&#x0025;&#x00B1;0.45&#x0025; and 97.19&#x0025;&#x00B1;0.57&#x0025;, respectively. Moreover, we also tested our proposed technique on the MNIST dataset and achieved state-of-the-art results in terms of accuracy and error rate.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Imdad Ali et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Pattern recognition (psychology); Feature extraction; Pooling; Deep learning; Computer-aided diagnosis; Contextual image classification; CAD; Feature (linguistics); Transfer of learning; Machine learning; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3026080",
      "cited_by_count": 80,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319993451",
      "doi": "10.1109/access.2023.3239692",
      "title": "Body-Worn Sensors for Recognizing Physical Sports Activities in Exergaming via Deep Learning Model",
      "abstract": "Obesity and laziness are some of the common issues in the majority of the youth today. This has led to the development of a proposed exergaming solution where users can play first-person physical games. This research study not only proposes a solution for physical fitness in the form of a game using wearable sensors but also proposes a multi-purpose system that provides different applications when trained for the domain-specific dataset. Critical tasks of gesture recognition and depiction in virtual reality can be applied to many applications in the domains of crime detection, fitness, healthcare, online learning, and sports. In particular, the proposed system enables a user to perform, detect, and depict different gestures in the virtual reality game. First, the system pre-processes input data by applying a median filter to overcome the anomalies. Then, features are extracted through a convolutional neural network, power spectral density, skewness, and kurtosis methods. Further, the system optimizes different features by using the grey wolf optimization. Lastly, the feature set which is optimized is fed to a recurrent neural network for classification. When Compared to the traditional methods, the suggested system gives better results while being easier to use. The IMSporting behaviors (IMSB) dataset includes badminton and other physical activities, the WISDM dataset includes common locomotor motions, and the ERICA dataset which includes a variety of exercises, were used in the experimentation. According to experimental findings, the suggested approach outperformed current methods, which showed detection accuracies of 85.01&#x0025;, 88.46&#x0025;, and 93.18&#x0025; over the IMSB, WISDM, and ERICA datasets, respectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mir Mushhood Afsar et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Machine learning; Gesture; Wearable computer; Set (abstract data type); Gesture recognition; Feature extraction; Benchmark (surveying); Human\u2013computer interaction; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3239692",
      "cited_by_count": 93,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3120489340",
      "doi": "10.1109/access.2021.3050524",
      "title": "Remote Assessment of Parkinson\u2019s Disease Symptom Severity Using the Simulated Cellular Mobile Telephone Network",
      "abstract": "Telemonitoring of Parkinson's Disease (PD) has attracted considerable research interest because of its potential to make a lasting, positive impact on the life of patients and their carers. Purpose-built devices have been developed that record various signals which can be associated with average PD symptom severity, as quantified on standard clinical metrics such as the Unified Parkinson's Disease Rating Scale (UPDRS). Speech signals are particularly promising in this regard, because they can be easily recorded without the use of expensive, dedicated hardware. Previous studies have demonstrated replication of UPDRS to within less than 2 points of a clinical raters' assessment of symptom severity, using high-quality speech signals collected using dedicated telemonitoring hardware. Here, we investigate the potential of using the standard voice-over-GSM (2G) or UMTS (3G) cellular mobile telephone networks for PD telemonitoring, networks that, together, have greater than 5 billion subscribers worldwide. We test the robustness of this approach using a simulated noisy mobile communication network over which speech signals are transmitted, and approximately 6000 recordings from 42 PD subjects. We show that UPDRS can be estimated to within less than 3.5 points difference from the clinical raters' assessment, which is clinically useful given that the inter-rater variability for UPDRS can be as high as 4-5 UPDRS points. This provides compelling evidence that the existing voice telephone network has potential towards facilitating inexpensive, mass-scale PD symptom telemonitoring applications.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Athanasios Tsanas et al.",
      "keywords": "UMTS frequency bands; Rating scale; GSM; Computer science; Cellular network; Telemedicine; Robustness (evolution); Quality of life (healthcare); Mobile telephony; Medicine; Physical medicine and rehabilitation; Telecommunications; Psychology; Mobile radio",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3050524",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3021993456",
      "doi": "10.1109/access.2020.2991845",
      "title": "Standard Plane Identification in Fetal Brain Ultrasound Scans Using a Differential Convolutional Neural Network",
      "abstract": "Ultrasound scanning has become a highly recommended examination in prenatal diagnosis in many countries. The accurate identification of fetal brain ultrasound scans is crucial to accurate head measurement and brain lesion detection, such as the measurement of the biparietal diameter and the detection of hydrocephalus. In recent years, deep learning has made great progress in the field of image processing. However, there are two difficulties in the identification of fetal brain ultrasound standard planes (FBSPs). First, since the fetal brain tissue is not mature, the fetal brain tissue features are not easy to be detected. Second, because of the expensive collection costs, the amount of labeled image data is limited, which can cause over-fitting and decrease the identification precision. In this study, we proposed a differential convolutional neural network (differential-CNN) to automatically identify six fetal brain standard planes (FBSPs) from the non-standard planes. In this differential-CNN framework, the additional differential feature maps were derived from the feature maps in the original CNN using differential operators. The derivation process did not increase the number of convolution layers and parameters. Moreover, the differential convolution maps have the large advantage of analyzing the directional pattern of pixels and their neighborhoods using additional variation calculations. Therefore, the differential convolution maps would result in good identification performance and cost no extra computational burden. To test the performance of these algorithms, we constructed a dataset consisting of 30,000 2D ultrasound images from 155 fetal subjects ranging from 16 to 34 weeks. The experimental results showed that this method achieved an accuracy of 92.93%. Our work shows that the differential-CNN can be used to facilitate the implementation of the automated identification of FBSPs.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ruowei Qu et al.",
      "keywords": "Convolutional neural network; Artificial intelligence; Computer science; Pattern recognition (psychology); Convolution (computer science); Ultrasound; Feature (linguistics); Artificial neural network; Identification (biology); Algorithm; Radiology; Medicine; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2991845",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3001120086",
      "doi": "10.1109/access.2020.2968367",
      "title": "TestGraphia, a Software System for the Early Diagnosis of Dysgraphia",
      "abstract": "Dysgraphia, which is known as a writing disorder, is a specific disorder of writing regarding the reproduction of alphabetical and numerical signs. Dysgraphia may be related to dyspraxia, which is secondary to incomplete lateralization and characterized by a difficulty to reproduce alphabetical and numerical signs. Since the causes of dysgraphia are unknown, the rapid detection of symptoms is very important. In academic and clinical uses, the most common tool for detecting dysgraphia is an evaluation of the quality of writing on paper sheets. A writing analysis is based on rules for scoring the writing quality. In this paper, we discuss TestGraphia, which is a software system that can support doctors in making diagnoses and monitoring patients with dysgraphia in an objective manner. The system is based on known document analysis algorithms and modified or specially designed algorithms. Based on this software, a forms analysis requires considerably less time than that needed by traditional methods, enabling large screening activities and reducing time and cost. Potential dynamic changes in dysgraphia screening can be assessed by monitoring the quality of writing in a non-invasive way with reduced costs, both in the laboratory and the patient's home, and the appropriate frequency. In the system that we will describe, the mean time to execute a diagnosis is nearly ten times faster with trustworthy results.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Giovanni Dimauro et al.",
      "keywords": "Dysgraphia; Computer science; Medical diagnosis; Software; Quality (philosophy); Artificial intelligence; Natural language processing; Medicine; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2968367",
      "cited_by_count": 68,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4232916392",
      "doi": "10.1109/tai.2021.3133819",
      "title": "Decentralized Deep Learning for Multi-Access Edge Computing: A Survey on Communication Efficiency and Trustworthiness",
      "abstract": "Wider coverage and a better solution to a latency reduction in 5G necessitate\\nits combination with multi-access edge computing (MEC) technology.\\nDecentralized deep learning (DDL) such as federated learning and swarm learning\\nas a promising solution to privacy-preserving data processing for millions of\\nsmart edge devices, leverages distributed computing of multi-layer neural\\nnetworks within the networking of local clients, whereas, without disclosing\\nthe original local training data. Notably, in industries such as finance and\\nhealthcare where sensitive data of transactions and personal medical records is\\ncautiously maintained, DDL can facilitate the collaboration among these\\ninstitutes to improve the performance of trained models while protecting the\\ndata privacy of participating clients. In this survey paper, we demonstrate the\\ntechnical fundamentals of DDL that benefit many walks of society through\\ndecentralized learning. Furthermore, we offer a comprehensive overview of the\\ncurrent state-of-the-art in the field by outlining the challenges of DDL and\\nthe most relevant solutions from novel perspectives of communication efficiency\\nand trustworthiness.\\n",
      "year": "2021",
      "journal": "IEEE Transactions on Artificial Intelligence",
      "authors": "Yuwei Sun et al.",
      "keywords": "Computer science; Deep learning; Trustworthiness; Edge computing; Latency (audio); Field (mathematics); Edge device; Enhanced Data Rates for GSM Evolution; Artificial intelligence; Data science; Distributed computing; Computer security; Telecommunications; Cloud computing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tai.2021.3133819",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3091082621",
      "doi": "10.1109/tnsre.2020.3027756",
      "title": "Automatic Identification of High-Risk Autism Spectrum Disorder: A Feasibility Study Using Video and Audio Data Under the Still-Face Paradigm",
      "abstract": "It is reported that the symptoms of autism spectrum disorder (ASD) could be improved by effective early interventions, which arouses an urgent need for large-scale early identification of ASD. Until now, the screening of ASD has relied on the child psychiatrist to collect medical history and conduct behavioral observations with the help of psychological assessment tools. Such screening measures inevitably have some disadvantages, including strong subjectivity, relying on experts and low-efficiency. With the development of computer science, it is possible to realize a computer-aided screening for ASD and alleviate the disadvantages of manual evaluation. In this study, we propose a behavior-based automated screening method to identify high-risk ASD (HR-ASD) for babies aged 8-24 months. The still-face paradigm (SFP) was used to elicit baby's spontaneous social behavior through a face-to-face interaction, in which a mother was required to maintain a normal interaction to amuse her baby for 2 minutes (a baseline episode) and then suddenly change to the no-reaction and no-expression status with 1 minute (a still-face episode). Here, multiple cues derived from baby's social stress response behavior during the latter episode, including head-movements, facial expressions and vocal characteristics, were statistically analyzed between HR-ASD and typical developmental (TD) groups. An automated identification model of HR-ASD was constructed based on these multi-cue features and the support vector machine (SVM) classifier; moreover, its screening performance was satisfied, for all the accuracy, specificity and sensitivity exceeded 90% on the cases included in this study. The experimental results suggest its feasibility in the early screening of HR-ASD.",
      "year": "2020",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Chuangao Tang et al.",
      "keywords": "Autism spectrum disorder; Psychology; Autism; Identification (biology); Facial expression; Artificial intelligence; Computer science; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2020.3027756",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2984562136",
      "doi": "10.1109/access.2019.2950387",
      "title": "Deep Learning-Based Methodology for Recognition of Fetal Brain Standard Scan Planes in 2D Ultrasound Images",
      "abstract": "Two-dimensional ultrasound scanning (US) has become a highly recommended examination in prenatal diagnosis in many countries. Accurate detection of abnormalities and correct fetal brain standard planes is the most necessary precondition for successful diagnosis and measurement. In the past few years, support vector machine (SVM) and other machine learning methods have been devoted to automatic recognition of 2D ultrasonic images, but the performance of recognition is not satisfactory due to the wide diversity of fetal postures, shortage of data, similarities between standard planes and other reasons. Especially in the recognition of fetal brain images, the features of fetal brain images such as shape, texture, color and others are very similar, which presents great challenges to the recognition work. In this study, we proposed two main methods based on deep convolutional neural networks to automatically recognize six standard planes of fetal brains. One is a deep convolutional neural network (CNN), and the other one is CNN-based domain transfer learning. To examine the performance of these algorithms, we constructed two datasets. Dataset 1 consists of 30,000 2D ultrasound images from 155 subjects between 16 and 34 weeks. Dataset 2, containing 1,200 images, was acquired from a research participant throughout 40 weeks, which is the entire pregnancy. Experimental results show that the proposed solutions achieve promising results and that the frameworks based on deep convolutional neural networks generally outperform the ones using other classical deep learning methods, thus demonstrating the great potential of convolutional neural networks in this area.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Ruowei Qu et al.",
      "keywords": "Computer science; Artificial intelligence; Ultrasound; Pattern recognition (psychology); Computer vision; Deep learning; Radiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2950387",
      "cited_by_count": 47,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4315630793",
      "doi": "10.1109/access.2023.3235833",
      "title": "Deep Learning in Cervical Cancer Diagnosis: Architecture, Opportunities, and Open Research Challenges",
      "abstract": "Nowadays, deep learning (DL) is a popular tool used in various applications in different fields, including the medical domain. DL techniques can cope with several challenges, which are difficult to resolve via traditional artificial intelligence (AI) techniques. Cervical cancer (CC) is one of the leading reasons for death in females and ranks second after breast cancer, with more than 700 mortalities daily. This number is estimated to be 400,000 annually by 2030. However, if the cancer is detected in the early and precancerous stages, it is completely curable. Pap smear and colposcopy are the most widely used screening methods for the detection of cervical cancer. But manual screening approach suffers from a high false rate due to human errors. To overcome this challenge, machine learning (ML) and DL-based computer-aided diagnostic (CAD) techniques are being extensively expanded to automatically segment and categorize cervical cytology and colposcopy images. These methods increase the accuracy of detecting different stages of cervical cancer. Hence, there is an increased interest in creating computer-aided solutions for CC screening, especially in less-developed countries where the majority of cervical cancer-related fatalities occur. This review overviews state-of-the-art approaches that use DL techniques to analyze cervical cytology and screening images. It reviews and discusses relevant DL techniques, their architectures, classification methods, and the segmentation of cervical cytology and colposcopy images. Finally, it reviews the DL algorithms that are currently used in CC screening and offers useful insights, research opportunities and future directions in this field.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nina Youneszade et al.",
      "keywords": "Colposcopy; Cervical cancer; Artificial intelligence; Computer science; Machine learning; Segmentation; Categorization; Cancer; Cervical cancer screening; Medical physics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3235833",
      "cited_by_count": 62,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388019189",
      "doi": "10.1109/access.2023.3328331",
      "title": "Explainable Artificial Intelligence of Multi-Level Stacking Ensemble for Detection of Alzheimer\u2019s Disease Based on Particle Swarm Optimization and the Sub-Scores of Cognitive Biomarkers",
      "abstract": "Alzheimer&#x2019;s disease (AD) is a progressive neurological disorder characterized by memory loss and cognitive decline, affecting millions worldwide. Early detection is crucial for effective treatment, as it can slow disease progression and improve quality of life. Machine learning has shown promise in AD detection using various medical modalities. In this paper, we propose a novel multi-level stacking model that combines heterogeneous models and modalities to predict different classes of AD. The modalities include cognitive sub-scores (e.g., clinical dementia rating &#x2013; sum of boxes, Alzheimer&#x2019;s disease assessment scale) from the Alzheimer&#x2019;s Disease Neuroimaging Initiative dataset. In the proposed approach, in level 1, we used six base models (Random Forest (RF), Decision Tree (DT), Support Vector Machine (SVM), Logistic Regression (LR), K-nearest Neighbors (KNN), and Native Bayes (NB)to train each modality (ADAS, CDR, and FQA). Then, we build stacking training that combines the outputs of each base model for the training set and staking testing that combines the outcomes of each model for the testing set. In level 2, three stacking models are produced for each modality that trains and evaluates based on the output of 6 base models based on (RF, LR, DT, SVM, KNN, and NB) are combined in training stacking for the training set and testing stacking for the testing set. Stacking training is used to train meta-learners (RF), and stacking testing is used to evaluate meta-learners (RF). Finally, in level 3, the output prediction of the stacking model from each modality (ADAS, CDR, and FQA) in the training and testing datasets is merged to build a new dataset, which is staking training and stacking testing. Training stacking is used to train the meta-learner, and the testing set is used to evaluate the meta-learner and produce the final prediction. Our research also aims to provide model explanations, ensuring efficiency, effectiveness, and trust through explainable artificial intelligence (XAI). Feature selection optimization based on Particle Swarm Optimization is used to select the most appropriate sub-scores. The proposed model shows significant potential for improving early disease diagnosis. The results demonstrate that the multi-modality approach outperforms single-modality approaches. Moreover, the proposed multi-level stacking models achieve the highest performance with selected features compared to regular ML classifiers and stacking models using full multi-modalities, achieving accuracy, precision, recall, and F1-scores of 92.08&#x0025;, 92.07&#x0025;, 92.08&#x0025;, and 92.01&#x0025; for two classes, and 90.03&#x0025;, 90.19&#x0025;, 90.03&#x0025;, and 90.05&#x0025; for three classes, respectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Abdulaziz AlMohimeed et al.",
      "keywords": "Computer science; Support vector machine; Random forest; Artificial intelligence; Stacking; Machine learning; Naive Bayes classifier; Modality (human\u2013computer interaction); Set (abstract data type); Dementia; Test set; Pattern recognition (psychology); Disease; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3328331",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3134315428",
      "doi": "10.1109/access.2021.3063986",
      "title": "A Bibliometric Analysis of Gamification Research",
      "abstract": "Gamification has rapidly emerged as one of the favorite persuasive technologies widely used with the aim of promoting a positive change in the user's behavior by means of including game-like elements in non-game contexts. As a research discipline, gamification is growing fast, maturing from basic and fundamental questions such as what and why gamify to more mature ones such as how to gamify, when and when not, and still facing empirical and theoretical challenges to prove the effects of its practice and consolidate the principles that guide meaningful gamification designs. The purpose of this paper is to conduct a bibliometric study to describe how gamification as a scientific discipline is structured and how it has evolved over time. To do this, we make use of bibliometric performance analysis and science mapping methods to display and analyze the intellectual, conceptual and social network structures of gamification research, as well as the evolution and dynamical aspects of the discipline. The results reveal the research fronts and intellectual structures of the field, the internal relationships among articles, authors and keywords, the existing networks of collaboration, the emerging trends, the hot topics, and the most influential authors, publications and sources. Together, they picture the intellectual landscape of gamification as a scientific field that will be useful for junior and senior researchers, practitioners, funding agencies and policymakers.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Manuel Trinidad et al.",
      "keywords": "Field (mathematics); Computer science; Knowledge management; Bibliometrics; Data science; Engineering ethics; Management science; Sociology; World Wide Web; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3063986",
      "cited_by_count": 91,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2943449403",
      "doi": "10.1109/access.2019.2913468",
      "title": "Collaborative Variational Deep Learning for Healthcare Recommendation",
      "abstract": "Healthcare recommender system (HRS) has shown the great potential of targeting medical experts or patients, and plays a key role in improving an individual's health by providing insightful recommendations. The HRSs generate recommendations based on a successful and widely applied method known as collaborative filtering (CF). Despite its success, the CF suffers from data sparsity and cold-start problem, which results in the poor quality of recommendations. In particular, it is a great challenge to seeking information relevant to patients' condition, and understanding the medical terms and relationships between them in HRSs. To address these problems, we design a novel collaborative variational deep learning model (CVDL) to exploit multi-sourced information for providing appropriate healthcare recommendations in primary care service. CVDL employs additional variational autoencoder (VAE) to learn deep latent representations for item contents (the description of primary care doctors) in latent space, instead of observation space through an inference network. Meanwhile, the CVDL extracts latent user (patient) features by incorporating user profile in a VAE neural network. Therefore, the CVDL can learn better implicit relationships between items and users from item content, user profile, and rating matrix. In addition, a Stochastic Gradient Variational Bayes (SGVB) approach is proposed to calculate the maximum posterior estimates for learning model parameters. The experiments conducted on three datasets have indicated that our method significantly outperforms the state-of-the-art hybrid CF methods.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Xiaoyi Deng et al.",
      "keywords": "Collaborative filtering; Computer science; Autoencoder; Recommender system; Inference; Machine learning; Deep learning; Artificial intelligence; Bayes' theorem; Health care; Artificial neural network; Data mining; Bayesian probability",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2913468",
      "cited_by_count": 40,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285817571",
      "doi": "10.1109/access.2022.3192024",
      "title": "Uncertainty-Aware Deep Learning Methods for Robust Diabetic Retinopathy Classification",
      "abstract": "Automatic classification of diabetic retinopathy from retinal images has been increasingly studied using deep neural networks with impressive results. However, there is clinical need for estimating uncertainty in the classifications, a shortcoming of modern neural networks. Recently, approximate Bayesian neural networks (BNNs) have been proposed for this task, but previous studies have only considered the binary referable/non-referable diabetic retinopathy classification applied to benchmark datasets. We present novel results for 9 BNNs by systematically investigating a clinical dataset and 5-class classification scheme, together with benchmark datasets and binary classification scheme. Moreover, we derive a connection between entropy-based uncertainty measure and classifier risk, from which we develop a novel uncertainty measure. We observe that the previously proposed entropy-based uncertainty measure improves performance on the clinical dataset for the binary classification scheme, but not to such an extent as on the benchmark datasets. It improves performance in the clinical 5-class classification scheme for the benchmark datasets, but not for the clinical dataset. Our novel uncertainty measure generalizes to the clinical dataset and to one benchmark dataset. Our findings suggest that BNNs can be utilized for uncertainty estimation in classifying diabetic retinopathy on clinical data, though proper uncertainty measures are needed to optimize the desired performance measure. In addition, methods developed for benchmark datasets might not generalize to clinical datasets.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Joel Jaskari et al.",
      "keywords": "Computer science; Benchmark (surveying); Artificial intelligence; Binary classification; Machine learning; Classifier (UML); Entropy (arrow of time); Data mining; Diabetic retinopathy; Binary number; Pattern recognition (psychology); Support vector machine; Mathematics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3192024",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390777660",
      "doi": "10.1109/access.2024.3351809",
      "title": "Unlocking the Potential of XAI for Improved Alzheimer\u2019s Disease Detection and Classification Using a ViT-GRU Model",
      "abstract": "Alzheimer&#x2019;s Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual&#x2019;s ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer&#x2019;s MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53&#x0025; for 4-class and 99.69&#x0025; for binary classification. It also demonstrated a high accuracy of 99.26&#x0025; for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model&#x2019;s decision-making process and gain insights into the underlying factors driving the AD diagnosis.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "S M Mahim et al.",
      "keywords": "Computer science; Artificial intelligence; Neuroimaging; Deep learning; Machine learning; Dementia; Magnetic resonance imaging; Class (philosophy); Pattern recognition (psychology); Disease; Medicine; Neuroscience; Pathology; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3351809",
      "cited_by_count": 59,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4318586178",
      "doi": "10.1109/access.2023.3240443",
      "title": "Multiple Types of Cancer Classification Using CT/MRI Images Based on Learning Without Forgetting Powered Deep Learning Models",
      "abstract": "Cancer is the second biggest cause of death worldwide, accounting for one of every six deaths. On the other hand, early detection of the disease significantly improves the chances of survival. The use of Artificial Intelligence (AI) to automate cancer detection might allow us to evaluate more cases in less time. In this research, AI-based deep learning models are proposed to classify the images of eight kinds of cancer, such as lung, brain, breast, and cervical cancer. This work evaluates the deep learning models, namely Convolutional Neural Networks (CNN), against classifying images with cancer traits. Pre-trained CNN variants such as MobileNet, VGGNet, and DenseNet are employed to transfer the knowledge they learned with the ImageNet dataset to detect different kinds of cancer cells. We use Bayesian Optimization to find the suitable values for the hyperparameters. However, transfer learning could make it so that models can no longer classify the datasets they were initially trained. So, we use Learning without Forgetting (LwF), which trains the network using only new task data while keeping the network&#x2019;s original abilities. The results of the experiments show that the proposed models based on transfer learning are more accurate than the current state-of-the-art techniques. We also show that LwF can better classify both new datasets and datasets that have been trained before.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Malliga Subramanian et al.",
      "keywords": "Computer science; Transfer of learning; Artificial intelligence; Deep learning; Convolutional neural network; Machine learning; Hyperparameter; Forgetting; Artificial neural network; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3240443",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380785280",
      "doi": "10.1109/access.2023.3286695",
      "title": "Serious Games and AI: Challenges and Opportunities for Computational Social Science",
      "abstract": "The gaming industry plays a crucial role in the realm of entertainment within our society. However, from Monopoly to Flight Simulators, serious games have also been appealing tools for learning a new language, conveying values, or training skills. The resurgence of Artificial Intelligence (AI) and data science in the last decade presents a unique window of opportunity for its integration into video games. This integration is of particular interest due to the vast amount of data that can be collected through a game, which is needed to feed the AI algorithms. This paper aims to identify relevant research paths in the intersection of serious games, AI, and computational social science, particularly in their utilization as novel research tools to comprehend human behavior and society. To provide a comprehensive context, we also present an overview of the serious game research field identifying the most prominent application areas and analyzing applications of AI in serious games that hold great potential for computational social science research. The goal of our work is to establish a valuable framework for researchers interested in utilizing serious games as a novel tool for AI-supported social research.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jaime P\u00e9rez et al.",
      "keywords": "Computer science; Computational sociology; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3286695",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2972385324",
      "doi": "10.1109/access.2019.2940866",
      "title": "AffectiveWall: Designing Collective Stress-Related Physiological Data Visualization for Reflection",
      "abstract": "Excessive workplace stress affects the individual's health as well as social collaborations, so the management of stressors is essential. However, an individual worker who only subjectively reflects on his or her individual and social stressors may misinterpret them, and thus not be able to manage them. This paper aims at engaging workplace stress reflection on objective stress-related physiological data using a shared display, which provides an anonymous view of the individual stress-related physiological signals (i.e., heart-rate variability) through a collective visualization. A minimalist proof-of-concept system is implemented for investigating the design space and deployed during group collaboration. The user study results show that the visualization successfully drew the participants' awareness and increased their understanding of self and organizational stress. This work highlights the importance of objective physiological data in the reflection process of organizational stress management.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Mengru Xue et al.",
      "keywords": "Visualization; Stressor; Stress (linguistics); Reflection (computer programming); Computer science; Data visualization; Process (computing); Human\u2013computer interaction; Psychology; Knowledge management; Applied psychology; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2940866",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3194944581",
      "doi": "10.1109/tnsre.2021.3107376",
      "title": "Preliminary Assessment of a Postural Synergy-Based Exoskeleton for Post-Stroke Upper Limb Rehabilitation",
      "abstract": "Upper limb exoskeletons have drawn significant attention in neurorehabilitation because of the anthropomorphic mechanical structure analogous to human anatomy. Whereas, the training movements are typically unorganized because most exoskeletons ignore the natural movement characteristic of human upper limbs, particularly inter-joint postural synergy. This paper introduces a newly developed exoskeleton (Armule) for upper limb rehabilitation with a postural synergy design concept, which can reproduce activities of daily living (ADL) motion with the characteristics of human natural movements. The semitransparent active control strategy with the interactive force guidance and visual feedback ensured the active participation of users. Eight participants with hemiplegia due to a first-ever, unilateral stroke were recruited and included. They participated in exoskeleton therapy sessions for 4 weeks, with passive/active training under trajectories and postures with the characteristics of human natural movements. The primary outcome was the Fugl-Meyer Assessment for Upper Extremities (FMA-UE). The secondary outcomes were the Action Research Arm Test(ARAT), modified Barthel Index (mBI), and metric measured with the exoskeleton After the 4-weeks intervention, all subjects showed significant improvements in the following clinical measures: the FMA-UE (difference, 11.50 points, p = 0.002), the ARAT (difference, 7.75 points ), and the mBI (difference, 17.50 points, p = 0.003 ) score. Besides, all subjects showed significant improvements in kinematic and interaction force metrics measured with the exoskeleton. These preliminary results demonstrate that the Armule exoskeleton could improve individuals' motor control and ADL function after stroke, which might be associated with kinematic and interaction force optimization and postural synergy modification during functional tasks.",
      "year": "2021",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Chang He et al.",
      "keywords": "Exoskeleton; Rehabilitation; Physical medicine and rehabilitation; Stroke (engine); Medicine; Physical therapy; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2021.3107376",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4362514394",
      "doi": "10.1109/access.2023.3264266",
      "title": "Optimal Channels and Features Selection Based ADHD Detection From EEG Signal Using Statistical and Machine Learning Techniques",
      "abstract": "Attention deficit hyperactivity disorder (ADHD) is one of the major psychiatric and neurodevelopment disorders worldwide. Electroencephalography (EEG) signal-based approach is very important for the early detection and classification of children with ADHD. However, diagnosing children with ADHD using full EEG channels with all features may lead to computational complexity and overfitting problems. To solve these problems, machine learning (ML)-based ADHD detection was designed by identifying optimal channels and its significant features. In this work, support vector machine and t-test based, two separate approaches were devised to select optimal channels individually and then proposed a hybrid channel selection approach by combining these two channel selection methods in order to select the optimal channels. After that, LASSO logistic regression-based model was used to select the important features from the selected channels. Finally, six ML-based classifiers, like Gaussian process classification (GPC), random forest, k-nearest neighbors, multilayer perceptron, decision tree, and logistic regression were applied for the detection of children with ADHD and evaluated their performances using accuracy and area under the curve (AUC). This study utilized a total of one hundred twenty-one children, with sixty-one children with ADHD, aged 7-12 years, and had nineteen channels. Ten different channels were selected by SVM based and an independent t-test-based approach separately and six overlapping channels were identified from both channel selection methods. Then, we selected twenty-eight features from selected six channels using LASSO. Using only six channels and twenty-eight features, GP-based classifier achieved an accuracy rate of 97.53&#x0025; and AUC of 0.999. This is an improvement of 3&#x0025; over previously developed techniques published in the literature. This study illustrated that LASSO with GP-based system performed outstanding performance in distinguishing children with ADHD from healthy children. This proposed system will be helpful to doctors and physicians in order to detect children with ADHD at an early stage and take the necessary steps for the patients to access appropriate healthcare services, receive effective treatment, and be more conscious of maintaining their lives.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Md. Maniruzzaman et al.",
      "keywords": "Overfitting; Artificial intelligence; Support vector machine; Computer science; Lasso (programming language); Machine learning; Pattern recognition (psychology); Feature selection; Random forest; Electroencephalography; Logistic regression; Multilayer perceptron; Channel (broadcasting); Artificial neural network; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3264266",
      "cited_by_count": 63,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3008437947",
      "doi": "10.1109/access.2020.2974887",
      "title": "Research on Risk Prediction of Dyslipidemia in Steel Workers Based on Recurrent Neural Network and LSTM Neural Network",
      "abstract": "With the development of medical digitization technology, artificial intelligence and big data technology, the medical model is gradually changing from treatment-oriented to prevention-oriented. In recent years, with the rise of artificial neural networks, especially deep learning, great achievements have been made in realizing image classification, natural language processing, text processing and other fields. Combining artificial intelligence and big data technology for disease risk prediction is a research focus in the field of intelligent medicine. Blood lipids are the main risk factors of cardiovascular and cerebrovascular diseases. If early prediction of abnormal blood lipids in iron and steel workers can be carried out, early intervention can be carried out, which is beneficial to protect the health of iron and steel workers. This paper around the steel workers dyslipidemia prediction problem for further study, firstly analyzes the influence factors of the steel workers dyslipidemia, discusses the commonly used method for prediction of disease, and then studied deep learning related theory, this paper introduces the two deep learning algorithms of RNN (Recurrent Neural Network) and LSTM (Long Short-Term Memory). Use the basic principle of Python language and the TensorFlow deep learning framework, establishes a prediction model based on two deep learning networks, and makes an example analysis. Experimental results show the LSTM prediction effect is superior to traditional RNN network, It provides scientific basis for the prevention of iron and steel dyslipidemia.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Shiyue Cui et al.",
      "keywords": "Deep learning; Dyslipidemia; Artificial intelligence; Computer science; Artificial neural network; Recurrent neural network; Machine learning; Field (mathematics); Disease; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2974887",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2906622835",
      "doi": "10.1109/access.2018.2889013",
      "title": "A Robust Parameter-Free Thresholding Method for Image Segmentation",
      "abstract": "In this work we presented a new parameter-free thresholding method for image segmentation. In separating an image into two classes, the method employs an objective function that not only maximizes the between-class variance but also the distance between the mean of each class and the global mean of the image. The design of the objective function aims to circumvent the challenge that many existing techniques encounter when the underlying two classes have very different sizes or variances. Advantages of the new method are two-fold. First, it is parameter-free, meaning that it can generate consistent results. Second, the new method has a simple form that makes it easy to adapt to different applications. We tested and compared the new method with the standard Otsu method, the maximum entropy method, and the 2D Otsu method on simulated and real biomedical and photographic images and found the new method can achieve a more accurate and robust performance.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Xinhua Cao et al.",
      "keywords": "Thresholding; Computer science; Image segmentation; Artificial intelligence; Otsu's method; Image (mathematics); Segmentation; Pattern recognition (psychology); Entropy (arrow of time); Balanced histogram thresholding; Principle of maximum entropy; Image processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2889013",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3084396173",
      "doi": "10.1109/mci.2020.3019898",
      "title": "Meaningful Big Data Integration for a Global COVID-19 Strategy",
      "abstract": "With the rapid spread of the COVID-19 pandemic,&#13;\\nthe novel Meaningful Integration of Data Analytics and Services&#13;\\n(MIDAS) platform quickly demonstrates its value, relevance&#13;\\nand transferability to this new global crisis. The MIDAS platform&#13;\\nenables the connection of a large number of isolated heterogeneous&#13;\\ndata sources, and combines rich datasets including&#13;\\nopen and social data, ingesting and preparing these for the&#13;\\napplication of analytics, monitoring and research tools. These&#13;\\nplatforms will assist public health author ities in: (i) better&#13;\\nunderstanding the disease and its impact; (ii) monitoring the&#13;\\ndifferent aspects of the evolution of the pandemic across a&#13;\\ndiverse range of groups; (iii) contributing to improved resilience&#13;\\nagainst the impacts of this global crisis; and (iv) enhancing&#13;\\npreparedness for future public health emergencies. The&#13;\\nmodel of governance and ethical review, incorporated and&#13;\\ndefined within MIDAS, also addresses the complex privacy and&#13;\\nethical issues that the developing pandemic has highlighted,&#13;\\nallowing oversight and scrutiny of more and richer data sources&#13;\\nby users of the system.",
      "year": "2020",
      "journal": "IEEE Computational Intelligence Magazine",
      "authors": "Jo\u00e3o Pita Costa et al.",
      "keywords": "Big data; Data science; Pandemic; Analytics; Computer science; Resilience (materials science); Coronavirus disease 2019 (COVID-19); Preparedness; Scrutiny; Data integration; Corporate governance; Business; Data mining; Political science; Infectious disease (medical specialty); Medicine; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mci.2020.3019898",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391097175",
      "doi": "10.1109/access.2024.3356602",
      "title": "Toward Improving Breast Cancer Classification Using an Adaptive Voting Ensemble Learning Algorithm",
      "abstract": "Over the past decade, breast cancer has been the most common type of cancer in women. Different methods were proposed for breast cancer detection. These methods mainly classify and categorize malignant and Benign tumors. Machine learning is a practical approach for breast cancer classification. Data mining and classification are effective methods to predict and categorize breast cancer. The optimum classification for detecting Breast Cancer (BC) is ensemble-based. The ensemble approach involves using multiple ways to find the best possible solution. This study used the Wisconsin Breast Cancer Diagnostic (WBCD) dataset. We created a voting ensemble classifier that combines four different machine learning models: Extra Trees Classifier (ETC), Light Gradient Boosting Machine (LightGBM), Ridge Classifier (RC), and Linear Discriminant Analysis (LDA). The proposed ELRL-E approach achieved an accuracy of 97.6&#x0025;, a precision of 96.4&#x0025;, a recall of 100&#x0025;, and an F1 score of 98.1&#x0025;. Various output evaluations are used to evaluate the performance and efficiency of the proposed model and other classifiers. Overall, the recommended strategy performed better. Results are directly compared with the individual classifier and different recognized state-of-the-art classifiers. The primary objective of this study is to identify the most influential ensemble machine learning classifier for breast cancer detection and diagnosis in terms of accuracy and AUC score.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Amreen Batool et al.",
      "keywords": "Computer science; Ensemble learning; Voting; Breast cancer; Statistical classification; Machine learning; Algorithm; Artificial intelligence; Cancer; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3356602",
      "cited_by_count": 57,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312383049",
      "doi": "10.1109/ojemb.2022.3217186",
      "title": "A Deep Probabilistic Sensing and Learning Model for Brain Tumor Classification With Fusion-Net and HFCMIK Segmentation",
      "abstract": "<i>Goal:</i> Implementation of an artificial intelli gence-based medical diagnosis tool for brain tumor classification, which is called the BTFSC-Net. <i>Methods:</i> Medical images are preprocessed using a hybrid probabilistic wiener filter (HPWF) The deep learning convolutional neural network (DLCNN) was utilized to fuse MRI and CT images with robust edge analysis (REA) properties, which are used to identify the slopes and edges of source images. Then, hybrid fuzzy c-means integrated k-means (HFCMIK) clustering is used to segment the disease affected region from the fused image. Further, hybrid features such as texture, colour, and low-level features are extracted from the fused image by using gray-level cooccurrence matrix (GLCM), redundant discrete wavelet transform (RDWT) descriptors. Finally, a deep learning based probabilistic neural network (DLPNN) is used to classify malignant and benign tumors. The BTFSC-Net attained 99.21% of segmentation accuracy and 99.46% of classification accuracy. <i>Conclusions:</i> The simulations showed that BTFSC-Net outperformed as compared to existing methods.",
      "year": "2022",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "M. V. S. Ramprasad et al.",
      "keywords": "Artificial intelligence; Pattern recognition (psychology); Computer science; Convolutional neural network; Deep learning; Probabilistic logic; Segmentation; Fuse (electrical); Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2022.3217186",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3135344852",
      "doi": "10.1109/access.2021.3064682",
      "title": "Risk Assessment Methodologies for the Internet of Medical Things: A Survey and Comparative Appraisal",
      "abstract": "The Internet of Medical Things (IoMT) has revolutionized health care services by providing significant benefits in terms of patient well being and relevant costs. Traditional risk assessment methodologies, however, cannot be effectively applied in the IoMT context since IoMT devices form part of a distributed and trustless environment and naturally support functionalities that favor reliability and usability instead of security. In this work we present a survey of risk assessment and mitigation methodologies for IoMT. For conducting the survey, we assess two streams of literature. First, we systematically review and classify the current scientific research in IoMT risk assessment methodologies. Second, we review existing standards/best practices for IoMT security assessment and mitigation in order to i) provide a comparative assessment of these standards/best practices on the basis of predefined criteria (scope and/or coverage, maturity level, and relevant risk methodology applied) and ii) identify common themes for IoMT security controls. Based on the analysis, we provide various IoMT research and implementation gaps along with a road map of fruitful areas for future research. The paper could be of significant value to security assessment researchers and policymakers/stakeholders in the health care industry.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Vangelis Malamas et al.",
      "keywords": "Computer science; The Internet; Scope (computer science); Usability; Context (archaeology); Risk assessment; Risk analysis (engineering); Health care; Computer security; Internet privacy; Data science; World Wide Web; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3064682",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3001522550",
      "doi": "10.1109/jbhi.2020.3021143",
      "title": "A Deep Learning Approach to Diagnosing Multiple Sclerosis from Smartphone Data",
      "abstract": "Multiple sclerosis (MS) affects the central nervous system with a wide range of symptoms. MS can, for example, cause pain, changes in mood and fatigue, and may impair a person's movement, speech and visual functions. Diagnosis of MS typically involves a combination of complex clinical assessments and tests to rule out other diseases with similar symptoms. New technologies, such as smartphone monitoring in free-living conditions, could potentially aid in objectively assessing the symptoms of MS by quantifying symptom presence and intensity over long periods of time. Here, we present a deep-learning approach to diagnosing MS from smartphone-derived digital biomarkers that uses a novel combination of a multilayer perceptron with neural soft attention to improve learning of patterns in long-term smartphone monitoring data. Using data from a cohort of 774 participants, we demonstrate that our deep-learning models are able to distinguish between people with and without MS with an area under the receiver operating characteristic curve of 0.88 (95% CI: 0.70, 0.88). Our experimental results indicate that digital biomarkers derived from smartphone data could in the future be used as additional diagnostic criteria for MS.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Patrick Schwab et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2020.3021143",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3163501241",
      "doi": "10.1109/access.2021.3081749",
      "title": "Knowledge of and Competence in Artificial Intelligence: Perspectives of Vietnamese Digital-Native Students",
      "abstract": "Artificial Intelligence (AI) and related technologies have been employed to simulate human decision-making processes to improve people&#x2019;s lives. Accordingly, AI knowledge and related competence are crucial, especially for students pursuing information technology (IT) and computer-related degrees, since they will eventually be the next generation of AI designers or users. While the importance of AI technology and its applications have been widely discussed and explored, AI technology in Vietnam is in a nascent stage due to the shortage of skilled experts and the reluctance to adopt AI applications by businesses. Thus, the primary objective of this study was to explore the knowledge of and competence in AI among Vietnamese university IT students. A total of 206 university students from software engineering and computer science programs participated in this study. The results indicate the need for a focused effort to establish a strong foundation for a comprehensive and accessible AI mandatory course plan for IT students.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Pei\u2010Ju Chao et al.",
      "keywords": "Vietnamese; Computer science; Competence (human resources); Applications of artificial intelligence; Economic shortage; Artificial intelligence; Knowledge management; Engineering management; Data science; Engineering; Psychology; Government (linguistics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3081749",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4319303099",
      "doi": "10.1109/ojsp.2023.3242862",
      "title": "Hierarchical Multi-Class Classification of Voice Disorders Using Self-Supervised Models and Glottal Features",
      "abstract": "Previous studies on the automatic classification of voice disorders have mostly investigated the binary classification task, which aims to distinguish pathological voice from healthy voice. Using multi-class classifiers, however, more fine-grained identification of voice disorders can be achieved, which is more helpful for clinical practitioners. Unfortunately, there is little publicly available training data for many voice disorders, which lowers the classification performance on data from unseen speakers. Earlier studies have shown that the usage of glottal source features can reduce data redundancy in detection of laryngeal voice disorders. Another approach to tackle the problems caused by scarcity of training data is to utilize deep learning models, such as wav2vec 2.0 and HuBERT, that have been pre-trained on larger databases. Since the aforementioned approaches have not been thoroughly studied in the multi-class classification of voice disorders, they will be jointly studied in the present work. In addition, we study a hierarchical classifier, which enables task-wise feature optimization and more efficient utilization of data. In this work, the aforementioned three approaches are compared with traditional mel frequency cepstral coefficient (MFCC) features and one-vs-rest and one-vs-one SVM classifiers. The results in a 3-class classification problem between healthy voice and two laryngeal disorders (hyperfunctional dysphonia and vocal fold paresis) indicate that all the studied methods outperform the baselines. The best performance was achieved by using features from wav2vec 2.0 LARGE together with hierarchical classification. The balanced classification accuracy of the system was 62.77% for male speakers, and 55.36% for female speakers, which outperformed the baseline systems by an absolute improvement of 15.76% and 6.95% for male and female speakers, respectively.",
      "year": "2023",
      "journal": "IEEE Open Journal of Signal Processing",
      "authors": "Saska Tirronen et al.",
      "keywords": "Computer science; Support vector machine; Classifier (UML); Binary classification; Voice Disorder; Speech recognition; Artificial intelligence; Mel-frequency cepstrum; Pattern recognition (psychology); Machine learning; Feature extraction; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojsp.2023.3242862",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3115542268",
      "doi": "10.1109/access.2020.3045906",
      "title": "Automatic Deep Learning Semantic Segmentation of Ultrasound Thyroid Cineclips Using Recurrent Fully Convolutional Networks",
      "abstract": "Medical segmentation is an important but challenging task with applications in standardized report generation, remote medicine and reducing medical exam costs by assisting experts. In this paper, we exploit time sequence information using a novel spatio-temporal recurrent deep learning network to automatically segment the thyroid gland in ultrasound cineclips. We train a DeepLabv3+ based convolutional LSTM model in four stages to perform semantic segmentation by exploiting spatial context from ultrasound cineclips. The backbone DeepLabv3+ model is replicated six times and the output layers are replaced with convolutional LSTM layers in an atrous spatial pyramid pooling configuration. Our proposed model achieves mean intersection over union scores of 0.427 for cysts, 0.533 for nodules and 0.739 for thyroid. We demonstrate the potential application of convolutional LSTM models for thyroid ultrasound segmentation.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jeremy Webb et al.",
      "keywords": "Computer science; Artificial intelligence; Segmentation; Pooling; Convolutional neural network; Deep learning; Context (archaeology); Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3045906",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293370590",
      "doi": "10.1109/access.2022.3202295",
      "title": "Hepatitis C Virus Detection Model by Using Random Forest, Logistic-Regression and ABC Algorithm",
      "abstract": "This study proposes an automatic classifier for detecting the multiclass probabilities of hepatitis C virus (HCV) incidence based on patients&#x2019; blood attributes. The purpose of this study is to establish an artificial intelligence-based model that can identify HCV patients and detect the disease in early stage for future treatments. This model can be applied by using clinical data and keeps the performance from imbalanced datasets. The innovation in this article lies in considering the &#x201C;unbalanced data&#x201D; existing in medical record-based clinical data. Synthetic minority oversampling technique (SMOTE) algorithm was further employed to derive corresponding solutions. This objective was achieved using a cascade two-stage method combining the random forest (RF) and logistic regression (LR) algorithms. Two models were trained by applying the RF (Model 1) and LR (Model 2) to raw and preprocessed data, respectively. The artificial bee colony (ABC) algorithm was then used to determine the optimal threshold value required for filtering and separation, that is, the optimal combination of both models. The two-stage mixing algorithm combines algorithms of different search dimensions, thus integrating the strengths of those algorithms. The critical threshold value for separating Model 1 and Model 2 was obtained through an optimized search using the ABC algorithm. After conducting 10-fold Monte Carlo cross-validation experiments 50 times (for mean values), data from the recent pandemic were used to verify the proposed method. To evaluate the quantitative results, indicators, such as prediction accuracy, precision, recall, F1-score, and Matthews correlation coefficient, were compared with those of the latest algorithms used in relevant fields. The results indicate that the proposed model, named Cascade RF-LR (with SMOTE), can be used to detect the multiclass probabilities of HCV incidence using the ABC algorithm, thereby improving the effectiveness of relevant treatments.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Tzuu\u2010Hseng S. Li et al.",
      "keywords": "Random forest; Algorithm; Computer science; Artificial intelligence; Support vector machine; Receiver operating characteristic; Logistic regression; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3202295",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3204201789",
      "doi": "10.1109/access.2021.3117578",
      "title": "Multi-Scale Fusion U-Net for the Segmentation of Breast Lesions",
      "abstract": "Breast lesion is a malignant tumor that occurs in the epithelial tissue of the breast. The early detection of breast lesions can make patients for treatment and improve survival rate. Thus, the accurate and automatic segmentation of breast lesions from ultrasound images is a fundamental task. However, the effectively segmentation of breast lesions is still faced with two challenges. One is the characteristics of breast lesions&#x2019; multi-scale and the other one is blurred edges making segmentation difficult. To solve these problems, we propose a deep learning architecture, named Multi-scale Fusion U-Net (MF U-Net), which extracts the texture features and edge features of the image. It includes two novel modules and a new focal loss: 1) the Fusion Module (WFM) which segmenting irregular and fuzzy breast lesions, 2) the Multi-Scale Dilated Convolutions Module (MDCM) which overcoming the segmentation difficulties caused by large-scale changes in breast lesions, and 3) focal-DSC loss is proposed to solve the class imbalance problems in breast lesions segmentation. Moreover, there are some convolutional layers with different receptive fields in MDCM, which improves the network&#x2019;s ability to extract multi-scale features. Comparative experiments reveal that the MF U-Net proposed in this paper outperforms other segmentation methods, and the proposed MF U-Net achieves state-of-the-art breast lesions segmentation results with 0.9421 Recall, 0.9345 Precision, 0.0694 FPs/image, 0.9535 DSC and 0.9112 IOU on Benchmark for Breast Ultrasound Image Segmentation (BUSIS) dataset.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Jingyao Li et al.",
      "keywords": "Segmentation; Artificial intelligence; Computer science; Pattern recognition (psychology); Convolutional neural network; Breast ultrasound; Image segmentation; Benchmark (surveying); Deep learning; Computer vision; Breast cancer; Mammography; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3117578",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2914342622",
      "doi": "10.1109/access.2019.2897078",
      "title": "Analytics of Heterogeneous Breast Cancer Data Using Neuroevolution",
      "abstract": "Breast cancer prognostic modeling is difficult since it is governed by many diverse factors. Given the low median survival and large scale breast cancer data, which comes from high throughput technology, the accurate and reliable prognosis of breast cancer is becoming increasingly difficult. While accurate and timely prognosis may save many patients from going through painful and expensive treatments, it may also help oncologists in managing the disease more efficiently and effectively. Data analytics augmented by machine-learning algorithms have been proposed in past for breast cancer prognosis; and however, most of these could not perform well owing to the heterogeneous nature of available data and model interpretability related issues. A robust prognostic modeling approach is proposed here whereby a Pareto optimal set of deep neural networks (DNNs) exhibiting equally good performance metrics is obtained. The set of DNNs is initialized and their hyperparameters are optimized using the evolutionary algorithm, NSGAIII. The final DNN model is selected from the Pareto optimal set of many DNNs using a fuzzy inferencing approach. Contrary to using DNNs as the black box, the proposed scheme allows understanding how various performance metrics (such as accuracy, sensitivity, F1, and so on) change with changes in hyper-parameters. This enhanced interpretability can be further used to improve or modify the behavior of DNNs. The heterogeneous breast cancer database requires preprocessing for better interpretation of categorical variables in order to improve prognosis from classifiers. Furthermore, we propose to use a neural network-based entity-embedding method for categorical features with high cardinality. This approach can provide a vector representation of categorical features in multidimensional space with enhanced interpretability. It is shown with evidence that DNNs optimized using evolutionary algorithms exhibit improved performance over other classifiers mentioned in this paper.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Beibit Abdikenov et al.",
      "keywords": "Interpretability; Computer science; Machine learning; Categorical variable; Artificial intelligence; Artificial neural network; Breast cancer; Set (abstract data type); Data mining; Cancer",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2897078",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4295308659",
      "doi": "10.1109/access.2022.3203973",
      "title": "Parkinson\u2019s Disease Detection Using Smartphone Recorded Phonemes in Real World Conditions",
      "abstract": "Parkinson&#x2019;s disease (PD) is a multi-symptom neurodegenerative disease. There are no biomarkers; the diagnosis and monitoring of the disease progression require clinical and functional symptom observation. Voice impairment is an early symptom of PD, and computerized analysis of voice has been proposed for early detection and monitoring of the disease. However, there is poor reproducibility of many studies, which is attributed to the experimental data having been collected under controlled conditions. To overcome the limitations of earlier works, this study has investigated three sustained phonemes: /a/, /o/, and /m/, which were recorded using an iOS-based smartphone from 72 participants (36 people with PD and 36 healthy) in a typical clinical setting. A number of signal features were obtained, statistically investigated, and ranked to identify the suitable feature sets. These were classified using machine learning models. The results show that a combination of phonemes /a/&#x002B;/o/&#x002B;/m/ was most suited to differentiate the voice of PD people from healthy control participants, with an average accuracy, sensitivity, and specificity of 100&#x0025;, 100&#x0025;, 100&#x0025;, respectively, using leave-one-out validation. The findings of this study could assist in the clinical assessments and remote telehealth monitoring for people with parkinsonian dysarthria using smartphones.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Mohammod Abdul Motin et al.",
      "keywords": "Dysarthria; Telehealth; Parkinson's disease; Disease; Audiology; Medicine; Smartphone app; Computer science; Physical medicine and rehabilitation; Telemedicine; Speech recognition; Internal medicine; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3203973",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205221301",
      "doi": "10.1109/access.2022.3143990",
      "title": "Unsupervised Deep Learning to Detect Agitation From Videos in People With Dementia",
      "abstract": "Behavioural symptoms of dementia present a significant risk within Long Term Care (LTC) homes, which face difficulties supporting residents and monitoring their safety with limited staffing resources. Many LTC facilities have installed video surveillance systems in common areas that can help staff to observe residents; however, typically these video streams are not monitored. In this paper, we present the development of a computer vision algorithm to use these video streams to detect episodes of clinically important agitation in people with dementia. Given that episodes of agitation are rare in comparison to normal behaviours, we formulated this as an anomaly detection problem. This involves using the video camera to monitor the scene rather than tracking individuals. We developed a customized spatio-temporal convolution autoencoder that is trained on the normal behaviours and then identified agitation during testing as anomalous behaviour. We present a proof-of-concept using video data collected from a specialized dementia unit and annotated for agitation events. We trained the unsupervised neural network on approximately 24 hours of normal activities and tested on 11 hours of videos containing both normal activities and agitation events, and obtained an area under the curve of the receiver operating characteristic curve of 0.754. This research paves the way for leveraging existing surveillance infrastructure in LTC and other mental health settings to detect agitation or aggression, with the potential for improved health and safety.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Shehroz S. Khan et al.",
      "keywords": "Dementia; Computer science; Autoencoder; Delirium; Artificial intelligence; Deep learning; Unsupervised learning; Convolutional neural network; Staffing; Machine learning; Medicine; Psychiatry; Nursing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3143990",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2979651045",
      "doi": "10.1109/access.2019.2946932",
      "title": "Localization of Myocardial Infarction With Multi-Lead Bidirectional Gated Recurrent Unit Neural Network",
      "abstract": "Myocardial infarction (MI) is an acute disease. Early detection and early treatment are of great significance for improving the health of people. In order to reduce the misdiagnosis rate of MI diseases, this paper proposes a multi-lead bidirectional gated recurrent unit neural network (ML-BiGRU) learning algorithm based on current research status in the field of intelligent medical diagnosis, combined with the timing and multi-lead correlation characteristics of the electrocardiogram (ECG) signals. At first, the original ECG signal is denoised and preprocessed and then segmented into heartbeats. After that, the heartbeat sequence is sent to the deep neural network training model to learn the classification. Lastly, the Physikalisch-Technische Bundesanstalt (PTB) ECG database is used to verify the multi-lead BiGRU algorithm. The verification results demonstrate that the accuracy of the algorithm for MI localization is 99.84%, which outperform the other algorithms. The experimental results also show that the algorithm is obviously superior to the traditional localization algorithm in improving the localization accuracy, which is of great significance for improving the correct diagnosis rate of MI.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Xingjin Zhang et al.",
      "keywords": "Heartbeat; Computer science; Artificial intelligence; Artificial neural network; Pattern recognition (psychology); Deep learning; Lead (geology); Myocardial infarction; Medicine; Cardiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2946932",
      "cited_by_count": 37,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3147957034",
      "doi": "10.1109/access.2021.3068896",
      "title": "LDNNET: Towards Robust Classification of Lung Nodule and Cancer Using Lung Dense Neural Network",
      "abstract": "Lung nodule classification plays an important role in diagnosis of lung cancer which is essential to patients&#x2019; survival. However, because the number of lung CT images in current dataset is relatively small and the ratio of nodule samples to non-nodule samples is usually very different, this makes the training of neural networks difficult and poor performance of neural networks. Hence, LDNNET is proposed, which adopts Dense-Block, batch normalization (BN) and dropout to cope with these problems. Meanwhile, LDNNET is an adaptive architecture based on convnets combining softmax classifier which is utilized to alleviate the problems of training deep convnets. Follows are our main work: Firstly, we utilized LDNNET on database LUng Nodule Analysis 2016 (LUNA16) for lung nodule classification and database KAGGLE DATA-SCIENCE-BOWL-2017(Kaggle DSB 2017) for lung cancer classification; Secondly, the comparison experiments are designed to compare the performance of dense connection, pooling layer and the input pixel size of lung CT(Computed Tomography) images; Thirdly, data enhancement, dense connection and dropout layer were utilized in LDNNET to reduce overfitting; Fourthly, pre-processing methods, for instance enhanced contrast, median filtering, Laplacian filtering are compared to the no-processing method to explore the effect of pre-processing on lung CT images classification. Fifthly, accuracy, specificity and sensitivity on LUNA16 are 0.988396, 0.994585 and 0.982072 and these indicators on Kaggle DSB 2017 are 0.999480, 0.999652 and 0.998974. Furthermore, AUC for both two datasets is over 0.98. Consequently, this paper conducts experiments with uniform parameter settings on two publicly available databases and shows that even in challenging situation where lung images are directly utilized as input images without preprocessing, LDNNET is still the more advanced algorithm than other recent algorithms respectively. Moreover, a series of comparative experiments were conducted to further confirm that the proposed algorithm has the higher accuracy and robustness through verification and discussion.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Ying Chen et al.",
      "keywords": "Computer science; Artificial intelligence; Softmax function; Pattern recognition (psychology); Normalization (sociology); Pooling; Dropout (neural networks); Lung cancer; Overfitting; Nodule (geology); Artificial neural network; Convolutional neural network; Machine learning; Medicine; Pathology; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3068896",
      "cited_by_count": 55,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4214946447",
      "doi": "10.1109/access.2022.3156607",
      "title": "IoT-Based Unobtrusive Physical Activity Monitoring System for Predicting Dementia",
      "abstract": "Mental health-related disorders are common in elderly populations. Among the various mental health disorders, one most significant threat is dementia, and prediction of dementia has become an important issue related to well-being in old age, because the disease progression of dementia can be slowed by early diagnosis and disease control. In this paper, we propose an unobtrusive dementia-prediction system for monitoring physical activities of elderly persons either living alone or as a couple in different house structures, achieved through passive infrared (PIR) motion sensors combined with data processing. The proposed feature extraction algorithm extracts feature values related to physical activities from simple passive infrared sensors located in each room space. We then apply a variety of common popular classification models, including Deep Neural Networks (DNNs), to predict the risk of dementia in a sensor-enabled home. We implemented and validated algorithms on data collected for over a month from 18 participants who were engaged with a variety of living conditions. The proposed system was effective in predicting dementia risk, with up to an 0.99 area under the curve (AUC) using DNN with principal component analysis (PCA) and a quantile transformer scaler. In terms of the result based on leave-one-subject-out (LOSO) analysis, an accuracy of 63.38&#x0025; was achieved using DNN with PCA and a standard scaler. The proposed methodology is non-invasive and cost-effective, and can be used for a variety of long-term monitoring and early symptom detection systems, helping caregivers provide optimal interventions to elderly individuals at risk for dementia.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Jungyoon Kim et al.",
      "keywords": "Dementia; Computer science; Feature extraction; Artificial intelligence; Principal component analysis; Machine learning; Disease; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3156607",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4212848258",
      "doi": "10.1109/access.2022.3151900",
      "title": "Adverse Drug Reaction Detection From Social Media Based on Quantum Bi-LSTM With Attention",
      "abstract": "Drug combination is very common in the course of disease treatment. However, it inevitably increases the overall risk of adverse drug reactions (ADRs). It is very important to early and accurately detect and identify the potential ADRs for combined medication safety and public health. Social media is an important pharmacovigilance data source for ADR detection. But the data are complex, mass, clutter, highly sparse, so it is difficult to detect the ADR information from these data. Deep learning stands out in terms of increased accuracy. However, it takes a lot of training time and requires a lot of computing power. Quantum computing has strong parallel computing capability, and requires less computing power. By introducing attention mechanism and quantum computing into Bi-directional Long Short-Term Memory (Bi-LSTM), a quantum Bi-LSTM with attention (QBi-LSTMA) model is constructed for ADR detection from social media big data. QBi-LSTMA is composed of 6 variable component subcircuits (VQC) stacked. Under the condition that the main topology of Bi-LSTM remains unchanged, the biases of QBi-LSTMA in input gate, forgetting gate, candidate memory unit and output gate are removed to simplify the network structure, and the weight and active value qubits of the model are used to update the network weight. The performance of the proposed method is evaluated on the SMM4H dataset, comparing with one traditional ADR detection method and three deep learning based ADR detection approaches. The experiment results show that the proposed method has great potential in ADR detection.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Xuqi Wang et al.",
      "keywords": "Computer science; Deep learning; Artificial intelligence; Pharmacovigilance; Quantum computer; Forgetting; Big data; Quantum; Machine learning; Data mining; Drug; Medicine; Pharmacology; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3151900",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3097744988",
      "doi": "10.1109/access.2020.3030787",
      "title": "Automated Pterygium Detection Using Deep Neural Network",
      "abstract": "Ocular imaging has developed rapidly and plays a critical role in clinical care and ocular disease management. Development of image processing technologies pertinent to ocular diseases has paved the way for automated diagnostic systems including detection techniques using deep learning (DL) approaches. The prevalence of an abnormal tissue layer in the conjunctiva, known as pterygium eye disease, is increasing due to lack of awareness. Despite the non-cancerous/benign nature of pterygium, a clinical diagnosis from an ophthalmologist is still required to prevent the pterygium tissues from extending into the pupil, which would result in blurred vision. However, current diagnostic methods are mostly dependent on human expertise. Automated detection can potentially serve as an assistive method to reduce diagnosis time by applying a DL approach. Considering the lack of comprehensive research work on pterygium detection using DL, we propose a new architecture consisting of an improved CNN-based trained network named VggNet16-wbn that is derived from VggNet16, a pre-trained CNN algorithm. This paper presents an overview of the DL as a core approach to the transfer learning (TL) concept, as well as current efforts towards automated ocular detection approaches. A new architecture of a CNN-based trained network was proposed based on a network assessment from six CNN pre-trained networks to detect pterygium. This work consists of two main modules, namely, data acquisition and DCNN classification. The proposed trained network, VggNet16-wbn, shows the best performance with 99.22% accuracy, 98.45% sensitivity, and a perfect score on specificity and area under the curve metrics. This work has high potential for creating a pterygium screening system that can be used as a baseline for fully automated detection using a DL approach.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Nurul Syahira Mohamad Zamani et al.",
      "keywords": "Pterygium; Computer science; Artificial intelligence; Deep learning; Convolutional neural network; Transfer of learning; Artificial neural network; Image processing; Architecture; Machine learning; Computer vision; Pattern recognition (psychology); Image (mathematics); Medicine; Ophthalmology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3030787",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386472969",
      "doi": "10.1109/access.2023.3312537",
      "title": "Feature Selection Using Selective Opposition Based Artificial Rabbits Optimization for Arrhythmia Classification on Internet of Medical Things Environment",
      "abstract": "An Electrocardiogram (ECG) is a non-invasive test that is broadly utilized for monitoring and diagnosing the cardiac arrhythmia. An irregularity of the heartbeat is generally defined as arrhythmia, which potentially causes the fatal difficulties that creates an instantaneous life risk. Therefore, the arrhythmia classification is a challenging task because of the overfitting issue caused by high dimensional feature space of ECG signal. In this research, the incorporation of the Internet of Medical Things (IoMT) is developed with artificial intelligence to provide the health monitoring for people who are having arrhythmia. In this work, the time, time-frequency, entropy, nonlinearity features of ECG and deep features of ECG from Convolutional Neural Network (CNN) are extracted to obtain different categories of ECG signal features. The Selective Opposition (SO) strategy based Artificial Rabbits Optimization (SOARO) is proposed for selecting the optimal feature subset from the overall features to avoid the overfitting issue. The chosen features are used to improve the classification done by Auto Encoder (AE). Further, the Shapley additive explanations (SHAP) based model is used to interpret the classified output from AE. The MIT-BIH arrhythmia database is used for evaluating the proposed SOARO-AE. The performance of the proposed SOARO-AE is evaluated by using the accuracy, sensitivity, specificity, recall and F1-Measure. The existing researches such as C-LSTM, DL-LAC-CNN, CNN-DNN, MC-ECG, FC and MEAHA-CNN are used to evaluate the SOARO-AE method. The accuracy of SOARO-AE is 98.89&#x0025; which is high when compared to the C-LSTM, DL-LAC-CNN, CNN-DNN, FC and MEAHA-CNN.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "G S Nijaguna et al.",
      "keywords": "Overfitting; Artificial intelligence; Computer science; Pattern recognition (psychology); Convolutional neural network; Feature selection; Cardiac arrhythmia; Deep learning; Entropy (arrow of time); Artificial neural network; Machine learning; Feature extraction; Autoencoder",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312537",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323897057",
      "doi": "10.1109/access.2023.3255403",
      "title": "Interpretable Classification of Pneumonia Infection Using eXplainable AI (XAI-ICP)",
      "abstract": "Open-box models in the medical domain have high acceptance and demand by many medical examiners. Even though the accuracy predicted by most of convolutional neural network (CNN) models is high, it is still not convincing as the detailed discussion regarding the outcome is semi-transparent in the functioning process. Pneumonia is known as one of the top contagious infections that makes most of the population affected due to low immunity. Therefore, the goal of this paper is to implement an interpretable classification of pneumonia infection using eXplainable AI (XAI-ICP). Thus, XAI-ICP is the highly efficient system designed to solve this challenge by adapting to the recent population health conditions. The aim is to design an interpretable deep classification and transfer learning based evaluation for pneumonia infection classification. The model is primarily pre-trained using the open Chest X-Ray (CXR) dataset from National Institutes of Health (NIH). Whereas, the training input and testing given to this system is Taichung Veterans General Hospital (TCVGH) for independent learning, Taiwan &#x002B; VinDr open dataset for transfer learning of pneumonia affected patients with labeled CXR images possessing three features of infiltrate, cardiomegaly and effusion. The data labeling is performed by the medical examiners with the XAI human-in-the-loop approach. XAI-ICP demonstrates the XAI based reconfigurable DCNN with human-in-the-loop as a novel approach. The interpretable deep classification provides detailed transparency analysis and transfer learning for competitive accuracy. The purpose of this work, to design a re-configurable model that can continuously improve itself by using a feedback system and provide feasibility for the model deployment across multiple countries to provide an efficient system for the pneumonia infection classification. The designed model then provides detailed decisions taken at each step as transparency and features used within the algorithm for the pneumonia classification during the hospitalization. Thus, the scope can be given as explainable AI usage for the diagnosis classification using data preprocessing and interpretable deep convolutional neural network by the CXR evaluation. The accuracy achieved by using independent learning classification is 92.14&#x0025; and is further improved based on successive transfer learning based evaluation is 93.29&#x0025;. The XAI-ICP model adapts to the different populations by using transfer learning, while providing competitive results to the affected conditions.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ruey\u2010Kai Sheu et al.",
      "keywords": "Computer science; Transfer of learning; Artificial intelligence; Convolutional neural network; Deep learning; Pneumonia; Population; Machine learning; Process (computing); Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3255403",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313387440",
      "doi": "10.1109/taslp.2022.3212829",
      "title": "Automatic Assessment of Parkinson's Disease Using Speech Representations of Phonation and Articulation",
      "abstract": "Speech from people with Parkinson's disease (PD) are likely to be degraded on phonation, articulation, and prosody. Motivated to describe articulation deficits comprehensively, we investigated 1) the universal phonological features that model articulation manner and place, also known as speech attributes, and 2) glottal features capturing phonation characteristics. These were further supplemented by, and compared with, prosodic features using a popular compact feature set and standard MFCC. Temporal characteristics of these features were modeled by convolutional neural networks. Besides the features, we were also interested in the speech tasks for collecting data for automatic PD speech assessment, like sustained vowels, text reading, and spontaneous monologue. For this, we utilized a recently collected Finnish PD corpus (PDSTU) as well as a Spanish database (PC-GITA). The experiments were formulated as regression problems against expert ratings of PD-related symptoms, including ratings of speech intelligibility, voice impairment, overall severity of communication disorder on PDSTU, as well as on the Unified Parkinson's Disease Rating Scale (UPDRS) on PC-GITA. The experimental results show: 1) the speech attribute features can well indicate the severity of pathologies in parkinsonian speech; 2) combining phonation features with articulatory features improves the PD assessment performance, but requires high-quality recordings to be applicable; 3) read speech leads to more accurate automatic ratings than the use of sustained vowels, but not if the amount of speech is limited to correspond to the sustained vowels in duration; and 4) jointly using data from several speech tasks can further improve the automatic PD assessment performance.",
      "year": "2022",
      "journal": "IEEE/ACM Transactions on Audio Speech and Language Processing",
      "authors": "Yuanyuan Liu et al.",
      "keywords": "Phonation; Prosody; Speech recognition; Intelligibility (philosophy); Articulation (sociology); Computer science; Feature (linguistics); Speech disorder; Psychology; Artificial intelligence; Audiology; Medicine; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taslp.2022.3212829",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3128321165",
      "doi": "10.1109/access.2021.3057715",
      "title": "Smartphone Speech Testing for Symptom Assessment in Rapid Eye Movement Sleep Behavior Disorder and Parkinson\u2019s Disease",
      "abstract": "Speech impairment in Parkinson\u2019s Disease (PD) has been extensively studied. Our understanding of speech in people who are at an increased risk of developing PD is, however, rather limited. It is known that isolated Rapid Eye Movement (REM) sleep Behavior Disorder (RBD) is associated with a high risk of developing PD. The aim of this study is to investigate smartphone speech testing to: (1) distinguish participants with RBD from controls and PD, and (2) predict a range of self- or researcher-administered clinical scores that quantify participants\u2019 motor symptoms, cognition, daytime sleepiness, depression, and the overall state of health. The rationale of our analyses is to test an initial hypothesis that speech can be used to detect and quantify the symptoms associated with RBD and PD. We analyzed 4242 smartphone voice recordings collected in clinic and at home from 92 Controls, 112 RBD and 335 PD participants. We used acoustic signal analysis and machine learning, employing 337 features that quantify different properties of speech impairment. Using a leave-one-subject-out cross-validation scheme, we were able to distinguish RBD from controls (sensitivity 60.7%, specificity 69.6%) and RBD from PD participants (sensitivity 74.9%, specificity 73.2%), and predict clinical assessments with clinically useful accuracy. These promising findings warrant further investigation in using speech as a digital biomarker for PD and RBD to facilitate intervention in the early and prodromal stages of PD.\\n",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Siddharth Arora et al.",
      "keywords": "Audiology; Eye movement; Disease; Parkinson's disease; REM sleep behavior disorder; Medicine; Physical medicine and rehabilitation; Psychology; Internal medicine; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3057715",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3081473229",
      "doi": "10.1109/access.2020.3019491",
      "title": "Suicidal Ideation Cause Extraction From Social Texts",
      "abstract": "Suicide has become a major public health and social concern in the world. Suicidal ideation cause extraction (SICE) in social texts can provide support for suicide prevention. This article summarizes the research on suicidal ideation causes (SICs) through the use of psychological and sociological analysis. Then, a social text-based SIC dataset is constructed and analyzed statistically for various features. A CRF model is provided along with Char-BiLSTM-CRF, which uses concatenation of word embeddings and character embeddings as word representation inputs. Then, the effects on the task are explored by the word (W), part of speech (POS), dependence relationship (DP), suicidal psychology (PCS), emotion (ET), and language (LG) features in the CRF model. The experiment shows that the word features worked best. POS and DP can be somehow covered by word features. PCS, ET and LG features can improve the effect of SICE. It also shows that Char-BiLSTM-CRF is better than CRF in general, but CRF still has advantages in terms of precision. Adding character embeddings and CRF layers can significantly improve the extraction using Char-BiLSTM-CRF. The experiment also compared three-word embeddings with Word2vec, ELMo and BERT. Compared with Word2vec, the F-value of ELMo is increased by approximately 5% on average, and compared with ELMo, the C_F and E_F of BERT are increased by 3.5% and 2.3%, respectively. Finally, the challenge of SICE is discussed based on the experimental results of Char-BiLSTM-CRF.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Dexi Liu et al.",
      "keywords": "Word2vec; Concatenation (mathematics); Suicidal ideation; Character (mathematics); Word (group theory); Natural language processing; Computer science; Char; Artificial intelligence; Psychology; Speech recognition; Poison control; Mathematics; Medicine; Suicide prevention; Combinatorics; Medical emergency; Chemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3019491",
      "cited_by_count": 30,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390204163",
      "doi": "10.1109/tnsre.2023.3346955",
      "title": "B2-ViT Net: Broad Vision Transformer Network With Broad Attention for Seizure Prediction",
      "abstract": "Seizure prediction are necessary for epileptic patients. The global spatial interactions among channels, and long-range temporal dependencies play a crucial role in seizure onset prediction. In addition, it is necessary to search for seizure prediction features in a vast space to learn new generalized feature representations. Many previous deep learning algorithms have achieved some results in automatic seizure prediction. However, most of them do not consider global spatial interactions among channels and long-range temporal dependencies together, and only learn the feature representation in the deep space. To tackle these issues, in this study, an novel bi-level programming seizure prediction model, B2-ViT Net, is proposed for learning the new generalized spatio-temporal long-range correlation features, which can characterize the global interactions among channels in spatial, and long-range dependencies in temporal required for seizure prediction. In addition, the proposed model can comprehensively learn generalized seizure prediction features in a vast space due to its strong deep and broad feature search capabilities. Sufficient experiments are conducted on two public datasets, CHB-MIT and Kaggle datasets. Compared with other existing methods, our proposed model has shown promising results in automatic seizure prediction tasks, and provides a certain degree of interpretability.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Shuiling Shi et al.",
      "keywords": "Interpretability; Computer science; Artificial intelligence; Feature (linguistics); Machine learning; Deep learning; Correlation; Range (aeronautics); Feature learning; Pattern recognition (psychology); Data mining; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3346955",
      "cited_by_count": 56,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285281980",
      "doi": "10.1109/access.2022.3182543",
      "title": "Machine Learning Approaches and Applications in Genome Wide Association Study for Alzheimer\u2019s Disease: A Systematic Review",
      "abstract": "Machine learning algorithms have been used for detection (and possibly) prediction of Alzheimer\u2019s disease using genotype information, with the potential to enhance the outcome prediction. However, detailed research about the analysis and the detection of Alzheimer\u2019s disease using genetic data is still in its primitive stage. The aim of this paper was to evaluate the scientific literature on the use of various machine learning approaches for the prediction of Alzheimer\u2019s disease based solely on genetic data. To identify gaps in the literature, critically appraise the reporting and methods of the algorithms, and provide the foundation for a wider research programme focused on developing novel machine learning based predictive algorithms in Alzheimer\u2019s disease. A systematic review of quantitative studies was conducted using three search engines (PubMed, Web of Science and Scopus), and included studies between 1st of January 2010 and 31st December 2021. Keywords used were \u2018Alzheimer\u2019s disease(s)\u2019, \u2018GWAS, \u2018Artificial intelligence\u2019 and their synonyms. After applying the inclusion/exclusion criteria, 24 studies were included. Machine learning methods in the reviewed papers performed in a wide range of ways (0.59 to 0.98 AUC). The main findings showed that high risk of bias in the analysis can be linked to feature selection, hyperparameter search and validation methods.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Abbas Saad Alatrany et al.",
      "keywords": "Machine learning; Artificial intelligence; Computer science; Scopus; Random forest; Disease; Feature selection; Systematic review; Artificial neural network; MEDLINE; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3182543",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2771336279",
      "doi": "10.1109/jtehm.2018.2881468",
      "title": "High-Resolution Cervical Auscultation Signal Features Reflect Vertical and Horizontal Displacements of the Hyoid Bone During Swallowing",
      "abstract": "Millions of people across the globe suffer from swallowing difficulties, known as dysphagia, which can lead to malnutrition, pneumonia, and even death. Swallowing cervical auscultation, which has been suggested as a noninvasive screening method for dysphagia, has not been associated yet with any physical events. In this paper, we have compared the hyoid bone displacement extracted from the videofluoroscopy images of 31 swallows to the signal features extracted from the cervical auscultation recordings captured with a tri-axial accelerometer and a microphone. First, the vertical displacement of the anterior part of the hyoid bone is related to the entropy rate of the superior-inferior swallowing vibrations and to the kurtosis of the swallowing sounds. Second, the vertical displacement of the posterior part of the hyoid bone is related to the bandwidth of the medial-lateral swallowing vibrations. Third, the horizontal displacements of the posterior and anterior parts of the hyoid bone are related to the spectral centroid of the superior-inferior swallowing vibrations and to the peak frequency of the medial-lateral swallowing vibrations, respectively. At last, the airway protection scores and the command characteristics were associated with the vertical and horizontal displacements, respectively, of the posterior part of the hyoid bone. Additional associations between the patients' characteristics and auscultations' signals were also observed. The hyoid bone maximal displacement is a cause of swallowing vibrations and sounds. High-resolution cervical auscultation may offer a noninvasive alternative for dysphagia screening and additional diagnostic information.",
      "year": "2018",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Cedrine Rebrion et al.",
      "keywords": "Hyoid bone; Swallowing; Auscultation; Anatomy; Orthodontics; Cervical vertebrae; Geology; Medicine; Computer science; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2018.2881468",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387272109",
      "doi": "10.1109/jsyst.2023.3317504",
      "title": "Integrating Physical and Cognitive Interaction Capabilities in a Robot-Aided Rehabilitation Platform",
      "abstract": "The communication channels between physiotherapists and patients are many and varied. Rehabilitation robots are able to deliver intensive treatments and improve the patient's quality of life. However, rehabilitation robots in the literature do not integrate physical manipulation with natural verbal communication yet. This article proposes an innovative integrated system for motor rehabilitation based on the combination of physical and cognitive components to emulate the natural interaction between physiotherapists and patients. The proposed approach was validated in a laboratory setting with 20 healthy subjects. The cognitive system's ability to interact linguistically as well as the participants' kinematic performance and the emotional impact generated by two different robotic systems were assessed. The former integrates advanced linguistic capabilities and the latter lacks any verbal communication. The results showed that the presence of linguistic interaction promotes the quality of interaction, leading to improvements both in the execution of movements and in emotional terms.",
      "year": "2023",
      "journal": "IEEE Systems Journal",
      "authors": "Christian Tamantini et al.",
      "keywords": "Rehabilitation; Human\u2013computer interaction; Cognition; Robot; Kinematics; Computer science; Quality (philosophy); Cyber-physical system; Human\u2013robot interaction; Physical medicine and rehabilitation; Psychology; Artificial intelligence; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsyst.2023.3317504",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226084584",
      "doi": "10.1109/tnsre.2022.3163777",
      "title": "Assessing Schizophrenia Patients Through Linguistic and Acoustic Features Using Deep Learning Techniques",
      "abstract": "Thought, language, and communication disorders are among the salient characteristics of schizophrenia. Such impairments are often exhibited in patients' conversations. Researches have shown that assessments of thought disorder are crucial for tracking the clinical patients' conditions and early detection of clinical high-risks. Detecting such symptoms require a trained clinician's expertise, which is prohibitive due to cost and the high patient-to-clinician ratio. In this paper, we propose a machine learning method using Transformer-based model to help automate the assessment of the severity of the thought disorder of schizophrenia. The proposed model uses both textual and acoustic speech between occupational therapists or psychiatric nurses and schizophrenia patients to predict the level of their thought disorder. Experimental results show that the proposed model has the ability to closely predict the results of assessments for Schizophrenia patients base on the extracted semantic, syntactic and acoustic features. Thus, we believe our model can be a helpful tool to doctors when they are assessing schizophrenia patients.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Yan-Jia Huang et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3163777",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2940829132",
      "doi": "10.1109/access.2019.2906908",
      "title": "Early Detection of Lower MMSE Scores in Elderly Based on Dual-Task Gait",
      "abstract": "The dual-task paradigm is a promising procedure for estimating cognitive status and may also be collaterally used to reduce cognitive decline and prevent dementia. In this paper, we use the mini-mental state exam (MMSE) to the assess cognitive status in the elderly as a reference and investigate the potential of using machine learning for early detecting cognitive impairment in the elderly. Although many studies have suggested that dual-task performance, in which participants perform a cognitive task while walking, is associated with cognition, they only considered the correlation between cognitive parameters and simple gait feature, such as gait speed, through the statistical analysis. We instead use a Kinect sensor to capture participants' whole-body movements and extract a rich gait feature that has the ability to exhibit different tendencies of movements between healthy and cognitive-impaired elderlies. In our experiments, a classifier based on the dual-task gait feature achieved a higher performance than the one based on the single-task feature; the performance of the rich gait feature was better than that of a simple one, and; an optimal detection performance was achieved with an MMSE cutoff score of 25. We positively validated that the proposed method could early detect elderly with lower MMSE scores based on dual-task gait feature with a promising performance. Our approach can support early and automated diagnosis of cognitive impairment.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "K. Aoki et al.",
      "keywords": "Cognition; Gait; Dementia; Task (project management); Computer science; Feature (linguistics); Physical medicine and rehabilitation; Elementary cognitive task; Artificial intelligence; Task analysis; Cognitive impairment; Psychology; Medicine; Neuroscience; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2906908",
      "cited_by_count": 34,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3007251795",
      "doi": "10.1109/access.2020.2976076",
      "title": "Capturing Tacit Knowledge in Security Operation Centers",
      "abstract": "The use of tacit knowledge has previously been shown to help expedite problem-solving procedures in the setting of medical emergency responses, as individuals can use past experiences in present and future challenges. However, there is a lack of understanding in its application in IT and socio-technical management. This paper examines the thought processes observed in Security Operational Centre (SOC) analysts facing threat events to lay the groundwork for tacit knowledge management in SOCs. Based on Sternberg&#x2019;s fieldwork in tacit knowledge, we conducted semi-structured interviews with ten analysts to explore the key artefacts and individual traits that aid their approach to communication, and to examine the thought processes under hypothetical incident handling scenarios. The results highlight a unanimous pursuit of Root Cause Analysis (RCA) upon the outbreak of an incident and stages of decision-making when escalating to third party support providers. Using Business Process Modelling and Notation (BPMN), we show the procedural elements of tacit knowledge from several scenarios. The results also suggest that simulation environments and physical proximity with analysts and vendors can facilitate the transfer of tacit knowledge more effectively in SOCs.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Selina Cho et al.",
      "keywords": "Tacit knowledge; Knowledge management; Process (computing); Explicit knowledge; Computer science; Key (lock); Notation; Business process; Process management; Business; Engineering; Computer security; Work in process; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2976076",
      "cited_by_count": 36,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2951780367",
      "doi": "10.1109/access.2019.2923002",
      "title": "Prediction of the Location of the Glottis in Laryngeal Images by Using a Novel Deep-Learning Algorithm",
      "abstract": "A novel deep-learning algorithm for artificial neural networks (ANNs) was developed and presented in this paper, which is intuitively understandable, simple, efficient, and completely different from the back-propagation method, i.e., randomly selecting weight factors and bias values of an ANN and adjusting their values by small random amounts during the training session where it does not need to calculate the gradients of the training error to adjust weight factors as does the back-propagation method. The algorithm was applied to predict the location of the glottis in airway images obtained using a video airway device. The glottic locations were marked in 1,200 airway images captured using GlideScope&#x00AE; and fiberoptic laryngoscopy. With the randomly selected 1,000 training set data, 84 ANN models were trained using the above algorithm. We sought an ANN model that minimized the average training error for all training set data by reducing the input image resolution. As the resolution was reduced, the average training error decreased to its lowest level at 30&#x00D7;30 pixels. Eventually, the 900-98-49 ANN model was selected as the prediction model for the location of the glottis; it was the model with the lowest training error, i.e., the highest learning rate. The selected prediction model was applied to the remaining 200 test set data to obtain the test accuracy, and we obtained that the accurate prediction and the adjacent prediction rates were 74.5% and 21.5%, respectively. Reducing the input image resolution to an appropriate level could yield better prediction of the glottic location in airway images. This ANN model can help clinicians perform intubation by presenting the predicted location of the glottis.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Jong Soo Kim et al.",
      "keywords": "Glottis; Computer science; Test set; Artificial neural network; Artificial intelligence; Data set; Set (abstract data type); Pixel; Training set; Algorithm; Larynx",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2923002",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4280616982",
      "doi": "10.1109/tmi.2022.3173743",
      "title": "Fully-Automated Spike Detection and Dipole Analysis of Epileptic MEG Using Deep Learning",
      "abstract": "Magnetoencephalography (MEG) is a useful tool for clinically evaluating the localization of interictal spikes. Neurophysiologists visually identify spikes from the MEG waveforms and estimate the equivalent current dipoles (ECD). However, presently, these analyses are manually performed by neurophysiologists and are time-consuming. Another problem is that spike identification from MEG waveforms largely depends on neurophysiologists' skills and experiences. These problems cause poor cost-effectiveness in clinical MEG examination. To overcome these problems, we fully automated spike identification and ECD estimation using a deep learning approach fully automated AI-based MEG interictal epileptiform discharge identification and ECD estimation (FAMED). We applied a semantic segmentation method, which is an image processing technique, to identify the appropriate times between spike onset and peak and to select appropriate sensors for ECD estimation. FAMED was trained and evaluated using clinical MEG data acquired from 375 patients. FAMED training was performed in two stages: in the first stage, a classification network was learned, and in the second stage, a segmentation network that extended the classification network was learned. The classification network had a mean AUC of 0.9868 (10-fold patient-wise cross-validation); the sensitivity and specificity were 0.7952 and 0.9971, respectively. The median distance between the ECDs estimated by the neurophysiologists and those using FAMED was 0.63 cm. Thus, the performance of FAMED is comparable to that of neurophysiologists, and it can contribute to the efficiency and consistency of MEG ECD analysis.",
      "year": "2022",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Ryoji Hirano et al.",
      "keywords": "Magnetoencephalography; Artificial intelligence; Ictal; Segmentation; Computer science; Spike (software development); Pattern recognition (psychology); Identification (biology); Consistency (knowledge bases); Image segmentation; Electroencephalography; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2022.3173743",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3135959923",
      "doi": "10.1109/access.2021.3064040",
      "title": "Research on Application of Classification Model Based on Stack Generalization in Staging of Cervical Tissue Pathological Images",
      "abstract": "Cervical cancer is a malignant tumor that threatens women&#x2019;s health and life. Cervical pathology examination, as the gold standard for cervical cancer diagnosis, provides an important basis for the surgical plan and postoperative follow-up strategy for cervical cancer. Cervical biopsy diagnosis includes normal, low-grade squamous intraepithelial lesion (LSIL), high-grade squamous intraepithelial lesion (HSIL) and squamous cell carcinoma (SCC). At present, cervical pathology examination still relies on the doctor&#x2019;s personal clinical experience and subjective judgment, which is time-consuming and may cause misdiagnosis or missed diagnosis. In addition, the current intelligent classification of cervical pathological images still has disadvantages such as imperfect classification system and low classification accuracy. Therefore, this experiment uses the ResNet50 model of the convolutional neural network as the feature extractor, and selects the K-Nearest Neighbour (KNN), Random Forest (RF), Support Vector Machine (SVM) classifiers in Machine Learning to perform cervical tissue pathological images Discrimination, the accuracy of the classification results were 85.83&#x0025;, 80.33&#x0025;, and 86.67&#x0025;. In order to further improve the accuracy of the model and enhance the applicability and stability of the model, this experiment proposes the Stacked Generalization (SK) classification model. The first-layer base learner of the SK classification model selects CNN-KNN, CNN-RF, CNN-SVM, and the second-layer classifier selects Multilayer Perceptron (MLP). Among them, MLP makes the final result by learning the classification performance of the base learner for label discrimination, the accuracy of the classification model after ensemble learning is 90.00&#x0025;. In addition, this experiment uses the Synthetic Minority Oversampling Technique (SMOTE) algorithm to amplify the training samples, and the amplified data set has a classification accuracy of 89.17&#x0025; under the training of the SK classification model. The results show that the SK classification model in this experiment has a high classification ability for cervical histopathological images, and has good generalization ability and robustness.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Shuailei Zhang et al.",
      "keywords": "Computer science; Artificial intelligence; Support vector machine; Cervical cancer; Convolutional neural network; Perceptron; Pattern recognition (psychology); Feature extraction; Contextual image classification; Random forest; Classifier (UML); Squamous intraepithelial lesion; Cervical intraepithelial neoplasia; Artificial neural network; Medicine; Cancer; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3064040",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285115413",
      "doi": "10.1109/access.2022.3174678",
      "title": "Lightweight Skip Connections With Efficient Feature Stacking for Respiratory Sound Classification",
      "abstract": "As the number of deaths from respiratory diseases due to COVID-19 and infectious diseases increases, early diagnosis is necessary. In general, the diagnosis of diseases is based on imaging devices (e.g., computed tomography and magnetic resonance imaging) as well as the patient&#x2019;s underlying disease information. However, these examinations are time-consuming, incur considerable costs, and in a situation like the ongoing pandemic, face-to-face examinations are difficult to conduct. Therefore, we propose a lung disease classification model based on deep learning using non-contact auscultation. In this study, two respiratory specialists collected normal respiratory sounds and five types of abnormal sounds associated with lung disease, including those associated with four lung lesions in the left and right anterior chest and left and right posterior chest. For preprocessing and feature extraction, the noise was removed using three pass filters (low, band, and high), and respiratory sound features were extracted using the Log-Mel Spectrogram-Mel Frequency Cepstral Coefficient followed by feature stacking. Then, we propose a lung disease classification model of dense lightweight convolutional neural network-bidirectional gated recurrent unit skip connections using depthwise separable convolution based on the extracted respiratory sound information. The performance of the classification model was compared with both the baseline and the lightweight models. The results indicate that the proposed model achieves high performance and has an accuracy of 92.3&#x0025;, sensitivity of 92.1&#x0025;, specificity of 98.5&#x0025;, and f1-score of 91.9&#x0025;. Using the proposed model, we aim to contribute to the early detection of diseases during the COVID-19 pandemic.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Youngjin Choi et al.",
      "keywords": "Computer science; Feature extraction; Respiratory sounds; Pattern recognition (psychology); Artificial intelligence; Convolutional neural network; Speech recognition; Feature (linguistics); Cepstrum; Auscultation; Preprocessor; Magnetic resonance imaging; Radiology; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3174678",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384786374",
      "doi": "10.1109/access.2023.3296710",
      "title": "Automated Detection of Gastric Lesions in Endoscopic Images by Leveraging Attention-Based YOLOv7",
      "abstract": "Gastric cancer is a leading cause of mortality, resulting in approximately 770000 deaths in the year 2020. Early detection theatres a vital role in facilitating targeted treatments for gastric conditions. One commonly employed method for diagnosis and treatment of gastrointestinal ailments is endoscopy. However, the effectiveness of endoscopy heavily depends on the expertise of the endoscopist. By integrating Artificial Intelligence techniques with endoscopic procedures, we can enhance the swiftness and accuracy of the diagnostic process.This study presents an automated approach that enhances the YOLO-v7 object detection algorithm through the integration of a Squeeze and Excitation attention block. This integration significantly improves the detection of small gastric lesions, demonstrating promising results. The attention-powered YOLOv7 achieved notable precision, recall, F1-score, and mean average precision values of 0.72, 0.69, 0.71, and 0.71, respectively. Additionally, the system achieved a high frame rate of 63 Frames Per Second, making it well-suited for real-time applications. Furthermore, a performance comparison with the baseline YOLOv7 model revealed a notable 10&#x0025; increase in mean average precision and improved detection of small-sized lesions. The proposed architecture enables real-time lesion detection and identification, thereby supporting endoscopists in the analysis of endoscopic images, facilitating early diagnosis, and reducing reliance on the operator&#x2019;s expertise.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sheeraz Ahmad et al.",
      "keywords": "Computer science; Frame rate; Object detection; Artificial intelligence; Frame (networking); Endoscopy; Precision and recall; Computer vision; Block (permutation group theory); Pattern recognition (psychology); Radiology; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3296710",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385731945",
      "doi": "10.1109/access.2023.3304269",
      "title": "Blockchain Enabled Smart Healthcare System Using Jellyfish Search Optimization With Dual-Pathway Deep Convolutional Neural Network",
      "abstract": "Blockchain (BC) and Artificial intelligence (AI) based technologies have earned a better reputation amongst the research community, especially in the medical field. BC technology has emerged as a promising solution to revolutionize the medical field by addressing challenges related to efficiency, data security, and interoperability. A BC-aided smart healthcare system leverages the immutable and decentralized nature of BC to construct a secured and transparent ecosystem to manage processes and healthcare data. It leverages the secure and decentralized nature of BC to optimize the processes, security, interoperability, and efficiency of medical data. The existing system is exposed to security attacks on healthcare data. It can be necessary to construct a real-time detection device utilizing a cyber-physical system (CPS) with BC technology in a significant way. This article designs a novel Blockchain-Enabled Smart Healthcare System using Jellyfish Search Optimization with Dual-Pathway Deep Convolutional Neural Network (JSO-DPCNN) technique. The presented JSO-DPDCNN technique exploits the concept of BC-enabled secure data transmission and DL-based diagnosis model for moneypox disease on smart healthcare monitoring. To accomplish this, the JSO-DPCNN technique uses Ethereum-based public BC to secure the privacy of healthcare images. In addition, the JSO-DPCNN technique applies a feature extraction module using DPCNN, which extracts the suitable set of features in the input images. Moreover, the multiplicative long short-term memory (MLSTM) approach was used for the disease detection process. Lastly, the JSO system can be employed for the parameter tuning of the MLSTM model. The simulation result of the JSO-DPCNN system was executed on a benchmark medical dataset. The comprehensive outcomes highlighted the significant outcome of the JSO-DPCNN approach in terms of different measures.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Fahad F. Alruwaili et al.",
      "keywords": "Computer science; Convolutional neural network; Interoperability; Artificial intelligence; Deep learning; Field (mathematics); Big data; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3304269",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3152593248",
      "doi": "10.1109/access.2021.3072559",
      "title": "A Survey on Classification Algorithms of Brain Images in Alzheimer\u2019s Disease Based on Feature Extraction Techniques",
      "abstract": "Alzheimer&#x2019;s disease (AD) is one of the most serious neurological disorders for elderly people. AD affected patient experiences severe memory loss. One of the main reasons for memory loss in AD patients is atrophy in the hippocampus, amygdala, etc. Due to the enormous growth of AD patients and the paucity of proper diagnostic tools, detection and classification of AD are considered as a challenging research area. Before a Cognitively normal (CN) person develops symptoms of AD, he may pass through an intermediate stage, commonly known as Mild Cognitive Impairment (MCI). MCI is having two stages, namely StableMCI (SMCI) and Progressive MCI (PMCI). In SMCI, a patient remains stable, whereas, in the case of PMCI, a person gradually develops few symptoms of AD. Several research works are in progress on the detection and classification of AD based on changes in the brain. In this paper, we have analyzed few existing state-of-art works for AD detection and classification, based on different feature extraction approaches. We have summarized the existing research articles with detailed observations. We have also compared the performance and research issues in each of the feature extraction mechanisms and observed that the AD classification using the wavelet transform-based feature extraction approaches might achieve convincing results.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Ruhul Amin Hazarika et al.",
      "keywords": "Feature extraction; Cognitive impairment; Computer science; Pattern recognition (psychology); Artificial intelligence; Cognition; Atrophy; Disease; Feature (linguistics); Amygdala; Psychology; Medicine; Neuroscience; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3072559",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3139316422",
      "doi": "10.1109/jtehm.2021.3066800",
      "title": "Detecting Effect of Levodopa in Parkinson\u2019s Disease Patients Using Sustained Phonemes",
      "abstract": "Studies of phonation by computerized voice analysis in PD should employ recordings of multiple phonemes. Our findings are potentially relevant in research to identify early parkinsonian dysarthria, and to tele-monitoring of the levodopa response in patients with established PD.",
      "year": "2021",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Nemuel D. Pah et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2021.3066800",
      "cited_by_count": 33,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4384916605",
      "doi": "10.1109/access.2023.3297097",
      "title": "A Two-Stage Method for Polyp Detection in Colonoscopy Images Based on Saliency Object Extraction and Transformers",
      "abstract": "The gastrointestinal tract is responsible for the entire digestive process. Several diseases, including colorectal cancer, can affect this pathway. Among the deadliest cancers, colorectal cancer is the second most common. It arises from benign tumors in the colon, rectum, and anus. These benign tumors, known as colorectal polyps, can be diagnosed and removed during colonoscopy. Early detection is essential to reduce the risk of cancer. However, approximately 28&#x0025; of polyps are lost during this examination, mainly because of limitations in diagnostic techniques and image analysis methods. In recent years, computer-aided detection techniques for these lesions have been developed to improve detection quality during periodic examinations. We proposed an automatic method for polyp detection using colonoscopy images. This study presents a two-stage polyp detection method for colonoscopy images using transformers. In the first stage, a saliency map extraction model is supported by the extracted depth maps to identify possible polyp areas. The second stage of the method consists of detecting polyps in the extracted images resulting from the first stage, combined with the green and blue channels. Several experiments were performed using four public colonoscopy datasets. The best results obtained for the polyp detection task were satisfactory, reaching 91&#x0025; Average Precision in the CVC-ClinicDB dataset, 92&#x0025; Average Precision in the Kvasir-SEG dataset, and 84&#x0025; Average Precision in the CVC-ColonDB dataset. This study demonstrates that polyp detection in colonoscopy images can be efficiently performed using a combination of depth maps, salient object-extracted maps, and transformers.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Alan Carlos de Moura Lima et al.",
      "keywords": "Colonoscopy; Artificial intelligence; Computer science; Colorectal cancer; Stage (stratigraphy); Object detection; Computer vision; Colorectal Polyp; Pattern recognition (psychology); Radiology; Medicine; Cancer; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3297097",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2910071560",
      "doi": "10.1109/access.2018.2889540",
      "title": "A Review of Data Analysis for Early-Childhood Period: Taxonomy, Motivations, Challenges, Recommendation, and Methodological Aspects",
      "abstract": "Early childhood is a significant period when transitions take place in children. This period is a hot topic among researchers who pursue this domain across different scientific disciplines. Many studies addressed social, scientific, medical, and technical topics during early childhood. Researchers also utilized different analysis measures to conduct experiments on the different types of data related to the early childhood to produce research articles. This paper aims to review and analyze the literature related to early childhood in addition to the data analyses and the types of data used. The factors that were considered to boost the understanding of contextual aspects in the published studies related to early childhood were considered as open challenges, motivations, and recommendations of researchers who aimed to advance the study in this area of science. We systematically searched articles on topics related to early childhood, the data analysis approaches used, and the types of data applied. The search was conducted on five major databases, namely, ScienceDirect, Scopus, Web of Science, IEEE Xplore, and PubMed from 2013 to September 2017. These indices were considered sufficiently extensive and reliable to cover our field of the literature. Articles were selected on the basis of our inclusion and exclusion criteria (n = 233). The first portion of studies (n = 103/233) focused on the different aspects related to the development of children in early age. They discussed different topics, such as the body growth development of children, psychology, skills, and other related topics that overlap between two or more of the previous topics or do not fall into any of the categories but are still under development. The second portion of studies (n = 107/233) focused on different aspects associated with health in early childhood. A number of topics were discussed in this regard, such as those related to family health, medical procedures, interventions, and risk that address the health-related aspects, in addition to other related topics that overlap between two or more of the previous topics or do not fall into any of the categories but are still under health. The remaining studies (n = 23/233) were categorized to the other main category because they overlap between the previous two major categories, namely, development and health, or they do not fall into any of the previous main categories. Early childhood is a sensitive period in every child's life. This period was studied using different means of data analysis and with the aid of different data types to produce different findings from the previous studies. Research areas on early childhood vary, but they are equally significant. This paper emphasizes the current standpoint and opportunities for research in this area and boosts additional efforts toward the understanding of this research field.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "A. H. Alamoodi et al.",
      "keywords": "Period (music); Computer science; Taxonomy (biology); Data science; Information retrieval",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2018.2889540",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2761691867",
      "doi": "10.1109/thms.2017.2754880",
      "title": "Eye Tracking the Visual Attention of Nurses Interpreting Simulated Vital Signs Scenarios: Mining Metrics to Discriminate Between Performance Level",
      "abstract": "Nurses welcome innovative training and assessment methods to effectively interpret physiological vital signs. The objective is to determine if eye-tracking technology can be used to develop biometrics for automatically predict the performance of nurses whilst they interact with computer-based simulations. 47 nurses were recruited, 36 nursing students (training group) and 11 coronary care nurses (qualified group). Each nurse interpreted five simulated vital signs scenarios whilst \u2018thinking-aloud\u2019. The participant\u2019s visual attention (eye tracking metrics), verbalisation, heart rate, confidence level (1-10, 10=most confident) and cognitive load (NASA-TLX) were recorded during performance. Scenario performances were scored out of ten. Analysis was used to find patterns between the eye tracking metrics and performance score. Multiple linear regression was used to predict performance score using eye tracking metrics. The qualified group scored higher than the training group (6.851.5 vs. 4.591.61, p=",
      "year": "2017",
      "journal": "IEEE Transactions on Human-Machine Systems",
      "authors": "Jonathan Currie et al.",
      "keywords": "Eye tracking; Vital signs; Confidence interval; Tracking (education); Biometrics; Computer science; Artificial intelligence; Psychology; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/thms.2017.2754880",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285284219",
      "doi": "10.1109/access.2022.3183077",
      "title": "A Facial and Vocal Expression Based Comprehensive Framework for Real-Time Student Stress Monitoring in an IoT-Fog-Cloud Environment",
      "abstract": "In this era of digital and modern education, the existence of psychological stress on students cannot be denied. The surplus aggregation of the stress may lead to different problems like a decline in student grade (performance), an increase of violence in behavior, and even more extreme cases. The advent of Information Communication and Technology (ICT) and its tools opened the doors to innovations that facilitate interactions among things and humans. In this utilization, the paper proposes a novel, IoT-aware student-centric stress monitoring and real-time alert generating framework to predict student stress index in a particular context. In elaboration, we respectively used extended VGG16, Bidirectional Long Short Term Memory network (Bi -LSTM), and Multinomial Na&#x00EF;ve Bayes techniques to generate the scores of emotions from student facial expressions, speech pitch, and content of student speech at the cloud layer. Specifically, the model aims to classify the stress events as normal or abnormal on basis of the overall emotion of the students&#x2019; physiological data readings. The activation of the abnormal event in case of higher values for negative emotions like stress, fear, sadness, disgust, etc.; a stern alert is sent to the student, coordinators, and caretakers. This proposed framework will ultimately be a great tool that will support the education institutions, students, their parents, and guardians to get a real-time alert on students&#x2019; overall emotions. The prior knowledge of stress accumulated on the mind of the student will help in overcoming major problems of student dropout, decrease student academic performance, and tackle the stress situation that may lead to the student attempting suicide.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Madanjit Singh et al.",
      "keywords": "Sadness; Computer science; Context (archaeology); Stress (linguistics); Facial expression; Disgust; Cloud computing; Sentiment analysis; Event (particle physics); Dynamic Bayesian network; Psychology; Multimedia; Anger; Applied psychology; Artificial intelligence; Bayesian network; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3183077",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382393552",
      "doi": "10.1109/tns.2023.3290826",
      "title": "Needs, Trends, and Advances in Scintillators for Radiographic Imaging and Tomography",
      "abstract": "Radiographic imaging and tomography (RadIT), which started with R\u00f6ntgen's seminal X-ray work in 1895, now includes an increasing number of IT modalities. In addition to the original absorption-based X-ray radiography, others include phase contrast X-ray imaging, coherent X-ray diffractive imaging, MeV X- and \u03b3 -ray radiography, X-ray computed tomography, proton IT, neutron IT, positron emission tomography (PET), high-energy electron radiography, and cosmic-ray muon tomography. Scintillators are widely used in RadIT as the detector frontend that converts ionizing radiation into signals and data. We give an overview of the status and needs of scintillator applications in RadIT. More than 160 kinds of scintillators were presented during the SCINT22 conference and offered ample options for novel RadIT applications. New trends in scintillators for RadIT applications include inorganic and organic scintillator composites or heterostructures, liquid-phase synthesized perovskites and single-crystal micrometer-thick films, use of multiphysics models and data science to guide scintillator and RadIT optimization, structural innovations, such as photonic crystals, nanoscintillators enhanced by the Purcell effect, heterostructural scintillating fibers, and multilayer configurations. RadIT has also been recognized as a powerful tool for scintillator discovery and development.",
      "year": "2023",
      "journal": "IEEE Transactions on Nuclear Science",
      "authors": "\u202aZhehui Wang et al.",
      "keywords": "Radiography; Scintillator; Medical physics; Tomography; Medical imaging; Nuclear medicine; Physics; Optics; Medicine; Nuclear physics; Radiology; Detector",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tns.2023.3290826",
      "cited_by_count": 71,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4393405337",
      "doi": "10.1109/access.2024.3384349",
      "title": "CardioGPT: An ECG Interpretation Generation Model",
      "abstract": "Numerous supervised learning models aimed at classifying 12-lead electrocardiograms into different groups have shown impressive performance by utilizing deep learning algorithms. However, few studies are dedicated to applying the Generative Pre-trained Transformer (GPT) model in interpreting electrocardiogram (ECG) using natural language. Thus, we are pioneering the exploration of this uncharted territory by employing the CardioGPT model to tackle this challenge. We used a dataset of ECGs (standard 10s, 12-channel format) from adult patients, with 60 distinct rhythms or conduction abnormalities annotated by board-certified, actively practicing cardiologists. The ECGs were collected from The First Affiliated Hospital of Ningbo University and Shanghai East Hospital. The dataset is partitioned into training (80%), validation (10%), and test (10%) cohorts for comprehensive evaluation. Each cohort contains ECGs from distinct patients, considering some patients took repeated ECG measurements. The proposed algorithm is evaluated in two levels, self-performance measurement and comparison with the residual neural network classification model. Two scores are used for self-performance measurement, including Bilingual Evaluation Understudy (BLEU) and Recall-Oriented Understudy for Gisting Evaluation (ROUGE). To compare the performance of the proposed model with the residual neural network model, we assessed the F1 score and area under the receiver operating characteristic curve (AUC). We have observed promising performance metrics across multiple evaluation criteria through an extensive evaluation of a large 12-lead ECG database comprising 1,128,553 ECG readings from 754,920 patients. The CardioGPT model exhibited high BLEU and ROUGE scores with 0.68 (95% CI: 0.66, 0.71) and 0.81 (95% CI: 0.79, 0.84). Furthermore, in the classification performance measurement setting, the CardioGPT achieved an average F1-score of 0.91(95% CI: 0.89, 0.93) and AUC of 0.82(95% CI: 0.79, 0.84) and has higher scores than that of the convolutional neural network model, indicating its proficiency in accurately classifying ECG recordings. By leveraging the power of transformer structure model and natural language processing, the GPT model addresses the challenge of imbalanced learning commonly encountered in ECG classification tasks. The results indicate that the GPT model can accurately interpret ECG using natural language, providing valuable insights into the underlying patterns and abnormalities present in the data. Significance: The pioneering application of the GPT model for interpreting ECGs with natural language demonstrates its potential to address ECG classification challenges and offer valuable insights into cardiac health.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Guohua Fu et al.",
      "keywords": "Computer science; Interpretation (philosophy); Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3384349",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210665286",
      "doi": "10.1109/jbhi.2022.3144941",
      "title": "Healthcare Innovations to Address the Challenges of the COVID-19 Pandemic",
      "abstract": "We have been faced with an unprecedented challenge in combating the COVID-19/SARS-CoV2 outbreak that is threatening the fabric of our civilization, causing catastrophic human losses and a tremendous economic burden globally. During this difficult time, there has been an urgent need for biomedical engineers, clinicians, and healthcare industry leaders to work together to develop novel diagnostics and treatments to fight the pandemic including the development of portable, rapidly deployable, and affordable diagnostic testing kits, personal protective equipment, mechanical ventilators, vaccines, and data analysis and modeling tools. In this position paper, we address the urgent need to bring these inventions into clinical practices. This paper highlights and summarizes the discussions and new technologies in COVID-19 healthcare, screening, tracing, and treatment-related presentations made at the IEEE EMBS Public Forum on COVID-19. The paper also provides recent studies, statistics and data and new perspectives on ongoing and future challenges pertaining to the COVID-19 pandemic.",
      "year": "2022",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Metin Akay et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2022.3144941",
      "cited_by_count": 27,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4320002875",
      "doi": "10.1109/access.2023.3240216",
      "title": "Classification of Liver Fibrosis From Heterogeneous Ultrasound Image",
      "abstract": "With the advances in deep learning, including Convolutional Neural Networks (CNN), automated diagnosis technology using medical images has received considerable attention in medical science. In particular, in the field of ultrasound imaging, CNN trains the features of organs through an amount of image data, so that an expert-level automatic diagnosis is possible only with images of actual patients. However, CNN models are also trained on the features that reflect the inherent bias of the imaging machine used for image acquisition. In other words, when the domain of data used for training is different from that of data applied for an actual diagnosis, it is unclear whether consistent performance can be provided by the domain bias. Therefore, we investigate the effect of domain bias on the model with liver ultrasound imaging data obtained from multiple domains. We have constructed a dataset considering the manufacturer and the year of manufacturing of 8 ultrasound imaging machines. First, training and testing were performed by dividing the entire data, in a commonly used method. Second, we have utilized the training data constructed according to the number of domains for the machine learning process. Then we have measured and compared the performance on internal and external domain data. Through the above experiment, we have analyzed the effect of domains of data on model performance. We show that the performance scores evaluated with the internal domain data and the external domain data do not match. We especially show that the performance measured in the evaluation data including the internal domain was much higher than the performance measured in the evaluation data consisting of the external domain. We also show that 3-level classification performance is slightly improved over 5-level classification by mitigating class imbalance by integrating similar classes. The results highlight the need to develop a new methodology for mitigating the machine bias problem so that the model can work correctly even on external domain data, as opposed to the usual approach of constructing evaluation data in the same domain as the training data.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Yunsang Joo et al.",
      "keywords": "Computer science; Convolutional neural network; Artificial intelligence; Domain (mathematical analysis); Medical imaging; Field (mathematics); Deep learning; Process (computing); Image (mathematics); Pattern recognition (psychology); Artificial neural network; Machine learning; Big data; Data modeling; Computer vision; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3240216",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3094365539",
      "doi": "10.1109/tnsre.2020.3033711",
      "title": "Patient-Preferred Prosthetic Ankle-Foot Alignment for Ramps and Level-Ground Walking",
      "abstract": "Patient preference of lower limb prosthesis behavior informally guides clinical decision making, and may become increasingly important for tuning new robotic prostheses. However, the processes for quantifying preference are still being developed, and the strengths and weaknesses of preference are not adequately understood. The present study sought to characterize the reliability (consistency) of patient preference of alignment during level-ground walking, and determine the patient-preferred ankle angle for ascent and descent of a 10\u00b0 ramp, with implications for the design and control of robotic prostheses. Seven subjects with transtibial amputation walked over level ground, and ascended and descended a 10\u00b0 ramp on a semi-active prosthetic ankle capable of unweighted repositioning in dorsiflexion and plantarflexion. Preferred ankle angle was measured with an adaptive forced-choice psychophysics paradigm, in which subjects walked on a randomized static ankle angle and reported whether they would prefer the ankle to be dorsiflexed or plantarflexed. Subjects had reliable preferences for alignment during level-ground walking, with deviations of 1.5\u00b0 from preference resulting in an 84% response rate preferring changes toward the preference. Relative to level walking, subjects preferred 7.8\u00b0 (SD: 4.8\u00b0) of dorsiflexion during ramp ascent, and 5.3\u00b0 (SD: 3.8\u00b0) plantarflexion during ramp descent. As the ankle angle better matched the ramp angle, socket pressures and tibial progression (shank pitch) both more closely mirrored those during level walking. These findings provide baseline behaviors for prosthetic ankles capable of adapting to slopes based on patient preference, and provide strong evidence that people with transtibial amputation can finely perceive ankle alignment.",
      "year": "2020",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Max K. Shepherd et al.",
      "keywords": "Ankle; Physical medicine and rehabilitation; Amputation; Ground reaction force; Prosthesis; Preference; Medicine; Ankle dorsiflexion; Physical therapy; Forefoot; Computer science; Psychology; Kinematics; Surgery; Mathematics; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2020.3033711",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4320015778",
      "doi": "10.1109/access.2023.3240769",
      "title": "A Survey on Yogic Posture Recognition",
      "abstract": "Yoga has been a great form of physical activity and one of the promising applications in personal health care. Several studies prove that yoga is used as one of the physical treatments for cancer, musculoskeletal disorder, depression, Parkinson&#x2019;s disease, and respiratory heart diseases. In yoga, the body should be mechanically aligned with some effort on the muscles, ligaments, and joints for optimal posture. Postural-based yoga increases flexibility, energy, overall brain activity and reduces stress, blood pressure, and back pain. Body Postural Alignment is a very important aspect while performing yogic asanas. Many yogic asanas including uttanasana, kurmasana, ustrasana, and dhanurasana, require bending forward or backward, and if the asanas are performed incorrectly, strain in the joints, ligaments, and backbone can result, which can cause problems with the hip joints. Hence it is vital to monitor the correct yoga poses while performing different asanas. Yoga posture prediction and automatic movement analysis are now possible because of advancements in computer vision algorithms and sensors. This research investigates a thorough analysis of yoga posture identification systems using computer vision, machine learning, and deep learning techniques.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Arun Kumar Rajendran et al.",
      "keywords": "Flexibility (engineering); Physical medicine and rehabilitation; Physical therapy; Biomechanics; Medicine; Computer science; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3240769",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4282920221",
      "doi": "10.1109/tnsre.2022.3179327",
      "title": "Extended Reality \u201cX-Reality\u201d for Prosthesis Training of Upper-Limb Amputees: A Review on Current and Future Clinical Potential",
      "abstract": "The rejection rates of upper-limb prosthetic devices in adults are high, currently averaging 26% and 23% for body-powered and electric devices, respectively. While many factors influence acceptance, prosthesis training methods relying on novel virtual reality systems have been cited as a critical factor capable of increasing the likelihood of long-term, full-time use. Despite that, these implementations have not yet garnered widespread traction in the clinical setting, and their use remains immaterial. This review aims to explore the reasons behind this situation by identifying trends in existing research that seek to advance Extended Reality \"X-Reality\" systems for the sake of upper-limb prosthesis rehabilitation and, secondly, analyzing barriers and presenting potential pathways to deployment for successful adoption in the future. The search yielded 42 research papers that were divided into two categories. The first category included articles that focused on the technical aspect of virtual prosthesis training. Articles in the second category utilize user evaluation procedures to ensure applicability in a clinical environment. The review showed that 75% of articles that conducted whole system testing experimented with non-immersive virtual systems. Furthermore, there is a shortage of experiments performed with amputee subjects. From the large-scale studies analyzed, 71% of those recruited solely non-disabled participants. This paper shows that X-Reality technologies for prosthesis rehabilitation of upper-limb amputees carry significant benefits. Nevertheless, much still must be done so that the technology reaches widespread clinical use.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Aya Gaballa et al.",
      "keywords": "Virtual reality; Economic shortage; Prosthesis; Software deployment; Rehabilitation; Implementation; Physical medicine and rehabilitation; Computer science; Human\u2013computer interaction; Medicine; Physical therapy; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tnsre.2022.3179327",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390481029",
      "doi": "10.1109/access.2023.3348788",
      "title": "Detection of Tooth Position by YOLOv4 and Various Dental Problems Based on CNN With Bitewing Radiograph",
      "abstract": "Periodontitis is a high prevalence dental disease caused by bacterial infection of the bone that surrounds the tooth. Early detection and precision treatment can prevent more severe symptoms such as tooth loss. Traditionally, periodontal disease is identified and labeled manually by dental professionals. The task requires expertise and extensive experience, and it is highly repetitive and time-consuming. The aim of this study is to explore the application of AI in the field of dental medicine. With the inherent learning capabilities, AI exhibits remarkable proficiency in processing extensive datasets and effectively managing repetitive tasks. This is particularly advantageous in professions demanding extensive experiential knowledge, such as dentistry. By harnessing AI, the potential arises to amplify process efficiency and velocity. In this study, bitewing radiographs are used as the image source, and there are two major steps to detect the dental symptoms including 1) tooth position identification; and 2) symptom identification. The study combines image enhancement techniques and tooth position identification using Gaussian filtering and adaptive binarization for data preprocessing, facilitated by the YOLOv4 model to precisely mark tooth positions. The subsequent step enhances symptom area visibility via contrast enhancement, utilizing a CNN model, particularly the AlexNet model, with significant improvements in caries recognition accuracy (92.85&#x0025;) and restorations recognition accuracy (96.55&#x0025;) compared to prior research. Moreover, the inclusion of periodontal disease symptoms achieves an accuracy of 91.13&#x0025;. By harnessing deep learning techniques based on CNN models, this research enhances diagnostic precision, reduces errors, and increases efficiency for dentists, thereby providing meticulous and swift patient care. This innovation not only saves time but also has the potential for widespread implementation in remote and preventive medicine, aligning with the aspiration of universal health care accessibility.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Kuo-Chen Li et al.",
      "keywords": "Computer science; Artificial intelligence; Deep learning; Identification (biology); Preprocessor; Computer vision; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3348788",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3109666658",
      "doi": "10.1109/tse.2020.3040554",
      "title": "How Software Developers Mitigate Their Errors When Developing Code",
      "abstract": "Code remains largely hand-made by humans and, as such, writing code is prone to error. Many previous studies have focused on the technical reasons for these errors and provided developers with increasingly sophisticated tools. Few studies have looked in detail at why code errors have been made from a human perspective. We use Human Error Theory to frame our exploratory study and use semi-structured interviews to uncover a preliminary understanding of the errors developers make while coding. We look particularly at the skill-based errors reported by 27 professional software developers. We found that the complexity of the development environment is one of the most frequently reported reasons for errors. Maintaining concentration and focus on a particular task also underpins many developer errors. We found that developers struggle with effective mitigation strategies for their errors, reporting strategies largely based on improving their own willpower to concentrate better on coding tasks. We discuss how using Reason's Swiss Cheese model may help reduce errors during software development. This model ensures that layers of tool, process and management mitigation are in place to prevent developer errors from causing system failures.",
      "year": "2020",
      "journal": "IEEE Transactions on Software Engineering",
      "authors": "Bhaveet Nagaria et al.",
      "keywords": "Computer science; Software engineering; Programming language; Software construction; Code (set theory); Software quality; Software development; Static program analysis; Software",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tse.2020.3040554",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4383503865",
      "doi": "10.1109/tnsre.2023.3293334",
      "title": "Iterative Self-Training Based Domain Adaptation for Cross-User sEMG Gesture Recognition",
      "abstract": "Surface electromyography (sEMG) based gesture recognition has received broad attention and application in rehabilitation areas for its direct and fine-grained sensing ability. sEMG signals exhibit strong user dependence properties among users with different physiology, causing the inapplicability of the recognition model on new users. Domain adaptation is the most representative method to reduce the user gap with feature decoupling to acquire motion-related features. However, the existing domain adaptation method shows awful decoupling results when handling complex time-series physiological signals. Therefore, this paper proposes an Iterative Self-Training based Domain Adaptation method (STDA) to supervise the feature decoupling process with the pseudo-label generated by self-training and to explore cross-user sEMG gesture recognition. STDA mainly consists of two parts, discrepancy-based domain adaptation (DDA) and pseudo-label iterative update (PIU). DDA aligns existing users' data and new users' unlabeled data with a Gaussian kernel-based distance constraint. PIU Iteratively continuously updates pseudo-labels to generate more accurate labelled data on new users with category balance. Detailed experiments are performed on publicly available benchmark datasets, including the NinaPro dataset (DB-1 and DB-5) and the CapgMyo dataset (DB-a, DB-b, and DB-c). Experimental results show that the proposed method achieves significant performance improvement compared with existing sEMG gesture recognition and domain adaption methods.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Kang Wang et al.",
      "keywords": "Computer science; Domain adaptation; Gesture recognition; Gesture; Training (meteorology); Adaptation (eye); Domain (mathematical analysis); Speech recognition; Artificial intelligence; Human\u2013computer interaction; Pattern recognition (psychology); Psychology; Neuroscience; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3293334",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285130568",
      "doi": "10.1109/access.2022.3183185",
      "title": "An Exemplar Pyramid Feature Extraction Based Alzheimer Disease Classification Method",
      "abstract": "&lt;p&gt;Dementia is a term used to describe a variety of symptoms related to cognitive impairment in which Alzheimer disease represents 60% \u2013 70% of the cases. As of today, there is no cure for this disease and the only way to prevent any associated medical, economic, and financial impacts or losses is to detect the disease early and work closely with suspected patients to prevent any further progress. In this research, a methodology consisting of 4 modules is proposed: (1) preprocessing, exemplar pyramid along with bi-linear interpolation followed by (2) feature extraction using Gray Level Co-Occurrence Matrix and Local Binary Pattern then (3) concatenation of all extracted features and finally (4) classification of Alzheimer disease stage using deep learning, Multi-Layer Perceptron, in particular. Our proposed method was tested using the MPRAGE structural MRI dataset from Alzheimer Disease Neuro Imaging Initiative (ADNI), and it outperformed other techniques used in the literature review. An accuracy result of 89.80 was reported for multi-class classification of 4 stages of Alzheimer disease (Cognitive Normal, Early Mild Cognitive Impairment, Late Mild Cognitive Impairment and Alzheimer Disease) for both Gray Matter (GM) and White Matter (WM). In term of binary-class classification, we were able to achieve very good results using both GM and WM. By using GM, we were able to distinguish between CN vs EMCI, EMCI vs AD and LMCI vs AD with accuracy results of 96.43%, 90.91% and 95.24% respectively. And using WM, we were able to distinguish between CN vs LMCI with 100% accuracy and EMCI vs LMCI with 95.65% accuracy. While we achieved the same accuracy result of 96.15 using both WM and GM.&lt;/p&gt;&lt;h2&gt;Other Information&lt;/h2&gt;&lt;p&gt;Published in: IEEE Access&lt;br&gt;License: &lt;a href=\"https://creativecommons.org/licenses/by/4.0/legalcode\" target=\"_blank\"&gt;https://creativecommons.org/licenses/by/4.0/&lt;/a&gt;&lt;br&gt;See article on publisher's website: &lt;a href=\"https://dx.doi.org/10.1109/access.2022.3183185\" target=\"_blank\"&gt;https://dx.doi.org/10.1109/access.2022.3183185&lt;/a&gt;&lt;/p&gt;",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Heba Soliman Zaina et al.",
      "keywords": "Dementia; Artificial intelligence; Disease; Pattern recognition (psychology); Computer science; Alzheimer's disease; White matter; Cognitive impairment; Cognition; Preprocessor; Concatenation (mathematics); Binary classification; Medicine; Psychology; Neuroscience; Magnetic resonance imaging; Pathology; Mathematics; Support vector machine; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3183185",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3163705825",
      "doi": "10.1109/access.2021.3078534",
      "title": "Complementary Photoplethysmogram Synthesis From Electrocardiogram Using Generative Adversarial Network",
      "abstract": "Photoplethysmogram (PPG) is one of the most widely measured biosignals alongside electrocardiogram (ECG). Due to the simplicity of measurement and the advent of wearable devices, there have been growing interest in using PPG for a variety of healthcare applications such as cardiac function estimation. However, unlike ECG, there are not many large databases available for clinically significant analyses of PPG. To overcome this issue, a Generative Adversarial Network-based model to generate PPG using ECG as input is proposed. The network was trained using a large open database of biosignals measured from surgical patients and was externally validated using an alternative database sourced from another hospital. The generated PPG was compared with the reference PPG using percent root mean square difference (PRD) and Pearson correlation coefficient to evaluate the morphological similarity. Additionally, heart rate measured from the reference ECG, reference PPG, and generated PPG, and compared through repeated measure analysis of variance to test for any significant differences. The mean PRD was 32&#x00B1; 10&#x0025; and the mean correlation coefficient was 0.95&#x00B1; 0.05 in the test dataset. The HR from the three biosignals showed no significant difference with a <inline-formula> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula>-value of 0.473. When the optimized GAN model was tested on atrial fibrillation ECG from a third dataset, the mean correlation coefficient between the generated PPG heart rate and the ECG heart rate was 0.94&#x00B1; 0.15, with paired t-test resulting in <inline-formula> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula>-value of 0.64. The results indicate that the proposed method may provide a valuable alternative to augmenting biosignal databases that are abundant in one signal while lacking in another.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Heean Shin et al.",
      "keywords": "Photoplethysmogram; Correlation coefficient; Pattern recognition (psychology); Computer science; Pearson product-moment correlation coefficient; Artificial intelligence; Correlation; Electrocardiography; Mathematics; Medicine; Statistics; Cardiology; Filter (signal processing); Machine learning; Computer vision",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3078534",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386824850",
      "doi": "10.1109/access.2023.3316509",
      "title": "Surface Electromyography and Artificial Intelligence for Human Activity Recognition\u2014A Systematic Review on Methods, Emerging Trends Applications, Challenges, and Future Implementation",
      "abstract": "Human activity recognition (HAR) has become increasingly popular in recent years due to its potential to meet the growing needs of various industries. Electromyography (EMG) is essential in various clinical and biological settings. It is a metric that helps doctors diagnose conditions that affect muscle activation patterns and monitor patients\u2019 progress in rehabilitation, disease diagnosis, motion intention recognition, etc. This review summarizes the various research papers based on HAR with EMG. Over recent years, the integration of Artificial Intelligence (AI) has catalyzed remarkable advancements in the classification of biomedical signals, with a particular focus on EMG data. Firstly, this review meticulously curates a wide array of research papers that have contributed significantly to the evolution of EMG-based activity recognition. By surveying the existing literature, we provide an insightful overview of the key findings and innovations that have propelled this field forward. It explore the various approaches utilized for preprocessing EMG signals, including noise reduction, baseline correction, filtering, and normalization, ensure that the EMG data is suitably prepared for subsequent analysis. In addition, we unravel the multitude of techniques employed to extract meaningful features from raw EMG data, encompassing both time-domain and frequency-domain features. These techniques are fundamental to achieving a comprehensive characterization of muscle activity patterns. Furthermore, we provide an extensive overview of both Machine Learning (ML) and Deep Learning (DL) classification methods, showcasing their respective strengths, limitations, and real-world applications in recognizing diverse human activities from EMG signals. In examining the hardware infrastructure for HAR with EMG, the synergy between hardware and software is underscored as paramount for enabling real-time monitoring. Finally, we also discovered open issues and future research direction that may point to new lines of inquiry for ongoing research toward EMG-based detection.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Gundala Jhansi Rani et al.",
      "keywords": "Electromyography; Artificial intelligence; Computer science; Machine learning; Preprocessor; Categorization; Deep learning; Feature extraction; Pattern recognition (psychology); Physical medicine and rehabilitation; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3316509",
      "cited_by_count": 43,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3198936926",
      "doi": "10.1109/access.2021.3112102",
      "title": "Enhanced Word Embedding Variations for the Detection of Substance Abuse and Mental Health Issues on Social Media Writings",
      "abstract": "International audience",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Diana Ram\u00edrez\u2010Cifuentes et al.",
      "keywords": "Word2vec; Computer science; Artificial intelligence; Embedding; Word embedding; Recall; Cosine similarity; Binary classification; Machine learning; Natural language processing; Class (philosophy); Support vector machine; Pattern recognition (psychology); Cognitive psychology; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3112102",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385236743",
      "doi": "10.1109/access.2023.3298569",
      "title": "BI-RADS-NET-V2: A Composite Multi-Task Neural Network for Computer-Aided Diagnosis of Breast Cancer in Ultrasound Images With Semantic and Quantitative Explanations",
      "abstract": "Computer-aided Diagnosis (CADx) based on explainable artificial intelligence (XAI) can gain the trust of radiologists and effectively improve diagnosis accuracy and consultation efficiency. This paper proposes BI-RADS-Net-V2, a novel machine learning approach for fully automatic breast cancer diagnosis in ultrasound images. The BI-RADS-Net-V2 can accurately distinguish malignant tumors from benign ones and provides both semantic and quantitative explanations. The explanations are provided in terms of clinically proven morphological features used by clinicians for diagnosis and reporting mass findings, i.e., Breast Imaging Reporting and Data System (BI-RADS). The experiments on 1,192 Breast Ultrasound (BUS) images indicate that the proposed method improves the diagnosis accuracy by taking full advantage of the medical knowledge in BI-RADS while providing both semantic and quantitative explanations for the decision.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Boyu Zhang et al.",
      "keywords": "Computer science; BI-RADS; Artificial neural network; Artificial intelligence; Breast cancer; Computer-aided diagnosis; Breast ultrasound; Task (project management); Machine learning; Ultrasound; Pattern recognition (psychology); Radiology; Cancer; Mammography; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3298569",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2920777385",
      "doi": "10.1109/access.2019.2901580",
      "title": "Deep Group-Wise Registration for Multi-Spectral Images From Fundus Images",
      "abstract": "Multi-spectral imaging (MSI) is a novel non-invasive tool for visualizing the entire span of the eye, from the internal limiting membrane to the choroid. However, spatial misalignments can be frequently observed in sequential MSI images because the eye saccade movement is usually faster than the MSI image acquisition speed. Therefore, registering MSI images is necessary for computer-based analysis of retinal degeneration via MSI. In this paper, we propose an early deep learning framework for achieving an accurate registration of MSI images in a group-wise fashion. The framework contains three parts: a template construction based on principal component analysis, a deformation field calculation, and a spatial transformation. The framework is uniquely capable of resolving two key challenges, i.e., the &#x201C;multi-modal&#x201D; characteristics in MSI images for the acquisition with different spectra and the requirement of joint registration of the sequential images. Our experimental results demonstrate the superior performance of our framework compared to several representative state-of-the-art techniques in both speed and accuracy.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Tongtong Che et al.",
      "keywords": "Computer science; Artificial intelligence; Computer vision; Fundus (uterus); Image registration; Pattern recognition (psychology); Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2901580",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3160277245",
      "doi": "10.1109/access.2021.3079992",
      "title": "Development and Evaluation of a Smartphone-Based Electroencephalography (EEG) System",
      "abstract": "The aim of the study was to design, develop and evaluate a general-purpose EEG platform which integrates with a smartphone. The target specification was a system with 19 EEG channels and data stored onto the smartphone via a Wi-Fi connection. The hardware was developed using three ADS1299 integrated circuits, and the game engine, Unity, was used to develop the smartphone app. An evaluation of the system was conducted using recordings of alpha waves during periods of eye closure in participants (Bland-Altman statistical comparison with a clinical grade EEG system). The smartphone was also used to deliver time-locked auditory stimuli using an oddball paradigm to evaluate the ability of the developed system to acquire event related potentials (ERP) during sitting and walking. No significant differences were found for the alpha wave peak amplitude, frequency and area under the curve for the intra-system (two consecutive periods of alpha waves) or inter-system (developed smartphone-based EEG system versus FDA-approved system) comparisons. ERP results showed the peak amplitude of the auditory P300 component to deviant tones was significantly higher when compared to standard tones for sitting and walking activities. It is envisaged that our general-purpose EEG system will encourage other researchers to design and build their own specific versions rather than being limited by the fixed features of commercial products.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Anthony D. Bateson et al.",
      "keywords": "Electroencephalography; Alpha wave; Computer science; Alpha (finance); Sitting; Oddball paradigm; Simulation; Audiology; Human\u2013computer interaction; Speech recognition; Computer hardware; Event-related potential; Psychology; Mathematics; Statistics; Medicine; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3079992",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4417438910",
      "doi": "10.1109/jbhi.2025.3645076",
      "title": "Benchmarking Foundation Models with Multimodal Public Electronic Health Records",
      "abstract": "Foundation models have emerged as a powerful approach for processing electronic health records (EHRs), offering flexibility to handle diverse medical data modalities. In this study, we present a comprehensive benchmark that evaluates the performance, fairness, and interpretability of foundation models, both as unimodal encoders and as multimodal learners, using the publicly available MIMIC-IV database. To support consistent and reproducible evaluation, we developed a standardized data processing pipeline that harmonizes heterogeneous clinical records into an analysis-ready format. We systematically compared twelve foundation models, encompassing both unimodal and multimodal models, as well as domain-specific and general-purpose variants. Our findings demonstrate that incorporating multiple data modalities generally improves predictive performance without introducing additional bias. While domain-specific fine-tuning offers a cost-effective solution for unimodal foundation models, this effectiveness does not translate well to multimodal scenarios. Additionally, our experiments reveal limited task generalizability in current large vision-language models (LVLMs), emphasizing the need for more versatile and robust medical LVLMs. Through this benchmark, we aim to support the development of effective and trustworthy multimodal artificial intelligence (AI) systems for real-world clinical applications.",
      "year": "2025",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Kunyu Yu et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2025.3645076",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4366205113",
      "doi": "10.1109/access.2023.3267492",
      "title": "A Novel Fusion Model of Hand-Crafted Features With Deep Convolutional Neural Networks for Classification of Several Chest Diseases Using X-Ray Images",
      "abstract": "With the continuing global pandemic of coronavirus (COVID-19) sickness, it is critical to seek diagnostic approaches that are both effective and rapid to limit the number of people infected with the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The results of recent research suggest that radiological images include important information related to COVID-19 and other chest diseases. As a result, the use of deep learning (DL) to assist in the automated diagnosis of chest diseases may prove useful as a diagnostic tool in the future. In this study, we propose a novel fusion model of hand-crafted features with deep convolutional neural networks (DCNNs) for classifying ten different chest diseases such as COVID-19, lung cancer (LC), atelectasis (ATE), consolidation lung (COL), tuberculosis (TB), pneumothorax (PNET), edema (EDE), pneumonia (PNEU), pleural thickening (PLT), and normal using chest X-rays (CXR). The method that has been suggested is split down into three distinct parts. The first step involves utilizing the Info-MGAN network to perform segmentation on the raw CXR data to construct lung images of ten different chest diseases. In the second step, the segmented lung images are fed into a novel pipeline that extracts discriminatory features by using hand-crafted techniques such as SURF and ORB, and then these extracted features are fused to the trained DCNNs. At last, various machine learning (ML) models have been used as the last layer of the DCNN models for the classification of chest diseases. Comparison is made between the performance of various proposed architectures for classification, all of which integrate DCNNs, key point extraction methods, and ML models. We were able to attain a classification accuracy of 98.20&#x0025; for testing by utilizing the VGG-19 model with a softmax layer in conjunction with the ORB technique. Screening for COVID-19 and other lung ailments can be accomplished using the method that has been proposed. The robustness of the model was further confirmed by statistical analyses of the datasets using McNemar&#x2019;s and ANOVA tests respectively.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Hassaan Malik et al.",
      "keywords": "Convolutional neural network; Artificial intelligence; Deep learning; Medicine; Computer science; Atelectasis; Radiology; Pattern recognition (psychology); Lung; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3267492",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3093989074",
      "doi": "10.1109/access.2020.3033027",
      "title": "Recent Techniques and Trends for Retinal Blood Vessel Extraction and Tortuosity Evaluation: A Comprehensive Review",
      "abstract": "Retinal blood vessel segmentation plays an important part in the early diagnosis and treatment of eye disease. It is a tool for ophthalmologists. Many diseases can be identified by examining manifestations and images of blood vessels, including diabetic retinopathy, retinopathy of prematurity, age-related macular degeneration, retinopathy due to hypertension, glaucoma and others. Early detection allows physicians to provide patients with effective treatment, while in the opposite case, the late detection of retinal disease can ultimately lead to blindness. One of the indices when examining the retina is an evaluation of blood vessels based on tortuosity, i.e. the degree of curvature of blood vessels. This article presents a comprehensive overview of all segmentation techniques for retinal blood vessel extraction from images taken with a fundus camera in adults and older children or with a RetCam fundus camera in new-borns and younger children over the last 10 years. An integral part of this review is a comprehensive overview with information on all available public and private databases with retinal images. The review includes an evaluation of segmentation techniques based on objectivization parameters, including information on all objectivization parameters used in this article. As already mentioned, the degree of curvature of retinal blood vessels is used to classify severity of blood vessels tortuosity. There is no uniform metric for determining tortuosity, but this review presents a comprehensive overview of all metrics and calculations used to determine the degree of tortuosity of retinal blood vessels.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Alice Krestanova et al.",
      "keywords": "Tortuosity; Fundus (uterus); Retinal; Medicine; Glaucoma; Ophthalmology; Hypertensive retinopathy; Diabetic retinopathy; Retina; Retinopathy; Macular degeneration; Artificial intelligence; Computer science; Optometry; Diabetes mellitus",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3033027",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3053200815",
      "doi": "10.1109/ojemb.2020.3017130",
      "title": "Robust Classification of Intramuscular EMG Signals to Aid the Diagnosis of Neuromuscular Disorders",
      "abstract": "<i>Goal:</i> This article presents the design and validation of an accurate automatic diagnostic system to classify intramuscular EMG (iEMG) signals into healthy, myopathy, or neuropathy categories to aid the diagnosis of neuromuscular diseases. <i>Methods:</i> First, an iEMG signal is decimated to produce a set of \"disjoint\" downsampled signals, which are decomposed by the lifting wavelet transform (LWT). The Higuchi's fractal dimensions (FDs) of LWT coefficients in the subbands are computed. The FDs of LWT subband coefficients are fused with one-dimensional local binary pattern derived from each downsampled signal. Next, a multilayer perceptron neural network (MLPNN) determines the class labels of downsampled signals. Finally, the sequence of class labels is fed to the Boyer-Moore majority vote (BMMV) algorithm, which assigns a class to every iEMG signal. <i>Results:</i> The MLPNN-BMMV classifier was experimented with 250 iEMG signals belonging to three categories. The performance of the classifier was validated in comparison with state-of-the-art approaches. The MLPNN-BMMV has resulted in impressive performance measures (%) using a 10-fold cross-validation-accuracy = [Formula: see text], sensitivity (normal) = [Formula: see text], sensitivity (myopathy) = [Formula: see text], sensitivity (neuropathy) = [Formula: see text], specificity (normal) = [Formula: see text], specificity (myopathy) = [Formula: see text], and specificity (neuropathy) = [Formula: see text]-surpassing the existing approaches. <i>Conclusions:</i> A future research direction is to validate the classifier performance with diverse iEMG datasets, which would lead to the design of an affordable real-time expert system for neuromuscular disorder diagnosis.",
      "year": "2020",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Shobha Jose et al.",
      "keywords": "Physical medicine and rehabilitation; Electromyography; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2020.3017130",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387197312",
      "doi": "10.1109/tnsre.2023.3320693",
      "title": "Exploring Adaptive Graph Topologies and Temporal Graph Networks for EEG-Based Depression Detection",
      "abstract": "In recent years, Graph Neural Networks (GNNs) based on deep learning techniques have achieved promising results in EEG-based depression detection tasks but still have some limitations. Firstly, most existing GNN-based methods use pre-computed graph adjacency matrices, which ignore the differences in brain networks between individuals. Additionally, methods based on graph-structured data do not consider the temporal dependency information of brain networks. To address these issues, we propose a deep learning algorithm that explores adaptive graph topologies and temporal graph networks for EEG-based depression detection. Specifically, we designed an Adaptive Graph Topology Generation (AGTG) module that can adaptively model the real-time connectivity of the brain networks, revealing differences between individuals. In addition, we designed a Graph Convolutional Gated Recurrent Unit (GCGRU) module to capture the temporal dynamical changes of brain networks. To further explore the differential features between depressed and healthy individuals, we adopt Graph Topology-based Max-Pooling (GTMP) module to extract graph representation vectors accurately. We conduct a comparative analysis with several advanced algorithms on both public and our own datasets. The results reveal that our final model achieves the highest Area Under the Receiver Operating Characteristic Curve (AUROC) on both datasets, with values of 83% and 99%, respectively. Furthermore, we perform extensive validation experiments demonstrating our proposed method's effectiveness and advantages. Finally, we present a comprehensive discussion on the differences in brain networks between healthy and depressed individuals based on the outputs of our final model's AGTG and GTMP modules.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Gang Luo et al.",
      "keywords": "Computer science; Graph; Network topology; Adjacency matrix; Power graph analysis; Electroencephalography; Pooling; Adjacency list; Artificial intelligence; Theoretical computer science; Algorithm; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3320693",
      "cited_by_count": 25,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2913265552",
      "doi": "10.1109/jproc.2018.2889678",
      "title": "Engineering-Based Design Methodology for Embedding Ethics in Autonomous Robots",
      "abstract": "This paper explores the design process of robotics and autonomous systems using a co-design approach, applied ethics, and values-driven methods. Specifically, the approach seeks to move beyond traditional risk assessment toward a greater consideration of end-user exposure. The goal of the ethics-based co-design approach is to identify end-user and stakeholder values that guide the minimization of end-user vulnerability associated with the employment of autonomous systems. This design process is also used to identify positive consequences that probably increase human well-being as opposed to simply avoiding harm. We argue that biomedical autonomous systems design, during the preclinical phase, should bring together diverse stakeholders that would not traditionally be involved in design. We also argue that embedding ethical considerations in the engineering design process should bring together a diverse range of stakeholders to more accurately appreciate possible end-user implications of a design. With complex systems design, such as biotechnologies, greater awareness is necessary of the ethical implications of designed autonomy to end-user exposure.",
      "year": "2019",
      "journal": "Proceedings of the IEEE",
      "authors": "Lindsay Robertson et al.",
      "keywords": "Autonomy; Stakeholder; Computer science; Vulnerability (computing); Process (computing); Engineering design process; Human\u2013computer interaction; Embedding; User-centered design; Design process; Knowledge management; Engineering ethics; Risk analysis (engineering); Management science; Process management; Artificial intelligence; Engineering; Business; Computer security; Political science; Work in process; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2018.2889678",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4380633142",
      "doi": "10.1109/jtehm.2023.3285723",
      "title": "A Graph Convolutional Network Based on Univariate Neurodegeneration Biomarker for Alzheimer\u2019s Disease Diagnosis",
      "abstract": "The proposed UNB measures were superior to the conventional volume measures in describing the AD-induced cerebral cortex morphological changes. And the UNB-GCN framework combined with attention module may effectively improve the classification performance between MCI subjects and AD patients. Clinical and Translational Impact Statement: This study aims to predict the early AD patients, so as to help clinicians develop effective interventions to delay the deterioration of AD symptoms.",
      "year": "2023",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Zongshuai Qu et al.",
      "keywords": "Univariate; Neurodegeneration; Graph; Atrophy; Neuroimaging; Pattern recognition (psychology); Alzheimer's Disease Neuroimaging Initiative; Artificial intelligence; Alzheimer's disease; Computer science; Disease; Neuroscience; Psychology; Medicine; Pathology; Machine learning; Multivariate statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2023.3285723",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384916670",
      "doi": "10.1109/access.2023.3296882",
      "title": "Recommendations for Developing Immersive Virtual Reality Serious Game for Autism: Insights From a Systematic Literature Review",
      "abstract": "The use of serious games for the treatment of people with autism is currently considered a promising approach due to its positive effects on promoting learning through playful and motivating experiences. In recent years, increased research has focused on serious games utilizing Immersive Virtual Reality (IVR) technologies, such as large-scale projection-based systems and head-mounted displays. The high level of immersion provided by IVR has been found to benefit learning outcomes, as it reduces environmental distractions and helps individuals focus on learning tasks while also addressing social anxiety. Researchers have conducted significant work in this field over the past decade, yielding promising results. However, the development of these learning interventions comes with methodological challenges and issues, especially in how to conduct the development process and design IVR-based serious games for the learning of people with autism. Based on these premises, this systematic review thoroughly analyzes the literature on developing IVR-based serious games for individuals with autism, discussing inherent shortcomings and reflecting on them. Then, twenty IVR-based serious games for people with autism developed between 2009 and mid-2021 are selected and analyzed, focusing on the people engaged in the development process, the design methodology adopted, and the serious game design framework employed. From this analysis, a set of recommendations are proposed to support anyone interested in developing IVR-based serious games for people with autism. In addition, the gaps left unsolved in the autism literature are highlighted, upon which a research agenda is grounded.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Federica Caruso et al.",
      "keywords": "Autism; Virtual reality; Psychological intervention; Computer science; Set (abstract data type); Process (computing); Psychology; Video game; Applied psychology; Multimedia; Human\u2013computer interaction; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3296882",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2792547937",
      "doi": "10.1109/access.2018.2817022",
      "title": "A Data-Driven Knowledge Acquisition System: An End-to-End Knowledge Engineering Process for Generating Production Rules",
      "abstract": "Data-driven knowledge acquisition is one of the key research fields in data mining. Dealingwith large amounts of data has received a lot of attention in the field recently, and a number of methodologies have been proposed to extract insights from data in an automated or semi-automated manner. However, these methodologies generally target a specific aspect of the data mining process, such as data acquisition, data preprocessing, or data classification. However, a comprehensive knowledge acquisition method is crucial to support the end-to-end knowledge engineering process. In this paper, we introduce a knowledge acquisition system that covers all major phases of the cross-industry standard process for data mining. Acknowledging the importance of an end-to-end knowledge engineering process, we designed and developed an easy-to-use data-driven knowledge acquisition tool (DDKAT). The major features of the DDKAT are: (1) a novel unified features scoring approach for data selection; (2) a user-friendly data processing interface to improve the quality of the raw data; (3) an appropriate decision tree algorithm selection approach to build a classification model; and (4) the generation of production rules from various decision tree classification models in an automated manner. Furthermore, two diabetes studies were performed to assess the value of the DDKAT in terms of user experience. A total of 19 experts were involved in the first study and 102 students in the artificial intelligence domain were involved in the second study. The results showed that the overall user experience of the DDKAT was positive in terms of its attractiveness, as well as its pragmatic and hedonic quality factors.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Maqbool Ali et al.",
      "keywords": "Computer science; Knowledge acquisition; Domain knowledge; Data mining; Data pre-processing; Raw data; Process (computing); Data acquisition; Knowledge extraction; Decision tree; Machine learning; Knowledge engineering; End user; Artificial intelligence; Data science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2817022",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3198127988",
      "doi": "10.1109/jsen.2021.3110283",
      "title": "Bioimpedance Sensors: A Tutorial",
      "abstract": "Electrical bioimpedance entails the measurement of the electrical properties of tissues as a function of frequency. It is thus a spectroscopic technique. It has been applied in a plethora of biomedical applications for diagnostic and monitoring purposes. In this tutorial, the basics of electrical bioimpedance sensor design will be discussed. The electrode/electrolyte interface is thoroughly described, as well as methods for its modelling with equivalent circuits and computational tools. The design optimization and modelling of bipolar and tetrapolar bioimpedance sensors is presented in detail, based on the sensitivity theorem. Analytical and numerical modelling approaches for electric field simulations based on conformal mapping, point electrode approximations and the finite element method (FEM) are also elaborated. Finally, current trends on bioimpedance sensors are discussed followed by an overview of instrumentation methods for bioimpedance measurements, covering aspects of voltage signal excitations, current sources, voltage measurement front-end topologies and methods for computing the electrical impedance.",
      "year": "2021",
      "journal": "IEEE Sensors Journal",
      "authors": "Panagiotis Kassanos",
      "keywords": "Electronic engineering; Electrical impedance; Finite element method; Voltage; Computer science; Sensitivity (control systems); Electrical network; Electronic circuit; Instrumentation (computer programming); Electrical engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2021.3110283",
      "cited_by_count": 75,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4285241049",
      "doi": "10.1109/ojap.2022.3186643",
      "title": "A Review of Magnetic Field Emissions From the Human Body: Sources, Sensors, and Uses",
      "abstract": "It has long been common practice to capture the electric fields emanated by the human body as a means of detecting and/or monitoring diverse health conditions. However, these electric fields are strongly impacted by the complex permittivity of biological tissues which deteriorates their waveforms and limits their diagnostic capabilities. As an alternative, recent progress has been made in the measurement of bio-magnetic fields occur from the natural currents flowing through the body. The advantage in this case is, since tissues are non-magnetic, magnetic fields propagate in an uninterrupted manner towards the skin surface where they are eventually collected. This unveils game-changing opportunities for future medical diagnostics. Nevertheless, a major challenge associated with sensing these naturally emanated magnetic fields is that they are extremely weak, and in fact orders of magnitude smaller than those generated by the Earth. To this end, extensive efforts have been pursued to realize sensing technology that is sensitive enough to collect bio-magnetic fields. Example fields of use include magnetomyography (MMG), magnetocardiography (MCG), magnetoencephalography (MEG), and Magnetoneurography (MNG) (including magnetospinography (MSG)). This review will provide an overview of technologies used to sense bio-magnetic fields, list their merits and limits in a critical manner, and discuss clinical applications.",
      "year": "2022",
      "journal": "IEEE Open Journal of Antennas and Propagation",
      "authors": "Keren Zhu et al.",
      "keywords": "Magnetic field; Human health; Computer science; Physics; Medicine",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/ojap.2022.3186643",
      "cited_by_count": 32,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389076564",
      "doi": "10.1109/access.2023.3335314",
      "title": "Particle Swarm Optimization-Based Random Forest Framework for the Classification of Chronic Diseases",
      "abstract": "In this paper, a hybrid metaheuristic-based Machine learning approach has been propounded for the classification of various Chronic Diseases (CDs). The CDs often get misdiagnosed due to various issues viz., similar and overlapping symptoms, sensitive devices, lack of clinical experts, etc. Based on the above issues, this study has utilized a fusion of Particle Swarm Optimization with Random Forest (PSORF) for the automatic identification of CDs. The approach PSORF comprises of two main components: PSO for obtaining the minimal optimal feature set, also to optimize the performance of the RF classifier, and RF classifier for the classification of multiple CDs. In this research, five different CD datasets have been deployed onto a series of experiments have been conducted to identify the best approach for the classification of CDs. To address the issues of imbalanced and incomplete data in the datasets used, Synthetic Minority Oversampling Technique (SMOTE) and Expected Minimization (EM) Imputation techniques have been applied before training the model. This ensures the data quality is improved before being used for analysis. Furthermore, the performance of the PSO and RF classifiers has been compared with other metaheuristic and ML classifiers in terms of different performance metrics. For this purpose, Friedman&#x2019;s tests have been employed to calculate the mean ranks of all the classifiers across all the datasets for different metrics. The results showed that the proposed technique achieved the highest mean rank in terms of Accuracy, F-measure, and Receiver Operating Characteristics (ROC) across all five datasets.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Akansha Singh et al.",
      "keywords": "Random forest; Particle swarm optimization; Oversampling; Computer science; Artificial intelligence; Classifier (UML); Metaheuristic; Machine learning; Data mining; Pattern recognition (psychology); Receiver operating characteristic; Bandwidth (computing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3335314",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3153486604",
      "doi": "10.1109/tem.2021.3066564",
      "title": "Barriers and Enablers to the Implementation of Intelligent Guidance Systems for Patients in Chinese Tertiary Transfer Hospitals: Usability Evaluation",
      "abstract": "Since the early 2000s, information systems have been widely employed across hospitals in China, changing the way in which the processes are managed, improving customer satisfaction and strengthening business competence. Intelligent guidance systems for patients (IGSP), which resemble humanoid characteristics using artificial intelligence, assist patients in wayfinding, obtaining medical guidance, consultations, and other medical services, and can improve user experiences before, during, and after hospital visits. However, despite their widespread adoption, usability studies on such systems are scarce. To date, there is no practical or standardized measurement for system usability, leading to difficult inspection, maintenance, and servicing processes. In this article, we aim to determine the usability deficiency of IGSP and understand how various factors influence user satisfaction during their use. We employ the requirements set out in the ISO9241-11:2018 standard using two inspection methods with three experts and 346 valid end-users. First, a heuristic evaluation method is employed to detect usability problems and to demonstrate the violations of Nielsen's ten heuristic principles. Second, a system usability scale is applied to evaluate participants' satisfaction toward IGSP. Finally, the analysis of variance tests and multiple linear regression analyses is performed to establish the correlations between the user satisfaction and characteristics. The results show that a total of 78 problems violated the heuristic principles 169 times. These are divided into five categories: voice interaction, in-hospital navigation, medical consultation, interactive interface design, and miscellaneous. This article contributes to the existing literature on new technologies in healthcare organizations, demonstrating that IGSP can improve customer satisfaction during hospital visits.",
      "year": "2021",
      "journal": "IEEE Transactions on Engineering Management",
      "authors": "Hengkui Cao et al.",
      "keywords": "Usability; Heuristic evaluation; Computer science; Customer satisfaction; Usability goals; Patient satisfaction; Competence (human resources); Knowledge management; Human\u2013computer interaction; Nursing; Psychology; Medicine; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tem.2021.3066564",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4379739849",
      "doi": "10.1109/tmrb.2023.3282325",
      "title": "Electromyography-Based Control of Lower Limb Prostheses: A Systematic Review",
      "abstract": "Most amputations occur in lower limbs and despite improvements in prosthetic technology, no commercially available prosthetic leg uses electromyography (EMG) information as an input for control. Efforts to integrate EMG signals as part of the control strategy have increased in the last decade. In this systematic review, we summarize the research in the field of lower limb prosthetic control using EMG. Four different online databases were searched until June 2022: Web of Science, Scopus, PubMed, and Science Direct. We included articles that reported systems for controlling a prosthetic leg (with an ankle and/or knee actuator) by decoding gait intent using EMG signals alone or in combination with other sensors. A total of 1,331 papers were initially assessed and 121 were finally included in this systematic review. The literature showed that despite the burgeoning interest in research, controlling a leg prosthesis using EMG signals remains challenging. Specifically, regarding EMG signal quality and stability, electrode placement, prosthetic hardware, and control algorithms, all of which need to be more robust for everyday use. In the studies that were investigated, large variations were found between the control methodologies, type of research participant, recording protocols, assessments, and prosthetic hardware.",
      "year": "2023",
      "journal": "IEEE Transactions on Medical Robotics and Bionics",
      "authors": "Bahareh Ahkami et al.",
      "keywords": "Electromyography; Physical medicine and rehabilitation; Computer science; Scopus; Systematic review; Ankle; Web of science; Gait; Medicine; MEDLINE; Meta-analysis; Surgery",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tmrb.2023.3282325",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389076761",
      "doi": "10.1109/access.2023.3337528",
      "title": "DEU-Net: Dual-Encoder U-Net for Automated Skin Lesion Segmentation",
      "abstract": "The computer-aided diagnosis (CAD) of skin diseases relies heavily on automated skin lesion segmentation, albeit presenting considerable challenges due to lesion diversity in shape, size, color, and texture, as well as potential blurry boundaries with surrounding tissues. Traditional Convolutional Neural Networks (CNN) typically underperform in this domain, given their inherent constraints in global context information capture. In the present study, we present a new U-shaped network, Dual-Encoder U-Net (DEU-Net), which is based on an encoder-decoder architecture. DEU-Net integrates a dual-encoder branch comprising a convolutional encoder and a transformer encoder, thereby facilitating the concurrent extraction of local features and global contextual information. Additionally, in order to enhance the performance of DEU-Net, we employ an integrated test-time augmentation technique. To ascertain the efficiency and superiority of our proposed methodology, we performed comprehensive experiments across four widely accessible skin lesion datasets, namely ISIC 2016, ISIC 2017, ISIC 2018, and PH2. The Dice coefficients achieved on these datasets were 92.90&#x0025;, 87.16&#x0025;, 90.81&#x0025;, and 95.65&#x0025;, respectively. These results demonstrate superior performance compared to most current state-of-the-art methods. The source code is released at <uri>https://github.com/alikm6/DEU-Net</uri>.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ali Karimi et al.",
      "keywords": "Computer science; Encoder; Artificial intelligence; Segmentation; Convolutional neural network; Context (archaeology); Source code; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3337528",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4384283976",
      "doi": "10.1109/tnsre.2023.3295453",
      "title": "Transfer Learning on Electromyography (EMG) Tasks: Approaches and Beyond",
      "abstract": "Machine learning on electromyography (EMG) has recently achieved remarkable success on various tasks, while such success relies heavily on the assumption that the training and future data must be of the same data distribution. However, this assumption may not hold in many real-world applications. Model calibration is required via data re-collection and label annotation, which is generally very expensive and time-consuming. To address this issue, transfer learning (TL), which aims to improve target learners' performance by transferring knowledge from related source domains, is emerging as a new paradigm to reduce the amount of calibration effort. This survey assesses the eligibility of more than fifty published peer-reviewed representative transfer learning approaches for EMG applications. Unlike previous surveys on purely transfer learning or EMG-based machine learning, this survey aims to provide insight into the biological foundations of existing transfer learning methods on EMG-related analysis. Specifically, we first introduce the muscles' physiological structure, the EMG generating mechanism, and the recording of EMG to provide biological insights behind existing transfer learning approaches. Further, we categorize existing research endeavors into data based, model based, training scheme based, and adversarial based. This survey systematically summarizes and categorizes existing transfer learning approaches for EMG related machine learning applications. In addition, we discuss possible drawbacks of existing works and point out the future direction of better EMG transfer learning algorithms to enhance practicality for real-world applications.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Di Wu et al.",
      "keywords": "Transfer of learning; Computer science; Machine learning; Categorization; Artificial intelligence; Point (geometry); Mechanism (biology); Transfer (computing)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3295453",
      "cited_by_count": 46,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4393241223",
      "doi": "10.1109/tnsre.2024.3381979",
      "title": "Lower-Limb Exoskeletons Appeal to Both Clinicians and Older Adults, Especially for Fall Prevention and Joint Pain Reduction",
      "abstract": "Exoskeletons are a burgeoning technology with many possible applications to improve human life; focusing the effort of exoskeleton research and development on the most important features is essential for facilitating adoption and maximizing positive societal impact. To identify important focus areas for exoskeleton research and development, we conducted a survey with 154 potential users (older adults) and another survey with 152 clinicians. The surveys were conducted online and to ensure a consistent concept of an exoskeleton across respondents, an image of a hip exoskeleton was shown during exoskeleton-related prompts. The survey responses indicate that both older adults and clinicians are open to using exoskeletons, fall prevention and joint pain reduction are especially important features, and users are likely to wear an exoskeleton in the scenarios when it has the greatest opportunity to help prevent a fall. These findings can help inform future exoskeleton research and guide the development of devices that are accepted, used, and provide meaningful benefit to users.",
      "year": "2024",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Michael Raitor et al.",
      "keywords": "Exoskeleton; Fall prevention; Medicine; Physical medicine and rehabilitation; Human factors and ergonomics; Applied psychology; Psychology; Poison control; Medical emergency",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2024.3381979",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3096252612",
      "doi": "10.1109/access.2020.3030621",
      "title": "Deep Learning for Multi-Class Antisocial Behavior Identification From Twitter",
      "abstract": "Social Media has become an integral part of our daily life. Not only it enables collaboration and flow of information but has also become an imperative tool for businesses and governments around the world. All this makes a compelling case for everyone to be on some sort of online social media platform. However, this virtuousness is overshadowed by some of its shortcomings. The manifestation of antisocial behaviour online is a growing concern that hinders participation and cultivates numerous social problems. Antisocial behaviour exists in its various forms such as aggression, disregard for safety, lack of remorse, unlawful behaviour, etc. The paper introduces a deep learning-based approach to detect and classify online antisocial behaviour (ASB). The automatic content classification addresses the issue of scalability, which is imperative when dealing with online platforms. A benchmark dataset was created with multi-class annotation under the supervision of a domain expert. Extensive experiments were conducted with multiple deep learning algorithms and their superior results were validated against the results from the traditional machine learning algorithms. Visually enhanced interpretation of the classification process is presented for model and error analyses. Accuracy of up to 99% in class identification was achieved on the ground truth dataset for empirical validation. The study is an evidence of how the cutting-edge deep learning technology can be utilized to solve a real-world problem of curtailing antisocial behaviour, which is a public health threat and a social problem.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ravinder Singh et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Social media; Benchmark (surveying); Identification (biology); Class (philosophy); Scalability; Deep learning; Empirical research; Process (computing); Data science; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3030621",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3187839449",
      "doi": "10.1109/jbhi.2021.3103389",
      "title": "Integrated Clinical and CT Based Artificial Intelligence Nomogram for Predicting Severity and Need for Ventilator Support in COVID-19 Patients: A Multi-Site Study",
      "abstract": "Almost 25% of COVID-19 patients end up in ICU needing critical mechanical ventilation support. There is currently no validated objective way to predict which patients will end up needing ventilator support, when the disease is mild and not progressed. N = 869 patients from two sites (D<sub>1</sub>: N = 822, D<sub>2</sub>: N = 47) with baseline clinical characteristics and chest CT scans were considered for this study. The entire dataset was randomly divided into 70% training, D<sub>1</sub><sup>train</sup> (N = 606) and 30% test-set (D<sup>test</sup>: D<sub>1</sub><sup>test</sup> (N = 216) + D<sub>2</sub> (N = 47)). An expert radiologist delineated ground-glass-opacities (GGOs) and consolidation regions on a subset of D<sub>1</sub><sup>train</sup>, (D<sub>1</sub><sup>train_sub</sup>, N = 88). These regions were automatically segmented and used along with their corresponding CT volumes to train an imaging AI predictor (AIP) on D<sub>1</sub><sup>train</sup> to predict the need of mechanical ventilators for COVID-19 patients. Finally, top five prognostic clinical factors selected using univariate analysis were integrated with AIP to construct an integrated clinical and AI imaging nomogram (ClAIN). Univariate analysis identified lactate dehydrogenase, prothrombin time, aspartate aminotransferase, %lymphocytes, albumin as top five prognostic clinical features. AIP yielded an AUC of 0.81 on D<sup>test</sup> and was independently prognostic irrespective of other clinical parameters on multivariable analysis (p<0.001). ClAIN improved the performance over AIP yielding an AUC of 0.84 (p = 0.04) on D<sup>test</sup>. ClAIN outperformed AIP in predicting which COVID-19 patients ended up needing a ventilator. Our results across multiple sites suggest that ClAIN could help identify COVID-19 with severe disease more precisely and likely to end up on a life-saving mechanical ventilation.",
      "year": "2021",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Amogh Hiremath et al.",
      "keywords": "Nomogram; Medicine; Univariate analysis; Mechanical ventilation; Coronavirus disease 2019 (COVID-19); Univariate; Radiology; Nuclear medicine; Internal medicine; Multivariate analysis; Disease; Machine learning; Multivariate statistics; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2021.3103389",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3158354756",
      "doi": "10.1109/access.2021.3076148",
      "title": "Mobile Learning as the Key to Higher Education Innovation: A Systematic Mapping",
      "abstract": "The study of educational innovations has attracted increasing attention from academics and researchers around the world. Educational innovation proposes the implementation of new approaches or practices that are beneficial and make an impact on individuals or academic communities. The current educational model of many higher education institutions (HEIs) was not designed for this generation of \u201cdigital natives\u201d. For this reason, HEIs face the challenge of building teaching strategies that generate meaningful educational experiences. This research seeks to address this issue through a systematic mapping that includes empirical research papers from 2015 to 2020 that study innovations in educational practices using mobile devices. A qualitative and quantitative approach was applied using a four-stage research methodology to evidence innovation in higher education. After employing the selected methodology and applying all the exclusion criteria, 27 papers related to the research topic were identified. Mapping was also performed between the corpus of papers and five dimensions on educational innovation (the purpose of learning, the context of learning, the role of the teacher, the role of the learner, and the evidence of the outcome). The findings reveal that the role of the teacher is the dimension that is least analyzed in innovation initiatives, whereas the most analyzed dimension is the purpose of learning. The goal of this work was to explore and identify educational innovations and unveil uncovered fields of research to generate opportunities for new lines of research in educational innovation.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Santiago Criollo-C et al.",
      "keywords": "Context (archaeology); Knowledge management; Higher education; Educational research; Dimension (graph theory); Computer science; Face (sociological concept); Empirical research; Sociology; Pedagogy; Political science; Social science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3076148",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387965551",
      "doi": "10.1109/tvcg.2023.3327158",
      "title": "Heuristics for Supporting Cooperative Dashboard Design",
      "abstract": "Dashboards are no longer mere static displays of metrics; through functionality such as interaction and storytelling, they have evolved to support analytic and communicative goals like monitoring and reporting. Existing dashboard design guidelines, however, are often unable to account for this expanded scope as they largely focus on best practices for visual design. In contrast, we frame dashboard design as facilitating an analytical conversation: a cooperative, interactive experience where a user may interact with, reason about, or freely query the underlying data. By drawing on established principles of conversational flow and communication, we define the concept of a cooperative dashboard as one that enables a fruitful and productive analytical conversation, and derive a set of 39 dashboard design heuristics to support effective analytical conversations. To assess the utility of this framing, we asked 52 computer science and engineering graduate students to apply our heuristics to critique and design dashboards as part of an ungraded, opt-in homework assignment. Feedback from participants demonstrates that our heuristics surface new reasons dashboards may fail, and encourage a more fluid, supportive, and responsive style of dashboard design. Our approach suggests several compelling directions for future work, including dashboard authoring tools that better anticipate conversational turn-taking, repair, and refinement and extending cooperative principles to other analytical workflows.",
      "year": "2023",
      "journal": "IEEE Transactions on Visualization and Computer Graphics",
      "authors": "Vidya Setlur et al.",
      "keywords": "Computer science; Heuristics; Conversation; Workflow; Human\u2013computer interaction; Dashboard; Data visualization; Visualization; Data science; Artificial intelligence; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tvcg.2023.3327158",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4366446443",
      "doi": "10.1109/access.2023.3268551",
      "title": "User Biometric Identification Methodology via EEG-Based Motor Imagery Signals",
      "abstract": "Human brain activities&#x2014;electroencephalogram (EEG) signals&#x2014;are likely to provide a secure biometric approach for user identification because they are more sensitive, secretive, and difficult to replicate. Many studies have recently focused on identifying and quantifying important frequency patterns in motor imagery (MI), recorded through EEG. However, there is still a lack of an optimal methodology for recognizing users with EEG-based MI. Therefore, we aimed to propose an EEG-MI methodology that utilizes optimized feature extraction methods and classifiers to improve user-aware accuracy. To accomplish this goal, we extracted four features related to MI and compared the accuracies for recognizing users using a support vector machine (SVM) and Gaussian Na&#x00EF;ve Bayes (GNB). We then used the half-total error rate (HTER) to determine whether the results were reliable due to an imbalance problem caused by the differences in the data sizes. Thus, we used a common spatial pattern (CSP) to achieve the highest user identification accuracies of 98.97&#x0025; and 97.47&#x0025; using SVM and GNB, respectively. All user recognition accuracies are guaranteed by the HTERs, which are below 0.5. However, CSP has the disadvantage of decreasing accuracy on a small dataset scale. Therefore, we proposed and tested a statistical methodology for estimating a minimum dataset scale to ensure CSP performance. We confirm that the used dataset adequately guarantees CSP performance. This study makes a great contribution to the field of information security by presenting an EEG-MI methodology that improves the identification accuracy in human biometrics based on EEG-MI signals.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "SuJin Bak et al.",
      "keywords": "Computer science; Biometrics; Support vector machine; Artificial intelligence; Electroencephalography; Identification (biology); Pattern recognition (psychology); Naive Bayes classifier; Feature extraction; Motor imagery; Machine learning; Speech recognition; Data mining; Brain\u2013computer interface",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3268551",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392172815",
      "doi": "10.1109/access.2024.3370684",
      "title": "MediSign: An Attention-Based CNN-BiLSTM Approach of Classifying Word Level Signs for Patient-Doctor Interaction in Hearing Impaired Community",
      "abstract": "Along with day-to-day communication, receiving medical care is quite challenging for the hearing impaired and mute population, especially in developing countries where medical facilities are not as modernized as in the West. A word-level sign language interpretation system that is aimed toward detecting medically relevant signs can allow smooth communication between doctors and hearing impaired patients, ensuring seamless medical care. To that end, a dataset from twenty distinct signers of diverse backgrounds performing 30 frequently used words in patient-doctor interaction was created. The proposed system has been built employing MobileNetV2 in conjunction with an attention-based Bidirectional LSTM network to achieve robust classification, where the validation accuracy and f1-scores were 95.83% and 93%, respectively. Notably, the accuracy of the proposed model surpasses the recent word-level sign language classification method in a medical context by 5%. Furthermore, the comparison of evaluation metrics with contemporary word-level sign language recognition models in American, Arabic, and German Sign Language further affirmed the capability of the proposed architecture.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Md. Amimul Ihsan et al.",
      "keywords": "Computer science; Sign language; Context (archaeology); Arabic; Word (group theory); Sign (mathematics); Natural language processing; Artificial intelligence; Speech recognition; Linguistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3370684",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391697034",
      "doi": "10.1109/access.2024.3364676",
      "title": "Drone Technologies: A Tertiary Systematic Literature Review on a Decade of Improvements",
      "abstract": "Unmanned aerial vehicles (UAVs) have emerged as versatile tools with significant potential in various fields, including, but not limited to civil engineering, ecology, networking and precision agriculture. Systematic literature reviews (SLRs) play a crucial role in assessing the quality of research methods and approaches, aiding researchers and practitioners in selecting and optimizing their projects. However, the quality assessment of UAV-related SLRs and the aggregation of UAV technologies across research fields remain limited. This study aims to address these gaps by conducting a tertiary literature review (TLR) that assesses the quality of SLRs, aggregates data across research fields, and provides guidelines for researchers and practitioners in the UAV community. Based on a review of 73 SLRs, it is evident that the quality of UAV-related SLRs is generally low, with a lack of quality assessment and inadequate reporting of detailed information on primary studies. Consequently, this study presents reporting items and example quality assessment ratings sourced from the SLRs to enhance the transparency and comparability of future UAV-related research. Additionally, it highlights common limitations faced by UAV applications, such as regulatory, technical, social, and research-related challenges, which require attention for progress in the field. Overall, this study aims to enhance the quality and knowledge sharing in the UAV research community by providing insights into the current state of UAV-related SLRs and offering practical guidance for researchers and practitioners through the provision of data-extraction templates and quality control questions for future UAV-related reviews and primary research.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Jurrian Doornbos et al.",
      "keywords": "Comparability; Computer science; Quality (philosophy); Transparency (behavior); Systematic review; Data science; Field (mathematics); Political science; MEDLINE; Computer security",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3364676",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4206176813",
      "doi": "10.1109/access.2021.3132133",
      "title": "Computer-Aided Ear Diagnosis System Based on CNN-LSTM Hybrid Learning Framework for Video Otoscopy Examination",
      "abstract": "Ear disorders are among the most common diseases treated in primary care, with a high&#13;\\npercentage of non-relevant referrals. The conventional diagnostic procedure is done by a visual examination&#13;\\nof the ear canal and tympanic membrane. Consequently, the accuracy of the diagnosis is affected by observerobserver&#13;\\nvariation, depending on the technical skill and experiences of the physician as well as on the&#13;\\nsubjective bias of the observer. This situation impacts the proper implementation of treatments, increases&#13;\\nhealth costs, and can lead to serious health complications. To eliminate subjectivity and enhance diagnostic&#13;\\naccuracy, we present a diagnostic tool for nine ear conditions in a computer-aided diagnosis scheme.&#13;\\nWe propose a hybrid learning framework based on convolutional and recurrent neural networks for video&#13;\\notoscopy analysis. The proposed method rst extracts the deep features of each relevant frame from the video.&#13;\\nThen, a Long Short-term Memory network is introduced to learn spatial sequential data by analyzing deep&#13;\\nfeatures for a certain time interval.We carried out the study in collaboration with the Clinical Hospital of the&#13;\\nUniversity of Chile and included 875 subjects in a period of 12 months (continuous). The experiments were&#13;\\nconducted on a new video otoscopy dataset and showed high performance in terms of accuracy (98.15%),&#13;\\nprecision (91.94%), sensitivity (91.67%), speci city (98.96%), and F1-score (91.51%). To the best of our&#13;\\nknowledge, the proposed system is capable of predicting more diagnoses of ear conditions known to date with&#13;\\nhigh performance. Our system is designed to assist in a real otoscopy examination by analyzing a sequence&#13;\\nof images instead of a still image as previous state-of-the-art works. This advantage allows it to provide a&#13;\\ncomprehensive diagnosis of both eardrum and ear canal diseases.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Michelle Visca\u00edno et al.",
      "keywords": "Computer science; Convolutional neural network; Medical diagnosis; Artificial intelligence; Deep learning; Observer (physics); Machine learning; Medicine; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3132133",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385834564",
      "doi": "10.1109/tnsre.2023.3305351",
      "title": "What Can Facial Movements Reveal? Depression Recognition and Analysis Based on Optical Flow Using Bayesian Networks",
      "abstract": "Recent evidence have demonstrated that facial expressions could be a valid and important aspect for depression recognition. Although various works have been achieved in automatic depression recognition, it is a challenge to explore the inherent nuances of facial expressions that might reveal the underlying differences between depressed patients and healthy subjects under different stimuli. There is a lack of an undisturbed system that monitors depressive patients' mental states in various free-living scenarios, so this paper steps towards building a classification model where data collection, feature extraction, depression recognition and facial actions analysis are conducted to infer the differences of facial movements between depressive patients and healthy subjects. In this study, we firstly present a plan of dividing facial regions of interest to extract optical flow features of facial expressions for depression recognition. We then propose facial movements coefficients utilising discrete wavelet transformation. Specifically, Bayesian Networks equipped with construction of Pearson Correlation Coefficients based on discrete wavelet transformation is learnt, which allows for analysing movements of different facial regions. We evaluate our method on a clinically validated dataset of 30 depressed patients and 30 healthy control subjects, and experiments results obtained the accuracy and recall of 81.7%, 96.7%, respectively, outperforming other features for comparison. Most importantly, the Bayesian Networks we built on the coefficients under different stimuli may reveal some facial action patterns of depressed subjects, which have a potential to assist the automatic diagnosis of depression.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Yu Ma et al.",
      "keywords": "Wavelet; Facial expression; Artificial intelligence; Pattern recognition (psychology); Depression (economics); Feature (linguistics); Bayesian probability; Bayesian network; Facial recognition system; Psychology; Computer science; Recall; Feature extraction; Transformation (genetics); Face (sociological concept); Cognitive psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3305351",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3133604223",
      "doi": "10.1109/access.2021.3063786",
      "title": "Guiding Measurement Protocols of Connected Medical Devices Using Digital Twins: A Statistical Methodology Applied to Detecting and Monitoring Lymphedema",
      "abstract": "International audience",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Lo\u00efc B\u00e9thencourt et al.",
      "keywords": "Computer science; Breast cancer; Robustness (evolution); Lymphedema; Phone; Protocol (science); Medical physics; Medicine; Cancer; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3063786",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387831808",
      "doi": "10.1109/access.2023.3326421",
      "title": "Enhancing Brain Tumor Diagnosis: Transitioning From Convolutional Neural Network to Involutional Neural Network",
      "abstract": "] Accurate classification of brain tumors is essential for effective medical diagnosis and treatment planning. Traditional approaches rely on convolutional neural networks (CNNs) for tumor detection, but they often suffer from high computational demands due to the large number of parameters. In this paper, we propose a novel approach for brain tumor classification using involutional neural networks (InvNets), which are designed to mitigate the parameter-intensive nature of CNNs. Unlike the spatial-agnostic and channel-specific convolution kernel, the involution kernel is location-specific and channel-agnostic. This location-specific operation allows the network to adapt to various visual patterns with respect to different spatial locations, enhancing its ability to capture intricate features within the medical images. Our study focuses on a four-class brain tumor classification problem, aiming to differentiate between different tumor types based on medical imaging data. In a comparative analysis, we demonstrate that conventional CNNs require over 4 million parameters, whereas our proposed InvNets require less than 0.2 million parameters, making them more efficient and resource-friendly. The evaluation of both CNNs and InvNets is carried out using standard performance matrices: accuracy, precision, recall, F1 score, and AUC-ROC values. Our findings reveal that the InvNets consistently outperform traditional CNNs. The InvNet architecture achieves an impressive 92&#x0025; accuracy rate, showcasing its potential for accurate brain tumor classification. This improved accuracy, combined with the reduced parameter count, highlights the effectiveness of InvNets for medical image analysis tasks, especially in scenarios with limited computational resources.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Abdullah A. Asiri et al.",
      "keywords": "Convolutional neural network; Computer science; Artificial intelligence; Kernel (algebra); Contextual image classification; Medical imaging; Pattern recognition (psychology); Machine learning; Artificial neural network; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326421",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4327664049",
      "doi": "10.1109/access.2023.3257767",
      "title": "CrossTransUnet: A New Computationally Inexpensive Tumor Segmentation Model for Brain MRI",
      "abstract": "Brain tumors are usually fatal diseases with low life expectancies due to the organs they affect, even if the tumors are benign. Diagnosis and treatment of these tumors are challenging tasks, even for experienced physicians and experts, due to the heterogeneity of tumor cells. In recent years, advances in deep learning (DL) methods have been integrated to aid in the diagnosis, detection, and segmentation of brain neoplasms. However, segmentation is a computationally expensive process, typically based on convolutional neural networks (CNNs) in the UNet framework. While UNet has shown promising results, new models and developments can be incorporated into the conventional architecture to improve performance. In this research, we propose three new, computationally inexpensive, segmentation networks inspired by Transformers. These networks are designed in a 4-stage deep encoder-decoder structure and implement our new cross-attention model, along with separable convolution layers, to avoid the loss of dimensionality of the activation maps and reduce the computational cost of the models while maintaining high segmentation performance. The new attention model is integrated in different configurations by modifying the transition layers, encoder, and decoder blocks. The proposed networks are evaluated against the classical UNet network, showing that our networks have differences of up to an order of magnitude in the number of training parameters. Additionally, one of the models outperforms UNet, achieving training in significantly less time and with a Dice Similarity Coefficient (DSC) of up to 94&#x0025;, ensuring high effectiveness in brain tumor segmentation.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Andr\u00e9s Anaya-Isaza et al.",
      "keywords": "Computer science; Segmentation; Deep learning; Artificial intelligence; Encoder; Convolutional neural network; Pattern recognition (psychology); Curse of dimensionality; Image segmentation; Artificial neural network; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3257767",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391953422",
      "doi": "10.1109/access.2024.3367774",
      "title": "Lumbar Disease Classification Using an Involutional Neural Based VGG Nets (INVGG)",
      "abstract": "Degenerative diseases of the lumbar spine, such as spondylolisthesis, disc degeneration, and lumbar spinal stenosis, are major contributors to global disability. Accurate classification of lumbar diseases is crucial for effective medical diagnosis. This paper introduces an innovative methodology for lumbar disease classification, addressing the limitations of traditional convolutional neural networks (CNNs). We propose a novel approach, InVGG, which combines involutional neural networks with the VGG architecture. Unlike traditional CNNs, InVGG utilizes involution kernels that are location-specific and channel-agnostic, enhancing its adaptability to varied visual patterns in medical images. Our study focuses on a four-class lumbar disease classification problem using sagittal T2 MRI images. The evaluation of InVGG is compared with traditional CNNs (VGG model) and machine learning algorithms, demonstrating superior performance in terms of accuracy, precision, recall, and AUC ROC values. InVGG achieves an impressive 96&#x0025; accuracy on the testing set and 99&#x0025; on the training set, showcasing its potential for accurate spinal lumbar disease classification. The reduced parameter count of InVGG compared to CNNs (VGG) makes it more resource-efficient, especially in scenarios with limited computational resources and datasets. The promising results position InVGG as a valuable tool for precise lumbar disease classification, with implications for improving patient care in resource-constrained scenarios.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Biniyam Mulugeta Abuhayi et al.",
      "keywords": "Computer science; Artificial neural network; Lumbar; Artificial intelligence; Pattern recognition (psychology); Medicine; Radiology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3367774",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4328030774",
      "doi": "10.1109/jbhi.2023.3259069",
      "title": "Repeated Photobiomodulation Induced Reduction of Bilateral Cortical Hemodynamic Activation During a Working Memory Task in Healthy Older Adults",
      "abstract": "Transcranial photobiomodulation (tPBM) is an emerging non-invasive light-based neuromodulation technique that shows promising potential for improving working memory (WM) performance in older adults. However, the neurophysiological mechanisms associated with tPBM that underlie the improvement of WM and the persistence of such improvement have not been investigated. Sixty-one healthy older adults were recruited to receive a baseline sham stimulation, followed by one-week active tPBM (12 min daily, 1064-nm laser, 250 mW/cm<sup>2</sup>) and three-week follow-ups. N-back WM task was conducted on post-stimulation of the baseline, the first (Day 1) and seventh (Day 7) days of the active treatment, and at the follow-ups. During the task, functional near-infrared spectroscopy (fNIRS) imaging was employed to record the cortical hemodynamic changes. Brain activations during the active and follow-up sessions were compared with the baseline to determine how tPBM had changed cortical hemodynamic activity and how long these changes persisted. We found that tPBM stimulation on Day 1 induced significantly decreased activation in the right hemisphere during the 3-back. The decreased activation expanded from only the right hemisphere on Day 1 to both hemispheres on Day 7. The decreased activation persisted for one week in the right supramarginal gyrus and the left angular gyrus and two weeks in the left somatosensory association cortex. These activation changes were accompanied by significantly improved task accuracy during the N-back. These findings provide important evidence for understanding neural mechanisms underlying cognitive enhancement after tPBM.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Zhishan Hu et al.",
      "keywords": "Hemodynamics; Working memory; Task (project management); Reduction (mathematics); Physical medicine and rehabilitation; Medicine; Psychology; Cardiology; Neuroscience; Cognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3259069",
      "cited_by_count": 24,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3089686247",
      "doi": "10.1109/access.2020.3028527",
      "title": "A Wearable Device for Indoor Imminent Danger Detection and Avoidance With Region-Based Ground Segmentation",
      "abstract": "Avoiding objects independently in indoor environments for individuals with severe visual impairment is one of the significant challenges in daily life. This paper presents a wearable application to help visually impaired people quickly build situational awareness and traverse safely. The system utilizes Red, Green, Blue, and Depth (RGB-D) camera and an Inertial Measurement Unit (IMU) to detect objects and the collision-free path in real-time. A region proposal module is presented to decide where to identify the ground from 3D point clouds. The segmented ground area can act as the traversable path, and its corresponding region in the image is removed to prevent detecting painted objects. The system can provide information about the category, distance, and direction of the detected objects by fusing the depth image and the neural network results. A 3D acoustic feedback mechanism is designed to improve the situational awareness for visually impaired people, and guild them traverse safely. The advantage of this system is that our 3D region proposal module can robustly propose the potential ground region and greatly reduce the computation cost of the ground segmentation. Besides, a typical machine-learning-based approach may miss objects because they could not be recognized, though they still may pose a danger. Another advantage of our approach is that the imminent danger detector can detect such unrecognizable objects to help users avoid a collision. Finally, experimental results demonstrate that the proposed system can be a useful indoor assistant tool to help blind individuals with collision avoidance and wayfinding.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Zhongen Li et al.",
      "keywords": "Computer science; Computer vision; Traverse; Inertial measurement unit; Artificial intelligence; Situation awareness; Wearable computer; Point cloud; Collision avoidance; Segmentation; Ground truth; Orientation (vector space); Collision; Computer security; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3028527",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2981356759",
      "doi": "10.1109/access.2019.2949643",
      "title": "Implementation and Rehabilitation Application of Sports Medical Deep Learning Model Driven by Big Data",
      "abstract": "A large number of unlabeled and limited style data greatly reduces the reuse possibility of existing motion sequences. Effective classification and fragment splicing have become an important way of data reuse. Aiming at these two problems, this paper focuses on the great success of deep learning in the field of graphics and iconography. Based on the theory of Restricted Boltzmann Machine (RBM), a spatio-temporal feature extraction model for human skeleton medical motion sequences is established. The research results are mainly manifested in three aspects. (1) In this paper, stack factor decomposition spatiotemporal feature model and discriminate RBM are used to construct semi-supervised combination model. (2) The underlying model firstly uses the idea of weight decomposition to construct the three channel generative RBM model; and then it extracts the abstract temporal and spatial characteristics of the original motion sequence. Furthermore, it identifies the behavior style of the current input segment at the top using the discriminate RBM model. Finally conduct the stylistic statistics of the whole motion sequence in the voting space. (3) An unsupervised similar frame detection model is constructed by using 3D convolution RBM's perception of human adjacent joints' linkage. In this way, Candidate frames for constructing graph model nodes are obtained. Trajectory and style switching control is realized based on attitude similarity screening criteria. The simulation experiment verifies the superiority and reliability of the algorithm, and it is effectively applied in rehabilitation training.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Yanfeng Su",
      "keywords": "Computer science; Artificial intelligence; Generative model; Restricted Boltzmann machine; Motion capture; Motion (physics); Feature (linguistics); Pattern recognition (psychology); Deep learning; Machine learning; Construct (python library); Similarity (geometry); Generative grammar",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2949643",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312837141",
      "doi": "10.1109/access.2022.3215706",
      "title": "Prediction Methods of Common Cancers in China Using PCA-ANN and DBN-ELM-BP",
      "abstract": "Accurate prediction of cancer cases is crucial for diagnosis of cancer at an early stage because a long-lasting chronic disease is harmful to both physical and mental health. While medical data about healthcare and health obtained from questionnaire, the true positive rate of cancers predicted by traditional methods is low. Machine learning can provide a pattern for classification for types of cancer (mainly including lung cancer, liver cancer, upper gastrointestinal cancer, lower gastrointestinal cancer and breast cancer) using instances of early questionnaire screening. The screening covered 3411 respondents in this study. Principal component analysis (PCA) is used to generate attributes, coupled with artificial neural network (ANN) technology to conduct cancer prediction by providing 28 attributes into models. While deep belief network (DBN) is used for unsupervised training and extracting relevant attributes. Extreme learning machine (ELM) optimizes DBN and conducts supervised classification. Back propagation (BP) algorithm conducts supervised fine tuning. Finally, PCA-ANN and DBN-ELM-BP common cancers prediction models are established. The training set and testing set of PCA-ANN model gives 35.29&amp;#x0025; and 37.5&amp;#x0025; sensitivity, 98.36&amp;#x0025; and 98.33&amp;#x0025; specificity, 97.01&amp;#x0025; and 97.85&amp;#x0025; accuracy, an area under the receiver operating characteristic curve (AUC) 0.7245 and 0.7221, respectively. While the training set and testing set of DBN-ELM-BP model gives 58.83&amp;#x0025; and 62.5&amp;#x0025; sensitivity, 98.31&amp;#x0025; and 98.52&amp;#x0025; specificity, 98.03&amp;#x0025; and 98.24&amp;#x0025; accuracy, AUC 0.7747 and 0.7238, respectively. The results show that DBN-ELM-BP model can provide a method to predict the possibility of common cancers, which is non-invasive and economical for clinicians to make diagnostic decisions.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Huitao Qi et al.",
      "keywords": "Artificial intelligence; Deep belief network; Extreme learning machine; Artificial neural network; Receiver operating characteristic; Cancer; Computer science; Backpropagation; Machine learning; Deep learning; Principal component analysis; Pattern recognition (psychology); Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3215706",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4285139457",
      "doi": "10.1109/access.2022.3174094",
      "title": "Toward Successful DevOps: A Decision-Making Framework",
      "abstract": "DevOps (development and operations) is a set of collaborative practices that automate delivery of new software updates with the aim to reduce the development life cycle and produce quality software products. Software organizations face several barriers while adopting DevOps practices as the integration of development and operation teams requires merger of different processes, tools, and skill sets. This study aims to develop a prioritization-based framework of the DevOps best practices based on evidence collected from industry experts. To attain the study aims, firstly, a systematic literature review was conducted to identify DevOps best practices reported in the literature. Next, a questionnaire survey study was conducted to receive insight from industry practitioners for the identified best practice. Finally, the fuzzy-AHP technique was applied to prioritize the best practices concerning to the significance for DevOps process. We believe that the identified best practices, their categorization and fuzzy-AHP based framework will help industry experts to revise and improve their strategies to make the DevOps process sustainable.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Muhammad Azeem Akbar et al.",
      "keywords": "DevOps; Best practice; Computer science; Process management; Agile software development; Scrum; Knowledge management; Software development process; Process (computing); Software development; Engineering management; Software; Software engineering; Engineering; Software deployment; Management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3174094",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4295308577",
      "doi": "10.1109/access.2022.3206389",
      "title": "A Deep Convolutional Neural Networks Based Approach for Alzheimer\u2019s Disease and Mild Cognitive Impairment Classification Using Brain Images",
      "abstract": "Alzheimer&amp;#x2019;s disease (AD) is a hazardous neurological disorder of people aged in the early 60s. The main symptoms of AD is significant memory loss. Mild Cognitive Impairment (MCI) is a state of dementia in which a patient exhibits the early symptoms of AD. Since brain is the most impacted region, the disorders can be classified by analyzing factors from brain tissues in different subjects. Machine Learning (ML) is a widely utilised concept that aids in the decision-making process. Deep Convolutional Neural Network (DNN) is a type of ML techniques that uses artificially connected neurons to mimic the human brain. In this work, we have proposed a novel DNN-based model for distinguishing AD and MCI patients from Cognitively Normal individuals. Inspired by the original VGG-19, we have created 19 deep layers in the network. In Back Propagation, deeper models suffer from the problem of vanishing gradient and information loss. As a solution, we borrowed the Dense-Block notion from the original DenseNet architecture, which provides a path of information exchange amongst all the layers. Furthermore, we have implemented depth-wise convolutional procedures to make the model computationally faster. Outcome of the proposed model is compared with some prominent DNN models and observed that, the proposed approach performs most convincingly with an average performance rate of 95.39&amp;#x0025;.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ruhul Amin Hazarika et al.",
      "keywords": "Dementia; Convolutional neural network; Computer science; Deep learning; Artificial intelligence; Cognitive impairment; Cognition; Pattern recognition (psychology); Disease; Neuroscience; Psychology; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3206389",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387350698",
      "doi": "10.1109/tnsre.2023.3321874",
      "title": "Disease Delineation for Multiple Sclerosis, Friedreich Ataxia, and Healthy Controls Using Supervised Machine Learning on Speech Acoustics",
      "abstract": "Neurodegenerative disease often affects speech. Speech acoustics can be used as objective clinical markers of pathology. Previous investigations of pathological speech have primarily compared controls with one specific condition and excluded comorbidities. We broaden the utility of speech markers by examining how multiple acoustic features can delineate diseases. We used supervised machine learning with gradient boosting (CatBoost) to delineate healthy speech from speech of people with multiple sclerosis or Friedreich ataxia. Participants performed a diadochokinetic task where they repeated alternating syllables. We subjected 74 spectral and temporal prosodic features from the speech recordings to machine learning. Results showed that Friedreich ataxia, multiple sclerosis and healthy controls were all identified with high accuracy (over 82%). Twenty-one acoustic features were strong markers of neurodegenerative diseases, falling under the categories of spectral qualia, spectral power, and speech rate. We demonstrated that speech markers can delineate neurodegenerative diseases and distinguish healthy speech from pathological speech with high accuracy. Findings emphasize the importance of examining speech outcomes when assessing indicators of neurodegenerative disease. We propose large-scale initiatives to broaden the scope for differentiating other neurological diseases and affective disorders.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Benjamin G. Schultz et al.",
      "keywords": "Multiple sclerosis; Spinocerebellar ataxia; Disease; Ataxia; Medicine; Audiology; Pathological; Psychology; Computer science; Neuroscience; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3321874",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3173657754",
      "doi": "10.1109/access.2021.3091838",
      "title": "FallDeF5: A Fall Detection Framework Using 5G-Based Deep Gated Recurrent Unit Networks",
      "abstract": "Fall prevalence is high among elderly people, which is challenging due to the severe consequences of falling. This is why rapid assistance is a critical task. Ambient assisted living (AAL) uses recent technologies such as 5G networks and the internet of medical things (IoMT) to address this research area. Edge computing can reduce the cost of cloud communication, including high latency and bandwidth use, by moving conventional healthcare services and applications closer to end-users. Artificial intelligence (AI) techniques such as deep learning (DL) have been used recently for automatic fall detection, as well as supporting healthcare services. However, DL requires a vast amount of data and substantial processing power to improve its performance for the IoMT linked to the traditional edge computing environment. This research proposes an effective fall detection framework based on DL algorithms and mobile edge computing (MEC) within 5G wireless networks, the aim being to empower IoMT-based healthcare applications. We also propose the use of a deep gated recurrent unit (DGRU) neural network to improve the accuracy of existing DL-based fall detection methods. DGRU has the advantage of dealing with time-series IoMT data, and it can reduce the number of parameters and avoid the vanishing gradient problem. The experimental results on two public datasets show that the DGRU model of the proposed framework achieves higher accuracy rates compared to the current related works on the same datasets.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mabrook Al\u2010Rakhami et al.",
      "keywords": "Computer science; Deep learning; Edge computing; Cloud computing; Artificial intelligence; Big data; Enhanced Data Rates for GSM Evolution; The Internet; Artificial neural network; Machine learning; Real-time computing; Data mining; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3091838",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2905162996",
      "doi": "10.1109/jtehm.2018.2884925",
      "title": "Patient Centered Communication and E-Health Information Exchange Patterns: Findings From a National Cross-Sectional Survey",
      "abstract": "This paper aimed to determine whether there was a connection between patient's perception of communication with their doctors in the visit and their use of online health information exchange using a nationally representative survey. We used the data from the Health Information National Trends survey pooled HINTS4 Cycle 4 data and assessed outcomes using logistic regression modeling composite communication scores as a continuous variable. We weighted participants to create population-level estimates. We adjusted for age, gender, race, and census region. The 3677 patients were included in the analysis who had an outpatient visit within the previous 12 months. In unadjusted analysis and analysis adjusted for demographic factors, patients who experienced higher communication scores were more likely to use online health information exchange with their providers. In unadjusted analysis, patients had 0.04 higher odds of interest in receiving appointment reminders from health care providers electronically (OR = 1.04 and [Formula: see text]) and 0.03 higher odds of interest in receiving general health tips (OR = 1.03 and [Formula: see text]) for every score increase in the communication summary score. In adjusted model, for each score increment in the communication score, patients were 7% more inclined to receive appointment reminders ([Formula: see text]), 4% more inclined to receive general health tips ([Formula: see text]), and 4% more likely to exchange information about lifestyle behaviors ([Formula: see text]). Findings suggest that the quality of the communication in the visit might increase use of informatics tool to exchange health information.",
      "year": "2018",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Onur Asan et al.",
      "keywords": "Cross-sectional study; Health Information National Trends Survey; Information exchange; Computer science; Medicine; Health information; Health care; Telecommunications; Pathology; Political science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2018.2884925",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3005049267",
      "doi": "10.1109/access.2020.3020868",
      "title": "Generating Biomedical Question Answering Corpora From Q&amp;A Forums",
      "abstract": "Question Answering (QA) is a natural language processing task that aims at obtaining relevant answers to user questions. While some progress has been made in this area, biomedical questions are still a challenge to most QA approaches, due to the complexity of the domain and limited availability of training sets. We present a method to automatically extract question-article pairs from Q&amp;A web forums, which can be used for document retrieval, a crucial step of most QA systems. The proposed framework extracts from selected forums the questions and the respective answers that contain citations. This way, QA systems based on document retrieval can be developed and evaluated using the question-article pairs annotated by users of these forums. We generated the BiQA corpus by applying our framework to three forums, obtaining 7,453 questions and 14,239 question-article pairs. We evaluated how the number of articles associated with each question and the number of votes on each answer affects the performance of baseline document retrieval approaches. Also, we demonstrated that the articles given as answers are significantly similar to the questions and trained a state-of-the-art deep learning model that obtained similar performance to using a dataset manually annotated by experts. The proposed framework can be used to update the BiQA corpus from the same forums as new posts are made, and from other forums that support their answers with documents. The BiQA corpus and the framework used to generate it are available at https://github.com/lasigeBioTM/BiQA.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Andre Lamurias et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3020868",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391696945",
      "doi": "10.1109/jbhi.2024.3364499",
      "title": "$\\bm{\\xi}$-$\\bm{\\pi}$: A Nonparametric Model for Neural Power Spectra Decomposition",
      "abstract": "The power spectra estimated from the brain recordings are the mixed representation of aperiodic transient activity and periodic oscillations, i.e., aperiodic component (AC) and periodic component (PC). Quantitative neurophysiology requires precise decomposition preceding parameterizing each component. However, the shape, statistical distribution, scale, and mixing mechanism of AC and PCs are unclear, challenging the effectiveness of current popular parametric models such as FOOOF, IRASA, BOSC, etc. Here, \u03be- \u03c0 was proposed to decompose the neural spectra by embedding the nonparametric spectra estimation with penalized Whittle likelihood and the shape language modeling into the expectation maximization framework. \u03be- \u03c0 was validated on the synthesized spectra with loss statistics and on the sleep EEG and the large sample iEEG with evaluation metrics and neurophysiological evidence. Compared to FOOOF, both the simulation presenting shape irregularities and the batch simulation with multiple isolated peaks indicated that \u03be- \u03c0 improved the fit of AC and PCs with less loss and higher F1-score in recognizing the centering frequencies and the number of peaks; the sleep EEG revealed that \u03be- \u03c0 produced more distinguishable AC exponents and improved the sleep state classification accuracy; the iEEG showed that \u03be- \u03c0 approached the clinical findings in peak discovery. Overall, \u03be- \u03c0 offered good performance in the spectra decomposition, which allows flexible parameterization using descriptive statistics or kernel functions. \u03be- \u03c0 is a seminal tool for brain signal decoding in fields such as cognitive neuroscience, brain-computer interface, neurofeedback, and brain diseases.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Shiang Hu et al.",
      "keywords": "Nonparametric statistics; Aperiodic graph; Representation (politics); Mathematics; Algorithm; Computer science; Artificial intelligence; Statistics; Combinatorics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3364499",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3160428113",
      "doi": "10.1109/tnsre.2021.3078460",
      "title": "Detection of Emotional Sensitivity Using fNIRS Based Dynamic Functional Connectivity",
      "abstract": "In this study, we proposed an analytical framework to identify dynamic task-based functional connectivity (FC) features as new biomarkers of emotional sensitivity in nursing students, by using a combination of unsupervised and supervised machine learning techniques. The dynamic FC was measured by functional Near-Infrared Spectroscopy (fNIRS), and computed using a sliding window correlation (SWC) analysis. A k -means clustering technique was applied to derive four recurring connectivity states. The states were characterized by both graph theory and semi-metric analysis. Occurrence probability and state transition were extracted as dynamic FC network features, and a Random Forest (RF) classifier was implemented to detect emotional sensitivity. The proposed method was trialled on 39 nursing students and 19 registered nurses during decision-making, where we assumed registered nurses have developed strategies to cope with emotional sensitivity. Emotional stimuli were selected from International Affective Digitized Sound System (IADS) database. Experiment results showed that registered nurses demonstrated single dominant connectivity state of task-relevance, while nursing students displayed in two states and had higher level of task-irrelevant state connectivity. The results also showed that students were more susceptive to emotional stimuli, and the derived dynamic FC features provided a stronger discriminating power than heart rate variability (accuracy of 81.65% vs 71.03%) as biomarkers of emotional sensitivity. This work forms the first study to demonstrate the stability of fNIRS based dynamic FC states as a biomarker. In conclusion, the results support that the state distribution of dynamic FC could help reveal the differentiating factors between the nursing students and registered nurses during decision making, and it is anticipated that the biomarkers might be used as indicators when developing professional training related to emotional sensitivity.",
      "year": "2021",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Tong Boon Tang et al.",
      "keywords": "Dynamic functional connectivity; Sensitivity (control systems); Classifier (UML); Computer science; Pattern recognition (psychology); Artificial intelligence; Functional connectivity; Stability (learning theory); Correlation; Metric (unit); Random forest; Machine learning; Psychology; Mathematics; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2021.3078460",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4225586433",
      "doi": "10.1109/access.2022.3165079",
      "title": "The Application Domains of Systematic Mapping Studies: A Mapping Study of the First Decade of Practice With the Method",
      "abstract": "The systematic mapping study (SMS) is a relatively new method of generating new information from existing studies. First defined as a methodology in 2007, it offers a method to filter existing information to produce novel insight into the observed research domain, and pinpoint new directions of research. In this study, the systematic mapping study method was utilized to determine how SMS as a method has spread and was utilized during the first decade since its conceptualization. In general, it was found that the SMS method is still at its early phase in utilization, and is mainly used in software engineering and healthcare studies, but also in several other scientific domains. SMS research and the scientific outputs rely on transparent protocols when conducting the actual search and identification process, and so far, the applied protocol and research procedure correlates strongly with the application domain; different domains have their own protocols. The SMS method can be recommended, for example, when the aim is to gain knowledge on how a specific topic is studied and where there are research gaps. There are still areas that are debated or where successful implementation is difficult, the biggest problems being the amount of work it requires and possible lack of quality analysis of the articles.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Erno Vanhala et al.",
      "keywords": "Computer science; Data science; Information retrieval",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3165079",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3014501953",
      "doi": "10.1109/access.2020.2985122",
      "title": "Reliable Data Collection in Participatory Trials to Assess Digital Healthcare Applications",
      "abstract": "The number of digital healthcare mobile applications in the market is exponentially increasing owing to the development of mobile networks and widespread usage of smartphones. However, only few of these applications have been adequately validated. Like many mobile applications, in general, the use of healthcare applications is considered safe; thus, developers and end users can easily exchange them in the marketplace. However, existing platforms are unsuitable for collecting reliable data for evaluating the effectiveness of the applications. Moreover, these platforms reflect only the perspectives of developers and experts, and not of end users. For instance, typical clinical trial data collection methods are not appropriate for participant-driven assessment of healthcare applications because of their complexity and high cost. Thus, we identified the need for a participant-driven data collection platform for end users that is interpretable, systematic, and sustainable, as a first step to validate the effectiveness of the applications. To collect reliable data in the participatory trial format, we defined distinct stages for data preparation, storage, and sharing. The interpretable data preparation consists of a protocol database system and semantic feature retrieval method that allow a person without professional knowledge to create a protocol. The systematic data storage stage includes calculation of the collected data reliability weight. For sustainable data collection, we integrated a weight method and a future reward distribution function. We validated the methods through statistical tests involving 718 human participants. The results of a validation experiment demonstrate that the compared methods differ significantly and prove that the choice of an appropriate method is essential for reliable data collection, to facilitate effectiveness validation of digital healthcare applications. Furthermore, we created a Web-based system for our pilot platform to collect reliable data in an integrated pipeline. We compared the platform features using existing clinical and pragmatic trial data collection platforms.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Junseok Park et al.",
      "keywords": "Computer science; Data collection; Protocol (science); Health care; Reliability (semiconductor); Data science; Mobile device; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2985122",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387659859",
      "doi": "10.1109/access.2023.3298951",
      "title": "Revolutionizing Healthcare Delivery Through Wireless Wearable Antenna Frameworks: Current Trends and Future Prospects",
      "abstract": "The arrival of various mechanism applications to healthcare is gaining more attention with various novel breakthroughs in digitalizing healthcare. The use of technology in improving the delivery of healthcare comprises various applications such as electronic health systems, telemedicine, mobile health, remote patient monitoring, and wearable devices. Wearables and implants are making a significant impact on revolutionizing healthcare globally, and the next generation of advanced technology is providing adequate applications in tackling the challenges in digital healthcare. The advancement of various techniques gives future direction to digitalizing healthcare. Antennas play a key part in digitalizing healthcare because of their characteristics and the adaptation to wireless communication with transmission and reception in different human body parts. Although there are a lot of studies done and published on digital healthcare, telemedicine, wearable, and many more mechanisms that enhance healthcare delivery, however, systematic studies that comprehensively review the applications in healthcare such as wearable antenna framework remain scarce. This paper attempts to close the gap in investigating mechanisms for digital health care, and wearable devices with antenna applications. This comprehensive systematic review covers antenna application in healthcare. Furthermore, it provides a state-of-the-art update on recent developments in healthcare with a focus on design, monitoring devices, diagnostic implants, early detection mechanisms, and control. We also examine wearable analysis and performance, fabrication and experimental approaches, and the major types of wearables. This assists with existing chronic disease management and future epidemics with provided tools. This finding will give a blueprint of how zero spread of future epidemics will be achieved by implementing the bio-electromagnetic application in the healthcare sector.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Segun Akinola et al.",
      "keywords": "Wearable computer; Health care; Computer science; Wearable technology; Blueprint; Telemedicine; Engineering; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3298951",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389891069",
      "doi": "10.1109/access.2023.3344464",
      "title": "Voice-Based SVM Model Reliability for Identifying Parkinson\u2019s Disease",
      "abstract": "One of the possibilities for developing non-invasive computerized diagnostic tools for&#13;\\nParkinson\u2019s disease (PD) is to detect changes in the voice, known as Parkinsonian dysarthria. Numerous&#13;\\nclassification models have been developed to diagnose PD based on voice features. However, the&#13;\\nperformance of models developed and trained only using voice features extracted from people with PD and&#13;\\nhealthy people might be affected when tested on individuals with other voice-related pathological conditions.&#13;\\nTherefore, we investigated the reliability of voice-based machine-learning models that were developed only&#13;\\nusing datasets of people with PD and healthy people for accurately identifying people without PD when&#13;\\nthey have other voice-related pathological conditions (i.e. dysphonia and laryngitis). Three different support&#13;\\nvector machines (SVMs) were developed and tested on voice features extracted from healthy people and&#13;\\nthose with PD, dysphonia, and laryngitis. The results confirmed that a voice-based SVM classifier only&#13;\\ntrained on the dataset of people with PD and healthy people was equally reliable in classifying other&#13;\\nvoice-related pathological conditions, such as dysphonia and laryngitis, as non-PD cases.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Nemuel Daniel Pah et al.",
      "keywords": "Laryngitis; Support vector machine; Dysarthria; Pathological; Computer science; Voice analysis; Reliability (semiconductor); Speech recognition; Voice Disorder; Classifier (UML); Artificial intelligence; Audiology; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3344464",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4283689687",
      "doi": "10.1109/tnsre.2022.3181690",
      "title": "Abnormal Brain Topological Structure of Mild Depression During Visual Search Processing Based on EEG Signals",
      "abstract": "Studies have shown that attention bias can affect behavioral indicators in patients with depression, but it is still unclear how this bias affects the brain network topology of patients with mild depression (MD). Therefore, a novel functional brain network analysis and hierarchical clustering methods were used to explore the abnormal brain topology of MD patients based on EEG signals during the visual search paradigm. The behavior results showed that the reaction time of MD group was significantly higher than that of normal group. The results of functional brain network indicated significant differences in functional connections between the two groups, the amount of inter-hemispheric long-distance connections are much larger than intra-hemispheric short-distance connections. Patients with MD showed significantly lower local efficiency and clustering coefficient, destroyed community structure of frontal lobe and parietal-occipital lobe, frontal asymmetry, especially in beta band. In addition, the average value of long-distance connections between left frontal and right parietal-occipital lobes presented significant correlation with depressive symptoms. Our results suggested that MD patients achieved long-distance connections between the frontal and parietal-occipital regions by sacrificing the connections within the regions, which might provide new insights into the abnormal cognitive processing mechanism of depression.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Shuting Sun et al.",
      "keywords": "Occipital lobe; Frontal lobe; Electroencephalography; Parietal lobe; Psychology; Neuroscience; Depression (economics); Cognition; Topology (electrical circuits); Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3181690",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3198960169",
      "doi": "10.1109/access.2021.3112345",
      "title": "Critical Success Factors for Virtual Reality Applications in Orthopaedic Surgical Training: A Systematic Literature Review",
      "abstract": "There is an increasing pressure to improve the cost-effectiveness of orthopaedic training, both temporally and financially. Accordingly, virtual reality (VR) has been incorporated into a number of surgical training programs, providing trainees a safe yet realistic environment to practice their craft before going into the operating room. Identification of critical success factors (CSFs) for VR integration in the orthopaedic training program, can be beneficial in guiding the focus of healthcare providers and VR designers during the VR platform development stage. The aim of this study is to identify VR-based training CSFs that encourage orthopaedic surgeons to use VR as a method for acquiring, maintaining, and improving skills. A total of 74 studies conducted between 2011 and 2021 were selected and examined. There were 73 CSFs listed as being essential for VR adoption in orthopaedic surgical training. The CSFs were divided into six general categories: HCI/VR Features, Learning Outcome, Usability, Control and Active Learning, Student and Limitation factors. Subsequently, recommendations were made to guide healthcare professionals, researchers, and designers for optimal adoption of VR in orthopaedic surgical training in the future.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mohd Yazid Bajuri et al.",
      "keywords": "Virtual reality; Computer science; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3112345",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4292387409",
      "doi": "10.1109/access.2022.3199736",
      "title": "Thermography for Emotion Recognition Using Deep Learning in Academic Settings: A Review",
      "abstract": "Understanding students&#x2019; emotional states during the learning process is one of the important aspects to improve learning quality. Measurements of emotion in an academic setting can be performed manually or automatically using a computer. However, developing an emotion recognition method using an imaging modality that is contactless, harmless, and illumination-independent is challenging. Thermography, as a non-invasive emotion recognition method, can recognize emotion variance during learning by observing the temperature distributions in a facial region. Deep learning models, such as convolutional neural networks (CNNs), can be used to interpret thermograms. CNNs can automatically classify emotion thermograms into several emotional states, such as happiness, anger, sadness, and fear. Despite their promising ability, CNNs have not been widely used in emotion recognition. In this study, we aimed to summarize the previous works and progress in emotion recognition in academic settings based on thermography and CNN. We first discussed the previous works on emotion recognition to provide an overview of the availability of modalities with their advantages and disadvantages. We also discussed emotion thermography potential for the academic context to find if there is any information in the available emotion thermal datasets related to the subjects&#x2019; educational backgrounds. Emotion classification using the proposed CNN model was described step by step, including the feature learning illustration. Lastly, we proposed future research directions for developing a representative dataset in the academic settings, fed the segmented image, assigned a good kernel, and built a CNN model to improve the recognition performance.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Fardian Fardian et al.",
      "keywords": "Computer science; Thermography; Emotion recognition; Deep learning; Artificial intelligence; Machine learning; Infrared",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3199736",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4200417987",
      "doi": "10.1109/jtehm.2021.3134160",
      "title": "New Radiomic Markers of Pulmonary Vein Morphology Associated With Post-Ablation Recurrence of Atrial Fibrillation",
      "abstract": "<i>Objective:</i> To identify radiomic and clinical features associated with post-ablation recurrence of AF, given that cardiac morphologic changes are associated with persistent atrial fibrillation (AF), and initiating triggers of AF often arise from the pulmonary veins which are targeted in ablation. <i>Methods:</i> Subjects with pre-ablation contrast CT scans prior to first-time catheter ablation for AF between 2014-2016 were retrospectively identified. A training dataset (D<sub>1</sub>) was constructed from left atrial and pulmonary vein morphometric features extracted from equal numbers of consecutively included subjects with and without AF recurrence determined at 1 year. The top-performing combination of feature selection and classifier methods based on C-statistic was evaluated on a validation dataset (D<sub>2</sub>), composed of subjects retrospectively identified between 2005-2010. Clinical models ([Formula: see text]) were similarly evaluated and compared to radiomic ([Formula: see text]) and radiomic-clinical models ([Formula: see text]), each independently validated on D<sub>2</sub>. <i>Results:</i> Of 150 subjects in D<sub>1</sub>, 108 received radiofrequency ablation and 42 received cryoballoon. Radiomic features of recurrence included greater right carina angle, reduced anterior-posterior atrial diameter, greater atrial volume normalized to height, and steeper right inferior pulmonary vein angle. Clinical features predicting recurrence included older age, greater BMI, hypertension, and warfarin use; apixaban use was associated with reduced recurrence. AF recurrence was predicted with radio-frequency ablation models on D<sub>2</sub> subjects with C-statistics of 0.68, 0.63, and 0.70 for radiomic, clinical, and combined feature models, though these were not prognostic in patients treated with cryoballoon. <i>Conclusions:</i> Pulmonary vein morphology associated with increased likelihood of AF recurrence within 1 year of catheter ablation was identified on cardiac CT. <i>Significance:</i> Radiomic and clinical features-based predictive models may assist in identifying atrial fibrillation ablation candidates with greatest likelihood of successful outcome.",
      "year": "2021",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Michael A. Labarbera et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2021.3134160",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313042883",
      "doi": "10.1109/access.2022.3213996",
      "title": "Decoding the User\u2019s Movements Preparation From EEG Signals Using Vision Transformer Architecture",
      "abstract": "Electroencephalography (EEG) signals have a major impact on how well assistive rehabilitation devices work. These signals have become a common technique in recent studies to investigate human motion functions and behaviors. However, incorporating EEG signals to investigate motor planning or movement intention could benefit all patients who can plan motion but are unable to execute it. In this paper, the movement planning of the lower limb was investigated using EEG signal and bilateral movements were employed, including dorsiflexion and plantar flexion of the right and left ankle joint movements. The proposed system uses Continuous Wavelet Transform (CWT) to generate a time-frequency (TF) map of each EEG signal in the motor cortex and then uses the extracted images as input to a deep learning model for classification. Deep Learning (DL) models are created based on vision transformer architecture (ViT) which is the state-of-the-art of image classification and also the proposed models were compared with residual neural network (ResNet). The proposed technique reveals a significant classification performance for the multiclass problem (p &lt; 0.0001) where the classification accuracy was 97.33\u00b11.86 % and the F score, recall and precision were 97.32\u00b11.88 %, 97.30\u00b11.90 % and 97.36\u00b11.81 % respectively. These results show that DL is a promising technique that can be applied to investigate the user's movements intention from EEG signals and highlight the potential of the proposed model for the development of future brain-machine interface (BMI) for neurorehabilitation purposes.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Maged S. Al-Quraishi et al.",
      "keywords": "Computer science; Electroencephalography; Artificial intelligence; Pattern recognition (psychology); Decoding methods; Speech recognition; Normalization (sociology); Deep learning; Computer vision; Neuroscience; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3213996",
      "cited_by_count": 16,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3009955828",
      "doi": "10.1109/access.2020.2978902",
      "title": "Approaches to Dealing With Missing Data in Railway Asset Management",
      "abstract": "The collection of reliable and high-quality data is seen as a prerequisite for effective and efficient rail infrastructure and rolling stock asset management to meet the requirements of asset owners and service providers. In this paper, the importance of recovering missing information in railway asset management is highlighted, and the advanced models and algorithms that have been applied to recovering the missed data are analyzed and discussed. Through making comparisons among these models and algorithms, a procedure is proposed to guide selecting the appropriate models based on different data missing scenarios. Using the newly developed framework with one dataset from each scenario, new models with different structures are trained and finally, the most suitable model is selected and utilized to recover the missing data and the selected model's performance is evaluated using the data with known or clearly identified missing data mechanisms. Challenges via application of advanced algorithms for recovering missing data are discussed.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Paul E. McMahon et al.",
      "keywords": "Missing data; Computer science; Asset management; Data mining; Data quality; Asset (computer security); Data collection; Data modeling; Data science; Service (business); Machine learning; Database; Computer security; Finance; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2978902",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3127794598",
      "doi": "10.1109/tnsre.2021.3056908",
      "title": "Robot-Based Assessment of HIV-Related Motor and Cognitive Impairment for Neurorehabilitation",
      "abstract": "There is a pressing need for strategies to slow or treat the progression of functional decline in people living with HIV. This paper explores a novel rehabilitation robotics approach to measuring cognitive and motor impairment in adults living with HIV, including a subset with stroke. We conducted a cross-sectional study with 21 subjects exhibiting varying levels of cognitive and motor impairment. We tested three robot-based tasks - trajectory tracking, N-back, and spatial span - to assess if metrics derived from these tasks were sensitive to differences in subjects with varying levels of executive function and upper limb motor impairments. We also examined how well these metrics could estimate clinical cognitive and motor scores. The results showed that the average sequence length on the robot-based spatial span task was the most sensitive to differences between various cognitive and motor impairment levels. We observed strong correlations between robot-based measures and clinical cognitive and motor assessments relevant to the HIV population, such as the Color Trails 1 (rho = 0.83), Color Trails 2 (rho = 0.71), Digit Symbol - Coding (rho = 0.81), Montreal Cognitive Assessment - Executive Function subscore (rho = 0.70), and Box and Block Test (rho = 0.74). Importantly, our results highlight that gross motor impairment may be overlooked in the assessment of HIV-related disability. This study shows that rehabilitation robotics can be expanded to new populations beyond stroke, namely to people living with HIV and those with cognitive impairments.",
      "year": "2021",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Kevin D. Bui et al.",
      "keywords": "Neurorehabilitation; Cognitive impairment; Human immunodeficiency virus (HIV); Physical medicine and rehabilitation; Cognition; Psychology; Medicine; Neuroscience; Rehabilitation; Virology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2021.3056908",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389747909",
      "doi": "10.1109/access.2023.3342917",
      "title": "Classification of Alzheimer\u2019s Disease Using Ensemble Convolutional Neural Network With LFA Algorithm",
      "abstract": "Alzheimer&#x2019;s disease (AD) is a disease that develops gradually, ultimately causing deterioration of brain functions. Thus, early diagnosis is essential for treating and managing AD. Magnetic-resonance-imaging (MRI)-based AD diagnosis classifies the stage of AD according to the extent of atrophy caused to a patient&#x2019;s hippocampal and entorhinal cortex. In this case, the shape of the patient&#x2019;s brain serves as a crucial feature. Therefore, in this paper, we propose an ensemble convolutional neural network (CNN) model that can classify the AD stage according to the shape of a patient&#x2019;s brain. The proposed model is structured by combining a convolutional layer part of the visual geometry group network (VGGNet) model, with proven performance in image classification, and a 1D CNN model into a pipeline. Here, the 1D CNN applies the line segment feature analysis (LFA) algorithm to MRI images to transform the visual line segment information of the images into vectors and record strong features indicating the shape of the brain. This is followed by 1D CNN model training. Notably, the 1D CNN model can carefully observe the brain shape owing to the parallel connection of ten 1D convolutional layers with LFA features. Subsequently, the brain shape information is combined with features obtained from the original image through the VGGNet to improve the model performance compared to that of existing methods. To evaluate the performance of the proposed ensemble CNN model, MRI datasets collected from Kaggle are used to evaluate and compare the proposed model with existing image classification methods and methods proposed in related studies. The experimental results reveal that the proposed model demonstrates superior performance with an accuracy of 0.986 and a loss of 0.0385.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Chang\u2010Min Kim et al.",
      "keywords": "Convolutional neural network; Computer science; Artificial intelligence; Pattern recognition (psychology); Contextual image classification; Feature (linguistics); Pipeline (software); Magnetic resonance imaging; Feature extraction; Deep learning; Image (mathematics); Radiology; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3342917",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4283834568",
      "doi": "10.1109/tnsre.2022.3188184",
      "title": "Detection of Stroke-Induced Visual Neglect and Target Response Prediction Using Augmented Reality and Electroencephalography",
      "abstract": "We aim to build a system incorporating electroencephalography (EEG) and augmented reality (AR) that is capable of identifying the presence of visual spatial neglect (SN) and mapping the estimated neglected visual field. An EEG-based brain-computer interface (BCI) was used to identify those spatiospectral features that best detect participants with SN among stroke survivors using their EEG responses to ipsilesional and contralesional visual stimuli. Frontal-central delta and alpha, frontal-parietal theta, Fp1 beta, and left frontal gamma were found to be important features for neglect detection. Additionally, temporal analysis of the responses shows that the proposed model is accurate in detecting potentially neglected targets. These targets were predicted using common spatial patterns as the feature extraction algorithm and regularized discriminant analysis combined with kernel density estimation for classification. With our preliminary results, our system shows promise for reliably detecting the presence of SN and predicting visual target responses in stroke patients with SN.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Jennifer Y. Mak et al.",
      "keywords": "Electroencephalography; Neglect; Brain\u2013computer interface; Linear discriminant analysis; Artificial intelligence; Pattern recognition (psychology); Computer science; EEG-fMRI; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3188184",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4210415489",
      "doi": "10.1109/access.2022.3147726",
      "title": "Attention-Based Applications in Extended Reality to Support Autistic Users: A Systematic Review",
      "abstract": "With the rising prevalence of autism diagnoses, it is essential for research\\nto understand how to leverage technology to support the diverse nature of\\nautistic traits. While traditional interventions focused on technology for\\nmedical cure and rehabilitation, recent research aims to understand how\\ntechnology can accommodate each unique situation in an efficient and engaging\\nway. Extended reality (XR) technology has been shown to be effective in\\nimproving attention in autistic users given that it is more engaging and\\nmotivating than other traditional mediums. Here, we conducted a systematic\\nreview of 59 research articles that explored the role of attention in XR\\ninterventions for autistic users. We systematically analyzed demographics,\\nstudy design and findings, including autism screening and attention measurement\\nmethods. Furthermore, given methodological inconsistencies in the literature,\\nwe systematically synthesize methods and protocols including screening tools,\\nphysiological and behavioral cues of autism and XR tasks. While there is\\nsubstantial evidence for the effectiveness of using XR in attention-based\\ninterventions for autism to support autistic traits, we have identified three\\nprincipal research gaps that provide promising research directions to examine\\nhow autistic populations interact with XR. First, our findings highlight the\\ndisproportionate geographic locations of autism studies and underrepresentation\\nof autistic adults, evidence of gender disparity, and presence of individuals\\ndiagnosed with co-occurring conditions across studies. Second, many studies\\nused an assortment of standardized and novel tasks and self-report assessments\\nwith limited tested reliability. Lastly, the research lacks evidence of\\nperformance maintenance and transferability.\\n",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Katherine Wang et al.",
      "keywords": "Computer science; Human\u2013computer interaction; Virtual reality; Autism; Psychology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3147726",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4392251775",
      "doi": "10.1109/jbhi.2024.3371097",
      "title": "Dynamic Reconfiguration of Brain Functional Network in Stroke",
      "abstract": "The brain continually reorganizes its functional network to adapt to post-stroke functional impairments. Previous studies using static modularity analysis have presented global-level behavior patterns of this network reorganization. However, it is far from understood how the brain reconfigures its functional network dynamically following a stroke. This study collected resting-state functional MRI data from 15 stroke patients, with mild (n = 6) and severe (n = 9) two subgroups based on their clinical symptoms. Additionally, 15 age-matched healthy subjects were considered as controls. By applying a multilayer temporal network method, a dynamic modular structure was recognized based on a time-resolved function network. The dynamic network measurements (recruitment, integration, and flexibility) were calculated to characterize the dynamic reconfiguration of post-stroke brain functional networks, hence, revealing the neural functional rebuilding process. It was found from this investigation that severe patients tended to have reduced recruitment and increased between-network integration, while mild patients exhibited low network flexibility and less network integration. It's also noted that previous studies using static methods could not reveal this severity-dependent alteration in network interaction. Clinically, the obtained knowledge of the diverse patterns of dynamic adjustment in brain functional networks observed from the brain neuronal images could help understand the underlying mechanism of the motor, speech, and cognitive functional impairments caused by stroke attacks. The present method not only could be used to evaluate patients' current brain status but also has the potential to provide insights into prognosis analysis and prediction.",
      "year": "2024",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Kaichao Wu et al.",
      "keywords": "Computer science; Control reconfiguration; Stroke (engine); Physical medicine and rehabilitation; Medicine; Embedded system; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2024.3371097",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2803080351",
      "doi": "10.1109/access.2018.2886644",
      "title": "Applying Bayesian Network Approach to Determine the Association Between Morphological Features Extracted from Prostate Cancer Images",
      "abstract": "Cancer is a major public health problem across the globe due to which millions of deaths occur every year. In the United States, prostate cancer is the second leading cause of cancer- related deaths in men. The major causes of prostate cancer include increasing age, family history, diet, sexual behavior, and geographic location. Early detection of prostate cancer can effectively reduce the mortality rate. In the past, researchers have adopted various multimodal feature extracting strategies to extract diverse and comprehensive quantitative imaging features and employed machine learning methods to detect prostate cancer. However, existing techniques lack detailed analysis of the magnitude of relationship among different individual discriminatory features, which is very important to understand the dynamics of the disease. In this study, we extracted diverse morphological features to summarize the imaging profile of patients of prostate cancer imaging database and employed Bayesian network analysis approach to quantify the association between different features and the strength of the association. The features and the association between the features were, respectively, modeled as the nodes and the edges of the network. The strength of association between the nodes was computed using Pearson&#x2019;s correlation, mutual Information and Kullback&#x2013;Liebler methods. The strongest associations were found between multiple features: (Area <inline-formula> <tex-math notation=\"LaTeX\">$\\to $ </tex-math></inline-formula> Equidiameter), (Area <inline-formula> <tex-math notation=\"LaTeX\">$\\to $ </tex-math></inline-formula> Circulatory 2), (Circulatory <inline-formula> <tex-math notation=\"LaTeX\">$1\\to $ </tex-math></inline-formula> (Elongatedness), (Circulatory <inline-formula> <tex-math notation=\"LaTeX\">$1\\to $ </tex-math></inline-formula> Entropy), (Circulatory <inline-formula> <tex-math notation=\"LaTeX\">$1\\to $ </tex-math></inline-formula> Max. Radius), and (Min. Radius <inline-formula> <tex-math notation=\"LaTeX\">$\\to $ </tex-math></inline-formula> Eccentricity). Moreover, interaction impact among nodes and node force was also computed. This analysis will help in finding the features that are more dominant to establish the relationship and can further increase the detection performance.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Lal Hussain et al.",
      "keywords": "Prostate cancer; Bayesian network; Artificial intelligence; Association (psychology); Computer science; Cancer; Machine learning; Medicine; Psychology; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2886644",
      "cited_by_count": 22,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3169914440",
      "doi": "10.1109/access.2021.3085530",
      "title": "Cyber Resilience Self-Assessment Tool (CR-SAT) for SMEs",
      "abstract": "On the current environment, companies face risks and threats to the systems they need to operate often known as cyber threats. Most of these companies are small and medium-sized enterprises (SMEs) and they are exposed to these cyber threats. To mitigate the risks and be able to thrive with as little disruption as possible, SMEs require cyber resilience capabilities. However, due to their limited resources, SMEs usually have no dedicated personnel for cyber resilience operationalization and thus lack the experience this discipline requires to implement. To aid SMEs in their cyber resilience operationalization, the current literature offers several kinds of solutions, but these solutions are usually targeted for companies with more resources than SMEs and do not aid in the complete process of assessing their current cyber resilience, deciding actions to improve it and prioritizing these actions. To aid companies in this systematic process to operationalize or implement cyber resilience, this article develops and tests an operational web-based tool in which companies can follow the complete process described before. To achieve this, a cyber resilience framework with the essential policies for SMEs, descriptions of their natural progressions in a progression model and a prioritization of these policies have been developed. In this article, this framework, progression model and prioritization are later transformed into one cyber resilience self-assessment tool (CR-SAT) and are tested in three case studies to qualitatively evaluate the tool by trying to ascertain its usefulness and completeness as well as improving it with the feedback from the end-users.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Juan Francisco Car\u00edas et al.",
      "keywords": "Resilience (materials science); Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3085530",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4391454512",
      "doi": "10.1109/access.2024.3361320",
      "title": "A Data-Driven MCDM Approach-Based Spherical Fuzzy Sets for Evaluating Global Augmented Reality Providers in Education",
      "abstract": "Amidst the heightened popularity of augmented reality (AR), particularly in education driven by the transformative impact of the COVID-19 pandemic on remote learning, this study addresses the intricacies surrounding the discerning selection of AR providers for educational purposes. It introduces a comprehensive decision support model, utilizing Spherical Fuzzy Sets (SFSs) to enhance the decision-making process. The methodology involves the application of SF-Delphi to ascertain the relative significance of eight pivotal criteria shaping AR provider selection. The Spherical Weighted Arithmetic Mean (SWAM) operator ensures an exhaustive and unbiased assessment. Subsequently, the Technique for Order of Preference by Similarity to the Ideal Solution (SF-TOPSIS) is systematically applied to evaluate and rank ten global AR providers. This research yields a dual contribution. Firstly, the proposed decision support model systematically guides AR provider selection, equipping decision-makers to navigate the intricacies of AR technology choices efficiently. Additionally, the impact extends to education, enriching the understanding of AR applications. This knowledge promotes well-informed and innovative AR technology utilization, enhancing the overall learning experience. In conclusion, this study introduces a pioneering decision support model that leverages SFSs to guide the selection of educational AR providers. This structured framework empowers decision-makers and advances the comprehension of AR dynamics, further propelling the strategic integration of AR technology in education.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Phi-Hung Nguyen",
      "keywords": "Augmented reality; Computer science; Fuzzy logic; Multiple-criteria decision analysis; Artificial intelligence; Mathematics; Mathematical optimization",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3361320",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391019685",
      "doi": "10.1109/access.2024.3356075",
      "title": "Raw Waveform-Based Custom Scalogram CRNN in Cardiac Abnormality Diagnosis",
      "abstract": "Cardiovascular disease is a significant cause of death worldwide, emphasizing the crucial need for timely detection and diagnosis of heart abnormalities. This study presents a new approach that utilizes deep learning models to diagnose cardiac issues by analyzing raw phonocardiogram (PCG) signals. The proposed method introduces a novel technique called custom scalogram-based convolutional recurrent neural network (CS-CRNN). Diverging from conventional techniques, this model directly handles the raw PCG signals. These signals undergo a transformation into scalogram images within the initial layer of the CRNN architecture, without incorporating any learnable parameters. The results obtained from the CS-CRNN model are compared with traditional feature-based recurrent neural network (RNN) models. The comparison demonstrates comparable performance in both binary classification (normal and abnormal categories) and multiclass classification (5 categories). The CS-CRNN model directly handles raw PCG data and employs data augmentation to enhance performance on small datasets. It achieves an accuracy of 99.6&#x0025; for binary classification and 98.6&#x0025; and 99.7&#x0025; before and after optimization for multiclass classification on the augmented dataset. The results show that the CS-CRNN model offers comparable performance to traditional methods, making it a promising tool for diagnosing cardiac abnormalities.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Kodali Radha et al.",
      "keywords": "Computer science; Recurrent neural network; Artificial intelligence; Binary classification; Pattern recognition (psychology); Feature (linguistics); Convolution (computer science); Convolutional neural network; Deep learning; Artificial neural network; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3356075",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386071670",
      "doi": "10.1109/ojim.2023.3303944",
      "title": "Noninvasive COVID-19 Screening Using Deep-Learning-Based Multilevel Fusion Model With an Attention Mechanism",
      "abstract": "The current pandemic has necessitated rapid and automatic detection of coronavirus disease (COVID-19) infections. Various artificial intelligence functionalities coupled with biomedical images can be utilized to efficiently detect these infections and recommend a prompt response (curative intervention) to limit the virus&#x2019;s spread. In particular, biomedical imaging could help to visualize the internal organs of the human body and disorders that affect them. One of them is chest X-rays (CXRs) which has widely been used for preventive medicine or disease screening. However, when it comes to detecting COVID-19 from CXR images, most of the approaches rely on standard image classification algorithms, which have limitations with low identification accuracy and improper extraction of key features. As a result, a convolutional neural network (CNN)-based fusion network has been developed for automated COVID-19 screening in this study. First, using attention networks and multiple fine-tuned CNN models, we extract key features that are resistant to overfitting. We then employ a locally connected layer to create a weighted combination of these models for final COVID-19 detection. Using a publicly available dataset of CXR images from healthy subjects as well as COVID-19 and pneumonia cases, we evaluated the predictive capabilities of our proposed model. Test results demonstrate that the proposed fusion model performs favorably compared to individual CNN models.",
      "year": "2023",
      "journal": "IEEE Open Journal of Instrumentation and Measurement",
      "authors": "M. Shamim Hossain et al.",
      "keywords": "Overfitting; Computer science; Artificial intelligence; Coronavirus disease 2019 (COVID-19); Convolutional neural network; Machine learning; Deep learning; Key (lock); Pattern recognition (psychology); Artificial neural network; Disease; Medicine; Infectious disease (medical specialty); Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojim.2023.3303944",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4286212087",
      "doi": "10.1109/tnsre.2022.3192533",
      "title": "Multimodal Emotion Classification Method and Analysis of Brain Functional Connectivity Networks",
      "abstract": "Since multimodal emotion classification in different human states has rarely been studied, this paper explores the emotional mechanisms of the brain functional connectivity networks after emotional stimulation. We devise a multimodal emotion classification method fusing a brain functional connectivity network based on electroencephalography (EEG) and eye gaze (ECFCEG) to study emotional mechanisms. First, the nonlinear phase lag index (PLI) and phase-locked value (PLV) are calculated to construct the multiband brain functional connectivity networks, which are then converted into binary brain networks, and the seven features of the binary brain networks are extracted. At the same time, the features of the eye gaze signals are extracted. Then, a fusion algorithm called kernel canonical correlation analysis, based on feature level and randomization (FRKCCA), is executed for feature-level fusion (FLF) of brain functional connectivity networks and eye gaze. Finally, support vector machines (SVMs) are utilized to classify positive and negative emotions in multiple frequency bands with single modal features and multimodal features. The experimental results demonstrate that multimodal complementary representation properties can effectively improve the accuracy of emotion classification, achieving a classification accuracy of 91.32\u00b11.81%. The classification accuracy of pupil diameter in the valence dimension is higher than that of additional features. In addition, the average emotion classification effect of the valence dimension is preferable to that of arousal. Our findings demonstrate that the brain functional connectivity networks of the right brain exhibit a deficiency. In particular, the information processing ability of the right temporal (RT) and right posterior (RP) regions is weak in the low frequency after emotional stimulation; Conversely, phase synchronization of the brain functional connectivity networks based on PLI is stronger than that of PLV.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Xiaofang Sun et al.",
      "keywords": "Artificial intelligence; Emotion classification; Computer science; Pattern recognition (psychology); Support vector machine; Electroencephalography; Functional connectivity; Linear discriminant analysis; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3192533",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4309167499",
      "doi": "10.1109/tbme.2022.3222124",
      "title": "A Handheld Quantifiable Soft Tissue Manipulation Device for Tracking Real-Time Dispersive Force-Motion Patterns to Characterize Manual Therapy Treatment",
      "abstract": "This medical device technology not only advances the state-of-the-art manual therapy with precision rehabilitation but also augments practice with reproducibility to examine neurobiological responses of individualized STM prescriptions for NMSK pathology.",
      "year": "2022",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Abhinaba Bhattacharjee et al.",
      "keywords": "Computer science; Usability; Artificial intelligence; Accelerometer; Mobile device; Match moving; Simulation; Computer vision; Motion (physics); Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2022.3222124",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3011813470",
      "doi": "10.1109/tim.2020.2981111",
      "title": "Unobtrusive Screening of Central Sleep Apnea From Pressure Sensors Measurements: A Patient-Specific Longitudinal Study",
      "abstract": "Historically, the lack of patients' sleep histories has caused low identification of sleep apnea (SA) and referral rates. Moreover, the costly and time-consuming nature of polysomnography (PSG) as a standard clinical test for detecting SA and the lack of sleep clinics has created a demand for suitable home-based monitoring devices. Pressure measurement using a pressure sensitive mat (PSM) can address the challenges found in current sleep-monitoring solutions. The noncontact PSM has a potential to replace obtrusive breathing sensors in the sleep lab and to be used as a prescreening tool for patients suspected of having SA. Applying classical support vector machine (SVM), this article presents a personalized system based on the measurements of each patient to detect central SA (CSA) events and monitor sleep characteristics longitudinally. For this purpose, sensor set-ups were installed in nine seniors' homes to collect unsupervised pressure data in approximately one year ranging from 8 to 12 months. Cost-based and resampling-based approaches were examined to combat imbalanced data. The results showed that the cost-based method outperformed other methods. Next, the patient-specific system was used to determine the total number of CSA events, as well as their starting time and duration in each day. The SA severity was measured by the central apnea index (CAI). In addition, other sleep characteristics such as bed occupancy (BO), day clock, and night clock were extracted from the PSM measurements. The impact of longitudinal sleep monitoring could be in tracking SA treatment progression, and possibly providing information on the interaction between SA and other disease progressions.",
      "year": "2020",
      "journal": "IEEE Transactions on Instrumentation and Measurement",
      "authors": "Hilda Azimi et al.",
      "keywords": "Polysomnography; Sleep apnea; Sleep (system call); Medicine; Remote patient monitoring; Support vector machine; Computer science; Apnea; Artificial intelligence; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tim.2020.2981111",
      "cited_by_count": 19,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3130571375",
      "doi": "10.1109/access.2021.3060178",
      "title": "Classification of Benign and Malignant Pulmonary Nodules Based on the Multiresolution 3D DPSECN Model and Semisupervised Clustering",
      "abstract": "Deep learning model training requires a large number of labeled samples, but the acquisition of labeled samples is time-consuming and laborious in the medical field. To solve this problem, a semisupervised clustering algorithm combined with a 3D convolutional neural network model is proposed to improve the classification performance for benign and malignant pulmonary nodules. The research contents are as follows: Firstly, a multiresolution 3D dual path squeeze excitation deep learning network model is constructed. Then, the feature extractor in the network model is used to extract the high-level features of the image, and semisupervised clustering is applied to the extracted image features. The corresponding pseudolabels can be obtained for the unlabeled samples, and the categories of unlabeled samples are determined and utilized. Finally, the oversampling algorithm is used to balance the data categories of different types of samples, and the benign and malignant pulmonary nodules are classified by a classifier constructed by a 3D dual path squeeze excitation network. The experimental results show that the proposed semisupervised clustering algorithm can label the categories of unlabeled samples. The proposed network model can learn more characteristics related to pulmonary nodules and can effectively improve the classification performance of pulmonary nodules. The proposed network model was tested using Lung Image Database Consortium (LIDC-IDRI) dataset, and an accuracy of 94.4&#x0025; and an AUC of 0.931 were obtained. Compared with some existing classification models, the proposed method can achieve a better classification effect of pulmonary nodules.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Siyuan Tang et al.",
      "keywords": "Artificial intelligence; Computer science; Cluster analysis; Pattern recognition (psychology); Convolutional neural network; Classifier (UML); Contextual image classification; Feature extraction; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3060178",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389040783",
      "doi": "10.1109/access.2023.3337035",
      "title": "Modeling EEG Signals for Mental Confusion Using DNN and LSTM With Custom Attention Layer",
      "abstract": "This study explored the impact of confusion on concentration and cognition, emphasizing the importance of detecting and preventing confusion from enhancing learning outcomes. By leveraging electroencephalogram (EEG) data, we proposed a novel deep learning model that uses long short-term memory (LSTM) networks to predict confusion levels in online massive open courses (MOOCs). LSTM&#x2019;s ability to model sequential data such as EEG signals has been harnessed to capture long-term dependencies and temporal dynamics effectively. To enhance pattern detection, we incorporated probabilistic features from machine learning (ML) models. By training them on the same dataset, we utilized their predictions as additional features for the deep learning model. Thereby, the neural network could make more informed decisions and improve its ability to detect and analyze EEG data patterns. Using LSTM and probabilistic features, our model effectively captured temporal dependencies, enabling an accurate online assessment of student perplexity to identify moments of confusion. The integration of attention mechanisms further enhanced the focus on critical EEG features, providing valuable insights into students&#x2019; cognitive states during online learning. We evaluated our approach by comparing the deep-learning model trained on the original dataset with that trained on feature-engineered data using K-fold cross-validation. Preliminary testing showed that the proposed DNN &#x002B; LSTM model, which incorporates probabilistic features and a custom attention layer, achieves high accuracy in identifying moments of confusion among MOOC students. This study advances the EEG data analysis, leading to a better understanding of confusion patterns and supports personalized interventions for online education platforms.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Raghavendra Ganiga et al.",
      "keywords": "Confusion; Computer science; Electroencephalography; Layer (electronics); Speech recognition; Brain\u2013computer interface; Artificial intelligence; Psychology; Neuroscience; Materials science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3337035",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3106488590",
      "doi": "10.1109/access.2020.3036692",
      "title": "Machine Learning Application With Quantitative Digital Subtraction Angiography for Detection of Hemorrhagic Brain Arteriovenous Malformations",
      "abstract": "Clinical features are the primary measures used for risk assessment of cerebrovascular diseases. However, clinical features, especially angioarchitecture, in digital subtraction angiography require further interpretation by specialized radiologists. This approach for risk assessment requires multivariable analysis and is, therefore, challenging when completed manually. In this study, we employed three machine learning models, namely the random forest, nai&#x0308;ve Bayes classifier, and support vector machine, for the detection of hemorrhagic brain arteriovenous malformations using digital subtraction angiography. Quantitative measurements from digital subtraction angiography were used as features, and the chi-squared test, minimum redundancy maximum relevance, ReliefF, and two-sample $t$ tests were used for feature selection. Bayesian optimization was conducted to optimize the hyperparameters of the three models. The random forest model outperformed the other two models. As a human control, three radiologists diagnosed an independent testing data set. The random forest model had a computation time of less than a second for the whole data set for classification. Accuracy and the area under the receiver operating characteristic curve were 92.7% and 0.98 for the training data set and 85.7% and 0.97 for the independent testing data set, respectively. Compared with the mean diagnosis time of approximately half a minute per patient and the highest accuracy of 76.2% for the three radiologists, the random forest model was faster and more accurate for our data set. These results suggest that the machine learning model based on hemodynamic features from quantitative digital subtraction angiography is a promising tool for detecting hemorrhagic brain arteriovenous malformations.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Jia\u2010Sheng Hong et al.",
      "keywords": "Random forest; Digital subtraction angiography; Artificial intelligence; Computer science; Naive Bayes classifier; Hyperparameter; Feature selection; Receiver operating characteristic; Support vector machine; Subtraction; Data set; Pattern recognition (psychology); Machine learning; Angiography; Radiology; Medicine; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3036692",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3099918527",
      "doi": "10.1109/jbhi.2020.3039414",
      "title": "Generalized Fixation Invariant Nuclei Detection Through Domain Adaptation Based Deep Learning",
      "abstract": "Nucleus detection is a fundamental task in histological image analysis and an important tool for many follow up analyses. It is known that sample preparation and scanning procedure of histological slides introduce a great amount of variability to the histological images and poses challenges for automated nucleus detection. Here, we studied the effect of histopathological sample fixation on the accuracy of a deep learning based nuclei detection model trained with hematoxylin and eosin stained images. We experimented with training data that includes three methods of fixation; PAXgene, formalin and frozen, and studied the detection accuracy results of various convolutional neural networks. Our results indicate that the variability introduced during sample preparation affects the generalization of a model and should be considered when building accurate and robust nuclei detection algorithms. Our dataset includes over 67 000 annotated nuclei locations from 16 patients and three different sample fixation types. The dataset provides excellent basis for building an accurate and robust nuclei detection model, and combined with unsupervised domain adaptation, the workflow allows generalization to images from unseen domains, including different tissues and images from different labs.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Mira Valkonen et al.",
      "keywords": "Artificial intelligence; Computer science; Convolutional neural network; Pattern recognition (psychology); Deep learning; Domain adaptation; Workflow; Generalization; Fixation (population genetics); Sample (material); Computer vision; Classifier (UML); Mathematics; Chemistry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2020.3039414",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4382138645",
      "doi": "10.1109/jsen.2023.3288151",
      "title": "Calibrating Oxygen Saturation Measurements for Different Skin Colors Using the Individual Typology Angle",
      "abstract": "Objective: Since the start of the SARS-CoV-2 pandemic, wearable devices featuring oxygen-saturation measurements have gradually attracted public attention. However, the US Food and Drug Administration (FDA) has raised doubts about the accuracy of watch-type oximeters (e.g., Apple Watch and Fitbit Sense) for darker-skinned users. That is, the accuracy of oxygen-saturation measurements is affected by skin tone. Accordingly, this article proposes a method of calibrating the bias of the oxygen-saturation measurement caused by differences in skin tone. Method: We integrate a color sensor into a wearable device featuring the function oxygen-saturation measurement. We also use the individual typology angle (ITA) to quantify the user's skin color and the skin's ITA quantization value to calibrate the oxygen saturation value of the pulse oximeter sensor. The oxygen-saturation-calibration algorithm of the ITA-quantified value is suitable for determining the R-value bias caused by skin color. Results: Our experimental findings derive from testing the R-values of subjects with different skin colors and simulating and verifying oxygen saturation ranges from 70% to 100%. The findings suggest that it is possible for the oxygen saturation bias of darker-skinned subjects to be reduced from an A <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">rms</sub> error of 5.44% to an A <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">rms</sub> error of 0.82%. That is, using ITA-quantified value for calibration, the accuracy of oxygen saturation measurements has been significantly improved. Conclusion: The proposed method enables the oxygen-saturation measurements of darker-skinned subjects to comply with the FDA guidance and ISO 80601-2-61:2017 standards, meaning that this study's method can effectively improve the accuracy of the oxygen-saturation measurements of watch-type oximeters.",
      "year": "2023",
      "journal": "IEEE Sensors Journal",
      "authors": "Cheng-Yan Guo et al.",
      "keywords": "Typology; Saturation (graph theory); Materials science; Optics; Computer science; Physics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2023.3288151",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3183340886",
      "doi": "10.1109/access.2021.3098453",
      "title": "Identifying Patients With PTSD Utilizing Resting-State fMRI Data and Neural Network Approach",
      "abstract": "Purpose: The primary aim of the study is to identify the existence of the post-traumatic stress disorder (PTSD) in an individual and to detect the dominance level of each affected brain region in PTSD using rs-fMRI data. This will assist the psychiatrists and neurologists to distinguish impartially between PTSD individuals and healthy controls for the brain-based treatment of PTSD. Methods: Twenty-eight individuals (14 with PTSD, 14 healthy controls) were assessed to obtain rs-fMRI data of their six brain regions-of-interest. The rs-fMRI data analyzed by the Artificial Neural Network (ANN), adopting the training-validation-testing approach to classify PTSD and to identify the most affected brain region due to PTSD. The classification accuracy is justified by a variety of different methods and metrics. Results: Three ANN models were established to attain the study\u2019s purpose using the susceptible regions in the right, left, and both hemispheres, and the classification accuracy of ANN models achieved 79%, 93.5%, and 94.5%, respectively. The prediction accuracy even increased in the independent holdout sample using trained models. The developed models are reliable, intellectually attractive and generalize. Additionally, the most dominant region in the PTSD individuals was the left hippocampus and the least was the right hippocampus. Conclusion: The present investigation achieved high classification accuracy and identified the brain regions those contributed most to differentiating PTSD individuals from healthy controls. The results indicated that the left hippocampus is the most affected brain region in PTSD individuals. Therefore, our findings are helpful for practitioners for diagnostic, medication, and therapy of the affected brain regions by knowing the strength of infected regions.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mirza Naveed Shahzad et al.",
      "keywords": "Artificial neural network; Resting state fMRI; Dominance (genetics); Psychology; Neural correlates of consciousness; Functional connectivity; Clinical psychology; Audiology; Artificial intelligence; Medicine; Neuroscience; Computer science; Cognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3098453",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3094069611",
      "doi": "10.1109/access.2020.3032066",
      "title": "Computer Aided Autism Diagnosis Using Diffusion Tensor Imaging",
      "abstract": "Autism Spectrum Disorder (ASD), commonly known as autism, is a lifelong developmental disorder associated with a broad range of symptoms including difficulties in social interaction, communication skills, and restricted and repetitive behaviors. In autism spectrum disorder, numerous studies suggest abnormal development of neural networks that manifest itself as abnormalities of brain shape, functionality, and/ or connectivity. The aim of this work is to present our automated computer aided diagnostic (CAD) system for accurate identification of autism spectrum disorder based on the connectivity of the white matter (WM) tracts. To achieve this goal, two levels of analysis are provided for local and global scores using diffusion tensor imaging (DTI) data. A local analysis using the Johns Hopkins WM atlas is exploited for DTI atlas-based segmentation. Furthermore, WM integrity is examined by extracting the most notable features representing WM connectivity from DTI. Interactions of WM features between different areas in the brain, demonstrating correlations between WM areas were used, and feature selection among those associations were made. Finally, a leave-one-subject-out classifier is employed to yield a final per-subject decision. The proposed system was tested on a large dataset of 263 subjects from the National Database of Autism Research (NDAR) with their Autism Diagnostic Observation Schedule (ADOS) scores and diagnosis (139 typically developed: 66 males, and 73 females, and 124 autistics: 66 males, and 58 females), with ages ranging from 96 to 215 months, achieving an overall accuracy of 73%. In addition to this achieved global accuracy, diagnostically-important brain areas were identified, allowing for a better understanding of ASD-related brain abnormalities, which is considered as an essential step towards developing early personalized treatment plans for children with autism spectrum disorder.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Yaser ElNakieb et al.",
      "keywords": "Autism; Autism Diagnostic Observation Schedule; Diffusion MRI; Autism spectrum disorder; White matter; Neuroimaging; Psychology; Computer science; Artificial intelligence; Neuroscience; Developmental psychology; Magnetic resonance imaging; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3032066",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4293499158",
      "doi": "10.1109/access.2022.3202560",
      "title": "Learning From Limited and Imbalanced Medical Images With Finer Synthetic Images From GANs",
      "abstract": "Chest X-ray is a prevalent medical imaging modality for detecting lung diseases. The clinical analysis of X-ray images is usually conducted by radiologists, who represent valuable human resources. In practice, situations with insufficient radiologists to timely analyze large quantities of X-ray data are very common. Accordingly, developing an automated computer-aided lung disease classification system is beneficial to facilitate diagnoses. However, due to restrictions of costs and time, collecting large amounts of accurately labeled X-ray images to train a machine learning based diagnosis system is challenging. Another limitation is the class imbalances present in datasets. Facing these challenges, we investigate the effectiveness of using generative models, particularly generative adversarial networks (GANs), to synthesize new data to tackle the issue of data paucity and class imbalances. To this end, it should be noted that few existing works have studied the effect of generated image quality on the performance of different learning models, particularly in medical imaging. Therefore, the current paper represents one of the first comprehensive investigations into the impact of synthetic image generation on classifier performance, which is empirically elucidated by a comparative analysis of a simpler deep convolutional GAN to a more complex progressive GAN design. Another contribution of this paper is a multi-scale convolutional neural network (CNN) architecture, which can take advantage of image features at different scales for better learning from scratch. Altogether, to verify the robustness of using GANs to augment datasets, we compare various data augmentation approaches, when applied to different network architectures, including transfer learning, learning-from-scratch CNNs, state-of-the-art ResNet, EfficientNet, DenseNet, and the proposed multi-scale CNN. Specifically, testing on two publicly available datasets, the obtained results show that using finer images synthesized from GANs with the proposed multi-scale CNN achieved good classification performance, under a wide range of operating conditions.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Xiaoli Qin et al.",
      "keywords": "Computer science; Artificial intelligence; Convolutional neural network; Robustness (evolution); Deep learning; Medical diagnosis; Machine learning; Classifier (UML); Medical imaging; Transfer of learning; Contextual image classification; Pattern recognition (psychology); Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3202560",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3011558710",
      "doi": "10.1109/access.2020.2979898",
      "title": "Clustering-Based Emotion Recognition Micro-Service Cloud Framework for Mobile Computing",
      "abstract": "In a situation where life becomes more stressful and challenging, people feel compelled to be more concerned about their mental situation. Different emotional statuses are external reactions to different mental states. Therefore, researchers always identify people's mental situation by monitoring their real-time emotions. At the same time, due to the availability of built-in sensors in a smartphone, applications that can identify real-time emotions of mobile users are constantly emerging. However, compared to most emotion recognition algorithms, computing resources and battery life in mobile phones are always limited. This makes accuracy and latency of these applications are unsatisfactory. In this paper, we propose a micro-service platform for mobile emotion recognition application developers (MSPMERAD) which can supply high performance. First, a classifier fusion emotion recognition algorithm is proposed by using a dynamic adaptive fusion strategy. Second, this new algorithm is encapsulated into a micro-service. With other affiliated micro-services such as data uploading, preprocessing, etc., developers can ignore the implementation of the emotion recognition algorithm and just focus on how to collect sensor data and interact with users. The accuracy and latency of one application based on the MSPMERAD are compared with another application that is implemented using a locale emotion recognition algorithm. Experiments based on the daily behavior data of 50 student volunteers show that the application based on our platform has higher recognition accuracy with a more reasonable time.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ping Wang et al.",
      "keywords": "Computer science; Cloud computing; Cluster analysis; Emotion recognition; Big data; Machine learning; Mobile computing; Upload; Artificial intelligence; Multimedia; Data mining; World Wide Web; Computer network; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2979898",
      "cited_by_count": 17,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389664981",
      "doi": "10.1109/access.2023.3342158",
      "title": "A Study on Mobile Crowd Sensing Systems for Healthcare Scenarios",
      "abstract": "Due to the growing capabilities of mobile phones and devices, mobile crowd sensing (MCS) is rapidly gaining popularity among researchers in different fields, given its ability to collect data at scale and low cost. MCS is particularly important in the healthcare domain since it provides opportunities to collect health, wellness, and Quality of Life information from a large and diverse population. For example, MCS can be used to detect early signs of emerging health conditions, track the spread of infectious diseases, and assess the effectiveness of interventions without the need for frequent clinical visits. Consequently, MCS can also reduce healthcare costs and help overcome barriers to healthcare access. This article takes a closer look at MCS systems that have been used to collect data for research in the medical and healthcare domains. We provide a thorough analysis of selected systems based on their different health-related objectives, such as monitoring physical activity, detecting and preventing disorders, and providing medical treatment. We also adopt a three-layered architecture to structure health-centric MCS frameworks, consisting of application, data, and sensing layers. In the application layer, we analyze participant recruitment, incentive mechanisms, and task allocation strategies. In the data layer, we analyze the types of data collected and how they are stored and processed for future use. The sensing layer specifies the sensing methods and explains the fundamental requirements at a lower level. Additionally, we explore the significant challenges faced by existing MCS systems and domains that offer promising avenues for future research, which are user privacy, resource utilization, data quality, and user compliance. This work provides insights into some practical applications of MCS, highlights challenges faced by existing MCS solutions, and how they can be addressed, all of which can help catalyze future research in MCS development.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Enshi Zhang et al.",
      "keywords": "Computer science; Health care; Popularity; Data science; Incentive; Mobile device; Risk analysis (engineering); Business; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3342158",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4200076507",
      "doi": "10.1109/jtehm.2021.3134926",
      "title": "A Preliminary Investigation of Similarities of High Resolution Cervical Auscultation Signals Between Thin Liquid Barium and Water Swallows",
      "abstract": "Dysphagia, commonly referred to as abnormal swallowing, affects millions of people annually. If not diagnosed expeditiously, dysphagia can lead to more severe complications, such as pneumonia, nutritional deficiency, and dehydration. Bedside screening is the first step of dysphagia characterization and is usually based on pass/fail tests in which a nurse observes the patient performing water swallows to look for dysphagia overt signs such as coughing. Though quick and convenient, bedside screening only provides low-level judgment of impairment, lacks standardization, and suffers from subjectivity. Recently, high resolution cervical auscultation (HRCA) has been investigated as a less expensive and non-invasive method to diagnose dysphagia. It has shown strong preliminary evidence of its effectiveness in penetration-aspiration detection as well as multiple swallow kinematics. HRCA signals have traditionally been collected and investigated in conjunction with videofluoroscopy exams which are performed using barium boluses including thin liquid. An HRCA-based bedside screening is highly desirable to expedite the initial dysphagia diagnosis and overcome all the drawbacks of the current pass/fail screening tests. However, all research conducted for using HRCA in dysphagia is based on thin liquid barium boluses and thus not guaranteed to provide valid results for water boluses used in bedside screening. If HRCA signals show no significant differences between water and thin liquid barium boluses, then the same algorithms developed on thin liquid barium boluses used in diagnostic imaging studies, it can be then directly used with water boluses. This study investigates the similarities and differences between HRCA signals from thin liquid barium swallows compared to those signals from water swallows. Multiple features from the time, frequency, time-frequency, and information-theoretic domain were extracted from each type of swallow and a group of linear mixed models was tested to determine the significance of differences. Machine learning classifiers were fit to the data as well to determine if the swallowed material (thin liquid barium or water) can be correctly predicted from an unlabeled set of HRCA signals. The results demonstrated that there is no systematic difference between the HRCA signals of thin liquid barium swallows and water swallows. While no systematic difference was discovered, the evidence of complete conformity between HRCA signals of both materials was inconclusive. These results must be validated further to confirm conformity between the HRCA signals of thin liquid barium swallows and water swallows.",
      "year": "2021",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Ryan Schwartz et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2021.3134926",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312579901",
      "doi": "10.1109/access.2022.3213725",
      "title": "ESPotensio: A Low-Cost and Portable Potentiostat With Multi-Channel and Multi-Analysis Electrochemical Measurements",
      "abstract": "Electrochemical measurement methods are widely used to analyze various biochemical reactions due to their simplicity and versatility. Therefore, the development of potentiostats, electrochemical-based analytical instruments, that are low in cost but maintaining rich analytical features is highly demanding. In this paper, we report the development of a low-cost and portable potentiostat system, named ESPotensio, which supports six different electrochemical measurement methods and a multi-channel electrochemical measurement. The measurement methods it supports include the cyclic voltammetry (CV), linear sweep voltammetry (LSV), square wave voltammetry (SWV), differential pulse voltammetry (DPV), normal pulse voltammetry (NPV), and the observation of electrochemical response current against time based on chronoamperometry (CA) measurement method. Moreover, each of these measurement methods can be run semi-parallelly within three different channels. The electrochemical measurement precision, accuracy, and error of ESPotensio were evaluated based on the repeated measurements and the comparison with the commercial potentiostats. The results showed that it could produce highly accurate electrochemical measurements by having an average accuracy of more than 90&#x0025; compared to the commercial potentiostat, Emstat Pico. Ultimately, the hardware design was determined accordingly to meet the low-cost demand by costing of only USD 21.4 for the total system realization.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Isa Anshori et al.",
      "keywords": "Potentiostat; Chronoamperometry; Cyclic voltammetry; Linear sweep voltammetry; Voltammetry; Differential pulse voltammetry; Analytical Chemistry (journal); Computer science; Electronic engineering; Materials science; Electrochemistry; Electrode; Chemistry; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3213725",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4366084014",
      "doi": "10.1109/tnsre.2023.3267811",
      "title": "Optimized Transfer Learning Based Dementia Prediction System for Rehabilitation Therapy Planning",
      "abstract": "Dementia is a neurodegenerative disease that causes a progressive deterioration of thinking, memory, and the ability to perform daily tasks. Other common symptoms include emotional disorders, language disorders, and reduced mobility; however, self-consciousness is unaffected. Dementia is irreversible, and medicine can only slow but not stop the degeneration. However, if dementia could be predicted, its onset may be preventable. Thus, this study proposes a revolutionary transfer-learning machine-learning model to predict dementia from magnetic resonance imaging data. In training, k-fold cross-validation and various parameter optimization algorithms were used to increase prediction accuracy. Synthetic minority oversampling was used for data augmentation. The final model achieved an accuracy of 90.7%, superior to that of competing methods on the same data set. This study's model facilitates the early diagnosis of dementia, which is key to arresting neurological deterioration from the disease, and is useful for underserved regions where many do not have access to a human physician. In the future, the proposed system can be used to plan rehabilitation therapy programs for patients.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Ping\u2010Huan Kuo et al.",
      "keywords": "Dementia; Oversampling; Physical medicine and rehabilitation; Set (abstract data type); Machine learning; Persistent vegetative state; Transfer of learning; Rehabilitation; Artificial intelligence; Computer science; Consciousness; Physical therapy; Disease; Medicine; Psychology; Neuroscience; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3267811",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386025853",
      "doi": "10.1109/access.2023.3307014",
      "title": "Collaborative Consultation Doctors Model: Unifying CNN and ViT for COVID-19 Diagnostic",
      "abstract": "The COVID-19 pandemic presents significant challenges due to its high transmissibility and mortality risk. Traditional diagnostic methods, such as RT-PCR, have limitations that hinder timely and accurate screening. In response, AI-powered computer-aided imaging analysis techniques have emerged as a promising alternative for COVID-19 diagnosis. In this paper, we propose a novel approach that combines the strengths of Convolutional Neural Network (CNN) and Vision Transformer (ViT) to enhance the performance of COVID-19 diagnosis models. CNN excels at capturing spatial features in medical images, while ViT leverages self-attention mechanisms inspired by human radiologists. Additionally, our approach draws inspiration from subclinical diagnosis, a collaborative process involving attending physicians and specialists, which has proven effective in achieving accurate and comprehensive diagnoses. To this end, we employ an early fusion strategy integrating CNN and ViT, then fed into a residual neural network. By fusing these complementary features, our approach achieves state-of-the-art performance in accurately identifying COVID-19 cases on two benchmark datasets: Chest X-ray and Clean-CC-CCII. This research has the potential to enable timely and accurate screening, aiding in the early detection and management of COVID-19 cases. Our findings contribute to the growing knowledge of AI-powered diagnostic techniques and demonstrate the potential for advanced imaging analysis methods to support medical professionals in combating the ongoing pandemic.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Trong-Thuan Nguyen et al.",
      "keywords": "Computer science; Medical diagnosis; Convolutional neural network; Artificial intelligence; Coronavirus disease 2019 (COVID-19); Medical imaging; Machine learning; Medical physics; Medicine; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3307014",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391559426",
      "doi": "10.1109/access.2024.3363634",
      "title": "Explainable Machine Learning Prediction for the Academic Performance of Deaf Scholars",
      "abstract": "Deaf and Hard of Hearing (DHH) students encounter obstacles in higher education due to language and communication challenges. Although research aims to improve their academic performance, the potential of Machine Learning (ML) remains underutilized in DHH education. The opacity of ML models further complicates their adoption. This study aims to fill this gap by developing a novel ML-based system with eXplainable AI (XAI), specifically utilizing Local Interpretable Model-Agnostic Explainer (LIME) and Shapley Additive Explainer (SHAP). The objective is twofold: predicting at-risk DHH students and explaining risk factors. Merging ML and XAI, this approach could positively impact DHH students&#x2019; educational outcomes. A dataset of 454 records detailing DHH students is collected. To address dataset limitations, synthetic data and SMOTE are used. Students are categorized into three performance levels. The data is modeled with different ML models, transfer models, ensemble models, and combination models. Among the models, the stacked model with XGBoost, ExtraTrees, and Random Forest exhibited better performance with an accuracy of 92.99&#x0025;. Results highlight the model&#x2019;s significance, providing insights through XAI into crucial factors affecting academic performance, including communication mode, early intervention, schooling type, and family deafness history. LIME and SHAP values were found to be effective in deriving insights into DHH student performance prediction framework. Communication mode, notably, strongly influences at-risk students. The major contribution of this study is the development of a novel ML-based system and the XAI interpretations whose value lies in its social relevance, guiding stakeholders to enhance DHH scholars&#x2019; academic achievements.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "N. R. Raji et al.",
      "keywords": "Computer science; Artificial intelligence; Machine learning; Natural language processing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3363634",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4226401072",
      "doi": "10.1109/access.2022.3168680",
      "title": "Mitigating Domain Shift in AI-Based TB Screening With Unsupervised Domain Adaptation",
      "abstract": "We demonstrate that Domain Invariant Feature Learning (DIFL) can improve the out-of-domain generalizability of a deep learning Tuberculosis (TB) screening algorithm. It is well known that state of the art deep learning algorithms often have difficulty generalizing to unseen data distributions due to &#x201C;domain shift.&#x201D; In the context of medical imaging, this could lead to unintended biases such as the inability to generalize from one patient population to another. We analyze the performance of a ResNet-50 classifier for the purposes of TB screening using the four most popular public datasets with geographically diverse sources of imagery. We show that without domain adaptation, ResNet-50 has difficulty in generalizing between imaging distributions from a number of public TB screening datasets with imagery from geographically distributed regions. However, with the incorporation of DIFL, the out-of-domain performance is greatly enhanced. Analysis criteria includes a comparison of accuracy, sensitivity, specificity and AUC over both the baseline, as well as the DIFL enhanced algorithms. We conclude that DIFL improves generalizability of TB screening while maintaining acceptable accuracy over the source domain imagery when applied across a variety of public datasets.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Nishanjan Ravin et al.",
      "keywords": "Generalizability theory; Computer science; Domain adaptation; Artificial intelligence; Classifier (UML); Deep learning; Machine learning; Pattern recognition (psychology); Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3168680",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4376478082",
      "doi": "10.1109/tcds.2023.3275587",
      "title": "ElectrodeNet\u2014A Deep-Learning-Based Sound Coding Strategy for Cochlear Implants",
      "abstract": "ElectrodeNet, a deep learning based sound coding strategy for the cochlear implant (CI), is proposed to emulate the advanced combination encoder (ACE) strategy by replacing the conventional envelope detection using various artificial neural networks. The extended ElectrodeNet-CS strategy further incorporates the channel selection (CS). Network models of deep neural network (DNN), convolutional neural network (CNN), and long short-term memory (LSTM) were trained using the Fast Fourier Transformed bins and channel envelopes obtained from the processing of clean speech by the ACE strategy. Objective speech understanding using short-time objective intelligibility (STOI) and normalized covariance metric (NCM) was estimated for ElectrodeNet using CI simulations. Sentence recognition tests for vocoded Mandarin speech were conducted with normal-hearing listeners. DNN, CNN, and LSTM based ElectrodeNets exhibited strong correlations to ACE in objective and subjective scores using mean squared error (MSE), linear correlation coefficient (LCC) and Spearman's rank correlation coefficient (SRCC). The ElectrodeNet-CS strategy was capable of producing N-of-M compatible electrode patterns using a modified DNN network to embed maxima selection, and to perform in similar or even slightly higher average in STOI and sentence recognition compared to ACE. The methods and findings demonstrated the feasibility and potential of using deep learning in CI coding strategy.",
      "year": "2023",
      "journal": "IEEE Transactions on Cognitive and Developmental Systems",
      "authors": "Enoch Hsin-Ho Huang et al.",
      "keywords": "Computer science; Speech recognition; Deep learning; Artificial neural network; Artificial intelligence; Convolutional neural network; Intelligibility (philosophy); Correlation coefficient; Recurrent neural network; Correlation; Pattern recognition (psychology); Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcds.2023.3275587",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2040917388",
      "doi": "10.1109/access.2014.2340372",
      "title": "GPU-Based Acceleration for Interior Tomography",
      "abstract": "The compressive sensing (CS) theory shows that real signals can be exactly recovered from very few samplings. Inspired by the CS theory, the interior problem in computed tomography is proved uniquely solvable by minimizing the region-of-interest's total variation if the imaging object is piecewise constant or polynomial. This is called CS-based interior tomography. However, the CS-based algorithms require high computational cost due to their iterative nature. In this paper, a graphics processing unit (GPU)-based parallel computing technique is applied to accelerate the CS-based interior reconstruction for practical application in both fan-beam and cone-beam geometries. Our results show that the CS-based interior tomography is able to reconstruct excellent volumetric images with GPU acceleration in a few minutes.",
      "year": "2014",
      "journal": "IEEE Access",
      "authors": "Rui Liu et al.",
      "keywords": "Acceleration; Piecewise; Graphics processing unit; Tomography; Computer science; Compressed sensing; Polynomial; Graphics; Computational science; Algorithm; Computer graphics (images); Mathematics; Physics; Optics; Mathematical analysis; Parallel computing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2014.2340372",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4296338923",
      "doi": "10.1109/tnsre.2022.3207624",
      "title": "An Interpretable Deep Learning Model for Speech Activity Detection Using Electrocorticographic Signals",
      "abstract": "Numerous state-of-the-art solutions for neural speech decoding and synthesis incorporate deep learning into the processing pipeline. These models are typically opaque and can require significant computational resources for training and execution. A deep learning architecture is presented that learns input bandpass filters that capture task-relevant spectral features directly from data. Incorporating such explainable feature extraction into the model furthers the goal of creating end-to-end architectures that enable automated subject-specific parameter tuning while yielding an interpretable result. The model is implemented using intracranial brain data collected during a speech task. Using raw, unprocessed timesamples, the model detects the presence of speech at every timesample in a causal manner, suitable for online application. Model performance is comparable or superior to existing approaches that require substantial signal preprocessing and the learned frequency bands were found to converge to ranges that are supported by previous studies.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Morgan Stuart et al.",
      "keywords": "Computer science; Pipeline (software); Preprocessor; Speech recognition; Artificial intelligence; Deep learning; Task (project management); Feature extraction; Artificial neural network; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3207624",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4324291913",
      "doi": "10.1109/jtehm.2023.3256966",
      "title": "Deep Survival Analysis With Clinical Variables for COVID-19",
      "abstract": "The findings indicate that using both Heparin and Exnox for treatment is typically the most useful factor in predicting a patient's chances of survival from COVID-19. Moreover, our predictive model shows that the combination of AI and clinical data can be applied to point-of-care services through fast-learning healthcare systems.",
      "year": "2023",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Ahmad Chaddad et al.",
      "keywords": "Coronavirus disease 2019 (COVID-19); 2019-20 coronavirus outbreak; Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); Computer science; Artificial intelligence; Medicine; Virology; Internal medicine; Outbreak",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2023.3256966",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312410003",
      "doi": "10.1109/access.2022.3226697",
      "title": "A Novel Respiratory Control and Actuation System for Upper-Limb Prosthesis Users: Clinical Evaluation Study",
      "abstract": "The most widely-used active upper-limb (UL) prostheses worldwide are body-powered (BP), which is a two-century-old technology. Despite their affordability and functional benefits to users, these devices are prone to poor outcomes for many patients. Additionally, BP devices have witnessed limited improvements compared to their externally-powered counterparts. Literature indicates a strong need for appropriate prosthetic solutions for children and adolescents. Our previous work introduced a first-of-its-kind breathing-powered UL prosthesis (&#x201C;Airbender&#x201D;) that can overcome several limitations of the current BP systems (e.g., restricted operation space, user discomfort caused by the harness to which the cables are attached). Users can regulate their breathing, and this controllable airflow is subsequently used to power a small (purpose-built and optimised) Tesla turbine that can accurately control the opening and closing of the prosthetic hand. The current work explores device usability in children and adolescents with a UL difference (n &#x003D; 15). Further, we gathered feedback, suggestions, and satisfaction levels from the study participants and their parents on breathing as a modality of controlling a prosthetic device. The collected responses and study observations were subjected to qualitative and statistical analysis. This study showcases real-world testing of a breathing-powered prosthesis and proves that UL-deficient children and adolescents can indeed operate the device (i.e., volitionally open or close) with their breathing input. The perceived level of difficulty in opening or closing the device tended to be on the &#x2018;easy&#x2019; side. We report generally favourable feedback obtained from participants and their parents. Additionally, design suggestions and satisfaction levels concerning different device attributes help us involve the key stakeholders in co-creating and proactively developing a robust product development roadmap. This work is aligned with creating a step-change in the potential BP prosthesis options for patients in the future, propelled by a need-led approach.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Vikranth Harthikote Nagaraja et al.",
      "keywords": "Usability; Breathing; Closing (real estate); Computer science; Control (management); Work (physics); Physical medicine and rehabilitation; Simulation; Human\u2013computer interaction; Medicine; Engineering; Artificial intelligence; Mechanical engineering; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3226697",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3192909585",
      "doi": "10.1109/access.2021.3101253",
      "title": "External Validation of Deep Learning Algorithms for Cardiothoracic Ratio Measurement",
      "abstract": "Recent advances in machine learning have made it possible to create automated systems for medical image diagnosis. Cardiothoracic ratio (CTR) measurement, a common procedure for assessing cardiac abnormality in chest radiographs, has been investigated by several deep learning studies aiming to automate the process. However, of key consideration is whether automated CTR measurements by machine learning models can yield CTR values as accurately and consistently as trained human technicians on unseen data and thereby be considered trustworthy for clinical application. To assess this, we performed external validation of automated CTR algorithms on a dataset of 7,517 images, comparing four variants of U-Net architecture in heart and lung segmentations and CTR calculations: VGG-11, VGG-16, SegNet, and AlbuNet. We then benchmarked their performance against two human experts manually measuring CTR on the same images in a clinical setting such that we could equitably compare model-to-human variation against human-to-human variation. Our analysis shows that AlbuNet demonstrates human-level performance in CTR measurements, achieving MAPE of 2.38&#x0025;, which is on par with human-to-human inter-rater variability (2.53&#x0025;) when using the manual measurement method. The other three U-Net variants, particularly VGG-16, also performed similarly well. Additionally, we conducted an extreme outlier analysis on each model architecture, assessing the percentage of samples with higher measurement errors than the maximum error from the manual method. AlbuNet outperformed other architectures with only 0.35&#x0025; occurrence of extreme outliers, while the other three U-Net variants ranged from 0.64&#x0025; to 1.06&#x0025; occurrence. Overall, the deep-learning-based algorithm was demonstrated to be as reliable as the manual method and shows strong potential for assisting radiologists in the CTR measurement process in clinical practice.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Warasinee Chaisangmongkon et al.",
      "keywords": "Computer science; Artificial intelligence; Outlier; Deep learning; Machine learning; Pattern recognition (psychology); Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3101253",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392902380",
      "doi": "10.1109/access.2024.3376438",
      "title": "Exploring Deep Learning and Machine Learning Approaches for Brain Hemorrhage Detection",
      "abstract": "Brain hemorrhage refers to a potentially fatal medical disorder that affects millions of individuals. The percentage of patients who survive can be significantly raised with the prompt identification of brain hemorrhages, due to image-guided radiography, which has emerged as the predominant treatment modality in clinical practice. A Computed Tomography Image has frequently been employed for the purpose of identifying and diagnosing neurological disorders. The manual identification of anomalies in the brain region from the Computed Tomography Image demands the radiologist to devote a greater amount of time and dedication. In the most recent studies, a variety of techniques rooted in Deep learning and traditional Machine Learning have been introduced with the purpose of promptly and reliably detecting and classifying brain hemorrhage. This overview provides a comprehensive analysis of the surveys that have been conducted by utilizing Machine Learning and Deep Learning. This research focuses on the main stages of brain hemorrhage, which involve preprocessing, feature extraction, and classification, as well as their findings and limitations. Moreover, this in-depth analysis provides a description of the existing benchmark datasets that are utilized for the analysis of the detection process. A detailed comparison of performances is analyzed. Moreover, this paper addresses some aspects of the above-mentioned technique and provides insights into prospective possibilities for future research.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Samia Ahmed et al.",
      "keywords": "Artificial intelligence; Identification (biology); Computer science; Deep learning; Preprocessor; Machine learning; Modality (human\u2013computer interaction); Benchmark (surveying); Feature extraction; Neuroimaging; Computed tomography; Feature (linguistics); Brain hemorrhage; Medical imaging; Variety (cybernetics); Process (computing); Medicine; Radiology; Neurosurgery",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3376438",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391341420",
      "doi": "10.1109/access.2024.3360328",
      "title": "A Comprehensive Survey of EEG Preprocessing Methods for Cognitive Load Assessment",
      "abstract": "Preprocessing electroencephalographic (EEG) signals during computer-mediated Cognitive Load tasks is crucial in Human-Computer Interaction (HCI). This process significantly influences subsequent EEG analysis and the efficacy of Artificial Intelligence (AI) models employed in Cognitive Load Assessment. Consequently, it stands as an indispensable procedure for developing dependable systems capable of adapting to users&#x2019; cognitive capacities and constraints. We systematically analyzed fifty-seven (57) research papers on computer-mediated Cognitive Load EEG experiments published between 2018 and 2023. The preprocessing methods identified were multiple, controversial, and strongly dependent on the particularities of each experiment and the derived experimental dataset. Our investigation involved the meticulous classification of preprocessing methods based on distinct parameters, namely the degree of user intervention, the noise level, and the subject pool size. Particular attention was paid to semi-automated denoising technology since conventional methods, advanced approaches, and standardized pipelines overwhelm research, but no optimum solution is available yet. This survey is anticipated to provide a valuable contribution to the rising demand for an efficient and fully automated preprocessing approach in EEG-based computerized Cognitive Load experiments.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Konstantina Kyriaki et al.",
      "keywords": "Computer science; Electroencephalography; Preprocessor; Cognition; Cognitive load; Artificial intelligence; Machine learning; Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3360328",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386265757",
      "doi": "10.1109/access.2023.3309638",
      "title": "3D Monitoring of Toothbrushing Regions and Force Using Multimodal Sensors and Unity",
      "abstract": "The goal of this study is to help people to monitor brushing process to maintain their oral quality by providing real-time feedback. In this research, a low-cost toothbrushing monitoring system of brushing regions and brushing force using multimodal sensors and Unity is proposed for toothbrushing quality monitoring. An inertial sensor attached to the handle of a toothbrush and Random Forester Classifier (RFC) model were used to estimate brushing regions; five force sensors clipped on the toothbrush and Random Forest Regression (RFR) model were used to estimate brushing force; a visual interface based on Unity was designed to display detection results in real-time. For brushing region detection, the results show that offline verification accuracy is 97.6&#x0025;, and average accuracy of online detection method is 74.0&#x0025;. For brushing force detection, 5 subjects were invited to participate in experiment on both User Dependent (UD) and User Independent (UI). The results show that average Root Mean Squared Error (RMSE) is 22.08g for UD experiment; average RMSE is 37.06g for UI experiment. For this 3D brushing monitoring system, 20 subjects were invited to participate in usability experiment. The results show that 3D brushing monitoring system of this research has good usability, performance, and user satisfaction.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Haicui Li et al.",
      "keywords": "Usability; Computer science; Mean squared error; Random forest; Artificial intelligence; Computer vision; Statistics; Mathematics; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3309638",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4391697021",
      "doi": "10.1109/tnsre.2024.3363756",
      "title": "Neural Network Dynamics and Brain Oscillations Underlying Aberrant Inhibitory Control in Internet Addiction",
      "abstract": "Previous studies have reported a role of alterations in the brain's inhibitory control mechanism in addiction. Mounting evidence from neuroimaging studies indicates that its key components can be evaluated with brain oscillations and connectivity during inhibitory control. In this study, we developed an internet-related stop-signal task with electroencephalography (EEG) signal recorded to investigate inhibitory control. Healthy controls and participants with Internet addiction were recruited to participate in the internet-related stop-signal task with 19-channel EEG signal recording, and the corresponding event-related potentials and spectral perturbations were analyzed. Brain effective connections were also evaluated using direct directed transfer function. The results showed that, relative to the healthy controls, participants with Internet addiction had increased Stop-P3 during inhibitory control, suggesting that they have an altered neural mechanism in impulsive control. Furthermore, participants with Internet addiction showed increased low-frequency synchronization and decreased alpha and beta desynchronization in the middle and right frontal regions compared to healthy controls. Aberrant brain effective connectivity was also observed, with increased occipital-parietal and intra-occipital connections, as well as decreased frontal-paracentral connection in participants with Internet addiction. These results suggest that physiological signals are essential in future implementations of cognitive assessment of Internet addiction to further investigate the underlying mechanisms and effective biomarkers.",
      "year": "2024",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Yi\u2010Li Tseng et al.",
      "keywords": "Addiction; Neuroscience; Electroencephalography; Psychology; Inhibitory control; The Internet; Brain activity and meditation; Mechanism (biology); Neuroimaging; Cognition; Computer science; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2024.3363756",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390871495",
      "doi": "10.1109/ojemb.2024.3354208",
      "title": "Expecting the Unexpected: Predicting Panic Attacks From Mood, Twitter, and Apple Watch Data",
      "abstract": "These promising results suggest that individuals who experience panic attacks may be able to anticipate their next attack which could be used to inform future prevention and intervention efforts.",
      "year": "2024",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Ellen W. McGinnis et al.",
      "keywords": "Panic; Mood; Psychology; Panic disorder; Psychiatry; Clinical psychology; Anxiety",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojemb.2024.3354208",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3089903515",
      "doi": "10.1109/access.2020.3028185",
      "title": "On the Road With 16 Neurons: Towards Interpretable and Manipulable Latent Representations for Visual Predictions in Driving Scenarios",
      "abstract": "This paper proposes a strategy for visual perception in the context of autonomous driving. Humans, when not distracted or drunk, are still the best drivers you can currently find. For this reason, we take inspiration from two theoretical ideas about the human mind and its neural organization. The first idea concerns how the brain uses structures of neuron ensembles that expand and compress information to extract abstract concepts from visual experience and code them into compact representations. The second idea suggests that these neural perceptual representations are not neutral but functional to predicting the future state of affairs in the environment. Similarly, the prediction mechanism is not neutral but oriented to the planning of future action. We identify within the deep learning framework two artificial counterparts of the aforementioned neurocognitive theories. We find a correspondence between the first theoretical idea and the architecture of convolutional autoencoders, while we translate the second theory into a training procedure that learns compact representations which are not neutral but oriented to driving tasks, from two distinct perspectives. From a static perspective, we force separate groups of neural units in the compact representations to represent specific concepts crucial to the driving task distinctly. From a dynamic perspective, we bias the compact representations to predict how the current road scenario will change in the future. We successfully learn compact representations that use as few as 16 neural units for each of the two basic driving concepts we consider: cars and lanes. We maintain the two concepts separated in the latent space to facilitate the interpretation and manipulation of the perceptual representations. The source code for this paper is available at https://github.com/3lis/rnn_vae.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Alice Plebe et al.",
      "keywords": "Computer science; Perception; Artificial intelligence; Perspective (graphical); Context (archaeology); Representation (politics); Action (physics); Task (project management); Visual perception; Cognitive science; Machine learning; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3028185",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3125737345",
      "doi": "10.1109/access.2021.3051274",
      "title": "3D Multi-Scale Residual Network Toward Lacunar Infarcts Identification From MR Images With Minimal User Intervention",
      "abstract": "Lacunes or lacunar infarcts are small fluid-filled cavities associated with cerebral small vessel disease (cSVD). They contribute to the development of lacunar stroke, dementia, and gait impairment. The identification of lacunes is of great significance in elucidating the pathophysiological mechanism of cSVD. This paper proposes a semi-automated 3D multi-scale residual convolutional network (3D ResNet) for lacunar infarcts detection, which can learn global representations of the anatomical location of lacunes using two multi-scale magnetic resonance image modalities. This process requires minimal user intervention by passing the potential suspicious lacunes into the network. The proposed network is trained, validated, and tested using five-fold cross-validation using data, including 696 lacunes, from 288 subjects. We also present experiments on various combinations of multi-scale inputs and their effect on extracting global context features that directly influence identification performance. The proposed system shows its capability to differentiate between true lacunes and lacune mimics, providing supportive interpretations for neuroradiologists. The proposed 3D multi-scale ResNet identifies lacunar infarcts with a sensitivity of 96.41%, a specificity of 90.92%, an overall accuracy of 93.67%, and an area under the receiver operator characteristic curve (AUC) of 93.67% over all fold tests. The proposed system also achieved a precision of 91.40% and an average number of FPs per subject of 1.32. The system may be feasible for clinical use by supporting decision-making for lacunar infarct detection.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mohammed A. Al\u2010masni et al.",
      "keywords": "Computer science; Residual; Scale (ratio); Identification (biology); Artificial intelligence; Intervention (counseling); Computer vision; Pattern recognition (psychology); Medicine; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3051274",
      "cited_by_count": 11,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312356006",
      "doi": "10.23919/jsc.2022.0008",
      "title": "Multi-Agent Based Stochastic Dynamical Model to Measure Community Resilience",
      "abstract": "Emergency services and utilities need appropriate planning tools to analyze and improve infrastructure and community resilience to disasters. Recognized as a key metric of community resilience is the social well-being of a community during a disaster, which is made up of mental and physical social health. Other factors influencing community resilience directly or indirectly are emotional health, emergency services, and the availability of critical infrastructures services, such as food, agriculture, water, transportation, electric power, and communications system. It turns out that in computational social science literature dealing with community resilience, the role of these critical infrastructures along with some important social characteristics is not considered. To address these weaknesses, we develop a new multi-agent based stochastic dynamical model, standardized by overview, design concepts, details, and decision (ODD+D) protocol and derived from neuro-science, psychological and social sciences, to measure community resilience in terms of mental and physical well-being. Using this model, we analyze the micro-macro level dependence between the emergency services and power systems and social characteristics such as fear, risk perception, information-seeking behaviour, cooperation, flexibility, empathy, and experience, in an artificial society. Furthermore, we simulate this model in two case studies and show that a high level of flexibility, experience, and cooperation enhances community resilience. Implications for both theory and practice are discussed.",
      "year": "2022",
      "journal": "Journal of Social Computing",
      "authors": "Jaber Valinejad et al.",
      "keywords": "Community resilience; Resilience (materials science); Flexibility (engineering); Psychological resilience; Emergency management; Knowledge management; Risk analysis (engineering); Computer science; Psychology; Business; Political science; Social psychology; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2022.0008",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3195652722",
      "doi": "10.1109/access.2021.3107457",
      "title": "Why College Students Prefer Typing Over Speech Input: The Dual Perspective",
      "abstract": "With the development of technology, the accuracy of speech input has vastly improved and the speed of speech input has surpassed that of typing. However, college students still refuse to switch to speech input as their primary compositional tool. To better understanding this phenomenon, this study investigates the preferences of 593 college students using PLS-SEM for structural model analysis. On the basis of innovation resistance theory (IRT) and technology acceptance model (TAM), this study explores the preference of college students for keyboard typing over speech input for document processing. Results showed that functional barriers (i.e., usage, value, and risk barriers) and psychological barriers (i.e., tradition and image barriers) positively affect users&#x2019; resistance to change. Perceived ease of use and perceived usefulness influence the intention to adopt speech input, which is consistent with TAM. Resistance to change was proven to negatively affect users&#x2019; intention to adopt speech input. Academically, results confirm that although barriers to speech input currently exist, users still consider speech input as easy and useful and plan to adopt the technology. In practice, speech recognition system companies can significantly enhance users&#x2019; adoption intentions by reducing barriers and increasing their perception of ease of use and usefulness of speech input.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Ling Long Tsai",
      "keywords": "Affect (linguistics); Perspective (graphical); Resistance (ecology); Usability; Perception; Dual (grammatical number); Technology acceptance model; Computer science; Preference; Value (mathematics); Speech recognition; Psychology; Human\u2013computer interaction; Artificial intelligence; Linguistics; Communication; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3107457",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3132258681",
      "doi": "10.1109/access.2021.3059785",
      "title": "Dental Impression Tray Selection From Maxillary Arch Images Using Multi-Feature Fusion and Ensemble Classifier",
      "abstract": "Dental impression tray is frequently used in dentistry to record the patient's oral structure for clinical oral diagnosis and treatment planning. Manual procedure of taking impressions is costly, time-consuming, and additionally, no research has been done on selecting dental impression tray from dental arch images using computer vision in real-life scenarios. In this spirit, an intelligent model is proposed based on computer vision and machine learning to select appropriate dental impression trays from maxillary arch images. A dataset of 52 patients' maxillary arch images have been acquired and various sets of features such as colors, textures, and shapes of the images were extracted to better characterize the maxillary arch images. Considering the importance of the features in describing the maxillary arch object and to improve the classification performance, a method based on multi-feature fusion with ensemble classifier is proposed. Besides, the performance of a deep learning based multilayer perceptron neural network is also investigated. The proposed multi-feature fusion with ensemble classifier attained 92.31% precision, 91.75% recall, 91.75% accuracy, respectively, on the dataset, which clearly establishes the feasibility of the proposed model. An illustration of a real-life application of the proposed model is also provided.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Muhammad Asif Hasan et al.",
      "keywords": "Computer science; Artificial intelligence; Impression; Classifier (UML); Arch; Dental arch; Feature extraction; Artificial neural network; Tray; Computer vision; Pattern recognition (psychology); Orthodontics; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3059785",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387247658",
      "doi": "10.1109/access.2023.3321509",
      "title": "Assessment of Hematological Predictors via Explainable Artificial Intelligence in the Prediction of Acute Myocardial Infarction",
      "abstract": "Acute myocardial infarction (AMI) is the main cause of death in developed and developing countries. AMI is a serious medical problem that necessitates hospitalization and sometimes results in death. Patients hospitalized in the emergency department (ED) should therefore receive an immediate diagnosis and treatment. Many studies have been conducted on the prognosis of AMI with hemogram parameters. However, no study has investigated potential hemogram parameters for the diagnosis of AMI using an interpretable artificial intelligence-based clinical approach. The purpose of this research is to implement the principles of explainable artificial intelligence (XAI) in the analysis of hematological predictors for AMI. In this retrospective analysis, 477 (48.6&#x0025;) patients with AMI and 504 (51.4&#x0025;) healthy individuals were enrolled and assessed in predicting AMI. Of the patients with AMI, 182 (38&#x0025;) had an ST-segment elevation MI (STEMI), and 295 (62&#x0025;) had a non-ST-segment elevation MI (NSTEMI). Demographic and hematological information of the patients was analyzed to determine AMI. The XAI approach combined with machine learning approaches (Extreme Gradient Boosting, XGB; Adaptive Boosting, AB; Light Gradient Boosting Machine, LGBM) was applied for the estimation of AMI and distinguishing subgroups of AMI (STEMI and NSTEMI). The SHAP approach was used to explain the predictions intuitively. After selecting the 10 most important hematological parameters for AMI, the LGBM model achieved 83&#x0025; and 74&#x0025; accuracy for prediction of AMI, and distinguishing subgroups of AMI (STEMI and NSTEMI), respectively. SHAP results showed that neutrophil (NEU), white blood cell (WBC), platelet width of distribution (PDW), and basophil (BA) were the most important for AMI prediction. Mean corpuscular volume (MCV), BA, monocytes (MO), and lymphocytes (LY) were the most important hematological parameters that distinguish STEMI from NSTEMI. The proposed model serves as a valuable tool for physicians, facilitating the diagnosis, treatment, and follow-up of patients with AMI and distinguishing subgroups of AMI (STEMI and NSTEMI). Analyzing readily accessible hemogram parameters empowers medical professionals to make informed decisions and provide enhanced care to a wide range of individuals.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "R\u00fcstem Y\u0131lmaz et al.",
      "keywords": "Medicine; Myocardial infarction; Internal medicine; Cardiology; Boosting (machine learning); Emergency department; Machine learning; Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3321509",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2994363107",
      "doi": "10.1109/tcbb.2019.2956708",
      "title": "RNASeqR: An R Package for Automated Two-Group RNA-Seq Analysis Workflow",
      "abstract": "RNA-Seq analysis has revolutionized researchers' understanding of the transcriptome in biological research. Assessing the differences in transcriptomic profiles between tissue samples or patient groups enables researchers to explore the underlying biological impact of transcription. RNA-Seq analysis requires multiple processing steps and huge computational capabilities. There are many well-developed R packages for individual steps; however, there are few R/Bioconductor packages that integrate existing software tools into a comprehensive RNA-Seq analysis and provide fundamental end-to-end results in pure R environment so that researchers can quickly and easily get fundamental information in big sequencing data. To address this need, we have developed the open source R/Bioconductor package, RNASeqR. It allows users to run an automated RNA-Seq analysis with only six steps, producing essential tabular and graphical results for further biological interpretation. The features of RNASeqR include: six-step analysis, comprehensive visualization, background execution version, and the integration of both R and command-line software. RNASeqR provides fast, light-weight, and easy-to-run RNA-Seq analysis pipeline in pure R environment. It allows users to efficiently utilize popular software tools, including both R/Bioconductor and command-line tools, without predefining the resources or environments. RNASeqR is freely available for Linux and macOS operating systems from Bioconductor (https://bioconductor.org/packages/release/bioc/html/RNASeqR.html).",
      "year": "2019",
      "journal": "IEEE/ACM Transactions on Computational Biology and Bioinformatics",
      "authors": "Kuan-Hao Chao et al.",
      "keywords": "Bioconductor; Workflow; Computer science; Software; Pipeline (software); RNA-Seq; Visualization; Software engineering; Data mining; Transcriptome; Operating system; Database; Biology; Genetics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcbb.2019.2956708",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4298127545",
      "doi": "10.23919/csms.2022.0016",
      "title": "Modeling and Analyzing of Breast Tumor Deterioration Process with Petri Nets and Logistic Regression",
      "abstract": "It is important to understand the process of cancer cell metastasis and some cancer characteristics that increase disease risk. Because the occurrence of the disease is caused by many factors, and the pathogenesis process is also complicated. It is necessary to use interpretable and visual modeling methods to characterize this complex process. Machine learning techniques have demonstrated extraordinary capabilities in identifying models and extracting patterns from data to improve medical prognostic decisions. However, in most cases, it is unexplainable. Using formal methods to model can ensure the correctness and understandability of prediction decisions in a certain extent, and can well visualize the analysis process. Coloured Petri Nets (CPN) is a powerful formal model. This paper presents a modeling approach with CPN and machine learning in breast cancer, which can visualize the process of cancer cell metastasis and the impact of cell characteristics on the risk of disease. By evaluating the performance of several common machine learning algorithms, we finally choose the logistic regression algorithm to analyze the data, and integrate the obtained prediction model into the CPN model. Our method allows us to understand the relations among the cancer cell metastasis and clearly see the quantitative prediction results.",
      "year": "2022",
      "journal": "Complex System Modeling and Simulation",
      "authors": "Xuyue Wang et al.",
      "keywords": "Computer science; Correctness; Machine learning; Process (computing); Petri net; Logistic regression; Artificial intelligence; Cancer; Breast cancer metastasis; Breast cancer; Metastasis; Data mining; Cancer metastasis; Algorithm; Medicine; Programming language; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/csms.2022.0016",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386453696",
      "doi": "10.1109/access.2023.3312310",
      "title": "Exploiting Censored Information in Self-Training for Time-to-Event Prediction",
      "abstract": "A common problem in medical applications is predicting the time until an event of interest such as the onset of a disease, time to tumor recurrence, and time to mortality. Traditionally, classical survival analysis techniques have been used to address this problem. However, these techniques are of limited usage when considering nonlinear and interaction effects among biomarkers, and high profiling survival datasets. Although supervised machine learning techniques have shown some advantages over standard statistical methods in handling high-dimensional datasets, their application to survival analysis, particularly in the context of feature-based approaches, is at best limited. A major reason behind this is the difficulty in processing censored data, which is a common component of survival analysis. In this paper, we have transformed the time-to-event prediction problem into a semi-supervised regression problem. We utilize a self-training wrapper approach, where an outer layer guides the iterative refinement of predictions. This approach enhances the performance of our model by leveraging confident predictions from censored instances. The self-training wrapper is applied in conjunction with random survival forests as the base learner. In this approach, censored observations are introduced as partially labeled observations since their predicted time (target value) should exceed the censoring time. First, the algorithm builds a base model over the observed instances and then augments them iteratively with highly confident predictions over the censored set, using a smart stopping criterion based on the censoring time. The proposed approach has been evaluated and compared on fifteen real-world survival analysis datasets, including clinical and high-dimensional data. The ability of our proposed approach to integrate partial supervision information within a semi-supervised learning strategy has enabled it to achieve competitive performance compared to baseline models, particularly in the case of a high-dimensional regime.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Fateme Nateghi Haredasht et al.",
      "keywords": "Censoring (clinical trials); Computer science; Machine learning; Survival analysis; Artificial intelligence; Random forest; Profiling (computer programming); Data mining; Event (particle physics); Regression; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3312310",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389252439",
      "doi": "10.1109/tbme.2023.3331305",
      "title": "DuKA: A Dual-Keyless-Attention Model for Multi-Modality EHR Data Fusion and Organ Failure Prediction",
      "abstract": "DuKA is a lightweight model that innovatively uses dual attention in a hierarchical way to fuse diagnosis, procedure and medication information for organ failure predictions. It also enhances disease comprehension and supports personalized treatment.",
      "year": "2023",
      "journal": "IEEE Transactions on Biomedical Engineering",
      "authors": "Zhangdaihong Liu et al.",
      "keywords": "Computer science; Modality (human\u2013computer interaction); Modalities; Heart failure; Flexibility (engineering); Artificial intelligence; Intensive care medicine; Data mining; Medicine; Internal medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbme.2023.3331305",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3122057397",
      "doi": "10.1109/tkde.2021.3052150",
      "title": "MOLER: Incorporate Molecule-Level Reward to Enhance Deep Generative Model for Molecule Optimization",
      "abstract": "The goal of molecular optimization is to generate molecules similar to a target molecule but with better chemical properties. Deep generative models have shown great success in molecule optimization. However, due to the iterative local generation process of deep generative models, the resulting molecules can significantly deviate from the input in molecular similarity and size, leading to poor chemical properties. The key issue here is that the existing deep generative models restrict their attention on substructure-level generation without considering the entire molecule as a whole. To address this challenge, we propose Molecule-Level Reward functions (MOLER) to encourage (1) the input and the generated molecule to be similar, and to ensure (2) the generated molecule has a similar size to the input. The proposed method can be combined with various deep generative models. Policy gradient technique is introduced to optimize reward-based objectives with small computational overhead. Empirical studies show that MOLER achieves up to 20.2% relative improvement in success rate over the best baseline method on several properties, including QED, DRD2 and LogP.",
      "year": "2021",
      "journal": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "Tianfan Fu et al.",
      "keywords": "Computer science; Generative model; Generative grammar; Artificial intelligence; Similarity (geometry); Overhead (engineering)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tkde.2021.3052150",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3107951804",
      "doi": "10.1109/access.2020.3040064",
      "title": "Implantable and Wearable Neuroengineering Education: A Review of Postgraduate Programmes",
      "abstract": "Neurological diseases (NDs) such as epilepsy, dementia, Alzheimer\u2019s and Parkinson\u2019s disease currently affect almost two thirds of Europe\u2019s population. Furthermore, enormous financial commitments are required to deal with these diseases. Therefore, there is growing concern that countries with transitional economies may struggle to handle this financial burden, which warrants the urgent development of new technologies for early disease identification and treatment. Consequently, the aim of our article is to survey the range of postgraduate programmes that strive to nurture neuroengineering graduates who will excel in designing and developing implantable and wearable technologies for ND applications. Based on the basic building blocks of these technologies, we have identified four key areas that programmes need to cover, which include Neuroscience, Integrated Circuits, Communications and Signal Processing as well as Electronic Devices. According to our systematic review, a total of fifteen institutes satisfied our search criteria and provided the necessary neuroengineering training. The majority of these programmes are located in Europe and North America, which means that cross border and interdisciplinary efforts are required to develop educational programmes in countries most vulnerable to these diseases. We also provide recommendations for how these programmes can be delivered using non-traditional teaching approaches to ensure that graduates develop the necessary soft skills required by the constantly shifting job market.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Rami Ghannam et al.",
      "keywords": "Population; Wearable computer; Identification (biology); Neural engineering; Computer science; Medical education; Medicine; Data science; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2020.3040064",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4292387247",
      "doi": "10.1109/access.2022.3199770",
      "title": "Agent-Based Simulations Using Genetic Algorithm Calibration: A Children\u2019s Services Application",
      "abstract": "With increased pressures and tightening budgets within English Children\u2019s Services in the UK, seeking more effective operational and financial management is becoming a more significant topic of discussion. In other sectors, complex data analysis methods provide the aforementioned management improvements through better understanding of current situations leading to better decision making. Currently, investment remains at a slow pace in English Local Authorities due to budget restrictions. In this paper, a potential opportunity is explored with existing publicly available data related to this area. With the help of industry experts, an Agent-Based Model is created to emulate basic Children\u2019s Services operations and optimised to fit existing data using NSGA-III. With relatively close matches being achieved with sample authorities, this approach demonstrates promise in advancing analytics capabilities for Children\u2019s Services and practical solutions are discussed. With this presented work, it is shown that further expansion and exploration into real-world applications is warranted.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Luke White et al.",
      "keywords": "Computer science; Calibration; Genetic algorithm; Algorithm; Machine learning; Mathematics; Statistics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3199770",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4312620530",
      "doi": "10.1109/access.2022.3228772",
      "title": "Using the SOCIO Chatbot for UML Modeling: A Second Family of Experiments on Usability in Academic Settings",
      "abstract": "After improving the SOCIO chatbot prototype model, we wanted to know how/if its usability&#13;\\nhas changed. An evidence-based empirical evaluation of the usability of SOCIO V1 (updated version)&#13;\\nrequires an extensive verification of the experimental results. A family of experiments is a method of&#13;\\nverification whereby we can check if the experimental results are reproducible. Through comparison with the updated control tool Creately, we aimed to gain a better understanding of the usability of the collaborative modeling chatbot and how it could be improved based on experimental evidence of changes in terms of efficiency, effectiveness, satisfaction, and quality. A total of 87 students from three countries were recruited. We conducted a family of three experiments to compare the usability of SOCIO V1 and updated Creately in academic settings. Students appeared to be more satisfied with SOCIO V1, and SOCIO V1 scored better on completeness. There were no significant differences between the two tools regarding efficiency and quality. This study provides evidence on how to employ a family of experiments to improve chatbot usability and enrich knowledge on chatbot usability experimentation.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ranci Ren et al.",
      "keywords": "Chatbot; Usability; Computer science; Quality (philosophy); Human\u2013computer interaction; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3228772",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389428535",
      "doi": "10.1109/jbhi.2023.3340201",
      "title": "Label-Free Medical Image Quality Evaluation by Semantics-Aware Contrastive Learning in IoMT",
      "abstract": "With the rapid development of the Internet-of-Medical-Things (IoMT) in recent years, it has emerged as a promising solution to alleviate the workload of medical staff, particularly in the field of Medical Image Quality Assessment (MIQA). By deploying MIQA based on IoMT, it proves to be highly valuable in assisting the diagnosis and treatment of various types of medical images, such as fundus images, ultrasound images, and dermoscopic images. However, traditional MIQA models necessitate a substantial number of labeled medical images to be effective, which poses a challenge in acquiring a sufficient training dataset. To address this issue, we present a label-free MIQA model developed through a zero-shot learning approach. This paper introduces a Semantics-Aware Contrastive Learning (SCL) model that can effectively generalise quality assessment to diverse medical image types. The proposed method integrates features extracted from zero-shot learning, the spatial domain, and the frequency domain. Zero-shot learning is achieved through a tailored Contrastive Language-Image Pre-training (CLIP) model. Natural Scene Statistics (NSS) and patch-based features are extracted in the spatial domain, while frequency features are hierarchically extracted from both local and global levels. All of this information is utilised to derive a final quality score for a medical image. To ensure a comprehensive evaluation, we not only utilise two existing datasets, EyeQ and LiverQ, but also create a dataset specifically for skin image quality assessment. As a result, our SCL method undergoes extensive evaluation using all three medical image quality datasets, demonstrating its superiority over advanced models.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Dewei Yi et al.",
      "keywords": "Computer science; Artificial intelligence; Image quality; Semantics (computer science); The Internet; Medical imaging; Quality (philosophy); Domain (mathematical analysis); Machine learning; Computer vision; Image (mathematics); World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3340201",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394804914",
      "doi": "10.1109/access.2024.3388911",
      "title": "Interpretable Deep Learning for Neuroimaging-Based Diagnostic Classification",
      "abstract": "Deep neural networks (DNN) are increasingly being used in neuroimaging research for the diagnosis of brain disorders and understanding of human brain. Despite their impressive performance, their usage in medical applications will be limited unless there is more transparency on how these algorithms arrive at their decisions. We address this issue in the current report. A DNN classifier was trained to discriminate between healthy subjects and those with posttraumatic stress disorder (PTSD) using brain connectivity obtained from functional magnetic resonance imaging data. The classifier provided 90&#x0025; accuracy. Brain connectivity features important for classification were generated for a pool of test subjects and permutation testing was used to identify significantly discriminative connections. Such heatmaps of significant paths were generated from 10 different interpretability algorithms based on variants of layer-wise relevance and gradient attribution methods. Since different interpretability algorithms make different assumptions about the data and model, their explanations had both commonalities and differences. Therefore, we developed a consensus across interpretability methods, which aligned well with the existing knowledge about brain alterations underlying PTSD. The confident identification of more than 20 regions, acknowledged for their relevance to PTSD in prior studies, was achieved with a voting score exceeding 8 and a family-wise correction threshold below 0.05. Our work illustrates how robustness and physiological plausibility of explanations can be achieved in interpreting classifications obtained from DNNs in diagnostic neuroimaging applications by evaluating convergence across methods. This will be crucial for trust in AI-based medical diagnostics in the future.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Gopikrishna Deshpande et al.",
      "keywords": "Interpretability; Neuroimaging; Discriminative model; Computer science; Artificial intelligence; Machine learning; Salience (neuroscience); Robustness (evolution); Artificial neural network; Classifier (UML); Psychology; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3388911",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4205936917",
      "doi": "10.1109/access.2022.3142925",
      "title": "Join Classifier of Type and Index Mutation on Lung Cancer DNA Using Sequential Labeling Model",
      "abstract": "The sequential labeling model is commonly used for time series or sequence data where each instance label is classified using previous instance label. In this work, a sequential labeling model is proposed as a new approach to detect the type and index mutations simultaneously, using DNA sequences from lung cancer study cases. The methods used are One Dimensional Convolutional Neural Network (1D-CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Bidirectional Gated Recurrent Unit (Bi-GRU). Each nucleotide in the patient&#x2019;s DNA sequence is classified as either normal or with a certain type of mutation in which case, its index mutation is predicted. The mutation types detected are either substitution, insertion, deletion, or delins (deletion insertion) mutations. Based on the experiments that were conducted using <italic>EGFR</italic> gene, BiLSTM and Bi-GRU displayed better performance and were more stable than 1D-CNN. Further tests were carried out on the <italic>TP53</italic>, <italic>KRAS</italic>, <italic>CTNNB1</italic>, <italic>SMARCA4</italic>, <italic>CDKN2A</italic>, <italic>PTPRD</italic>, <italic>BRAF</italic>, <italic>ERBB2</italic>, and <italic>PTPRT</italic> gene. The proposed model reports F1-scores of 0.9596, and 0.9612 using Bi-GRU and BiLSTM, respectively. Based on the results the model can successfully detect the type and index mutations in the DNA sequence more accurately and faster without the need for other supporting data and tools, and does not require re-alignment to reference sequences. This will greatly facilitate the user in detecting type and index mutations faster by entering only the DNA sequence.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Untari Novia Wisesty et al.",
      "keywords": "KRAS; Computer science; Artificial intelligence; Mutation; Computational biology; Classifier (UML); Algorithm; Biology; Genetics; Gene",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3142925",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225700922",
      "doi": "10.1109/access.2022.3165208",
      "title": "Dementia Scale Score Classification Based on Daily Activities Using Multiple Sensors",
      "abstract": "Early detection of age-related disease symptoms in older people by the use of daily activity data is one of the central challenges of home sensor systems. This paper focuses on dementia scale classification from daily activity data collected using sensors that can be deployed in actual residential environments. Activity data collected by four sensors (a door sensor, human motion sensor, location sensor, and sleep sensor) were obtained by recording 56 older adults living in common residences. We analyzed the effects of different types of sensor data, such as time spent in an individual room according to human motion sensors, location in a facility, and sleep patterns, on dementia detection. We then developed a feature extraction method related to daily activity patterns based on a clustering algorithm and analyzed its effectiveness. In the experimental evaluation, we trained binary classification models to classify dementia scale scores based on the Mini-Mental State Examination (MMSE) from these datasets. The experimental results show that a maximum accuracy of 0.871 was obtained with a linear support vector machine (SVM) model by fusing the door, location, and sleep features and by clustering activity patterns using the X-means algorithm.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Akira Minamisawa et al.",
      "keywords": "Support vector machine; Dementia; Computer science; Activities of daily living; Cluster analysis; Feature extraction; Artificial intelligence; Scale (ratio); Activity recognition; Wireless sensor network; Statistical classification; Pattern recognition (psychology); Medicine; Disease; Geography",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3165208",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392694187",
      "doi": "10.1109/access.2024.3376379",
      "title": "XEmoAccent: Embracing Diversity in Cross-Accent Emotion Recognition Using Deep Learning",
      "abstract": "Speech is a powerful means to expressing thoughts, emotions, and perspectives. However, accurately determining the emotions conveyed through speech remains a challenging task. Existing manual methods for analyzing speech to recognize emotions are prone to errors, limiting our understanding and response to individuals&#x2019; emotional states. To address diverse accents, an automated system capable of real-time emotion prediction from human speech is needed. This paper introduces a speech emotion recognition (SER) system that leverages supervised learning techniques to tackle cross-accent diversity. Distinctively, the system extracts a comprehensive set of nine speech features&#x2014;Zero Crossing Rate, Mel Spectrum, Pitch, Root Mean Square values, Mel Frequency Cepstral Coefficients, chroma-stft, and three spectral features (Centroid, Contrast, and Roll-off) for refined speech signal processing and recognition. Seven machine learning models are employed, encompassing Random Forest, Logistic Regression, Decision Tree, Support Vector Machines, Gaussian Naive Bayes, K-Nearest Neighbors, ensemble learning, and four individual, hybrid deep learning models including Long short-term memory (LSTM) and 1-Dimensional Convolutional Neural Network (1D-CNN) with stratified cross-validation. Audio samples from diverse English regions are combined to train the models. The performance evaluation results of conventional machine learning and deep learning models indicate that the Random Forest-based feature selection model achieves the highest accuracy of up to 76&#x0025; among the conventional machine learning models. Simultaneously, the 1D-CNN model with stratified cross-validation reaches up to 99&#x0025; accuracy. The proposed framework enhances the cross-accent emotion recognition accuracy up to 86.3&#x0025;, 89.87&#x0025;, 90.27&#x0025;, and 84.96&#x0025; by margins of 14.71&#x0025;, 10.15&#x0025;, 9.6&#x0025;, and 16.52&#x0025; respectively.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Raheel Ahmad et al.",
      "keywords": "Computer science; Artificial intelligence; Speech recognition; Support vector machine; Random forest; Convolutional neural network; Naive Bayes classifier; Machine learning; Cross-validation; Deep learning; Mel-frequency cepstrum; Decision tree; Hidden Markov model; Pattern recognition (psychology); Feature extraction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3376379",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3041853361",
      "doi": "10.22489/cinc.2019.161",
      "title": "Machine Learning Algorithmic and System Level Considerations for Early Prediction of Sepsis",
      "abstract": "This study presents a machine learning (ML) model that predicts onset of sepsis earlier in time than what is possible using common severity scoring systems.Our study's focus is on building solutions that maximizes sepsis prediction, is real-world implementable and usable by care providers particularly in developing countries like India.We have selected features based on the observation that patient vitals are available on an hourly basis, whereas lab results if available are less frequent.To capture the time series nature of the data, we trained the model using long short term memory (LSTM), a version of recurrent neural network (RNN) architecture.To capture locale specific pathology baseline, we have engineered features using two methods.We define a minimum & maximum value for vitals and lab tests and normalize the incoming data against this min-max value.Secondly, to leverage sparsely available lab data that signal increased sepsis risk, we define a synthetic \"risk\" feature.This risk feature is assigned a higher score when certain lab values are available and exceed a threshold.Our solution achieved an official utility score of 0.179 on the full test under the team name LDBR.Finally, we present practical considerations we discovered from our interactions with local hospitals and health-care providers.",
      "year": "2019",
      "journal": "Computing in cardiology",
      "authors": "Lakshman Narayanaswamy et al.",
      "keywords": "Computer science; Machine learning; Artificial intelligence; Sepsis; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.22489/cinc.2019.161",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323020852",
      "doi": "10.1109/access.2023.3249786",
      "title": "Toward a Unified mHealth Platform: A Survey of Current User Challenges and Expectations",
      "abstract": "Mobile health (mHealth) applications have become ubiquitous and have enabled self-monitoring to help provide better health outcomes. However, the wide availability of mHealth apps introduces new challenges when users need to download and use several apps. While past app evaluations have highlighted many issues, the surrounding work is limited. This study aims to analyse the current user challenges and expectations from future mHealth apps. This information is important to inform and guide the design of better and more attractive mHealth platforms of the future. For our empirical investigation of user feedback, we designed an anonymous online survey using key dimensions from the Mobile Application Rating Scale (MARS), the Technology Acceptance Model (TAM) and the Value Proposition Canvas. Our survey was distributed via online channels such as Twitter and LinkedIn, and we received 70 valid responses that indicated challenges such as functional overlaps between different apps, unnecessary features, and poor customizability. Similarly, most respondents expressed their preference for a single platform to manage their health. These challenges suggest the need to design more capable unified mHealth platforms that can be tailored to a user&#x2019;s needs. While the development of such platforms raise valid questions around the increase in software complexity and privacy concerns around user data, an open design can address these concerns and offer a better experience. Overall, these findings indicate the need for more research into mHealth app design strategies where the regular use of more than one app must be considered to create better, more engaging mHealth apps.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ben Joseph Philip et al.",
      "keywords": "mHealth; Computer science; Current (fluid); Human\u2013computer interaction; Engineering; Health care; Electrical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3249786",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226257137",
      "doi": "10.1109/access.2022.3159700",
      "title": "On the Dynamics and Feasibility of Transferred Inference for Diagnosis of Invasive Ductal Carcinoma: A Perspective",
      "abstract": "It is generally noticed that increasing the number of convolutional layers in generic image classification procedures proves to be detrimental to model performance in terms of validation accuracy and loss. Apart from vanilla CNNs, we have state-of-the-art (SOTA) architectures such as ResNet50 (and its variants) which show that through the use of skip-connections, higher performance metrics are attainable through deeper architectures. However, most evaluative metrics converge on a log scale as we go deeper with diminishing gradient of the metrics&#x2019; curves. Given these two contrasting speculations, in this paper, we implement various vanilla and SOTA CNNs for the diagnosis of one of the most common forms of breast cancer - invasive ductal carcinoma (IDC) - to examine and understand the feasibility of implementation of SOTA CNNs through transferred weights when juxtaposed with vanilla CNNs (and LeNet-5) of varying configurations in terms of their performance metrics and other parameters. In this paper, we solve the dual-objective of studying behavioural aspects of avant-garde CNN models (more specifically, VGG16, VGG19, ResNet50, ResNet50V2, MobileNetV2, and DenseNet121) and proper diagnosis of IDC through intermediate neural activations to critically evaluate and theorize the performance of different models. We notice that among all the models, only VGG16, VGG19, LeNet-5 and a selected vanilla CNN through an optimization procedure were the ones to attain the best metrics, shared amongst them.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Harshvardhan GM et al.",
      "keywords": "Perspective (graphical); Computer science; Inference; Dynamics (music); Invasive ductal carcinoma; Artificial intelligence; Medicine; Internal medicine; Cancer; Breast cancer; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3159700",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2944835936",
      "doi": "10.1109/access.2019.2917922",
      "title": "An Annotation Model on End-to-End Chest Radiology Reports",
      "abstract": "Annotating radiographic images with tags is an indispensable preliminary work in&#13;\\ncomputer-aided medical research, which requires professional physician participated in and is quite timeconsuming. Therefore, how to automatically annotate radiographic images has become the focus of&#13;\\nresearchers. However, image report texts, containing crucial radiologic information, have not to be given&#13;\\nenough attention for images annotation. In this paper, we propose a neural sequence-to-sequence annotation&#13;\\nmodel. Especially, in the decoding phase, a probability is first learned to copy existing words from report texts&#13;\\nor generate new words. Second, to incorporate the patient\u2019s background information, \u2018\u2018indication\u2019\u2019 section&#13;\\nof the report is encoded as a sentence embedding, and concatenated with the decoder neural unit input.&#13;\\nWhat\u2019s more, we devise a more reasonable evaluation metric for this annotation task, aiming at assessing the&#13;\\nimportance of different words. On the Open-i dataset, our model outperforms existing non-neural and neural&#13;\\nbaselines under the BLEU-4 metrics. To our best knowledge, we are the first to use sequence-to-sequence&#13;\\nmodel for radiographic image annotation.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Xin Huang et al.",
      "keywords": "End-to-end principle; Computer science; Annotation; Radiology; End of history; Medicine; Artificial intelligence",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2917922",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323338561",
      "doi": "10.1109/tnsre.2023.3253683",
      "title": "Similarity Function for One-Shot Learning to Enhance the Flexibility of Myoelectric Interfaces",
      "abstract": "$\\textit {Objective:}$ This study aims to develop a flexible myoelectric pattern recognition (MPR) method based on one-shot learning, which enables convenient switching across different usage scenarios, thereby reducing the re-training burden. $\\textit {Methods}$ : First, a one-shot learning model based on a Siamese neural network was constructed to assess the similarity for any given sample pair. In a new scenario involving a new set of gestural categories and/or a new user, just one sample of each category was required to constitute a support set. This enabled the quick deployment of the classifier suitable for the new scenario, which decided for any unknown query sample by selecting the category whose sample in the support set was quantified to be the most like the query sample. The effectiveness of the proposed method was evaluated by experiments conducting MPR across diverse scenarios. Results: The proposed method achieved high recognition accuracy of over 89% under the cross-scenario conditions, and it significantly outperformed other common one-shot learning methods and conventional MPR methods ( ${p} < 0.01$ ). $\\textit {Conclusion}$ : This study demonstrates the feasibility of applying one-shot learning to rapidly deploy myoelectric pattern classifiers in response to scenario change. It provides a valuable way of improving the flexibility of myoelectric interfaces toward intelligent gestural control with extensive applications in medical, industrial, and consumer electronics.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Xiang Wang et al.",
      "keywords": "Computer science; Flexibility (engineering); Sample (material); Classifier (UML); Artificial intelligence; Similarity (geometry); Set (abstract data type); Artificial neural network; Machine learning; Pattern recognition (psychology); Data mining; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3253683",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390357700",
      "doi": "10.1109/access.2023.3347410",
      "title": "DMRNet Based Tuberculosis Screening With Cough Sound",
      "abstract": "Tuberculosis is the leading cause of death due to a single infection prior to the COVID-19 pandemic. Screening of tuberculosis patients in a large population is of paramount importance for disease treatment and control, especially with an economical, accurate, and easy-to-operate method. Based on cough sounds, we proposed DMRNet to distinguish between patients with tuberculosis, other respiratory diseases, and healthy individuals. DMRNet comprises four convolutional blocks and six identification blocks and incorporates dynamic convolution into the first three convolutional blocks to promote feature extraction. After the second and third dynamic convolutions, a polarized self-attention mechanism was added to reduce the information loss caused by the dimensionality reduction. Finally, a multihead self-attention layer is added to the fourth convolutional block and the last three identification blocks to enhance the aggregation of global information. Using a dataset with 1323 cough sound fragments, the results achieved the accuracy, sensitivity, and specificity of tuberculosis screening were 94.32&#x0025;, 97.73&#x0025;, and 99.43&#x0025;, respectively. Compared with reported studies, the proposed model demonstrated better accuracy and reliability. Cough sound-based DMRNet analysis is a promising method for tuberculosis screening, especially in densely populated areas. Owing to its convenience, low equipment requirements, and low cost, it is expected to become an effective tool for community tuberculosis screening.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Wenlong Xu et al.",
      "keywords": "Tuberculosis; Medicine; Computer science; Population; Pathology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3347410",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4388624303",
      "doi": "10.1109/tnsre.2023.3332467",
      "title": "Quantitative Identification of ADHD Tendency in Children With Immersive Fingertip Force Control Tasks",
      "abstract": "Attention-deficit/hyperactivity disorder (ADHD) is a prevalent neurodevelopmental disorder that affects children. However, the traditional scale-based diagnosis methods rely more on subjective experiences, leading to a demand of objective biomarkers and quantified diagnostic methods. This study proposes a quantitative approach for identifying ADHD tendency based on fingertip pressing force control paradigm with immersive visual feedback. By extracting nine behavioral features from reaction time and dynamic force fluctuation features with high temporal and amplitude resolution, the proposed method can effectively capture the continuous changes in attention levels for ADHD diagnosis. The extracted features were analyzed using independent sample t-test and Pearson correlation to determine their association with ADHD-RS scale scores. Results showed that 12 statistical indicators were effective for distinguishing ADHD children from typically developed children, and several features of force control ability were also associated with core ADHD symptoms. A support vector machine (SVM) based classifier is trained for ADHD diagnosis and achieved an accuracy of 78.5%. This work provides an objective and quantitative approach for identifying ADHD tendency within a short testing time, and reveals the inherent correlation between the attention levels and the extracted features of reaction time and force fluctuation dynamics.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Zhihao Zhang et al.",
      "keywords": "Attention deficit hyperactivity disorder; Correlation; Support vector machine; Artificial intelligence; Computer science; Identification (biology); Psychology; Machine learning; Pattern recognition (psychology); Clinical psychology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3332467",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387587629",
      "doi": "10.1109/access.2023.3324061",
      "title": "Parallel Metaheuristic Algorithms for Solving Imbalanced Data Classification Problems",
      "abstract": "An imbalanced classification problem is one in which the distribution of instances across defined classes is uneven or biased in one direction or another. In data mining, the probabilistic neural network (PNN) classifier is a well-known technology that has been successfully used to solve a variety of classification difficulties. On the other hand, metaheuristic optimization approaches offer an excellent means by which to deal with this problem. Therefore, this work combines two metaheuristic algorithms&#x2013;the Ali Baba and the Forty Thieves (AFT) algorithm and the Water Strider Algorithm (WSA)&#x2013;in order to alter the weights of a PNN classifier for imbalanced datasets. This article introduces a self-contained multiple-search approach for parallel metaheuristics that may be used in a variety of situations. Most implementations begin many search processes, all of which utilize the same search algorithm, with a set of starting parameters that are all generated separately. Most implementations pick a processor to collect data and verify the data for compliance with some stopping criteria, with the latter being the default. In the proposed AFT-WSA parallel method, the two algorithms begin simultaneously, and the fitness value is communicated in each iteration to find the best classification accuracy in the smallest number of iterations, thereby allowing the weight of the PNN classifier to be adjusted. In this study, ten imbalanced public datasets were used to test the performance of the proposed approach in terms of classification accuracy, standard deviation, and F-measure.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Mohammed Alweshah et al.",
      "keywords": "Computer science; Metaheuristic; Classifier (UML); Algorithm; Artificial neural network; Implementation; Machine learning; Artificial intelligence; Probabilistic logic; Data classification; Data mining; Statistical classification",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3324061",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2968159874",
      "doi": "10.1109/access.2019.2934490",
      "title": "Inferring Cortical Connectivity From ECoG Signals Using Graph Signal Processing",
      "abstract": "A novel method to characterize connectivity between sites in the cerebral cortex of primates is proposed in this paper. Connectivity graphs for two macaque monkeys are inferred from Electrocorticographic (ECoG) activity recorded while the animals were alert. The locations of ECoG electrodes are considered as nodes of the graph, the coefficients of the auto-regressive (AR) representation of the signals measured at each node are considered as the signal on the graph and the connectivity strengths between the nodes are considered as the edges of the graph. Maximization of the graph smoothness defined from the Laplacian quadratic form is used to infer the connectivity map (adjacency matrix of the graph). The cortical evoked potential (CEP) map was obtained by stimulating different electrodes and recording the evoked potentials at the other electrodes. The maps obtained by the graph inference and the traditional method of spectral coherence are compared with the CEP map. The results show that the proposed method provides a description of cortical connectivity that is more similar to the stimulation-based measures than spectral coherence. The results are also tested by the surrogate map analysis in which the CEP map is randomly permuted and the distribution of the errors is obtained. It is shown that error between the two maps is comfortably outside the surrogate map error distribution. This indicates that the similarity between the map calculated by the graph inference and the CEP map is statistically significant.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Siddhi Tavildar et al.",
      "keywords": "Adjacency matrix; Computer science; Pattern recognition (psychology); Graph; Laplacian matrix; Artificial intelligence; Brain\u2013computer interface; Algorithm; Electroencephalography; Theoretical computer science; Neuroscience",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2934490",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285049515",
      "doi": "10.1109/tem.2022.3184871",
      "title": "The Corruption of Project Governance Through Normalization of Deviance",
      "abstract": "Organizational mistakes and accidents have a long history in practice and have been studied extensively in the engineering and organizational literature. One of the primary causes of persistent organizational error is the existence of deviance; i.e., behavior violating organizational norms. We examined the behaviors and motivations of project team members in situations where deviant behaviors had been accepted and normalized as part of project operations. We used NVivo content analysis to classify the narratives of 52 project professionals as they related to normalization of deviance (NoD) situations, their perceived causes, and subsequent outcomes for their organizations. Our findings suggest that NoD occurs in three primary dimensions: project processes, relationships, and outcomes. We discuss the implications of these findings for project organization performance improvement and avoiding NoD situations.",
      "year": "2022",
      "journal": "IEEE Transactions on Engineering Management",
      "authors": "Kate Davis et al.",
      "keywords": "Deviance (statistics); Corporate governance; Normalization (sociology); Project management; Psychology; Knowledge management; Social psychology; Process management; Public relations; Political science; Computer science; Sociology; Engineering; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tem.2022.3184871",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3150344390",
      "doi": "10.1109/access.2021.3071118",
      "title": "Diagnostic Biomarker Exploration of Autistic Patients With Different Ages and Different Verbal Intelligence Quotients Based on Random Forest Model",
      "abstract": "As a neurodevelopmental disorder with complex pathogenesis, the existing diagnostic methods of autism still only rely on the scale method. In recent years, there have been some methods using machine learning to classify Autism Spectrum Disorders (ASD), and achieved good accuracy. However, the generalization of these models is poor, and the conclusions are inconsistent. The main reason is that most of them use single site dataset or private dataset for analysis, which will lead to one-sided conclusion. They did not analyze the phenotypic features of the dataset, such as handedness, gender, and age. In order to make the obtained brain diagnostic biomarkers of ASD more universal and generalized, instead of analyzing the dataset from a single site, the whole dataset is divided into subgroups according to age and Verbal Intelligence Quotient (VIQ), and then each subgroup is classified and analyzed by Random Forest (RF) model. The experimental results show that if all male subjects are used for classification, the accuracy of classification can only reach about 55&#x0025;. By using the proposed grouping method and RF model, the classification accuracy for different subgroups will be improved by 3&#x0025; &#x007E; 17&#x0025;. Through the analysis of the importance and difference of the features in each subgroup, we can find that the features obtained in the above experiments are closely related to the functions of speech, emotion, auditory and visual information processing. This may partly explain why ASD patients have speech, social disorder, repetitive behavior and narrow interests. The classification methods proposed and diagnostic biomarkers obtained in this paper may provide some reference for the clinical diagnosis and early treatment of ASD.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Fengkai Ke et al.",
      "keywords": "Autism spectrum disorder; Random forest; Generalization; Artificial intelligence; Computer science; Autism; Intelligence quotient; Machine learning; Neurodevelopmental disorder; Pattern recognition (psychology); Cognitive psychology; Psychology; Natural language processing; Developmental psychology; Mathematics; Cognition; Psychiatry",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3071118",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312597830",
      "doi": "10.1109/tnsre.2022.3228073",
      "title": "Deep Neural Network-Based Video Processing to Obtain Dual-Task Upper-Extremity Motor Performance Toward Assessment of Cognitive and Motor Function",
      "abstract": "Dementia is an increasing global health challenge. Motoric Cognitive Risk Syndrome (MCR) is a predementia stage that can be used to predict future occurrence of dementia. Traditionally, gait speed and subjective memory complaints are used to identify older adults with MCR. Our previous studies indicated that dual-task upper-extremity motor performance (DTUEMP) quantified by a single wrist-worn sensor was correlated with both motor and cognitive function. Therefore, the DTUEMP had a potential to be used in the diagnosis of MCR. Instead of using inertial sensors to capture kinematic data of upper-extremity movements, here we proposed a deep neural network-based video processing model to obtain DTUEMP metrics from a 20-second repetitive elbow flexion-extension test under dual-task condition. In details, we used a deep residual neural network to obtain joint coordinate set of the elbow and wrist in each frame, and then used optical flow method to correct the joint coordinates generated by the neural network. The coordinate sets of all frames in a video recording were used to generate an angle sequence which represents rotation angle of the line between the wrist and elbow. Then, the DTUEMP metrics (the mean and SD of flexion and extension phase) were derived from angle sequences. Multi-task learning (MTL) was used to assess cognitive and motor function represented by MMSE and TUG scores based on DTUEMP metrics, with single-task learning (STL) linear model as a benchmark. The results showed a good agreement (r $\\ge0.80$ and ICC $\\ge0.58$ ) between the derived DTUEMP metrics from our proposed model and the ones from clinically validated sensor processing model. We also found that there were correlations with statistical significance (p < 0.05) between some of video-derived DTUEMP metrics (i.e. the mean of flexion time and extension time) and clinical cognitive scale (Mini-Mental State Examination, MMSE). Additionally, some of video-derived DTUEMP metrics (i.e. the mean and standard deviation of flexion time and extension time) were also associated with the scores of timed-up and go (TUG) which is a gold standard to measure functional mobility. Mean absolute percentage error (MAPE) of MTL surpassed that of STL (For MMSE, MTL: 18.63%, STL: 23.18%. For TUG, MTL: 17.88%, STL: 22.53%). The experiments with different light conditions and shot angles verified the robustness of our proposed video processing model to extract DTUEMP metrics in potentially various home environments (r $\\ge0.58$ and ICC $\\ge0.71$ ). This study shows possibility of replacing sensor processing model with video processing model for analyzing the DTUEMP and a promising future to adjuvant diagnosis of MCR via a mobile platform.",
      "year": "2022",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Zilong Liu et al.",
      "keywords": "Cognition; Dual (grammatical number); Task (project management); Motor function; Computer science; Artificial neural network; Function (biology); Dual function; Physical medicine and rehabilitation; Artificial intelligence; Psychology; Neuroscience; Medicine; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2022.3228073",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4390970349",
      "doi": "10.1109/jtehm.2024.3355432",
      "title": "NeuroDiag: Software for Automated Diagnosis of Parkinson\u2019s Disease Using Handwriting",
      "abstract": "In this work, we tested the reliability of NeuroDiag in differentiating between PPD and AMC for real-time applications. The results show that NeuroDiag has the potential to be used to assist neurologists and for telehealth applications. Clinical and Translational Impact Statement - This pre-clinical study shows the feasibility of developing a community-wide screening program for Parkinson's disease using automated handwriting analysis software, NeuroDiag.",
      "year": "2024",
      "journal": "IEEE Journal of Translational Engineering in Health and Medicine",
      "authors": "Quoc Cuong Ngo et al.",
      "keywords": "Handwriting; Software; Computer science; Parkinson's disease; Artificial intelligence; Disease; Pattern recognition (psychology); Natural language processing; Medicine; Pathology; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jtehm.2024.3355432",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2788019842",
      "doi": "10.1109/tnse.2018.2878487",
      "title": "Modeling Communication Processes in the Human Connectome through Cooperative Learning",
      "abstract": "Communication processes within the human brain at different cognitive states are neither well understood nor completely characterized. We assess communication processes in the human connectome using ant colony-inspired cooperative learning algorithm, starting from a source with no a priori information about the network topology, and cooperatively searching for the target through a pheromone-inspired model. This framework relies on two parameters, namely pheromone perception and edge perception, to define the cognizance and subsequent behaviour of the ants on the network and, overall, the communication processes happening between source and target nodes. Simulations obtained through different configurations allow the identification of path-ensembles that are involved in the communication between node pairs. These path-ensembles may contain different number of paths depending on the perception parameters and the node pair. In order to assess the different communication regimes displayed on the simulations and their associations with functional connectivity, we introduce two network measurements, effective path-length and arrival rate. These communication features are tested as individual as well as combined predictors of functional connectivity during different tasks. Finally, different communication regimes are found in different specialized functional networks. Overall, this framework may be used as a test-bed for different communication regimes on top of an underlaying topology.",
      "year": "2018",
      "journal": "IEEE Transactions on Network Science and Engineering",
      "authors": "Uttara Tipnis et al.",
      "keywords": "Computer science; Node (physics); A priori and a posteriori; Network topology; Path (computing); Perception; Topology (electrical circuits); Telecommunications network; Enhanced Data Rates for GSM Evolution; Distributed computing; Artificial intelligence; Computer network; Mathematics; Psychology; Engineering; Neuroscience",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tnse.2018.2878487",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388544069",
      "doi": "10.1109/access.2023.3331762",
      "title": "Analysis of Time Series Data Generated From the Internet of Things Using Deep Learning Models",
      "abstract": "The ever-increasing widespread use of the Internet of Things and its applications has generated massive amounts of data. IoT sensor-generated datasets typically have a time-series structure and relational metadata to describe them. Time series data are typically data that have timestamps and can be obtained from sensors and IoT devices. Data prediction is required to maximize the potential of IoT-generated data, and anomaly detection and correction are needed to preserve data quality and integrity. Traditional machine learning models are incapable of analyzing the gigantic amounts of IoT-generated data. On the other hand, deep learning can properly analyze large data volumes, leading to increased use in the IoT domain. This research has examined the use of deep learning models for prediction, anomaly detection, and correction of data generated by IoT devices. The study found that deep learning is widely used in different fields today to analyze IoT-generated data. The research also outlines some challenges being faced while using deep learning models for IoT data analysis. More research is suggested in this study to expose more challenges and tackle the current challenges to achieve better IoT data analysis using deep learning.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Polycarp Shizawaliyi Yakoi et al.",
      "keywords": "Computer science; Deep learning; Metadata; Timestamp; Anomaly detection; Artificial intelligence; Internet of Things; Time series; Machine learning; Data modeling; Data mining; Data science; Real-time computing; Database; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3331762",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3010396365",
      "doi": "10.1109/access.2020.2978079",
      "title": "A Neural Network Architecture for Information Extraction in Chinese Drug Package Insert",
      "abstract": "There is a lot of useful information in the medical photocopying materials. The correct extraction and identification of this information are of great significance for the construction of digital medical. In most previous research, researchers have been working on clinical data, and there is little discussion on the extraction of information from Chinese drug package insert. To settle this issue, a neural network model is proposed in this paper. This model uses OCR's post-document as the data source, which can not only correct these data but also classify sentences. It is mainly composed of three layers: the first layer is employed to correct the data using the language model and the seq2seq model, the second layer is defined by convolution neural network (CNN) aiming to enrich the processed sentences, and another layer is used to determine the label of each sentence. The quantitative experimental results verify the feasibility and validity of the proposed model. In addition, the comparing experiments demonstrate that our method outperforms the regular rule-based approaches, which indicated 4%-6% higher in F1 score.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ri\u2010Gui Zhou et al.",
      "keywords": "Computer science; Sentence; Artificial neural network; Convolution (computer science); Identification (biology); Layer (electronics); Information extraction; Artificial intelligence; Natural language processing; Convolutional neural network; Data mining; Feature extraction; Pattern recognition (psychology)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2978079",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4221029388",
      "doi": "10.1109/access.2022.3162272",
      "title": "Universal Convolutional Neural Network for Histology-Independent Analysis of Collagen Fiber Organization in Scar Tissue",
      "abstract": "Histological examination of collagen fiber organization is essential for pathologists to observe the wound healing process. A convolutional neural network (CNN) can be utilized to visually analyze collagen fibers during tissue remodeling in histology images. In this study, a universal CNN (UCNN) independent of the histological staining process is proposed to classify the histology images of burn-induced scar tissues and characterize collagen fiber organization. Normal and scar tissues obtained from an in vivo rodent model are stained using Masson&#x2019;s Trichrome (MT) and Hematoxylin &#x0026; Eosin (H&#x0026;E). The proposed universal model is trained using both MT- and H&#x0026;E-stained histological image datasets over multiple scales with color augmentation, and classification accuracies of up to 98&#x0025; and 97&#x0025; are achieved for the MT- and H&#x0026;E-stained image datasets, respectively. Regardless of the histological staining process used, the collagen characteristics are visualized by determining the density and directional variance of the normal and scar tissues by using the features extracted with the proposed universal model. Statistical analysis results demonstrated clear differences between scar and normal tissues in terms of collagen fiber organization. The proposed UCNN model can contribute to the development of an intelligent and efficient method that pathologists can use to rapidly evaluate wound healing and tissue remodeling.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Thi Tram Anh Pham et al.",
      "keywords": "Histology; Computer science; Collagen fiber; Convolutional neural network; Fiber; Artificial intelligence; Biomedical engineering; Materials science; Pathology; Composite material; Anatomy; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3162272",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389459395",
      "doi": "10.1109/jsen.2023.3334364",
      "title": "First Demonstration of GaN HEMT-Based Handheld System for Noninvasive Detection of Traumatic Brain Injury Using Saliva",
      "abstract": "Traumatic brain injury (TBI) is an insult to the brain caused by an external mechanical force that is neither congenital nor degenerative leading to morbidity and mortality among people of various age groups globally.The work reports design, development, and validation of novel GaN HEMT on Si-based handheld system for noninvasive detection of food and drug administration (FDA)-approved TBI biomarkers UCH-L1 and GFAP in clinically relevant concentration ranges.The developed system can detect and differentiate TBI biomarkers in saliva in almost imperceptible amount of pg/mL using specific conjugation of TBI antibody and target analyte over biofunctionalized chips.The platform offers a peak sensitivity of 17.42 \u00b5A/pg/mL with high resolution and a pre-eminent selectivity toward target TBI biomarkers.The system is portable, easy to handle, ultrasensitive with volant response time of less than 5 s, and compact with a potential for point-of-care applications.It can be utilized for clinical analysis and on-field application areas for TBI diagnosis and prognosis.The system can be imperative in early medical diagnosis, patient management, and decision-making for computed tomography (CT) or magnetic resonance imaging (MRI).To the best of our knowledge, this is the first-time reporting of a label-free noninvasive TBI detection system based on GaN HEMT on Si.",
      "year": "2023",
      "journal": "IEEE Sensors Journal",
      "authors": "Rajiv Ranjan Thakur et al.",
      "keywords": "High-electron-mobility transistor; Mobile device; Saliva; Optoelectronics; Computer science; Materials science; Embedded system; Biomedical engineering; Medicine; Engineering; Electrical engineering; Transistor; Internal medicine; Operating system; Voltage",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jsen.2023.3334364",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4388430775",
      "doi": "10.1109/ojemb.2023.3330290",
      "title": "Printed Strain Sensors for Motion Recognition: A Review of Materials, Fabrication Methods, and Machine Learning Algorithms",
      "abstract": "Recent studies in functional nanomaterials with advanced macro, micro, and nano-scale structures have yielded substantial improvements in human-interfaced strain sensors for motion and gesture recognition. Furthermore, fundamental advances in nanomaterial printing have been developed and leveraged to translate these materials and mechanical innovations into practical applications. Significant progress in machine learning for human-interfaced strain sensing has unlocked numerous opportunities to improve lives and the human experience through healthcare innovations, sports performance monitoring, and human-machine interfaces. However, several key challenges still must be overcome if strain sensors can become ubiquitous tools for human motion recognition. This review begins with a summary of the critical strain-sensing mechanisms employed today and how recent works have sought to push their boundaries. It then proceeds to cover the primary functional materials used in wearable strain sensors from a performance and printability perspective. Next is a review of recent advances in nanomaterial printing to produce the complex structures necessary for functional devices. Next, we summarize machine learning approaches for human gesture recognition and the myriad applications and use cases for human-interfaced strain sensors. Finally, it concludes with a discussion of challenges and opportunities for future research in the field.",
      "year": "2023",
      "journal": "IEEE Open Journal of Engineering in Medicine and Biology",
      "authors": "Nathan Zavanelli et al.",
      "keywords": "Fabrication; Motion (physics); Computer science; Motion sensors; Artificial intelligence; Algorithm; Machine learning; Computer vision",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/ojemb.2023.3330290",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392405523",
      "doi": "10.1109/access.2024.3373265",
      "title": "A Review of the Insider Threat, a Practitioner Perspective Within the U.K. Financial Services",
      "abstract": "The insider threat within organisational cybersecurity continues to be of great concern globally. The current insider threat detection strategies are acknowledged as ineffective, evidenced by the increased reported events in high-profile insider threats and cyber data loss cases borne from insider and privilege misuse. The impact of insider incidents on Financial Service (FS) organisations is vast, operationally disruptive, and costly from a regulatory, financial, and reputational perspective. Many United Kingdom (UK) FS organisations have invested in insider risk programmes, but there is no sign of the insider threat diminishing. This paper will address the following research questions: (1) What factors influence employees to become malicious insider threats and apply this to employees working within the UK? (2) What preventative measures could be effectively operationalised within UK FS organisations to prevent malicious insider attacks? A literature review was conducted, reviewing 54 articles in peer-reviewed journals. Additional and relevant articles were incorporated to enrich the review, further substantiating the academic currency and context of the study. The review reveals five primary emerging insider threat themes, subsequently discussed and including behavioural indicators, information security behaviours, technical controls, insider threat strategies, and regulation. Throughout the literature review, one primary challenge highlighted the lack of articles published concerning the FS industry; however, the studies reviewed were relevant, appropriate, and applied across this review. Furthermore, the review also considers outcomes from a practitioner\u2019s perspective, offering insights into the limitations of insider threat approaches and strategies and offering potential recommendations.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Findlay Whitelaw et al.",
      "keywords": "Perspective (graphical); Insider threat; Insider; Business; Financial services; Computer security; Finance; Computer science; Political science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3373265",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3216280545",
      "doi": "10.1109/access.2021.3131517",
      "title": "Real, Forged or Deep Fake? Enabling the Ground Truth on the Internet",
      "abstract": "The proliferation of smartphones and mobile communication has enabled users to capture images or videos and share them immediately on social networking and messaging platforms. Unfortunately, these platforms are also used to manipulate the masses by performing social engineering attacks by sharing fabricated images (or videos). These attacks cause public shame, ethnic violence and claim lives. With the rise of advanced image processing tools, the deep fakes are automated, and their implications are boundless. In this article, we discuss different types of modification of images/videos and survey the corresponding methods and tools. We also highlight the ongoing efforts to detect fake images and videos using advanced machine learning tools and fact-checking. Along with these tools, we also need different complementary approaches discouraging the production and propagation of manipulative forged images and videos on the Internet. This paper further emphasizes that we desperately need socio-technological solutions that empower end-users with the right tools to make an informed moral decision while producing, uploading, and sharing media. Finally, supporting this, we discuss a holistic blockchain-based solution.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Mohammad A. Hoque et al.",
      "keywords": "Upload; Computer science; The Internet; Social media; Shame; Cybercrime; Internet privacy; Mobile device; Adversarial system; Cyberspace; Deep learning; World Wide Web; Computer security; Human\u2013computer interaction; Artificial intelligence; Multimedia",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3131517",
      "cited_by_count": 12,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4385757396",
      "doi": "10.1109/jbhi.2023.3304369",
      "title": "An Online Attachment Style Recognition System Based on Voice and Machine Learning",
      "abstract": "Attachment styles are known to have significant associations with mental and physical health. Specifically, insecure attachment leads individuals to higher risk of suffering from mental disorders and chronic diseases. The aim of this study is to develop an attachment recognition model that can distinguish between secure and insecure attachment styles from voice recordings, exploring the importance of acoustic features while also evaluating gender differences. A total of 199 participants recorded their responses to four open questions intended to trigger their attachment system using a web-based interrogation system. The recordings were processed to obtain the standard acoustic feature set eGeMAPS, and recursive feature elimination was applied to select the relevant features. Different supervised machine learning models were trained to recognize attachment styles using both gender-dependent and gender-independent approaches. The gender-independent model achieved a test accuracy of 58.88%, whereas the gender-dependent models obtained 63.88% and 83.63% test accuracy for women and men respectively, indicating a strong influence of gender on attachment style recognition and the need to consider them separately in further studies. These results also demonstrate the potential of acoustic properties for remote assessment of attachment style, enabling fast and objective identification of this health risk factor, and thus supporting the implementation of large-scale mobile screening systems.",
      "year": "2023",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Luc\u00eda G\u00f3mez-Zaragoz\u00e1 et al.",
      "keywords": "Attachment theory; Machine learning; Computer science; Identification (biology); Style (visual arts); Set (abstract data type); Feature extraction; Mental health; Test (biology); Scale (ratio); Feature (linguistics); Artificial intelligence; Psychology; Developmental psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2023.3304369",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3206262303",
      "doi": "10.1109/access.2021.3121288",
      "title": "Development of Eye Blink Rate Level Classification System Utilizing Sitting Postural Behavior Data",
      "abstract": "The prevalence of dry eye syndrome (DES) has rapidly increased in recent years, negatively affecting the eye health of many office workers worldwide. Although low eye blink rate (EBR) has been pointed out as one of the main risk factors for DES, it is difficult for office workers to continuously monitor and increase their own involuntary blinking, especially when they are focused on the primary work task. Thus, as an effort to help office workers correct their low EBR, the current study developed a real-time EBR level classification system utilizing sitting postural behavior data. A total of twenty participants performed typical computer tasks on a sensor-embedded chair. The participants&#x2019; eye blinking and postural behavior data were collected to develop the EBR level classification system with a random forest algorithm. After evaluating the system performance, the relationships between EBR and postural behaviors were empirically examined to help understand how the system worked for EBR level classification. As a result, the developed system showed high classification performance overall; and compared with high EBR condition, low EBR condition was related to less overall postural variability and greater extent of forward bending posture. The real-time EBR level classification system is expected to contribute to preventing/relieving DES and thereby enhancing the eye health of office workers.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Haehyun Lee et al.",
      "keywords": "Sitting; Task (project management); Physical medicine and rehabilitation; Office workers; Computer science; Physical therapy; Medicine; Simulation; Engineering; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3121288",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392309252",
      "doi": "10.1109/access.2024.3371517",
      "title": "PPGCN: Phase-Aligned Periodic Graph Convolutional Network for Dual-Task-Based Cognitive Impairment Detection",
      "abstract": "Early detection methods for cognitive impairment are crucial for its effective treatment. Dual-task-based pipelines that rely on skeleton sequences can detect cognitive impairment reliably. Although such pipelines achieve state-of-the-art results by analyzing skeleton sequences of periodic stepping motion, we propose that their performance can be improved by decomposing the skeleton sequence into representative phase-aligned periods and focusing on them instead of the entire sequence. We present the phase-aligned periodic graph convolutional network, which is capable of processing phase-aligned periodic skeleton sequences. We trained it with a cross-modality feature fusion loss using a representative dataset of 392 samples annotated by medical professionals. As part of a dual-task cognitive impairment detection pipeline that relies on two-dimensional skeleton sequences extracted from RGB images to improve its general usability, our proposed method outperformed existing approaches and achieved a mean sensitivity of 0.9231 and specificity of 0.9398 in a four-fold cross-validation setup.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "\u00c1kos God\u00f3 et al.",
      "keywords": "Computer science; Artificial intelligence; Graph; Pattern recognition (psychology); Convolutional neural network; Cognitive impairment; Pipeline (software); Feature extraction; Task (project management); Skeleton (computer programming); Cognition; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3371517",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4393972842",
      "doi": "10.1109/access.2024.3385668",
      "title": "X2V: 3D Organ Volume Reconstruction From a Planar X-Ray Image With Neural Implicit Methods",
      "abstract": "In this work, an innovative approach is proposed for three-dimensional (3D) organ volume reconstruction from a single planar X-ray, namely X2V network. Such capability holds pivotal clinical potential, especially in real-time image-guided radiotherapy, computer-aided surgery, and patient follow-up sessions. Traditional methods for 3D volume reconstruction from X-rays often require the utilization of statistical 3D organ templates, which are employed in 2D/3D registration. However, these methods may not accurately account for the variation in organ shapes across different subjects. Our X2V model overcomes this problem by leveraging neural implicit representation. A vision transformer model is integrated as an encoder network, specifically designed to direct and enhance attention to particular regions within the X-ray image. The reconstructed meshes exhibit a similar topology to the ground truth organ volume, demonstrating the ability of X2V in accurately capturing the 3D structure from a 2D image. The effectiveness of X2V is evaluated on lung X-rays using several metrics, including volumetric Intersection over Union (IoU). X2V outperforms the state-of-the-art method in the literature for lungs (DeepOrganNet) by about 7-9% achieving IoU's between 0.892-0.942 versus DeepOrganNet's IoU of 0.815-0.888.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "G\u00f6k\u00e7e G\u00fcven et al.",
      "keywords": "Iterative reconstruction; Computer science; Volume (thermodynamics); Computer vision; Artificial intelligence; Image (mathematics); Planar; Computer graphics (images); Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3385668",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387831867",
      "doi": "10.1109/tnsre.2023.3324131",
      "title": "VR for Vocational and Ecological Rehabilitation of Patients With Cognitive Impairment: A Survey",
      "abstract": "Cognitive impairment arises from various brain injuries or diseases, such as traumatic brain injury, stroke, schizophrenia, or cancer-related cognitive impairment. Cognitive impairment can be an obstacle for patients to the return-to-work. Research suggests various interventions using technology for cognitive and vocational rehabilitation. The present work offers an overview of sixteen vocational or ecological VR-based clinical studies among patients with cognitive impairment. The objective is to analyze these studies from a VR perspective focusing on the VR apparatus and tasks, adaptivity, transferability, and immersion of the interventions. Our results highlight how a higher level of immersion could bring the participants to a deeper level of engagement and transferability, rarely assessed in current literature, and a lack of adaptivity in studies involving patients with cognitive impairments. From these considerations, we discuss the challenges of creating a standardized yet adaptive protocol and the perspectives of using immersive technologies to allow precise monitoring, personalized rehabilitation and increased commitment.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Emilie Hummel et al.",
      "keywords": "Rehabilitation; Transferability; Cognition; Psychological intervention; Cognitive rehabilitation therapy; Psychology; Physical medicine and rehabilitation; Vocational education; Perspective (graphical); Cognitive remediation therapy; Cognitive impairment; Medicine; Clinical psychology; Physical therapy; Psychiatry; Computer science",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/tnsre.2023.3324131",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4386536171",
      "doi": "10.1109/tnsre.2023.3310340",
      "title": "Homogeneous-Multiset-CCA-Based Brain Covariation and Contravariance Connectivity Network Modeling",
      "abstract": "Brain connectivity networks based on functional magnetic resonance imaging (fMRI) have expanded our understanding of brain functions in both healthy and diseased states. However, most current studies construct connectivity networks using averaged regional time courses with the strong assumption that the activities of voxels contained in each brain region are similar, ignoring their possible variations. Additionally, pairwise correlation analysis is often adopted with more attention to positive relationships, while joint interactions at the network level as well as anti-correlations are less investigated. In this paper, to provide a new strategy for regional activity representation and brain connectivity modeling, a novel homogeneous multiset canonical correlation analysis (HMCCA) model is proposed, which enforces sign constraints on the weights of voxels to guarantee homogeneity within each brain region. It is capable of obtaining regional representative signals and constructing covariation and contravariance networks simultaneously, at both group and subject levels. Validations on two sessions of fMRI data verified its reproducibility and reliability when dealing with brain connectivity networks. Further experiments on subjects with and without Parkinson's disease (PD) revealed significant alterations in brain connectivity patterns, which were further associated with clinical scores and demonstrated superior prediction ability, indicating its potential in clinical practice.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Qinrui Ling et al.",
      "keywords": "Multiset; Voxel; Canonical correlation; Pairwise comparison; Homogeneity (statistics); Computer science; Functional magnetic resonance imaging; Correlation; Homogeneous; Connectomics; Pattern recognition (psychology); Connectome; Artificial intelligence; Psychology; Neuroscience; Functional connectivity; Machine learning; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3310340",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2904231691",
      "doi": "10.1109/access.2018.2885336",
      "title": "A Programmable Multi-Biomarker Neural Sensor for Closed-Loop DBS",
      "abstract": "Most of the current closed-loop DBS devices use a single biomarker in their feedback loop which may limit their performance and applications. This paper presents design, fabrication, and validation of a programmable multi-biomarker neural sensor which can be integrated into closed-loop DBS devices. The device is capable of sensing a combination of low-frequency (7-45 Hz), and high-frequency (200-1000 Hz) neural signals. The signals can be amplified with a digitally programmable gain within the range 50-100 dB. The neural signals can be stored into a local memory for processing and validation. The sensing and storage functions are implemented via a combination of analog and digital circuits involving preamplifiers, filters, programmable post-amplifiers, microcontroller, digital potentiometer, and flash memory. The device is fabricated, and its performance is validated through: (i) bench tests using sinusoidal and pre-recorded neural signals, (ii) in-vitro tests using pre-recorded neural signals in saline solution, and (iii) in-vivo tests by recording neural signals from freely-moving laboratory mice. The animals were implanted with a PlasticsOne electrode, and recording was conducted after recovery from the electrode implantation surgery. The experimental results are presented and discussed confirming the successful operation of the device. The size and weight of the device enable tetherless back-mountable use in pre-clinical trials.",
      "year": "2018",
      "journal": "IEEE Access",
      "authors": "Mahboubeh Parastarfeizabadi et al.",
      "keywords": "Computer science; Closed loop; Control engineering; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2018.2885336",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226101395",
      "doi": "10.1109/access.2022.3166158",
      "title": "Continual Learning With Speculative Backpropagation and Activation History",
      "abstract": "Continual learning is gaining traction these days with the explosive emergence of deep learning applications. Continual learning suffers from a severe problem called catastrophic forgetting. It means that the trained model loses the previously learned information when training with new data. This paper proposes two novel ideas for mitigating catastrophic forgetting: Speculative Backpropagation (SB) and Activation History (AH). The SB enables performing backpropagation based on past knowledge. The AH enables isolating important weights for the previous task. We evaluated the performance of our scheme in terms of accuracy and training time. The experiment results show a 4.4&#x0025; improvement in knowledge preservation and a 31&#x0025; reduction in training time, compared to the state-of-the-arts (EWC and SI).",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Sangwoo Park et al.",
      "keywords": "Backpropagation; Computer science; Artificial intelligence; Artificial neural network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3166158",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4388819694",
      "doi": "10.1109/tnsre.2023.3334718",
      "title": "Machine Learning-Based Scoring System to Predict the Risk and Severity of Ataxic Speech Using Different Speech Tasks",
      "abstract": "The assessment of speech in Cerebellar Ataxia (CA) is time-consuming and requires clinical interpretation. In this study, we introduce a fully automated objective algorithm that uses significant acoustic features from time, spectral, cepstral, and non-linear dynamics present in microphone data obtained from different repeated Consonant-Vowel (C-V) syllable paradigms. The algorithm builds machine-learning models to support a 3-tier diagnostic categorisation for distinguishing Ataxic Speech from healthy speech, rating the severity of Ataxic Speech, and nomogram-based supporting scoring charts for Ataxic Speech diagnosis and severity prediction. The selection of features was accomplished using a combination of mass univariate analysis and elastic net regularization for the binary outcome, while for the ordinal outcome, Spearman's rank-order correlation criterion was employed. The algorithm was developed and evaluated using recordings from 126 participants: 65 individuals with CA and 61 controls (i.e., individuals without ataxia or neurotypical). For Ataxic Speech diagnosis, the reduced feature set yielded an area under the curve (AUC) of 0.97 (95% CI 0.90-1), the sensitivity of 97.43%, specificity of 85.29%, and balanced accuracy of 91.2% in the test dataset. The mean AUC for severity estimation was 0.74 for the test set. The high C-indexes of the prediction nomograms for identifying the presence of Ataxic Speech (0.96) and estimating its severity (0.81) in the test set indicates the efficacy of this algorithm. Decision curve analysis demonstrated the value of incorporating acoustic features from two repeated C-V syllable paradigms. The strong classification ability of the specified speech features supports the framework's usefulness for identifying and monitoring Ataxic Speech.",
      "year": "2023",
      "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "authors": "Bipasha Kashyap et al.",
      "keywords": "Speech recognition; Computer science; Test set; Artificial intelligence; Scoring algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tnsre.2023.3334718",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4389105006",
      "doi": "10.1109/access.2023.3336861",
      "title": "Encoding Kinematic and Temporal Gait Data in an Appearance-Based Feature for the Automatic Classification of Autism Spectrum Disorder",
      "abstract": "In appearance-based gait analysis studies, Gait Energy Images (GEI) have been shown to be an effective tool for human identification and gait pathology detection. In addition, model-based studies found kinematic and spatio-temporal features to be useful for gait recognition and Autism Spectrum Disorder (ASD) classification. Adapting the GEI to focus on the strong ASD features would improve the early screening of ASD by allowing the use of powerful appearance-based classifiers such as Convolutional Neural Networks (CNN). This paper introduces an enhanced GEI, by averaging images from a video sequence to produce a single image but by retention of a person&#x2019;s joint positions only, instead of the full body silhouettes. Depth is encoded into the binary images before they are averaged using colour mapping, a technique used in the Chrono-Gait Image. The Joint Energy Image (JEI) therefore embeds both the temporal and depth information of the joints into a 2D image. The image was preprocessed using Principal Component Analysis before being applied to a Multi-Layer Perceptron, and a Random Forest classifier. The JEI was also applied to a CNN directly and accuracy was improved when using a Test Time Augmentation (TTA) measure. The CNN achieved a TTA accuracy of 95.56&#x0025; when trained on a primary dataset of 100 subjects (50 with ASD and 50 that are typically developed), and 80&#x0025; TTA accuracy on a secondary dataset of 20 subjects (10 ASD and 10 typically developed) across multiple tests.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Bradley G. Henderson et al.",
      "keywords": "Computer science; Feature (linguistics); Kinematics; Artificial intelligence; Gait; Pattern recognition (psychology); Autism spectrum disorder; Encoding (memory); Feature extraction; Gait analysis; Speech recognition; Computer vision; Autism; Physical medicine and rehabilitation; Psychology; Medicine; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3336861",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3186408998",
      "doi": "10.1109/access.2021.3097800",
      "title": "The Primary Actors of Technology Standardization in the Manufacturing Industry",
      "abstract": "To date, discussions on standards and standards-related market issues have mainly been focused on market influence, such as a company&#x2019;s performance, trade, and technological innovation. Despite the fact that many studies have been conducted with a focus on technology standards, the ways in which primary actors of standards affect the market are yet to be fully investigated in extant studies. In this study, we investigate the primary actors in technology standardization by carrying out a systematic review and constructing a conceptual framework and concept maps of primary actors. Based on our analysis, we categorize primary actors, according to their roles and timing of engagement in standardization, as follows: Technology producers, standard-setters, regulators, and technology users. We illustrate each actor&#x2019;s detailed actions, motives, and difficulties with concept maps that are structured based on the SAO/P model, in order to elucidate why primary actors participate in standardization and how they act to achieve their goals or resolve difficulties. Based on our findings, we derive implications in terms of the strategic management of standardization activities in the manufacturing industry.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Seungyeon Moon et al.",
      "keywords": "Standardization; Extant taxon; Order (exchange); Conceptual model; Knowledge management; Process management; Business; Categorization; Technology management; Process (computing); Computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3097800",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3049060842",
      "doi": "10.1109/access.2020.3016301",
      "title": "Research on Screening of Empathy Information Based on Image Recognition and Data Mining",
      "abstract": "The Internet not only provides help for people to understand the world and facilitate life, but also provides a convenient way for widespread dissemination of bad information. It follows that young people are often harassed by pornographic, violent and other bad images, which affects the development of young people's empathy. In this study, from the perspective of the combination of bad image screening and youth empathy ability, the effect of bad image on youth empathy ability is studied. In this article, a new empathy analysis model is constructed based on traditional empathy theory, combined with image recognition and data mining technology. First, the theoretical principles of bad image recognition technology and their application in the evaluation of empathy ability are expounded. Then, based on image recognition and fusion particle swarm optimization algorithm, the classification of bad images was studied. Finally, on the basis of image classification, a data envelopment model is used to grade the young people's empathy ability. The actual case analysis and performance test results illustrate the superiority of the implemented image classification and empathy evaluation method based on image recognition and data mining. This research has certain theoretical significance for the research of enriching empathy ability and interpersonal relationship. At the same time, it has certain practical significance for improving the youth's interpersonal trust, realizing the harmonious interpersonal relationship and the healthy development of body and mind.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Gong Ying et al.",
      "keywords": "Empathy; Interpersonal communication; Perspective (graphical); Artificial intelligence; Computer science; Image (mathematics); Psychology; Social psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3016301",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387757723",
      "doi": "10.1109/access.2023.3325404",
      "title": "An Enhanced Framework for Overcoming Pitfalls and Enabling Model Interpretation in Pneumonia and Covid-19 Classification",
      "abstract": "Currently, in the health area, a large amount of information is generated daily, enabling the creation of tools using the concepts of Machine Learning to help professionals make clinical decisions. In addition, due to the current scenario that we experienced in the Covid-19 pandemic, the development of tools that can assist in the diagnosis of this new disease has become essential. Besides several papers had explored deep learning algorithms for pneumonia classification, a recent survey showed they present some pitfalls and can not be used in real scenarios (eg. data sets from unreliable sources, training with small and imbalanced data sets, duplicated images due to improper merging data, problems with demographic differences among the patients such as age group, improper evaluation metrics, no use of external datasets for validation, no model interpretability). Moreover, the papers do not present a complete system, that can be tested in real scenarios. We aim to deal with these limitations and propose a framework to overcome the pointed pitfalls. We conducted a comprehensive analysis that underscores the significance of such an approach. Our efforts encompassed mitigating dataset biases and testing many popular Convolutional Neural Network models under a comprehensive evaluation. The inclusion of an external dataset fortified the credibility of our assessment. We engineered a prototype web platform with a Containerized architecture. Moreover, due to the overparameterization and black-box nature of deep learning models, it is difficult to understand the prediction results. We also explored tools to understand how the models make decisions. Through the experiments carried out in the ternary classification VGG16 network reached 89.7&#x0025; of accuracy in the external datasets. In addition, the efficiency of these models in detecting the presence of diseases in patients, measured using the recall metric, was 0.96 for Covid-19 and 0.86 for Pneumonia, this result is of great importance since in the health area there is a great focus on avoiding false negatives.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Matheus A. De Castro Santos et al.",
      "keywords": "Interpretability; Computer science; Machine learning; Artificial intelligence; Credibility; Data science; Deep learning; Convolutional neural network; Coronavirus disease 2019 (COVID-19); Data mining; Disease",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3325404",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4312946302",
      "doi": "10.1109/access.2022.3218776",
      "title": "A Comprehensive User Modeling Framework and a Recommender System for Personalizing Well-Being Related Behavior Change Interventions: Development and Evaluation",
      "abstract": "Health recommender systems (HRSs) have the potential to effectively personalize well-being related behavior change interventions to the needs of individuals. However, personalization is often conducted with a narrow perspective, and the underlying user features are inconsistent across HRSs. Particularly, theory-based determinants of behavior and the variety of lifestyle domains influencing well-being are poorly addressed. We propose a comprehensive theory-based framework of user features, the virtual individual (VI) model, to support the extensive personalization of digital well-being interventions. We introduce a prototype HRS (With-Me HRS) with knowledge-based filtering, which recommends behavior change objectives and activities from several lifestyle domains. With-Me HRS realizes a minimum set of important VI model features related to well-being, lifestyle, and behavioral intention. We report the preliminary validity and usefulness of the HRS, evaluated in a real-life health-coaching program with 50 participants. The recommendations were used in decision-making for half of the participants and were hidden for others. For 73&#x0025; of the participants (85&#x0025; with visible vs. 62&#x0025; with hidden recommendations), at least one of the recommended activities was included into their coaching plans. The HRS reduced coaches&#x2019; perceived effort in identifying appropriate coaching tasks for the participants (effect size: Vargha-Delaney <inline-formula> <tex-math notation=\"LaTeX\">$\\hat {A}$ </tex-math></inline-formula> &#x003D; 0.71, 95&#x0025; CI 0.59-0.84) but not in identifying behavior change objectives. From the participants&#x2019; perspective, the quality of coaching improved (effect size for one of three quality metrics: <inline-formula> <tex-math notation=\"LaTeX\">$\\hat {A}$ </tex-math></inline-formula> &#x003D; 0.71, 95&#x0025; CI 0.57-0.83). These results provide a baseline for testing the influence of additional user model features on the validity of recommendations generated by knowledge-based multi-domain HRSs.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Anita Honka et al.",
      "keywords": "Coaching; Personalization; Psychological intervention; Behavior change; Computer science; Perspective (graphical); Recommender system; Applied psychology; Set (abstract data type); Baseline (sea); Quality (philosophy); Psychology; Medicine; Artificial intelligence; Machine learning; World Wide Web; Social psychology; Nursing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3218776",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4409917207",
      "doi": "10.1109/tmi.2025.3564320",
      "title": "Structure Causal Models and LLMs Integration in Medical Visual Question Answering",
      "abstract": "Medical Visual Question Answering (MedVQA) aims to answer medical questions according to medical images. However, the complexity of medical data leads to confounders that are difficult to observe, so bias between images and questions is inevitable. Such cross-modal bias makes it challenging to infer medically meaningful answers. In this work, we propose a causal inference framework for the MedVQA task, which effectively eliminates the relative confounding effect between the image and the question to ensure the precision of the question-answering (QA) session. We are the first to introduce a novel causal graph structure that represents the interaction between visual and textual elements, explicitly capturing how different questions influence visual features. During optimization, we apply the mutual information to discover spurious correlations and propose a multi-variable resampling front-door adjustment method to eliminate the relative confounding effect, which aims to align features based on their true causal relevance to the question-answering task. In addition, we also introduce a prompt strategy that combines multiple prompt forms to improve the model's ability to understand complex medical data and answer accurately. Extensive experiments on three MedVQA datasets demonstrate that 1) our method significantly improves the accuracy of MedVQA, and 2) our method achieves true causal correlations in the face of complex medical data.",
      "year": "2025",
      "journal": "IEEE Transactions on Medical Imaging",
      "authors": "Zibo Xu et al.",
      "keywords": "Question answering; Computer science; Artificial intelligence; Natural language processing; Cognitive psychology; Information retrieval; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tmi.2025.3564320",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4367666203",
      "doi": "10.1109/access.2023.3271751",
      "title": "Continuity of Essential Services as an Emerging Challenge for Societal Resilience",
      "abstract": "Critical infrastructure (CI) business continuity is fundamental in today&#x2019;s turbulent times. The new trend is the reference to essential services (ES). This paper aims to identify lead topics in the ES area and analyze actions to provide ES business continuity. The goal will be achieved by <xref rid=\"deqn1\" ref-type=\"disp-formula\">(1)</xref> identifying leading research topics using Latent Dirichlet Allocation, <xref rid=\"deqn2\" ref-type=\"disp-formula\">(2)</xref> conducting a systematic literature review using VOSviewer, (3) mapping the results obtained, and identifying possibilities for further research. Web of Science, Scopus, and specific keywords were used to select peer-reviewed papers discussing the ES issue. The results showed that, despite the importance of the ES issue, there are few publications related to the business continuity of ES. The work focuses on the relevance of ES to individual entities such as companies, cities, municipalities, and countries. There are also isolated works on ES security, but mainly in cybersecurity. The added value of the article is that it organizes the knowledge related to leading topics in the ES area from a Business, Management, and Accounting perspective and indicates the research areas that require further scrutiny. It is the first comprehensive literature review focusing specifically on ES.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Micha\u0142 Wi\u015bniewski et al.",
      "keywords": "Resilience (materials science); Computer science; Data science; Computer security; Risk analysis (engineering); Business; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3271751",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4285060938",
      "doi": "10.1109/access.2022.3183201",
      "title": "Utility-Embraced Microaggregation for Machine Learning Applications",
      "abstract": "With access to vast amounts of data, privacy protection is more important than ever. Among various de-identification (anonymization) techniques, <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>-anonymous microaggregation has been widely studied since it enables us to balance between confidentiality and data utility. Despite plenty of microaggregation methods in the sense of reducing the information loss and/or computational complexity, machine learning (ML) models using the resulting aggregated data face the problem that they are not as effective as expected. Motivated by the fact that ML models can be heavily influenced by distorted training data (albeit slightly), we deliberate on the performance of microaggregation in terms of not only data privacy but also <italic>data utility</italic>. In this paper, we propose <italic>Util-MA</italic>, a new utility-embraced microaggregation framework for effective ML applications. Specifically, unlike prior studies that apply microaggregation techniques directly to raw data, we design a unified framework that can potentially enhance the data utility while preserving the <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>-anonymity through preprocessing steps including <italic>dimensionality reduction</italic> and <italic>clustering</italic>. By using real-world datasets, we empirically demonstrate the superiority of <italic>Util-MA</italic> over benchmark microaggregation methods in terms of classification accuracy. Moreover, we investigate the importance of preprocessing by measuring key performance indicators (KPIs) of clustering; the clustering stage of <italic>Util-MA</italic> leads to high performance on the classification when the clustering results substantially coincide with the ground truth labels. We also establish a close relationship between the KPIs of clustering and the classification accuracies, which tends to be revealed when there is a gain of <italic>Util-MA</italic> over the benchmark method is observed. Our framework is microaggregation-model-agnostic; thus, underlying microaggregation models can be appropriately chosen according to one&#x2019;s needs and ML tasks.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Soobin Lee et al.",
      "keywords": "Computer science; Cluster analysis; Dimensionality reduction; Data mining; Machine learning; Preprocessor; Data pre-processing; Benchmark (surveying); Raw data; Information privacy; Artificial intelligence; Identification (biology); Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3183201",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392667129",
      "doi": "10.1109/tse.2024.3374382",
      "title": "Evaluation Framework for Autonomous Systems: The Case of Programmable Electronic Medical Systems",
      "abstract": "This paper proposes an evaluation framework for autonomous systems, called LENS. It is an instrument to make an assessment of a system through the lens of abilities related to adaptation and smartness. The assessment can then help engineers understand in which direction it is worth investing to make their system smarter. It also helps to identify possible improvement directions and to plan for concrete activities. Finally, it helps to make a re-assessment when the improvement has been performed in order to check whether the activity plan has been accomplished. <p xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Given the high variability in the various domains in which autonomous systems are and can be used, LENS is defined in abstract terms and instantiated to a specific and important class of medical devices, i.e., Programmable Electronic Medical Systems (PEMS). The instantiation, called LENS<i><sub>PEMS</sub></i>, is validated in terms of <i>applicability</i>, i.e., how it is applicable to real PEMS, <i>generalizability</i>, i.e., to what extent LENS<i><sub>PEMS</sub></i> is generalizable to the PEMS class of systems, and <i>usefulness</i>, i.e., how it is useful in making an assessment and identifying possible directions of improvement towards smartness.",
      "year": "2024",
      "journal": "IEEE Transactions on Software Engineering",
      "authors": "Andrea Bombarda et al.",
      "keywords": "Computer science; Software engineering; Embedded system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tse.2024.3374382",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4323027696",
      "doi": "10.22489/cinc.2022.338",
      "title": "Robustness of Residual Network in Predicting PR Interval Trained using Noisy Labels",
      "abstract": "The PR interval represents the time required from the electrical impulse to advance from the atrium to AV node and His-Purkinje system until the ventricular myocardium begins to depolarize.PR interval prolongation has been associated with significant increases in atrial fibrillation, heart failure and mortality.Over the past years, multiple deep learning models have been proposed to interpret electrocardiogram (ECG) signals.Despite initial success, these models are often trained and validated using datasets that contain partially incorrect labels.These \"noisy\" labels exist because of the way the annotated data was collected and pose challenges for model training and validation.As a result, a residual neural network (ResNet), trained on noisy data, was proposed to estimate PR intervals.In addition, an electrophysiologist performed a blinded manual adjudication on a stratified sample to validate the accuracy of both the model and the noisy labels.The conclusion is that a ResNet trained on noisy data can correctly estimate PR intervals and outperforms the noisy labels it was trained on.",
      "year": "2022",
      "journal": "Computing in cardiology",
      "authors": "Loc Cao et al.",
      "keywords": "Residual; Computer science; Robustness (evolution); Artificial intelligence; Noisy data; Pattern recognition (psychology); Artificial neural network; Atrial fibrillation; Cardiology; Medicine; Algorithm",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.22489/cinc.2022.338",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3020861576",
      "doi": "10.1109/mcom.001.2000280",
      "title": "Optical Wireless Communications for In-Body and Transdermal Biomedical Applications",
      "abstract": "This article discusses the fundamental architectures for optical wireless systems for biomedical applications. After summarizing the main applications and reporting their requirements, {we describe the characteristics of the transdermal and in-body optical channels as well as the challenges that they impose in the design of communication systems.} In more detail, we provide three possible architectures for transdermal communications, namely electro-optical (EO) monitoring, opto-electrical (OE), and all-optical (AO) for neural stimulation, which are currently under investigation, whereas for in-body communications, we provide a nano-scale AO (NAO) concept. For each architecture, we discuss the main operation principles, the technology enablers, and research directions for their development. Finally, we highlight the necessity of designing an information-theoretic framework for the analysis and design of the physical (PHY) and medium access control (MAC) layers, which takes into account the channels'~characteristics.",
      "year": "2021",
      "journal": "IEEE Communications Magazine",
      "authors": "Alexandros\u2013Apostolos A. Boulogeorgos et al.",
      "keywords": "Transdermal; Wireless; PHY; Computer science; Optical wireless; Optical communication; Physical layer; Telecommunications; Electronic engineering; Computer architecture; Engineering; Medicine",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/mcom.001.2000280",
      "cited_by_count": 3,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3015925383",
      "doi": "10.1109/jbhi.2020.3032479",
      "title": "Automatically Assessing Quality of Online Health Articles",
      "abstract": "The information ecosystem today is overwhelmed by an unprecedented quantity of data on versatile topics are with varied quality. However, the quality of information disseminated in the field of medicine has been questioned as the negative health consequences of health misinformation can be life-threatening. There is currently no generic automated tool for evaluating the quality of online health information spanned over a broad range. To address this gap, in this paper, we applied a data mining approach to automatically assess the quality of online health articles based on 10 quality criteria. We have prepared a labeled dataset with 53012 features and applied different feature selection methods to identify the best feature subset with which our trained classifier achieved an accuracy of 84%-90% varied over 10 criteria. Our semantic analysis of features shows the underpinning associations between the selected features &amp; assessment criteria and further rationalize our assessment approach. Our findings will help in identifying high-quality health articles and thus aiding users in shaping their opinion to make the right choice while picking health-related help from online.",
      "year": "2020",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Fariha Afsana et al.",
      "keywords": "Misinformation; Computer science; Quality (philosophy); Feature selection; Data science; Data quality; Feature (linguistics); Underpinning; Field (mathematics); Classifier (UML); Information retrieval; Data mining; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/jbhi.2020.3032479",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392406053",
      "doi": "10.1109/access.2024.3373068",
      "title": "Robust Online Correlation Method for Identification of a Nonparametric Model of Type 1 Diabetes",
      "abstract": "The paper presents an online version of the identification method for estimating the impulse responses in the case of a two-input single-output linear empirical model of type 1 diabetes that allows us to adapt the model parameters due to the intra-subject time variability in real time. The method builds on and augments our original research by providing important enhancements concerning the online parameter estimation, recursive formulation of essential equations, improved regularization, and new effective approaches to numerically solve the estimation problem. Recursive equations are derived to update the covariance matrix of the sample cross-correlation function, as well as the inverse of this covariance matrix, where the customized Sherman-Morrison formula was considered. To efficiently update the parameter estimate at each sample while avoiding direct calculation of the Hessian matrix inverse, two alternative strategies are proposed to be applied instead. The first is based on the numeric minimization by the conjugate gradient method, whereas the second takes advantage of the Schulz method to approximate the inverse Hessian matrix. As a result, all steps of the identification algorithm were designed so that only basic linear operations are required. Features to robustify the estimate were also involved, as the optimal regularization strategies based on the inverse of the covariance matrix of the actual parameter distribution and the inter-sample parameter drift were applied. In the end of the paper, a series of simulation-based experiments was carried out to assess the effectiveness of the proposed method and to demonstrate all of its aspects and important characteristics. The documented results showed that the method can yield valid estimates of impulse responses and also effectively adapt parameters in real time under the influence of time-varying physiology.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Martin Dodek et al.",
      "keywords": "Correlation; Nonparametric statistics; Identification (biology); Computer science; Artificial intelligence; Statistics; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3373068",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4313006550",
      "doi": "10.1109/access.2022.3224038",
      "title": "A Scoping Review of the Use of Log Data for Evaluating Mobile Apps: Exploring Implications for mHealth Apps",
      "abstract": "There is a growing trend in the potential benefits and application of log data to evaluate mHealth Apps. Unfortunately, log analyses within this field are faced with challenges such as unregulated processes, questionable validity of the findings, and subjective assessment criteria resulting in the underutilization of mHealth data. To increase the use and benefit of mHealth data, there is a call for more complete data and process transparency to derive trustworthy evidence of the Apps&#x2019; efficacy. We aimed to explore extant literature and guidance through a scoping review of how log data analysis can be used to generate valuable insights supporting the evaluation of mobile Apps. The scoping review followed the Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) guidelines for a scoping review. The Scopus database and grey literature (through a Google search) delivered 105 articles, and we applied inclusion and exclusion criteria to retain 33 articles in the sample for analysis and synthesis. This scoping review sought to identify how log data are used for mobile App evaluations. By highlighting the existing trends found in the literature, identifying the similarities and differences between mHealth and General App analyses, and categorizing the indicators, insights, and improvements, this study contributes to the existing knowledge base of mHealth evaluations and future standardizations. The concepts and categories identified by this review are combined to form a conceptual framework that will be refined and incorporated into future research toward addressing the gap identified in the current literature.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Ane van Schalkwyk et al.",
      "keywords": "mHealth; Computer science; Scopus; Systematic review; Mobile apps; Data science; Grey literature; Process (computing); World Wide Web; MEDLINE; Psychology; Psychological intervention",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2022.3224038",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389040882",
      "doi": "10.1109/access.2023.3336946",
      "title": "The Analysis of Nutrition Toxicology Detection Based on Big Data and Deep Learning",
      "abstract": "Public health and safety are increasingly concerned as public awareness of health-related issues grows. To find a rapid, convenient, and non-destructive testing method for detecting human nutritional toxicology detection, this study selects sildenafil, phenolphthalein, and metformin hydrochloride&#x2014;commonly found additives in health products&#x2014;as the focal point. The research endeavors to tackle the paramount issue of public health and safety. The study begins by elucidating the public health and safety concept and then outlines the computational process for determining the terahertz (THz) optical properties. Subsequently, it provides a brief overview of deep learning (DL) methods, including the Back Propagation Neural Network (BPNN), Convolutional Neural Network (CNN), Residual Network (ResNet), and MobileNet model. Finally, the study compares and tests the THz absorption spectrum data of 22 pure samples containing sildenafil, phenolphthalein, and metformin hydrochloride by DL technique to evaluate the model&#x2019;s classification performance. The findings demonstrate that, with increased training iterations, the model&#x2019;s accuracy consistently improves and stabilizes. For instance, after 12 training iterations, CNN&#x2019;s accuracy under the verification set stabilizes, frequently reaching nearly 100&#x0025;. After 83 iterations, the accuracy remains steady at 98.96&#x0025;. Similarly, the MobileNet model reaches stability after 17 iterations, achieving 100&#x0025; accuracy. The BPNN demonstrates the fastest prediction time among the four DL algorithm models, at 310&#x2013;5 seconds. Meanwhile, the MobileNet model exhibits the highest accuracy and stability. This study using THz waves to identify contaminants in medical items can significantly enhance public health and safety.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Jing Shi et al.",
      "keywords": "Computer science; Big data; Data science; Artificial intelligence; Machine learning; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3336946",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4387245533",
      "doi": "10.1109/tcss.2023.3313208",
      "title": "The Impact of Computational Drug Discovery on Society",
      "abstract": "Greetings and welcome to the fifth issue of IEEE Transactions on Computational Social Systems (TCSS) for 2023. This edition presents a collection of 55 diverse regular articles that illuminate various facets of the interaction between computer technology and society.",
      "year": "2023",
      "journal": "IEEE Transactions on Computational Social Systems",
      "authors": "Jianxin Wang et al.",
      "keywords": "Drug discovery; Computer science; Computational model; Data science; Computer security; Artificial intelligence; Bioinformatics; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcss.2023.3313208",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3183701424",
      "doi": "10.1109/access.2021.3100581",
      "title": "A Hybrid Approach to Building Peer Groups for Technology Evaluation to Generate Reference Information",
      "abstract": "Technology evaluation facilitates successful implementation of a technology financing system. It is usually done with a combined approach of data-driven quantitative evaluation and expert-driven qualitative evaluation due to the labyrinthine nature of the technology, but largely relies on the qualitative judgement of experts. It naturally causes a problem that the evaluation result for the same technology varies considerably depending on who evaluates it. To enable consistent technology evaluation, a few methods have been presented to generate reference information for technology evaluation by identifying relevant firms. However, they cannot explore the detailed properties of individual technologies when building peer groups with the identified relevant firms. Since technology is the ultimate subject of evaluation, not only the similarity between firms, but also the similarity between technologies should be investigated in the process of identifying relevant firms. Therefore, this study proposes a hybrid approach, which builds peer groups by measuring both the similarities between firms and between technologies and generates reference information that enables efficient and consistent technology evaluation. It is quite common for several evaluators to be involved in technology evaluation. If the evaluation results are inconsistent, additional manual work should be performed to reconcile these inconsistent results. Therefore, the proposed approach can improve the efficiency of the technology evaluation activities by avoiding unnecessary manual work. Furthermore, by providing useful reference information to the evaluator in an automated way, it will help maintain the consistency of the evaluation result so that the result does not vary greatly depending on the evaluators.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Wonchul Seo",
      "keywords": "Computer science; Consistency (knowledge bases); Process (computing); Information technology; Judgement; Work (physics); Similarity (geometry); Knowledge management; Data science; Risk analysis (engineering); Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3100581",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2942269774",
      "doi": "10.1109/access.2019.2923321",
      "title": "Machine Learning Tips and Tricks for Power Line Communications",
      "abstract": "A great deal of attention has been recently given to Machine Learning (ML) techniques in many different application fields. This paper provides a vision of what ML can do in Power Line Communications (PLC). We firstly and briefly describe classical formulations of ML, and distinguish deterministic from statistical learning models with relevance to communications. We then discuss ML applications in PLC for each layer, namely, for characterization and modeling, for the development of physical layer algorithms, for media access control and networking. Finally, other applications of PLC that can benefit from the usage of ML, as grid diagnostics, are analyzed. Illustrative numerical examples are reported to serve the purpose of validating the ideas and motivate future research endeavors in this stimulating signal/data processing field.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Andrea M. Tonello et al.",
      "keywords": "Computer science; Relevance (law); Field (mathematics); Layer (electronics); Artificial intelligence; Power (physics); Line (geometry); Physical layer; SIGNAL (programming language); Power-line communication; Machine learning; Grid; Telecommunications; Wireless",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2019.2923321",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2608399496",
      "doi": "10.22489/cinc.2016.048-277",
      "title": "An Annotation Driven Rule:based Algorithm for Suggesting Multiple 12:lead Electrocardiogram Interpretations",
      "abstract": "The 12-lead Electrocardiogram (ECG) is ubiquitously used as a diagnostic support tool to detect cardiovascular disease.However, it is difficult to read and is often incorrectly interpreted.This study aims to further previous research, which used of a set of interactive questions and prompts to guide an interpreter through the ECG reporting process.The model was named 'Interactive Progressive based ECG Interpretation' (IPI).In this study, the IPI model has been augmented with an automatic diagnoses suggestion tool following annotated analysis of an ECG.To accomplish this, a rule-based algorithm has been created to assess the interpreters' ECG annotations to each of the interactive questions in the IPI model.This Differential Diagnoses Algorithm (DDA) was implemented using web technologies such as JavaScript and uses a modern device agnostic and language independent storage format (JSON) for defining the rules.Hence, by augmenting the IPI model with the DDA we hypothesize that this will further lower the number of interpretation errors and increase diagnostic accuracy in ECG interpretation.",
      "year": "2016",
      "journal": "Computing in cardiology",
      "authors": "Andrew Cairns et al.",
      "keywords": "Computer science; Algorithm; Annotation; Lead (geology); Artificial intelligence; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.22489/cinc.2016.048-277",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391547654",
      "doi": "10.1109/tbdata.2024.3362193",
      "title": "ALTRUIST: A Python Package to Emulate a Virtual Digital Cohort Study Using Social Media Data",
      "abstract": "Epidemiological cohort studies play a crucial role in identifying risk factors for various outcomes among participants. These studies are often time-consuming and costly due to recruitment and long-term follow-up. Social media (SM) data has emerged as a valuable complementary source for digital epidemiology and health research, as online communities of patients regularly share information about their illnesses. Unlike traditional clinical questionnaires, SM offer unstructured but insightful information about patients' disease burden. Yet, there is limited guidance on analyzing SM data as a prospective cohort. We presented the concept of virtual digital cohort studies (VDCS) as an approach to replicate cohort studies using SM data. In this paper, we introduce ALTRUIST, an open-source Python package enabling standardized generation of VDCS on SM. ALTRUIST facilitates data collection, preprocessing, and analysis steps that mimic a traditional cohort study. We provide a practical use case focusing on diabetes to illustrate the methodology. By leveraging SM data, which offers large-scale and cost-effective information on users' health, we demonstrate the potential of VDCS as an essential tool for specific research questions. ALTRUIST is customizable and can be applied to data from various online communities of patients, complementing traditional epidemiological methods and promoting minimally disruptive health research.",
      "year": "2024",
      "journal": "IEEE Transactions on Big Data",
      "authors": "Charline Bour et al.",
      "keywords": "Computer science; Python (programming language); Data science; Cohort; Preprocessor; Data collection; R package; Data mining; Medicine; Artificial intelligence; Statistics; Pathology; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tbdata.2024.3362193",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4414271163",
      "doi": "10.1109/tvcg.2025.3610803",
      "title": "Cognitive Affordances in Visualization: Related Constructs, Design Factors, and Framework",
      "abstract": "Classically, affordance research investigates how the shape of objects communicates actions to potential users. Cognitive affordances, a subset of this research, characterize how the design of objects influences cognitive actions, such as information processing. Within visualization, cognitive affordances inform how graphs' design decisions communicate information to their readers. Although several related concepts exist in visualization, a formal translation of affordance theory to visualization is still lacking. In this paper, we review and translate affordance theory to visualization by formalizing how cognitive affordances operate within a visualization context. We also review common methods and terms, and compare related constructs to cognitive affordances in visualization. Based on a synthesis of research from psychology, human-computer interaction, and visualization, we propose a framework of cognitive affordances in visualization that enumerates design decisions and reader characteristics that influence a visualization's hierarchy of communicated information. Finally, we demonstrate how this framework can guide the evaluation and redesign of visualizations.",
      "year": "2025",
      "journal": "IEEE Transactions on Visualization and Computer Graphics",
      "authors": "Racquel Fygenson et al.",
      "keywords": "",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tvcg.2025.3610803",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4387885719",
      "doi": "10.1109/access.2023.3327058",
      "title": "Design of an Electronic Health Record for Treating and Monitoring Oncology Patients in Chile",
      "abstract": "Identifying the clinical needs to evaluate and manage the treatment and monitoring of cancer patients is a multidimensional challenge in healthcare institutions. In this regard, electronic health records (EHRs) are beneficial for managing clinical information; however, EHRs focused exclusively on patients with cancer have not been sufficiently adopted. In Chile, the need for oncology EHR has only been briefly addressed, resulting in insufficient updated and systematized information on oncology patients. In this paper, we propose the design of an oncology EHR that manages critical variables and processes for the treatment and monitoring of patients with cancer in Chile. We used a systematic methodology to design a software architecture oriented to focus groups and interviews to elicit the requirements and needs of stakeholders. We created and described an EHR design that considers four modules that group and manage the main variables and processes that are critical for treating and monitoring oncology patients. Enabling and designing a treatment and monitoring registry for cancer patients in Chile is essential because it allows for the evaluation of strategic clinical decisions in favor of patients.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Carla Taramasco et al.",
      "keywords": "Health records; Electronic health record; Medicine; Cancer; Health care; Focus group; Clinical Oncology; Medical physics; Oncology; Internal medicine; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3327058",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2157954477",
      "doi": "10.1109/access.2014.2332453",
      "title": "Toward Scalable Systems for Big Data Analytics: A Technology Tutorial",
      "abstract": "Recent technological advancements have led to a deluge of data from distinctive domains (e.g., health care and scientific sensors, user-generated data, Internet and financial companies, and supply chain systems) over the past two decades. The term big data was coined to capture the meaning of this emerging trend. In addition to its sheer volume, big data also exhibits other unique characteristics as compared with traditional data. For instance, big data is commonly unstructured and require more real-time analysis. This development calls for new system architectures for data acquisition, transmission, storage, and large-scale data processing mechanisms. In this paper, we present a literature survey and system tutorial for big data analytics platforms, aiming to provide an overall picture for nonexpert readers and instill a do-it-yourself spirit for advanced audiences to customize their own big-data solutions. First, we present the definition of big data and discuss big data challenges. Next, we present a systematic framework to decompose big data systems into four sequential modules, namely data generation, data acquisition, data storage, and data analytics. These four modules form a big data value chain. Following that, we present a detailed survey of numerous approaches and mechanisms from research and industry communities. In addition, we present the prevalent Hadoop framework for addressing big data challenges. Finally, we outline several evaluation benchmarks and potential research directions for big data systems.",
      "year": "2014",
      "journal": "IEEE Access",
      "authors": "Han Hu et al.",
      "keywords": "Big data; Data science; Computer science; Scalability; Analytics; Unstructured data; Data analysis; Data mining; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2014.2332453",
      "cited_by_count": 1085,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3045086480",
      "doi": "10.1109/access.2020.3010896",
      "title": "6G and Beyond: The Future of Wireless Communications Systems",
      "abstract": "6G and beyond will fulfill the requirements of a fully connected world and provide ubiquitous wireless connectivity for all. Transformative solutions are expected to drive the surge for accommodating a rapidly growing number of intelligent devices and services. Major technological breakthroughs to achieve connectivity goals within 6G include: (i) a network operating at the THz band with much wider spectrum resources, (ii) intelligent communication environments that enable a wireless propagation environment with active signal transmission and reception, (iii) pervasive artificial intelligence, (iv) large-scale network automation, (v) an all-spectrum reconfigurable front-end for dynamic spectrum access, (vi) ambient backscatter communications for energy savings, (vii) the Internet of Space Things enabled by CubeSats and UAVs, and (viii) cell-free massive MIMO communication networks. In this roadmap paper, use cases for these enabling techniques as well as recent advancements on related topics are highlighted, and open problems with possible solutions are discussed, followed by a development timeline outlining the worldwide efforts in the realization of 6G. Going beyond 6G, promising early-stage technologies such as the Internet of NanoThings, the Internet of BioNanoThings, and quantum communications, which are expected to have a far-reaching impact on wireless communications, have also been discussed at length in this paper.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ian F. Akyildiz et al.",
      "keywords": "Computer science; Wireless; Telecommunications; Wireless network; The Internet; Personal Communications Service; Spectrum management; Computer network; Wi-Fi array; Cognitive radio; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3010896",
      "cited_by_count": 1267,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3201870057",
      "doi": "10.1109/jproc.2023.3308088",
      "title": "Training Spiking Neural Networks Using Lessons From Deep Learning",
      "abstract": "The brain is the perfect place to look for inspiration to develop more efficient neural networks. The inner workings of our synapses and neurons provide a glimpse at what the future of deep learning might look like. This article serves as a tutorial and perspective showing how to apply the lessons learned from several decades of research in deep learning, gradient descent, backpropagation, and neuroscience to biologically plausible spiking neural networks (SNNs). We also explore the delicate interplay between encoding data as spikes and the learning process; the challenges and solutions of applying gradient-based learning to SNNs; the subtle link between temporal backpropagation and spike timing-dependent plasticity; and how deep learning might move toward biologically plausible online learning. Some ideas are well accepted and commonly used among the neuromorphic engineering community, while others are presented or justified for the first time here. A series of companion interactive tutorials complementary to this article using our Python package, &lt;italic&gt;snnTorch&lt;/italic&gt;, are also made available: https://snntorch.readthedocs.io/en/latest/tutorials/index.html.",
      "year": "2023",
      "journal": "Proceedings of the IEEE",
      "authors": "Jason K. Eshraghian et al.",
      "keywords": "Computer science; Python (programming language); Artificial intelligence; Deep learning; Spiking neural network; Backpropagation; Artificial neural network; Cognitive science; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2023.3308088",
      "cited_by_count": 572,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3199488820",
      "doi": "10.1109/access.2021.3111083",
      "title": "Machine Learning Based Indoor Localization Using Wi-Fi RSSI Fingerprints: An Overview",
      "abstract": "In the era of the Internet of Things (IoT) and Industry 4.0, the indoor usage of smart devices is expected to increase, thereby making their location information more important. Based on various practical issues related to large delays, high design cost, and limited performance, conventional localization techniques are not practical for indoor IoT applications. In recent years, many researchers have proposed a wide range of machine learning (ML)-based indoor localization approaches using Wi-Fi received signal strength indicator (RSSI) fingerprints. This survey attempts to provide a summarized investigation of ML-based Wi-Fi RSSI fingerprinting schemes, including data preprocessing, data augmentation, ML prediction models for indoor localization, and postprocessing in ML, and compare their performance. Any ML-based study is heavily reliant on datasets. Therefore, we dedicate a significant portion of this survey to the discussion of dataset collection and open-source datasets. To provide good direction for future research, we discuss the current challenges and potential solutions related to ML-based indoor localization systems.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Navneet Singh et al.",
      "keywords": "Computer science; Internet of Things; Signal strength; Preprocessor; Data pre-processing; Machine learning; Artificial intelligence; Data mining; Received signal strength indication; Real-time computing; Wireless sensor network; Embedded system; Wireless; Telecommunications; Computer network",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3111083",
      "cited_by_count": 222,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3096235391",
      "doi": "10.1109/access.2021.3057912",
      "title": "Weed Density and Distribution Estimation for Precision Agriculture Using Semi-Supervised Learning",
      "abstract": "Uncontrolled growth of weeds can severely affect the crop yield and quality. Unrestricted use of herbicide for weed removal alters biodiversity and cause environmental pollution. Instead, identifying weed-infested regions can aid selective chemical treatment of these regions. Advances in analyzing farm images have resulted in solutions to identify weed plants. However, a majority of these approaches are based on supervised learning methods which requires huge amount of manually annotated images. As a result, these supervised approaches are economically infeasible for the individual farmer because of the wide variety of plant species being cultivated. In this paper, we propose a deep learning-based semi-supervised approach for robust estimation of weed density and distribution across farmlands using only limited color images acquired from autonomous robots. This weed density and distribution can be useful in a site-specific weed management system for selective treatment of infected areas using autonomous robots. In this work, the foreground vegetation pixels containing crops and weeds are first identified using a Convolutional Neural Network (CNN) based unsupervised segmentation. Subsequently, the weed infected regions are identified using a fine-tuned CNN, eliminating the need for designing hand-crafted features. The approach is validated on two datasets of different crop/weed species (1) Crop Weed Field Image Dataset (CWFID), which consists of carrot plant images and the (2) Sugar Beets dataset. The proposed method is able to localize weed-infested regions a maximum recall of 0.99 and estimate weed density with a maximum accuracy of 82.13%. Hence, the proposed approach is shown to generalize to different plant species without the need for extensive labeled data.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Shantam Shorewala et al.",
      "keywords": "Weed; Computer science; Artificial intelligence; Convolutional neural network; Precision agriculture; Pixel; Agricultural engineering; Agriculture; Pattern recognition (psychology); Machine learning; Agronomy; Ecology; Biology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3057912",
      "cited_by_count": 99,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3128027446",
      "doi": "10.1109/access.2021.3058018",
      "title": "A Dynamic Spatial-Temporal Attention-Based GRU Model With Healthy Features for State-of-Health Estimation of Lithium-Ion Batteries",
      "abstract": "A proper battery management system (BMS) plays a vital role in ensuring the safety and reliability of electric vehicles (EVs) and other electronic products. Accurate State-of-Health (SOH) estimation of Lithium-ion (Li-ion) batteries is a key factor in a BMS. It is difficult to determine SOH because of the complexity of the electrochemical reactions within the battery. To improve the accuracy of SOH estimation, a dynamic spatial-temporal attention-based gated recurrent unit (DSTA-GRU) model is proposed in this paper. First, we extract six features from the battery's charging and discharging processes that can reflect the aging degree of the battery to some extent. Second, this paper proposes a model to combine spatial attention and temporal attention that can not only consider the effects of states at different time step on the results, but also consider the effects of different features in the space domain. Third, the proposed model is trained and tested on NASA battery datasets and compared with other conventional models. Experiments carried on these data sets demonstrate that our model achieves higher accuracy than other conventional models.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Shengmin Cui et al.",
      "keywords": "Battery (electricity); Computer science; State of health; Reliability (semiconductor); Lithium-ion battery; Key (lock); Data modeling; State of charge; Artificial intelligence; Data mining; Power (physics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3058018",
      "cited_by_count": 71,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3013865762",
      "doi": "10.1109/access.2020.2982906",
      "title": "Transfer Deep Learning Along With Binary Support Vector Machine for Abnormal Behavior Detection",
      "abstract": "Today, machine learning and deep learning have paved the way for vital and critical applications such as abnormal detection. Despite the modernity of transfer learning, it has proved to be one of the crucial inventions in the field of deep learning because of its promising results. For the purpose of this study, transfer learning is utilized to extract human motion features from RGB video frames to improve detection accuracy. A convolutional neural network (CNN) based on Visual Geometry Group network 19 (VGGNet-19) pre-trained model is used to extract descriptive features. Next, the feature vector is passed into Binary Support Vector Machine classifier (BSVM) to construct a binary-SVM model. The performance of the proposed framework is evaluated by three parameters: accuracy, area under the curve, and equal error rate. Experiments performed on two different datasets comprising highly different context abnormalities accomplished an accuracy of 97.44% and an area under the curve (AUC) of 0.9795 for University of Minnesota (UMN) dataset and accomplished an accuracy of 86.69% and an AUC of 0.7987 for University of California, San Diego Pedistrain1 (UCSD-PED1) dataset. Moreover, the performance of the pre-trained network VGGNet-19 with handcrafted feature descriptors and with other CNN pre-trained networks, respectively, has been investigated in this study for abnormal behavior detection. The results demonstrated that VGGNet-19 has better performance than histogram of oriented gradients, background subtraction, and optical flow. In addition, the VGGNet-19 shows higher detection accuracy than other pre-trained networks: GoogleNet, ResNet50, AlexNet, and VGGNet-16.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Ahlam Al-Dhamari et al.",
      "keywords": "Computer science; Artificial intelligence; Transfer of learning; Support vector machine; Convolutional neural network; Pattern recognition (psychology); RGB color model; Deep learning; Binary classification; Histogram of oriented gradients; Classifier (UML); Local binary patterns; Machine learning; Feature (linguistics); Optical flow; Feature learning; Context (archaeology); Histogram; Feature extraction; Image (mathematics)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.2982906",
      "cited_by_count": 78,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3186328757",
      "doi": "10.1109/jstars.2021.3098817",
      "title": "Exploitation of Time Series Sentinel-2 Data and Different Machine Learning Algorithms for Detailed Tree Species Classification",
      "abstract": "The classification of tree species through remote sensing data is of great significance to monitoring forest disturbances, biodiversity assessment, and carbon estimation. The dense time series and a wide swath of Sentinel-2 data provided the opportunity to map tree species accurately and in a timely manner over a large area. Many current studies have applied machine learning (ML) algorithms combined with Sentinel-2 images to classify tree species, but it is still unclear, which algorithm is more effective in the automotive extraction of tree species. In this study, five ML algorithms were compared to identify the composition of tree species with multitemporal Sentinel-2 images in the JianShe forest farm, Northeast China. Three major types of deep neural networks [Conv1D, AlexNet, and long short-term memory (LSTM)] were tested to classify Sentinel-2 time series, which represent three disparate but effective strategies to apply sequential data. The other two models are support vector machine (SVM) and random forest (RF), which are renowned for extensive adoption and high performance for various remote sensing applications. The results show that the overall accuracy of neural network models is better than that of SVM and RF. The Conv1D model had the highest classification accuracy (84.19&#x0025;), followed by the LSTM model (81.52&#x0025;), and the AlexNet model (76.02&#x0025;). For non-neural network models, RF&#x0027;s classification accuracy (79.04&#x0025;) is higher than that of SVM (72.79&#x0025;), but lower than that of Conv1D and LSTM. Therefore, the deep neural networks combined with multitemporal Sentinel-2 images can efficiently improve the accuracy of tree species classification.",
      "year": "2021",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Yanbiao Xi et al.",
      "keywords": "Computer science; Random forest; Support vector machine; Artificial intelligence; Artificial neural network; Tree (set theory); Machine learning; Time series; Statistical classification; Feature extraction; Data mining; Remote sensing; Algorithm; Pattern recognition (psychology); Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2021.3098817",
      "cited_by_count": 77,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2769122466",
      "doi": "10.1109/tkde.2018.2861006",
      "title": "Machine Learning for the Geosciences: Challenges and Opportunities",
      "abstract": "Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML) -- that has been widely successful in commercial domains -- offers immense potential to contribute to problems in geosciences. However, problems in geosciences have several unique challenges that are seldom found in traditional applications, requiring novel problem formulations and methodologies in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their properties that make it challenging to use traditional machine learning techniques. We then describe some of the common categories of geoscience problems where machine learning can play a role, and discuss some of the existing efforts and promising directions for methodological development in machine learning. We conclude by discussing some of the emerging research themes in machine learning that are applicable across all problems in the geosciences, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.",
      "year": "2019",
      "journal": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "Anuj Karpatne et al.",
      "keywords": "Artificial intelligence; Computer science; Relevance (law); Machine learning; Field (mathematics); Big data; Earth science; Data science; Geology; Data mining; Mathematics; Political science",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/tkde.2018.2861006",
      "cited_by_count": 48,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4381249489",
      "doi": "10.1109/access.2023.3287490",
      "title": "Predictive Maintenance in Healthcare System: A Survey",
      "abstract": "Medical devices are a vital component of healthcare systems, the advantages they may give continue to grow as they are crucial for the safe and effective prevention, diagnosis, treatment, and rehabilitation of illnesses and diseases. Therefore, it is critical to maintain them in good operating order to ensure optimum availability, minimal failures, and guarantee patients&#x2019; and users&#x2019; safety. The stages involved in medical devices regulation and management are complex, but they are necessary to ensure their quality, safety, and compatibility with the settings in which they are used. Medical equipment complexity has increased due to technological advancement and the traditional maintenance strategies do not meet the needs of today&#x2019;s healthcare organizations. Therefore, integrating information technology, social networking technologies, digitization and management of medical devices, and the use of big data technologies and Machine Learning (ML) techniques has the potential to significantly improve healthcare services. Integrating autonomous and intelligent systems where data and sophisticated data analytics may be employed led to enhanced equipment data collecting via the deployment of information and communication technologies, notably intelligent devices. With this advancement came an increase in Predictive Maintenance (PdM) solutions. PdM has become a commonly used approach, described as a set of procedures used to evaluate the condition of equipment and predict future failures. These estimations are then utilized to schedule maintenance activities through smart scheduling of maintenance procedures, which aids in preventing or at least minimizing the impacts of unanticipated failures. The purpose of this article is to present a Systematic Literature Review (SLR) exploring and reviewing prior research on the subject of PdM and the developments of this method, particularly in the medical field. In addition to supporting new research projects in the PdM sector, this paper offers a good foundation for understanding PdM approaches, their key findings, problems, and potential. This review focuses on two scientific databases from which a substantial number of articles dedicated solely to PdM in the medical field have been retrieved for analysis. Our research led us to conclude that, despite the many potential benefits of predictive maintenance in the medical field, the concept is still being under-exploited and faces many obstacles.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Oumaima Manchadi et al.",
      "keywords": "Predictive maintenance; Computer science; Risk analysis (engineering); Software deployment; Health care; Schedule; Reliability engineering; Engineering; Business",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3287490",
      "cited_by_count": 49,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3122331648",
      "doi": "10.1109/access.2021.3053704",
      "title": "Unsupervised Domain Adaptation in Activity Recognition: A GAN-Based Approach",
      "abstract": "Sensor-based human activity recognition (HAR) is having a significant impact in a wide range of applications in smart city, smart home, and personal healthcare. Such wide deployment of HAR systems often faces the annotation-scarcity challenge; that is, most of the HAR techniques, especially the deep learning techniques, require a large number of training data while annotating sensor data is very time- and effort-consuming. Unsupervised domain adaptation has been successfully applied to tackle this challenge, where the activity knowledge from a well-annotated domain can be transferred to a new, unlabelled domain. However, these existing techniques do not perform well on highly heterogeneous domains. This article proposes shift-GAN that integrate bidirectional generative adversarial networks (Bi-GAN) and kernel mean matching (KMM) in an innovative way to learn intrinsic, robust feature transfer between two heterogeneous domains. Bi-GAN consists of two GANs that are bound by a cyclic constraint, which enables more effective feature transfer than a classic, single GAN model. KMM is a powerful non-parametric technique to correct covariate shift, which further improves feature space alignment. Through a series of comprehensive, empirical evaluations, shift-GAN has not only achieved its superior performance over 10 state-of-the-art domain adaptation techniques but also demonstrated its effectiveness in learning activity-independent, intrinsic feature mappings between two domains, robustness to sensor noise, and less sensitivity to training data.",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Andrea Rosales Sanabria et al.",
      "keywords": "Computer science; Robustness (evolution); Activity recognition; Artificial intelligence; Domain adaptation; Machine learning; Feature (linguistics); Transfer of learning; Pattern recognition (psychology); Data mining; Classifier (UML)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2021.3053704",
      "cited_by_count": 39,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2979259801",
      "doi": "10.1109/taffc.2019.2945014",
      "title": "FaceEngage: Robust Estimation of Gameplay Engagement from User-Contributed (YouTube) Videos",
      "abstract": "Measuring user engagement in interactive tasks can facilitate numerous applications toward optimizing user experience, ranging from eLearning to gaming. However, a significant challenge is the lack of non-contact engagement estimation methods that are robust in unconstrained environments. We present FaceEngage, a non-intrusive engagement estimator leveraging user facial recordings during actual gameplay in naturalistic conditions. Our contributions are three-fold. First, we show the potential of using front-facing videos as training data to build the engagement estimator. We compile FaceEngage Dataset with over 700 picture-in-picture, realisitic, and user-contributed YouTube gaming videos (i.e., with both full-screen game scenes and time-synchronized user facial recordings in subwindows). Second, we develop FaceEngage system, that captures relevant gamer facial features from front-facing recordings to infer task engagement. We implement two FaceEngage pipelines: an estimator trained on user facial motion features inspired by prior psychological works, and a deep learning-enabled estimator. Lastly, we conduct extensive experiments and conclude: (i) certain user facial motion cues (e.g., blink rates, head movements) are engagement-indicative; (ii) our deep learning-enabled FaceEngage pipeline can automatically extract more informative features, outperforming the facial motion feature-based pipeline; (iii) FaceEngage is robust to various video lengths, users/game genres and interpretable. Despite the challenging nature of realistic videos, FaceEngage attains the accuracy of 83.8 percent and leave-one-user-out precision of 79.9 percent, both of which are superior to our face motion-based model.",
      "year": "2019",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Xu Chen et al.",
      "keywords": "Computer science; User engagement; Estimator; Pipeline (software); Artificial intelligence; Feature (linguistics); Human\u2013computer interaction; Motion (physics); Computer vision; Machine learning; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taffc.2019.2945014",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2934801780",
      "doi": "10.1109/jstqe.2019.2906270",
      "title": "Foundry Development of System-On-Chip InP-Based Photonic Integrated Circuits",
      "abstract": "We review the state-of-the-art in monolithic-integrated InP-based system-on-chip (SOC) photonic integrated circuits (PICs) and the extension of this capability to a foundry offering. The learnings and best practices embodied in the design and fabrication capability of commercially deployed monolithically integrated coherent optical communication SOC are leveraged to develop an optimized and scalable integration platform for a turn-key foundry process. The design automation and infrastructure required to enable a consistent reproducible InP-based foundry offering is summarized.",
      "year": "2019",
      "journal": "IEEE Journal of Selected Topics in Quantum Electronics",
      "authors": "Gloria E. Hoefler et al.",
      "keywords": "Photonic integrated circuit; Foundry; Integrated circuit; Chip; Scalability; Computer science; Electronic design automation; Electronic circuit; Key (lock); Integrated circuit design; System on a chip; Process (computing); Photonics; Embedded system; Electronic engineering; Computer architecture; Engineering; Materials science; Electrical engineering; Optoelectronics; Telecommunications; Mechanical engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstqe.2019.2906270",
      "cited_by_count": 41,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4328008031",
      "doi": "10.1109/access.2023.3258973",
      "title": "Assessing the Impact of Contextual Information in Hate Speech Detection",
      "abstract": "Social networks and other digital media deal with huge amounts of user-generated contents where hate speech has become a problematic more and more relevant. A great effort has been made to develop automatic tools for its analysis and moderation, at least in its most threatening forms, such as in violent acts against people and groups protected by law. One limitation of current approaches to automatic hate speech detection is the lack of context. The spotlight on isolated messages, without considering any type of conversational context or even the topic being discussed, severely restricts the available information to determine whether a post on a social network should be tagged as hateful or not. In this work, we assess the impact of adding contextual information to the hate speech detection task. We specifically study a subdomain of Twitter data consisting of replies to digital newspapers posts, which provides a natural environment for contextualized hate speech detection. We built a new corpus in Spanish (Rioplatense variant) focused on hate speech associated to the COVID-19 pandemic, annotated using guidelines carefully designed by our interdisciplinary team. Our classification experiments using state-of-the-art transformer-based machine learning techniques show evidence that adding contextual information improves the performance of hate speech detection for two proposed tasks: binary and multi-label prediction, increasing their Macro F1 by 4.2 and 5.5 points, respectively. These results highlight the importance of using contextual information in hate speech detection. Our code, models, and corpus has been made available for further research.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Juan Manuel P\u00e9rez et al.",
      "keywords": "Computer science; Voice activity detection; Relevance (law); Task (project management); Social media; Variety (cybernetics); Context (archaeology); Binary classification; Natural language processing; Artificial intelligence; Emotion detection; Speech recognition; Speech processing; Support vector machine; World Wide Web; Emotion recognition",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3258973",
      "cited_by_count": 53,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4362002261",
      "doi": "10.1109/access.2023.3263392",
      "title": "FPG-AI: A Technology-Independent Framework for the Automation of CNN Deployment on FPGAs",
      "abstract": "In recent years, Convolutional Neural Networks (CNNs) have demonstrated outstanding results in several emerging classification tasks. The high-quality predictions are often achieved with computationally intensive workloads that hinder the hardware acceleration of these models at the edge. Field Programmable Gate Arrays (FPGAs) have proven to be energy efficient platforms for the execution of these algorithms and works proposing methods for automating the design on these devices have acquired relevance. The common purpose is to enable a wide range of users without specific skills to accelerate CNNs on FPGAs with reduced development times. In this paper, we present FPG-AI, a technology-independent toolflow for automating the deployment of CNNs on FPGA. The framework combines the use of model compression strategies with a fully handcrafted Hardware Description Languages (HDL)-based accelerator that poses no limit on device portability. On top of that, an automation process merges the two design spaces to define an end-to-end and ready-to-use tool. Experimental results are reported for reference models extracted from the literature (LeNet, NiN, VGG16, MobileNet-V1) on multiple classification datasets (MNIST, CIFAR10, ImageNet). To prove the technology independence of FPG-AI, we characterize the toolflow on devices with heterogeneous resource budgets belonging to different vendors (Xilinx, Intel, and Microsemi). Comparison with state-of-the-art work confirms the unmatched device portability of FPG-AI and shows performance metrics in line with the literature.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Tommaso Pacini et al.",
      "keywords": "Computer science; Software portability; Field-programmable gate array; MNIST database; Convolutional neural network; Automation; Software deployment; Machine learning; Artificial intelligence; Benchmark (surveying); Embedded system; Computer architecture; Deep learning; Software engineering; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3263392",
      "cited_by_count": 20,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4285222486",
      "doi": "10.1109/access.2022.3174865",
      "title": "Blockchain-Enabled Federated Learning for UAV Edge Computing Network: Issues and Solutions",
      "abstract": "Unmanned aerial vehicles (UAVs) extend the traditional ground-based Internet of Things (IoT) into the air. UAV mobile edge computing (MEC) architectures have been proposed by integrating UAVs into MEC networks during the current novel coronavirus disease (COVID-19) era. UAV mobile edge computing (MEC) shares personal data with external parties (such as edge servers) during intelligent medical analytics. However, this technique raises privacy concerns about patients&#x2019; health data. More recently, the concept of federal learning (FL) has been set up to protect mobile user data privacy. Compared to traditional machine learning, federated learning requires a decentralized distribution system to enhance trust for UAVs. Blockchain technology provides a secure and reliable solution for FL settings between multiple untrusted parties with anonymous, immutable, and distributed features. Therefore, blockchain-enabled FL provides both theories and techniques to improve the performance of intelligent UAV edge computing networks from various perspectives. This survey begins by discussing the current state of research on blockchain and FL. Then, compare the leading technologies and limitations. Second, we will discuss how to integrate blockchain and FL into UAV edge computing networks and the associated challenges and solutions. Finally, we discuss the fundamental research challenges and future directions.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Chaoyang Zhu et al.",
      "keywords": "Computer science; Edge computing; Blockchain; Edge device; Enhanced Data Rates for GSM Evolution; Distributed computing; Computer network; Computer security; Theoretical computer science; Artificial intelligence; Operating system; Cloud computing",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3174865",
      "cited_by_count": 54,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4385322239",
      "doi": "10.1109/access.2023.3299296",
      "title": "A Survey on Reservoir Computing and its Interdisciplinary Applications Beyond Traditional Machine Learning",
      "abstract": "Reservoir computing (RC), first applied to temporal signal processing, is a\\nrecurrent neural network in which neurons are randomly connected. Once\\ninitialized, the connection strengths remain unchanged. Such a simple structure\\nturns RC into a non-linear dynamical system that maps low-dimensional inputs\\ninto a high-dimensional space. The model's rich dynamics, linear separability,\\nand memory capacity then enable a simple linear readout to generate adequate\\nresponses for various applications. RC spans areas far beyond machine learning,\\nsince it has been shown that the complex dynamics can be realized in various\\nphysical hardware implementations and biological devices. This yields greater\\nflexibility and shorter computation time. Moreover, the neuronal responses\\ntriggered by the model's dynamics shed light on understanding brain mechanisms\\nthat also exploit similar dynamical processes. While the literature on RC is\\nvast and fragmented, here we conduct a unified review of RC's recent\\ndevelopments from machine learning to physics, biology, and neuroscience. We\\nfirst review the early RC models, and then survey the state-of-the-art models\\nand their applications. We further introduce studies on modeling the brain's\\nmechanisms by RC. Finally, we offer new perspectives on RC development,\\nincluding reservoir design, coding frameworks unification, physical RC\\nimplementations, and interaction between RC, cognitive neuroscience and\\nevolution.\\n",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Heng Zhang et al.",
      "keywords": "Reservoir computing; Computer science; Exploit; Flexibility (engineering); Implementation; Computational neuroscience; Artificial intelligence; Coding (social sciences); Recurrent neural network; Dynamical systems theory; Neuromorphic engineering; Computation; Artificial neural network; Theoretical computer science; Machine learning; Algorithm; Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3299296",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2950545134",
      "doi": "10.1109/jproc.2019.2919306",
      "title": "Review and Perspectives on Data Sharing and Privacy in Expanding Electricity Access",
      "abstract": "Increased sensing and data collection in electric power systems from utility to minigrid to individual household scale are resulting in an explosion of data collection about users and providers of electricity services. In the push to expand energy access for poor communities, the collection, use, and curation of these data have historically taken a back seat to the goal of expanding energy access but are increasingly being recognized as important issues. We review the nascent literature on this topic, characterize current data management practices, and examine how expanding access to data and data sharing are likely to provide value and pose risks to key stakeholders: end users of electricity, microutilities, macroutilities, governments, development institutions, and researchers. We identify the key opportunities and tensions and provide recommendations for the design and implementation of new data-sharing practices and platforms. Our review and analysis suggest that although a common and open platform for sharing technical data can mitigate risks and enable efficiency, fewer benefits are likely to be realized from sharing detailed financial data. We also recommend codesigning practices with each stakeholder group, increasing legal protections for end users of electricity and using deep qualitative data in addition to quantitative metrics.",
      "year": "2019",
      "journal": "Proceedings of the IEEE",
      "authors": "Jonathan T. Lee et al.",
      "keywords": "Data sharing; Data collection; Stakeholder; Electricity; Business; Data access; Key (lock); Qualitative property; Open data; Internet privacy; Knowledge management; Data science; Computer science; Environmental economics; Computer security; World Wide Web; Database; Public relations; Engineering; Economics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jproc.2019.2919306",
      "cited_by_count": 21,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3166708802",
      "doi": "10.1109/ojcs.2021.3085846",
      "title": "Lattice: A Vision for Machine Learning, Data Engineering, and Policy Considerations for Digital Agriculture at Scale",
      "abstract": "Digital agriculture, with the incorporation of Internet-of-Things (IoT)-based technologies, presents the ability to control a system at multiple levels (individual, local, regional, and global) and generates tools that allow for improved decision making and higher productivity. Recent advances in IoT hardware, e.g., networks of heterogeneous embedded devices, and software, e.g., lightweight computer vision algorithms and cloud optimization solutions, make it possible to efficiently process data from diverse sources in a connected (smart) farm. By interconnecting these IoT devices, often across large geographical distances, it is possible to collect data at different time scales, including in near real-time (i.e., with delays of only a few tens of seconds). This data can then be used for actionable insights, e.g., precise applications of soil supplements and reduced environmental footprint. Through LATTICE, we present an integrated vision for IoT solutions, data processing, and actionable analytics for digital agriculture. We couple this with discussion of economics and policy considerations that will underlie adoption of such IoT and ML technologies. Our paper starts off with the types of datasets in typical field operations, followed by the lifecycle for the data and storage, cloud and edge analytics, and fast information-retrieval solutions. We discuss what algorithms are proving to be most impactful in this space, e.g., approximate data analytics and on-device/in-network processing. We conclude by discussing analytics for alternative agriculture for generation of biofuels and policy challenges in the implementation of digital agriculture in the wild.",
      "year": "2021",
      "journal": "IEEE Open Journal of the Computer Society",
      "authors": "Somali Chaterji et al.",
      "keywords": "Computer science; Cloud computing; Analytics; Data science; Data analysis; Big data; Precision agriculture; Agriculture; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/ojcs.2021.3085846",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4226104776",
      "doi": "10.1109/access.2022.3178195",
      "title": "Systematic Literature Review on Cyber Situational Awareness Visualizations",
      "abstract": "The dynamics of cyber threats are increasingly complex, making it more challenging than ever for organizations to obtain in-depth insights into their cyber security status. Therefore, organizations rely on Cyber Situational Awareness (CSA) to support them in better understanding the threats and associated impacts of cyber events. Due to the heterogeneity and complexity of cyber security data, often with multidimensional attributes, sophisticated visualization techniques are needed to achieve CSA. However, there have been no previous attempts to systematically review and analyze the scientific literature on CSA visualizations. In this paper, we systematically select and review 54 publications that discuss visualizations to support CSA. We extract data from these papers to identify key stakeholders, information types, data sources, and visualization techniques. Furthermore, we analyze the level of CSA supported by the visualizations, alongside examining the maturity of the visualizations, challenges, and practices related to CSA visualizations to prepare a full analysis of the current state of CSA in an organizational context. Our results reveal certain gaps in CSA visualizations. For instance, the largest focus is on operational-level staff, and there is a clear lack of visualizations targeting other types of stakeholders such as managers, higher-level decision makers, and non-expert users. Most papers focus on threat information visualization, and there is a dearth of papers that visualize impact information, response plans, and information shared within teams. Interestingly, we find that only a few studies proposed visualizations to facilitate up to the <italic>projection</italic> level (i.e., the highest level of CSA), whereas most studies facilitated only the <italic>perception</italic> level (i.e., the lowest level of CSA). Most of the studies provide evidence of the proposed visualizations through toy examples and demonstrations, while only a few visualizations are employed in industrial practice. Based on the results that highlight the important concerns in CSA visualizations, we recommend a list of future research directions.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Liuyue Jiang et al.",
      "keywords": "Situation awareness; Computer science; Visualization; Context (archaeology); Data science; Information visualization; Data visualization; Focus (optics); Situational ethics; Creative visualization; Visual analytics; Knowledge management; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3178195",
      "cited_by_count": 45,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4226048161",
      "doi": "10.1109/access.2022.3162863",
      "title": "Recent Advances in Data Engineering for Networking",
      "abstract": "&lt;p&gt;This tutorial paper examines recent advances in data engineering, focusing on aspects of network management and orchestration. We provide a comprehensive analysis of standardization efforts as well as platform development activities related to data engineering driven network design. We then focus on the integration aspects of the data engineering ecosystem and telecommunication networks. The results of our tutorial investigation show that despite various efforts towards standardization and network management and orchestration platforms, there is still a significant gap in applying recent developments in the evolving data engineering world to the telecommunication domain. New advanced functionalities in data engineering as well as clear separations between the building blocks of data engineering pipelines within the proposed standardized architectures have been overlooked or not explored in detail by the standardization or platform development bodies in the telecommunication domain. Therefore, at the end of the paper, we discuss these gaps and research challenges in the context of future development processes for data engineering-driven network design and applications of data engineering concepts in telecommunication networks. We also propose several recommendations for early adoption of these technologies and frameworks in telecommunication infrastructures and platforms.&lt;/p&gt;",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Engin Zeydan et al.",
      "keywords": "Standardization; Orchestration; Computer science; Context (archaeology); Domain (mathematical analysis); Data management; Data science; Systems engineering; Telecommunications; Software engineering; Engineering; Database",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3162863",
      "cited_by_count": 26,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W3173829101",
      "doi": "10.1109/comst.2021.3090778",
      "title": "Neurosciences and Wireless Networks: The Potential of Brain-Type Communications and Their Applications",
      "abstract": "PUBLISHED",
      "year": "2021",
      "journal": "IEEE Communications Surveys & Tutorials",
      "authors": "Renan C. Moioli et al.",
      "keywords": "Wireless; Computer science; Telecommunications; Cognitive science; Psychology",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/comst.2021.3090778",
      "cited_by_count": 42,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2940848139",
      "doi": "10.1109/comst.2019.2911906",
      "title": "Vehicular Data Space: The Data Point of View",
      "abstract": "Over the years, governments and automakers launched initiatives to improve road traffic efficiency, safety, and people mobility. They have been working on various aspects of intelligent transportation systems (ITSs), which aim to improve decision-making, availability of information, and communication technologies to provide applications and services to boost the transportation systems. The development of new applications and services for ITS depends on the availability of different data sources, what it is not the current case. Many studies focus on the communication issues of applications and their associated challenges. To reveal the recent vehicular data use, we examined the most remarkable studies of the last few years, which describe services and applications for ITS, however with a focus on the data employed by them. We introduce the concept of vehicular data space (VDS), which is then used to describe the vehicular scenario from the perspective of data. Moreover, we outline a taxonomy, according to the different data sources. We also categorize the applications, highlighting the data each one used in their approach. Finally, we present some challenges and open issues related to the process for data creation, data preparation, data processing, and data use. In a nutshell, this paper constitutes one of the first holistic surveys on services and applications for ITSs, focusing on the data used by them, as well as their future challenges.",
      "year": "2019",
      "journal": "IEEE Communications Surveys & Tutorials",
      "authors": "Paulo H. L. Rettore et al.",
      "keywords": "Computer science; Data science; Intelligent transportation system; Categorization; Process (computing); Focus (optics); Open research; Database-centric architecture; World Wide Web; Transport engineering; Software; Artificial intelligence; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/comst.2019.2911906",
      "cited_by_count": 29,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4392940311",
      "doi": "10.1109/jstars.2024.3378348",
      "title": "Multimodal Colearning Meets Remote Sensing: Taxonomy, State of the Art, and Future Works",
      "abstract": "In remote sensing (RS), multiple modalities of data are usually available, e.g., RGB, multispectral, hyperspectral, light detection and ranging (LiDAR), and synthetic aperture radar (SAR). Multimodal machine learning systems, which fuse these rich multimodal data modalities, have shown better performance compared to unimodal systems. Most multimodal research assumes that all modalities are present, aligned, and noiseless during training and testing time. However, in real-world scenarios, it is common to observe that one or more modalities are missing, noisy, and nonaligned, in either training or testing or both. In addition, acquiring large-scale, noise-free annotations is expensive, as a result, lacking sufficient annotated datasets or having to deal with inconsistent labels are open challenges. These challenges can be addressed under a learning paradigm called multimodal colearning. This article focuses on multimodal colearning techniques for RS data. We first review what data modalities are available in the RS domain and the key benefits and challenges of combining multimodal data in the RS context. We then review the RS tasks that would benefit from multimodal processing including classification, segmentation, target detection, anomaly detection, and temporal change detection. We then dive deeper into technical details by reviewing more than 200 recent efforts in this area and provide a comprehensive taxonomy to systematically review state-of-the-art approaches in four key colearning challenges including missing modalities, noisy modalities, limited modality annotations, and weakly paired modalities. Based on these insights, we propose emerging research directions to inform potential future research in multimodal colearning for RS.",
      "year": "2024",
      "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
      "authors": "Nhi Ngo et al.",
      "keywords": "Modalities; Computer science; Multimodal learning; Artificial intelligence; Modality (human\u2013computer interaction); Key (lock); Machine learning; Deep learning; Human\u2013computer interaction",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jstars.2024.3378348",
      "cited_by_count": 23,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387831816",
      "doi": "10.1109/access.2023.3326411",
      "title": "DEFT: A Novel Deep Framework for Fuzz Testing Performance Evaluation in NextG Vulnerability Detection",
      "abstract": "As the evolution of wireless communications advances rapidly, the next-generation (NextG) networks have undeniably become integral components of modern society. However, given the vast infrastructure requirement and the intricacy of their protocols, they inevitably present considerable security challenges. Recently, fuzz testing has emerged as a prominent method of security assurance for 5G and NextG systems. It can test and exploit 5G networks to detect vulnerabilities. This paper proposes a novel modeling framework, coined as DEFT, to perform causation analysis in the system under test (SUT) in detecting the fuzzed location, therefore, DEFT can be further applied to identifying the type of attacks or abnormal inputs from the partial system profiling for the impacted behaviors. In particular, we show, for the first time, that by utilizing the DEFT, we can precisely detect the fuzzed layer in the log file which can then be further utilized to identify the root cause of vulnerabilities with high accuracy using only a tiny segment of the log file in real-time. To test the DEFT, we generate an unbiased dataset by performing fuzz testing to trigger potential vulnerabilities and unintended behaviors on the 5G test bed and recording the system behaviors via regular logging information. We then analyze a random segment of the log files to detect the root cause of the vulnerabilities via the processing of the word embedding vectors that are enabled by two architectures, Skip-gram and continuous bag-of-words (CBOW). The DEFT can effectively identify the fuzzed location and thereby the occurrence of unknown attacks, therefore, can be considered a crucial step in performing a timely attack response and the root cause analysis. We assess multiple machine learning models integrated with the two architectures by the input segment length of log files, computation complexity, and accuracy matrix. It is shown that, for the Skip-gram, an area under the curve (AUC) value of 0.938 is achieved for the Fully Connected Network (FCN) model while considering only 50&#x0025; length of the original log file, thereby significantly reducing the computational complexity. By eliminating the necessity for a 100&#x0025; comprehensive log file and instead utilizing a 50&#x0025; log file, we have effectuated an 8&#x0025; decrease in testing duration. We make an important observation that, compared with CBOW, Skip-gram shows superior performance when only a smaller fraction of the log file is considered for vulnerability detection and, thereby, can readily be applied to real-time 5G applications.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Yifeng Peng et al.",
      "keywords": "Fuzz testing; Vulnerability (computing); Computer science; Vulnerability assessment; Reliability engineering; Artificial intelligence; Computer security; Engineering; Psychology; Operating system",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3326411",
      "cited_by_count": 15,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4394862704",
      "doi": "10.1109/access.2024.3385863",
      "title": "Robustness of Workload Forecasting Models in Cloud Data Centers: A White-Box Adversarial Attack Perspective",
      "abstract": "Cloud computing has become the cornerstone of modern technology, propelling industries to unprecedented heights with its remarkable and recent advances. However, the fundamental challenge for cloud service providers is real-time workload prediction and management for optimal resource allocation. Cloud workloads are characterized by their heterogeneous, unpredictable, and fluctuating nature, making this task even more challenging. As a result of the remarkable achievements of deep learning (DL) algorithms across diverse fields, scholars have begun to embrace this approach to addressing such challenges. It has become the defacto standard for cloud workload prediction. Unfortunately, DL algorithms have been widely recognized for their vulnerability to adversarial examples, which poses a significant challenge to DL-based forecasting models. In this study, we utilize established white-box adversarial attack generation methods from the field of computer vision to construct adversarial cloud workload examples for four cutting-edge deep learning regression models, including Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), 1D Convolutional Neural Network (1D-CNN) and attention-based models. We evaluate our study with three widely recognized cloud benchmark datasets: Google trace, Alibaba trace, and Bitbrain. The findings of our analysis unequivocally indicate that DL-based cloud workload forecasting models are highly vulnerable to adversarial attacks. To the best of our knowledge, we are the first to conduct systematic research exploring the vulnerability of DL-based models for workload forecasting in the cloud data center, highlighting the inherent hazards to both security and cost-effectiveness in cloud data centers. By raising awareness of these vulnerabilities, we advocate the urgent development of robust defensive mechanisms to enhance the security of cloud workload forecasting in a constantly evolving technical landscape.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Nosin Ibna Mahbub et al.",
      "keywords": "Computer science; Cloud computing; Deep learning; Adversarial system; Artificial intelligence; Robustness (evolution); Machine learning; Workload; Convolutional neural network; Data science; Data mining",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3385863",
      "cited_by_count": 9,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4394564211",
      "doi": "10.1109/access.2024.3385017",
      "title": "Exploring the Impact of Computer Applications on Cross-Border E-Commerce Performance",
      "abstract": "In the dynamic landscape of global commerce, cross-border e-commerce has emerged as a critical avenue for businesses to expand their reach and capitalize on international markets. This study focuses on the intricate relationship between computer applications and the performance of cross-border e-commerce ventures. Through a comprehensive analysis of diverse computer applications utilized in cross-border e-commerce settings, this research aims to elucidate their impact on various performance metrics, including sales volume, customer satisfaction, operational efficiency, and market penetration. Drawing upon both qualitative and quantitative methodologies, this investigation examines the deployment of computer applications across different stages of the cross-border e-commerce process, from market research and platform selection to payment processing and post-purchase support. By synthesizing insights from industry case studies, surveys, and statistical analyses, this study seeks to provide valuable insights for businesses aiming to optimize their cross-border e-commerce strategies. The findings of this research contribute to a deeper understanding of the role of computer applications in shaping the dynamics of cross-border e-commerce, offering practical recommendations for businesses to enhance their performance in the global marketplace. Ultimately, this study underscores the crucial importance of leveraging technology to navigate the complexities of cross-border trade and achieve sustainable growth in an increasingly interconnected world.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Lijing Jin et al.",
      "keywords": "Computer science; E-commerce; World Wide Web",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3385017",
      "cited_by_count": 10,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389164466",
      "doi": "10.1109/access.2023.3337806",
      "title": "Blockchain-Based Trust Management for Virtual Entities in the Metaverse: A Model for Avatar and Virtual Organization Interactions",
      "abstract": "As blockchain technology and decentralized systems evolve, the security of these infrastructures faces challenges from increasingly sophisticated threats. This research introduces a methodology designed to strengthen the security parameters of distributed systems, with a specific focus on its applicability within the Metaverse. Our probabilistic trust model dynamically allocates weights to system nodes based on their observed behaviour and the reputation of associated entities. This mechanism effectively counters a range of security threats, including the Sybil, Good/Bad mouthing, and On/Off attacks. By integrating blockchain technology, we establish a robust trust foundation within the Metaverse, ensuring enhanced security for digital interactions. To further combat deceptive activities and reduce superfluous intermediaries, our model incorporates smart contracts. Beyond their transactional utility, these contracts function as trust regulators for interactions among Metaverse avatars. Our trust model efficiently differentiates various virtual entities, assigning trust scores that resonate with their specific classifications. We also introduce a decentralized dispute resolution framework, where virtual entities act as impartial arbiters, promoting transparency and fairness in conflict resolution. We have implemented our proposed solution on real-time blockchain platform in comparison with the existing appraoches, i.e., BTCGS and MSBC-CTrust. The evident enhancements in threat detection capabilities and the agility in neutralizing these threats validate our model&#x2019;s resilience and adaptability.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Kamran Ahmad Awan et al.",
      "keywords": "Computer science; Metaverse; Computer security; Adaptability; Reputation; Avatar; Transparency (behavior); Human\u2013computer interaction; Virtual reality",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3337806",
      "cited_by_count": 14,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4392449608",
      "doi": "10.1109/access.2024.3373786",
      "title": "Greenhouse Gas Emission Reduction Architecture in Computer Science: A Systematic Review",
      "abstract": "Computer Science Architecture (CSA), encompassing data, application, technology, and business architecture, is a vital tool for addressing climate change challenges. It aims to reduce greenhouse gas emissions from sectors such as stationary energy, transportation, industry, product use, waste, and land use. CSA principles extend to advanced technologies like artificial intelligence (AI), the Internet of Things (IoT), Machine Learning (ML), data centers, blockchain, multi-agent systems, sensors, and smart grids. This review explores CSA&#x2019;s role in mitigating greenhouse gas emissions for a sustainable environment. It analyzes implications, indicators, and methodologies for data, application, technology, and business architecture, highlighting their direct impact on creating an environmentally friendly technological landscape. The study also delves into emerging trends and suggestions for future research, contributing to the discourse on leveraging technology for a greener future.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Asep Somantri et al.",
      "keywords": "Reduction (mathematics); Greenhouse gas; Computer science; Architecture; Environmental science; Mathematics; Geology",
      "mesh_terms": "",
      "pub_types": "review",
      "url": "https://doi.org/10.1109/access.2024.3373786",
      "cited_by_count": 18,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4390547602",
      "doi": "10.1109/access.2024.3349510",
      "title": "Generalized Zero-Shot Learning for Action Recognition Fusing Text and Image GANs",
      "abstract": "Generalized Zero-Shot Action Recognition (GZSAR) is geared towards recognizing classes that the model has not been trained on, while still maintaining robust performance on the familiar, trained classes. This approach mitigates the need for an extensive amount of labeled training data and enhances the efficient utilization of available datasets. The main contribution of this paper is a novel approach for GZSAR that combines the power of two Generative Adversarial Networks (GANs). One GAN is responsible for generating embeddings from visual representations, while the other GAN focuses on generating embeddings from textual representations. These generated embeddings are fused, with the selection of the maximum value from each array that represents the embeddings, and this fused data is then utilized to train a GZSAR classifier in a supervised manner.\\nThis framework also incorporates a feature refinement component and an out-of-distribution detector to mitigate the domain shift problem between seen and unseen classes. In our experiments, notable improvements were observed. On the UCF101 benchmark dataset, we achieved a 7.43% increase in performance, rising from 50.93% (utilizing images and Word2Vec alone) to 54.71% with the implementation of two GANs. Additionally, on the HMDB51 dataset, we saw a 7.06% improvement, advancing from 36.11% using Text and Word2Vec to 38.66% with the dual-GAN approach. These results underscore the efficacy of our dualGAN framework in enhancing GZSAR performance. The rest of the paper shows the main contributions to the field of GZSAR and highlights the potential and future lines of research in this exciting area.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Kaiqiang Huang et al.",
      "keywords": "Computer science; Artificial intelligence; Zero (linguistics); Computer vision; Image (mathematics); Pattern recognition (psychology); Shot (pellet); Action (physics); Action recognition; Class (philosophy); Physics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3349510",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4395096806",
      "doi": "10.1109/access.2024.3392916",
      "title": "Federated Versus Central Machine Learning on Diabetic Foot Ulcer Images: Comparative Simulations",
      "abstract": "This research examines the implementation of the U-Net model within a federated learning framework, focusing on the semantic segmentation of Diabetic Foot Ulcers (DFUs) images. The objective is to start with a set of random parameters for a U-Net model and train in a federated learning setting and a centralized setting. Due to the sensitive nature of medical images, we use an open-source dataset of diabetic foot ulcers provided by Medetec. Federated learning enables us to decentralize our approach to machine learning, which eliminates the need for centralizing raw data. Methods used include comparative simulations between federated and centralized machine learning systems. The results indicate that federated learning, combined with the U-Net architecture, eliminates centralized data collection and achieves a notable dice score of 0.9, paralleling the performance of centralized models. This conclusion underscores the potential of federated learning in enhancing detection methods for DFUs, balancing privacy concerns with analytical accuracy. Significantly, this study contributes to the biomedical imaging field by providing a set of federated learning codebases that enable interested researchers to reproduce the results and expand upon them. The source code can be accessed via GitHub.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "Mahdi Saeedi et al.",
      "keywords": "Computer science; Diabetic foot; Artificial intelligence; Machine learning; Diabetic foot ulcer; Foot (prosody); Diabetes mellitus; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3392916",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3139269311",
      "doi": "10.1109/access.2021.3115258",
      "title": "The Digital Agricultural Revolution: A Bibliometric Analysis Literature Review",
      "abstract": "The application of digital technologies in agriculture can improve traditional practices to adapt to climate change, reduce Greenhouse Gases (GHG) emissions, and promote a sustainable intensification for food security. Some authors argued that we are experiencing a Digital Agricultural Revolution (DAR) that will boost sustainable farming. This study aims to find evidence of the ongoing DAR process and clarify its roots, what it means, and where it is heading. We investigated the scientific literature with bibliometric analysis tools to produce an objective and reproducible literature review. We retrieved 4995 articles by querying the Web of Science database in the timespan 2012-2019, and we analyzed the obtained dataset to answer three specific research questions: i) what is the spectrum of the DAR-related terminology?; ii) what are the key articles and the most influential journals, institutions, and countries?; iii) what are the main research streams and the emerging topics? By grouping the authors' keywords reported on publications, we identified five main research streams: Climate-Smart Agriculture (CSA), Site-Specific Management (SSM), Remote Sensing (RS), Internet of Things (IoT), and Artificial Intelligence (AI). To provide a broad overview of each of these topics, we analyzed relevant review articles, and we present here the main achievements and the ongoing challenges. Finally, we showed the trending topics of the last three years (2017, 2018, 2019).",
      "year": "2021",
      "journal": "IEEE Access",
      "authors": "Riccardo Bertoglio et al.",
      "keywords": "Terminology; Agriculture; Computer science; Digital Revolution; Sustainable agriculture; Data science; Digital library; The Internet; Process (computing); World Wide Web; Geography",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/access.2021.3115258",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4386451244",
      "doi": "10.23919/jsc.2023.0011",
      "title": "Developing an Integrated IoT Cloud Based Predictive Conservation Model for Asset Management in Industry 4.0",
      "abstract": "With the advent of Industry 4.0 (I4.0), predictive maintenance (PdM) methods have been widely adopted by businesses to deal with the condition of their machinery. With the help of I4.0, digital transformation, information techniques, computerised control, and communication networks, large amounts of data on operational and process conditions can be collected from multiple pieces of equipment and used to make an automated fault detection and diagnosis, all with the goal of reducing unscheduled maintenance, improving component utilisation, and lengthening the lifespan of the equipment. In this paper, we use smart approaches to create a PdM planning model. The five key steps of the created approach are as follows: (1) cleaning the data, (2) normalising the data, (3) selecting the best features, (4) making a decision about the prediction network, and (5) producing a prediction. At the outset, PdM-related data undergo data cleaning and normalisation to get everything in order and within some kind of bounds. The next step is to execute optimal feature selection in order to eliminate unnecessary data. This research presents the golden search optimization (GSO) algorithm, a powerful population-based optimization technique for efficient feature selection. The first phase of GSO is to produce a set of possible solutions or objects at random. These objects will then interact with one another using a straightforward mathematical model to find the best feasible answer. Due to the wide range over which the prediction values fall, machine learning and deep learning confront challenges in providing reliable predictions. This is why we recommend a multilayer hybrid convolution neural network (MLH-CNN). While conceptually similar to VGGNet, this approach uses fewer parameters while maintaining or improving classification correctness by adjusting the amount of network modules and channels. The projected perfect is evaluated on two datasets to show that it can accurately predict the future state of components for upkeep preparation.",
      "year": "2023",
      "journal": "Journal of Social Computing",
      "authors": "K. Shanmugam et al.",
      "keywords": "Computer science; Predictive maintenance; Process (computing); Asset (computer security); Feature selection; Cloud computing; Key (lock); Artificial intelligence; Set (abstract data type); Machine learning; Asset management; Population; Feature (linguistics); Data mining; Engineering; Reliability engineering; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.23919/jsc.2023.0011",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4323655609",
      "doi": "10.1109/tem.2023.3242518",
      "title": "Editorial Deciphering Convergence: Novel Insights and Future Ideas on Science, Technology, and Industry Convergence",
      "abstract": "",
      "year": "2023",
      "journal": "IEEE Transactions on Engineering Management",
      "authors": "Francesco Paolo Appio et al.",
      "keywords": "Convergence (economics); Technological convergence; Engineering ethics; Management science; Computer science; Engineering; Data science; Economics; Telecommunications; Economic growth",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tem.2023.3242518",
      "cited_by_count": 5,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4312595346",
      "doi": "10.1109/access.2022.3213044",
      "title": "Identifying the Top-<i>k</i> Influential Spreaders in Social Networks: a Survey and Experimental Evaluation",
      "abstract": "Identifying the influential and spreader nodes in complex networks solves many types of complex scientific problems. In social networks, identifying the influential individuals can be useful for structuring techniques that accelerate or hinder information propagation. Each node in the network has unique characteristics that reflect its importance. These characteristics are used by researchers to design many different centrality algorithms. Unfortunately, current survey papers categorize these algorithms into broad classes and do not draw distinguishable boundaries among the specific techniques adopted by them. This can result in misclassifying unrelated algorithms into the same analysis category. To overcome this, we introduce a methodology-based taxonomy for classifying the algorithms that identify top-&lt;inline-formula&gt; &lt;tex-math notation=\"LaTeX\"&gt;$k$ &lt;/tex-math&gt;&lt;/inline-formula&gt; influential spreaders into hierarchically nested, specific, and fine-grained categories. We survey 184 papers and discuss their algorithms, which fall under 26 specific techniques. Our methodological taxonomy classifies the algorithms hierarchically into the following manner: Analysis type &lt;inline-formula&gt; &lt;tex-math notation=\"LaTeX\"&gt;$ \\\\rightarrow $ &lt;/tex-math&gt;&lt;/inline-formula&gt; analysis scope &lt;inline-formula&gt; &lt;tex-math notation=\"LaTeX\"&gt;$ \\\\rightarrow $ &lt;/tex-math&gt;&lt;/inline-formula&gt; analysis approach &lt;inline-formula&gt; &lt;tex-math notation=\"LaTeX\"&gt;$ \\\\rightarrow $ &lt;/tex-math&gt;&lt;/inline-formula&gt; analysis category &lt;inline-formula&gt; &lt;tex-math notation=\"LaTeX\"&gt;$ \\\\rightarrow $ &lt;/tex-math&gt;&lt;/inline-formula&gt; analysis sub-category &lt;inline-formula&gt; &lt;tex-math notation=\"LaTeX\"&gt;$ \\\\rightarrow $ &lt;/tex-math&gt;&lt;/inline-formula&gt; analysis specific technique. We introduce in this paper a comprehensive survey, review, and experimental evaluation of the recent and state-of-the-art algorithms that identify the top-&lt;inline-formula&gt; &lt;tex-math notation=\"LaTeX\"&gt;$k$ &lt;/tex-math&gt;&lt;/inline-formula&gt; and influential spreader nodes in social networks.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "Kamal Taha",
      "keywords": "Computer science; Categorization; Centrality; Social network analysis; Taxonomy (biology); Structuring; Complex network; Scope (computer science); Data mining; Theoretical computer science; Artificial intelligence; Information retrieval; Machine learning; Data science; Social media; World Wide Web; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3213044",
      "cited_by_count": 7,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4360770777",
      "doi": "10.1109/access.2023.3260981",
      "title": "GANs for Privacy-Aware Mobility Modeling",
      "abstract": "Human mobility modeling is crucial for many facets of our society, including disease transmission modeling and urban planning. The explosion of mobility data prompted the application of deep learning to human mobility. Along with the growth of research interest, there is also increasing privacy concern. This study first examines the cutting-edge approaches for trajectory generation, classification, and next-location prediction. Second, we propose a novel privacy-aware approach for predicting next-week trajectories. The approach is based on two modules, a Generative Adversarial Network used for generating synthetic trajectories and a deep learning model for user identification which safeguards privacy. These two modules are combined with a next-week trajectory predictor that uses privacy-aware synthetic data. The experiments on two real-life datasets show that the generator creates trajectories similar to the real ones yet different enough to safeguard privacy. The low user-recognition recognition accuracy of models trained on the generated data demonstrates privacy awareness. Statistical tests confirm no significant difference between the original and the generated trajectories. We further demonstrate the utility of the synthetic data by predicting week-ahead trajectories based on the synthetic trajectories. Our study shows how privacy and utility can be managed jointly using the proposed privacy-aware approach.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Ivan Fontana et al.",
      "keywords": "Computer science; Generator (circuit theory); Artificial intelligence; Machine learning; Information privacy; Identification (biology); Deep learning; Trajectory; Data modeling; Synthetic data; Privacy protection; Generative model; Data mining; Generative grammar; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3260981",
      "cited_by_count": 6,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4206416353",
      "doi": "10.1109/access.2022.3143858",
      "title": "Spatio Temporal Sparsity in Homicide Prediction Models",
      "abstract": "Homicide prediction is a challenging task due to the spatio-temporal sparsity of these crime events. In this paper we report the results of using several approaches to mitigate this sparsity condition in machine learning models specially tailored towards modeling homicides events. Since spatial resolution is a direct determinant of sparsity, we focus on the performance of these models across different resolutions of interest to police authorities. We use a simple count model as benchmark and propose some enhancements of it directed towards improving prediction performance. We then compare the results to more complex models motivated by manifold learning and graph signal processing methods. We found that the simple benchmark models are as good as state of the art models for low resolution, but, as resolution increases, the performance of machine learning models outperform the benchmark. These results provide a rationality for the use of state of the art machine learning models for homicide prediction at the high resolution of interest for the deployment of police resources.",
      "year": "2022",
      "journal": "IEEE Access",
      "authors": "\u00c1lvaro Riascos et al.",
      "keywords": "Computer science; Benchmark (surveying); Machine learning; Artificial intelligence; Focus (optics); Software deployment; Graph; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2022.3143858",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4387415016",
      "doi": "10.1109/access.2023.3322429",
      "title": "Incorporating Feature Interactions and Contrastive Learning for Credit Prediction",
      "abstract": "The efficacy of credit risk assessment models is pivotal to the risk management capacity of financial institutions. Traditional credit risk models often suffer from inadequate predictive accuracy due to overlooked feature combinations and weak supervisory signals. Addressing these limitations, we present a novel approach for credit default prediction that integrates feature interactions and contrastive learning. Specifically, we introduce second-order interactions atop standard linear models to achieve low-order feature interplay. Concurrently, the integration of deep neural networks and attention mechanisms facilitates the learning of concealed high-order features, thus enhancing the model&#x2019;s non-linear modeling capabilities and illuminating latent feature associations. Further, to ameliorate the issues of noise and diminished supervisory signals, we embed slight noise in feature embeddings for data augmentation and construct contrastive views, ultimately refining feature quality. To attest to the effectiveness of our approach, we conducted experiments on two real-world datasets, benchmarking against eight predictive methods including LR, XGBoost, and FiBiNET. The results unequivocally demonstrate the superior performance of our method across various metrics, underscoring its promise and excellence in the realm of credit risk assessment.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Lisi Zhang et al.",
      "keywords": "Computer science; Feature (linguistics); Artificial intelligence; Machine learning",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3322429",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W2931636880",
      "doi": "10.1109/taffc.2020.2964549",
      "title": "Recognition of Advertisement Emotions With Application to Computational Advertising",
      "abstract": "Advertisements (ads) often contain strong affective content to capture viewer attention and convey an effective message to the audience. However, most computational affect recognition (AR) approaches examine ads via the text modality, and only limited work has been devoted to decoding ad emotions from audiovisual or user cues. This work (1) compiles an affective ad dataset capable of evoking coherent emotions across users; (2) explores the efficacy of content-centric convolutional neural network (CNN) features for AR vis-\u00e3-vis handcrafted audio-visual descriptors; (3) examines user-centric ad AR from Electroencephalogram (EEG) responses acquired during ad-viewing, and (4) demonstrates how better affect predictions facilitate effective computational advertising as determined by a study involving 18 users. Experiments reveal that (a) CNN features outperform audiovisual descriptors for content-centric AR; (b) EEG features are able to encode ad-induced emotions better than content-based features; (c) Multi-task learning performs best among a slew of classification algorithms to achieve optimal AR, and (d) Pursuant to (b), EEG features also enable optimized ad insertion onto streamed video, as compared to content-based or manual insertion techniques in terms of ad memorability and overall user experience.",
      "year": "2020",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Abhinav Shukla et al.",
      "keywords": "Computer science; Convolutional neural network; ENCODE; Task (project management); Affective computing; Affect (linguistics); Decoding methods; Electroencephalography; Speech recognition; Artificial intelligence; Psychology; Communication",
      "mesh_terms": "",
      "pub_types": "preprint",
      "url": "https://doi.org/10.1109/taffc.2020.2964549",
      "cited_by_count": 4,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4384915796",
      "doi": "10.1109/access.2023.3296798",
      "title": "SDN Attack Identification Model Based on CNN Algorithm",
      "abstract": "With the complexity of network structure, the requirements for network architecture are also increasing, and Software Defined Network (SDN) technology has emerged. SDN technology has successfully simplified network management, but its open programming nature poses a risk of network attacks. In complex network environments, the recognition accuracy of traditional recognition models cannot meet the requirements of accuracy and speed. In view of this, this research proposes an attack identification model based on Convolutional neural network (CNN), hoping to solve the attack identification problems faced in the SDN environment, improve the accuracy of the model, and ensure the security of SDN. An SDN attack recognition model is constructed using the NSL-KDD dataset and the MITLL DARPA dataset, and the CNN is used to utilize it in SDN. In the performance testing experiment of the model, the results show that the proposed model has an accuracy of 98.25&#x0025; in SDN attack recognition, and its performance is significantly better than traditional CNN models. The accuracy of traditional attack recognition reaches 98.25&#x0025;, and its performance is superior to the KNN-PSO model. The superiority of the model has been verified, further confirming the application value of the research model in SDN attack recognition.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Huimin Xue et al.",
      "keywords": "Computer science; Convolutional neural network; Identification (biology); Machine learning; Artificial intelligence; Artificial neural network; Network security; Data mining; Computer security",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3296798",
      "cited_by_count": 2,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W4389633747",
      "doi": "10.1109/access.2023.3341756",
      "title": "Detecting Low-Credibility Medical Websites Through Semi-Supervised Learning Techniques",
      "abstract": "The rapid spread of biased information and disinformation has intensified in recent times due to the increased reliance on the Internet and social media platforms as primary sources of information. This issue is of particular concern in the fields of medicine and healthcare, given the critical nature of decisions and understandings in these areas. While medical experts can mitigate the repercussions of misinformation by evaluating questionable websites, this approach is time-consuming. Consequently, there is a pressing need to develop software solutions that can automate the detection of misleading information. This paper presents CO-training and Active Learning-based framework for Finding Low-credibility web Addresses in the MEdical field (COAL4FLAME), a novel system designed to analyze health-related websites and identify misinformation. The system integrates results from multiple estimators to reach a comprehensive conclusion. COAL4FLAME uses semi-supervised learning strategies, such as multi-view learning, co-training, and active learning, to address the challenge of limited labeled data, a major strength of the presented proposal. Medical experts have rigorously tested and evaluated the system using a selected set of websites.",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "C\u00e9sar Gonz\u00e1lez-Fern\u00e1ndez et al.",
      "keywords": "Misinformation; Credibility; Computer science; The Internet; Set (abstract data type); Field (mathematics); Artificial intelligence; World Wide Web; Data science; Machine learning; Information retrieval; Computer security; Mathematics",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3341756",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4225886563",
      "doi": "10.1109/tcbb.2022.3165395",
      "title": "Small-Sample Estimation of the Mutational Support and Distribution of SARS-CoV-2",
      "abstract": "We consider the problem of determining the mutational support and distribution of the SARS-CoV-2 viral genome in the small-sample regime. The mutational support refers to the unknown number of sites that may eventually mutate in the SARS-CoV-2 genome while mutational distribution refers to the distribution of point mutations in the viral genome across a population. The mutational support may be used to assess the virulence of the virus and guide primer selection for real-time RT-PCR testing. Estimating the distribution of mutations in the genome of different subpopulations while accounting for the unseen may also aid in discovering new variants. To estimate the mutational support in the small-sample regime, we use GISAID sequencing data and our state-of-the-art polynomial estimation techniques based on new weighted and regularized Chebyshev approximation methods. For distribution estimation, we adapt the well-known Good-Turing estimator. Our analysis reveals several findings: First, the mutational supports exhibit significant differences in the ORF6 and ORF7a regions (older versus younger patients), ORF1b and ORF10 regions (females versus males) and in almost all ORFs (Asia/Europe/North America). Second, even though the N region of SARS-CoV-2 has a predicted 10% mutational support, mutations fall outside of the primer regions recommended by the CDC.",
      "year": "2022",
      "journal": "IEEE/ACM Transactions on Computational Biology and Bioinformatics",
      "authors": "Vishal Rana et al.",
      "keywords": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); Coronavirus disease 2019 (COVID-19); Estimation; Distribution (mathematics); Sample (material); 2019-20 coronavirus outbreak; Biology; Computational biology; Genetics; Virology; Medicine; Mathematics; Engineering; Chromatography; Outbreak; Chemistry; Infectious disease (medical specialty)",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tcbb.2022.3165395",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W4389105025",
      "doi": "10.1109/access.2023.3337651",
      "title": "Investigating Knowledge Structure and Future Directions in IT-Based Business Methods Using Hierarchical Main Path Approach",
      "abstract": "135334",
      "year": "2023",
      "journal": "IEEE Access",
      "authors": "Sejun Yoon et al.",
      "keywords": "Domain knowledge; Computer science; Domain (mathematical analysis); Knowledge management; Metric (unit); Path (computing); Data mining; Knowledge engineering; Data science; Mathematics; Engineering",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2023.3337651",
      "cited_by_count": 1,
      "include": false,
      "screen_reason": "No AI/ML component"
    },
    {
      "openalex_id": "https://openalex.org/W2997725735",
      "doi": "10.1109/taffc.2019.2961881",
      "title": "Holistic Affect Recognition Using PaNDA: Paralinguistic Non-Metric Dimensional Analysis",
      "abstract": "Humans perceive emotion from each other using a holistic perspective, accounting for diverse personal, non-emotional variables that shape expression. In contrast, today's algorithms are mainly designed to recognize emotion in isolation. In this work, we propose a multi-task learning approach to jointly learn the recognition of affective states from speech along with various speaker attributes. A problem with multi-task learning is that sometimes inductive transfer can negatively impact performance. To mitigate negative transfer, we introduce the Paralinguistic Non-metric Dimensional Analysis (PaNDA) method that systematically measures task relatedness and also enables visualizing the topology of affective phenomena as a whole. In addition, we present a generic framework that conflates the concepts of single-task and multi-task learning. Using this framework, we construct two models that demonstrate holistic affect recognition: one treats all tasks as equally related, whereas the other one incorporates the task correlations between a main task and its supporting tasks obtained from PaNDA. Both models employ a multi-task deep neural network, in which separate output layers are used to predict discrete and continuous attributes, while hidden layers are shared across different tasks. On average across 18 classification and regression tasks, the weighted multi-task learning with PaNDA significantly improves performance compared to single-task and unweighted multi-task learning.",
      "year": "2019",
      "journal": "IEEE Transactions on Affective Computing",
      "authors": "Yue Zhang et al.",
      "keywords": "Paralanguage; Affect (linguistics); Metric (unit); Computer science; Communication; Artificial intelligence; Psychology; Engineering; Operations management",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/taffc.2019.2961881",
      "cited_by_count": 0,
      "include": false,
      "screen_reason": "Not health-related"
    },
    {
      "openalex_id": "https://openalex.org/W3025030523",
      "doi": "10.1109/tetc.2020.2993177",
      "title": "Detecting Activities of Daily Living and Routine Behaviours in Dementia Patients Living Alone Using Smart Meter Load Disaggregation",
      "abstract": "The emergence of an ageing population is a significant public health concern. This has led to an increase in the number of people living with progressive neurodegenerative disorders. The strain this places on services means providing 24-hour monitoring is not sustainable. No solution exists to non-intrusively monitor the wellbeing of patients with dementia, resulting in delayed intervention. Using machine learning and signal processing, domestic energy supplies can be disaggregated to detect appliance usage. This enables Activities of Daily Living (ADLs) to be assessed. The aim is to facilitate early intervention and enable patients to stay in their homes for longer. A Support Vector Machine (SVM) and Random Decision Forest classifier are modelled using data from three test homes. The trained models are then used to monitor two patients with dementia during a six-month clinical trial undertaken in partnership with Mersey Care NHS Foundation Trust. In the case of load disaggregation, the SVM achieved (AUC=0.86074, Sen=0.756 and Spec=0.92838). While the Decision Forest achieved (AUC=0.9429, Sen=0.9634 and Spec=0.9634). ADLs are also analysed to identify the behavioural patterns of the occupant while detecting alterations in routine. The approach is sensitive in identifying behavioural routines and detecting anomalies in patient behaviour.",
      "year": "2020",
      "journal": "IEEE Transactions on Emerging Topics in Computing",
      "authors": "Carl Chalmers et al.",
      "keywords": "Dementia; Activities of daily living; Random forest; Support vector machine; Independent living; Smart meter; Computer science; Medicine; General partnership; Gerontology; Machine learning; Artificial intelligence; Physical therapy; Engineering; Business; Disease; Pathology; Smart grid",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/tetc.2020.2993177",
      "cited_by_count": 71,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4391892547",
      "doi": "10.1109/access.2024.3366537",
      "title": "A Novel Early Detection and Prevention of Coronary Heart Disease Framework Using Hybrid Deep Learning Model and Neural Fuzzy Inference System",
      "abstract": "Diabetes is the &#x201C;mother of all diseases&#x201D; as it affects multiple organs of body of an individual in some way. Its timely detection and management are critically important. Otherwise, the long run, it can cause several complications in a diabetic. Heart disease is one of the major complications of diabetes.This work proposed an Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM), SBGC-LSTM enhanced by Eurygaster Optimization Algorithm (EOA) to tune hyperparameters for early prevention and detection of diabetes disease. This work proposed an Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM), SBGC-LSTM enhanced by Eurygaster Optimization Algorithm (EOA) to tune hyperparameters for early prevention and detection of diabetes disease. This method not only captures discriminative features in spatial configuration and temporal dynamics but also explore the co-occurrence relationship between spatial and temporal domains. This method also presents a temporal hierarchical architecture to increase temporal receptive fields of top SBGC-LSTM layer, which boosts the ability to learn high-level semantic representation and significantly reduces computation cost. The performance of O-SBGC-LSTM was found overall to be satisfactory, reaching &#x003E;98&#x0025; accuracy in most studies. In comparison with classic machine learning approaches, proposed hybrid DL was found to achieve better performance in almost all studies that reported such comparison outcomes. Furthermore, prevention is better than cure. Additionally, employed fuzzy based inference techniques to enhance the prevention procedure using suggestion table.",
      "year": "2024",
      "journal": "IEEE Access",
      "authors": "B. Ramesh et al.",
      "keywords": "Computer science; Artificial intelligence; Artificial neural network; Deep learning; Inference; Fuzzy inference system; Fuzzy inference; Fuzzy control system; Fuzzy logic; Inference system; Adaptive neuro fuzzy inference system; Coronary heart disease; Backpropagation; Machine learning; Internal medicine; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2024.3366537",
      "cited_by_count": 50,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W3111876549",
      "doi": "10.1109/access.2020.3042451",
      "title": "Remote Physical Frailty Monitoring\u2013 The Application of Deep Learning-Based Image Processing in Tele-Health",
      "abstract": "Remote screening physical frailty (PF) may assist in triaging patients with chronic obstructive pulmonary disease (COPD) who are in clinical priorities to visit a clinical center for preventive care. Conventional PF assessment tools have however limited feasibility for remote patient monitoring applications. To improve the safety of PF assessment, we previously developed and validated a quick and safe PF screening tool called Frailty Meter (FM). FM works by quantifying weakness, slowness, rigidity, and exhaustion during a 20-second repetitive elbow flexion/extension task using a wrist-worn sensor and generates a frailty index (FI) ranging from zero to one; higher values indicate progressively greater severity of frailty. However, the use of wrist-sensor limits its applications in telemedicine and remote patient monitoring. In this study, we developed a sensor-less FM based on deep learning-based image processing, which can be easily integrated into mobile health and enables remote assessment of physical frailty. The sensor-less FM extracts kinematic features of the forearm motion from the video of 20-second elbow flexion and extension recorded by a tablet camera, and then calculates frailty phenotypes and FI. To test the validity of sensor-less FM, 11 COPD patients admitted to a Telehealth pulmonary rehabilitation clinic and 10 healthy young volunteers (controls) were recruited. All participants completed the test indicating high feasibility. Strong correlations (0.72 <i><</i> r <i><</i> 0.99) were observed between the sensor-based FM and sensor-less FM to extract all frailty phenotypes and FI. After adjusting with age and body mass index(BMI), sensor-less FM enables distinguishing COPD group from controls (p<i><</i>0.050) with the largest effect sizes observed for weakness (Cohen's effect size d=2.24), frailty index (d=1.70), and slowness (d=1.70). These pilot findings suggest feasibility and proof of concept validity of this sensor-less FM toward remote assessment of PF in COPD patients.",
      "year": "2020",
      "journal": "IEEE Access",
      "authors": "Mohsen Zahiri et al.",
      "keywords": "Telemedicine; Medicine; Telehealth; Remote patient monitoring; Accelerometer; Physical medicine and rehabilitation; Wrist; COPD; Artificial intelligence; Computer science; Physical therapy; Health care; Surgery",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2020.3042451",
      "cited_by_count": 31,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2956513391",
      "doi": "10.1109/access.2019.2928579",
      "title": "An Interpretable Disease Onset Predictive Model Using Crossover Attention Mechanism From Electronic Health Records",
      "abstract": "Analysis of patients' Electronic Health Records (EHRs) can help guide the prevention of diseases and personalization of treatment. Therefore, it is an important task to predict the disease onset information (referred to as medical codes in this paper) within the upcoming visit based on patients' EHR data. In order to achieve this objective, the real-time nature and high dimensionality of EHR data must be addressed. Moreover, the prediction results of the model must be interpretable. Existing methods mainly use Recurrent Neural Networks (RNNs) to model EHR data and adopt attention mechanism to provide interpretability. However, diagnosis and treatment information have usually been regarded as the same kind of information, the difference and relationship between the two parts being ignored. This has led to unclear analysis about the patient's disease development and inaccurate prediction results. To address this limitation, we propose a CrossOver Attention Model (COAM). This model adopts two RNNs to process diagnosis and treatment information, respectively, and then deploys a crossover attention mechanism to improve prediction accuracy by leveraging the correlation between the two parts of information. It can learn effective representations of personal medical diagnosis and treatment, and provide interpretable prediction results. Experiments demonstrate that COAM can significantly improve the accuracy of prediction and provide clinically meaningful explanations.",
      "year": "2019",
      "journal": "IEEE Access",
      "authors": "Wei Guo et al.",
      "keywords": "Interpretability; Computer science; Crossover; Machine learning; Artificial intelligence; Mechanism (biology); Recurrent neural network; Personalization; Health records; Task (project management); Process (computing); Medical record; Data mining; Medical classification; Artificial neural network; Health care; Medicine",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/access.2019.2928579",
      "cited_by_count": 28,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W2013938307",
      "doi": "10.1109/jbhi.2014.2353031",
      "title": "Stabilizing High-Dimensional Prediction Models Using Feature Graphs",
      "abstract": "We investigate feature stability in the context of clinical prognosis derived from high-dimensional electronic medical records. To reduce variance in the selected features that are predictive, we introduce Laplacian-based regularization into a regression model. The Laplacian is derived on a feature graph that captures both the temporal and hierarchic relations between hospital events, diseases, and interventions. Using a cohort of patients with heart failure, we demonstrate better feature stability and goodness-of-fit through feature graph stabilization.",
      "year": "2014",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "authors": "Shivapratap Gopakumar et al.",
      "keywords": "Regularization (linguistics); Feature (linguistics); Computer science; Artificial intelligence; Pattern recognition (psychology); Context (archaeology); Graph; Stability (learning theory); Data mining; Machine learning; Theoretical computer science",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/jbhi.2014.2353031",
      "cited_by_count": 13,
      "include": false,
      "screen_reason": "Bias/fairness not central topic"
    },
    {
      "openalex_id": "https://openalex.org/W4319879392",
      "doi": "10.1109/mc.2022.3213209",
      "title": "Detecting Systematic Deviations in Data and Models",
      "abstract": "Trustworthy artificial intelligence researchers should seek to better detect and characterize systematic deviations in data and models (that is, bias). This article provides data scientists with motivation, theory, code, and examples on how to perform disciplined discovery of systematic deviations in data and models at the subset level.",
      "year": "2023",
      "journal": "Computer",
      "authors": "Skyler Speakman et al.",
      "keywords": "Computer science; Trustworthiness; Data mining; Data science; Large deviations theory; Code (set theory); Data modeling; Artificial intelligence; Machine learning; Software engineering; Computer security; Statistics; Programming language",
      "mesh_terms": "",
      "pub_types": "article",
      "url": "https://doi.org/10.1109/mc.2022.3213209",
      "cited_by_count": 8,
      "include": false,
      "screen_reason": "Not health-related"
    }
  ],
  "query_stats": [
    {
      "id": "Q1",
      "label": "Core: algorithmic bias/fairness + health",
      "search": "algorithmic bias fairness health healthcare clinical medical",
      "results_found": 307,
      "results": 307,
      "new_unique": 307,
      "cumulative": 307
    },
    {
      "id": "Q2",
      "label": "AI bias mitigation health",
      "search": "AI bias mitigation debiasing health healthcare clinical",
      "results_found": 14,
      "results": 14,
      "new_unique": 3,
      "cumulative": 310
    },
    {
      "id": "Q3",
      "label": "Machine learning fairness health",
      "search": "machine learning fairness bias health clinical medical",
      "results_found": 447,
      "results": 447,
      "new_unique": 152,
      "cumulative": 462
    },
    {
      "id": "Q4",
      "label": "Bias assessment AI healthcare",
      "search": "bias assessment evaluation audit artificial intelligence healthcare",
      "results_found": 172,
      "results": 172,
      "new_unique": 131,
      "cumulative": 593
    },
    {
      "id": "Q5",
      "label": "Racial gender bias clinical AI",
      "search": "racial gender bias clinical prediction algorithm machine learning",
      "results_found": 40,
      "results": 40,
      "new_unique": 17,
      "cumulative": 610
    },
    {
      "id": "Q6",
      "label": "Health disparities AI algorithm",
      "search": "health disparities algorithmic bias machine learning deep learning",
      "results_found": 320,
      "results": 320,
      "new_unique": 246,
      "cumulative": 856
    },
    {
      "id": "Q7",
      "label": "Fairness-aware ML health",
      "search": "fairness-aware machine learning equalized odds demographic parity health",
      "results_found": 3,
      "results": 3,
      "new_unique": 1,
      "cumulative": 857
    },
    {
      "id": "Q8",
      "label": "Bias EHR clinical decision support",
      "search": "bias electronic health record clinical decision support algorithm",
      "results_found": 581,
      "results": 581,
      "new_unique": 400,
      "cumulative": 1257
    },
    {
      "id": "Q9",
      "label": "Bias medical imaging AI",
      "search": "bias medical imaging radiology dermatology deep learning AI",
      "results_found": 20,
      "results": 20,
      "new_unique": 7,
      "cumulative": 1264
    },
    {
      "id": "Q10",
      "label": "Equitable AI health",
      "search": "equitable AI health equity fairness algorithm clinical",
      "results_found": 12,
      "results": 12,
      "new_unique": 4,
      "cumulative": 1268
    },
    {
      "id": "Q11",
      "label": "NLP bias clinical health",
      "search": "natural language processing bias clinical health medical NLP",
      "results_found": 208,
      "results": 208,
      "new_unique": 71,
      "cumulative": 1339
    },
    {
      "id": "Q12",
      "label": "Bias federated learning health",
      "search": "bias fairness federated learning health clinical",
      "results_found": 81,
      "results": 81,
      "new_unique": 1,
      "cumulative": 1340
    },
    {
      "id": "Q13",
      "label": "LLM bias health",
      "search": "large language model bias health clinical medical",
      "results_found": 807,
      "results": 807,
      "new_unique": 296,
      "cumulative": 1636
    },
    {
      "id": "Q14",
      "label": "Disparate impact health prediction",
      "search": "disparate impact health prediction model algorithm bias",
      "results_found": 89,
      "results": 89,
      "new_unique": 44,
      "cumulative": 1680
    },
    {
      "id": "Q15",
      "label": "Bias risk prediction clinical",
      "search": "bias risk prediction mortality readmission clinical algorithm",
      "results_found": 43,
      "results": 43,
      "new_unique": 7,
      "cumulative": 1687
    }
  ],
  "meta": {
    "total_unique": 1687,
    "ta_included": 23,
    "ft_screened": 0,
    "ft_unavailable": 23,
    "ft_excluded": 0
  },
  "db": "ieee"
}